<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9624028</article-id>
    <article-id pub-id-type="publisher-id">5009</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-022-05009-x</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MLAGO: machine learning-aided global optimization for Michaelis constant estimation of kinetic modeling</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Maeda</surname>
          <given-names>Kazuhiro</given-names>
        </name>
        <address>
          <email>kmaeda@bio.kyutech.ac.jp</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hatae</surname>
          <given-names>Aoi</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sakai</surname>
          <given-names>Yukie</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Boogerd</surname>
          <given-names>Fred C.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kurata</surname>
          <given-names>Hiroyuki</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.258806.1</institution-id><institution-id institution-id-type="ISNI">0000 0001 2110 1386</institution-id><institution>Department of Bioscience and Bioinformatics, </institution><institution>Kyushu Institute of Technology, </institution></institution-wrap>680-4 Kawazu, Iizuka, Fukuoka 820-8502 Japan </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.12380.38</institution-id><institution-id institution-id-type="ISNI">0000 0004 1754 9227</institution-id><institution>Department of Molecular Cell Biology, Faculty of Science, </institution><institution>VU University Amsterdam, </institution></institution-wrap>O|2 Building, Amsterdam, The Netherlands </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>1</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>1</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>455</elocation-id>
    <history>
      <date date-type="received">
        <day>29</day>
        <month>8</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>26</day>
        <month>10</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Kinetic modeling is a powerful tool for understanding the dynamic behavior of biochemical systems. For kinetic modeling, determination of a number of kinetic parameters, such as the Michaelis constant (K<sub>m</sub>), is necessary, and global optimization algorithms have long been used for parameter estimation. However, the conventional global optimization approach has three problems: (i) It is computationally demanding. (ii) It often yields unrealistic parameter values because it simply seeks a better model fitting to experimentally observed behaviors. (iii) It has difficulty in identifying a unique solution because multiple parameter sets can allow a kinetic model to fit experimental data equally well (the non-identifiability problem).</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">To solve these problems, we propose the Machine Learning-Aided Global Optimization (MLAGO) method for K<sub>m</sub> estimation of kinetic modeling. First, we use a machine learning-based K<sub>m</sub> predictor based only on three factors: EC number, KEGG Compound ID, and Organism ID, then conduct a constrained global optimization-based parameter estimation by using the machine learning-predicted K<sub>m</sub> values as the reference values. The machine learning model achieved relatively good prediction scores: RMSE = 0.795 and R<sup>2</sup> = 0.536, making the subsequent global optimization easy and practical. The MLAGO approach reduced the error between simulation and experimental data while keeping K<sub>m</sub> values close to the machine learning-predicted values. As a result, the MLAGO approach successfully estimated K<sub>m</sub> values with less computational cost than the conventional method. Moreover, the MLAGO approach uniquely estimated K<sub>m</sub> values, which were close to the measured values.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">MLAGO overcomes the major problems in parameter estimation, accelerates kinetic modeling, and thus ultimately leads to better understanding of complex cellular systems. The web application for our machine learning-based K<sub>m</sub> predictor is accessible at <ext-link ext-link-type="uri" xlink:href="https://sites.google.com/view/kazuhiro-maeda/software-tools-web-apps">https://sites.google.com/view/kazuhiro-maeda/software-tools-web-apps</ext-link>, which helps modelers perform MLAGO on their own parameter estimation tasks.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12859-022-05009-x.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Simulation</kwd>
      <kwd>Michaelis constant</kwd>
      <kwd>Kinetic modeling</kwd>
      <kwd>Parameter estimation</kwd>
      <kwd>Machine learning</kwd>
      <kwd>Global optimization</kwd>
      <kwd>Systems biology</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001691</institution-id>
            <institution>Japan Society for the Promotion of Science</institution>
          </institution-wrap>
        </funding-source>
        <award-id>22K12247</award-id>
        <award-id>22H03688</award-id>
        <principal-award-recipient>
          <name>
            <surname>Maeda</surname>
            <given-names>Kazuhiro</given-names>
          </name>
          <name>
            <surname>Kurata</surname>
            <given-names>Hiroyuki</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002241</institution-id>
            <institution>Japan Science and Technology Agency</institution>
          </institution-wrap>
        </funding-source>
        <award-id>JPMJPR20K8</award-id>
        <principal-award-recipient>
          <name>
            <surname>Maeda</surname>
            <given-names>Kazuhiro</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par4">Kinetic modeling is essential for understanding the dynamic behavior of biochemical networks [<xref ref-type="bibr" rid="CR1">1</xref>]. Kinetic models consist of sets of ordinary differential equations (ODEs) with various kinetic parameters, such as Michaelis constants (K<sub>m</sub>s). K<sub>m</sub> is the substrate concentration at which an enzyme operates at its half-maximal catalytic rate [<xref ref-type="bibr" rid="CR2">2</xref>]. Most kinetic parameters have not been measured because they are traditionally measured in laborious low-throughput assays. Moreover, as kinetic parameters are measured under different experimental settings and often in vitro [<xref ref-type="bibr" rid="CR3">3</xref>], even if the measured values are available, fine-tuning is still required to develop a realistic kinetic model that captures in vivo cellular behavior [<xref ref-type="bibr" rid="CR4">4</xref>]. Kinetic parameter estimation has been a significant bottleneck in kinetic modeling [<xref ref-type="bibr" rid="CR5">5</xref>].</p>
    <p id="Par5">Global optimization algorithms are often used to estimate kinetic parameters. In global optimization, the values of kinetic parameters are optimized so that models best fit the experimental data. Although different algorithms and software tools have been developed (e.g., [<xref ref-type="bibr" rid="CR6">6</xref>–<xref ref-type="bibr" rid="CR12">12</xref>]), the global optimization approach is time-consuming due to the large number of model parameters, nonlinear dynamics, and multiple local optima [<xref ref-type="bibr" rid="CR13">13</xref>]. The conventional approach often yields unrealistic parameter values (e.g., extremely small or large values) because it simply seeks a better fit to the experimental data. Moreover, it often leads to nonunique solutions because different parameter sets allow a kinetic model to fit experimental data equally well [<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR15">15</xref>]. The problem of parameter non-identifiability makes the subsequent simulation studies difficult.</p>
    <p id="Par6">A few recent studies proposed alternative approaches: machine learning-based predictors for kinetic parameters. Heckmann et al. [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>] and Li et al. [<xref ref-type="bibr" rid="CR18">18</xref>] employed machine and deep learning models to predict enzyme turnover numbers (k<sub>cat</sub>s). Kroll et al. [<xref ref-type="bibr" rid="CR19">19</xref>] developed machine and deep learning models that predict K<sub>m</sub> values. However, a few critical problems remain to be addressed. First, these predictors rely on a number of different features for substrates and enzymes, which are typically hard to obtain. For instance, the machine learning predictors proposed by [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>] require enzyme’s structural information, which is not broadly available for most enzymes. Moreover, the existing studies have not tested whether the predicted kinetic parameters are useful for kinetic modeling.</p>
    <p id="Par7">To overcome these limitations, we propose the Machine Learning-Aided Global Optimization (MLAGO) for K<sub>m</sub> estimation of kinetic modeling. First, we develop a machine learning model for K<sub>m</sub> prediction. Unlike the previous study [<xref ref-type="bibr" rid="CR19">19</xref>], our machine learning model is based merely on EC number, KEGG Compound ID, and Organism ID. For the independent test dataset, there was only a four-fold difference between the measured and predicted K<sub>m</sub> values on average. Then, we used the predicted K<sub>m</sub> values as the reference values for the constrained global optimization-based parameter estimation. Through the real-world parameter estimation problems, we demonstrate that the MLAGO method can estimate K<sub>m</sub> values with less computational cost than the conventional method. Moreover, we show that the MLAGO method could uniquely estimate realistic K<sub>m</sub> values, which enable the kinetic models to fit experimental data.</p>
  </sec>
  <sec id="Sec2">
    <title>Results</title>
    <sec id="Sec3">
      <title>Kinetic modeling</title>
      <p id="Par8">Kinetic models for biochemical networks are formulated as ODEs:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{d{\mathbf{x}}}}{dt} = f(t,{\mathbf{x}},{\mathbf{p}}),$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">dt</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2022_5009_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <italic>t</italic> is time, <bold>x</bold> is a variable vector representing molecular concentrations, and <bold>p</bold> is a kinetic parameter vector including K<sub>m</sub>s. Parameter estimation is a task to find <bold>p</bold> that enables the model to fit the experimental data.</p>
      <p id="Par9">A model’s badness-of-fit (BOF) to the experimental data can be calculated as follows:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$BOF({\mathbf{p}}) = \sqrt {n_{exp}^{ - 1} \cdot n_{point}^{ - 1} \cdot n_{mol}^{ - 1} \cdot \sum\limits_{i = 1}^{{n_{exp} }} {\sum\limits_{j = 1}^{{n_{point} }} {\sum\limits_{k = 1}^{{n_{mol} }} {\left( {\frac{{x_{i,j,k}^{sim} ({\mathbf{p}}) - x_{i,j,k}^{exp} }}{{x_{i,j,k}^{exp} }}} \right)^{2} } } } } ,$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:mi>B</mml:mi><mml:mi>O</mml:mi><mml:mi>F</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">exp</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>·</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">point</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>·</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">mol</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>·</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">exp</mml:mi></mml:mrow></mml:msub></mml:munderover><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">point</mml:mi></mml:mrow></mml:msub></mml:munderover><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">mol</mml:mi></mml:mrow></mml:msub></mml:munderover><mml:msup><mml:mfenced close=")" open="("><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">sim</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">exp</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">exp</mml:mi></mml:mrow></mml:msubsup></mml:mfrac></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:msqrt><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2022_5009_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <bold>p</bold> = (<italic>p</italic><sub>1</sub>, <italic>p</italic><sub>2</sub>, …) is a set of kinetic parameters used in the model. <inline-formula id="IEq1"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{i,j,k}^{sim}$$\end{document}</tex-math><mml:math id="M6"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">sim</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq1.gif"/></alternatives></inline-formula> and <inline-formula id="IEq2"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{i,j,k}^{exp}$$\end{document}</tex-math><mml:math id="M8"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">exp</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq2.gif"/></alternatives></inline-formula> are simulated and measured molecular concentrations, respectively. <italic>n</italic><sub><italic>exp</italic></sub>, <italic>n</italic><sub><italic>point</italic></sub>, and <italic>n</italic><sub><italic>mol</italic></sub> are the numbers of experimental conditions, data points, and measured molecular components, respectively.</p>
      <p id="Par10">In kinetic modeling, kinetic parameter values not only need to provide a good model fit to experimental data but also need to be biologically reasonable. If the models require unrealistic parameter values for a good fit, they fail to comply with reality. The implausibility of a set of estimated parameter values can be calculated as the root mean squared error (RMSE):<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$RMSE({\mathbf{q}},{\mathbf{q}}*) = \sqrt {n_{param}^{ - 1} \cdot \sum\limits_{i = 1}^{{n_{param} }} {\left( {q_{i} - q_{i} *} \right)^{2} } } .$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mrow><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">q</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">q</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">param</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>·</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">param</mml:mi></mml:mrow></mml:msub></mml:munderover><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt><mml:mo>.</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2022_5009_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par11">As kinetic parameters take a large order of magnitude, we calculate RMSE on log<sub>10</sub>-scale. <inline-formula id="IEq3"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{q}} = (q_{1} ,q_{2} , \ldots )$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:mi mathvariant="bold">q</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq3.gif"/></alternatives></inline-formula> and <inline-formula id="IEq4"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{q}}* = (q_{1} *,q_{2} *, \ldots )$$\end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:mi mathvariant="bold">q</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq4.gif"/></alternatives></inline-formula> are the log<sub>10</sub>-scaled estimated and reference parameter vectors, respectively. In other words, <inline-formula id="IEq5"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$q_{i} = \log_{10} (p_{i} )$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mo>log</mml:mo><mml:mn>10</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq5.gif"/></alternatives></inline-formula> and <inline-formula id="IEq6"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$q_{i} * = \log_{10} (p_{i} *)$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mo>log</mml:mo><mml:mn>10</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq6.gif"/></alternatives></inline-formula>, where <inline-formula id="IEq7"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{i}$$\end{document}</tex-math><mml:math id="M20"><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq7.gif"/></alternatives></inline-formula> and <inline-formula id="IEq8"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p_{i} *$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq8.gif"/></alternatives></inline-formula> are the estimated and reference values, respectively. <italic>Reference</italic> refers to the values considered reasonable, such as measured values, and machine learning-predicted values.</p>
      <p id="Par12">Taken together, it is essential in kinetic modeling to find realistic kinetic parameter values that provide a good fit to experimental data, i.e., a kinetic parameter vector (<bold>p</bold>) that provides small BOF and RMSE values.</p>
    </sec>
    <sec id="Sec4">
      <title>Conventional global optimization approach</title>
      <p id="Par13">In the conventional global optimization approach, the parameter estimation problem is formulated as the following optimization problem:<disp-formula id="Equ4"><label>4a</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{Minimize}}\quad \, BOF({\mathbf{p}}),$$\end{document}</tex-math><mml:math id="M24" display="block"><mml:mrow><mml:mtext>Minimize</mml:mtext><mml:mspace width="1em"/><mml:mspace width="0.166667em"/><mml:mi>B</mml:mi><mml:mi>O</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2022_5009_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ5"><label>4b</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{Subject}}\;{\text{to}}\quad {\mathbf{p}}^{L} \le {\mathbf{p}} \le {\mathbf{p}}^{U} ,$$\end{document}</tex-math><mml:math id="M26" display="block"><mml:mrow><mml:mtext>Subject</mml:mtext><mml:mspace width="0.277778em"/><mml:mtext>to</mml:mtext><mml:mspace width="1em"/><mml:msup><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msup><mml:mo>≤</mml:mo><mml:mi mathvariant="bold">p</mml:mi><mml:mo>≤</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mi>U</mml:mi></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2022_5009_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <bold>p</bold> = (<italic>p</italic><sub>1</sub>, <italic>p</italic><sub>2</sub>, …) is a set of kinetic parameters to be searched. BOF is the badness-of-fit [Eq. (<xref rid="Equ2" ref-type="">2</xref>)]. <bold>p</bold><sup><italic>L</italic></sup> and <bold>p</bold><sup><italic>U</italic></sup> are the lower and upper bound vectors, respectively. Equation (<xref rid="Equ5" ref-type="">4b</xref>) defines the search space. To cover the vast majority of K<sub>m</sub> values (&gt; 99%), we set a relatively large search space throughout this study: <bold>p</bold><sup><italic>L</italic></sup> = 10<sup>−5</sup> mM and <bold>p</bold><sup><italic>U</italic></sup> = 10<sup>3</sup> mM. The conventional approach simply seeks the parameter set that minimizes BOF, and the parameters can take any value within the lower and upper bounds without any penalties. Therefore, the estimated parameter values can be biologically unreasonable.</p>
      <p id="Par14">Global optimization algorithms are used for the global optimization approach, such as differential evolution [<xref ref-type="bibr" rid="CR20">20</xref>], particle swarm optimization [<xref ref-type="bibr" rid="CR21">21</xref>, <xref ref-type="bibr" rid="CR22">22</xref>], and scatter search [<xref ref-type="bibr" rid="CR23">23</xref>, <xref ref-type="bibr" rid="CR24">24</xref>]. In this study, we used a particular real-coded genetic algorithm (RCGA), named the real-coded ensemble crossover star with just generation gap (REX<sup>star</sup>/JGG) [<xref ref-type="bibr" rid="CR25">25</xref>]. REX<sup>star</sup>/JGG has been demonstrated competitive in parameter estimation tasks [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR26">26</xref>–<xref ref-type="bibr" rid="CR28">28</xref>]. We employed the implementation provided by RCGAToolbox [<xref ref-type="bibr" rid="CR7">7</xref>].</p>
    </sec>
    <sec id="Sec5">
      <title>Machine learning-aided global optimization (MLAGO)</title>
      <p id="Par15">In the conventional approach, the estimated parameter values can be biologically unrealistic (a large RMSE). In contrast, machine learning models may be able to predict reasonable parameter values based on available data on databases. However, the predicted values may not provide a good model fitting because the machine learning predictors do not take BOF into account.</p>
      <p id="Par16">To overcome these limitations, we propose the machine learning-aided global optimization (MLAGO) (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). In this study, we focus on a specific type of kinetic parameters, K<sub>m</sub>s, which commonly appear in kinetic models. First, we use a machine learning model to predict unknown K<sub>m</sub>s in a kinetic model of interest. Then, we use the predicted K<sub>m</sub>s as reference values in the global optimization-based parameter estimation. More specifically, we formulate the parameter estimation task as the constrained global optimization problem:<disp-formula id="Equ6"><label>5a</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{Minimize}}\;RMSE({\mathbf{q}},{\mathbf{q}}^{ML} ),$$\end{document}</tex-math><mml:math id="M28" display="block"><mml:mrow><mml:mtext>Minimize</mml:mtext><mml:mspace width="0.277778em"/><mml:mi>R</mml:mi><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">q</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ML</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2022_5009_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ7"><label>5b</label><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\text{Subject}}\;{\text{to}}\;BOF({\mathbf{p}}) \le AE,$$\end{document}</tex-math><mml:math id="M30" display="block"><mml:mrow><mml:mtext>Subject</mml:mtext><mml:mspace width="0.277778em"/><mml:mtext>to</mml:mtext><mml:mspace width="0.277778em"/><mml:mi>B</mml:mi><mml:mi>O</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">p</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:mi>A</mml:mi><mml:mi>E</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2022_5009_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ8"><label>5c</label><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{p}}^{L} \le {\mathbf{p}} \le {\mathbf{p}}^{U} ,$$\end{document}</tex-math><mml:math id="M32" display="block"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msup><mml:mo>≤</mml:mo><mml:mi mathvariant="bold">p</mml:mi><mml:mo>≤</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mi>U</mml:mi></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2022_5009_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula><fig id="Fig1"><label>Fig. 1</label><caption><p>Overview of MLAGO, the machine learning-aided global optimization. Based on the enzyme information of EC number, Compound ID, and Organism ID, the machine learning model, which is trained and tested with 17,151 enzyme reaction data, predicts the values for unknown K<sub>m</sub>s in a kinetic model. The predicted K<sub>m</sub> values are used as the reference values in the constrained global optimization. Finally, a global optimization algorithm estimates K<sub>m</sub> values so that the kinetic model fits experimental data. <bold>p</bold> is a set of K<sub>m</sub>s to be searched, and <bold>q</bold> is log<sub>10</sub>-transformed <bold>p</bold>. <bold>q</bold><sup><italic>ML</italic></sup> is log<sub>10</sub>-transformed machine learning-predicted K<sub>m</sub>s. <bold>p</bold><sup><italic>L</italic></sup> and <bold>p</bold><sup><italic>U</italic></sup> are the lower and upper bound vectors, respectively. Abbreviations: ML (machine learning), RMSE (root mean squared error), and BOF (badness of fit), AE (allowable error). For RMSE, BOF, and AE, see the main text</p></caption><graphic xlink:href="12859_2022_5009_Fig1_HTML" id="MO1"/></fig>where <bold>p</bold> = (<italic>p</italic><sub>1</sub>, <italic>p</italic><sub>2</sub>, …) is a set of kinetic parameters (i.e., K<sub>m</sub>s) to be searched, and <bold>p</bold><sup><italic>ML</italic></sup> = (<italic>p</italic><sub>1</sub><sup><italic>ML</italic></sup>, <italic>p</italic><sub>2</sub><sup><italic>ML</italic></sup>, …) is a set of the machine learning-predicted parameter values. <inline-formula id="IEq9"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{q}} = (q_{1} ,q_{2} , \ldots )$$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:mi mathvariant="bold">q</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq9.gif"/></alternatives></inline-formula> and <inline-formula id="IEq10"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{q}}^{ML} = (q_{1}^{ML} ,q_{2}^{ML} , \ldots )$$\end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">q</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ML</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ML</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ML</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq10.gif"/></alternatives></inline-formula> are the log<sub>10</sub>-scaled <bold>p</bold> and <bold>p</bold><sup><italic>ML</italic></sup>, respectively. RMSE and BOF are the root mean square error [Eq. (<xref rid="Equ3" ref-type="">3</xref>)] and the badness-of-fit [Eq. (<xref rid="Equ2" ref-type="">2</xref>)], respectively. AE is the allowable error (0.02 in this study). <bold>p</bold><sup><italic>L</italic></sup> and <bold>p</bold><sup><italic>U</italic></sup> are the lower and upper bound vectors, respectively. To cover the vast majority of K<sub>m</sub> values, we use a relatively large search space, e.g., <bold>p</bold><sup><italic>L</italic></sup> = 10<sup>–5</sup> mM and <bold>p</bold><sup><italic>U</italic></sup> = 10<sup>3</sup> mM. In this study, we call the parameter sets that satisfy Eq. (<xref rid="Equ7" ref-type="">5b</xref>) and (<xref rid="Equ8" ref-type="">5c</xref>) as “solution parameter sets” or “solutions.” The constrained global optimization aims to minimize RMSE between K<sub>m</sub>s to be searched and machine learning-predicted K<sub>m</sub> values while keeping a sufficiently good model fit to experimental data. Minimization of RMSE works as “regularization” [<xref ref-type="bibr" rid="CR15">15</xref>], which helps the global optimization algorithm to estimate a unique solution. Whether the MLAGO works well or not depends on how accurate the machine learning predictor can predict K<sub>m</sub> values for <bold>p</bold><sup><italic>ML</italic></sup>.</p>
    </sec>
    <sec id="Sec6">
      <title>Developing the machine learning-based K<sub>m</sub> predictor</title>
      <sec id="Sec7">
        <title>Data preparation</title>
        <p id="Par17">To develop machine learning-based K<sub>m</sub> predictors, we employed the well-curated K<sub>m</sub> dataset provided by Bar-Even et al. [<xref ref-type="bibr" rid="CR29">29</xref>]. The dataset is publicly available as a Supporting Information of [<xref ref-type="bibr" rid="CR29">29</xref>]. Briefly, this dataset was originally obtained from BRENDA [<xref ref-type="bibr" rid="CR30">30</xref>, <xref ref-type="bibr" rid="CR31">31</xref>] and contained 31,162 K<sub>m</sub> values for different combinations of EC numbers, substrates, organisms, and experimental conditions (e.g., temperature and pH). The entries for mutated enzymes and non-natural substrates had already been removed. KEGG Compound IDs and Organism IDs had been assigned to substrates and organisms, respectively [<xref ref-type="bibr" rid="CR32">32</xref>]. We did not use temperature or pH for our machine learning models because they do not contribute to prediction performance (see Discussion). Next, we merged duplicated entries (i.e., entries with identical EC numbers, Compound IDs, and Organism IDs) into a single entry. We took the geometric mean for K<sub>m</sub> values across duplicated entries. Then, we removed 17 entries related to K<sub>m</sub>s for the two kinetic models employed in the benchmark experiments. As a result, we obtained K<sub>m</sub> dataset with 17,151 entries (2,588 unique EC numbers, 1,612 unique Compound IDs, and 2212 unique Organism IDs). We randomly divided the dataset into the training and test datasets with a ratio of 4:1.</p>
      </sec>
      <sec id="Sec8">
        <title>Feature encoding</title>
        <p id="Par18">For feature encoding, we took the most straightforward approach: the one-hot encoding (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). As our dataset contained 1612 different compounds, we used a 1612-dimensional binary vector to encode a compound. In this vector, only an element corresponding to a particular Compound ID is one, and the remaining elements are zeros. In the same way, we employed a 2212-dimensional binary vector for Organism ID.<fig id="Fig2"><label>Fig. 2</label><caption><p>Feature encoding. Glutamine synthetase (EC 6.3.1.2), ATP, and <italic>E. coli</italic> were shown for illustrative purpose</p></caption><graphic xlink:href="12859_2022_5009_Fig2_HTML" id="MO2"/></fig></p>
        <p id="Par19">To retain the hierarchical information, we took a slightly different approach to encode EC numbers. We used four binary vectors to encode an EC number: The vectors for the first digit, the first two digits, the first three digits, and the entire four digits. As our dataset contained six different first digits (i.e., EC 1 to 6), we used a 6-dimensional vector to encode the first digit. As our data contained 59 different first two digits (e.g., EC 1.1, 1.2, 3.1, and 6.3), we used a 59-dimensional vector to encode the first two digits. Similarly, we used 194-dimensional and 2588-dimensional vectors for the first three digits and the entire four digits, respectively. Then, to represent an EC number, we concatenated these four vectors, i.e., the vectors for the first digit, the first two digits, the first three digits, and the entire four digits.</p>
        <p id="Par20">As a result of the hierarchical encoding, the feature vector for EC 1.1.1.1 is more similar to that for EC 1.1.1.2 than that for EC 2.1.1.1: The feature vector for EC 1.1.1.1 is generated by substituting 1 for the elements corresponding to “1”, “1.1”, “1.1.1”, and “1.1.1.1”. Namely, the 1st, 7th (6 + 1), 66th (6 + 59 + 1), and 260th (6 + 59 + 194 + 1) elements are one. The remaining elements are zero. Similarly, the feature vector for EC 1.1.1.2 is generated by substituting 1 for the elements corresponding to “1”, “1.1”, “1.1.1”, and “1.1.1.2”, i.e., the 1<sup>st</sup>, 7th (6 + 1), 66th (6 + 59 + 1), and 261st (6 + 59 + 194 + 2) elements. The feature vector for EC 2.1.1.1 is generated by entering 1 to the elements corresponding to “2”, “2.1”, “2.1.1”, and “2.1.1.1”, i.e., the 2nd, 28th (6 + 22), 162nd (6 + 59 + 97), and 1136th (6 + 59 + 194 + 877) elements. Thus, the vectors for EC 1.1.1.1 and EC 1.1.1.2 have 1 for the three common elements (i.e., the 1st, 7th, and 66th elements). Meanwhile, the vectors for EC 1.1.1.1 and EC 2.1.1.1 do not have 1 for any common elements.</p>
        <p id="Par21">Taken together, an entry from our dataset has a 6671-dimensional binary feature vector in total. The task that machine learning models perform in this study is to predict K<sub>m</sub> values based on the 6671-dimensional binary feature vectors.</p>
      </sec>
    </sec>
    <sec id="Sec9">
      <title>Evaluation of machine learning-based K<sub>m</sub> predictors</title>
      <p id="Par22">We employed five machine learning algorithms: <italic>k</italic>-nearest neighbors algorithm, elastic net, random forest model, gradient boosting model, and TabNet (see Methods). First, we performed hyperparameter tuning for the five models through five-fold cross-validation on the training dataset. Next, we trained the machine learning models with the best hyperparameter settings and all the training data. Finally, we tested the predictive performance on the test dataset.</p>
      <p id="Par23">The best hyperparameter settings are summarized in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1, and model performance is shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. The random forest model achieved the best performance in the cross-validation and the independent test (Fig. <xref rid="Fig3" ref-type="fig">3</xref>A, <xref rid="Fig3" ref-type="fig">B</xref>). In the independent test with the test dataset, the random forest model achieved RMSE = 0.795 and R<sup>2</sup> = 0.536. Since the random forest model achieved the best performance, we used it for further analyses.<fig id="Fig3"><label>Fig. 3</label><caption><p>Performance of the machine learning-based K<sub>m</sub> predictors. <bold>A</bold> RMSE. <bold>B</bold> R<sup>2</sup>. The values in (<bold>A</bold>) and (<bold>B</bold>) were calculated with the best hyperparameter setting for each model. The boxes, whiskers, and open circles are for four independent rounds of five-fold cross-validation with the training dataset. The red circles are for the test dataset, which was not used for hyperparameter tuning. <bold>C</bold> Scatter plot of K<sub>m</sub> values of the test dataset predicted with the random forest model versus the experimental values. <bold>D</bold> Histogram of the ratio of the predicted K<sub>m</sub> values to the experimental values. <bold>E</bold> Top 10-ranked important features in the random forest model. <bold>F</bold> Feature importance for each feature class. Feature importance in (<bold>E</bold>) and (<bold>F</bold>) was calculated by the permutation-based method</p></caption><graphic xlink:href="12859_2022_5009_Fig3_HTML" id="MO3"/></fig></p>
      <p id="Par24">Figure <xref rid="Fig3" ref-type="fig">3</xref>C is the scatter plot of K<sub>m</sub> values of the test datasets predicted with the random forest model versus measured K<sub>m</sub> values. The predicted and measured values were different by four-fold on average on either side of the measured values. The deviations in 82% of K<sub>m</sub>s were less than ten-fold on either side of the measured values (Fig. <xref rid="Fig3" ref-type="fig">3</xref>D). Next, we investigated important features for prediction. As shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>E, all the top 10-ranked features were the features related to EC numbers or Compound IDs. Indeed, the sum of the feature importance values for the Organism ID-derived features is much smaller than those for EC number and Compound ID-derived features (Fig. <xref rid="Fig3" ref-type="fig">3</xref>F), indicating that the K<sub>m</sub> predictor mainly uses EC number and Compound ID.</p>
      <p id="Par25">In summary, we developed machine learning models for K<sub>m</sub> prediction, which relies merely on EC number, Compound ID, and Organism ID. The random forest model achieved the best prediction scores.</p>
    </sec>
    <sec id="Sec10">
      <title>Machine learning-predicted K<sub>m</sub> values do not provide a good model fit</title>
      <p id="Par26">Next, we investigated whether the machine learning-predicted K<sub>m</sub> values as they are can be used for kinetic modeling. We considered the two real-world kinetic models: The carbon metabolism model [<xref ref-type="bibr" rid="CR33">33</xref>] and the nitrogen metabolism model [<xref ref-type="bibr" rid="CR26">26</xref>] (see Methods). Using the machine learning K<sub>m</sub> predictor, we estimated 32 and 18 K<sub>m</sub>s in the carbon and nitrogen metabolism models, respectively. Please note that these K<sub>m</sub>s were not included in the training or test datasets. However, the machine learning model predicted those K<sub>m</sub> values with good accuracy (Fig. <xref rid="Fig4" ref-type="fig">4</xref>A, <xref rid="Fig4" ref-type="fig">B</xref>): RMSE = 0.616 and 0.727 for the carbon and nitrogen metabolism models, respectively. Encouraged by this result, we tested whether the kinetic models with the predicted K<sub>m</sub> values reproduce the experimentally observed behaviors. As shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>C, <xref rid="Fig4" ref-type="fig">D</xref>, the kinetic models did not fit the experimental data (BOF &gt; 1.143). Therefore, we concluded that machine learning-predicted K<sub>m</sub> values could not be used for kinetic models as they were.<fig id="Fig4"><label>Fig. 4</label><caption><p>Machine learning prediction of K<sub>m</sub> for the benchmark models. <bold>A</bold> and <bold>B</bold> Scatter plots of predicted K<sub>m</sub> values versus the experimental values for the carbon and nitrogen metabolism models. <bold>C</bold> and <bold>D</bold> Simulation results of the carbon and nitrogen metabolism models with the machine learning-predicted K<sub>m</sub> values. The circles and lines represent experimental data and simulation, respectively. Only important molecular components are shown for clarity</p></caption><graphic xlink:href="12859_2022_5009_Fig4_HTML" id="MO4"/></fig></p>
    </sec>
    <sec id="Sec11">
      <title>MLAGO outperforms the conventional global optimization approach</title>
      <p id="Par27">Next, we investigated whether the machine learning-predicted K<sub>m</sub> values can be used as the reference values for MLAGO. We compared the MLAGO approach and the conventional global optimization approach. Again, we employed the carbon and nitrogen metabolism models as benchmark problems. We used the machine learning predictor (the random forest model) to predict K<sub>m</sub> values and used them as the reference values for the MLAGO approach [<bold>p</bold><sup><italic>ML</italic></sup> in Eq. (5)]. We employed REX<sup>star</sup>/JGG as a global optimization algorithm both for the MLAGO and conventional approaches. Each approach was carried out ten times for each kinetic model.</p>
      <p id="Par28">The convergence curves are shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>A, <xref rid="Fig5" ref-type="fig">B</xref>. The MLAGO method found solutions (BOF ≤ AE) with less computational costs than the conventional method. Please note that a set of K<sub>m</sub> values with BOF = AE already provides a sufficiently good fit to experimental data. Once BOF ≤ AE is achieved, the MLAGO approach focuses on reducing RMSE, and thus BOF stays slightly below or equal to AE. The MLAGO approach found solutions for all ten trials for both the carbon and nitrogen metabolism models. In contrast, the conventional method failed to find solutions in one trial for the carbon metabolism model and three trials for the nitrogen metabolism model. We confirmed that the K<sub>m</sub> values estimated by the MLAGO (Fig. <xref rid="Fig5" ref-type="fig">5</xref>C, <xref rid="Fig5" ref-type="fig">D</xref>) and conventional methods (not shown) could provide a good model fit to experimental data.<fig id="Fig5"><label>Fig. 5</label><caption><p>Performance of the MLAGO method. <bold>A</bold> and <bold>B</bold> Convergence curves for the MLAGO method (red) and conventional method (blue). The thin lines with light colors represent independent trials, and the thick lines with strong colors represent the geometric mean of these trials. The dashed black lines represent the allowable error (AE). The number of evaluations indicates the number of simulations performed during the global optimization. <bold>C</bold> and <bold>D</bold> Simulation results of the carbon and nitrogen metabolism models with the K<sub>m</sub> values estimated by the MLAGO method. The circles and lines represent experimental data and simulation, respectively. Only important molecular components are shown for clarity. <bold>E</bold> and <bold>F</bold> Scatter plots of K<sub>m</sub> values estimated by the MLAGO method. <bold>G</bold> and <bold>H</bold> Scatter plots of K<sub>m</sub> values estimated by the conventional method. In (<bold>E</bold>)–(<bold>H</bold>), the circles represent mean values, and error bars represent ± standard deviation (<italic>n</italic> = 10). In (<bold>E</bold>) and (<bold>F</bold>), the error bars are not clearly visible because the standard deviation is small</p></caption><graphic xlink:href="12859_2022_5009_Fig5_HTML" id="MO5"/></fig></p>
      <p id="Par29">Next, we checked whether the estimated K<sub>m</sub> values were close to measured values. The MLAGO method obtained K<sub>m</sub> values close to their measured values (Fig. <xref rid="Fig5" ref-type="fig">5</xref>E, <xref rid="Fig5" ref-type="fig">F</xref>). Indeed, the RMSE values between the estimated and measured values were small, and the obtained parameter sets were almost identical for all the ten trials: RMSE = 0.787 ± 0.002 and RMSE = 0.571 ± 0.001 for the carbon and nitrogen metabolism models, respectively (<italic>n</italic> = 10; ± SD). In contrast, the K<sub>m</sub> values estimated by the conventional method were very different from their measured values, and the estimated values varied depending on the trials (Fig. <xref rid="Fig5" ref-type="fig">5</xref>G, <xref rid="Fig5" ref-type="fig">H</xref>): RMSE = 1.879 ± 0.196 for the carbon metabolism model and RMSE = 1.698 ± 0.283 for the nitrogen metabolism model. Most K<sub>m</sub> values estimated by the MLAGO were within a reasonable range: For the carbon metabolism model, the deviations in 78% of the K<sub>m</sub>s were less than ten-fold on either side of the measured values. For the nitrogen metabolism model, it was 89%.</p>
      <p id="Par30">In summary, the MLAGO approach estimated K<sub>m</sub> values with less computational cost than the conventional approach. Moreover, the MLAGO approach almost uniquely identified K<sub>m</sub> values, most of which were close to the measured values.</p>
    </sec>
  </sec>
  <sec id="Sec12">
    <title>Discussion</title>
    <p id="Par31">We proposed a hybrid parameter estimation technique based on machine learning and global optimization, named MLAGO. In kinetic modeling, the global optimization approach has been used for parameter estimation. However, the conventional approach had three major problems: (i) It is computationally costly. (ii) It often yields unrealistic parameter values. (iii) It has difficulty identifying a unique solution. To solve these problems, we proposed the MLAGO approach integrating global optimization and machine learning. The main idea is to use the machine learning-predicted K<sub>m</sub> values as the reference values for constrained global optimization. The MLAGO approach updates K<sub>m</sub> values to improve model fit to experimental data while keeping them close to the values predicted by machine learning. To implement the MLAGO approach, we developed a machine learning model for K<sub>m</sub> prediction using three factors: EC number, Compound ID, and Organism ID. Through real-world benchmark problems, we confirmed that the MLAGO approach was superior to the conventional approach: The MLAGO approach found a solution with less computational cost than the conventional approach, and the solution was close to measured K<sub>m</sub> values. Moreover, the MLAGO approach estimated almost the identical solution for all the independent trials. To our knowledge, this work is the first study to integrate global optimization and machine learning for kinetic parameter estimation. Machine learning-predicted, realistic K<sub>m</sub> values can be helpful for kinetic modeling because unrealistic K<sub>m</sub> values may lead to wrong predictions.</p>
    <p id="Par32">As a further experiment, we investigated whether we could improve the machine learning K<sub>m</sub> predictors by adding different features. Specifically, we added temperature, pH, amino acid sequence motifs (Pfam domain [<xref ref-type="bibr" rid="CR34">34</xref>]), and pathway information (KEGG Pathway ID [<xref ref-type="bibr" rid="CR32">32</xref>]). Temperature and pathway information slightly improved the prediction score; however, the improvement was not statistically significant (<italic>p</italic> &gt; 0.05). Therefore, the prediction scores achieved by our best model (RMSE = 0.795 and R<sup>2</sup> = 0.536) may be close to the best possible prediction scores, considering the number and quality of datasets available in public databases. This speculation is supported by the fact that Kroll et al. took a very different approach and achieved performance scores comparable to ours: MSE = 0.65 (i.e., RMSE = 0.81) and R<sup>2</sup> = 0.53 [<xref ref-type="bibr" rid="CR19">19</xref>].</p>
    <p id="Par33">As another experiment, we investigated whether the carbon and nitrogen metabolism models with measured K<sub>m</sub> values reproduce their experimentally observed behaviors. As shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig S1, they failed to do so (BOF &gt; 0.509). One reason for the misfit is that K<sub>m</sub> values are usually measured under enzyme-specific in vitro conditions. Thus, K<sub>m</sub> values need to be tuned by global optimization for better model fit. Indeed, the measured K<sub>m</sub> values in our datasets are different from the “original” K<sub>m</sub> values given in the carbon and nitrogen metabolism models. The RMSE between the original and measured values was 0.857 for the carbon metabolism model and 0.111 for the nitrogen metabolism model. For the carbon metabolism model, the RMSE between the machine learning-predicted K<sub>m</sub> values and the measured values was 0.616. Therefore, K<sub>m</sub> values for the carbon metabolism model were greatly improved by the machine learning K<sub>m</sub> predictor.</p>
    <p id="Par34">Not only K<sub>m</sub>s but also k<sub>cat</sub>s and V<sub>max</sub>es are often estimated in parameter estimation. We conducted additional computational experiments to investigate whether MLAGO can uniquely estimate K<sub>m</sub> values even along with k<sub>cat</sub>s and V<sub>max</sub>es. k<sub>cat</sub> and V<sub>max</sub> values were searched in global optimization but not considered in the RMSE calculation [Eq. (<xref rid="Equ6" ref-type="">5a</xref>)] because measured values are rarely available for them. As shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig S2, MLAGO estimated K<sub>m</sub> values almost uniquely even if k<sub>cat</sub>s and V<sub>max</sub>es are searched: RMSE = 0.650 ± 0.018 and RMSE = 0.596 ± 0.001 for the carbon and nitrogen metabolism models, respectively (<italic>n</italic> = 10; ± SD).</p>
    <p id="Par35">It is difficult to compare the prediction quality of our K<sub>m</sub> predictor with Kroll’s [<xref ref-type="bibr" rid="CR19">19</xref>] as their and our datasets are not exactly the same due to differences in employed features. Nevertheless, it is notable that our K<sub>m</sub> predictor achieved a good prediction score, RMSE = 0.795, compared to RMSE = 0.81 by Kroll et al. In their article, Kroll et al. provided genome-scale K<sub>m</sub> predictions for 47 model organisms. Thus, we investigated whether their predicted K<sub>m</sub> values could be used for the carbon and nitrogen metabolism models. Specifically, we used the predicted K<sub>m</sub> values provided for an <italic>E. coli</italic> genome-scale metabolic model (iAF1260). We found that the RMSE between their prediction and the measured values are relatively large: RMSE = 0.961 for the carbon metabolism model and RMSE = 1.328 for the nitrogen metabolism model. As mentioned above, our K<sub>m</sub> predictor achieved better scores: RMSE = 0.616 for the carbon metabolism model and RMSE = 0.727 for the nitrogen metabolism model.</p>
    <p id="Par36">Kroll et al. [<xref ref-type="bibr" rid="CR19">19</xref>] and we took a different approach to K<sub>m</sub> prediction. Kroll et al. combined deep and machine learning models. They employed deep learning for feature encoding: a task-specific molecular fingerprint of the substrate and deep numerical representation of the enzyme’s amino acid sequence [<xref ref-type="bibr" rid="CR19">19</xref>]. In their approach, substrate’s structure and enzyme’s amino acid sequence were converted into a 52-dimensional fingerprint vector and a 1,900-dimensional UniRep [<xref ref-type="bibr" rid="CR35">35</xref>] vector, respectively. Then, the resultant 1,952-dimensional feature vector was used by the gradient boosting model (XGBoost). In contrast, we employed simple feature encoding and machine learning methods, i.e., the one-hot encoding and random forest. In our approach, EC number, Compound ID, and Organism ID were converted into 2847-dimensional, 1612-dimensional, and 2212-dimensional binary vectors, respectively. The resultant 6671-dimensional feature vector was used for the random forest. It may be surprising that our simple machine learning model achieved a good performance. We encoded EC number so that the feature vector retains the information on enzyme classification. We think this encoding method contributed to the prediction performance. Indeed, the feature importance for EC number is larger than that for Compound ID and Organism ID in our machine-learning K<sub>m</sub> predictor (Fig. <xref rid="Fig3" ref-type="fig">3</xref>F), which is in contrast to Kroll’s K<sub>m</sub> predictor in which the substrate information is more important than enzyme information.</p>
    <p id="Par37">The advantage of our K<sub>m</sub> predictor over Kroll’s [<xref ref-type="bibr" rid="CR19">19</xref>] is that ours does not require compound’s structural information or enzyme’s amino acid sequence. Our predictor requires only EC number, Compound ID, and Organism ID, which are easily available for kinetic modelers. Nonetheless, our predictor has a limitation: although the dataset used in this study covers a vast number of enzymes, substrates, and organisms (2588 EC numbers, 1612 Compound IDs, and 2212 Organism IDs), our K<sub>m</sub> predictor would probably show poor performance on uncommon enzymes, substrates, and organisms that were not included in the training data. Moreover, EC numbers have not been assigned to newly found enzymes. Similarly, Compound IDs and Organism IDs may not be assigned to rare substrates and organisms. Our K<sub>m</sub> predictor cannot handle these enzymes, compounds, and organisms without EC number, Compound ID, and Organism ID. Therefore, our approach is not applicable to rare enzymes and compounds. In contrast, Kroll’s approach is organism-independent and applicable as long as compound’s structure and enzyme’s amino acid sequence are available.</p>
    <p id="Par38">We successfully predicted K<sub>m</sub> values without chemical, physicochemical, or structural information. This fact implies that enzymes with similar EC numbers (i.e., enzymes that catalyze similar reactions) tend to have similar K<sub>m</sub> values. Also, which substrate is involved is an essential factor to determine K<sub>m</sub> values. Indeed, K<sub>m</sub> values and physiological substrate concentrations may have co-evolved to match each other [<xref ref-type="bibr" rid="CR29">29</xref>, <xref ref-type="bibr" rid="CR36">36</xref>].</p>
    <p id="Par39">Generally speaking, the gradient boosting model and TabNet tend to outperform the random forest model. In this study, we tested 864 and 172 hyperparameter combinations for the gradient boosting model and TabNet, respectively. However, despite the intensive hyperparameter tuning, we could not find any hyperparameter settings for these models to outcompete the random forest model. This may be due to the limited size of the training dataset (13,721 entries) compared to the dimension of the feature vector (6,671). In general, more complex models need more data.</p>
    <p id="Par40">There are two limitations in the MLAGO approach. First, our machine learning model is relatively poor at predicting extremely small or large K<sub>m</sub> values. The K<sub>m</sub> predictor tends to predict a slightly higher value for the K<sub>m</sub>s whose measured values are less than 0.01 mM, and a slightly lower value for the K<sub>m</sub>s whose measured values are more than 1 mM (Fig. <xref rid="Fig3" ref-type="fig">3</xref>C and Fig. <xref rid="Fig4" ref-type="fig">4</xref>A, <xref rid="Fig4" ref-type="fig">B</xref>). Second, the goal of parameter estimation is to simultaneously achieve accurate K<sub>m</sub> estimation and model fitting, but it is not always achievable. Indeed, the accuracy of K<sub>m</sub> estimation and quality of model fitting are trade-off in some cases, including the carbon metabolism model (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig S3A). The trade-off is caused by different reasons, such as inaccurate experimental data or flaws in kinetic models. In the trade-off cases, AE needs to be tuned to balance the accuracy of K<sub>m</sub> estimation and model fitting. Modelers can also use the trade-off as an indicator of inconsistency between a kinetic model and experimental data.</p>
  </sec>
  <sec id="Sec13">
    <title>Conclusions</title>
    <p id="Par41">The previous studies [<xref ref-type="bibr" rid="CR16">16</xref>–<xref ref-type="bibr" rid="CR18">18</xref>] demonstrated that deep learning-based k<sub>cat</sub> prediction improved genome-scale constraint-based metabolic models. However, whether machine learning-based K<sub>m</sub> prediction is helpful to kinetic modeling had not been tested. In this study, we showed that machine learning-predicted K<sub>m</sub> values can serve as the reference values for the constrained optimization-based parameter estimation. We conclude that the MLAGO approach improves parameter estimation in kinetic modeling, leading to better understanding of complex cellular systems. The web application for the machine learning-based K<sub>m</sub> predictor is accessible at <ext-link ext-link-type="uri" xlink:href="https://sites.google.com/view/kazuhiro-maeda/software-tools-web-apps">https://sites.google.com/view/kazuhiro-maeda/software-tools-web-apps</ext-link>, which helps modelers perform MLAGO on their own parameter estimation tasks. The K<sub>m</sub> predictor is applicable not only to kinetic modeling but also to diverse applications, including Enzymology and Bioindustry.</p>
  </sec>
  <sec id="Sec14">
    <title>Methods</title>
    <sec id="Sec15">
      <title>Machine learning algorithms</title>
      <p id="Par42">We employed five machine learning algorithms: <italic>k</italic>-nearest neighbors algorithm, elastic net, random forest model, gradient boosting model, and TabNet. The <italic>k</italic>-nearest neighbors algorithm is the simplest: the output is the average of the values of <italic>k</italic> nearest neighbors. The elastic net is a regularized regression method that linearly combines the L<sub>1</sub> and L<sub>2</sub> penalties. The random forest and gradient boosting are ensemble learning methods that operate by constructing a number of decision trees at training. TabNet is an interpretable canonical deep learning architecture for tabular data [<xref ref-type="bibr" rid="CR37">37</xref>]. We used scikit-learn [<xref ref-type="bibr" rid="CR38">38</xref>] for the <italic>k</italic>-nearest neighbors algorithm, elastic net, and random forest model. We employed XGBoost [<xref ref-type="bibr" rid="CR39">39</xref>] for the gradient boosting model. For TabNet, we used an implementation provided in GitHub [<xref ref-type="bibr" rid="CR40">40</xref>].</p>
    </sec>
    <sec id="Sec16">
      <title>Performance criteria</title>
      <p id="Par43">To evaluate the performance of machine learning models, we use the two measures: RMSE [Eq. (<xref rid="Equ3" ref-type="">3</xref>)] and the coefficient of determination (R<sup>2</sup>):<disp-formula id="Equ9"><label>6</label><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R^{2} ({\mathbf{q}},{\mathbf{q}}*) = 1 - \frac{{\sum\nolimits_{i = 1}^{{n_{param} }} {\left( {q_{i} - q_{i} *} \right)^{2} } }}{{\sum\nolimits_{i = 1}^{{n_{param} }} {\left( {q_{i} - \overline{q*} } \right)^{2} } }},$$\end{document}</tex-math><mml:math id="M38" display="block"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">q</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">q</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">param</mml:mi></mml:mrow></mml:msub></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">param</mml:mi></mml:mrow></mml:msub></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mover><mml:mrow><mml:mi>q</mml:mi><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2022_5009_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq11"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\overline{q*} = n_{param}^{ - 1} \cdot \sum\nolimits_{i = 1}^{{n_{param} }} {q_{i} *}$$\end{document}</tex-math><mml:math id="M40"><mml:mrow><mml:mover><mml:mrow><mml:mi>q</mml:mi><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msubsup><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">param</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>·</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi mathvariant="italic">param</mml:mi></mml:mrow></mml:msub></mml:msubsup><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow/><mml:mo>∗</mml:mo></mml:mrow></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq11.gif"/></alternatives></inline-formula>. <inline-formula id="IEq12"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{q}} = (q_{1} ,q_{2} , \ldots )$$\end{document}</tex-math><mml:math id="M42"><mml:mrow><mml:mi mathvariant="bold">q</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq12.gif"/></alternatives></inline-formula> and <inline-formula id="IEq13"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathbf{q}}* = (q_{1} *,q_{2} *, \ldots )$$\end{document}</tex-math><mml:math id="M44"><mml:mrow><mml:mi mathvariant="bold">q</mml:mi><mml:mrow/><mml:mo>∗</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow/><mml:mo>∗</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq13.gif"/></alternatives></inline-formula> are the log<sub>10</sub>-scaled estimated and experimentally measured K<sub>m</sub> vectors, respectively.</p>
    </sec>
    <sec id="Sec17">
      <title>Benchmark problems</title>
      <p id="Par44">We employed two kinetic models for benchmarking the MLAGO approach presented in this study. The carbon metabolism model [<xref ref-type="bibr" rid="CR33">33</xref>] contains the glycolysis and pentose-phosphate pathway and consists of 18 variables and 137 model parameters. The nitrogen metabolism model [<xref ref-type="bibr" rid="CR26">26</xref>] contains the ammonium transport and glutamate and glutamine production pathways and consists of 13 variables and 111 kinetic parameters. The main features of the carbon metabolism model [<xref ref-type="bibr" rid="CR33">33</xref>] and the nitrogen metabolism model [<xref ref-type="bibr" rid="CR26">26</xref>] are summarized in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2. We chose these models because (i) they are realistic models that can quantitatively reproduce changes in metabolite concentrations, (ii) their simulation models were available from the BioModels database [<xref ref-type="bibr" rid="CR41">41</xref>], and (iii) their simulations are computationally feasible.</p>
      <p id="Par45">In the benchmark experiments, we estimated 32 K<sub>m</sub>s in the carbon metabolism model and 18 K<sub>m</sub>s in the nitrogen metabolism model (see Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2). We chose these K<sub>m</sub>s as targets because they have been measured, and thus we can check estimation accuracy. For simplicity, we generated quasi-experimental data [<inline-formula id="IEq14"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{i,j,k}^{exp}$$\end{document}</tex-math><mml:math id="M46"><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">exp</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2022_5009_Article_IEq14.gif"/></alternatives></inline-formula> in Eq. (<xref rid="Equ2" ref-type="">2</xref>)] by performing simulations with the original K<sub>m</sub> values given in the models.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec18">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2022_5009_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1</bold>. Tables S1–S2 and Figs S1–S3.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>KM conceived of the project. KM, AH, and YS performed the computational experiments. KM, FCB, and HK analyzed the data and wrote the manuscript. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported by Grant-in-Aid for Scientific Research (C) (22K12247), Grant-in-Aid for Transformative Research Areas (B) (20H05743), and Grant-in-Aid for Scientific Research (B) (22H03688) from the Japan Society for the Promotion of Science. This work was further supported by JST PRESTO (JPMJPR20K8).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The datasets generated and/or analyzed during the current study are available in GitHub, <ext-link ext-link-type="uri" xlink:href="https://github.com/kmaeda16/MLAGO-data">https://github.com/kmaeda16/MLAGO-data</ext-link></p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par46">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par47">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par48">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kitano</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Systems biology: a brief overview</article-title>
        <source>Science</source>
        <year>2002</year>
        <volume>295</volume>
        <issue>5560</issue>
        <fpage>1662</fpage>
        <lpage>1664</lpage>
        <pub-id pub-id-type="doi">10.1126/science.1069492</pub-id>
        <?supplied-pmid 11872829?>
        <pub-id pub-id-type="pmid">11872829</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <mixed-citation publication-type="other">Segel IH. Enzyme kinetics: behavior and analysis of rapid equilibrium and steady-state enzyme systems. Wiley; 1975.</mixed-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Garcia-Contreras</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Vos</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Westerhoff</surname>
            <given-names>HV</given-names>
          </name>
          <name>
            <surname>Boogerd</surname>
            <given-names>FC</given-names>
          </name>
        </person-group>
        <article-title>Why in vivo may not equal in vitro: new effectors revealed by measurement of enzymatic activities under the same in vivo-like assay conditions</article-title>
        <source>FEBS J</source>
        <year>2012</year>
        <volume>279</volume>
        <issue>22</issue>
        <fpage>4145</fpage>
        <lpage>4159</lpage>
        <pub-id pub-id-type="doi">10.1111/febs.12007</pub-id>
        <?supplied-pmid 22978366?>
        <pub-id pub-id-type="pmid">22978366</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>van Riel</surname>
            <given-names>NA</given-names>
          </name>
        </person-group>
        <article-title>Dynamic modelling and analysis of biochemical networks: mechanism-based models and model-based experiments</article-title>
        <source>Brief Bioinform</source>
        <year>2006</year>
        <volume>7</volume>
        <issue>4</issue>
        <fpage>364</fpage>
        <lpage>374</lpage>
        <pub-id pub-id-type="doi">10.1093/bib/bbl040</pub-id>
        <?supplied-pmid 17107967?>
        <pub-id pub-id-type="pmid">17107967</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Palsson</surname>
            <given-names>BO</given-names>
          </name>
          <name>
            <surname>Yurkovich</surname>
            <given-names>JT</given-names>
          </name>
        </person-group>
        <article-title>Is the kinetome conserved?</article-title>
        <source>Mol Syst Biol</source>
        <year>2022</year>
        <volume>18</volume>
        <issue>2</issue>
        <fpage>e10782</fpage>
        <pub-id pub-id-type="doi">10.15252/msb.202110782</pub-id>
        <?supplied-pmid 35188334?>
        <pub-id pub-id-type="pmid">35188334</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Maeda</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Boogerd</surname>
            <given-names>FC</given-names>
          </name>
          <name>
            <surname>Kurata</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>libRCGA: a C library for real-coded genetic algorithms for rapid parameter estimation of kinetic models</article-title>
        <source>IPSJ Trans. Bioinform.</source>
        <year>2018</year>
        <volume>11</volume>
        <fpage>31</fpage>
        <lpage>40</lpage>
        <pub-id pub-id-type="doi">10.2197/ipsjtbio.11.31</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Maeda</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Boogerd</surname>
            <given-names>FC</given-names>
          </name>
          <name>
            <surname>Kurata</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>RCGAToolbox: a real-coded genetic algorithm software for parameter estimation of kinetic models</article-title>
        <source>IPSJ Trans. Bioinform.</source>
        <year>2021</year>
        <volume>14</volume>
        <fpage>30</fpage>
        <lpage>35</lpage>
        <pub-id pub-id-type="doi">10.2197/ipsjtbio.14.30</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Egea</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Henriques</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Cokelaer</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Villaverde</surname>
            <given-names>AF</given-names>
          </name>
          <name>
            <surname>MacNamara</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Danciu</surname>
            <given-names>DP</given-names>
          </name>
          <name>
            <surname>Banga</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Saez-Rodriguez</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>MEIGO: an open-source software suite based on metaheuristics for global optimization in systems biology and bioinformatics</article-title>
        <source>BMC Bioinform</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>136</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-15-136</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Balsa-Canto</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Henriques</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Gabor</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Banga</surname>
            <given-names>JR</given-names>
          </name>
        </person-group>
        <article-title>AMIGO2, a toolbox for dynamic modeling, optimization and control in systems biology</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <issue>21</issue>
        <fpage>3357</fpage>
        <lpage>3359</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw411</pub-id>
        <?supplied-pmid 27378288?>
        <pub-id pub-id-type="pmid">27378288</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Raue</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Steiert</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Schelker</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kreutz</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Maiwald</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Hass</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Vanlier</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Tonsing</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Adlung</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Engesser</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Data2Dynamics: a modeling environment tailored to parameter estimation in dynamical systems</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>31</volume>
        <issue>21</issue>
        <fpage>3558</fpage>
        <lpage>3560</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btv405</pub-id>
        <?supplied-pmid 26142188?>
        <pub-id pub-id-type="pmid">26142188</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stapor</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Weindl</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Ballnus</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Hug</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Loos</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Fiedler</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Krause</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hross</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Frohlich</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Hasenauer</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>PESTO: parameter EStimation TOolbox</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>4</issue>
        <fpage>705</fpage>
        <lpage>707</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx676</pub-id>
        <?supplied-pmid 29069312?>
        <pub-id pub-id-type="pmid">29069312</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Inoue</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Maeda</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Miyabe</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Matsuoka</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Kurata</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>CADLIVE toolbox for MATLAB: automatic dynamic modeling of biochemical networks with comprehensive system analysis</article-title>
        <source>Bioprocess Biosyst Eng</source>
        <year>2014</year>
        <volume>37</volume>
        <issue>9</issue>
        <fpage>1925</fpage>
        <lpage>1927</lpage>
        <pub-id pub-id-type="doi">10.1007/s00449-014-1167-8</pub-id>
        <?supplied-pmid 24623466?>
        <pub-id pub-id-type="pmid">24623466</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Banga</surname>
            <given-names>JR</given-names>
          </name>
        </person-group>
        <article-title>Optimization in computational systems biology</article-title>
        <source>BMC Syst Biol</source>
        <year>2008</year>
        <volume>2</volume>
        <issue>1</issue>
        <fpage>47</fpage>
        <pub-id pub-id-type="doi">10.1186/1752-0509-2-47</pub-id>
        <?supplied-pmid 18507829?>
        <pub-id pub-id-type="pmid">18507829</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jaqaman</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Danuser</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Linking data to models: data regression</article-title>
        <source>Nat Rev Mol Cell Biol</source>
        <year>2006</year>
        <volume>7</volume>
        <issue>11</issue>
        <fpage>813</fpage>
        <lpage>819</lpage>
        <pub-id pub-id-type="doi">10.1038/nrm2030</pub-id>
        <?supplied-pmid 17006434?>
        <pub-id pub-id-type="pmid">17006434</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Klipp</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Liebermeister</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Wierling</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Kowald</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lehrach</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Herwig</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <source>Systems biology: a textbook</source>
        <year>2009</year>
        <publisher-loc>Germany</publisher-loc>
        <publisher-name>Wiley-VCH</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Heckmann</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Lloyd</surname>
            <given-names>CJ</given-names>
          </name>
          <name>
            <surname>Mih</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Ha</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zielinski</surname>
            <given-names>DC</given-names>
          </name>
          <name>
            <surname>Haiman</surname>
            <given-names>ZB</given-names>
          </name>
          <name>
            <surname>Desouki</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Lercher</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Palsson</surname>
            <given-names>BO</given-names>
          </name>
        </person-group>
        <article-title>Machine learning applied to enzyme turnover numbers reveals protein structural correlates and improves metabolic models</article-title>
        <source>Nat Commun</source>
        <year>2018</year>
        <volume>9</volume>
        <issue>1</issue>
        <fpage>5252</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-018-07652-6</pub-id>
        <?supplied-pmid 30531987?>
        <pub-id pub-id-type="pmid">30531987</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Heckmann</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Campeau</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lloyd</surname>
            <given-names>CJ</given-names>
          </name>
          <name>
            <surname>Phaneuf</surname>
            <given-names>PV</given-names>
          </name>
          <name>
            <surname>Hefner</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Carrillo-Terrazas</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Feist</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Gonzalez</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Palsson</surname>
            <given-names>BO</given-names>
          </name>
        </person-group>
        <article-title>Kinetic profiling of metabolic specialists demonstrates stability and consistency of in vivo enzyme turnover numbers</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2020</year>
        <volume>117</volume>
        <issue>37</issue>
        <fpage>23182</fpage>
        <lpage>23190</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.2001562117</pub-id>
        <?supplied-pmid 32873645?>
        <pub-id pub-id-type="pmid">32873645</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Li F, Yuan L, Lu H, Li G, Chen Y, Engqvist MKM, Kerkhoven EJ, Nielsen J. Deep learning-based kcat prediction enables improved enzyme-constrained model reconstruction. <italic>Nature Catalysis</italic> 2022.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kroll</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Engqvist</surname>
            <given-names>MKM</given-names>
          </name>
          <name>
            <surname>Heckmann</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Lercher</surname>
            <given-names>MJ</given-names>
          </name>
        </person-group>
        <article-title>Deep learning allows genome-scale prediction of Michaelis constants from structural features</article-title>
        <source>PLoS Biol</source>
        <year>2021</year>
        <volume>19</volume>
        <issue>10</issue>
        <fpage>e3001402</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.3001402</pub-id>
        <?supplied-pmid 34665809?>
        <pub-id pub-id-type="pmid">34665809</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Takahama T, Sakai S: Constrained optimization by the ε constrained differential evolution with an archive and gradient-based mutation. In: <italic>IEEE Congress on Evolutionary Computation: 2010; Barcelona, Spain</italic>. 1680–1688.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ismail</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Mohamad</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Abdul Majid</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Abas</surname>
            <given-names>KH</given-names>
          </name>
          <name>
            <surname>Deris</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zaki</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Mohd Hashim</surname>
            <given-names>SZ</given-names>
          </name>
          <name>
            <surname>Ibrahim</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Remli</surname>
            <given-names>MA</given-names>
          </name>
        </person-group>
        <article-title>An improved hybrid of particle swarm optimization and the gravitational search algorithm to produce a kinetic parameter estimation of aspartate biochemical pathways</article-title>
        <source>Biosystems</source>
        <year>2017</year>
        <volume>162</volume>
        <fpage>81</fpage>
        <lpage>89</lpage>
        <pub-id pub-id-type="doi">10.1016/j.biosystems.2017.09.013</pub-id>
        <?supplied-pmid 28951204?>
        <pub-id pub-id-type="pmid">28951204</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sagar</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>LeCover</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Shoemaker</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Varner</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Dynamic Optimization with Particle Swarms (DOPS): a meta-heuristic for parameter estimation in biochemical models</article-title>
        <source>BMC Syst Biol</source>
        <year>2018</year>
        <volume>12</volume>
        <issue>1</issue>
        <fpage>87</fpage>
        <pub-id pub-id-type="doi">10.1186/s12918-018-0610-x</pub-id>
        <?supplied-pmid 30314484?>
        <pub-id pub-id-type="pmid">30314484</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Egea</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Balsa-Canto</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Gracia</surname>
            <given-names>M-SG</given-names>
          </name>
          <name>
            <surname>Banga</surname>
            <given-names>JR</given-names>
          </name>
        </person-group>
        <article-title>Dynamic optimization of nonlinear processes with an enhanced scatter search method</article-title>
        <source>Ind Eng Chem Res</source>
        <year>2009</year>
        <volume>48</volume>
        <issue>9</issue>
        <fpage>4388</fpage>
        <lpage>4401</lpage>
        <pub-id pub-id-type="doi">10.1021/ie801717t</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Pardo XC, Argüeso-Alejandro P, González P, Banga JR, Doallo R. Spark implementation of the enhanced Scatter Search metaheuristic: methodology and assessment. Swarm Evol Comput. 2020;100748.</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kobayashi</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>The frontiers of real-coded genetic algorithms</article-title>
        <source>J Jpn Soc Artif Intell</source>
        <year>2009</year>
        <volume>24</volume>
        <issue>1</issue>
        <fpage>147</fpage>
        <lpage>162</lpage>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Maeda K, Westerhoff HV, Kurata H, Boogerd FC: Ranking network mechanisms by how they fit diverse experiments and deciding on <italic>E. coli's</italic> ammonium transport and assimilation network. NPJ Syst Biol Appl. 2019;5(1):14.</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tohsato</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ikuta</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Shionoya</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mazaki</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ito</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Parameter optimization and sensitivity analysis for large kinetic models using a real-coded genetic algorithm</article-title>
        <source>Gene</source>
        <year>2013</year>
        <volume>518</volume>
        <issue>1</issue>
        <fpage>84</fpage>
        <lpage>90</lpage>
        <pub-id pub-id-type="doi">10.1016/j.gene.2012.11.080</pub-id>
        <?supplied-pmid 23274652?>
        <pub-id pub-id-type="pmid">23274652</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kimura</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sato</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Okada-Hatakeyama</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>An effective method for the inference of reduced S-system models of genetic networks</article-title>
        <source>Inform Media Tech</source>
        <year>2015</year>
        <volume>10</volume>
        <issue>1</issue>
        <fpage>166</fpage>
        <lpage>174</lpage>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bar-Even</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Noor</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Savir</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Liebermeister</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Davidi</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Tawfik</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Milo</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>The moderately efficient enzyme: evolutionary and physicochemical trends shaping enzyme parameters</article-title>
        <source>Biochemistry</source>
        <year>2011</year>
        <volume>50</volume>
        <issue>21</issue>
        <fpage>4402</fpage>
        <lpage>4410</lpage>
        <pub-id pub-id-type="doi">10.1021/bi2002289</pub-id>
        <?supplied-pmid 21506553?>
        <pub-id pub-id-type="pmid">21506553</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schomburg</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hofmann</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Ebeling</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ehrentreich</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Schomburg</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>BRENDA: a resource for enzyme data and metabolic information</article-title>
        <source>Trends Biochem Sci</source>
        <year>2002</year>
        <volume>27</volume>
        <issue>1</issue>
        <fpage>54</fpage>
        <lpage>56</lpage>
        <pub-id pub-id-type="doi">10.1016/S0968-0004(01)02027-8</pub-id>
        <?supplied-pmid 11796225?>
        <pub-id pub-id-type="pmid">11796225</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schomburg</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Schomburg</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>BRENDA, enzyme data and metabolic information</article-title>
        <source>Nucleic Acids Res</source>
        <year>2002</year>
        <volume>30</volume>
        <issue>1</issue>
        <fpage>47</fpage>
        <lpage>49</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/30.1.47</pub-id>
        <?supplied-pmid 11752250?>
        <pub-id pub-id-type="pmid">11752250</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kanehisa</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Furumichi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sato</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ishiguro-Watanabe</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Tanabe</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>KEGG: integrating viruses and cellular organisms</article-title>
        <source>Nucleic Acids Res</source>
        <year>2021</year>
        <volume>49</volume>
        <issue>D1</issue>
        <fpage>D545</fpage>
        <lpage>D551</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkaa970</pub-id>
        <?supplied-pmid 33125081?>
        <pub-id pub-id-type="pmid">33125081</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chassagnole</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Noisommit-Rizzi</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Schmid</surname>
            <given-names>JW</given-names>
          </name>
          <name>
            <surname>Mauch</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Reuss</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Dynamic modeling of the central carbon metabolism of <italic>Escherichia coli</italic></article-title>
        <source>Biotechnol Bioeng</source>
        <year>2002</year>
        <volume>79</volume>
        <issue>1</issue>
        <fpage>53</fpage>
        <lpage>73</lpage>
        <pub-id pub-id-type="doi">10.1002/bit.10288</pub-id>
        <?supplied-pmid 17590932?>
        <pub-id pub-id-type="pmid">17590932</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mistry</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chuguransky</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Williams</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Qureshi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Salazar</surname>
            <given-names>GA</given-names>
          </name>
          <name>
            <surname>Sonnhammer</surname>
            <given-names>ELL</given-names>
          </name>
          <name>
            <surname>Tosatto</surname>
            <given-names>SCE</given-names>
          </name>
          <name>
            <surname>Paladin</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Raj</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Richardson</surname>
            <given-names>LJ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Pfam: The protein families database in 2021</article-title>
        <source>Nucleic Acids Res</source>
        <year>2021</year>
        <volume>49</volume>
        <issue>D1</issue>
        <fpage>D412</fpage>
        <lpage>D419</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkaa913</pub-id>
        <?supplied-pmid 33125078?>
        <pub-id pub-id-type="pmid">33125078</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alley</surname>
            <given-names>EC</given-names>
          </name>
          <name>
            <surname>Khimulya</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Biswas</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>AlQuraishi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Church</surname>
            <given-names>GM</given-names>
          </name>
        </person-group>
        <article-title>Unified rational protein engineering with sequence-based deep representation learning</article-title>
        <source>Nat Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <issue>12</issue>
        <fpage>1315</fpage>
        <lpage>1322</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-019-0598-1</pub-id>
        <?supplied-pmid 31636460?>
        <pub-id pub-id-type="pmid">31636460</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bennett</surname>
            <given-names>BD</given-names>
          </name>
          <name>
            <surname>Kimball</surname>
            <given-names>EH</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Osterhout</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Van Dien</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Rabinowitz</surname>
            <given-names>JD</given-names>
          </name>
        </person-group>
        <article-title>Absolute metabolite concentrations and implied enzyme active site occupancy in Escherichia coli</article-title>
        <source>Nat Chem Biol</source>
        <year>2009</year>
        <volume>5</volume>
        <issue>8</issue>
        <fpage>593</fpage>
        <lpage>599</lpage>
        <pub-id pub-id-type="doi">10.1038/nchembio.186</pub-id>
        <?supplied-pmid 19561621?>
        <pub-id pub-id-type="pmid">19561621</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Arik SO, Pfister T. TabNet: attentive interpretable tabular learning. <italic>arXiv</italic> 2019.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pedregosa</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Varoquaux</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Gramfort</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Michel</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Thirion</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Grisel</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Blondel</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Prettenhofer</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Weiss</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Dubourg</surname>
            <given-names>V</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Scikit-learn: machine learning in python</article-title>
        <source>J Mach Learn Res</source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>2825</fpage>
        <lpage>2830</lpage>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Chen T, Guestrin C. XGBoost: a scalable tree boosting system. in <italic>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</italic> 2016:785–794.</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">dreamquark-ai/tabnet [<ext-link ext-link-type="uri" xlink:href="https://github.com/dreamquark-ai/tabnet">https://github.com/dreamquark-ai/tabnet</ext-link>]</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Malik-Sheriff</surname>
            <given-names>RS</given-names>
          </name>
          <name>
            <surname>Glont</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>TVN</given-names>
          </name>
          <name>
            <surname>Tiwari</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Roberts</surname>
            <given-names>MG</given-names>
          </name>
          <name>
            <surname>Xavier</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Vu</surname>
            <given-names>MT</given-names>
          </name>
          <name>
            <surname>Men</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Maire</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kananathan</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>BioModels-15 years of sharing computational models in life science</article-title>
        <source>Nucleic Acids Res</source>
        <year>2020</year>
        <volume>48</volume>
        <issue>D1</issue>
        <fpage>D407</fpage>
        <lpage>D415</lpage>
        <?supplied-pmid 31701150?>
        <pub-id pub-id-type="pmid">31701150</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
