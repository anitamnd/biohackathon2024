<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLoS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9278763</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-21-01856</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1010184</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Measurement</subject>
          <subj-group>
            <subject>Distance Measurement</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Data Management</subject>
          <subj-group>
            <subject>Data Visualization</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Cluster Analysis</subject>
            <subj-group>
              <subject>K Means Clustering</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Microbiology</subject>
          <subj-group>
            <subject>Medical Microbiology</subject>
            <subj-group>
              <subject>Microbiome</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Microbial Genomics</subject>
              <subj-group>
                <subject>Microbiome</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Microbiology</subject>
          <subj-group>
            <subject>Microbial Genomics</subject>
            <subj-group>
              <subject>Microbiome</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and life sciences</subject>
        <subj-group>
          <subject>Molecular biology</subject>
          <subj-group>
            <subject>Molecular biology techniques</subject>
            <subj-group>
              <subject>Sequencing techniques</subject>
              <subj-group>
                <subject>RNA sequencing</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and analysis methods</subject>
        <subj-group>
          <subject>Molecular biology techniques</subject>
          <subj-group>
            <subject>Sequencing techniques</subject>
            <subj-group>
              <subject>RNA sequencing</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Statistical Methods</subject>
            <subj-group>
              <subject>Multivariate Analysis</subject>
              <subj-group>
                <subject>Principal Component Analysis</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical Methods</subject>
              <subj-group>
                <subject>Multivariate Analysis</subject>
                <subj-group>
                  <subject>Principal Component Analysis</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and life sciences</subject>
        <subj-group>
          <subject>Molecular biology</subject>
          <subj-group>
            <subject>Molecular biology techniques</subject>
            <subj-group>
              <subject>Sequencing techniques</subject>
              <subj-group>
                <subject>DNA sequencing</subject>
                <subj-group>
                  <subject>Next-Generation Sequencing</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and analysis methods</subject>
        <subj-group>
          <subject>Molecular biology techniques</subject>
          <subj-group>
            <subject>Sequencing techniques</subject>
            <subj-group>
              <subject>DNA sequencing</subject>
              <subj-group>
                <subject>Next-Generation Sequencing</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Computational Biology</subject>
          <subj-group>
            <subject>Genome Analysis</subject>
            <subj-group>
              <subject>Transcriptome Analysis</subject>
              <subj-group>
                <subject>Next-Generation Sequencing</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Genome Analysis</subject>
              <subj-group>
                <subject>Transcriptome Analysis</subject>
                <subj-group>
                  <subject>Next-Generation Sequencing</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Algebra</subject>
            <subj-group>
              <subject>Linear Algebra</subject>
              <subj-group>
                <subject>Eigenvectors</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>AC-PCoA: Adjustment for confounding factors using principal coordinate analysis</article-title>
      <alt-title alt-title-type="running-head">Adjustment for confounding factors using PCoA</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8070-116X</contrib-id>
        <name>
          <surname>Wang</surname>
          <given-names>Yu</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8552-043X</contrib-id>
        <name>
          <surname>Sun</surname>
          <given-names>Fengzhu</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <xref rid="aff003" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1863-4306</contrib-id>
        <name>
          <surname>Lin</surname>
          <given-names>Wei</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff004" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="aff005" ref-type="aff">
          <sup>5</sup>
        </xref>
        <xref rid="aff006" ref-type="aff">
          <sup>6</sup>
        </xref>
        <xref rid="aff007" ref-type="aff">
          <sup>7</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8223-844X</contrib-id>
        <name>
          <surname>Zhang</surname>
          <given-names>Shuqin</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff006" ref-type="aff">
          <sup>6</sup>
        </xref>
        <xref rid="aff007" ref-type="aff">
          <sup>7</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>School of Mathematical Sciences, Fudan University, Shanghai, China</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Research Institute of Intelligent Complex Systems, Fudan University, Shanghai, China</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Quantitative and Computational Biology Department, University of Southern California, Los Angeles, California, United States of America</addr-line>
    </aff>
    <aff id="aff004">
      <label>4</label>
      <addr-line>State Key Laboratory of Medical Neurobiology, MOE Frontiers Center for Brain Science, and Institutes of Brain Science, Fudan University, Shanghai, China</addr-line>
    </aff>
    <aff id="aff005">
      <label>5</label>
      <addr-line>Shanghai Artificial Intelligence Laboratory, Shanghai, China</addr-line>
    </aff>
    <aff id="aff006">
      <label>6</label>
      <addr-line>Key Laboratory of Mathematics for Nonlinear Science (Fudan University), Ministry of Education, Shanghai, China</addr-line>
    </aff>
    <aff id="aff007">
      <label>7</label>
      <addr-line>Shanghai Key Laboratory for Contemporary Applied Mathematics (Fudan University), Shanghai, China</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Chikina</surname>
          <given-names>Maria D.</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Univrsity of Pittsburgh, UNITED STATES</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>zhangs@fudan.edu.cn</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>13</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <volume>18</volume>
    <issue>7</issue>
    <elocation-id>e1010184</elocation-id>
    <history>
      <date date-type="received">
        <day>12</day>
        <month>10</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>8</day>
        <month>5</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 Wang et al</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Wang et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1010184.pdf"/>
    <abstract>
      <p>Confounding factors exist widely in various biological data owing to technical variations, population structures and experimental conditions. Such factors may mask the true signals and lead to spurious associations in the respective biological data, making it necessary to adjust confounding factors accordingly. However, existing confounder correction methods were mainly developed based on the original data or the pairwise Euclidean distance, either one of which is inadequate for analyzing different types of data, such as sequencing data.</p>
      <p>In this work, we proposed a method called Adjustment for Confounding factors using Principal Coordinate Analysis, or AC-PCoA, which reduces data dimension and extracts the information from different distance measures using principal coordinate analysis, and adjusts confounding factors across multiple datasets by minimizing the associations between lower-dimensional representations and confounding variables. Application of the proposed method was further extended to classification and prediction. We demonstrated the efficacy of AC-PCoA on three simulated datasets and five real datasets. Compared to the existing methods, AC-PCoA shows better results in visualization, statistical testing, clustering, and classification.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>With today’s unprecedented amount of data, researchers are challenged by the need to enhance meaningful signals without the interference of unwanted confounders hidden inside the data. Data visualization is an important step toward exploring and explaining data in order to intuitively identify the dominant patterns. Principal coordinate analysis (PCoA), as a visualization tool, allows flexible ways to define pairwise distances and project the samples into lower dimensions without changing the distances. However, when visualizing large-scale biological datasets, the true patterns are often hindered by unwanted confounding variations, either biologically or technically in origin. To eliminate these confounding factors and recover underlying signals, we proposed a method called Adjustment for Confounding factors using Principal Coordinate Analysis, or AC-PCoA, and showed that it significantly outperforms existing methods in visualization through three simulation studies and five real datasets. We further showed that the low-dimensional representations given by AC-PCoA provide promising results in statistical testing, clustering, and classification as well.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>11925103</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1863-4306</contrib-id>
          <name>
            <surname>Lin</surname>
            <given-names>Wei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100003399</institution-id>
            <institution>Science and Technology Commission of Shanghai Municipality</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2021SHZDZX0103</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1863-4306</contrib-id>
          <name>
            <surname>Lin</surname>
            <given-names>Wei</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award003">
        <funding-source>
          <institution>National Key Research and Development Program</institution>
        </funding-source>
        <award-id>2021YFC2701600</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8223-844X</contrib-id>
          <name>
            <surname>Zhang</surname>
            <given-names>Shuqin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award004">
        <funding-source>
          <institution>National Key Research and Development Program</institution>
        </funding-source>
        <award-id>2021YFC2701601</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8223-844X</contrib-id>
          <name>
            <surname>Zhang</surname>
            <given-names>Shuqin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award005">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100003399</institution-id>
            <institution>Science and Technology Commission of Shanghai Municipality</institution>
          </institution-wrap>
        </funding-source>
        <award-id>20ZR1407700</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8223-844X</contrib-id>
          <name>
            <surname>Zhang</surname>
            <given-names>Shuqin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award006">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100014718</institution-id>
            <institution>Innovative Research Group Project of the National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>61932008</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8223-844X</contrib-id>
          <name>
            <surname>Zhang</surname>
            <given-names>Shuqin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>W.L is supported by National Natural Science Foundation of China (Grant No. 11925103) and Shanghai Municipal Science and Technology Major Project (Grant No. 2021SHZDZX0103). S.Z was supported by the National Key Research and Development Program (Grant No. 2021YFC2701601), Science and Technology Commission of Shanghai Municipality (Grant No. 20ZR1407700) and Key Program of National Natural Science Foundation of China (Grant No. 61932008). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="6"/>
      <table-count count="0"/>
      <page-count count="21"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All relevant data and code are within the manuscript and its <xref rid="sec019" ref-type="sec">Supporting information</xref> files.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All relevant data and code are within the manuscript and its <xref rid="sec019" ref-type="sec">Supporting information</xref> files.</p>
  </notes>
</front>
<body>
  <disp-quote>
    <p>This is a <italic toggle="yes">PLOS Computational Biology</italic> Methods paper.</p>
  </disp-quote>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Confounding factors, which are generally regarded as hidden variables, exist widely in various biological data, and they affect data in unknown ways. Some of these confounding factors are caused by technical issues, also known as batch effects, such as lab variations in multisite data generation processes. Others are biologically oriented, such as unwanted differences of sex, age, or ethnic groups. Such factors may mask the true signals and lead to spurious findings. Therefore, it is necessary to correct the confounding factors when analyzing datasets with possible underlying confounders.</p>
    <p>Many methods have been developed in the last few decades to remove confounding factors directly. For example, Johnson <italic toggle="yes">et al</italic>. [<xref rid="pcbi.1010184.ref001" ref-type="bibr">1</xref>] proposed parametric and non-parametric empirical Bayes methods, which are robust to outliers for samples of small size, to adjust for batch effects. Leek <italic toggle="yes">et al</italic>. [<xref rid="pcbi.1010184.ref002" ref-type="bibr">2</xref>–<xref rid="pcbi.1010184.ref004" ref-type="bibr">4</xref>] introduced surrogate variable analysis (SVA) for identifying, estimating, and incorporating sources of expression heterogeneity into gene expression analysis. SVA identifies groups of genes affected by each unobserved factor and estimates the factor based on the expression of those genes. Negative controls and technical replicates have also been introduced to identify and remove unwanted variations in high-dimensional data [<xref rid="pcbi.1010184.ref005" ref-type="bibr">5</xref>–<xref rid="pcbi.1010184.ref008" ref-type="bibr">8</xref>]. A large number of scientific research from various disciplines are still focusing on this issue in recent years [<xref rid="pcbi.1010184.ref009" ref-type="bibr">9</xref>–<xref rid="pcbi.1010184.ref014" ref-type="bibr">14</xref>].</p>
    <p>More high-dimensional data lead to more corresponding demand for simultaneous dimension reduction and confounding factor correction. To meet this demand, Lin <italic toggle="yes">et al</italic>. [<xref rid="pcbi.1010184.ref015" ref-type="bibr">15</xref>] proposed AC-PCA for simultaneous dimension reduction and adjustment for confounding variations. It is a model-free method, and it has shown good performance when removing variations across individual donors in a human brain exon array dataset and across different species in an ENCODE RNA-Seq dataset. However, when only pairwise distances are available in the data, AC-PCA is no longer applicable. In reality, there are also situations where non-Euclidean distances are better at describing pairwise relationships. For example, alignment-free distances [<xref rid="pcbi.1010184.ref016" ref-type="bibr">16</xref>–<xref rid="pcbi.1010184.ref018" ref-type="bibr">18</xref>] are particularly designed for next-generation sequencing data, and Bray-Curtis distance [<xref rid="pcbi.1010184.ref019" ref-type="bibr">19</xref>] is widely used in the field of metagenomics, while Manhattan distance is suitable for data sampled from Laplace distribution. Some generalized distance measures are specifically designed for ordinal data [<xref rid="pcbi.1010184.ref020" ref-type="bibr">20</xref>], categorical data [<xref rid="pcbi.1010184.ref021" ref-type="bibr">21</xref>], and sparse data [<xref rid="pcbi.1010184.ref022" ref-type="bibr">22</xref>, <xref rid="pcbi.1010184.ref023" ref-type="bibr">23</xref>]. Involving analysis of the proper distance measures can help capture major, as well as subtle, differences among samples. Such cases require appropriate methods to adjust for confounding variation.</p>
    <p>Principal Coordinate Analysis (PCoA), also known as classical Multidimensional Scaling (MDS), is a popular method of dimension reduction when only the distance measures are given. It was seminally proposed by Torgerson in 1958 [<xref rid="pcbi.1010184.ref024" ref-type="bibr">24</xref>] and Gower in 1966 [<xref rid="pcbi.1010184.ref025" ref-type="bibr">25</xref>], and it has been widely used in biological and ecological studies [<xref rid="pcbi.1010184.ref026" ref-type="bibr">26</xref>–<xref rid="pcbi.1010184.ref028" ref-type="bibr">28</xref>]. Based on PCoA, adjusted Principal Coordinates Analysis (aPCoA) is a recently proposed method for adjusting covariates [<xref rid="pcbi.1010184.ref029" ref-type="bibr">29</xref>]. By calculating the eigenvectors and the eigenvalues of confounder-adjusted Gower’s center matrix, aPCoA can improve data visualization and enhance presentation of the effects of interest. However, aPCoA assumes a linear relationship between the Euclidean representation of data and the confounding factors, which may introduce bias and remove desired signals in the original data.</p>
    <p>Therefore, in this work, we introduce AC-PCoA, a novel method to simultaneously perform dimension reduction and confounding factor removal. This method definitely can manage a large variety of confounders for various types of data and distances. AC-PCoA can also be extended for data preprocessing in classification and prediction problems when confounding factors exist. In order to further validate the performance of AC-PCoA, we consider four evaluation criteria, using three simulated datasets and five real datasets. Then, comparisons with the existing methods show that AC-PCoA gives more meaningful patterns in visualization, more significant results in MANOVA testing, as well as better clustering and classification accuracy.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>Methods</title>
    <p>In this section, we first review AC-PCA, and then present AC-PCoA in detail. Furthermore, we discuss the applications of AC-PCoA in classification problems.</p>
    <sec id="sec003">
      <title>AC-PCA</title>
      <p>AC-PCA was proposed by Lin <italic toggle="yes">et al</italic>. [<xref rid="pcbi.1010184.ref015" ref-type="bibr">15</xref>] to perform simultaneous dimension reduction and adjustment for confounding variations. In a typical case, let <italic toggle="yes">X</italic> be an <italic toggle="yes">N</italic> × <italic toggle="yes">p</italic> data matrix representing <italic toggle="yes">N</italic> samples and <italic toggle="yes">p</italic> features with each data point denoted as <italic toggle="yes"><bold>x</bold></italic><sub><italic toggle="yes">i</italic></sub> ∈ <italic toggle="yes">R</italic><sup><italic toggle="yes">p</italic></sup>. Here, <italic toggle="yes">X</italic> is centered by column. Let <italic toggle="yes">Y</italic> be the <italic toggle="yes">N</italic> × <italic toggle="yes">l</italic> matrix for <italic toggle="yes">l</italic> confounding factors with <italic toggle="yes"><bold>y</bold></italic><sub><italic toggle="yes">i</italic></sub> ∈ <italic toggle="yes">R</italic><sup><italic toggle="yes">l</italic></sup> as the confounding factor of each sample <italic toggle="yes"><bold>x</bold></italic><sub><italic toggle="yes">i</italic></sub>. AC-PCA modifies principal component analysis (PCA) and aims to solve the following optimization problem:
<disp-formula id="pcbi.1010184.e001"><alternatives><graphic xlink:href="pcbi.1010184.e001.jpg" id="pcbi.1010184.e001g" position="anchor"/><mml:math id="M1" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mtext>max</mml:mtext><mml:mi>V</mml:mi></mml:munder><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mtext>trace</mml:mtext><mml:mo>{</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mi>X</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mi>X</mml:mi><mml:mi>V</mml:mi><mml:mo>-</mml:mo><mml:mo>λ</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mi>X</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mi>K</mml:mi><mml:mi>X</mml:mi><mml:mi>V</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mo>∥</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>≠</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula>
where <italic toggle="yes"><bold>v</bold></italic><sub><italic toggle="yes">t</italic></sub> and <italic toggle="yes"><bold>v</bold></italic><sub><italic toggle="yes">g</italic></sub> denote the <italic toggle="yes">t</italic>-th and <italic toggle="yes">g</italic>-th columns of <italic toggle="yes">V</italic>, and <italic toggle="yes">T</italic> is the reduced dimensionality. In addition, <italic toggle="yes">K</italic> is the <italic toggle="yes">N</italic> × <italic toggle="yes">N</italic> kernel matrix constructed from the confounding factors, and <italic toggle="yes">K</italic><sub><italic toggle="yes">ij</italic></sub> = <italic toggle="yes">k</italic>(<italic toggle="yes"><bold>y</bold></italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes"><bold>y</bold></italic><sub><italic toggle="yes">j</italic></sub>). The first term in the objective function maximizes the variance of the projected data <italic toggle="yes">XV</italic>, as in principal component analysis. The second term penalizes the dependence between projected data <italic toggle="yes">XV</italic> and the confounding factors <italic toggle="yes">Y</italic>. The parameter λ balances these two terms. Denote <italic toggle="yes">Z</italic> = <italic toggle="yes">X</italic><sup>⊤</sup><italic toggle="yes">X</italic> − λ<italic toggle="yes">X</italic><sup>⊤</sup><italic toggle="yes">KX</italic>. The above optimization problem can be rewritten as:
<disp-formula id="pcbi.1010184.e002"><alternatives><graphic xlink:href="pcbi.1010184.e002.jpg" id="pcbi.1010184.e002g" position="anchor"/><mml:math id="M2" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mtext>max</mml:mtext><mml:mi>V</mml:mi></mml:munder><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mtext>trace</mml:mtext><mml:mo>{</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mi>Z</mml:mi><mml:mi>V</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mo>∥</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>≠</mml:mo><mml:mi>g</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
      <p>It is straightforward to solve this optimization problem by implementing an eigen-decomposition on <italic toggle="yes">Z</italic>.</p>
      <p>AC-PCA is effective when Euclidean distance is used to characterize sample relationships. However, it is a common case in biological data that non-Euclidean distance is better for describing pairwise dissimilarities. Accordingly, we were motivated to extend AC-PCA to AC-PCoA for handling more generalized distance measures.</p>
    </sec>
    <sec id="sec004">
      <title>AC-PCoA: Confounding factor adjustment based on pairwise distances</title>
      <p>In this subsection, we extend PCoA to AC-PCoA to perform confounding factor adjustment with dimension reduction. As previously noted, PCoA is a popular dimension reduction and visualization method when pairwise distances of the samples are given without the original data. It projects the samples into a lower-dimensional Euclidean space so that the given pairwise relations are preserved. The procedure of applying PCoA can be summarized in the following steps:</p>
      <list list-type="order">
        <list-item>
          <p>Given the <italic toggle="yes">N</italic> × <italic toggle="yes">p</italic> data matrix <italic toggle="yes">X</italic>, representing <italic toggle="yes">N</italic> samples and <italic toggle="yes">p</italic> features, the pairwise distance matrix <italic toggle="yes">D</italic> using the desired distance measure is first calculated. If data available are pairwise distance matrix <italic toggle="yes">D</italic>, go to the next step.</p>
        </list-item>
        <list-item>
          <p>Transform distance matrix to similarity matrix <italic toggle="yes">A</italic>: <inline-formula id="pcbi.1010184.e003"><alternatives><graphic xlink:href="pcbi.1010184.e003.jpg" id="pcbi.1010184.e003g" position="anchor"/><mml:math id="M3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>.</p>
        </list-item>
        <list-item>
          <p>Normalize similarity matrix: <inline-formula id="pcbi.1010184.e004"><alternatives><graphic xlink:href="pcbi.1010184.e004.jpg" id="pcbi.1010184.e004g" position="anchor"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>-</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mo>)</mml:mo><mml:mi>A</mml:mi><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>-</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mi>⊤</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1010184.e005"><alternatives><graphic xlink:href="pcbi.1010184.e005.jpg" id="pcbi.1010184.e005g" position="anchor"/><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">s</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <bold>1</bold> = (1, …, 1)<sup>⊤</sup>.</p>
        </list-item>
        <list-item>
          <p>Calculate the <italic toggle="yes">M</italic> eigenvectors corresponding to the <italic toggle="yes">M</italic> leading eigenvalues λ<sub><italic toggle="yes">m</italic></sub>, <italic toggle="yes">m</italic> = 1, 2, …, <italic toggle="yes">M</italic> of <inline-formula id="pcbi.1010184.e006"><alternatives><graphic xlink:href="pcbi.1010184.e006.jpg" id="pcbi.1010184.e006g" position="anchor"/><mml:math id="M6" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. These eigenvectors are then normalized to have norm <inline-formula id="pcbi.1010184.e007"><alternatives><graphic xlink:href="pcbi.1010184.e007.jpg" id="pcbi.1010184.e007g" position="anchor"/><mml:math id="M7" display="inline" overflow="scroll"><mml:msqrt><mml:msub><mml:mo>λ</mml:mo><mml:mi>m</mml:mi></mml:msub></mml:msqrt></mml:math></alternatives></inline-formula>.</p>
        </list-item>
      </list>
      <p>The result of PCoA is defined as matrix <inline-formula id="pcbi.1010184.e008"><alternatives><graphic xlink:href="pcbi.1010184.e008.jpg" id="pcbi.1010184.e008g" position="anchor"/><mml:math id="M8" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>M</mml:mi></mml:msub></mml:math></alternatives></inline-formula> with each column being one of the <italic toggle="yes">M</italic> corresponding normalized eigenvectors of <inline-formula id="pcbi.1010184.e009"><alternatives><graphic xlink:href="pcbi.1010184.e009.jpg" id="pcbi.1010184.e009g" position="anchor"/><mml:math id="M9" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. In the following, we set <italic toggle="yes">M</italic> as the number of positive eigenvalues of <inline-formula id="pcbi.1010184.e010"><alternatives><graphic xlink:href="pcbi.1010184.e010.jpg" id="pcbi.1010184.e010g" position="anchor"/><mml:math id="M10" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, which can well capture the patterns in the data, and simplify <inline-formula id="pcbi.1010184.e011"><alternatives><graphic xlink:href="pcbi.1010184.e011.jpg" id="pcbi.1010184.e011g" position="anchor"/><mml:math id="M11" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>M</mml:mi></mml:msub></mml:math></alternatives></inline-formula> as <inline-formula id="pcbi.1010184.e012"><alternatives><graphic xlink:href="pcbi.1010184.e012.jpg" id="pcbi.1010184.e012g" position="anchor"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. Notice that PCoA is equivalent to PCA when Euclidean distance is used to calculate the pairwise distances [<xref rid="pcbi.1010184.ref030" ref-type="bibr">30</xref>]. Detailed explanations were given in Gower [<xref rid="pcbi.1010184.ref025" ref-type="bibr">25</xref>, <xref rid="pcbi.1010184.ref031" ref-type="bibr">31</xref>] and Legendra [<xref rid="pcbi.1010184.ref024" ref-type="bibr">24</xref>].</p>
      <p>To extend PCoA to handle multiple datasets with confounding factors, we aim to preserve pairwise distances in a lower dimensional space, and at the same time minimize the associations between the lower-dimensional representation and the confounding variables. Based on principal coordinate representations <inline-formula id="pcbi.1010184.e013"><alternatives><graphic xlink:href="pcbi.1010184.e013.jpg" id="pcbi.1010184.e013g" position="anchor"/><mml:math id="M13" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> of the original data, AC-PCoA is proposed as a method of adjusting confounding factors that finds the principal directions by solving the following optimization problem:
<disp-formula id="pcbi.1010184.e014"><alternatives><graphic xlink:href="pcbi.1010184.e014.jpg" id="pcbi.1010184.e014g" position="anchor"/><mml:math id="M14" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mtext>max</mml:mtext><mml:mi>V</mml:mi></mml:munder><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mtext>trace</mml:mtext><mml:mo>{</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>⊤</mml:mi></mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>V</mml:mi><mml:mo>-</mml:mo><mml:mo>λ</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>⊤</mml:mi></mml:msup><mml:mi>K</mml:mi><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>V</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mo>∥</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>≠</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(2)</label></disp-formula>
where the notations are the same as those in AC-PCA. Confounding factors are user-defined and depend on the assumptions of confounding factors’ variation. We provide several examples on the choice of <italic toggle="yes">Y</italic> in simulation studies and real data analysis. To solve the optimization problem (<xref rid="pcbi.1010184.e014" ref-type="disp-formula">2</xref>), we denote <inline-formula id="pcbi.1010184.e015"><alternatives><graphic xlink:href="pcbi.1010184.e015.jpg" id="pcbi.1010184.e015g" position="anchor"/><mml:math id="M15" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>Z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>⊤</mml:mi></mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:mo>λ</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>⊤</mml:mi></mml:msup><mml:mi>K</mml:mi><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>, and the optimization problem can be rewritten as:
<disp-formula id="pcbi.1010184.e016"><alternatives><graphic xlink:href="pcbi.1010184.e016.jpg" id="pcbi.1010184.e016g" position="anchor"/><mml:math id="M16" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mtext>max</mml:mtext><mml:mi>V</mml:mi></mml:munder><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mtext>trace</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mover accent="true"><mml:mi>Z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>V</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mo>∥</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>≠</mml:mo><mml:mi>g</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
      <p>By implementing eigen-decomposition on <inline-formula id="pcbi.1010184.e017"><alternatives><graphic xlink:href="pcbi.1010184.e017.jpg" id="pcbi.1010184.e017g" position="anchor"/><mml:math id="M17" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>Z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, we may get the principal directions <inline-formula id="pcbi.1010184.e018"><alternatives><graphic xlink:href="pcbi.1010184.e018.jpg" id="pcbi.1010184.e018g" position="anchor"/><mml:math id="M18" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and the data representation <inline-formula id="pcbi.1010184.e019"><alternatives><graphic xlink:href="pcbi.1010184.e019.jpg" id="pcbi.1010184.e019g" position="anchor"/><mml:math id="M19" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>. Note that PCoA is equivalent to PCA when Euclidean distance is used to calculate pairwise distances. We performed extensive simulation studies and real data analysis, and the experiments showed that the results of AC-PCoA, when using Euclidean distance, are pretty close to that of AC-PCA.</p>
      <p>As for the choice of parameter λ, we followed Lin <italic toggle="yes">et al</italic>. [<xref rid="pcbi.1010184.ref015" ref-type="bibr">15</xref>] and defined <inline-formula id="pcbi.1010184.e020"><alternatives><graphic xlink:href="pcbi.1010184.e020.jpg" id="pcbi.1010184.e020g" position="anchor"/><mml:math id="M20" display="inline" overflow="scroll"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>λ</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>trace</mml:mtext><mml:mo>(</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>⊤</mml:mi></mml:msup><mml:mi>K</mml:mi><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>V</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mtext>trace</mml:mtext><mml:mo>(</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>⊤</mml:mi></mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>V</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> to be the ratio of penalty term verses the principal projection. As λ increases from 0, <italic toggle="yes">R</italic>(λ) tends to decrease. When the penalty term in <xref rid="pcbi.1010184.e014" ref-type="disp-formula">Eq (2)</xref> is designed as the between-groups sum of squares, λ is determined by the smallest value such that <italic toggle="yes">R</italic>(λ) ≤ 0.05 in the principal coordinates of interest. For other definitions of the penalty term, we choose the smallest λ that can satisfy <italic toggle="yes">R</italic>(λ) ≤ 0.05<italic toggle="yes">R</italic>(0). It is worth mentioning that the overall results are quite robust against the fluctuation of λ in a wide range.</p>
    </sec>
    <sec id="sec005">
      <title>Data preprocessing using AC-PCoA in classification and prediction problems</title>
      <p>In this subsection, we extend the application of AC-PCoA to classification and prediction. In large-scale data analysis, the data may be collected from multiple sites or different groups, which could affect the performance of prediction methods. Correcting these confounding factors can help improve prediction accuracy. Here, we adapt AC-PCoA to correct confounding factors and perform dimension reduction for the training data and test data, and then conduct prediction and classification.</p>
      <p>Suppose we have training dataset {<italic toggle="yes">X</italic>, <italic toggle="yes">Y</italic>, <bold>z</bold>}, where <italic toggle="yes">X</italic> is the covariate data matrix of size <italic toggle="yes">N</italic> × <italic toggle="yes">p</italic> with each data point denoted as <italic toggle="yes"><bold>x</bold></italic><sub><italic toggle="yes">i</italic></sub> ∈ <italic toggle="yes">R</italic><sup><italic toggle="yes">p</italic></sup>, <italic toggle="yes">Y</italic> is the <italic toggle="yes">N</italic> × <italic toggle="yes">l</italic> confounding factor matrix with <italic toggle="yes"><bold>y</bold></italic><sub><italic toggle="yes">i</italic></sub> ∈ <italic toggle="yes">R</italic><sup><italic toggle="yes">l</italic></sup> as the confounding factors of each sample <italic toggle="yes"><bold>x</bold></italic><sub><italic toggle="yes">i</italic></sub>, and <bold>z</bold> describes the classes to which each sample belongs for <italic toggle="yes">i</italic> = 1, 2, ⋯, <italic toggle="yes">N</italic>. The relationships between <italic toggle="yes">X</italic> and <bold>z</bold> are modelled such that the corresponding class of a new data point <italic toggle="yes"><bold>x</bold></italic> can be predicted. When confounding factors <italic toggle="yes">Y</italic> exist, the prediction may be misled by these variations. However, by applying AC-PCoA to the training set, we can obtain the lower-dimensional representations <inline-formula id="pcbi.1010184.e021"><alternatives><graphic xlink:href="pcbi.1010184.e021.jpg" id="pcbi.1010184.e021g" position="anchor"/><mml:math id="M21" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mtext>s</mml:mtext></mml:math></alternatives></inline-formula> after confounder adjustment and then we can train the classification and prediction model. When a test data point <italic toggle="yes"><bold>x</bold></italic> ∈ <italic toggle="yes">R</italic><sup><italic toggle="yes">p</italic></sup> with confounding factor <italic toggle="yes"><bold>y</bold></italic> ∈ <italic toggle="yes">R</italic><sup><italic toggle="yes">l</italic></sup> comes, higher prediction accuracy is expected by using the data point’s lower-dimensional representation <inline-formula id="pcbi.1010184.e022"><alternatives><graphic xlink:href="pcbi.1010184.e022.jpg" id="pcbi.1010184.e022g" position="anchor"/><mml:math id="M22" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> in the same space as that of the training data for classification.</p>
      <p>We employ the idea of kernel PCA [<xref rid="pcbi.1010184.ref032" ref-type="bibr">32</xref>] to perform confounder correction for the newcoming data point <italic toggle="yes"><bold>x</bold></italic>. Consider a feature space introduced by a mapping Φ(⋅), which is implicit and is characterized by a kernel matrix <inline-formula id="pcbi.1010184.e023"><alternatives><graphic xlink:href="pcbi.1010184.e023.jpg" id="pcbi.1010184.e023g" position="anchor"/><mml:math id="M23" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>〈</mml:mo><mml:mo>Φ</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>Φ</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1010184.e024"><alternatives><graphic xlink:href="pcbi.1010184.e024.jpg" id="pcbi.1010184.e024g" position="anchor"/><mml:math id="M24" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is the normalized similarity matrix in PCoA. For the training data, PCoA is equivalent to projecting the mapped data Φ(<italic toggle="yes"><bold>x</bold></italic><sub><italic toggle="yes">i</italic></sub>) onto the direction of the first <italic toggle="yes">M</italic> normalized eigenvectors <italic toggle="yes"><bold>w</bold></italic><sub>1</sub>, ⋯, <italic toggle="yes"><bold>w</bold></italic><sub><italic toggle="yes">M</italic></sub> of the covariance matrix <inline-formula id="pcbi.1010184.e025"><alternatives><graphic xlink:href="pcbi.1010184.e025.jpg" id="pcbi.1010184.e025g" position="anchor"/><mml:math id="M25" display="inline" overflow="scroll"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mo>Φ</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>Φ</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, i.e., for each <inline-formula id="pcbi.1010184.e026"><alternatives><graphic xlink:href="pcbi.1010184.e026.jpg" id="pcbi.1010184.e026g" position="anchor"/><mml:math id="M26" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1010184.e027"><alternatives><graphic xlink:href="pcbi.1010184.e027.jpg" id="pcbi.1010184.e027g" position="anchor"/><mml:math id="M27" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>〈</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>Φ</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where ‖<italic toggle="yes"><bold>w</bold></italic><sub><italic toggle="yes">m</italic></sub>‖<sub>2</sub> = 1, <italic toggle="yes">m</italic> = 1, …, <italic toggle="yes">M</italic>. This projection becomes tractable since <inline-formula id="pcbi.1010184.e028"><alternatives><graphic xlink:href="pcbi.1010184.e028.jpg" id="pcbi.1010184.e028g" position="anchor"/><mml:math id="M28" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>Φ</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>〉</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>〈</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <italic toggle="yes"><bold>u</bold></italic><sub><italic toggle="yes">m</italic></sub> = (<italic toggle="yes">u</italic><sub><italic toggle="yes">m</italic>1</sub>, ⋯, <italic toggle="yes">u</italic><sub><italic toggle="yes">mn</italic></sub>) is the eigenvector of kernel matrix <inline-formula id="pcbi.1010184.e029"><alternatives><graphic xlink:href="pcbi.1010184.e029.jpg" id="pcbi.1010184.e029g" position="anchor"/><mml:math id="M29" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> with norm <inline-formula id="pcbi.1010184.e030"><alternatives><graphic xlink:href="pcbi.1010184.e030.jpg" id="pcbi.1010184.e030g" position="anchor"/><mml:math id="M30" display="inline" overflow="scroll"><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:msub><mml:mo>λ</mml:mo><mml:mi>m</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:math></alternatives></inline-formula> corresponding to the <italic toggle="yes">m</italic>-th eigenvalue λ<sub><italic toggle="yes">m</italic></sub> of <inline-formula id="pcbi.1010184.e031"><alternatives><graphic xlink:href="pcbi.1010184.e031.jpg" id="pcbi.1010184.e031g" position="anchor"/><mml:math id="M31" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. For a test point <italic toggle="yes"><bold>x</bold></italic>, the image of which is Φ(<italic toggle="yes"><bold>x</bold></italic>), one can also use the same idea and compute the projected point <inline-formula id="pcbi.1010184.e032"><alternatives><graphic xlink:href="pcbi.1010184.e032.jpg" id="pcbi.1010184.e032g" position="anchor"/><mml:math id="M32" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1010184.e033"><alternatives><graphic xlink:href="pcbi.1010184.e033.jpg" id="pcbi.1010184.e033g" position="anchor"/><mml:math id="M33" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>{</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>}</mml:mo></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>〈</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">w</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>Φ</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>〉</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>〈</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>〉</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. <inline-formula id="pcbi.1010184.e034"><alternatives><graphic xlink:href="pcbi.1010184.e034.jpg" id="pcbi.1010184.e034g" position="anchor"/><mml:math id="M34" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> denotes the vector of centered kernel function applied to <italic toggle="yes"><bold>x</bold></italic> and all training points. After obtaining the projected test data <inline-formula id="pcbi.1010184.e035"><alternatives><graphic xlink:href="pcbi.1010184.e035.jpg" id="pcbi.1010184.e035g" position="anchor"/><mml:math id="M35" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> from PCoA, we then adjust for confounding factors by multiplying the projection <inline-formula id="pcbi.1010184.e036"><alternatives><graphic xlink:href="pcbi.1010184.e036.jpg" id="pcbi.1010184.e036g" position="anchor"/><mml:math id="M36" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> with the direction <inline-formula id="pcbi.1010184.e037"><alternatives><graphic xlink:href="pcbi.1010184.e037.jpg" id="pcbi.1010184.e037g" position="anchor"/><mml:math id="M37" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> obtained from the training step. We can then perform classification on the lower-dimensional representations <inline-formula id="pcbi.1010184.e038"><alternatives><graphic xlink:href="pcbi.1010184.e038.jpg" id="pcbi.1010184.e038g" position="anchor"/><mml:math id="M38" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>⊤</mml:mi></mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> of the test data points. The procedure is given below.</p>
      <list list-type="order">
        <list-item>
          <p>Perform AC-PCoA on training data <italic toggle="yes">X</italic> to get principal direction matrix <inline-formula id="pcbi.1010184.e039"><alternatives><graphic xlink:href="pcbi.1010184.e039.jpg" id="pcbi.1010184.e039g" position="anchor"/><mml:math id="M39" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and data projection matrix <inline-formula id="pcbi.1010184.e040"><alternatives><graphic xlink:href="pcbi.1010184.e040.jpg" id="pcbi.1010184.e040g" position="anchor"/><mml:math id="M40" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Meanwhile, save matrix <inline-formula id="pcbi.1010184.e041"><alternatives><graphic xlink:href="pcbi.1010184.e041.jpg" id="pcbi.1010184.e041g" position="anchor"/><mml:math id="M41" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> as similarity matrix and matrix <italic toggle="yes">U</italic> = (<italic toggle="yes"><bold>u</bold></italic><sub>1</sub>, <italic toggle="yes"><bold>u</bold></italic><sub>2</sub>, …, <italic toggle="yes"><bold>u</bold></italic><sub><italic toggle="yes">M</italic></sub>) as the matrix of eigenvectors of <inline-formula id="pcbi.1010184.e042"><alternatives><graphic xlink:href="pcbi.1010184.e042.jpg" id="pcbi.1010184.e042g" position="anchor"/><mml:math id="M42" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> corresponding to positive eigenvalues with <inline-formula id="pcbi.1010184.e043"><alternatives><graphic xlink:href="pcbi.1010184.e043.jpg" id="pcbi.1010184.e043g" position="anchor"/><mml:math id="M43" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">u</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msqrt><mml:msub><mml:mo>λ</mml:mo><mml:mi>m</mml:mi></mml:msub></mml:msqrt></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> for later use.</p>
        </list-item>
        <list-item>
          <p>Conduct AC-PCoA on test data.</p>
          <list list-type="alpha-lower">
            <list-item>
              <p>For a test data point <italic toggle="yes"><bold>x</bold></italic>, calculate the distances between it and all the training data points. Denote this vector as <italic toggle="yes">D</italic>(<italic toggle="yes"><bold>x</bold></italic>, ⋅) = (<italic toggle="yes">d</italic><sub><italic toggle="yes"><bold>x</bold></italic>1</sub>, ⋯, <italic toggle="yes">d</italic><sub><italic toggle="yes"><bold>x</bold>N</italic></sub>).</p>
            </list-item>
            <list-item>
              <p>Calculate the corresponding similarity vector <italic toggle="yes">A</italic>(<italic toggle="yes"><bold>x</bold></italic>, ⋅) = (<italic toggle="yes">a</italic><sub><italic toggle="yes"><bold>x</bold></italic>1</sub>, ⋯, <italic toggle="yes">a</italic><sub><italic toggle="yes"><bold>x</bold>N</italic></sub>) by <inline-formula id="pcbi.1010184.e044"><alternatives><graphic xlink:href="pcbi.1010184.e044.jpg" id="pcbi.1010184.e044g" position="anchor"/><mml:math id="M44" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msubsup><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. Center it to the same origin as that of the training data by <inline-formula id="pcbi.1010184.e045"><alternatives><graphic xlink:href="pcbi.1010184.e045.jpg" id="pcbi.1010184.e045g" position="anchor"/><mml:math id="M45" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mn mathvariant="bold">1</mml:mn><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mi>⊤</mml:mi></mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mi>A</mml:mi><mml:mn mathvariant="bold">1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mn mathvariant="bold">1</mml:mn><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mi>⊤</mml:mi></mml:msup><mml:mi>A</mml:mi><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
            </list-item>
            <list-item>
              <p>Calculate PCoA representation of test data point by <inline-formula id="pcbi.1010184.e046"><alternatives><graphic xlink:href="pcbi.1010184.e046.jpg" id="pcbi.1010184.e046g" position="anchor"/><mml:math id="M46" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mi>U</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>,</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
            </list-item>
            <list-item>
              <p>Obtain the <italic toggle="yes">T</italic> dimensional AC-PCoA representation <inline-formula id="pcbi.1010184.e047"><alternatives><graphic xlink:href="pcbi.1010184.e047.jpg" id="pcbi.1010184.e047g" position="anchor"/><mml:math id="M47" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msub></mml:math></alternatives></inline-formula> by <inline-formula id="pcbi.1010184.e048"><alternatives><graphic xlink:href="pcbi.1010184.e048.jpg" id="pcbi.1010184.e048g" position="anchor"/><mml:math id="M48" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>⊤</mml:mi></mml:msup><mml:msub><mml:mover accent="true"><mml:mi>V</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p>
            </list-item>
          </list>
        </list-item>
        <list-item>
          <p>Use <inline-formula id="pcbi.1010184.e049"><alternatives><graphic xlink:href="pcbi.1010184.e049.jpg" id="pcbi.1010184.e049g" position="anchor"/><mml:math id="M49" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msub></mml:math></alternatives></inline-formula> as input to train the classifier.</p>
        </list-item>
        <list-item>
          <p>Feed <inline-formula id="pcbi.1010184.e050"><alternatives><graphic xlink:href="pcbi.1010184.e050.jpg" id="pcbi.1010184.e050g" position="anchor"/><mml:math id="M50" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msub></mml:math></alternatives></inline-formula> to the trained classifier to do prediction.</p>
        </list-item>
      </list>
      <p>By first projecting the data to a lower-dimensional space and selecting relevant features, signal-to-noise ratio can be increased, which might help improve classification accuracy. AC-PCoA, as a preprocessing step, is beneficial to finding desired principal directions of data without the potential misdirection of confounding variation, thus improving classification accuracy.</p>
    </sec>
    <sec id="sec006">
      <title>Evaluation criteria</title>
      <p>The performance of AC-PCoA is evaluated through four different criteria.</p>
      <list list-type="order">
        <list-item>
          <p>Visualization. By projecting the data to a two-dimensional space after using AC-PCoA and coloring the data with inherent features, check whether AC-PCoA can remove confounding variations and recover the underlying patterns hidden in the data.</p>
        </list-item>
        <list-item>
          <p>Multivariate analysis of variance (MANOVA). MANOVA can evaluate the significance of groups defined by data representation after confounding factor adjustment and the underlying true labels. In MANOVA, an <italic toggle="yes">F</italic>-statistic is defined to access the mean rank of distance between samples in two groups, and a permutation test is employed to calculate the p-value. In this paper, the function ‘anosim’ in R package <monospace>vegan</monospace> is employed to calculate the <italic toggle="yes">F</italic>-statistic. As the <italic toggle="yes">F</italic>-statistic increases, the significance of the cluster increases.</p>
        </list-item>
        <list-item>
          <p>Normalized mutual information (NMI) [<xref rid="pcbi.1010184.ref033" ref-type="bibr">33</xref>]. NMI is one of the popular evaluation metrics estimating clustering quality. After conducting <italic toggle="yes">k</italic>-means clustering on low-dimensional data representations given by AC-PCoA, NMI is employed to measure how well the low-dimensional representations of samples are clustered. NMI is calculated using the ‘NMI’ function in R package <monospace>aricode</monospace>. The number of clusters <italic toggle="yes">k</italic> in <italic toggle="yes">k</italic>-means is set to be the number of true labels.</p>
        </list-item>
        <list-item>
          <p>Classification accuracy. AC-PCoA can be applied as the preprocessing step in classification problems. Random forest is used as the classifier and parameters are tuned using grid search. Five-fold cross validation is used to evaluate performance. All the classification procedures are performed by tuning parameters on the training set only and evaluating accuracy on independent validation set. In the following analysis, the numbers of principal components are set to 2 and 3 to demonstrate the performance of AC-PCoA as a visualization tool. The classification performance of AC-PCoA on higher dimensions is provided in <xref rid="pcbi.1010184.s004" ref-type="supplementary-material">S1 Fig</xref> and <xref rid="pcbi.1010184.s001" ref-type="supplementary-material">S1 Appendix</xref>.</p>
        </list-item>
      </list>
    </sec>
  </sec>
  <sec sec-type="results" id="sec007">
    <title>Results</title>
    <p>In this section, AC-PCoA was first tested on three simulation studies and then on five real datasets.</p>
    <p>In all experiments, AC-PCoA was carried out following <xref rid="pcbi.1010184.e014" ref-type="disp-formula">Eq (2)</xref>, and the linear kernel was chosen. Different distance measures were considered, the definitions of which are provided in <xref rid="pcbi.1010184.s002" ref-type="supplementary-material">S2 Appendix</xref>. For comparison, we also conducted PCoA and aPCoA [<xref rid="pcbi.1010184.ref029" ref-type="bibr">29</xref>] using the same distance measures. We demonstrated the results of AC-PCA implicitly via AC-PCoA using Euclidean distance, denoted as AC-PCoA(eu), in real data analysis because the two- and three-dimensional representations given by AC-PCA are equivalent to those given by AC-PCoA(eu). Also, running AC-PCA takes more time than running AC-PCoA when the number of variables is large. Four criteria were employed to evaluate the performance of PCoA, AC-PCoA, and aPCoA. Note that aPCoA cannot be applied to classification.</p>
    <sec id="sec008">
      <title>Simulation studies</title>
      <p>We evaluated AC-PCoA in three simulation settings.</p>
      <sec id="sec009">
        <title>Setting 1</title>
        <p>We simulated biological samples of different types generated from independent labs. For samples from lab <italic toggle="yes">i</italic>, we assumed that the data matrix was generated from <italic toggle="yes">X</italic><sub><italic toggle="yes">i</italic></sub> = <italic toggle="yes">F</italic>(Ω + <italic toggle="yes">α</italic>Γ<sup>(<italic toggle="yes">i</italic>)</sup> + <italic toggle="yes">ϵ</italic><sup>(<italic toggle="yes">i</italic>)</sup>), where Ω is the low rank component shared among labs, Γ<sup>(<italic toggle="yes">i</italic>)</sup> is the lab-specific component, <italic toggle="yes">α</italic> represents the strength of confounding variation, and <italic toggle="yes">ϵ</italic><sup>(<italic toggle="yes">i</italic>)</sup> is Gaussian noise. The lab-specific variation is modeled as <inline-formula id="pcbi.1010184.e051"><alternatives><graphic xlink:href="pcbi.1010184.e051.jpg" id="pcbi.1010184.e051g" position="anchor"/><mml:math id="M51" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>Γ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mo>Λ</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mo>Λ</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. In <inline-formula id="pcbi.1010184.e052"><alternatives><graphic xlink:href="pcbi.1010184.e052.jpg" id="pcbi.1010184.e052g" position="anchor"/><mml:math id="M52" display="inline" overflow="scroll"><mml:msubsup><mml:mo>Λ</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, the lab’s effect is the same in all samples within one lab. In <inline-formula id="pcbi.1010184.e053"><alternatives><graphic xlink:href="pcbi.1010184.e053.jpg" id="pcbi.1010184.e053g" position="anchor"/><mml:math id="M53" display="inline" overflow="scroll"><mml:msubsup><mml:mo>Λ</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, the lab’s effect is different in that only a subset of samples is affected, allowing for more complicated confounding effects. By stacking the rows of <italic toggle="yes">X</italic><sub><italic toggle="yes">i</italic></sub>, we formed a matrix <italic toggle="yes">X</italic> representing the data from all labs.</p>
        <p>Specifically, samples of 3 different types were generated from 5 independent labs. Each lab contains <italic toggle="yes">n</italic> = 9 samples, among which 3 samples belong to the same type. The length of variables in each sample is <italic toggle="yes">p</italic> = 400. <italic toggle="yes">F</italic>(⋅) is a nonlinear element-wise function with <inline-formula id="pcbi.1010184.e054"><alternatives><graphic xlink:href="pcbi.1010184.e054.jpg" id="pcbi.1010184.e054g" position="anchor"/><mml:math id="M54" display="inline" overflow="scroll"><mml:mrow><mml:mi>F</mml:mi><mml:mo>(</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>(</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. For visualization, we assumed that the shared component Ω = <italic toggle="yes">EH</italic> has rank 2. <italic toggle="yes">E</italic> = (<italic toggle="yes">e</italic><sub>1</sub>, <italic toggle="yes">e</italic><sub>2</sub>) is an <italic toggle="yes">n</italic> × 2 matrix, representing the latent structure of the shared variation. We further assumed that samples of the same type have the same low rank representation. That is, 3 distinct rows comprise <italic toggle="yes">E</italic>, corresponding to samples of 3 different types. Each entry is generated from Uniform[−3, 3]. The rows of <italic toggle="yes">E</italic> corresponding to samples of the same type have the same values, <italic toggle="yes">H</italic> is a 2 × <italic toggle="yes">p</italic> matrix, and the rows in <italic toggle="yes">H</italic> are generated from <inline-formula id="pcbi.1010184.e055"><alternatives><graphic xlink:href="pcbi.1010184.e055.jpg" id="pcbi.1010184.e055g" position="anchor"/><mml:math id="M55" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. For the lab-specific component <inline-formula id="pcbi.1010184.e056"><alternatives><graphic xlink:href="pcbi.1010184.e056.jpg" id="pcbi.1010184.e056g" position="anchor"/><mml:math id="M56" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>Γ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mo>Λ</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mo>Λ</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, we set <inline-formula id="pcbi.1010184.e057"><alternatives><graphic xlink:href="pcbi.1010184.e057.jpg" id="pcbi.1010184.e057g" position="anchor"/><mml:math id="M57" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>Λ</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1010184.e058"><alternatives><graphic xlink:href="pcbi.1010184.e058.jpg" id="pcbi.1010184.e058g" position="anchor"/><mml:math id="M58" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>Λ</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Here, <italic toggle="yes">B</italic><sub><italic toggle="yes">i</italic></sub> is an <italic toggle="yes">n</italic> × 1 matrix, wherein three random entries are generated from Uniform[0, 2], and the other entries are set to 0. Moreover, <italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub> and <italic toggle="yes">s</italic><sub><italic toggle="yes">i</italic></sub> are 1 × <italic toggle="yes">p</italic> matrices generated from <inline-formula id="pcbi.1010184.e059"><alternatives><graphic xlink:href="pcbi.1010184.e059.jpg" id="pcbi.1010184.e059g" position="anchor"/><mml:math id="M59" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, and <italic toggle="yes">α</italic> is set to be 2.5. Each row of <italic toggle="yes">ϵ</italic><sup>(<italic toggle="yes">i</italic>)</sup> is generated from <inline-formula id="pcbi.1010184.e060"><alternatives><graphic xlink:href="pcbi.1010184.e060.jpg" id="pcbi.1010184.e060g" position="anchor"/><mml:math id="M60" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>25</mml:mn><mml:msub><mml:mi>I</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.</p>
        <p>To pool samples from multiple labs together, we performed AC-PCoA using <xref rid="pcbi.1010184.e014" ref-type="disp-formula">Eq (2)</xref> to remove lab-specific component Γ<sup>(<italic toggle="yes">i</italic>)</sup> and capture the shared component Ω. Confounding factor matrix <italic toggle="yes">Y</italic> in <xref rid="pcbi.1010184.e014" ref-type="disp-formula">Eq (2)</xref> is defined to be a matrix of <italic toggle="yes">N</italic> × 10, wherein each column has two groups of non-zero entries, <inline-formula id="pcbi.1010184.e061"><alternatives><graphic xlink:href="pcbi.1010184.e061.jpg" id="pcbi.1010184.e061g" position="anchor"/><mml:math id="M61" display="inline" overflow="scroll"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:math></alternatives></inline-formula> corresponding to the samples from lab <italic toggle="yes">i</italic> and <inline-formula id="pcbi.1010184.e062"><alternatives><graphic xlink:href="pcbi.1010184.e062.jpg" id="pcbi.1010184.e062g" position="anchor"/><mml:math id="M62" display="inline" overflow="scroll"><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> corresponding to those from lab <italic toggle="yes">j</italic>. Hence, the optimization problem (<xref rid="pcbi.1010184.e014" ref-type="disp-formula">2</xref>) becomes:
<disp-formula id="pcbi.1010184.e063"><alternatives><graphic xlink:href="pcbi.1010184.e063.jpg" id="pcbi.1010184.e063g" position="anchor"/><mml:math id="M63" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mtext>max</mml:mtext><mml:mi>V</mml:mi></mml:munder><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mtext>trace</mml:mtext><mml:mo>{</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>⊤</mml:mi></mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>V</mml:mi><mml:mo>-</mml:mo><mml:mo>λ</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>4</mml:mn></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>5</mml:mn></mml:munderover><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:mo>[</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo><mml:mi>V</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mo>∥</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>≠</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <inline-formula id="pcbi.1010184.e064"><alternatives><graphic xlink:href="pcbi.1010184.e064.jpg" id="pcbi.1010184.e064g" position="anchor"/><mml:math id="M64" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mi>⊤</mml:mi></mml:msup><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p>
        <p>The results of one representative run and 100 runs are shown in <xref rid="pcbi.1010184.g001" ref-type="fig">Fig 1A</xref>. Note that the nonlinear function in this setting is a monotonically increasing function. We selected Spearman distance (sp) as the distance measure in AC-PCoA because Spearman distance only takes the order of data into consideration. The results of visualization, MANOVA, and NMI all show that AC-PCoA(sp) has sufficient flexibility to manage nonlinear structures.</p>
        <fig position="float" id="pcbi.1010184.g001">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1010184.g001</object-id>
          <label>Fig 1</label>
          <caption>
            <title>Results of simulation data.</title>
            <p>A: Simulation setting 1. The first line shows the true pattern and two-dimensional representations of samples from PCA, AC-PCA, PCoA(sp), AC-PCoA(sp) and aPCoA for one representative run. Samples are colored according to 3 types. The second line shows box plots of MANOVA <italic toggle="yes">F</italic>-statistic and NMI of <italic toggle="yes">k</italic>-means clustering on two-dimensional representations for 100 runs. B: Simulation setting 2. The first line shows the true pattern and two-dimensional sample representations from PCA, AC-PCA, PCoA(man), AC-PCoA(man) and aPCoA for one representative run. Samples are colored according to 10 types. The second line shows box plots of MANOVA <italic toggle="yes">F</italic>-statistic and NMI of <italic toggle="yes">k</italic>-means clustering for 100 runs. C: Simulation setting 3. The first line shows two-dimensional sample representations from PCA, AC-PCA, PCoA(bc), AC-PCoA(bc) and aPCoA for one representative run. Samples are colored according to 2 clinical groups. The second line shows box plots of MANOVA <italic toggle="yes">F</italic>-statistic and NMI of <italic toggle="yes">k</italic>-means clustering for 100 runs.</p>
          </caption>
          <graphic xlink:href="pcbi.1010184.g001" position="float"/>
        </fig>
      </sec>
      <sec id="sec010">
        <title>Setting 2</title>
        <p>Under the same framework as that for setting 1, parameters of the second simulation setting are given below. Samples of 10 different types were generated from 5 independent labs. Each lab contains <italic toggle="yes">n</italic> = 10 samples of different types. The length of variables of each sample is <italic toggle="yes">p</italic> = 400. <italic toggle="yes">E</italic> = (<italic toggle="yes">e</italic><sub>1</sub>, <italic toggle="yes">e</italic><sub>2</sub>) is an <italic toggle="yes">n</italic> × 2 matrix. Define <italic toggle="yes">μ</italic> = (1, ⋯, <italic toggle="yes">n</italic>)<sup>⊤</sup> and scale <italic toggle="yes">μ</italic> to have mean 0 and variance 1. Particularly, <italic toggle="yes">e</italic><sub>1</sub> is set to be the scaled <italic toggle="yes">μ</italic>, and <italic toggle="yes">e</italic><sub>2</sub> is assumed to be sampled from multivariate Laplace distribution Laplace(<bold>0</bold>, 0.25<italic toggle="yes">Σ</italic>), where Σ<sub><italic toggle="yes">ij</italic></sub> = exp [−(<italic toggle="yes">e</italic><sub><italic toggle="yes">i</italic>1</sub> − <italic toggle="yes">e</italic><sub><italic toggle="yes">j</italic>1</sub>)<sup>2</sup>/4]. Additionally, <italic toggle="yes">H</italic> is a 2 × <italic toggle="yes">p</italic> matrix and its rows are generated from multivariate Laplace distribution Laplace(<bold>0</bold>, <italic toggle="yes">I</italic><sub><italic toggle="yes">p</italic></sub>). The lab-specific components are set to be <inline-formula id="pcbi.1010184.e065"><alternatives><graphic xlink:href="pcbi.1010184.e065.jpg" id="pcbi.1010184.e065g" position="anchor"/><mml:math id="M65" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>Λ</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn mathvariant="bold">1</mml:mn><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1010184.e066"><alternatives><graphic xlink:href="pcbi.1010184.e066.jpg" id="pcbi.1010184.e066g" position="anchor"/><mml:math id="M66" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>Λ</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Here, each entry of <italic toggle="yes">B</italic><sub><italic toggle="yes">i</italic></sub> is generated from Uniform[0, 2], <italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub> and <italic toggle="yes">s</italic><sub><italic toggle="yes">i</italic></sub> are generated from multivariate Laplace distribution Laplace(<bold>0</bold>, <italic toggle="yes">I</italic><sub><italic toggle="yes">p</italic></sub>), <italic toggle="yes">α</italic> is set to be 2.5, and the entries in <italic toggle="yes">ϵ</italic><sup>(<italic toggle="yes">i</italic>)</sup> are generated from Laplace(0, 0.25) independently.</p>
        <p>Results of setting 2 are shown in <xref rid="pcbi.1010184.g001" ref-type="fig">Fig 1B</xref>. Because Manhattan distance (man) is commonly used to describe pairwise distances of samples generated from Laplace distribution, we implemented AC-PCoA using Manhattan distance. We set <italic toggle="yes">Y</italic> to have the following structure: each column of <italic toggle="yes">Y</italic> contains only two non-zero entries, 1 and −1, corresponding to the rows of a pair of samples of the same type, but from different labs. Thus, <xref rid="pcbi.1010184.e014" ref-type="disp-formula">Eq (2)</xref> becomes:
<disp-formula id="pcbi.1010184.e067"><alternatives><graphic xlink:href="pcbi.1010184.e067.jpg" id="pcbi.1010184.e067g" position="anchor"/><mml:math id="M67" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mtext>max</mml:mtext><mml:mi>V</mml:mi></mml:munder><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mtext>trace</mml:mtext><mml:mo>{</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>⊤</mml:mi></mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>V</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mo>λ</mml:mo><mml:mn>5</mml:mn></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>4</mml:mn></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>5</mml:mn></mml:munderover><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>V</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mo>∥</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>≠</mml:mo><mml:mi>g</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
        <p>The results show that AC-PCoA(man) gives better visualization results compared to AC-PCA since samples of the same label are clustered more tightly. AC-PCoA(man) also outperforms AC-PCA in both MANOVA and NMI.</p>
      </sec>
      <sec id="sec011">
        <title>Setting 3</title>
        <p>We used the ‘SimulateMSeq’ function in R package <monospace>GUniFrac</monospace> [<xref rid="pcbi.1010184.ref034" ref-type="bibr">34</xref>] to simulate microbiome data from Dirichlet-multinomial distribution. <monospace>GUniFrac</monospace> is a popular R-package for microbiome data. ‘SimulateMSeq’ implements a semiparametric approach and generates synthetic microbiome sequencing data to study the performance of different abundance analysis methods. We simulated samples from 2 clinical groups, each of which contains <italic toggle="yes">n</italic> = 25 samples. The number of OTUs was set to be <italic toggle="yes">p</italic> = 100. 80% of the OTUs were affected by the label of clinical groups. We further assumed that samples were collected by 2 independent labs where 80% of OTUs were affected by batch labeling.</p>
        <p>The results are shown in <xref rid="pcbi.1010184.g001" ref-type="fig">Fig 1C</xref>. Since Bray-Curtis distance (bc) is commonly applied to microbiome abundance data, we implemented AC-PCoA with Bray-Curtis distance. Confounding factors are chosen in the same manner as that in Setting 1. <xref rid="pcbi.1010184.g001" ref-type="fig">Fig 1C</xref> shows that the performance of AC-PCoA(bc) is better than that of the other methods.</p>
      </sec>
    </sec>
    <sec id="sec012">
      <title>Real data analysis</title>
      <p>In this section, we applied the proposed method to five real datasets to evaluate its performance: 1) whole genome shotgun sequencing data of white oak trees, 2) human microbiome OTU counts table from the Microbiome Quality Control Project, 3) RNA-Seq data from the Sequencing Quality Control Project, 4) single-cell RNA-Seq data of human PBMCs, and 5) human brain exon array data.</p>
      <sec id="sec013">
        <title>NGS whole genome shotgun sequencing data of white oak trees</title>
        <p>We first applied AC-PCoA to NGS whole genome shotgun (WGS) sequencing data of white oak trees. Data were downloaded from NCBI BioProject PRJNA269970, PRJNA308314, and PRJNA327502. The samples in the first two BioProjects were collected using the Illumina platform. In the third BioProject, 8 samples were collected using Illumina, and 22 using PacBio. Owing to the small size and the outlier performance, nine data points were deleted [<xref rid="pcbi.1010184.ref035" ref-type="bibr">35</xref>]. After preprocessing, we were left with a total of 131 samples from 4 batches. Samples were divided into three geographic categories according to their continental origins. Samples from the United States and Canada were categorized as North America (NA). Samples from west of 100°<italic toggle="yes">E</italic> longitude were categorized as West Europe (WE). And samples from east of 100°<italic toggle="yes">E</italic> longitude were categorized as East Europe and Asia (EEA). The origins were considered as underlying true labels of the data. To reduce the effects caused by different sequence quantities, we downsampled the data to produce random samples of reads totaling 100 Mbp for each sample. We took the unwanted variations between different BioProjects and sequencing platforms as confounding factors.</p>
        <p>Note that the original data are raw sequence reads, to which most computational methods, including PCA and AC-PCA, cannot be applied. Here, we employed six alignment-free distance measures specifically designed for next generation sequencing data, including three traditional distance measures: Manhattan distance (man), Euclidean distance (eu), and <italic toggle="yes">d</italic><sub>2</sub> distances (d2), as well as three recently developed background-adjusted measures: CVTree, <inline-formula id="pcbi.1010184.e068"><alternatives><graphic xlink:href="pcbi.1010184.e068.jpg" id="pcbi.1010184.e068g" position="anchor"/><mml:math id="M68" display="inline" overflow="scroll"><mml:msubsup><mml:mi>d</mml:mi><mml:mn>2</mml:mn><mml:mo>*</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> (d2star) and <inline-formula id="pcbi.1010184.e069"><alternatives><graphic xlink:href="pcbi.1010184.e069.jpg" id="pcbi.1010184.e069g" position="anchor"/><mml:math id="M69" display="inline" overflow="scroll"><mml:msubsup><mml:mi>d</mml:mi><mml:mn>2</mml:mn><mml:mi>s</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> (d2shepp). These distances are based on the relative frequencies of k-mers (k-grams, k-tuples, k-words). Here, k-mer length is set to be 12 and Markov order is set to be 10.</p>
        <p>Denote by <italic toggle="yes">E</italic><sub><italic toggle="yes">i</italic></sub> the set of tree sequences from batch <italic toggle="yes">i</italic>, where <italic toggle="yes">i</italic> = 1, …, 4. Suppose <italic toggle="yes">n</italic><sub><italic toggle="yes">i</italic></sub> be the number of trees from batch <italic toggle="yes">i</italic>. Let <italic toggle="yes">E</italic> represent the whole set of tree sequences from all batches. Further assume <italic toggle="yes">N</italic> = <italic toggle="yes">n</italic><sub>1</sub> + ⋯ + <italic toggle="yes">n</italic><sub>4</sub> as the total number of trees. Confounding factor matrix <italic toggle="yes">Y</italic> in <xref rid="pcbi.1010184.e014" ref-type="disp-formula">Eq (2)</xref> is defined to be a matrix of <italic toggle="yes">N</italic> × 6, wherein each column has two groups of non-zero entries, <inline-formula id="pcbi.1010184.e070"><alternatives><graphic xlink:href="pcbi.1010184.e070.jpg" id="pcbi.1010184.e070g" position="anchor"/><mml:math id="M70" display="inline" overflow="scroll"><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfrac></mml:math></alternatives></inline-formula> corresponding to the samples from batch <italic toggle="yes">i</italic> and <inline-formula id="pcbi.1010184.e071"><alternatives><graphic xlink:href="pcbi.1010184.e071.jpg" id="pcbi.1010184.e071g" position="anchor"/><mml:math id="M71" display="inline" overflow="scroll"><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> corresponding to those from batch <italic toggle="yes">j</italic>. Hence, the optimization problem (<xref rid="pcbi.1010184.e014" ref-type="disp-formula">2</xref>) becomes:
<disp-formula id="pcbi.1010184.e072"><alternatives><graphic xlink:href="pcbi.1010184.e072.jpg" id="pcbi.1010184.e072g" position="anchor"/><mml:math id="M72" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mtext>max</mml:mtext><mml:mi>V</mml:mi></mml:munder><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mtext>trace</mml:mtext><mml:mo>{</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>⊤</mml:mi></mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>V</mml:mi><mml:mo>-</mml:mo><mml:mo>λ</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>4</mml:mn></mml:munderover><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:mo>[</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo><mml:mi>V</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mo>∥</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>≠</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <inline-formula id="pcbi.1010184.e073"><alternatives><graphic xlink:href="pcbi.1010184.e073.jpg" id="pcbi.1010184.e073g" position="anchor"/><mml:math id="M73" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfrac><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mi>⊤</mml:mi></mml:msup><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p>
        <p>The results are shown in <xref rid="pcbi.1010184.g002" ref-type="fig">Fig 2</xref>. AC-PCoA demonstrates its superior ability to discriminate continental origins compared to that of either PCoA or aPCoA. Besides, <inline-formula id="pcbi.1010184.e074"><alternatives><graphic xlink:href="pcbi.1010184.e074.jpg" id="pcbi.1010184.e074g" position="anchor"/><mml:math id="M74" display="inline" overflow="scroll"><mml:msubsup><mml:mi>d</mml:mi><mml:mn>2</mml:mn><mml:mo>*</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1010184.e075"><alternatives><graphic xlink:href="pcbi.1010184.e075.jpg" id="pcbi.1010184.e075g" position="anchor"/><mml:math id="M75" display="inline" overflow="scroll"><mml:msubsup><mml:mi>d</mml:mi><mml:mn>2</mml:mn><mml:mi>s</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and CVTree perform much better than traditional Euclidean distance. In MANOVA tests on both two and three dimensions, AC-PCoA outperforms PCoA and aPCoA under all six distance measures. NMI shows that three recently developed measures can better cluster trees from the same continental origin than traditional distances. AC-PCoA improves classification accuracy over that of PCoA under five out of six distance measures in both two and three dimensions by removing confounding factors in the data. These consistent results show that AC-PCoA can both remove confounding factors and contribute to downstream analysis.</p>
        <fig position="float" id="pcbi.1010184.g002">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1010184.g002</object-id>
          <label>Fig 2</label>
          <caption>
            <title>Results of white oak tree data.</title>
            <p>A: Two-dimensional representations of samples colored by continental origins after conducting AC-PCoA, PCoA, and aPCoA using six distance measures. B: MANOVA <italic toggle="yes">F</italic>-statistic, NMI of <italic toggle="yes">k</italic>-means clustering, and classification accuracy. Continental origins are set to be the true labels. MANOVA test, <italic toggle="yes">k</italic>-means clustering, and classification were conducted on two and three principal coordinates from PCoA, AC-PCoA, and aPCoA.</p>
          </caption>
          <graphic xlink:href="pcbi.1010184.g002" position="float"/>
        </fig>
      </sec>
      <sec id="sec014">
        <title>The Microbiome Quality Control Project data</title>
        <p>The Microbiome Quality Control Project (MBQC) [<xref rid="pcbi.1010184.ref036" ref-type="bibr">36</xref>] is a collaborative effort to comprehensively evaluate methods for measuring the human microbiome. Specifically, a set of initial samples of 23 specimens was collected. A subset of specimens was replicated or triplicated into 96-sample aliquot sets that were sent to 15 biology labs to carry out extraction and/or 16S amplicon sequencing. Each biology lab received one or more blinded copies of the 96-aliquot set. The raw sequence data were re-blinded and distributed to 9 bioinformatics labs for generating OTU counts of each sample. A total of 16140 samples were distributed in the final summarized data. We discarded samples without specimen information and samples with zero levels in all OTUs. Labs that processed fewer than 1000 samples were removed. Negative control samples were also removed. Thus, 16089 samples from 13 biology labs and 8 bioinformatics labs, including 22 specimens, were involved in the following analysis. Data were further grouped into 14 subsets (denoted as ‘A’, ‘B’, ‘C’, ‘D’, ‘E’, ‘F’, ‘1’, ‘2’, ‘3’, ‘4’, ‘5’, ‘6’, ‘7’, and ‘8’). Samples in subset ‘A’, ⋯, ‘F’ were processed by their own biology lab and different bioinformatics labs. Samples in subset ‘1’, ⋯, ‘8’ were processed by their own bioinformatics lab and different biology labs. The details of subset construction are described in <xref rid="pcbi.1010184.s003" ref-type="supplementary-material">S3 Appendix</xref>. This gave rise to 14 subsets in total. The following analyses were conducted on 14 subsets, respectively. The unwanted variations among different labs act as confounding factors in following analysis.</p>
        <p>In the microbiome community, Bray-Curtis distance [<xref rid="pcbi.1010184.ref019" ref-type="bibr">19</xref>] is widely used to measure dissimilarity between samples, owing to the nature of abundance levels. In the following analysis, Bray-Curtis distance (bc) and Euclidean distance (eu) were implemented.</p>
        <p>We employed subset ‘A’ as a demonstration. Let <inline-formula id="pcbi.1010184.e076"><alternatives><graphic xlink:href="pcbi.1010184.e076.jpg" id="pcbi.1010184.e076g" position="anchor"/><mml:math id="M76" display="inline" overflow="scroll"><mml:msubsup><mml:mi>X</mml:mi><mml:mi>i</mml:mi><mml:mi mathvariant="normal">A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> represent the <italic toggle="yes">n</italic> × <italic toggle="yes">p</italic> matrix for OTU levels of <italic toggle="yes">n</italic> samples and <italic toggle="yes">p</italic> OTUs processed by biology lab A and bioinformatics lab <italic toggle="yes">i</italic>. By stacking the rows of <inline-formula id="pcbi.1010184.e077"><alternatives><graphic xlink:href="pcbi.1010184.e077.jpg" id="pcbi.1010184.e077g" position="anchor"/><mml:math id="M77" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>X</mml:mi><mml:mn>1</mml:mn><mml:mi mathvariant="normal">A</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mn>8</mml:mn><mml:mi mathvariant="normal">A</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, we formed an <italic toggle="yes">N</italic> × <italic toggle="yes">p</italic> matrix <italic toggle="yes">X</italic><sup>A</sup> wherein <italic toggle="yes">N</italic> = 8 × <italic toggle="yes">n</italic>, representing the data from subset ‘A’. <italic toggle="yes">Y</italic> in <xref rid="pcbi.1010184.e014" ref-type="disp-formula">Eq (2)</xref> was defined to have only two non-zero entries in each column, 1 and −1, corresponding to the rows of a pair of samples from the same specimen, but different labs. The optimization problem (<xref rid="pcbi.1010184.e014" ref-type="disp-formula">2</xref>) was then formulated as:
<disp-formula id="pcbi.1010184.e078"><alternatives><graphic xlink:href="pcbi.1010184.e078.jpg" id="pcbi.1010184.e078g" position="anchor"/><mml:math id="M78" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mtext>max</mml:mtext><mml:mi>V</mml:mi></mml:munder><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mtext>trace</mml:mtext><mml:mo>{</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi mathvariant="normal">A</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi mathvariant="normal">A</mml:mi></mml:msup><mml:mi>V</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mo>λ</mml:mo><mml:mn>8</mml:mn></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>7</mml:mn></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>8</mml:mn></mml:munderover><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi><mml:mi mathvariant="normal">A</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mi mathvariant="normal">A</mml:mi></mml:msubsup><mml:mo>]</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:mo>[</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi><mml:mi mathvariant="normal">A</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mi mathvariant="normal">A</mml:mi></mml:msubsup><mml:mo>]</mml:mo><mml:mi>V</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mo>∥</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>≠</mml:mo><mml:mi>g</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
        <p><xref rid="pcbi.1010184.g003" ref-type="fig">Fig 3A</xref> shows the visualization results of subset ‘A’. Here, AC-PCoA(bc) distinguishes the original specimens better than all other methods in two-dimensional plots. AC-PCoA(eu) fails to give meaningful results because Euclidean distance is unable to describe dissimilarities between microbiome abundance levels. This example demonstrates the flexibility of AC-PCoA in handling non-Euclidean distance measures in order to facilitate visualization.</p>
        <fig position="float" id="pcbi.1010184.g003">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1010184.g003</object-id>
          <label>Fig 3</label>
          <caption>
            <title>Results of MBQC data (Dataset ‘A’).</title>
            <p>A: Two-dimensional representations colored by specimens after conducting PCoA, AC-PCoA and aPCoA using Euclidean distance and Bray-Curtis distance. B: MANOVA <italic toggle="yes">F</italic>-statistic, NMI of <italic toggle="yes">k</italic>-means clustering, and classification accuracy. Specimens are set to be the true labels. MANOVA, <italic toggle="yes">k</italic>-means clustering, and classification were conducted on two and three principal coordinates from PCoA, AC-PCoA, and aPCoA.</p>
          </caption>
          <graphic xlink:href="pcbi.1010184.g003" position="float"/>
        </fig>
        <p>MANOVA, NMI and classification accuracy of subset ‘A’ are shown in <xref rid="pcbi.1010184.g003" ref-type="fig">Fig 3B</xref>. Results of all 14 subsets are shown in <xref rid="pcbi.1010184.s005" ref-type="supplementary-material">S2</xref>, <xref rid="pcbi.1010184.s006" ref-type="supplementary-material">S3</xref> and <xref rid="pcbi.1010184.s007" ref-type="supplementary-material">S4</xref> Figs. It is shown that AC-PCoA(bc) gives the highest MANOVA <italic toggle="yes">F</italic>-statistic and highest NMI in 13 out of 14 subsets in both two and three dimensions. Also, AC-PCoA(bc) gives the highest classification accuracy in 12 out of 14 subsets in both dimensions. This shows that AC-PCoA(bc) can cluster samples of the same specimen better and improve classification accuracy on two- and three-dimensional representations.</p>
        <p>Moreover, we compared AC-PCoA with another popular data normalization method, SVA [<xref rid="pcbi.1010184.ref003" ref-type="bibr">3</xref>]. We conducted PCA after SVA for comparison. The results are included in <xref rid="pcbi.1010184.s008" ref-type="supplementary-material">S5 Fig</xref>. Results of SVA are not as good as those of AC-PCoA(bc) since it doesn’t take the proper pairwise relationships into account.</p>
      </sec>
      <sec id="sec015">
        <title>The Sequencing Quality Control Project data</title>
        <p>The Sequencing Quality Control (SEQC) Project [<xref rid="pcbi.1010184.ref037" ref-type="bibr">37</xref>], also known as the third phase of the MAQC project (MAQC-III), is an FDA-led community-wide consortium aimed at assessing the technical performance of next-generation sequencing platforms at multiple sites by generating benchmark datasets with reference samples and evaluating advantages and limitations of various bioinformatics strategies in RNA and DNA analyses. Specifically, 6 distinguished reference samples (sample ID: A, B, C, D, E and F) were replicated and distributed to several independent sites for RNA-Seq library construction and profiling using three RNA-Seq platforms (Illumina HiSeq, Life Technologies SOLiD, and Roche 454). In this paper, we only consider data generated by six independent sites (NVS, COH, AGR, BGI, MAY and CNL) using Illumina HiSeq 2000. For simplicity, we only used data with the same replication number (i.e. replication number 1) in the following analysis. The variations caused by technical differences of six sites act as confounding factors.</p>
        <p>In this dataset, we considered four distance measures: Euclidean distance (eu), Bray-Curtis distance (bc), Manhattan distance (man), and Spearman distance (sp). Let <italic toggle="yes">X</italic><sub><italic toggle="yes">i</italic></sub> represent the <italic toggle="yes">n</italic><sub><italic toggle="yes">i</italic></sub> × <italic toggle="yes">p</italic> matrix for the gene expression levels of <italic toggle="yes">n</italic><sub><italic toggle="yes">i</italic></sub> samples and <italic toggle="yes">p</italic> genes processed by site <italic toggle="yes">i</italic>. The sample size <italic toggle="yes">n</italic><sub><italic toggle="yes">i</italic></sub> is different for different sites owing to the different number of lanes and sectors conducted by independent sites. By stacking the rows of <italic toggle="yes">X</italic><sub>1</sub>, ⋯, <italic toggle="yes">X</italic><sub>6</sub>, we formed an <italic toggle="yes">N</italic> × <italic toggle="yes">p</italic> matrix <italic toggle="yes">X</italic> where <italic toggle="yes">N</italic> = <italic toggle="yes">n</italic><sub>1</sub> + ⋯+ <italic toggle="yes">n</italic><sub>6</sub>. We defined <italic toggle="yes">Y</italic> to have only two groups of non-zero entries in each column, 1 and −1, corresponding to the rows of a pair of samples of the same reference sample IDs but from different sites. The optimization problem (<xref rid="pcbi.1010184.e014" ref-type="disp-formula">2</xref>) was defined as:
<disp-formula id="pcbi.1010184.e079"><alternatives><graphic xlink:href="pcbi.1010184.e079.jpg" id="pcbi.1010184.e079g" position="anchor"/><mml:math id="M79" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mtext>max</mml:mtext><mml:mi>V</mml:mi></mml:munder><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mtext>trace</mml:mtext><mml:mo>{</mml:mo><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>⊤</mml:mi></mml:msup><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>V</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mo>λ</mml:mo><mml:mn>6</mml:mn></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>5</mml:mn></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:munderover><mml:msup><mml:mi>V</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>⊤</mml:mi></mml:msup><mml:mo>[</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>j</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo><mml:mi>V</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo></mml:mrow><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mo>∥</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:msubsup><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>t</mml:mi><mml:mi>⊤</mml:mi></mml:msubsup><mml:msub><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi>t</mml:mi><mml:mo>≠</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <italic toggle="yes">X</italic><sub><italic toggle="yes">il</italic></sub> is a submatrix of <italic toggle="yes">X</italic><sub><italic toggle="yes">i</italic></sub>, containing samples of reference sample ID <italic toggle="yes">l</italic> processed by site <italic toggle="yes">i</italic>, and <inline-formula id="pcbi.1010184.e080"><alternatives><graphic xlink:href="pcbi.1010184.e080.jpg" id="pcbi.1010184.e080g" position="anchor"/><mml:math id="M80" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mn mathvariant="bold">1</mml:mn><mml:mi>⊤</mml:mi></mml:msup><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p>
        <p><xref rid="pcbi.1010184.g004" ref-type="fig">Fig 4A</xref> shows that AC-PCoA can tightly cluster samples with the same reference sample ID compared to PCoA when the same distance measure is considered. aPCoA cannot improve clustering over PCoA. Euclidean distance is able to distinguish reference sample ID E and F, while the other three distances can separate reference sample ID A, B, C and D.</p>
        <fig position="float" id="pcbi.1010184.g004">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1010184.g004</object-id>
          <label>Fig 4</label>
          <caption>
            <title>Results of SEQC data.</title>
            <p>A: Two-dimensional plots colored by reference sample IDs after conducting PCoA, AC-PCoA and aPCoA, using four distance measures. B: MANOVA <italic toggle="yes">F</italic>-statistic, NMI of <italic toggle="yes">k</italic>-means clustering, and classification accuracy. Reference samples IDs are set to be the true label. MANOVA test, <italic toggle="yes">k</italic>-means clustering, and classification were conducted on two and three principal coordinates from PCoA, AC-PCoA, and aPCoA.</p>
          </caption>
          <graphic xlink:href="pcbi.1010184.g004" position="float"/>
        </fig>
        <p>In <xref rid="pcbi.1010184.g004" ref-type="fig">Fig 4B</xref>, AC-PCoA gives higher MANOVA <italic toggle="yes">F</italic>-statistic than PCoA and aPCoA in all four distance measures in both two and three dimensions. AC-PCoA(bc) and AC-PCoA(man) show the best performance in clustering. These results demonstrate that incorporating non-Euclidean distances in confounding factor adjustment via AC-PCoA is necessary.</p>
      </sec>
      <sec id="sec016">
        <title>Single-cell RNA-Seq data</title>
        <p>Single-cell experiments are often conducted with notable differences in capturing time, equipment and even technology platforms, which may introduce batch effects to the data. Up to now, it has remained challenging to characterize cell types across a wide variety of biological and technical conditions. We followed Korsunsky <italic toggle="yes">et al</italic>. [<xref rid="pcbi.1010184.ref038" ref-type="bibr">38</xref>] and gathered three datasets of human peripheral blood mononuclear cells (PBMCs), each of which assayed on the Chromium 10X platform but prepared with different protocols: 3’-end v1 (3pV1), 3’-end v2 (3pV2) and 5’-end (5p) chemistries. After pooling all the cells together, 6 cell types were identified in total. Since the number of cells of type “mk” was much smaller than that of the other 5 cell types, we discarded cell type “mk” and saved the other cell types (“bcells”, “dc”, “mono”, “nk” and “tcells”) for later analysis. To simplify computation, we then randomly selected at most sixty cells from each cell type and each protocol, and constructed a subset consisting of 849 cells. Afterwards, we normalized the data following [<xref rid="pcbi.1010184.ref038" ref-type="bibr">38</xref>] and performed the analysis on the normalized expression matrix.</p>
        <p>We considered Euclidean distance (eu), Bray-Curtis distance (bc), Manhattan distance (man), and Spearman distance (sp). Let <italic toggle="yes">X</italic><sub><italic toggle="yes">i</italic></sub> represent the <italic toggle="yes">n</italic><sub><italic toggle="yes">i</italic></sub> × <italic toggle="yes">p</italic> matrix for the normalized expression level of <italic toggle="yes">n</italic><sub><italic toggle="yes">i</italic></sub> cells and <italic toggle="yes">p</italic> genes processed by the <italic toggle="yes">i</italic>-th protocol. We stacked the rows of <italic toggle="yes">X</italic><sub>1</sub>, <italic toggle="yes">X</italic><sub>2</sub>, <italic toggle="yes">X</italic><sub>3</sub>, and formed an <italic toggle="yes">N</italic> × <italic toggle="yes">p</italic> matrix <italic toggle="yes">X</italic> of the pooled data wherein <italic toggle="yes">N</italic> = <italic toggle="yes">n</italic><sub>1</sub> + <italic toggle="yes">n</italic><sub>2</sub> + <italic toggle="yes">n</italic><sub>3</sub>. The definition of <italic toggle="yes">Y</italic> and the optimization formula (<xref rid="pcbi.1010184.e014" ref-type="disp-formula">2</xref>) was set to be the same as those given in the white oak trees NGS whole genome shotgun sequencing data analysis.</p>
        <p>The results are shown in <xref rid="pcbi.1010184.g005" ref-type="fig">Fig 5</xref>. AC-PCoA, including AC-PCA, can better separate different cell types than PCoA and aPCoA in visualization. Bray-Curtis distance and Spearman distance give better results than Euclidean distance in MANOVA <italic toggle="yes">F</italic>-statistic (nPC = 2 and nPC = 3) and NMI (nPC = 2).</p>
        <fig position="float" id="pcbi.1010184.g005">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1010184.g005</object-id>
          <label>Fig 5</label>
          <caption>
            <title>Results of scRNA-Seq data.</title>
            <p>A: Two-dimensional representations of samples colored by cell types after conducting PCoA, AC-PCoA and aPCoA using four distance measures. B: MANOVA <italic toggle="yes">F</italic>-statistic, NMI of <italic toggle="yes">k</italic>-means clustering, and classification accuracy. Cell types are set to be the true labels. MANOVA, <italic toggle="yes">k</italic>-means clustering, and classification were conducted on two and three principal coordinates from PCoA, AC-PCoA, and aPCoA.</p>
          </caption>
          <graphic xlink:href="pcbi.1010184.g005" position="float"/>
        </fig>
        <p>Moreover, since tSNE is often employed to perform visualization in single-cell RNA-Seq data analysis, we conducted AC-PCoA to reduce the dimension to 50, and then visualized samples in two-dimensional space using tSNE. We compared the results of tSNE after conducting AC-PCoA to the result of tSNE after conducting PCA and PCoA. The results are plotted in <xref rid="pcbi.1010184.s009" ref-type="supplementary-material">S6 Fig</xref>. It shows that AC-PCoA, including AC-PCA, helps to cluster together each cell type.</p>
      </sec>
      <sec id="sec017">
        <title>Human brain exon array data</title>
        <p>Lastly, we implemented AC-PCoA on a subset of human brain exon array data [<xref rid="pcbi.1010184.ref039" ref-type="bibr">39</xref>] reported by Lin <italic toggle="yes">et al</italic>. [<xref rid="pcbi.1010184.ref015" ref-type="bibr">15</xref>]. This dataset includes the transcriptomes of 16 brain regions across developmental epochs. Samples from 10 brain regions in the neocortex were used in the analysis. Lin <italic toggle="yes">et al</italic>. reorganized the data and defined nine time windows by grouping samples from every six donors. By conducting PCA on each donor, they found that the gross morphological structure of the hemisphere was largely recapitulated. This pattern disappeared when PCA was applied to multiple donors in one window simultaneously. When applying AC-PCA, the anatomical structure of neocortex could be recovered since the confounding effects from individual donor were adjusted.</p>
        <p>We considered four distance measures: Euclidean distance (eu), Spearman distance (sp), Kendall’s tau (tauD), and Manhattan distance (man). We also performed PCA and AC-PCA on these data to verify the equivalence between PCA and PCoA(eu), and between AC-PCA and AC-PCoA(eu). For one window, let <italic toggle="yes">X</italic><sub><italic toggle="yes">i</italic></sub> represent the <italic toggle="yes">n</italic> × <italic toggle="yes">p</italic> matrix for the gene expression levels of donor <italic toggle="yes">i</italic>, where <italic toggle="yes">n</italic> is the number of brain regions and <italic toggle="yes">p</italic> is the number of genes. By stacking the rows of <italic toggle="yes">X</italic><sub>1</sub>, ⋯, <italic toggle="yes">X</italic><sub><italic toggle="yes">m</italic></sub>, where <italic toggle="yes">m</italic> is the number of donors, we obtained the <italic toggle="yes">N</italic> × <italic toggle="yes">p</italic> data matrix <italic toggle="yes">X</italic>, wherein <italic toggle="yes">N</italic> = <italic toggle="yes">n</italic> × <italic toggle="yes">m</italic>. Confounder matrix <italic toggle="yes">Y</italic> was defined to have the same structure as that in the Microbiome Quality Control Project data analysis.</p>
        <p>The results of window 5 are given in <xref rid="pcbi.1010184.g006" ref-type="fig">Fig 6</xref> as a demonstrating example. <xref rid="pcbi.1010184.g006" ref-type="fig">Fig 6A</xref> shows that the two-dimensional plots of PCA and PCoA(eu) are the same, and the two-dimensional plots of AC-PCA and AC-PCoA(eu) are also the same, thus confirming the equivalence of two-dimensional representations given by AC-PCA and AC-PCoA(eu) in this dataset. In addition to Euclidean distance, Spearman distance, Kendall’s tau distance and Manhattan distance could remove confounding effect and recover the anatomical structure as well. Moreover, aPCoA could not remove the confounding factors in this dataset.</p>
        <fig position="float" id="pcbi.1010184.g006">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1010184.g006</object-id>
          <label>Fig 6</label>
          <caption>
            <title>Results of human brain exon array data (window 5).</title>
            <p>A: Two-dimensional plot colored by brain regions after conducting PCA, AC-PCA, PCoA, AC-PCoA and aPCoA, using four distance measures. B: MANOVA <italic toggle="yes">F</italic>-statistic, NMI of <italic toggle="yes">k</italic>-means clustering, and classification accuracy. Brain regions are set to be the true labels. MANOVA, <italic toggle="yes">k</italic>-means clustering, and classification were conducted on two and three principal coordinates from PCoA, AC-PCoA, and aPCoA.</p>
          </caption>
          <graphic xlink:href="pcbi.1010184.g006" position="float"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec018">
    <title>Discussion</title>
    <p>Confounding factors have a significant effect on scientific findings in data-driven research, especially in today’s large-scale data analysis. In this work, we have developed a method called AC-PCoA to simultaneously perform confounding factors adjustment and dimension reduction based on distance measures. AC-PCoA is effective, even when non-Euclidean distance measures are applied to describe pairwise relationships, which is a common case in biological data analysis. AC-PCoA is able to borrow strength from pairwise distances and make use of the underlying topological structures of the samples. Thus, it shows promising results in various kinds of data analysis, especially for data using non-Euclidean distance measures. Practically and significantly, we have showed the good performance of AC-PCoA on the next generation sequencing data, the microbiome taxonomic data, the RNA-Seq data, and the exon array data.</p>
    <p>As an exploratory tool, AC-PCoA can be applied in combination with other data analysis methods, such as classification. As shown in the experiments, it can help improve classification accuracy by adjusting for confounding factors. Furthermore, AC-PCoA can be used as a preprocessing step before applying other machine learning methods, such as regression and clustering. Since more and more biological data are used for diagnostic, predictive and classification applications nowadays, it is of paramount importance that AC-PCoA as well as its idea can be further generalized to such scenarios, and even causality analytics [<xref rid="pcbi.1010184.ref040" ref-type="bibr">40</xref>, <xref rid="pcbi.1010184.ref041" ref-type="bibr">41</xref>].</p>
    <p>Like most confounding factor adjustment methods, confounding factors are user-defined. In our method, the choices of <italic toggle="yes">Y</italic> and <italic toggle="yes">K</italic> play a crucial role in the whole process. To give proper definitions of <italic toggle="yes">Y</italic> and <italic toggle="yes">K</italic> is not always straightforward. Sometimes researchers have no information at all about the confounding factors. Thus, in our future studies, we will focus much on performing confounding factor adjustment using distance measures with unknown confounding factors.</p>
    <p>The R-package with application examples is available at <ext-link xlink:href="https://github.com/YuWang28/acPCoA" ext-link-type="uri">https://github.com/YuWang28/acPCoA</ext-link>.</p>
  </sec>
  <sec id="sec019" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pcbi.1010184.s001" position="float" content-type="local-data">
      <label>S1 Appendix</label>
      <caption>
        <title>AC-PCoA classification results when nPC is large.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010184.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010184.s002" position="float" content-type="local-data">
      <label>S2 Appendix</label>
      <caption>
        <title>Definitions of distances.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010184.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010184.s003" position="float" content-type="local-data">
      <label>S3 Appendix</label>
      <caption>
        <title>Preprocessing steps for MBQC data.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010184.s003.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010184.s004" position="float" content-type="local-data">
      <label>S1 Fig</label>
      <caption>
        <title>Classification results of PCoA and AC-PCoA when nPC is large, compared with benchmark.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010184.s004.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010184.s005" position="float" content-type="local-data">
      <label>S2 Fig</label>
      <caption>
        <title>MANOVA <italic toggle="yes">F</italic>-statistic of MBQC data (all subsets).</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010184.s005.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010184.s006" position="float" content-type="local-data">
      <label>S3 Fig</label>
      <caption>
        <title><italic toggle="yes">k</italic>-means clustering NMI of MBQC data (all subsets).</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010184.s006.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010184.s007" position="float" content-type="local-data">
      <label>S4 Fig</label>
      <caption>
        <title>Classification accuracy of MBQC data (all subsets).</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010184.s007.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010184.s008" position="float" content-type="local-data">
      <label>S5 Fig</label>
      <caption>
        <title>SVA results of MBQC data (all subsets).</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010184.s008.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010184.s009" position="float" content-type="local-data">
      <label>S6 Fig</label>
      <caption>
        <title>tSNE visualization of scRNA-Seq data after PCoA and AC-PCoA.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010184.s009.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>We thank Mr. David Martin for his professionally editing the final version of this work.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1010184.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Johnson</surname><given-names>WE</given-names></name>, <name><surname>Li</surname><given-names>C</given-names></name>, <name><surname>Rabinovic</surname><given-names>A</given-names></name>. <article-title>Adjusting batch effects in microarray expression data using empirical Bayes methods</article-title>. <source>Biostatistics</source>. <year>2007</year>;<volume>8</volume>(<issue>1</issue>):<fpage>118</fpage>–<lpage>127</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/biostatistics/kxj037</pub-id><?supplied-pmid 16632515?><pub-id pub-id-type="pmid">16632515</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Leek</surname><given-names>JT</given-names></name>, <name><surname>Johnson</surname><given-names>WE</given-names></name>, <name><surname>Parker</surname><given-names>HS</given-names></name>, <name><surname>Jaffe</surname><given-names>AE</given-names></name>, <name><surname>Storey</surname><given-names>JD</given-names></name>. <article-title>The sva package for removing batch effects and other unwanted variation in high-throughput experiments</article-title>. <source>Bioinformatics</source>. <year>2012</year>;<volume>28</volume>(<issue>6</issue>):<fpage>882</fpage>–<lpage>883</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/bts034</pub-id><?supplied-pmid 22257669?><pub-id pub-id-type="pmid">22257669</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Leek</surname><given-names>JT</given-names></name>, <name><surname>Storey</surname><given-names>JD</given-names></name>. <article-title>Capturing heterogeneity in gene expression studies by surrogate variable analysis</article-title>. <source>PLoS Genet</source>. <year>2007</year>;<volume>3</volume>(<issue>9</issue>):<fpage>1724</fpage>–<lpage>1735</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pgen.0030161</pub-id><?supplied-pmid 17907809?><pub-id pub-id-type="pmid">17907809</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Leek</surname><given-names>JT</given-names></name>, <name><surname>Storey</surname><given-names>JD</given-names></name>. <article-title>A general framework for multiple testing dependence</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2008</year>;<volume>105</volume>(<issue>48</issue>):<fpage>18718</fpage>–<lpage>18723</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.0808709105</pub-id><?supplied-pmid 19033188?><pub-id pub-id-type="pmid">19033188</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref005">
      <label>5</label>
      <mixed-citation publication-type="book"><name><surname>Gagnon-Bartsch</surname><given-names>JA</given-names></name>, <name><surname>Jacob</surname><given-names>L</given-names></name>, <name><surname>Speed</surname><given-names>TP</given-names></name>. <source>Removing unwanted variation from high dimensional data with negative controls</source>. <publisher-loc>Berkeley</publisher-loc>: <publisher-name>Tech Reports from Dep Stat Univ California</publisher-name>. <year>2013</year>; p. <fpage>1</fpage>–<lpage>112</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Gagnon-Bartsch</surname><given-names>JA</given-names></name>, <name><surname>Speed</surname><given-names>TP</given-names></name>. <article-title>Using control genes to correct for unwanted variation in microarray data</article-title>. <source>Biostatistics</source>. <year>2012</year>;<volume>13</volume>(<issue>3</issue>):<fpage>539</fpage>–<lpage>552</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/biostatistics/kxr034</pub-id><?supplied-pmid 22101192?><pub-id pub-id-type="pmid">22101192</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Jacob</surname><given-names>L</given-names></name>, <name><surname>Gagnon-Bartsch</surname><given-names>JA</given-names></name>, <name><surname>Speed</surname><given-names>TP</given-names></name>. <article-title>Correcting gene expression data when neither the unwanted variation nor the factor of interest are observed</article-title>. <source>Biostatistics</source>. <year>2016</year>;<volume>17</volume>(<issue>1</issue>):<fpage>16</fpage>–<lpage>28</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/biostatistics/kxv026</pub-id><?supplied-pmid 26286812?><pub-id pub-id-type="pmid">26286812</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Molania</surname><given-names>R</given-names></name>, <name><surname>Gagnon-Bartsch</surname><given-names>JA</given-names></name>, <name><surname>Dobrovic</surname><given-names>A</given-names></name>, <name><surname>Speed</surname><given-names>TP</given-names></name>. <article-title>A new normalization for Nanostring nCounter gene expression data</article-title>. <source>Nucleic Acids Res</source>. <year>2019</year>;<volume>47</volume>(<issue>12</issue>):<fpage>6073</fpage>–<lpage>6083</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkz433</pub-id><?supplied-pmid 31114909?><pub-id pub-id-type="pmid">31114909</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>M</given-names></name>, <name><surname>Zhou</surname><given-names>X</given-names></name>. <article-title>Controlling for confounding effects in single cell RNA sequencing studies using both control and target genes</article-title>. <source>Scientific Reports</source>. <year>2017</year>;<volume>7</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>14</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-017-13665-w</pub-id><?supplied-pmid 29051597?><pub-id pub-id-type="pmid">28127051</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Fan</surname><given-names>Y</given-names></name>, <name><surname>Zhu</surname><given-names>H</given-names></name>, <name><surname>Song</surname><given-names>Y</given-names></name>, <name><surname>Peng</surname><given-names>Q</given-names></name>, <name><surname>Zhou</surname><given-names>X</given-names></name>. <article-title>Efficient and effective control of confounding in eQTL mapping studies through joint differential expression and Mendelian randomization analyses</article-title>. <source>Bioinformatics</source>. <year>2021</year>;<volume>37</volume>(<issue>3</issue>):<fpage>296</fpage>–<lpage>302</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btaa715</pub-id><?supplied-pmid 32790868?><pub-id pub-id-type="pmid">32790868</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Maksimovic</surname><given-names>J</given-names></name>, <name><surname>Gagnon-Bartsch</surname><given-names>JA</given-names></name>, <name><surname>Speed</surname><given-names>TP</given-names></name>, <name><surname>Oshlack</surname><given-names>A</given-names></name>. <article-title>Removing unwanted variation in a differential methylation analysis of Illumina HumanMethylation450 array data</article-title>. <source>Nucleic Acids Research</source>. <year>2015</year>;<volume>43</volume>(<issue>16</issue>):<fpage>e106</fpage>–<lpage>e106</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkv526</pub-id><?supplied-pmid 25990733?><pub-id pub-id-type="pmid">25990733</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Risso</surname><given-names>D</given-names></name>, <name><surname>Ngai</surname><given-names>J</given-names></name>, <name><surname>Speed</surname><given-names>TP</given-names></name>, <name><surname>Dudoit</surname><given-names>S</given-names></name>. <article-title>Normalization of RNA-seq data using factor analysis of control genes or samples</article-title>. <source>Nat Biotechnol</source>. <year>2014</year>;<volume>32</volume>(<issue>9</issue>):<fpage>896</fpage>–<lpage>902</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nbt.2931</pub-id><?supplied-pmid 25150836?><pub-id pub-id-type="pmid">25150836</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Schölkopf</surname><given-names>B</given-names></name>, <name><surname>Hogg</surname><given-names>DW</given-names></name>, <name><surname>Wang</surname><given-names>D</given-names></name>, <name><surname>Foreman-Mackey</surname><given-names>D</given-names></name>, <name><surname>Janzing</surname><given-names>D</given-names></name>, <name><surname>Simon-Gabriel</surname><given-names>CJ</given-names></name>, <etal>et al</etal>. <article-title>Modeling confounding by half-sibling regression</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2016</year>;<volume>113</volume>(<issue>27</issue>):<fpage>7391</fpage>–<lpage>7398</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.1511656113</pub-id><?supplied-pmid 27382154?><pub-id pub-id-type="pmid">27382154</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Yang</surname><given-names>C</given-names></name>, <name><surname>Wang</surname><given-names>L</given-names></name>, <name><surname>Zhang</surname><given-names>S</given-names></name>, <name><surname>Zhao</surname><given-names>H</given-names></name>. <article-title>Accounting for non-genetic factors by low-rank representation and sparse regression for eQTL mapping</article-title>. <source>Bioinformatics</source>. <year>2013</year>;<volume>29</volume>(<issue>8</issue>):<fpage>1026</fpage>–<lpage>1034</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btt075</pub-id><?supplied-pmid 23419377?><pub-id pub-id-type="pmid">23419377</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>Z</given-names></name>, <name><surname>Yang</surname><given-names>C</given-names></name>, <name><surname>Zhu</surname><given-names>Y</given-names></name>, <name><surname>Duchi</surname><given-names>J</given-names></name>, <name><surname>Fu</surname><given-names>Y</given-names></name>, <name><surname>Wang</surname><given-names>Y</given-names></name>, <etal>et al</etal>. <article-title>Simultaneous dimension reduction and adjustment for confounding variation</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2016</year>;<volume>113</volume>(<issue>51</issue>):<fpage>14662</fpage>–<lpage>14667</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.1617317113</pub-id><?supplied-pmid 27930330?><pub-id pub-id-type="pmid">27930330</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Qi</surname><given-names>J</given-names></name>, <name><surname>Luo</surname><given-names>H</given-names></name>, <name><surname>Hao</surname><given-names>B</given-names></name>. <article-title>CVTree: a phylogenetic tree reconstruction tool based on whole genomes</article-title>. <source>Nucleic Acids Res</source>. <year>2004</year>;<volume>32</volume>:<fpage>W45</fpage>–<lpage>47</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkh362</pub-id><?supplied-pmid 15215347?><pub-id pub-id-type="pmid">15215347</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Song</surname><given-names>K</given-names></name>, <name><surname>Ren</surname><given-names>J</given-names></name>, <name><surname>Zhai</surname><given-names>Z</given-names></name>, <name><surname>Liu</surname><given-names>X</given-names></name>, <name><surname>Deng</surname><given-names>M</given-names></name>, <name><surname>Sun</surname><given-names>F</given-names></name>. <article-title>Alignment-free sequence comparison based on next-generation sequencing reads</article-title>. <source>J Comput Biol</source>. <year>2013</year>;<volume>20</volume>(<issue>2</issue>):<fpage>64</fpage>–<lpage>79</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1089/cmb.2012.0228</pub-id><?supplied-pmid 23383994?><pub-id pub-id-type="pmid">23383994</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref018">
      <label>18</label>
      <mixed-citation publication-type="book"><name><surname>Torney</surname><given-names>DC</given-names></name>, <name><surname>Burks</surname><given-names>C</given-names></name>, <name><surname>Davison</surname><given-names>D</given-names></name>, <name><surname>Sirotkin</surname><given-names>KM</given-names></name>. <part-title>Computation of d 2: A measure of sequence dissimilarity</part-title>. In: <source>Computers and DNA</source>. <publisher-name>Routledge</publisher-name>; <year>2018</year>. p. <fpage>109</fpage>–<lpage>125</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Bray</surname><given-names>JR</given-names></name>, <name><surname>Curtis</surname><given-names>JT</given-names></name>. <article-title>An ordination of the upland forest communities of southern Wisconsin</article-title>. <source>Ecological Monographs</source>. <year>1957</year>;<volume>27</volume>(<issue>4</issue>):<fpage>325</fpage>–<lpage>349</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2307/1942268</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref020">
      <label>20</label>
      <mixed-citation publication-type="book"><name><surname>Jajuga</surname><given-names>K</given-names></name>, <name><surname>Walesiak</surname><given-names>M</given-names></name>, <name><surname>Bak</surname><given-names>A</given-names></name>. <part-title>On the general distance measure</part-title>. In: <source>Exploratory Data Analysis in Empirical Research</source>. <publisher-name>Springer</publisher-name>; <year>2003</year>. p. <fpage>104</fpage>–<lpage>109</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref021">
      <label>21</label>
      <mixed-citation publication-type="other">Boriah S, Chandola V, Kumar V. Similarity measures for categorical data: A comparative evaluation. In: Proceedings of the 2008 SIAM international conference on data mining. SIAM; 2008. p. 243–254.</mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref022">
      <label>22</label>
      <mixed-citation publication-type="other">Bojorque R, Hurtado R, Inga A. A comparative analysis of similarity metrics on sparse data for clustering in recommender systems. In: International Conference on Applied Human Factors and Ergonomics. Springer; 2018. p. 291–299.</mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Patra</surname><given-names>BK</given-names></name>, <name><surname>Launonen</surname><given-names>R</given-names></name>, <name><surname>Ollikainen</surname><given-names>V</given-names></name>, <name><surname>Nandi</surname><given-names>S</given-names></name>. <article-title>A new similarity measure using Bhattacharyya coefficient for collaborative filtering in sparse data</article-title>. <source>Knowledge-Based Systems</source>. <year>2015</year>;<volume>82</volume>:<fpage>163</fpage>–<lpage>177</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.knosys.2015.03.001</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref024">
      <label>24</label>
      <mixed-citation publication-type="other">Torgerson WS. Theory and methods of scaling. 1958;.</mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Gower</surname><given-names>JC</given-names></name>. <article-title>A Q-technique for the calculation of canonical variates</article-title>. <source>Biometrika</source>. <year>1966</year>; p. <fpage>588</fpage>–<lpage>590</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2307/2333664</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Dray</surname><given-names>S</given-names></name>, <name><surname>Legendre</surname><given-names>P</given-names></name>, <name><surname>Peres-Neto</surname><given-names>PR</given-names></name>. <article-title>Spatial modelling: a comprehensive framework for principal coordinate analysis of neighbour matrices (PCNM)</article-title>. <source>Ecological Modelling</source>. <year>2006</year>;<volume>196</volume>(<issue>3-4</issue>):<fpage>483</fpage>–<lpage>493</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ecolmodel.2006.02.015</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Goodrich</surname><given-names>JK</given-names></name>, <name><surname>Waters</surname><given-names>JL</given-names></name>, <name><surname>Poole</surname><given-names>AC</given-names></name>, <name><surname>Sutter</surname><given-names>JL</given-names></name>, <name><surname>Koren</surname><given-names>O</given-names></name>, <name><surname>Blekhman</surname><given-names>R</given-names></name>, <etal>et al</etal>. <article-title>Human genetics shape the gut microbiome</article-title>. <source>Cell</source>. <year>2014</year>;<volume>159</volume>(<issue>4</issue>):<fpage>789</fpage>–<lpage>799</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.cell.2014.09.053</pub-id><?supplied-pmid 25417156?><pub-id pub-id-type="pmid">25417156</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Zuur</surname><given-names>AF</given-names></name>, <name><surname>Ieno</surname><given-names>EN</given-names></name>, <name><surname>Smith</surname><given-names>GM</given-names></name>. <article-title>Principal coordinate analysis and non-metric multidimensional scaling</article-title>. <source>Analysing Ecological Data</source>. <year>2007</year>; p. <fpage>259</fpage>–<lpage>264</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Shi</surname><given-names>Y</given-names></name>, <name><surname>Zhang</surname><given-names>L</given-names></name>, <name><surname>Do</surname><given-names>KA</given-names></name>, <name><surname>Peterson</surname><given-names>CB</given-names></name>, <name><surname>Jenq</surname><given-names>RR</given-names></name>. <article-title>aPCoA: covariate adjusted principal coordinates analysis</article-title>. <source>Bioinformatics</source>. <year>2020</year>;<volume>36</volume>(<issue>13</issue>):<fpage>4099</fpage>–<lpage>4101</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btaa276</pub-id><?supplied-pmid 32339223?><pub-id pub-id-type="pmid">32339223</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Dray</surname><given-names>S</given-names></name>, <name><surname>Josse</surname><given-names>J</given-names></name>. <article-title>Principal component analysis with missing values: a comparative survey of methods</article-title>. <source>Plant Ecology</source>. <year>2015</year>;<volume>216</volume>(<issue>5</issue>):<fpage>657</fpage>–<lpage>667</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s11258-014-0406-z</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref031">
      <label>31</label>
      <mixed-citation publication-type="other">Gower JC. Principal coordinates analysis. Wiley StatsRef: Statistics Reference Online. 2014;.</mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref032">
      <label>32</label>
      <mixed-citation publication-type="book"><name><surname>Schölkopf</surname><given-names>B</given-names></name>, <name><surname>Smola</surname><given-names>AJ</given-names></name>, <name><surname>Bach</surname><given-names>F</given-names></name>, <etal>et al</etal>. <source>Learning with kernels: support vector machines, regularization, optimization, and beyond</source>. <publisher-name>MIT press</publisher-name>; <year>2002</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Estévez</surname><given-names>PA</given-names></name>, <name><surname>Tesmer</surname><given-names>M</given-names></name>, <name><surname>Perez</surname><given-names>CA</given-names></name>, <name><surname>Zurada</surname><given-names>JM</given-names></name>. <article-title>Normalized mutual information feature selection</article-title>. <source>IEEE Trans Neural Netw</source>. <year>2009</year>;<volume>20</volume>(<issue>2</issue>):<fpage>189</fpage>–<lpage>201</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TNN.2008.2005601</pub-id><?supplied-pmid 19150792?><pub-id pub-id-type="pmid">19150792</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref034">
      <label>34</label>
      <mixed-citation publication-type="other">Chen J, Zhang X, Zhou H. GUniFrac: Generalized UniFrac Distances, Distance-Based Multivariate Methods and Feature-Based Univariate Methods for Microbiome Data Analysis; 2021. Available from: <ext-link xlink:href="https://CRAN.R-project.org/package=GUniFrac" ext-link-type="uri">https://CRAN.R-project.org/package=GUniFrac</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Tang</surname><given-names>K</given-names></name>, <name><surname>Ren</surname><given-names>J</given-names></name>, <name><surname>Cronn</surname><given-names>R</given-names></name>, <name><surname>Erickson</surname><given-names>DL</given-names></name>, <name><surname>Milligan</surname><given-names>BG</given-names></name>, <name><surname>Parker-Forney</surname><given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Alignment-free genome comparison enables accurate geographic sourcing of white oak DNA</article-title>. <source>BMC Genomics</source>. <year>2018</year>;<volume>19</volume>(<issue>1</issue>):<fpage>896</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12864-018-5253-1</pub-id><?supplied-pmid 30526482?><pub-id pub-id-type="pmid">30526482</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Sinha</surname><given-names>R</given-names></name>, <name><surname>Abnet</surname><given-names>CC</given-names></name>, <name><surname>White</surname><given-names>O</given-names></name>, <name><surname>Knight</surname><given-names>R</given-names></name>, <name><surname>Huttenhower</surname><given-names>C</given-names></name>. <article-title>The microbiome quality control project: baseline study design and future directions</article-title>. <source>Genome Biol</source>. <year>2015</year>;<volume>16</volume>:<fpage>276</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s13059-015-0841-8</pub-id><?supplied-pmid 26653756?><pub-id pub-id-type="pmid">26653756</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Su</surname><given-names>Z</given-names></name>, <name><surname>Łabaj</surname><given-names>PP</given-names></name>, <name><surname>Li</surname><given-names>S</given-names></name>, <name><surname>Thierry-Mieg</surname><given-names>J</given-names></name>, <name><surname>Thierry-Mieg</surname><given-names>D</given-names></name>, <name><surname>Shi</surname><given-names>W</given-names></name>, <etal>et al</etal>. <article-title>A comprehensive assessment of RNA-seq accuracy, reproducibility and information content by the Sequencing Quality Control Consortium</article-title>. <source>Nat Biotechnol</source>. <year>2014</year>;<volume>32</volume>(<issue>9</issue>):<fpage>903</fpage>–<lpage>914</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nbt.2957</pub-id><pub-id pub-id-type="pmid">25150838</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref038">
      <label>38</label>
      <mixed-citation publication-type="journal"><name><surname>Korsunsky</surname><given-names>I</given-names></name>, <name><surname>Millard</surname><given-names>N</given-names></name>, <name><surname>Fan</surname><given-names>J</given-names></name>, <name><surname>Slowikowski</surname><given-names>K</given-names></name>, <name><surname>Zhang</surname><given-names>F</given-names></name>, <name><surname>Wei</surname><given-names>K</given-names></name>, <etal>et al</etal>. <article-title>Fast, sensitive and accurate integration of single-cell data with Harmony</article-title>. <source>Nat Methods</source>. <year>2019</year>;<volume>16</volume>(<issue>12</issue>):<fpage>1289</fpage>–<lpage>1296</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41592-019-0619-0</pub-id><?supplied-pmid 31740819?><pub-id pub-id-type="pmid">31740819</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Kang</surname><given-names>HJ</given-names></name>, <name><surname>Kawasawa</surname><given-names>YI</given-names></name>, <name><surname>Cheng</surname><given-names>F</given-names></name>, <name><surname>Zhu</surname><given-names>Y</given-names></name>, <name><surname>Xu</surname><given-names>X</given-names></name>, <name><surname>Li</surname><given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Spatio-temporal transcriptome of the human brain</article-title>. <source>Nature</source>. <year>2011</year>;<volume>478</volume>(<issue>7370</issue>):<fpage>483</fpage>–<lpage>489</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nature10523</pub-id><?supplied-pmid 22031440?><pub-id pub-id-type="pmid">22031440</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>Leng</surname><given-names>SY</given-names></name>, <name><surname>Ma</surname><given-names>HF</given-names></name>, <name><surname>Kurths</surname><given-names>J</given-names></name>, <name><surname>Lai</surname><given-names>YC</given-names></name>, <name><surname>Lin</surname><given-names>W</given-names></name>, <name><surname>Aihara</surname><given-names>K</given-names></name>, <etal>et al</etal>. <article-title>Partial cross mapping eliminates indirect causal influences</article-title>. <source>Nat Comm</source>. <year>2020</year>;<volume>11</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41467-020-16238-0</pub-id><?supplied-pmid 32457301?><pub-id pub-id-type="pmid">32457301</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010184.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Ying</surname><given-names>X</given-names></name>, <name><surname>Leng</surname><given-names>SY</given-names></name>, <name><surname>Ma</surname><given-names>HF</given-names></name>, <name><surname>Nie</surname><given-names>Q</given-names></name>, <name><surname>Lai</surname><given-names>YC</given-names></name>, <name><surname>Lin</surname><given-names>W</given-names></name>. <article-title>Continuity scaling: A rigorous framework for detecting and quantifying causality accurately</article-title>. <source>Research</source>. <year>2022</year>;<volume>2022</volume>:<fpage>9870149</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.34133/2022/9870149</pub-id><?supplied-pmid 35600089?><pub-id pub-id-type="pmid">35600089</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
