<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6815465</article-id>
    <article-id pub-id-type="publisher-id">3136</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-019-3136-3</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MIC_Locator: a novel image-based protein subcellular location multi-label prediction model based on multi-scale monogenic signal representation and intensity encoding strategy</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5591-5919</contrib-id>
        <name>
          <surname>Yang</surname>
          <given-names>Fan</given-names>
        </name>
        <address>
          <email>fan_yang@hms.harvard.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Yang</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Yanbin</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yin</surname>
          <given-names>Zhijian</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yang</surname>
          <given-names>Zhen</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.411864.e</institution-id><institution>School of Communications and Electronics, </institution><institution>Jiangxi Science &amp; Technology Normal University, </institution></institution-wrap>Nanchang, 330003 China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">000000041936754X</institution-id><institution-id institution-id-type="GRID">grid.38142.3c</institution-id><institution>Department of Biological Chemistry and Molecular Pharmacology, </institution><institution>Harvard Medical School, </institution></institution-wrap>Boston, MA 02115 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>26</day>
      <month>10</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>26</day>
      <month>10</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>20</volume>
    <elocation-id>522</elocation-id>
    <history>
      <date date-type="received">
        <day>14</day>
        <month>6</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>9</day>
        <month>10</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s). 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Protein subcellular localization plays a crucial role in understanding cell function. Proteins need to be in the right place at the right time, and combine with the corresponding molecules to fulfill their functions. Furthermore, prediction of protein subcellular location not only should be a guiding role in drug design and development due to potential molecular targets but also be an essential role in genome annotation. Taking the current status of image-based protein subcellular localization as an example, there are three common drawbacks, i.e., obsolete datasets without updating label information, stereotypical feature descriptor on spatial domain or grey level, and single-function prediction algorithm’s limited capacity of handling single-label database.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">In this paper, a novel human protein subcellular localization prediction model MIC_Locator is proposed. Firstly, the latest datasets are collected and collated as our benchmark dataset instead of obsolete data while training prediction model. Secondly, Fourier transformation, Riesz transformation, Log-Gabor filter and intensity coding strategy are employed to obtain frequency feature based on three components of monogenic signal with different frequency scales. Thirdly, a chained prediction model is proposed to handle multi-label instead of single-label datasets. The experiment results showed that the MIC_Locator can achieve 60.56% subset accuracy and outperform the existing majority of prediction models, and the frequency feature and intensity coding strategy can be conducive to improving the classification accuracy.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">Our results demonstrate that the frequency feature is more beneficial for improving the performance of model compared to features extracted from spatial domain, and the MIC_Locator proposed in this paper can speed up validation of protein annotation, knowledge of protein function and proteomics research.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Bioimage informatics</kwd>
      <kwd>Protein subcellular localization</kwd>
      <kwd>Frequency domain feature</kwd>
      <kwd>Monogenic signal</kwd>
      <kwd>Image intensity encoding strategy</kwd>
      <kwd>Multi-label classifier chain</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>61603161</award-id>
        <principal-award-recipient>
          <name>
            <surname>Yang</surname>
            <given-names>Fan</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>the Key Science Foundation of Educational Commission of Jiangxi Province of China</institution>
        </funding-source>
        <award-id>GJJ160768</award-id>
        <principal-award-recipient>
          <name>
            <surname>Yang</surname>
            <given-names>Fan</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>the scholastic youth talent support program of Jiangxi Science and Technology Normal University</institution>
        </funding-source>
        <award-id>2016QNBJRC004</award-id>
        <principal-award-recipient>
          <name>
            <surname>Yang</surname>
            <given-names>Fan</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>the Science Foundation of Artificial Intelligence and Bioinformatics Cognitive Research Base Fund of Jiangxi Science and Technology Normal University of China</institution>
        </funding-source>
        <award-id>2017ZDPYJD005</award-id>
        <principal-award-recipient>
          <name>
            <surname>Yang</surname>
            <given-names>Fan</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par34">Human protein subcellular localization prediction is an important component of bioinformatics. Identifying the subcellular locations of proteins can improve our understanding of their functions, mechanisms of molecular interaction, genome annotation and identification of drug targets [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. For example, protein synthesized from ribosome must be transported to their corresponding subcellular locations to fulfill their functions. Aberrant subcellular localization of protein can lead to serious loss of biological function or disorder occurrence in organisms and can even cause cancer [<xref ref-type="bibr" rid="CR3">3</xref>]. Diabetes, blindness and certain forms of cancer have been demonstrated to be caused by the malfunction of G Protein-Coupled Receptor (GPCR) signaling pathways [<xref ref-type="bibr" rid="CR4">4</xref>, <xref ref-type="bibr" rid="CR5">5</xref>]. Moreover, understanding of protein subcellular localization can greatly improve target identification during drug discovery. In the case of membrane proteins and secreted proteins, they are easily accessible by drug molecules due to their localization in the cell membrane or on the cell surface. It is well known that the traditional protein subcellular location annotation is derived from biological experiments in wet laboratory, however, computational models offer an attractive complement to time-consuming and laborious experimental methods [<xref ref-type="bibr" rid="CR6">6</xref>, <xref ref-type="bibr" rid="CR7">7</xref>].</p>
    <p id="Par35">Currently, a large number of automated prediction models have been developed for correctly predicting the subcellular locations of protein [<xref ref-type="bibr" rid="CR8">8</xref>–<xref ref-type="bibr" rid="CR10">10</xref>]. These prediction models can be divided into two categories in terms of processing target datasets, i.e., sequence-based [<xref ref-type="bibr" rid="CR11">11</xref>–<xref ref-type="bibr" rid="CR14">14</xref>], which uses the amino acids sequence as the input protein information, and image-based [<xref ref-type="bibr" rid="CR15">15</xref>–<xref ref-type="bibr" rid="CR18">18</xref>], which employs the biology image as the target dataset.</p>
    <p id="Par36">Efforts on sequence-based protein subcellular localization have been made by many research groups, such as Chou group, Briesemeister group, Wan group and Almagro group, and the corresponding software is Cell-Ploc, YLoc, iLoc-Hum, FUEL-mLoc, SpaPredictor and DeepLoc [<xref ref-type="bibr" rid="CR19">19</xref>–<xref ref-type="bibr" rid="CR24">24</xref>]. For instance, Chou et al. proposed a high-performance prediction model, iLoc-Hum, which can handle proteins with single-labeled and multi-labeled subcellular locations [<xref ref-type="bibr" rid="CR20">20</xref>]. By applying the gene ontology (GO) and position specific scoring matrix (PSSM) sequence information and K-nearest neighbor classifier (KNN) classification, iLoc-Hum achieve a remarkably higher success rate at 76%, and a user-friendly web-server is developed. FUEL_mLoc is proposed to predict with single- or multi-label, and it uses the key go terms to analyze how a prediction is made and it can predict several species. The experimental results proved that FUEL-mLoc outperforms state-of-the-art subcellular localization predictors [<xref ref-type="bibr" rid="CR22">22</xref>]. However, with the technology development in gene sequencing, the imperfection of protein sequence annotation was preferred by scientists [<xref ref-type="bibr" rid="CR25">25</xref>, <xref ref-type="bibr" rid="CR26">26</xref>]. Then several genes sequencing reannotation tools are designed for checking and correcting the error of annotation. They encouraged researchers to realize that these sequence-based methods may not be significantly reliable [<xref ref-type="bibr" rid="CR27">27</xref>].</p>
    <p id="Par37">Moreover, the sequence-based methods are not sensitive to protein translocations, especially when dealing with cancer. In detail, human health is reflected by cells, which are restricted by the internal ecological environment of human body. When unavoidable changes of environment occur, cells must have complex collaborative response, i.e., protein translocation [<xref ref-type="bibr" rid="CR14">14</xref>]. Amino acid sequence itself does not change when the protein trans-location in cancer cell environment. Hence, image-based protein subcellular localization prediction models have gradually become a research hotspot [<xref ref-type="bibr" rid="CR28">28</xref>–<xref ref-type="bibr" rid="CR30">30</xref>]. Murphy group proposed a framework for the construction of image-based protein subcellular localization prediction, and the prediction framework was first applied to the Human Protein Atlas (HPA) database [<xref ref-type="bibr" rid="CR16">16</xref>]. This initiative is regarded as the pioneering work in the field of image-based subcellular localization prediction.</p>
    <p id="Par38">In the following years, an increasing number of image-based protein subcellular localization prediction models have been proposed based on the combination of image processing technologies and machine learning algorithms. For example, Boland et al. utilized the back-propagation neural network classifier and subcellular location features (SLFs) to recognize the subcellular localization of Hela cells [<xref ref-type="bibr" rid="CR31">31</xref>], however, the local information of sample was not revealed. Muhammad Tahir et al. proposed the SVM-SubLoc method, which focuses on the combination of the Haralick feature and local image descriptor, then feeds into the support vector machine (SVM) classification. The SVM-SubLoc model can achieve 99.7% prediction accuracy in Hela cells dataset [<xref ref-type="bibr" rid="CR32">32</xref>]. Lin group proposed a new learning algorithm named AdaBoost.ERC. They utilized the error-correcting output codes (ECOC) coding strategy and the boosting method to improve the prediction accuracy [<xref ref-type="bibr" rid="CR33">33</xref>]. Although the model mentioned above can obtain high accuracy, the involved features are extracted in spatial domain, which may be attributed to the limited image processing technology.</p>
    <p id="Par39">To describe local features more accurately, XU et al. first proposed the local binary pattern (LBP), a popular local image descriptor applied in the field of image retrieval, to protein subcellular images. Experimental results showed that LBP plays a significant role in improving the performance of prediction model by capturing the texture information of immunohistochemistry (IHC) images [<xref ref-type="bibr" rid="CR17">17</xref>]. Coelhp L P et al. obtain the interest regions of IHC image by using the K-means method within the target image [<xref ref-type="bibr" rid="CR18">18</xref>]. The feature descriptor is calculated in the interested regions of image. These entirely featured descriptors generated the local feature by clustering method. Although the approach achieved an improvement in the classification accuracy, the number of K-means clustering centers may cause fluctuations in the performance of prediction model for various datasets. For instance, the method just achieves 78.9% classification accuracy in the HPA dataset [<xref ref-type="bibr" rid="CR34">34</xref>]; in contrast, 94.4% classification was obtained in the Hela2D dataset [<xref ref-type="bibr" rid="CR35">35</xref>]. Shao group made efforts on the improvement of accuracy by using a novel voting strategy in decision level and taking the different relationship of labels into account. Although the method achieved high prediction accuracy, it was unable to handle multi-label protein subcellular location prediction [<xref ref-type="bibr" rid="CR15">15</xref>]. Jieyue L and Newberg J et al. proposed to update the subcellular localization annotation of datasets by using the hierarchical clustering method and SVM classification, followed by continuously revising the subcellular localizations of test samples. Godinez W J et al. proposed M-CNN prediction model, which uses the convolution neural network (CNN) with multi-scale architecture, to predict image subcellular localization in eight published datasets. Although the experimental result showed that M-CNN achieved around 95% prediction accuracy in the seven datasets more than these popular network architectures, such as AlexNet and GoogleNet [<xref ref-type="bibr" rid="CR36">36</xref>–<xref ref-type="bibr" rid="CR38">38</xref>], M-CNN merely obtained the 77% prediction accuracy in the HPA dataset, as the HPA dataset consists of image with multi-label.</p>
    <p id="Par40">Moreover, many efforts have been made on the algorithm level [<xref ref-type="bibr" rid="CR39">39</xref>–<xref ref-type="bibr" rid="CR41">41</xref>]. Wei group proposed a novel feature selection method that used the biology background to set up a regularization item so as to optimize the feature selection method, and this method can select more informative feature subsets [<xref ref-type="bibr" rid="CR40">40</xref>]. The Sullivan group innovatively used the online game (EVE Online) to attract the numerous participants to annotate the subcellular locations of protein image based on both of the transfer learning framework and the deep learning method to build the automated Localization Cellular Annotation Tool (Loc-CAT). This work not only achieved the F1 score of 0.74 but also proposed a novel approach to obtain the precious annotated data by the online game [<xref ref-type="bibr" rid="CR41">41</xref>].</p>
    <p id="Par41">The contributions made by the predecessors in the field of protein subcellular localization prediction, especially in imaged-based, should be positively evaluated, however, three shortcomings can be summarized as follows.</p>
    <p id="Par42">Firstly, the labels of benchmark dataset in published works have been updated by database, such as HPA. Although the prediction accuracy at that time was quite gratifying, it would greatly reduce the credibility of the prediction model if the training samples used in the prediction model construction are involved in the label updating of database. Obviously, it is meaningless to accurately predict an error or a failed label, and the corresponding training samples can also be treated as obsolete data. Different from face and natural images, the label information of protein image datasets is updated regularly to ensure that the subcellular location corresponding to a sample image is true and accurate. For instance, the subcellular location of gene “ENSG00000182606” is reported “Cytopl” in [<xref ref-type="bibr" rid="CR17">17</xref>], while the subcellular location of gene is updated “ER” and “Nucleoplasm” in version 18 of HPA database. The label of “ENSG00000155876” in HPA has been updated to Golgi apparatus and Vesicles in the latest version while its labels reported in [<xref ref-type="bibr" rid="CR17">17</xref>] are “Golgi apparatus”, “Lysosomes” and “Vesicles”. Inspired by this, the latest datasets from HPA have been collected and collated as our benchmark instead of obsolete data.</p>
    <p id="Par43">Secondly, they lack of in-depth understanding of protein image signals. For a target protein image, it is not just a digital image, but more importantly, it is still a 2-dimension signal, which is often overlooked. Researchers are more eager to find a simple image descriptor to extract features from protein images rather than taking the time to figure out the 2-dimension signal. For example, LBP and its variation, local ternary pattern (LTP) and local quinary pattern (LQP), are employed to extract local feature of protein IHC images [<xref ref-type="bibr" rid="CR42">42</xref>, <xref ref-type="bibr" rid="CR35">35</xref>]. These kinds of image descriptors focus on encoding the gray level information of image in spatial domain rather than considering other aspects of image, such as the local energy, structure and geometry information, which can be obtained from the transformation or frequency domain of image signal [<xref ref-type="bibr" rid="CR43">43</xref>]. Even for complicated feature descriptors, such as completed local binary pattern (CLBP) and local tetra pattern (LTrP), can capture more local information [<xref ref-type="bibr" rid="CR44">44</xref>, <xref ref-type="bibr" rid="CR45">45</xref>]; however, the target protein image is still encoded in grey level or spatial domain. This kind of roughly transplanted approach has ignored the biological properties of IHC protein images, which included multiple cells and can be sparse representation in frequency domain. Few researchers have been taking this point into account.</p>
    <p id="Par44">In this paper, to generally capture the essential local property of IHC image, Fourier transformation, Riesz transformation, Log-Gabor filter and intensity coding strategy are employed to obtain frequency feature based on three components of monogenic signal with several frequency scales. 2-dimension fast Fourier transform is employed to convert target protein channel from spatial domain into the frequency domain, and then the Riesz transformation [<xref ref-type="bibr" rid="CR46">46</xref>] is employed to obtain two frequency responses in orthogonal directions [<xref ref-type="bibr" rid="CR47">47</xref>]. To improve the robustness of model, the convolution of three parts, i.e., original frequency information and two frequency responses of Riesz transform, and Log-Gabor band-pass filter with different frequency scales is calculated. It is known that the detail information of IHC image, e.g., slight textures and edges, mainly concentrated on the high frequency band. In addition, larger frequency response can be obtained, if the frequency of local texture information is closer to the center frequency of Log-Gabor filter, and vice versa. The inverse 2-dimension fast Fourier transform converts three parts into the spatial domain, and the monogenic signal of image can be represented. By using various mathematical formulas, the three components of monogenic signal of protein channel can be calculated, namely, local amplitude, phase and orientation (APO). These three components denote to the energetic, structural, and geometric information of target protein image, respectively. The details for corresponding encoding strategies ara given in the following section.</p>
    <p id="Par45">Thirdly, it is well-known that above 50% of proteins are found in two or more subcellular locations. An effective and accurate prediction model should be capable of handling multi-label datasets, and it is critical to capture the dynamic transfer of proteins between different subcellular locations and to screen for cancer biomarkers. Xu et al. proposed an image-based multi-label protein subcellular prediction model CorrASemiB based on the combination of Bayesian theory and variety decision strategies [<xref ref-type="bibr" rid="CR48">48</xref>]. The CorrASemiB employed the binary relevance (BR) classification as the multi-label classification, which leads the neglect of the correlation of subcellular localizations. In order to find the correlation between different subcellular locations, Wang group proposed the random label selection (RALS) to more accurately predict the subcellular localizations of protein with multi-label, which learned the correlation of different subcellular localizations from datasets by randomly selected labels as the additional features adding into the original feature space [<xref ref-type="bibr" rid="CR49">49</xref>]. However, the randomly selected labels will lead to the prediction performance instability of model. Zhou et al. used the multi-view complementary protein information, i.e. GO, conserved domain database (CDD) and amino acid composition (AAC), to build the prediction model [<xref ref-type="bibr" rid="CR9">9</xref>]. While this method achieved an increase in the prediction accuracy at 5–11% because the sample feature was extracted from the multi-view of protein, the correlation of labels and the hierarchical structure of GO terms are ignored.</p>
    <p id="Par46">Considering the importance of multi-labeled proteins, the predictive model is expected to handle multi-labeled datasets, a chained classification is proposed in this paper. The experimental results show that the subset accuracy of the proposed prediction model can achieve 60.56% classification accuracy and outperform the existing prediction models.</p>
  </sec>
  <sec id="Sec2">
    <title>Results</title>
    <p id="Par47">The 5-fold cross-validation is utilized to split the train set and test set on the benchmark dataset in this paper. The benchmark dataset consists of 3240 IHC images, and the proportion of image with multi-label is 25%, i.e., 824 multi-label IHC images in total. The numbers of subcellular locations involved in benchmark are seven, i.e., “Cytosol”, “Endoplasmic reticulum”, “Golgi apparatus”, “Nucleoli”, “Mitochondria”, “Nucleus” and “Vesicles”. A total of 1864-dimension features, derived from SLFs and frequency feature, have fed into subsequent classifier chains (CC). In the next section, the MIC_Locator<sup>X_S</sup> (X is one of A, P and O components; S represents the scale factor from 1 to 5) prediction model is trained by the combination of global features and local image descriptor with different frequency scales in these components of monogenic signal. The MIC_Locator<sup>X_E</sup> prediction model (X is A, P and O components) denotes to the ensemble prediction model of three APO components. These weighted ensemble methods are used to fuse all single prediction models for constructing the prediction model MIC_Locator.</p>
    <sec id="Sec3">
      <title>The performance of MIC_Locator with frequency feature on new benchmark dataset</title>
      <p id="Par48">In this section, we aim to compare the performance of frequency feature with different local image descriptors, namely LBP, CLBP and LTrP. The SLFs feature with 10 dbs, which derives from the 10 vanishing moments of 2-dimension wavelet analysis function, e.g. db1-db10, is directly combined with these different local image descriptors and frequency domain feature as the sample feature. As the results (mean and standard deviations) are shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, there are two distinct trends. One is that the MIC_Locator achieves the best classification accuracy, and the other is that the ensemble prediction model of APO components is more high-performance than these local image descriptors extracted from spatial domain.
<fig id="Fig1"><label>Fig. 1</label><caption><p>The classification results of prediction model trained with the combination of global feature and different local feature based on the 5 times 5-fold cross-validation, and the corresponding mean and standard deviation of each case are also given</p></caption><graphic xlink:href="12859_2019_3136_Fig1_HTML" id="MO1"/></fig></p>
      <p id="Par49">From Fig. <xref rid="Fig1" ref-type="fig">1</xref>, the MIC_Locator can achieve the 63.24% subset accuracy in db5, but the classification SLFs_LBP, SLFs_CLBP, SLFs_LTrP just achieve lower accuracy at 51.29, 51.05 and 53.13%. Consistent with the above conclusion, MIC_Locator achieves the best performance in other dbs. The ensemble prediction models of APO components are fused by the weighted ensemble algorithm. The weight parameter of weighted ensemble method is obtained by the grid research from 0.1 to 0.5 with the step of 0.01 based on db4, and the producer of experiment has been shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. The weight parameter is set to be 0.43 as the final weight parameter, when the MIC_Locator achieves the highest subset accuracy.
<fig id="Fig2"><label>Fig. 2</label><caption><p>The subset accuracy of MIC_Locator fluctuates with the weighted parameter <italic>W</italic></p></caption><graphic xlink:href="12859_2019_3136_Fig2_HTML" id="MO2"/></fig></p>
      <p id="Par50">An expected result is observed that the ensemble prediction model MIC_Locator<sup>X_E</sup> can extremely improve the classification accuracy of prediction model except the MIC_Locator<sup>A_E</sup>. For instance, MIC_Locator<sup>P_E</sup> and MIC_Locator<sup>O_E</sup> respectively achieve 59.06 and 56.31% subset accuracy, which exceed the SLFs_LBP to 7.77 and 5.02% in db5. Nevertheless, there is a deficiency that MIC_Locator<sup>A_E</sup> achieves relatively low classification accuracy, since the ability A component to describe subtle texture information is poor compared with P and O components. This result can be attributed to the fact that the slight texture information is more sparely expressed in the frequency domain making it easily to be captured by the PO components, and then MIC_Locator<sup>P_E</sup> and MIC_Locator<sup>O_E</sup> can be superior to SLFs_LBP. The above-mentioned reasons can be validated with experimental results in the next section.</p>
      <p id="Par51">Furthermore, in the comparison of local image descriptors extracted in the spatial domain, the LTrP achieve the highest classification accuracy than the LBP, CLBP. Specifically, SLFs_LTrP prediction model trained by the combination of SLFs and LTrP local image descriptor can achieve 53.13% subset accuracy in db5. The results demonstrated that the LTrP local image descriptor can preferably extract the texture information of image, as the LTrP captures the statistic information of image by comparing the consistency of center pixel with neighboring pixels. Although the LTrP used a more complex local image descriptor coding strategy, higher subset accuracy is achieved by the MIC_Locator at 63.24% in db5 as the local image descriptor of MIC_Locator codes the frequency information rather than the spatial information. The classification accuracy of prediction model SLFs_LBP achieves 51.29% subset accuracy in db5, which is 1.84% lower than the prediction model SLFs_LTrP. Because the definition of LBP is concerned the difference between the center pixel and its neighboring in gray level to capture the statistic information of image. The SLFs_CLBP prediction model achieves limited classification accuracy at 51.05% in db5. The reason is that the CLBP local image descriptor compares the gray level of center pixel with the average gray level of whole image to add center pixel information, which cannot more precisely capture the essential property of center pixel. In addition, while the local image descriptor as a complementary feature combined with the SLFs, the prediction model can hugely increase the classification accuracy. For example, the prediction model SLFs obtain the lowest classification accuracy in 44.97%, owing to the lack of local image descriptor. The SLFs_LTrP, SLFs_LBP, SLFs_CLBP prediction model respectively achieve a higher classification accuracy compared the SLFs prediction to 8.19, 6.29 and 6.08% in db5. Although the performance of local image descriptors extracted from the spatial domain has been validated, it is still inferior to MIC_Locator. Hence, we have made further analysis to verify and reveal the internal logic, such as the analysis of Log-Gabor filter, coding strategy, APO components and multi-scale.</p>
    </sec>
    <sec id="Sec4">
      <title>Performance of log-Gabor, image intensity coding strategy and classifier chain</title>
      <p id="Par52">In this section, to validate the advantages of parts, namely Log-Gabor filter, image intensity encoding strategy and CC, we respectively compare the MIC-Locator and the MIC-Locator without each part.</p>
      <p id="Par53">The constructed MIC_Locator prediction model without Log-Gabor filter and image intensity encoding strategy is named as Without_image_intensity and Without_Log-Gabor. As shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, the experimental results illustrate that the MIC_Locator without the Log-Gabor and image intensity coding strategy achieve lower performance. Specifically, the MIC_Locator achieve 59.04% subset accuracy in db3, but the Without_Log-Gabor and Without_image_intensity just obtain 46.28 and 55.46%. We can draw a conclusion that the Log-Gabor filter and image intensity coding strategy actually play an indispensable role in contributing the performance of MIC_Locator.
<fig id="Fig3"><label>Fig. 3</label><caption><p>The results of various evaluation metrics for MIC_Locator, Without_image_intensity and Without_Log-Gabor on db3</p></caption><graphic xlink:href="12859_2019_3136_Fig3_HTML" id="MO3"/></fig></p>
      <p id="Par54">Furthermore, the CC classification is replaced by the BR multi-label classifier. The Table <xref rid="Tab1" ref-type="table">1</xref> investigates that the performance of MIC_Locator based on the CC and BR in 10 dbs in terms of overall, single-labeled and multi-labeled subset accuracy. As can be seen, the CC outperforms BR in the MIC_Locator<sup>A_E</sup>, MIC_Locator<sup>P_E</sup> and MIC_Locator<sup>O_E</sup> in all evaluation indexes. Although the MIC_Locator with BR classifier slightly outperforms the CC classifier at 0.75% in terms of overall subset accuracy, the CC can extremely boost the multi-labeled subset accuracy from 19.96 to 31.30%. Considering the CC is importantly effective for determining subcellular localization of multi-label proteins. Hence, the CC and frequency feature are jointly leveraged to constructing the MIC_Locator.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>The comparison of subset accuracy on both overall, single-label and multi-label testing dataset of MIC_Locator by using BR and CC in 1–10 dbs</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2"/><th colspan="3">CC</th><th colspan="3">BR</th></tr><tr><th>Subset accuracy</th><th>Single-labeled subset accuracy</th><th>Multi-labeled subset accuracy</th><th>Subset accuracy</th><th>Single-labeled subset accuracy</th><th>Multi-labeled subset accuracy</th></tr></thead><tbody><tr><td>MIC_Locator<sup>A_E</sup></td><td>54.73%</td><td>64.26%</td><td>26.90%</td><td>51.14%</td><td>63.47%</td><td>15.26%</td></tr><tr><td>MIC_Locator<sup>P_E</sup></td><td>58.08%</td><td>67.45%</td><td>30.70%</td><td>55.25%</td><td>67.33%</td><td>20.06%</td></tr><tr><td>MIC_Locator<sup>O_E</sup></td><td>57.71%</td><td>67.36%</td><td>29.52%</td><td>56.12%</td><td>68.80%</td><td>19.18%</td></tr><tr><td>MIC_Locator</td><td>59.86%</td><td>69.63%</td><td>31.30%</td><td>60.61%</td><td>74.56%</td><td>19.96%</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec5">
      <title>Results of exploration of the three components from monogenic signal</title>
      <p id="Par55">An obvious conclusion can be drawn from Fig. <xref rid="Fig1" ref-type="fig">1</xref> that frequency features are more discriminative than SLFs and the original spatial feature, and can greatly improve the accuracy of the prediction model; however, we are more interested in which component plays a more important role in the whole frequency domain. Hence, the APO components are visualized and showed intuitively in Fig. <xref rid="Fig4" ref-type="fig">4</xref>.
<fig id="Fig4"><label>Fig. 4</label><caption><p>The comparison of ability in capturing slight texture feature on these APO components of image based on a given local patch in an IHC image. <bold>a</bold> Denotes to an IHC image derived from the “ENSG00000013364” and the corresponding subcellular location is “Cytosol”. An example of local patch region is presented in the original IHC image by marking red rectangle. The APO components on this local patch are separated in frequency domain and inverse transform (Fourier Inversion) to spatial domain for easy visualization. <bold>b</bold> Denotes to amplitude component under the local patch. <bold>c</bold> Represents the phase component under the local patch. <bold>d</bold> Represents the orientation component under the local patch</p></caption><graphic xlink:href="12859_2019_3136_Fig4_HTML" id="MO4"/></fig></p>
      <p id="Par56">It is well known that the phase spectrum is most important in frequency domain analysis of the signal, and the consistent conclusion can be observed in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. Firstly, an IHC image is selected from the benchmark datasets, and the selected patch is marked by the red rectangle frame. Secondly, the local patch in these three components is commonly amplified, which are shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. It is clear that the amplitude component mainly reflects the outline of image in local patch, and the phase component extremely reflects the slight texture, and the orientation component presents the texture information along the gradient direction.</p>
      <p id="Par57">Another important finding was that the phase component captures more frequency information than other components. Specifically, the orientation component vaguely presents the outline of local patch in the upper right of Fig. <xref rid="Fig4" ref-type="fig">4</xref>d, but the phase component more distinctly presents the texture of local patch in the upper right of Fig. <xref rid="Fig4" ref-type="fig">4</xref>c. In order to verify the conclusion of the subjective evaluation, some essential experiments are carried out and the corresponding results are shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. The result of FSL_PSL<sup>P_E</sup> outperforms phase component can significantly reflect frequency information.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Compared the ensemble prediction model with each single prediction model based on the APO components, local amplitude, local phase and local orientation. <bold>a</bold> Compares MIC_Locator<sup>A_E</sup> with MIC_Locator<sup>A_S1</sup> to MIC_Locator<sup>A_S5</sup> based on 10 dbs. <bold>b</bold> Compares MIC_Locator<sup>P_E</sup> with MIC_Locator<sup>P_S1</sup> to MIC_Locator<sup>P_S5</sup> based on 10 dbs. <bold>c</bold> Compares MIC_Locator<sup>O_E</sup> with MIC_Locator<sup>O_S1</sup> to MIC_Locator<sup>O_S5</sup> based on 10 dbs</p></caption><graphic xlink:href="12859_2019_3136_Fig5_HTML" id="MO5"/></fig></p>
    </sec>
    <sec id="Sec6">
      <title>Results of MIC_Locator on different frequency scales</title>
      <p id="Par58">To gain better understanding of which frequency scale is better and whether fusing these prediction model with single frequency scale can obtain more benefits, the performance of MIC_Locator with different frequency scales on APO components are compared, and it is necessary for us to verify whether the conclusion mentioned above is consistent at all scales.</p>
      <p id="Par59">In this section, the scale index is set from 1 to 5, which affects the center frequency that makes the Log-Gabor band-pass filter has different frequency responses, and the results are showed in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. The prediction model with frequency scale from 1 to 3 can achieve superior classification performance. For instance, the MIC_Locator<sup>P_S3</sup> achieves 55.89% classification accuracy in db2, while the MIC_Locator<sup>P_S4</sup> and MIC_Locator<sup>P_S5</sup> respectively achieve 55.3 and 51% classification accuracy; the MIC_Locator<sup>O_S3</sup> achieve 55.02% classification accuracy in db2, whereas the MIC_Locator<sup>O_S4</sup> and MIC_Locator<sup>O_S5</sup> respectively achieve 53.14 and 49.4% classification accuracy.</p>
      <p id="Par60">Furthermore, these ensemble prediction models of each component, MIC_Locator<sup>A_E</sup>, MIC_Locator<sup>P_E</sup> and MIC_Locator <sup>O_E</sup>, achieve the highest prediction accuracy on each db. For example, MIC_Locator<sup>P_E</sup> achieves the 58.92% classification accuracy, while the MIC_Locator<sup>P_S1</sup> and the MIC_Locator<sup>P_S5</sup> respectively achieve 56.94 and 50.57% classification accuracy in db5, since these ensemble prediction models fuse the advantage of each single prediction model. From the Table <xref rid="Tab1" ref-type="table">1</xref>, the ensemble prediction model of phase components MIC_Locator<sup>P_E</sup> achieve the highest subset accuracy than MIC_Locator<sup>A_E</sup> and MIC_Locator<sup>O_E</sup> on 10 dbs by 3.35 and 0.37%, as the phase component is preferable to capture the texture information of image; the MIC_Locator, however, outperforms the MIC_Locator<sup>P_E</sup>.</p>
    </sec>
    <sec id="Sec7">
      <title>Performance validation of MIC_Locator on both single-label and multi-label datasets</title>
      <p id="Par61">In order to validate the performance of proposed prediction model MIC_Locator, we compare MIC_Locator with opened and popular methods in db4. The comparison experiments can be carried out divided into two parts, namely multi-label part and single-label part.</p>
      <p id="Par62">An excellent prediction model, accurate and efficient prediction of single-labeled samples in the benchmark dataset is the basic guarantee of the generalization ability of prediction model. The performance of MIC_Locator is compared with the [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR16">16</xref>] in predicting the single-labeled sample part. The accuracy, recall and precision are used for the evaluation index, and the experimental result has been shown in Table <xref rid="Tab2" ref-type="table">2</xref>.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>The performance comparisons of single-label prediction model on db4</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Prediction model</th><th>Accuracy</th><th>Recall</th><th>Precision</th></tr></thead><tbody><tr><td>Coelho et al. [<xref ref-type="bibr" rid="CR16">16</xref>]</td><td>56.34%</td><td>54.35%</td><td>57.97%</td></tr><tr><td>Wei et al. [<xref ref-type="bibr" rid="CR15">15</xref>]</td><td>60.46%</td><td>57.75%</td><td>66.84%</td></tr><tr><td>MIC_Locator</td><td>71.27%</td><td>70.54%</td><td>72.00%</td></tr></tbody></table></table-wrap></p>
      <p id="Par63">The [<xref ref-type="bibr" rid="CR16">16</xref>] uses the SLFs as the sample feature, and the linear SVM is applied as a classification to predict the subcellular location of test sample. The LBP and SLFs are combined as the sample features feeding the SVM, and the SC-PSorter voting strategy and multi-kernel learning method are used to enhance the performance of [<xref ref-type="bibr" rid="CR15">15</xref>]. To obtain an objective comparison result, these single-labeled samples are selected from benchmark datasets as a dataset for the [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR16">16</xref>], as the benchmark datasets include the multi-labeled protein, which disturbers the performance of single-labeled prediction model [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR16">16</xref>]. Meanwhile, MIC_Locator only predicts the single-labeled sample in the benchmark dataset. Based on the 5-fold cross-validation, the MIC_Locator obtain 71.27% accuracy 70.54% recall and 72% precision, and these three metrics are higher the [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR16">16</xref>]. The better performance of MIC_Locator mainly owes to the following two aspects: (i) we use the frequency feature of IHC to construct prediction model and (ii) fusing the single prediction based on several frequency scales enhances the robustness and general ability of MIC_Locator.</p>
      <p id="Par64">To further confirm the performance of MIC_Locator in multi-label part, the MIC_Locator is compared with the iLocator, which belongs to the multi-label subcellular localizations prediction model, and the experiment result is shown in Table <xref rid="Tab3" ref-type="table">3</xref>. The accuracy, recall, precision and label average accuracy are used for the evaluation index, and these evaluation indexes are defined in [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR61">61</xref>]. The better performance of MIC_Locator mainly owes to the following two aspects: (i) we use the frequency feature of IHC to construct prediction model and (ii) fusing the single prediction based on several frequency scales enhances the robustness and general ability of MIC_Locator.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>The performance comparisons of multi-label prediction model on db4</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Prediction model</th><th>Subset accuracy</th><th>Recall</th><th>Precision</th><th>Average label accuracy</th></tr></thead><tbody><tr><td>iLocator [<xref ref-type="bibr" rid="CR17">17</xref>]</td><td>54.81%</td><td>53.63%</td><td>57.51%</td><td>84.90%</td></tr><tr><td>MIC_Locator</td><td>60.43%</td><td>60.12%</td><td>69.24%</td><td>88.43%</td></tr></tbody></table></table-wrap></p>
      <p id="Par65">Based on the original benchmark dataset and 5-fold cross-validation, the MIC_Locator achieve 60.43% subset accuracy, and it exceeds the iLocator by 5.62%. For the analysis of experiment result, it is described in the discussion section.</p>
    </sec>
    <sec id="Sec8">
      <title>Extended exploration results of MIC_Locator</title>
      <p id="Par66">It is well known that target images with high quality dyeing properties and accurate label are less than 50% in HPA. Some semi-supervised learning models are proposed to select properly from medium quality dyeing images and participate in the training stage of the model in order to solve the shortage of high quality dyeing sample. However, such kind of approach must be fully confident in the robustness of the prediction model. In this section, we compare the model proposed in this paper with the existing semi-supervised model. The experimental results show that the proposed model is better than the semi-supervised model. Moreover, transform the proposed model into a semi-supervised model is a very interesting follow-up work.</p>
      <p id="Par67">In this section, we compared our prediction model with two popular semi-supervised prediction models, i.e. standard semi-supervised approach [<xref ref-type="bibr" rid="CR39">39</xref>] and improved semi-supervised approach CorrASemiB [<xref ref-type="bibr" rid="CR48">48</xref>]. The results of performance comparison have been shown in Table <xref rid="Tab4" ref-type="table">4</xref>. Referring to the [<xref ref-type="bibr" rid="CR39">39</xref>], this standard approach is to select properly based on the consistency between the prediction labels from the proposed supervised learning model and the true labels. As for CorrASemiB, integrating the different organelles correlation emerges a DAG structure by the Bayesian algorithm that each node represents a subcellular location, and the edge of DAG structure symbolizes the reliable relations between two subcellular locations.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>The subset accuracy (%) for the different prediction models based on 10 dbs</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th>db1</th><th>db2</th><th>db3</th><th>db4</th><th>db5</th><th>db6</th><th>db7</th><th>db8</th><th>db9</th><th>db10</th></tr></thead><tbody><tr><td>Hady et al. [<xref ref-type="bibr" rid="CR39">39</xref>]</td><td>36.37</td><td>36.37</td><td>35.93</td><td>36.49</td><td>37.55</td><td>35.75</td><td>37.45</td><td>37.45</td><td>36.93</td><td>37.80</td></tr><tr><td>CorrASemiB [<xref ref-type="bibr" rid="CR48">48</xref>]</td><td>48.38</td><td>48.38</td><td>49.00</td><td>48.07</td><td>49.77</td><td>50.23</td><td>46.21</td><td>49.61</td><td>49.46</td><td>48.53</td></tr><tr><td>MIC_Locator</td><td>59.85</td><td>60.43</td><td>59.04</td><td>60.43</td><td>60.37</td><td>59.04</td><td>60.04</td><td>60.56</td><td>59.47</td><td>58.98</td></tr></tbody></table></table-wrap></p>
      <p id="Par68">Two consistent conclusions can be observed from the comparison experimental results. Firstly, the MIC_Locator achieve the highest subset accuracy in 10 dbs, and the identical conclusions were obtained in the Fig. <xref rid="Fig1" ref-type="fig">1</xref>. Since we utilized amplitude, phase and orientation components in various frequency scales to describe the IHC image which can not only describe the energetic, structural, and geometric information of protein channel, but also the texture of protein channel with different frequency spans can be captured; Secondly, The performance of the standard semi-supervised [<xref ref-type="bibr" rid="CR39">39</xref>] only can reach 36% subset accuracy on the new benchmark dataset while the result of improved semi-supervised approach is 12% higher than the standard approach. Refer to [<xref ref-type="bibr" rid="CR39">39</xref>] approach, the BR classification is employed as multi-label classification which cannot consider the correlation between different subcellular locations leading lower classification accuracy. The CorrASemiB approach achieves progress in prediction performance compared to [<xref ref-type="bibr" rid="CR39">39</xref>] approach, as the Bayesian network is applied to guide the constructing of model. However, the lack of efficient local image descriptor results in limited prediction accuracy.</p>
    </sec>
  </sec>
  <sec id="Sec9">
    <title>Discussion</title>
    <p id="Par69">By comparing local image descriptors deriving from spatial domain and frequency information, it is observed that several important factors contributed to the excellent performance of MIC_Locator. Firstly, extracting frequency features by three different aspects of image, namely APO components, is superior to capturing the texture information of image from the amplitude, phase and orientation perspective of image. Secondly, as shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, fusing in decision level based on several single frequency scales and APO components not only can integrate the advantages of each prediction model but also can enable multiple prediction models to complement each other, and ultimately obtain better classification accuracy.</p>
    <p id="Par70">To get an inquiry of MIC_Locator in depth, the comparison experiment had been carried out to explore the performance contribution of Log-Gabor filter, image intensity coding strategy and CC parts on the final prediction. As shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>, our experiment results demonstrate that the MIC_Locator without these three parts achieve limited performance, and identical conclusions can be obtained. Firstly, the Log-Gabor with different frequency scales can capture more frequency information distributing in various frequency bands and avoid the disturbance of DC. Secondly, the image intensity encoding strategy more accurately describes the distribution of local signal, and it enhances the discrimination of MIC_Locator. Finally, CC can significantly improve the classification accuracy for multi-label by capturing the correlation of different subcellular location.</p>
    <p id="Par71">It is well known that phase is the position of a point in time (an instant) on a waveform cycle in the field of physics and mathematics, and also a typical feature in frequency domain. Hence, P component is given a higher expectation, which means it will have a better performance in MIC_Locator while comparing with A and O component. By analyzing the experiment result of MIC_Locator under various APO components with qualitative and quantitative approaches, it is found that the phase component is indeed more superior to improving the performance of classification than amplitude and orientation components and extracting the slight texture information of image, which further demonstrates that the phase component plays a significant role in capturing the frequency information of sample. Furthermore, comparing with state-of-the-art methods belonging to both single-labeled and multi-labeled methods, the proposed MIC_Locator outperforms other baseline approaches shown in Tables <xref rid="Tab2" ref-type="table">2</xref> and <xref rid="Tab3" ref-type="table">3</xref> in terms of different evaluation indexes, which demonstrate again the high-performance of MIC_Locator. The reasons are summarized as follows. Firstly, the fine-grain information of IHC is transformed into the spare information in frequency domain by the Riesz transform, Fourier transform and the Log-Gabor with the multi-scale frequency factor, which is conducive to capturing the information of IHC. Secondly, APO components enable IHC information to be captured more completely, because the APO components reflect the energy, structure and geometry information of IHC rather than the gray level information. Thirdly, the LBP and image intensity coding schedules are commonly used to capture the statistic information of APO components. Finally, the CC classification is used to handle multi-label task, which considers the correlation of several subcellular localizations in the process of constructing prediction model. The result validates the advantage of MIC_Locator for the subcellular localization prediction of multi-label protein.</p>
    <p id="Par72">Owing to the advantage of semi-supervised model is that more training samples are used to enhance the generalization ability of the model in the training stage, two excellent semi-supervised models are proposed [<xref ref-type="bibr" rid="CR39">39</xref>, <xref ref-type="bibr" rid="CR48">48</xref>]. Hence, the investigation on the performance comparison between MIC_Locator and some semi-supervised models had been carried out. As can be seen from the comparison results in Table <xref rid="Tab4" ref-type="table">4</xref>, the proposed MIC_Locator is about 12% higher than the overall accuracy of the semi-supervised learning model. This is not to say that the semi-supervised learning framework does not work, but because semi-supervised learning is based on supervised learning. Once the quantitative features are weakly discriminative or the machine learning algorithms are not robust, and then the advantages of semi-supervised learning are difficult to fully exploit. Although MIC_Locator has a good predictive performance, more samples to participate in training are expected. However, it is an indisputable fact that high quality dyeing images are a minority in HPA database. Therefore, it is meaningful for MIC_Locator to combine with semi-supervised framework, and two advantages can be summarized as follows. Firstly, MIC_Locator achieved significant improvement can provide a very accurate and efficient supervised-prediction-model guarantee for the semi-supervised learning framework. Secondly, more medium quality dyeing images can make feature capture more comprehensive and accurate in frequency domain.</p>
    <p id="Par73">Furthermore, research work based on image signals is still very few while comparing with the study of protein subcellular localization prediction at the sequence level; however, the prediction model based on image signal of analysis is more visualized and interpretable, such as phase components shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>. Therefore, we believe that the combination of prior knowledge of protein at the sequence level and analysis at the protein robustness and generalization ability of the predictive model, which is also a very meaningful follow-up research direction.</p>
  </sec>
  <sec id="Sec10">
    <title>Conclusion</title>
    <p id="Par74">In this study, an accurate and effective multi-label protein subcellular locations prediction model named MIC_Locator is proposed. Experimental results have demonstrated that MIC_Locator can achieve 60.56% subset accuracy on the new multi-label benchmark dataset derived from version 18 of HPA. Different from the reported prediction model, MIC_Locator transforms IHC images into frequency domain to capture more discriminative information, i.e., amplitude, phase and orientation information. In detail, the frequency feature is extracted from the monogenic signal of image based on the different frequency scales. In addition, intensity encoding strategy is employed to provide complementary information. Finally Classifier Chain enables MIC_Locator to enhance the capabilities of handling the multi-labeled dataset efficiently.</p>
    <p id="Par75">In order to evaluate the overall capabilities of the proposed MIC_Locator model objectively, we analyzed the MIC_Locator model from multiple angles: Firstly, integrity evaluation of predictive models under the introduction of frequency domain features and classifier chain architecture in 10 dbs. The proposed MIC_Locator outperformed any other approaches in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. Secondly, independent exploration in-depth of APO components to demonstrated that the P component outperforms A and O components in discriminative ability of prediction model. The relevant experimental results further validate our expectation that the phase information should have a more general meaning in the frequency domain signal; thirdly, study in-depth of the impact of different frequency scales and components on the prediction model, and the decision fusion also considered. Finally, based on all previous results mentioned above, the expanded experiment of the comparison between MIC_Locator and semi-supervised framework was carried out. This is because the high quality dyeing image samples are really limited in the HPA database, and we hope to further improve MIC_Locator. The experimental results show that the combination with the semi-supervised framework is indeed very sensible. Furthermore, we have made efforts on applying CNN into determining subcellular location. Due to the huge loss of gradient information in the high layer of CNN model, it remains a challenge for training a high-performance CNN model. In future work, we plan to develop a CNN model based on the residual network architecture so that the problem of gradient disappearance can be effectively solved.</p>
    <p id="Par76">From the perspective of model application, MIC_Locator can be used to automate annotation of proteins subcellular location, and contribute to revealing protein function. Moreover, the MIC_Locator can provide reliable indication of whether a certain protein is suitable as a cancer biomarker by capturing the transfer among its subcellular locations. Some initial results have been achieved but not reported in this paper.</p>
  </sec>
  <sec id="Sec11">
    <title>Methods</title>
    <sec id="Sec12">
      <title>Benchmark datasets</title>
      <p id="Par77">When it comes to image databases, HPA is undoubtedly one of the most popular protein image data sources in the world in recent years [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR51">51</xref>–<xref ref-type="bibr" rid="CR53">53</xref>]. It is a completely open database that allows academics and industry researchers to freely access to explore all human science issues related to human proteomics. The HPA project originated in 2003 is supported by the Knut and Alice Wallenberg Foundations (KAWF) in Sweden, and has maintained a good tradition of updating at least once a year. Currently, HPA has been updating to version 18, which consists of three separate parts, i.e., the Tissue Atlas (TA) [<xref ref-type="bibr" rid="CR51">51</xref>], the Cell Atlas (CA) [<xref ref-type="bibr" rid="CR2">2</xref>] and Pathology Atlas (PA) [<xref ref-type="bibr" rid="CR52">52</xref>]. In this paper, the benchmark dataset has been collected and collated from TA, which mainly focuses on the expression profiles of human genes at the protein level. The images in this sub-database had derived from antibody-based protein analysis by using immunohistochemistry, and covered 15,273 genes (78%) with available antibodies, and involved a total of 44 normal tissues in humans.</p>
      <p id="Par78">The collation and verification of the benchmark dataset are critical to the construction of the predictive model. Hence, a carefully checking task has been carried out on the corresponding benchmark dataset of two published papers [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>]. These benchmark datasets derive from published literature in [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>], which are respectively single-label dataset and multi-label dataset and has been used in references [<xref ref-type="bibr" rid="CR15">15</xref>, <xref ref-type="bibr" rid="CR40">40</xref>]. The benchmark datasets in [<xref ref-type="bibr" rid="CR16">16</xref>] based on the early version of HPA database, and the other benchmark datasets proposed by the Xu et al. [<xref ref-type="bibr" rid="CR17">17</xref>] are collected from the 12 version of HPA database.</p>
      <p id="Par79">The comparison between two reported benchmark datasets and protein subcellular localization annotation on the version 18 of HPA has been summarized in Table <xref rid="Tab5" ref-type="table">5</xref>.
<table-wrap id="Tab5"><label>Table 5</label><caption><p>The change of subcellular locations annotation of benchmark datasets in version 18 of HPA</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2"/><th colspan="4">The number of proteins.</th></tr><tr><th>Total</th><th>Location Consistently</th><th>Location Missing</th><th>Location Transfer</th></tr></thead><tbody><tr><td>Xu et al. [<xref ref-type="bibr" rid="CR17">17</xref>].</td><td char="." align="char">28</td><td>8</td><td>1</td><td>19</td></tr><tr><td>Murhpy et al. [<xref ref-type="bibr" rid="CR16">16</xref>].</td><td char="." align="char">16</td><td>4</td><td>2</td><td>10</td></tr></tbody></table></table-wrap></p>
      <p id="Par80">These update of two reported benchmark datasets about protein subcellular localization annotation on the version 18 of HPA has been summarized in the Table <xref rid="Tab5" ref-type="table">5</xref>. As we are concerned, these datasets can no longer be used as benchmark datasets because the label information in these datasets has been updated by HPA. Furthermore, labels of some protein images are completely different with those of the original dataset. For example, the subcellular localization of Arylsulfatase B protein has been updated from the “lysosome” to the “Golgi apparatus” [<xref ref-type="bibr" rid="CR2">2</xref>]; the subcellular location of protein HSPA5 belongs “ER” subcellular location in the [<xref ref-type="bibr" rid="CR2">2</xref>], while its subcellular localizations changes in “Cytosol” in the version 18 of HPA. This is how we are motivated; an updating IHC benchmark dataset is collected and collated based on the latest version of HPA.</p>
      <p id="Par81">In addition, each image in HPA has two criterion scores, i.e., reliability score and protein expression level. Both of them play a crucial role in collected a reliable benchmark dataset. The reliability scores are divided into four types, i.e., “Enhanced”, “Supported”, “Approved”, and “Uncertain”. The four types indicate the level of reliability of the analyzed protein expression pattern based on available RNA-seq data, protein or gene characterization data and immunohistochemical data from one or several antibodies with non-overlapping epitopes. For example, the type “Enhanced” is the strictest index among these four reliability score indexes, which not only take the consistency of annotation with other available databases but also utilized the orthogonal or independent antibody validation method. Protein expression level denotes to the protein staining extent of target IHC image, and is divided into four patterns, i.e., “high”, “medium”, “low” and “not detected”. For example, the pattern “high” denotes to the best expression level of protein channel in the target IHC image. To better describe the difference between different protein expression levels, we listed several images with seven subcellular localizations and protein expression levels in Fig. <xref rid="Fig6" ref-type="fig">6</xref>.
<fig id="Fig6"><label>Fig. 6</label><caption><p>Visual differences of protein images under different subcellular locations and protein expression levels</p></caption><graphic xlink:href="12859_2019_3136_Fig6_HTML" id="MO6"/></fig></p>
      <p id="Par82">In this paper, a benchmark image dataset with a total number of 3420 is prepared in consideration of both “Enhanced” and “high” criteria based on version 18 of HPA. The number of proteins with single-label and multi-label are 55 and 25, and the number of images with single-label and multi-label are 2413 and 827. The proportion of protein with multi-label nearly occupies 30%, and the proportion of image with multi-label closes to 25%. The number of the corresponding subcellular organelles is 7, namely “Cytosol”, “Endoplasmic reticulum”, “Golgi apparatus”, “Nucleoli”, “Mitochondria”, “Nucleus”, “Vesicles”. In the process of collecting and collating our benchmark dataset, the same data structure as [<xref ref-type="bibr" rid="CR17">17</xref>] is followed, namely 70% single-labeled proteins and 30% multi-labeled proteins, which has been listed in Table <xref rid="Tab6" ref-type="table">6</xref>.
<table-wrap id="Tab6"><label>Table 6</label><caption><p>The distribution of protein and image with single-label and multi-label in the benchmark dataset</p></caption><table frame="hsides" rules="groups"><thead><tr><th>New Benchmark dataset</th><th>Total</th><th>Single-label</th><th>Multi-label</th></tr></thead><tbody><tr><td>Proteins</td><td>80</td><td>55</td><td>25</td></tr><tr><td>Images</td><td>3240</td><td>2413</td><td>827</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec13">
      <title>IHC image preprocessing</title>
      <p id="Par83">Different from natural and facial images, the preprocessing of IHC protein images requires a separation of protein channel from original IHC image rather than image rectification or illumination normalization. Each IHC image in HPA contains both DNA and protein components, to which correspond purple and brown color respectively, and photographed by an RGB camera. Hence, the three most important steps in the preprocessing of IHC image can be summarized as follows. Firstly, the transform stage, the original IHC protein image is transformed from RGB space to HSV space, and then filtering at hue level. Secondly, the filtering stage, a certain threshold named dyed index (DI) is employed to filter out badly dyed images, and is fixed at 13 in general [<xref ref-type="bibr" rid="CR16">16</xref>]. Thirdly, separation stage, linear separated method is employed to achieve precise separation at signal and numerical levels [<xref ref-type="bibr" rid="CR54">54</xref>].</p>
    </sec>
    <sec id="Sec14">
      <title>Traditional feature</title>
      <p id="Par84">In the field of protein subcellular localization prediction, there are numerous image features regarded as the excellent feature for the IHC image, such as LBP [<xref ref-type="bibr" rid="CR42">42</xref>], CLBP [<xref ref-type="bibr" rid="CR44">44</xref>] and SLFs [<xref ref-type="bibr" rid="CR31">31</xref>]. LBP calculates the gray value of center pixel with the neighboring pixels as statistic information for a target image. CLBP adds coding the property of center pixels on the basis of LBP. The Haralick texture and DNA spatial distribution feature are one of the most discriminative features of SLFs to describe the IHC image from a global perspective, and it has been widely used in many works and has validated its high-performance [<xref ref-type="bibr" rid="CR15">15</xref>–<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR34">34</xref>, <xref ref-type="bibr" rid="CR40">40</xref>, <xref ref-type="bibr" rid="CR41">41</xref>]. In this paper, the SLFs feature, derived from the combination of Haralick feature and the DNA distribution feature, is unified into global feature in total 840-dimension [<xref ref-type="bibr" rid="CR54">54</xref>]. The employment of wavelet transformation has played a positive role in global feature quantization and extraction of IHC images. It has been demonstrated that frequency domain information has certain advantages in describing global feature of IHC images.</p>
      <p id="Par85">However, most research papers prefer to employ an image descriptor to extract features from target protein images in the spatial domain because they only focus on the image properties of digital signals, and ignore the signal properties of its own [<xref ref-type="bibr" rid="CR55">55</xref>, <xref ref-type="bibr" rid="CR35">35</xref>]. Richer information can be observed through signal processing, for example, transforming the target signal from the spatial domain to the frequency domain.</p>
      <p id="Par86">In this paper, frequency feature of IHC image is extracted from these three components of monogenic signal of image based on different frequency scales rather than grey level information, while Haralick features and DNA distribution features being employed to describe the IHC image as the complementary global feature.</p>
    </sec>
    <sec id="Sec15">
      <title>Local image descriptor extraction on frequency domain</title>
      <p id="Par87">Although the conventional features, such as SLFs, LBP, CLBP, can describe the IHC image to some extent. However, local information of IHC image especially in amplitude, phase and orientation aspects are not well mined. In this paper, the target IHC image is transformed into the frequency domain from the spatial domain by the fast fourier transform (FFT). And then, the Riesz transformation is employed to generate the corresponding monogenic signal in frequency domain, which composes three parts i.e., a real part and two imaginary parts. The three parts can be considered as original frequency information and two frequency response parts in signal processing. In order to understand in-depth the protein image signal, Log-Gabor is employed to filter with different frequency scales because it not only inherits the essential property of traditional Gabor filter reflecting the information of specific frequency band in a specific direction but also avoid the influence of DC signal [<xref ref-type="bibr" rid="CR56">56</xref>]. By using Log-Gabor filter with different frequency scales, local frequency information, which distributes in different frequency bands, can be captured and extracted [<xref ref-type="bibr" rid="CR57">57</xref>]. Finally, the three parts of different frequency scales are transformed back to the spatial domain respectively.</p>
      <p id="Par88">Since the monogenic signal consists of a real part and two imaginary parts, it is numerically unsuitable for feature extraction of the target signal. Hence, some numerical operations have been done on these three parts so that it can provide more information about the original signal, for example, amplitude (A), phase (P) and orientation (O), and the corresponding formula is given by formula (<xref rid="Equ4" ref-type="">4</xref>, <xref rid="Equ5" ref-type="">5</xref>, <xref rid="Equ6" ref-type="">6</xref>). The A component can well represent the edge and contour information of each IHC image, and the P component can well represent structural information and the O component can reflect the geometry information. And then, an efficient 8-bit LBP coding strategy is used to extract the statistic features of three components. Besides, these two imaginary parts are compared with a threshold 0, and generating the 2-bits binary code is considered as the image intensity code. Finally, the image intensity coding and LBP are combined as the 1024-dimension local image descriptor. The Haralick feature united the local image descriptor as a sample feature of 1864-dimension, feeding into CC to construct the prediction model. The details of local image descriptor coding have been described in the next section. Finally, the average and weighted ensemble method are employed to fuse the probability scores at prediction level. The top and threshold criteria are proposed to give the final decision of subcellular locations. The flowchart of proposed MIC_Locator is shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>. The meaning of the proposed prediction model, MIC_Locator, can be summarized as follows: letter “M” denotes to monogenic signal; letter “I” denotes to image intensity coding strategy; letter “C” represents to classifier chain; word “Locator” stands for the goal of subcellular localization.
<fig id="Fig7"><label>Fig. 7</label><caption><p>The flowchart of proposed MIC_Locator. The IHC image is selected from gene “ENSG00000013364”. The corresponding number of IHC image is “6980_A_4_6”, and it belongs to the “Cytosol” subcellular location. In the preprocess stage, the DNA and protein channel of protein are separated. On the one hand, the DNA and protein channel are used to extract the 840-dimension SLFs feature. On the other hand, the protein channel is transformed into the frequency domain by the Fourier transform. The frequency information of protein is multiplied by the Riesz transform, generating two frequency responses in orthogonal directions. The frequency information of protein and two frequency response parts of Riesz transform are multiplied by the Log-Gabor filter with multi-scale frequency factor. Afterwards, the protein information and two frequency response parts are transformed into the spatial domain, which commonly consist of the monogenic signal of protein. The APO components of image monogenic signal are calculated. The 8-bits LBP code extracts the statistic information of APO component, and the 2-bits image intensity code is calculated from the two imaginary parts of monogenic signal by the formula (<xref rid="Equ19" ref-type="">19</xref>). The LBP, image intensity and SLFs are united as the final 1864-dimension sample feature, feeding into the CC. The top and threshold criteria are applied to judge the subcellular localizations of test sample</p></caption><graphic xlink:href="12859_2019_3136_Fig7_HTML" id="MO7"/></fig></p>
    </sec>
    <sec id="Sec16">
      <title>APO components generation of monogenic signal</title>
      <p id="Par89">Frequency domain signal analysis (FDSA), as one of the most important approaches in the field of signal processing, can show in depth how many sub-signals lie within each given frequency band over a range of frequencies, and these different frequencies can well represent approximate information and detailed information of the original signal. At the level of mathematical analysis, the primary purpose of FDSA is to obtain the analytic signal of target signal, for example, the combination of a 2-D signal with the Riesz transformed one yields a sophisticated 2-D analytic signal. The analytic signal approach was introduced by Felsberg M, Sommer G in 2001 [<xref ref-type="bibr" rid="CR46">46</xref>] and has been widely applied to many fields, such as medical image analysis [<xref ref-type="bibr" rid="CR58">58</xref>] and synthetic-aperture radar (SAR) image recognition [<xref ref-type="bibr" rid="CR59">59</xref>].</p>
      <p id="Par90">In this paper, Riesz transform, defined as a high-dimension generalization of the Hilbert transform, is employed to transform the original signal into a new signal on a 2-D complex plane. In 2-D plane, the Riesz transform can be expressed as follow.
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {S}_R{(p)}_{x,y}=\left(\begin{array}{c}{S}_x(p)\\ {}{S}_y(p)\end{array}\right)=\left(\begin{array}{c}{h}_x\ast s(p)\\ {}{h}_y\ast s(p)\end{array}\right) $$\end{document}</tex-math><mml:math id="M2" display="block"><mml:msub><mml:mi>S</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mtable columnalign="center"><mml:mtr><mml:mtd><mml:msub><mml:mi>S</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>S</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mtable columnalign="center"><mml:mtr><mml:mtd><mml:msub><mml:mi>h</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>∗</mml:mo><mml:mi>s</mml:mi><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>h</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>∗</mml:mo><mml:mi>s</mml:mi><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <italic>s</italic>(<italic>p</italic>) denotes to the original or target signal. X and Y are the two orthogonal directions of the 2-D complex plane, and the entire 2-D Hilbert space has been spanned by Riesz transform. <italic>h</italic><sub><italic>x</italic></sub> and <italic>h</italic><sub><italic>y</italic></sub> is defined as Hilbert transform factor, and the corresponding Fourier transform can be defined as <italic>H</italic><sub><italic>x</italic></sub> =  − <italic>jw</italic><sub><italic>x</italic></sub>/‖<italic>ω</italic>‖ and <italic>H</italic><sub><italic>y</italic></sub> =  − <italic>jw</italic><sub><italic>y</italic></sub>/‖<italic>ω</italic>‖ with the angular frequency <italic>ω</italic> = (<italic>ω</italic><sub><italic>x</italic></sub>, <italic>ω</italic><sub><italic>y</italic></sub>). The character <italic>R</italic> of <italic>S</italic><sub><italic>R</italic></sub>(<italic>p</italic>)<sub><italic>x</italic>, <italic>y</italic></sub> symbolizes the Riesz transform or 2-D Hilbert transform of image. The Riesz transform kernel is defined as follow.
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \left({h}_x,{h}_y\right)=\left(\frac{x}{2\pi {\left\Vert p\right\Vert}^3},\frac{y}{2\pi {\left\Vert p\right\Vert}^3}\right) $$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mfenced close=")" open="(" separators=","><mml:msub><mml:mi>h</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close=")" open="(" separators=","><mml:mfrac><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mfenced close="‖" open="‖"><mml:mi>p</mml:mi></mml:mfenced><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mfrac><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mfenced close="‖" open="‖"><mml:mi>p</mml:mi></mml:mfenced><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par91">Thus, for target signal <italic>s</italic>(<italic>p</italic>), the corresponding monogenic signal is defined as follow:
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {S}_M{(P)}_{x,y}=\left(S(p),{S}_x(p),{S}_y(p)\right) $$\end{document}</tex-math><mml:math id="M6" display="block"><mml:msub><mml:mi>S</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:msub><mml:mfenced close=")" open="("><mml:mi>P</mml:mi></mml:mfenced><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close=")" open="(" separators=",,"><mml:mrow><mml:mi>S</mml:mi><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>where <italic>S</italic>(<italic>p</italic>) denotes to the real part of the monogenic signal. <italic>S</italic><sub><italic>x</italic></sub>(<italic>p</italic>) and <italic>S</italic><sub><italic>y</italic></sub>(<italic>p</italic>) are the two imaginary parts along the X-axis and Y-axis direction respectively. Finally, the APO components can be obtained by using formula (<xref rid="Equ4" ref-type="">4</xref>, <xref rid="Equ5" ref-type="">5</xref>, <xref rid="Equ6" ref-type="">6</xref>).
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ A=\sqrt{S^2+{S}_x^2+{S}_y^2} $$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mi>S</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \phi =\mathrm{atan}2\left(\sqrt{S_y^2+{S}_x^2}/S\right) $$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mi>ϕ</mml:mi><mml:mo>=</mml:mo><mml:mtext>atan</mml:mtext><mml:mn>2</mml:mn><mml:mfenced close=")" open="("><mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt><mml:mo>/</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \theta =\mathrm{atan}2\left({S}_x/{S}_y\right) $$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mtext>atan</mml:mtext><mml:mn>2</mml:mn><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par92">The function atan(x/y) presents the arctan(x/y) function, and the value range of the function atan(x/y) arranges [−<italic>pi</italic>/2, <italic>pi</italic>/2] and covers two quadrants. In contrast, the value range of function atan2(<italic>x</italic>, <italic>y</italic>) is [−<italic>pi</italic>, <italic>pi</italic>] covering four quadrants, and the value of element in these PO components same belongs [−<italic>pi</italic>, <italic>pi</italic>]. Hence, the function atan2(<italic>x</italic>, <italic>y</italic>) is employed to calculate the value of element these PO components. Where A denotes to amplitude (A) component, and <italic>ϕ</italic> denotes to phase (P) component, and <italic>θ</italic> denotes to orientation (O) component.</p>
    </sec>
    <sec id="Sec17">
      <title>Multi-scale monogenic signal representation</title>
      <p id="Par93">It is well known that the representation of target signal in frequency domain is much more explicit than spatial domain because the energy of target signal is more concentrated in frequency domain. Furthermore, this is benefited by the multi-scale decomposition of target signal in frequency domain. For example, the interested region of image in spatial domain, such as patches consisting of contour or edge information, can be easily captured and represented in the frequency domain. Inspired by this, the Log-Gabor filter with the logarithmic mapping function is employed to achieve multi-scale decomposition in this paper. The advantage of the Log-Gabor filter is a more desirable frequency response especially in the high-frequency band while comparing with the traditional Gabor filter [<xref ref-type="bibr" rid="CR57">57</xref>]. Moreover, the Log-Gabor filter can avoid the influence of DC, which limits the bandwidth of band-pass filter. The definition of the Log-Gabor filter is shown as follow.
<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ G\left(\omega \right)=\exp \left\{-{\left[\mathrm{Log}\left(\omega /{\omega}_0\right)\right]}^2/2{\left[\mathrm{Log}\left(\sigma /{\omega}_0\right)\right]}^2\right\} $$\end{document}</tex-math><mml:math id="M14" display="block"><mml:mi>G</mml:mi><mml:mfenced close=")" open="("><mml:mi>ω</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mo>exp</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mfenced close="]" open="["><mml:mrow><mml:mi>Log</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>ω</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mfenced close="]" open="["><mml:mrow><mml:mi>Log</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>σ</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\omega}_0={\left(\lambda {k}^{r-1}\right)}^{-1} $$\end{document}</tex-math><mml:math id="M16" display="block"><mml:msub><mml:mi>ω</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>λ</mml:mi><mml:msup><mml:mi>k</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>where <italic>ω</italic><sub>0</sub> denotes to the center frequency. The <italic>λ</italic> is defined as the setting minimum wavelength, and it is set 4. The <italic>k</italic> is the multiply factor of wavelength, which equals 1.7. The <italic>σ</italic>/<italic>ω</italic><sub>0</sub> is set as a constant value to make the Log-Gabor with a constant shape ratio, which is set 0.64. The <italic>r</italic> is the scale index, and its intervals are from 1 to 5. The parameters are set according to the recommendation in [<xref ref-type="bibr" rid="CR47">47</xref>] and our own experiments result.</p>
      <p id="Par94">With changing the frequency scale factors from 1 to 5, the frequency response of Log-Gabor filter has been shown in Fig. <xref rid="Fig8" ref-type="fig">8</xref>. Specifically, the center region is caved in the frequency response of Log-Gabor filter. The phenomenon denotes to the current direct by avoided, and the low frequency information can be restrained. Meanwhile, with the frequency scale increase, the frequency response of Log-Gabor filter in high frequency band can be apparently improved.
<fig id="Fig8"><label>Fig. 8</label><caption><p>The frequency response of Log-Gabor filter with different frequency scale factors. <bold>a</bold>, <bold>b</bold> and <bold>c</bold> Respectively present the frequency response of Log-Gabor filter based on the frequency scale factor 1, 3 and 5</p></caption><graphic xlink:href="12859_2019_3136_Fig8_HTML" id="MO8"/></fig></p>
      <p id="Par95">Then, the band-pass monogenic signal is obtained by making the convolution of original signal and Log-Gabor, which has been shown in the formula (<xref rid="Equ9" ref-type="">9</xref>).
<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {S}_{LG-M}\left(\mathrm{p}\right)=\left({S}_{LG}(p),{S}_{LG-\mathrm{x}}(p),{S}_{LG-y}(p)\right)=\left({S}_{LG}(p),{h}_x\ast {S}_{LG}(p),{h}_y\ast {S}_{LG}(p)\right) $$\end{document}</tex-math><mml:math id="M18" display="block"><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi mathvariant="normal">p</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close=")" open="(" separators=",,"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi mathvariant="italic">LG</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close=")" open="(" separators=",,"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi mathvariant="italic">LG</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>∗</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi mathvariant="italic">LG</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>∗</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi mathvariant="italic">LG</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {S}_{LG}(p)=S(p)\ast {F}^{- 1}\left(G\left(\omega \right)\right) $$\end{document}</tex-math><mml:math id="M20" display="block"><mml:msub><mml:mi>S</mml:mi><mml:mi mathvariant="italic">LG</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced><mml:mo>∗</mml:mo><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn mathvariant="italic">1</mml:mn></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>G</mml:mi><mml:mfenced close=")" open="("><mml:mi>ω</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {S}_{LG-x}(p)={h}_x\ast {S}_{LG}(p) $$\end{document}</tex-math><mml:math id="M22" display="block"><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>∗</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi mathvariant="italic">LG</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {S}_{LG-y}(p)={h}_y\ast {S}_{LG}(p) $$\end{document}</tex-math><mml:math id="M24" display="block"><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>∗</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi mathvariant="italic">LG</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>p</mml:mi></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par96">In formula (<xref rid="Equ10" ref-type="">10</xref>), the <italic>F</italic><sup>−<italic>1</italic></sup> denotes to the 2D inverse Fourier transform, and <italic>S</italic><sub><italic>LG</italic></sub>(<italic>p</italic>) is the real part of monogenic signal convolving the Log-Gabor filter. The <italic>S</italic><sub><italic>LG</italic> ‐ <italic>x</italic></sub>(<italic>p</italic>) is the X-direction imaginary part of monogenic signal convolving the Log-Gabor filter in formula (<xref rid="Equ11" ref-type="">11</xref>), and <italic>S</italic><sub><italic>LG</italic> − <italic>y</italic></sub>(<italic>p</italic>) is the Y-direction imaginary part of monogenic signal convolving the Log-Gabor filter in formula (<xref rid="Equ12" ref-type="">12</xref>). The corresponding APO components are updated as follows.
<disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {A}_{LG}=\sqrt{S_{LG}^2+{S}_{LG-x}^2+{S}_{LG-y}^2} $$\end{document}</tex-math><mml:math id="M26" display="block"><mml:msub><mml:mi>A</mml:mi><mml:mi mathvariant="italic">LG</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi mathvariant="italic">LG</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ14"><label>14</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\phi}_{LG}=\mathrm{atan}2\left(\sqrt{S_{LG-y}^2+{S}_{LG-x}^2}/{S}_{LG}\right) $$\end{document}</tex-math><mml:math id="M28" display="block"><mml:msub><mml:mi>ϕ</mml:mi><mml:mi mathvariant="italic">LG</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>atan</mml:mtext><mml:mn>2</mml:mn><mml:mfenced close=")" open="("><mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt><mml:mo>/</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi mathvariant="italic">LG</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ14.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ15"><label>15</label><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\theta}_{LG}=\mathrm{atan}2\left({S}_{LG-x}/{S}_{LG-y}\right) $$\end{document}</tex-math><mml:math id="M30" display="block"><mml:msub><mml:mi>θ</mml:mi><mml:mi mathvariant="italic">LG</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>atan</mml:mtext><mml:mn>2</mml:mn><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ15.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par97">To represent intuitively, APO components under different scales have been shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>. For A component, it reflects the shape of an image and describes local energetic information. For local phase and orientation component, these two components denote to local structure and geometry information.</p>
    </sec>
    <sec id="Sec18">
      <title>Monogenic signal encoding and feature quantification</title>
      <p id="Par98">An effective encoding method is not only the accurate quantification of the target signal but also can provide more discriminative features to the subsequent classifiers. In this paper, two encoding strategies, i.e., general encoding strategy and intensity encoding strategy, are employed to quantify target IHC image. The former strategy encodes APO components, i.e., <italic>A</italic><sub><italic>LG</italic></sub>
<italic>ϕ</italic><sub><italic>LG</italic></sub> and <italic>θ</italic><sub><italic>LG</italic></sub>, by using traditional LBP encoding method, which calculates the relationship between the center pixel and its surrounding pixels in the target local region. The latter strategy focuses on encoding the variation consistency of two imaginary parts of monogenic signal. Obviously, these two encoding strategies work on the local region of target image, and then perform statistics and quantization. The processing of monogenic signal generation has been shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>, and the details of LBP descriptor can be found in [<xref ref-type="bibr" rid="CR42">42</xref>].</p>
    </sec>
    <sec id="Sec19">
      <title>General encoding strategy of APO components</title>
      <p id="Par99">The traditional LBP encoding strategy has been widely applied in many fields related to image processing, such as cell localization and phenotype recognition due to its simple and efficient characteristics [<xref ref-type="bibr" rid="CR60">60</xref>, <xref ref-type="bibr" rid="CR61">61</xref>]. The corresponding formula is given below.
<disp-formula id="Equ16"><label>16</label><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {K}^{N,r}\left({p}_c\right)=\sum \limits_{i=1}^N{2}^{\left(\mathrm{i}-1\right)}\ast L\left({p}_i-{p}_c\right),\kern1em L(x)=\left\{\begin{array}{cc}1,&amp; x\ge 0\\ {}0,&amp; else\end{array}\right. $$\end{document}</tex-math><mml:math id="M32" display="block"><mml:msup><mml:mi>K</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msup><mml:mn>2</mml:mn><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:msup><mml:mo>∗</mml:mo><mml:mi>L</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>L</mml:mi><mml:mfenced close=")" open="("><mml:mi>x</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close="" open="{"><mml:mtable columnalign="center"><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mtd><mml:mtd><mml:mtext mathvariant="italic">else</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ16.gif" position="anchor"/></alternatives></disp-formula>where <italic>p</italic><sub><italic>c</italic></sub> stands for the center pixel in each local region, and <italic>p</italic><sub><italic>i</italic></sub> denotes to a neighboring pixel. <italic>N</italic> represents the number of neighboring pixels, and <italic>r</italic> denotes to the radius of neighborhood. <italic>L</italic>(<italic>x</italic>) is a symbol function, and the function value is defined as 0 when independent variable is negative. The <italic>K</italic><sup><italic>N</italic>, <italic>r</italic></sup>(<italic>p</italic><sub><italic>c</italic></sub>) presents the LBP coding of each center pixel in spatial domain.</p>
      <p id="Par100">To extract the statistic information of local amplitude, the local amplitude component is normalized to [<italic>0</italic>, <italic>255</italic>]. However, local orientation and local phase components represent an angle with a specific direction, and the corresponding value is ranged from [−<italic>pi</italic>, <italic>pi</italic>], which is unlike with that of local amplitude component. Hence, P and O components are required special numerical coding. The general encoding strategy of APO components can be summarized as follows.</p>
      <sec id="Sec20">
        <title>The encoding strategy of local amplitude component</title>
        <p id="Par101">The local amplitude component represents the energetic information of local region in target IHC image. Hence, taking into account the property of amplitude component, and the interval of local amplitude is normalized to [<italic>0</italic>, <italic>255</italic>]. The standard encoding strategy of LBP is employed to quantize amplitude component feature. In detail, if the grey level of neighbor pixels is larger than the center pixel, and then the value of neighbor pixels is encoded as 1; whereas, the value of neighbor pixels is encoded as 0 if the grey level of neighbor pixels is smaller than the grey level of center pixel. The coding process of amplitude component has been shown in Fig. <xref rid="Fig9" ref-type="fig">9</xref>.
<fig id="Fig9"><label>Fig. 9</label><caption><p>The LBP coding process of amplitude component in a local patch. The starting point of the LBP coding is in the lower right corner and encoded in a clockwise direction</p></caption><graphic xlink:href="12859_2019_3136_Fig9_HTML" id="MO9"/></fig></p>
      </sec>
      <sec id="Sec21">
        <title>The encoding strategy of local phase and orientation components</title>
        <p id="Par102">Different from amplitude component in the monogenic signal, the elements of phase and orientation component range in value from [−<italic>pi</italic>, <italic>pi</italic>]. Considering the physical meaning of local orientation and local phase, namely, the different value of local orientation and the local phase is associated with the corresponding types of feature. For example, two phases are close to 0, which presents that feature type of two elements is similar and belongs step edge; two orientations are close, and it means that the gradient direction of two elements are almost along a same direction.</p>
        <p id="Par103">Therefore, a quadrant encoding strategy is employed in this study. In detail, each element of local orientation and phase component is normalized to [<italic>0</italic>, <italic>359</italic>]. Then, we divided the range of [<italic>0</italic>, <italic>359</italic>] into M intervals (M = 4 while set quadrant encoding), i.e., [<italic>0</italic>, <italic>89</italic>), [<italic>90</italic>, <italic>179</italic>), [<italic>180</italic>, <italic>269</italic>) and [<italic>270</italic>, <italic>359</italic>), and the corresponding value falling in each interval is encoded as “0”, “1”, “2” and “3” respectively.</p>
        <p id="Par104">Obviously, each quadrant coding is different from others, and related to different types of feature described in [<xref ref-type="bibr" rid="CR47">47</xref>], for example, different phase angles. The coding formulas of the local phase and orientation component are given as follows.
<disp-formula id="Equ17"><label>17</label><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {X}_i\left({p}_c\right)=\left\{\begin{array}{cc}0&amp;\ if\ Q\left(\Phi \left({p}_c\right)\right)=Q\left(\Phi \left({p}_i\right)\right)\\ {}1&amp; else\end{array}\right. $$\end{document}</tex-math><mml:math id="M34" display="block"><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close="" open="{"><mml:mtable columnalign="center"><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mspace width="0.25em"/><mml:mtext mathvariant="italic">if</mml:mtext><mml:mspace width="0.25em"/><mml:mi>Q</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>Q</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mtext mathvariant="italic">else</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ17.gif" position="anchor"/></alternatives></disp-formula>
<disp-formula id="Equ18"><label>18</label><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ Q(Deg)=p,\kern0.5em if\ \frac{360\cdot \left(p-1\right)}{M}\le Deg&lt;\frac{360\cdot p}{M}\kern0.5em $$\end{document}</tex-math><mml:math id="M36" display="block"><mml:mi>Q</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="italic">Deg</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:mtext mathvariant="italic">if</mml:mtext><mml:mspace width="0.25em"/><mml:mfrac><mml:mrow><mml:mn>360</mml:mn><mml:mo>⋅</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:mrow><mml:mi>M</mml:mi></mml:mfrac><mml:mo>≤</mml:mo><mml:mi mathvariant="italic">Deg</mml:mi><mml:mo>&lt;</mml:mo><mml:mfrac><mml:mrow><mml:mn>360</mml:mn><mml:mo>⋅</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mi>M</mml:mi></mml:mfrac><mml:mspace width="0.5em"/></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ18.gif" position="anchor"/></alternatives></disp-formula></p>
        <p id="Par105">For the orientation and phase components, Φ(<italic>p</italic><sub><italic>c</italic></sub>) represents the value of each center pixel <italic>p</italic><sub><italic>c</italic></sub>, and Φ(<italic>p</italic><sub><italic>i</italic></sub>) represents the value of neighboring pixel <italic>p</italic><sub><italic>i</italic></sub>. Meanwhile, the formula (<xref rid="Equ18" ref-type="">18</xref>) is the quantification of local phase and orientation. The coding process of phase and orientation component has been shown in Fig. <xref rid="Fig10" ref-type="fig">10</xref>.
<fig id="Fig10"><label>Fig. 10</label><caption><p>An example of encoding phase and orientation components of monogenic signal. The value of phase and orientation component is converted into four intervals, and four intervals present different types of feature. Afterwards, the LBP of phase and orientation components is generated, and LBP code begins to generate from the bottom right corner in clockwise direction</p></caption><graphic xlink:href="12859_2019_3136_Fig10_HTML" id="MO10"/></fig></p>
      </sec>
    </sec>
    <sec id="Sec22">
      <title>Image intensity encoding strategy</title>
      <p id="Par106">Inspired by the characteristics of CLBP feature [<xref ref-type="bibr" rid="CR44">44</xref>], taking the property of center pixel into account, an encoding strategy named intensity encoding is proposed to generate a complementary feature coding for LBP coding of APO components.</p>
      <p id="Par107">The two imaginary parts originated from the monogenic signal of protein channel can be considered as the representation of each target IHC image in 2-D Hilbert space. Hence, the variation consistency of two imaginary parts of monogenic signal is captured and encoded as a 2-bits code corresponding to 4 patterns, which has been shown as follow.
<disp-formula id="Equ19"><label>19</label><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \left[{C}_x^I\left({p}_c\right),{C}_y^I\left({p}_c\right)\right]=\left\{\begin{array}{cc}00&amp; if\kern0.5em {S}_{LG-x}\left({p}_c\right)&gt;0\ \mathrm{and}\ {S}_{LG-y}\left({p}_c\right)&gt;0\\ {}10&amp; if\kern0.5em {S}_{LG-x}\left({p}_c\right)&lt;0\ \mathrm{and}\kern0.5em {S}_{LG-y}\left({p}_c\right)&gt;0\\ {}11&amp; if\kern0.5em {S}_{LG-x}\left({p}_c\right)&lt;0\ \mathrm{and}\ {S}_{LG-y}\left({p}_c\right)&lt;0\\ {}01&amp; if\kern0.5em {S}_{LG-x}\left({p}_c\right)&gt;0\ \mathrm{and}\ {S}_{LG-y}\left({p}_c\right)&lt;0\end{array}\right. $$\end{document}</tex-math><mml:math id="M38" display="block"><mml:mfenced close="]" open="[" separators=","><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mi>x</mml:mi><mml:mi>I</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced></mml:mrow><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mi>y</mml:mi><mml:mi>I</mml:mi></mml:msubsup><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced close="" open="{"><mml:mtable columnalign="center"><mml:mtr><mml:mtd><mml:mn>00</mml:mn></mml:mtd><mml:mtd><mml:mtext mathvariant="italic">if</mml:mtext><mml:mspace width="0.5em"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.25em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.25em"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>10</mml:mn></mml:mtd><mml:mtd><mml:mtext mathvariant="italic">if</mml:mtext><mml:mspace width="0.5em"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.25em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.5em"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>11</mml:mn></mml:mtd><mml:mtd><mml:mtext mathvariant="italic">if</mml:mtext><mml:mspace width="0.5em"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.25em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.25em"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>01</mml:mn></mml:mtd><mml:mtd><mml:mtext mathvariant="italic">if</mml:mtext><mml:mspace width="0.5em"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.25em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.25em"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">LG</mml:mi><mml:mo>−</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="("><mml:msub><mml:mi>p</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mfenced><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ19.gif" position="anchor"/></alternatives></disp-formula>where <italic>S</italic><sub><italic>LG</italic> − <italic>x</italic></sub> and <italic>S</italic><sub><italic>LG</italic> − <italic>y</italic></sub> (refer to formula <xref rid="Equ9" ref-type="">9</xref>) please) are the two imaginary parts of monogenic signal. Comparing these two imaginary parts of monogenic signal with the threshold 0, the 2-bits image intensity code can be generated, “00”, “10”, “11” and “01”, and the process of image intensity coding have been shown in Fig. <xref rid="Fig11" ref-type="fig">11</xref>.
<fig id="Fig11"><label>Fig. 11</label><caption><p>The image intensity coding process of center pixel in frequency domain. The two imaginary parts of monogenic signal in the X and Y direction are compared to the threshold value 0. The comparison result is mapped into the four quadrants, and four quadrants respectively stand for four 2-bits codes, “00”, “10”, “11” and “01”, as the image intensity code. As the value of X-direction and Y-direction imaginary part are 0.24 and − 2.4, the image intensity binary code of element is “01”</p></caption><graphic xlink:href="12859_2019_3136_Fig11_HTML" id="MO11"/></fig></p>
    </sec>
    <sec id="Sec23">
      <title>The qualitative analysis of image intensity encoding strategy</title>
      <p id="Par108">The characteristics of Hilbert transformation is phase shift 90 degree based on the original signal, and the Riesz transform consists of two Hilbert transform in X and Y directions. Hence, the monogenic signal can be presented in a spherical coordinate system. These two imaginary parts of monogenic signal along the X and Y direction can be regarded as the X-axis and Y-axis of spherical coordinate system, and the Z-axis is equal to the real part of monogenic signal. The spherical coordinate system representation of monogenic signal has been shown in Fig. <xref rid="Fig12" ref-type="fig">12</xref>. Samples contribute in the surface of spherical coordinate system, and these components of monogenic signal can be calculated. For instance, a given sample X1, the amplitude component of X1 is the distance of X1 and the origin, which is presented as the A1 and is remarked by the red. The phase component is an angle between the Z-axis and the amplitude component A1, which is P1 and remarked by the green color. The orientation component of sample is an angle between the imaginary part in Y-direction and the projection of A1 in the XY plane, such as O1 which belongs to the orientation components of X1 and remarked by the blue color. Supposing the sample X2 is generated by rotating the sample X1 with 90 degree in the anticlockwise, and the rotation is remarked by the yellow color. Then the three components of sample X2 are generated, A2, P2 and O2. It is considerably obvious that values of A2 and P2 are same as these A1 and P1, and the O2 and O1 are various. The similar APO components value of sample easily leads the prediction model lacking the discriminative and generation ability. The key problem is how to distinguish these similar samples in the entirely spherical system, such as X1 and X2.
<fig id="Fig12"><label>Fig. 12</label><caption><p>The spherical coordinate system representation of monogenic signal. The z-axis is the real part of monogenic signal. The X-axis and Y-axis are respectively the two imaginary parts of monogenic signal in the X and Y direction. In the Spherical coordinate system, these are four regions dividing into 4 regions according to the formula (<xref rid="Equ19" ref-type="">19</xref>). The X1 is a sample in region 1, and its amplitude, phase and orientation are A1, P1 and O1 which are respectively marked by the red, green and blue. The X2 is generated by rotating the X1 90 degree in an anti-clockwise direction located in region 4, and the rotation direction is presented by the yellow color. These amplitude, phase and orientation components of X2 are A2, P2 and O2, where A2, P2 and O2 components are respectively marked by the red, green and blue</p></caption><graphic xlink:href="12859_2019_3136_Fig12_HTML" id="MO12"/></fig></p>
      <p id="Par109">In this study, the spherical system is divided into four regions. The X-axis and Y-axis of spherical coordinate system is the X-direction and Y-direction of imaginary part of monogenic signal. By the formula (<xref rid="Equ19" ref-type="">19</xref>), these four regions respectively response to these four image intensity codes, “00”, “01”, “11” and “01”. By coding the image intensity, X1 and X2 can be distinguished. Such as the X1 in the region 1 and the X2 in the region 4, and the image intensity code respectively is “00” and “01”. The 2-bits image intensity code is concatenated on 8-bit LBP as a final 10-bit local image descriptor.</p>
    </sec>
    <sec id="Sec24">
      <title>Chains classification and fusing strategy of prediction model</title>
      <p id="Par110">As the aforementioned, the local image descriptor consists of the LBP code in these three APO components and image intensity code, and the 1864-dimension sample feature is formed by combining the local image descriptor and global image feature (SLFs features). The stepwise discriminant analysis (SDA) feature selection method is used to select the discriminative feature subset from the original feature space, which uses the Wilks’ λ statistic to iteratively judge which features are the most discriminating. The selected feature subset is fed into the CC. Considering the correlation of labels in the multi-label datasets, the classifier chain approach is employed to handle multi-label datasets classification. The CC consists of several binary SVM classifications, and the probability score of previous SVM outputs is added into the feature space in the next SVM classification so that CC can capture the correlation of label.</p>
      <p id="Par111">Under the different APO components and the frequency scales factors of Log-Gabor, constructing the prediction model is presented MIC_Locator<sup>X_S (</sup>the x is A, P and O components; S denotes to the frequency scale factor Log-Gabor from 1 to 5). Because prediction model with the various frequency scale factor S, namely MIC_Locator<sup>A_1</sup>, MIC_Locator<sup>A_2</sup>, MIC_Locator<sup>A_3</sup>, MIC_Locator<sup>A_4</sup> and MIC_Locator<sup>A_5</sup>, has various discriminative for information distributing in different frequency bands, the average ensemble approach is used to sum the seven prediction probability scores of MIC_Locator<sup>X_S</sup> in each component. The MIC_Locator<sup>X_E</sup> is an ensemble prediction model based on three components, and X denotes to amplitude, phase or orientation components.</p>
      <p id="Par112">Finally, we summed the probabilities value deriving from the three ensemble prediction models of monogenic components. As the amplitude, phase and orientation component of monogenic signal mainly reflects the local energetic information, the local structural and the local geometric information along main orientation respectively, and the phase and orientation components can describe the image texture superior to the amplitude component. The weighted ensemble algorithm is applied to fuse these three prediction models based on the APO components. The formula of weighted ensemble algorithm has been shown as follow:
<disp-formula id="Equ20"><label>20</label><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {S}_{FDI\_ PSL}=\left(1-2\ast w\right)\ast {S}_{\mathrm{MIC}\_{Locator}^{A\_E}}+w\ast {S}_{\mathrm{MIC}\_{Locator}^{P\_E}}+w\ast {S}_{\mathrm{MIC}\_{Locator}^{O\_E}} $$\end{document}</tex-math><mml:math id="M40" display="block"><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi mathvariant="italic">FDI</mml:mi><mml:mo>_</mml:mo><mml:mi mathvariant="italic">PSL</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>∗</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mfenced><mml:mo>∗</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>MIC</mml:mi><mml:mo>_</mml:mo><mml:msup><mml:mtext mathvariant="italic">Locator</mml:mtext><mml:mrow><mml:mi>A</mml:mi><mml:mo>_</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mo>∗</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>MIC</mml:mi><mml:mo>_</mml:mo><mml:msup><mml:mtext mathvariant="italic">Locator</mml:mtext><mml:mrow><mml:mi>P</mml:mi><mml:mo>_</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>w</mml:mi><mml:mo>∗</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>MIC</mml:mi><mml:mo>_</mml:mo><mml:msup><mml:mtext mathvariant="italic">Locator</mml:mtext><mml:mrow><mml:mi>O</mml:mi><mml:mo>_</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:math><graphic xlink:href="12859_2019_3136_Article_Equ20.gif" position="anchor"/></alternatives></disp-formula>where <italic>W</italic> is the weight and is set 0.43. The extensive experiment of selecting <italic>W</italic> has been shown in Fig. <xref rid="Fig12" ref-type="fig">12</xref> and in the next section. By the formula (<xref rid="Equ20" ref-type="">20</xref>), we can build the MIC_Locator prediction model. Refer to all 10 vanishing moments, we summed the prediction probabilities of test images of prediction model output and divided the sum value by the number of 10 vanishing moments.</p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>AAC</term>
        <def>
          <p id="Par4">Amino acid composition</p>
        </def>
      </def-item>
      <def-item>
        <term>APO</term>
        <def>
          <p id="Par5">Amplitude, phase and orientation</p>
        </def>
      </def-item>
      <def-item>
        <term>BR</term>
        <def>
          <p id="Par6">Binary relevance classifier</p>
        </def>
      </def-item>
      <def-item>
        <term>CA</term>
        <def>
          <p id="Par7">Cell atlas</p>
        </def>
      </def-item>
      <def-item>
        <term>CC</term>
        <def>
          <p id="Par8">Multi-label classifier chains</p>
        </def>
      </def-item>
      <def-item>
        <term>CDD</term>
        <def>
          <p id="Par9">Conserved domain database</p>
        </def>
      </def-item>
      <def-item>
        <term>CLBP</term>
        <def>
          <p id="Par10">Completed local binary pattern</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par11">Convolution neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>DC</term>
        <def>
          <p id="Par12">Direct current</p>
        </def>
      </def-item>
      <def-item>
        <term>DI</term>
        <def>
          <p id="Par13">Dyed index</p>
        </def>
      </def-item>
      <def-item>
        <term>ECOC</term>
        <def>
          <p id="Par14">Error-correcting output codes strategy</p>
        </def>
      </def-item>
      <def-item>
        <term>FDSA</term>
        <def>
          <p id="Par15">Frequency domain signal analysis</p>
        </def>
      </def-item>
      <def-item>
        <term>FFT</term>
        <def>
          <p id="Par16">The fast fourier transform</p>
        </def>
      </def-item>
      <def-item>
        <term>GO</term>
        <def>
          <p id="Par17">Gene ontology</p>
        </def>
      </def-item>
      <def-item>
        <term>GPCR</term>
        <def>
          <p id="Par18">G Protein-Coupled Receptor</p>
        </def>
      </def-item>
      <def-item>
        <term>HPA</term>
        <def>
          <p id="Par19">Human protein atlas database</p>
        </def>
      </def-item>
      <def-item>
        <term>IHC</term>
        <def>
          <p id="Par20">Immunohistochemistry</p>
        </def>
      </def-item>
      <def-item>
        <term>KAWF</term>
        <def>
          <p id="Par21">The Knut and Alice Wallenberg Foundations</p>
        </def>
      </def-item>
      <def-item>
        <term>KNN</term>
        <def>
          <p id="Par22">K-nearest neighbor classifier</p>
        </def>
      </def-item>
      <def-item>
        <term>LBP</term>
        <def>
          <p id="Par23">Local binary pattern</p>
        </def>
      </def-item>
      <def-item>
        <term>LQP</term>
        <def>
          <p id="Par24">Local quinary pattern</p>
        </def>
      </def-item>
      <def-item>
        <term>LTP</term>
        <def>
          <p id="Par25">Local ternary pattern</p>
        </def>
      </def-item>
      <def-item>
        <term>LTrP</term>
        <def>
          <p id="Par26">Local tetra pattern</p>
        </def>
      </def-item>
      <def-item>
        <term>PA</term>
        <def>
          <p id="Par27">Pathology atlas</p>
        </def>
      </def-item>
      <def-item>
        <term>PSSM</term>
        <def>
          <p id="Par28">Position specific scoring matrix</p>
        </def>
      </def-item>
      <def-item>
        <term>RALS</term>
        <def>
          <p id="Par29">Random label selection method</p>
        </def>
      </def-item>
      <def-item>
        <term>SDA</term>
        <def>
          <p id="Par30">Stepwise discriminant analysis</p>
        </def>
      </def-item>
      <def-item>
        <term>SLFs</term>
        <def>
          <p id="Par31">Subcellular location features</p>
        </def>
      </def-item>
      <def-item>
        <term>SVM</term>
        <def>
          <p id="Par32">Support vector machine</p>
        </def>
      </def-item>
      <def-item>
        <term>TA</term>
        <def>
          <p id="Par33">Tissue atlas</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank the editor and reviewers for their helpful suggestions and comments which have significantly improved the quality and representation of our work. We are very grateful to Dr. Wen Chen from Harvard Medical School for examining our manuscript carefully with the grammars and typos corrected.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>FY designed the study, and YL carried out experiments and conducted the evaluations. YBW, ZJY and ZY helped with performing the analysis of the proposed model. FY supervised the project. All authors wrote and edited the manuscript. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported in part by the National Natural Science Foundation of China (61603161), the Key Science Foundation of Educational Commission of Jiangxi Province of China (GJJ160768), The scholastic youth talent support program of Jiangxi Science and Technology Normal University (2016QNBJRC004), the Science Foundation of Artificial Intelligence and Bioinformatics Cognitive Research Base Fund of Jiangxi Science and Technology Normal University of China (2017ZDPYJD005). The funding bodies did not play any role in the design of the study, data collection and analysis, and preparation of the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The selected benchmark dataset can be available in the website (<ext-link ext-link-type="uri" xlink:href="https://github.com/ProteinLocator/MIC_Locator">https://github.com/ProteinLocator/MIC_Locator</ext-link>) for the academic research.</p>
  </notes>
  <notes>
    <title>Ethics approval and consent to participate</title>
    <p id="Par113">Not applicable.</p>
  </notes>
  <notes>
    <title>Consent for publication</title>
    <p id="Par114">Not applicable.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par115">The authors declare that they have no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kumar</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Rao</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bhavani</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Newberg</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Murphy</surname>
            <given-names>RF</given-names>
          </name>
        </person-group>
        <article-title>Automated analysis of immunohistochemistry images identifies candidate location biomarkers for cancers</article-title>
        <source>Proc Natl Acad Sci U S A</source>
        <year>2014</year>
        <volume>111</volume>
        <issue>51</issue>
        <fpage>18249</fpage>
        <lpage>18254</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1415120112</pub-id>
        <?supplied-pmid 25489103?>
        <pub-id pub-id-type="pmid">25489103</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thul</surname>
            <given-names>Peter J.</given-names>
          </name>
          <name>
            <surname>Åkesson</surname>
            <given-names>Lovisa</given-names>
          </name>
          <name>
            <surname>Wiking</surname>
            <given-names>Mikaela</given-names>
          </name>
          <name>
            <surname>Mahdessian</surname>
            <given-names>Diana</given-names>
          </name>
          <name>
            <surname>Geladaki</surname>
            <given-names>Aikaterini</given-names>
          </name>
          <name>
            <surname>Ait Blal</surname>
            <given-names>Hammou</given-names>
          </name>
          <name>
            <surname>Alm</surname>
            <given-names>Tove</given-names>
          </name>
          <name>
            <surname>Asplund</surname>
            <given-names>Anna</given-names>
          </name>
          <name>
            <surname>Björk</surname>
            <given-names>Lars</given-names>
          </name>
          <name>
            <surname>Breckels</surname>
            <given-names>Lisa M.</given-names>
          </name>
          <name>
            <surname>Bäckström</surname>
            <given-names>Anna</given-names>
          </name>
          <name>
            <surname>Danielsson</surname>
            <given-names>Frida</given-names>
          </name>
          <name>
            <surname>Fagerberg</surname>
            <given-names>Linn</given-names>
          </name>
          <name>
            <surname>Fall</surname>
            <given-names>Jenny</given-names>
          </name>
          <name>
            <surname>Gatto</surname>
            <given-names>Laurent</given-names>
          </name>
          <name>
            <surname>Gnann</surname>
            <given-names>Christian</given-names>
          </name>
          <name>
            <surname>Hober</surname>
            <given-names>Sophia</given-names>
          </name>
          <name>
            <surname>Hjelmare</surname>
            <given-names>Martin</given-names>
          </name>
          <name>
            <surname>Johansson</surname>
            <given-names>Fredric</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>Sunjae</given-names>
          </name>
          <name>
            <surname>Lindskog</surname>
            <given-names>Cecilia</given-names>
          </name>
          <name>
            <surname>Mulder</surname>
            <given-names>Jan</given-names>
          </name>
          <name>
            <surname>Mulvey</surname>
            <given-names>Claire M.</given-names>
          </name>
          <name>
            <surname>Nilsson</surname>
            <given-names>Peter</given-names>
          </name>
          <name>
            <surname>Oksvold</surname>
            <given-names>Per</given-names>
          </name>
          <name>
            <surname>Rockberg</surname>
            <given-names>Johan</given-names>
          </name>
          <name>
            <surname>Schutten</surname>
            <given-names>Rutger</given-names>
          </name>
          <name>
            <surname>Schwenk</surname>
            <given-names>Jochen M.</given-names>
          </name>
          <name>
            <surname>Sivertsson</surname>
            <given-names>Åsa</given-names>
          </name>
          <name>
            <surname>Sjöstedt</surname>
            <given-names>Evelina</given-names>
          </name>
          <name>
            <surname>Skogs</surname>
            <given-names>Marie</given-names>
          </name>
          <name>
            <surname>Stadler</surname>
            <given-names>Charlotte</given-names>
          </name>
          <name>
            <surname>Sullivan</surname>
            <given-names>Devin P.</given-names>
          </name>
          <name>
            <surname>Tegel</surname>
            <given-names>Hanna</given-names>
          </name>
          <name>
            <surname>Winsnes</surname>
            <given-names>Casper</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Cheng</given-names>
          </name>
          <name>
            <surname>Zwahlen</surname>
            <given-names>Martin</given-names>
          </name>
          <name>
            <surname>Mardinoglu</surname>
            <given-names>Adil</given-names>
          </name>
          <name>
            <surname>Pontén</surname>
            <given-names>Fredrik</given-names>
          </name>
          <name>
            <surname>von Feilitzen</surname>
            <given-names>Kalle</given-names>
          </name>
          <name>
            <surname>Lilley</surname>
            <given-names>Kathryn S.</given-names>
          </name>
          <name>
            <surname>Uhlén</surname>
            <given-names>Mathias</given-names>
          </name>
          <name>
            <surname>Lundberg</surname>
            <given-names>Emma</given-names>
          </name>
        </person-group>
        <article-title>A subcellular map of the human proteome</article-title>
        <source>Science</source>
        <year>2017</year>
        <volume>356</volume>
        <issue>6340</issue>
        <fpage>eaal3321</fpage>
        <pub-id pub-id-type="doi">10.1126/science.aal3321</pub-id>
        <?supplied-pmid 28495876?>
        <pub-id pub-id-type="pmid">28495876</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kajiwara</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Minamiguchi</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Seki</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Mizutani</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Aoyagi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Okajima</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sasaki</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Utsugi</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Iwasawa</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Effect of a new type androgen receptor antagonist, TAS3681, on ligand-independent AR activation through its AR downregulation activity</article-title>
        <source>J Clin Oncol</source>
        <year>2016</year>
        <volume>34</volume>
        <fpage>199</fpage>
        <pub-id pub-id-type="doi">10.1200/jco.2016.34.2_suppl.199</pub-id>
        <pub-id pub-id-type="pmid">26573076</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nogues</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Palaciosgarcia</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Reglero</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Rivas</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Neves</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ribas</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Penela</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Mayor</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>G protein-coupled receptor kinases (GRKs) in tumorigenesis and cancer progression: GPCR regulators and signaling hubs</article-title>
        <source>Semin Cancer Biol</source>
        <year>2017</year>
        <volume>48</volume>
        <fpage>78</fpage>
        <lpage>90</lpage>
        <pub-id pub-id-type="doi">10.1016/j.semcancer.2017.04.013</pub-id>
        <?supplied-pmid 28473253?>
        <pub-id pub-id-type="pmid">28473253</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Insel</surname>
            <given-names>PA</given-names>
          </name>
          <name>
            <surname>Sriram</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wiley</surname>
            <given-names>SZ</given-names>
          </name>
          <name>
            <surname>Wilderman</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Katakia</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Mccann</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Yokouchi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Corriden</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>GPCRomics: GPCR expression in Cancer cells and tumors identifies new, potential biomarkers and therapeutic targets</article-title>
        <source>Front Pharmacol</source>
        <year>2018</year>
        <volume>9</volume>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="doi">10.3389/fphar.2018.00431</pub-id>
        <pub-id pub-id-type="pmid">29387012</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chebira</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Barbotin</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Jackson</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Merryman</surname>
            <given-names>TE</given-names>
          </name>
          <name>
            <surname>Srinivasa</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Murphy</surname>
            <given-names>RF</given-names>
          </name>
          <name>
            <surname>Kovacevic</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>A multiresolution approach to automated classification of protein subcellular location images</article-title>
        <source>BMC Bioinformatics</source>
        <year>2007</year>
        <volume>8</volume>
        <issue>1</issue>
        <fpage>210</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-8-210</pub-id>
        <?supplied-pmid 17578580?>
        <pub-id pub-id-type="pmid">17578580</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kampf</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Olsson</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Ryberg</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Sjostedt</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Ponten</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Production of tissue microarrays, immunohistochemistry staining and digitalization within the human protein atlas</article-title>
        <source>J Vis Exp</source>
        <year>2012</year>
        <volume>63</volume>
        <fpage>25</fpage>
        <lpage>30</lpage>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Predicting RNA–protein binding sites and motifs through combining local and global deep convolutional neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>20</issue>
        <fpage>3427</fpage>
        <lpage>3436</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty364</pub-id>
        <?supplied-pmid 29722865?>
        <pub-id pub-id-type="pmid">29722865</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Hum-mPLoc 3.0: prediction enhancement of human protein subcellular localization through modeling the hidden correlations of gene ontology and functional domain features</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>33</volume>
        <issue>6</issue>
        <fpage>843</fpage>
        <lpage>853</lpage>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>pLoc-mAnimal: predict subcellular localization of animal proteins with both single and multiple sites</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <issue>22</issue>
        <fpage>3524</fpage>
        <lpage>3531</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx476</pub-id>
        <?supplied-pmid 29036535?>
        <pub-id pub-id-type="pmid">29036535</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Salvatore</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Warholm</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Shu</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Basile</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Elofsson</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>SubCons: a new ensemble method for improved human subcellular localization predictions</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <issue>16</issue>
        <fpage>2464</fpage>
        <lpage>2470</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx219</pub-id>
        <?supplied-pmid 28407043?>
        <pub-id pub-id-type="pmid">28407043</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zou</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>A new multi-label classifier in identifying the functional types of human membrane proteins</article-title>
        <source>J Membr Biol</source>
        <year>2015</year>
        <volume>248</volume>
        <issue>2</issue>
        <fpage>179</fpage>
        <lpage>186</lpage>
        <pub-id pub-id-type="doi">10.1007/s00232-014-9755-8</pub-id>
        <?supplied-pmid 25433431?>
        <pub-id pub-id-type="pmid">25433431</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>MultiP-SChlo: multi-label protein subchloroplast localization prediction with Chou’s pseudo amino acid composition and a novel multi-label classifier</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>31</volume>
        <issue>16</issue>
        <fpage>2639</fpage>
        <lpage>2645</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btv212</pub-id>
        <?supplied-pmid 25900916?>
        <pub-id pub-id-type="pmid">25900916</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nair</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Rost</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Sequence conserved for subcellular localization</article-title>
        <source>Protein Sci</source>
        <year>2009</year>
        <volume>11</volume>
        <issue>12</issue>
        <fpage>2836</fpage>
        <lpage>2847</lpage>
        <pub-id pub-id-type="doi">10.1110/ps.0207402</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shao</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Human cell structure-driven model construction for predicting protein subcellular location from biological images</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>32</volume>
        <issue>1</issue>
        <fpage>114</fpage>
        <lpage>121</lpage>
        <?supplied-pmid 26363175?>
        <pub-id pub-id-type="pmid">26363175</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Newberg</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Murphy</surname>
            <given-names>RF</given-names>
          </name>
        </person-group>
        <article-title>A framework for the automated analysis of subcellular patterns in human protein atlas images</article-title>
        <source>J Proteome Res</source>
        <year>2008</year>
        <volume>7</volume>
        <issue>6</issue>
        <fpage>2300</fpage>
        <lpage>2308</lpage>
        <pub-id pub-id-type="doi">10.1021/pr7007626</pub-id>
        <?supplied-pmid 18435555?>
        <pub-id pub-id-type="pmid">18435555</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>An image-based multi-label human protein subcellular localization predictor (iLocator) reveals protein mislocalizations in cancer tissues</article-title>
        <source>Bioinformatics</source>
        <year>2013</year>
        <volume>29</volume>
        <issue>16</issue>
        <fpage>2032</fpage>
        <lpage>2040</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btt320</pub-id>
        <?supplied-pmid 23740749?>
        <pub-id pub-id-type="pmid">23740749</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Coelho</surname>
            <given-names>LP</given-names>
          </name>
          <name>
            <surname>Kangas</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>Naik</surname>
            <given-names>AW</given-names>
          </name>
          <name>
            <surname>Osunahighley</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Gloryafshar</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Fuhrman</surname>
            <given-names>MH</given-names>
          </name>
          <name>
            <surname>Simha</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Berget</surname>
            <given-names>PB</given-names>
          </name>
          <name>
            <surname>Jarvik</surname>
            <given-names>JW</given-names>
          </name>
          <name>
            <surname>Murphy</surname>
            <given-names>RF</given-names>
          </name>
        </person-group>
        <article-title>Determining the subcellular location of new proteins from microscope images using local features</article-title>
        <source>Bioinformatics</source>
        <year>2013</year>
        <volume>29</volume>
        <issue>18</issue>
        <fpage>2343</fpage>
        <lpage>2349</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btt392</pub-id>
        <?supplied-pmid 23836142?>
        <pub-id pub-id-type="pmid">23836142</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kuo-Chen</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Hong-Bin</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Cell-PLoc: a package of web servers for predicting subcellular localization of proteins in various organisms</article-title>
        <source>Nat Protoc</source>
        <year>2007</year>
        <volume>3</volume>
        <issue>2</issue>
        <fpage>153</fpage>
        <lpage>162</lpage>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Briesemeister</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kohlbacher</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>YLoc-an interpretable web server for predicting subcellular localization</article-title>
        <source>Nucleic Acids Res</source>
        <year>2010</year>
        <volume>38</volume>
        <issue>Web Server</issue>
        <fpage>W497</fpage>
        <lpage>W502</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkq477</pub-id>
        <?supplied-pmid 20507917?>
        <pub-id pub-id-type="pmid">20507917</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>ZC</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>iLoc-Hum: using the accumulation-label scale to predict subcellular locations of human proteins with both single and multiple sites</article-title>
        <source>Mol BioSyst</source>
        <year>2012</year>
        <volume>8</volume>
        <issue>2</issue>
        <fpage>629</fpage>
        <pub-id pub-id-type="doi">10.1039/C1MB05420A</pub-id>
        <?supplied-pmid 22134333?>
        <pub-id pub-id-type="pmid">22134333</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">Wan S, Mak MW, Kung SY. FUEL-mLoc: feature-unified prediction and explanation of multi-localization of cellular proteins in multiple organisms. Bioinformatics. 2016;33(5):749–50.</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wan</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Mak</surname>
            <given-names>MW</given-names>
          </name>
          <name>
            <surname>Kung</surname>
            <given-names>SY</given-names>
          </name>
        </person-group>
        <article-title>Sparse regressions for predicting and interpreting subcellular localization of multi-label proteins</article-title>
        <source>BMC Bioinformatics</source>
        <year>2016</year>
        <volume>17</volume>
        <issue>1</issue>
        <fpage>97</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-016-0940-x</pub-id>
        <?supplied-pmid 26911432?>
        <pub-id pub-id-type="pmid">26911432</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Almagro Armenteros</surname>
            <given-names>José Juan</given-names>
          </name>
          <name>
            <surname>Sønderby</surname>
            <given-names>Casper Kaae</given-names>
          </name>
          <name>
            <surname>Sønderby</surname>
            <given-names>Søren Kaae</given-names>
          </name>
          <name>
            <surname>Nielsen</surname>
            <given-names>Henrik</given-names>
          </name>
          <name>
            <surname>Winther</surname>
            <given-names>Ole</given-names>
          </name>
        </person-group>
        <article-title>DeepLoc: prediction of protein subcellular localization using deep learning</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <issue>21</issue>
        <fpage>3387</fpage>
        <lpage>3395</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx431</pub-id>
        <?supplied-pmid 29036616?>
        <pub-id pub-id-type="pmid">29036616</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ouzounis</surname>
            <given-names>Christos A</given-names>
          </name>
          <name>
            <surname>Karp</surname>
            <given-names>Peter D</given-names>
          </name>
        </person-group>
        <source>Genome Biology</source>
        <year>2002</year>
        <volume>3</volume>
        <issue>2</issue>
        <fpage>comment2001.1</fpage>
        <pub-id pub-id-type="doi">10.1186/gb-2002-3-2-comment2001</pub-id>
        <pub-id pub-id-type="pmid">11864365</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hurtley</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>A new look at old data</article-title>
        <source>Science</source>
        <year>2010</year>
        <volume>329</volume>
        <issue>5990</issue>
        <fpage>368</fpage>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Siezen</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Van Hijum</surname>
            <given-names>SAFT</given-names>
          </name>
        </person-group>
        <article-title>Genome (re-)annotation and open-source annotation pipelines</article-title>
        <source>Microb Biotechnol</source>
        <year>2010</year>
        <volume>3</volume>
        <issue>4</issue>
        <fpage>362</fpage>
        <lpage>369</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1751-7915.2010.00191.x</pub-id>
        <?supplied-pmid 21255336?>
        <pub-id pub-id-type="pmid">21255336</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peng</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Bateman</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Valencia</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wren</surname>
            <given-names>JD</given-names>
          </name>
        </person-group>
        <article-title>Bioimage informatics: a new category in bioinformatics</article-title>
        <source>Bioinformatics</source>
        <year>2012</year>
        <volume>28</volume>
        <issue>8</issue>
        <fpage>1057</fpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bts111</pub-id>
        <?supplied-pmid 22399678?>
        <pub-id pub-id-type="pmid">22399678</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peng</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Bioimage informatics: a new area of engineering biology</article-title>
        <source>Bioinformatics</source>
        <year>2008</year>
        <volume>24</volume>
        <issue>17</issue>
        <fpage>1827</fpage>
        <lpage>1836</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btn346</pub-id>
        <?supplied-pmid 18603566?>
        <pub-id pub-id-type="pmid">18603566</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Murphy</surname>
            <given-names>R. F.</given-names>
          </name>
        </person-group>
        <article-title>A new era in bioimage informatics</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <issue>10</issue>
        <fpage>1353</fpage>
        <lpage>1353</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu158</pub-id>
        <?supplied-pmid 24753489?>
        <pub-id pub-id-type="pmid">24753489</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boland</surname>
            <given-names>MV</given-names>
          </name>
          <name>
            <surname>Murphy</surname>
            <given-names>RF</given-names>
          </name>
        </person-group>
        <article-title>A neural network classifier capable of recognizing the patterns of all major subcellular structures in fluorescence microscope images of HeLa cells</article-title>
        <source>Bioinformatics</source>
        <year>2001</year>
        <volume>17</volume>
        <issue>12</issue>
        <fpage>1213</fpage>
        <lpage>1223</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/17.12.1213</pub-id>
        <?supplied-pmid 11751230?>
        <pub-id pub-id-type="pmid">11751230</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tahir</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Majid</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Protein subcellular localization of fluorescence imagery using spatial and transform domain features</article-title>
        <source>Bioinformatics</source>
        <year>2011</year>
        <volume>28</volume>
        <issue>1</issue>
        <fpage>91</fpage>
        <lpage>97</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btr624</pub-id>
        <?supplied-pmid 22088847?>
        <pub-id pub-id-type="pmid">22088847</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>C-C</given-names>
          </name>
          <name>
            <surname>Tsai</surname>
            <given-names>Y-S</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>Y-S</given-names>
          </name>
          <name>
            <surname>Chiu</surname>
            <given-names>T-Y</given-names>
          </name>
          <name>
            <surname>Hsiung</surname>
            <given-names>C-C</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>M-I</given-names>
          </name>
          <name>
            <surname>Simpson</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Hsu</surname>
            <given-names>C-N</given-names>
          </name>
        </person-group>
        <article-title>Boosting multiclass learning with repeating codes and weak detectors for protein subcellular localization</article-title>
        <source>Bioinformatics</source>
        <year>2007</year>
        <volume>23</volume>
        <issue>24</issue>
        <fpage>3374</fpage>
        <lpage>3381</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btm497</pub-id>
        <?supplied-pmid 17956879?>
        <pub-id pub-id-type="pmid">17956879</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Newberg</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Uhlén</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lundberg</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Murphy</surname>
            <given-names>RF</given-names>
          </name>
        </person-group>
        <article-title>Automated analysis and reannotation of subcellular locations in confocal images from the human protein atlas</article-title>
        <source>PLoS One</source>
        <year>2012</year>
        <volume>7</volume>
        <issue>11</issue>
        <fpage>e50514</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0050514</pub-id>
        <?supplied-pmid 23226299?>
        <pub-id pub-id-type="pmid">23226299</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nanni</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Lumini</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Brahnam</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Local binary patterns variants as texture descriptors for medical image analysis</article-title>
        <source>Artif Intell Med</source>
        <year>2010</year>
        <volume>49</volume>
        <issue>2</issue>
        <fpage>117</fpage>
        <lpage>125</lpage>
        <pub-id pub-id-type="doi">10.1016/j.artmed.2010.02.006</pub-id>
        <?supplied-pmid 20338737?>
        <pub-id pub-id-type="pmid">20338737</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Godinez</surname>
            <given-names>WJ</given-names>
          </name>
          <name>
            <surname>Hossain</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Lazic</surname>
            <given-names>SE</given-names>
          </name>
          <name>
            <surname>Davies</surname>
            <given-names>JW</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>A multi-scale convolutional neural network for phenotyping high-content cellular images</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <issue>13</issue>
        <fpage>2010</fpage>
        <lpage>2019</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx069</pub-id>
        <?supplied-pmid 28203779?>
        <pub-id pub-id-type="pmid">28203779</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>GE</given-names>
          </name>
        </person-group>
        <article-title>Imagenet classification with deep convolutional neural networks</article-title>
        <source>Advances in neural information processing systems</source>
        <year>2012</year>
        <fpage>1097</fpage>
        <lpage>1105</lpage>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Szegedy</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Jia</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Sermanet</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Reed</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Anguelov</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Erhan</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Vanhoucke</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Rabinovich</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Going deeper with convolutions</article-title>
        <source>Proceedings of the IEEE conference on computer vision and pattern recognition</source>
        <year>2015</year>
        <fpage>1</fpage>
        <lpage>9</lpage>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Hady</surname>
            <given-names>MFA</given-names>
          </name>
          <name>
            <surname>Schwenker</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Semi-supervised learning</article-title>
        <source>International conference on neural information processing</source>
        <year>2013</year>
        <fpage>215</fpage>
        <lpage>239</lpage>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shao</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Y-Y</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H-B</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>An organelle correlation-guided feature selection approach for classifying multi-label subcellular bio-images</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <year>2017</year>
        <volume>15</volume>
        <issue>3</issue>
        <fpage>828</fpage>
        <lpage>838</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2017.2677907</pub-id>
        <?supplied-pmid 28278481?>
        <pub-id pub-id-type="pmid">28278481</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sullivan</surname>
            <given-names>DP</given-names>
          </name>
          <name>
            <surname>Winsnes</surname>
            <given-names>CF</given-names>
          </name>
          <name>
            <surname>Åkesson</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Hjelmare</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wiking</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Schutten</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Campbell</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Leifsson</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Rhodes</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Nordgren</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Deep learning is combined with massive-scale citizen science to improve large-scale image classification</article-title>
        <source>Nat Biotechnol</source>
        <year>2018</year>
        <volume>36</volume>
        <issue>9</issue>
        <fpage>820</fpage>
        <pub-id pub-id-type="doi">10.1038/nbt.4225</pub-id>
        <?supplied-pmid 30125267?>
        <pub-id pub-id-type="pmid">30125267</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ojala</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Pietikäinen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Mäenpää</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</article-title>
        <source>IEEE Trans Pattern Anal Mach Intell</source>
        <year>2002</year>
        <volume>7</volume>
        <fpage>971</fpage>
        <lpage>987</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2002.1017623</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nafchi</surname>
            <given-names>HZ</given-names>
          </name>
          <name>
            <surname>Moghaddam</surname>
            <given-names>RF</given-names>
          </name>
          <name>
            <surname>Cheriet</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Phase-based binarization of ancient document images: model and applications</article-title>
        <source>IEEE Trans Image Process</source>
        <year>2014</year>
        <volume>23</volume>
        <issue>7</issue>
        <fpage>2916</fpage>
        <lpage>2930</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2014.2322451</pub-id>
        <?supplied-pmid 24816587?>
        <pub-id pub-id-type="pmid">24816587</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>A completed modeling of local binary pattern operator for texture classification</article-title>
        <source>IEEE Trans Image Process</source>
        <year>2010</year>
        <volume>19</volume>
        <issue>6</issue>
        <fpage>1657</fpage>
        <lpage>1663</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2010.2044957</pub-id>
        <?supplied-pmid 20215079?>
        <pub-id pub-id-type="pmid">20215079</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Murala</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Maheshwari</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Balasubramanian</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Local tetra patterns: a new feature descriptor for content-based image retrieval</article-title>
        <source>IEEE Trans Image Process</source>
        <year>2012</year>
        <volume>21</volume>
        <issue>5</issue>
        <fpage>2874</fpage>
        <lpage>2886</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2012.2188809</pub-id>
        <?supplied-pmid 22514130?>
        <pub-id pub-id-type="pmid">22514130</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Felsberg</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sommer</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>The monogenic signal</article-title>
        <source>IEEE Trans Signal Process</source>
        <year>2001</year>
        <volume>49</volume>
        <issue>12</issue>
        <fpage>3136</fpage>
        <lpage>3144</lpage>
        <pub-id pub-id-type="doi">10.1109/78.969520</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Shiu</surname>
            <given-names>SC-K</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Monogenic binary coding: an efficient local feature extraction approach to face recognition</article-title>
        <source>IEEE Trans Inf Forensics Secur</source>
        <year>2012</year>
        <volume>7</volume>
        <issue>6</issue>
        <fpage>1738</fpage>
        <lpage>1751</lpage>
        <pub-id pub-id-type="doi">10.1109/TIFS.2012.2217332</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>Y-Y</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H-B</given-names>
          </name>
        </person-group>
        <article-title>Incorporating organelle correlations into semi-supervised learning for protein subcellular localization prediction</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <issue>14</issue>
        <fpage>2184</fpage>
        <lpage>2192</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw219</pub-id>
        <?supplied-pmid 27153655?>
        <pub-id pub-id-type="pmid">27153655</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>G-Z</given-names>
          </name>
        </person-group>
        <article-title>Multilabel learning via random label selection for protein subcellular multilocations prediction</article-title>
        <source>IEEE/ACM Trans Comput Biol Bioinform</source>
        <year>2013</year>
        <volume>10</volume>
        <issue>2</issue>
        <fpage>436</fpage>
        <lpage>446</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2013.21</pub-id>
        <?supplied-pmid 23929867?>
        <pub-id pub-id-type="pmid">23929867</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>A review on multi-label learning algorithms</article-title>
        <source>IEEE Trans Knowl Data Eng</source>
        <year>2014</year>
        <volume>26</volume>
        <issue>8</issue>
        <fpage>1819</fpage>
        <lpage>1837</lpage>
        <pub-id pub-id-type="doi">10.1109/TKDE.2013.39</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Uhlén</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Fagerberg</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Hallström</surname>
            <given-names>BM</given-names>
          </name>
          <name>
            <surname>Lindskog</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Oksvold</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Mardinoglu</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sivertsson</surname>
            <given-names>Å</given-names>
          </name>
          <name>
            <surname>Kampf</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sjöstedt</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Asplund</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Tissue-based map of the human proteome</article-title>
        <source>Science</source>
        <year>2015</year>
        <volume>347</volume>
        <issue>6220</issue>
        <fpage>1260419</fpage>
        <pub-id pub-id-type="doi">10.1126/science.1260419</pub-id>
        <?supplied-pmid 25613900?>
        <pub-id pub-id-type="pmid">25613900</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Uhlen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sjöstedt</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Fagerberg</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Bidkhori</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Benfeitas</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Arif</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Edfors</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>A pathology atlas of the human cancer transcriptome</article-title>
        <source>Science</source>
        <year>2017</year>
        <volume>357</volume>
        <issue>6352</issue>
        <fpage>eaan2507</fpage>
        <pub-id pub-id-type="doi">10.1126/science.aan2507</pub-id>
        <pub-id pub-id-type="pmid">28818916</pub-id>
      </element-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Uhlen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Oksvold</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Fagerberg</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Lundberg</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Jonasson</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Forsberg</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Zwahlen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kampf</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Wester</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Hober</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Towards a knowledge-based human protein atlas</article-title>
        <source>Nat Biotechnol</source>
        <year>2010</year>
        <volume>28</volume>
        <issue>12</issue>
        <fpage>1248</fpage>
        <pub-id pub-id-type="doi">10.1038/nbt1210-1248</pub-id>
        <pub-id pub-id-type="pmid">21139605</pub-id>
      </element-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Murphy</surname>
            <given-names>RF</given-names>
          </name>
        </person-group>
        <article-title>Automated classification of subcellular patterns in multicell images without segmentation into single cells</article-title>
        <source>International symposium on biomedical imaging</source>
        <year>2004</year>
        <fpage>1139</fpage>
        <lpage>1142</lpage>
      </element-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Triggs</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>Enhanced local texture feature sets for face recognition under difficult lighting conditions</article-title>
        <source>IEEE Trans Image Process</source>
        <year>2010</year>
        <volume>19</volume>
        <issue>6</issue>
        <fpage>1635</fpage>
        <lpage>1650</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2010.2042645</pub-id>
        <?supplied-pmid 20172829?>
        <pub-id pub-id-type="pmid">20172829</pub-id>
      </element-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fogel</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Sagi</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Gabor filters as texture discriminator</article-title>
        <source>Biol Cybern</source>
        <year>1989</year>
        <volume>61</volume>
        <issue>2</issue>
        <fpage>103</fpage>
        <lpage>113</lpage>
        <pub-id pub-id-type="doi">10.1007/BF00204594</pub-id>
      </element-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Arrospide</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Salgado</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Log-Gabor filters for image-based vehicle verification</article-title>
        <source>IEEE Trans Image Process</source>
        <year>2013</year>
        <volume>22</volume>
        <issue>6</issue>
        <fpage>2286</fpage>
        <lpage>2295</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2013.2249080</pub-id>
        <?supplied-pmid 23475361?>
        <pub-id pub-id-type="pmid">23475361</pub-id>
      </element-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alessandrini</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Basarab</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Liebgott</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Bernard</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>Myocardial motion estimation from medical images using the monogenic signal</article-title>
        <source>IEEE Trans Image Process</source>
        <year>2013</year>
        <volume>22</volume>
        <issue>3</issue>
        <fpage>1084</fpage>
        <lpage>1095</lpage>
        <pub-id pub-id-type="doi">10.1109/TIP.2012.2226903</pub-id>
        <?supplied-pmid 23193239?>
        <pub-id pub-id-type="pmid">23193239</pub-id>
      </element-citation>
    </ref>
    <ref id="CR59">
      <label>59.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dong</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Kuang</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>SAR target recognition via joint sparse representation of monogenic signal</article-title>
        <source>IEEE J Selected Top Appl Earth Observ Remote Sensing</source>
        <year>2015</year>
        <volume>8</volume>
        <issue>7</issue>
        <fpage>3316</fpage>
        <lpage>3328</lpage>
        <pub-id pub-id-type="doi">10.1109/JSTARS.2015.2436694</pub-id>
      </element-citation>
    </ref>
    <ref id="CR60">
      <label>60.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Pham</surname>
            <given-names>TD</given-names>
          </name>
        </person-group>
        <article-title>Phenotype recognition with combined features and random subspace classifier ensemble</article-title>
        <source>BMC Bioinformatics</source>
        <year>2011</year>
        <volume>12</volume>
        <issue>1</issue>
        <fpage>128</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-12-128</pub-id>
        <?supplied-pmid 21529372?>
        <pub-id pub-id-type="pmid">21529372</pub-id>
      </element-citation>
    </ref>
    <ref id="CR61">
      <label>61.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Song</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Cai</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>DD</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Region-based progressive localization of cell nuclei in microscopic images with data adaptive modeling</article-title>
        <source>BMC Bioinformatics</source>
        <year>2013</year>
        <volume>14</volume>
        <issue>1</issue>
        <fpage>173</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-14-173</pub-id>
        <?supplied-pmid 23725412?>
        <pub-id pub-id-type="pmid">23725412</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
