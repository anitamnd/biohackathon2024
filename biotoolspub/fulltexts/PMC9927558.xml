<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinform Adv</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinform Adv</journal-id>
    <journal-id journal-id-type="publisher-id">bioadv</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics Advances</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2635-0041</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9927558</article-id>
    <article-id pub-id-type="doi">10.1093/bioadv/vbad011</article-id>
    <article-id pub-id-type="publisher-id">vbad011</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Structural Bioinformatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>G-RANK: an equivariant graph neural network for the scoring of protein–protein docking models</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-6372-7448</contrib-id>
        <name>
          <surname>Kim</surname>
          <given-names>Ha Young</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="http://credit.niso.org/contributor-roles/investigation/" degree-contribution="lead">Investigation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="http://credit.niso.org/contributor-roles/methodology/" degree-contribution="lead">Methodology</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Software" vocab-term-identifier="http://credit.niso.org/contributor-roles/software/" degree-contribution="lead">Software</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing – original draft" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-original-draft/" degree-contribution="lead">Writing – original draft</role>
        <aff><institution>Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology</institution>, Daejeon 34141, South <country country="KR">Korea</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kim</surname>
          <given-names>Sungsik</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Software" vocab-term-identifier="http://credit.niso.org/contributor-roles/software/" degree-contribution="supporting">Software</role>
        <aff><institution>GENINUS Inc.</institution>, Seoul 05836, South <country country="KR">Korea</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Park</surname>
          <given-names>Woong-Yang</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Software" vocab-term-identifier="http://credit.niso.org/contributor-roles/software/" degree-contribution="supporting">Software</role>
        <aff><institution>GENINUS Inc.</institution>, Seoul 05836, South <country country="KR">Korea</country></aff>
        <aff><institution>Samsung Genome Institute, Samsung Medical Center</institution>, Seoul 06351, South <country country="KR">Korea</country></aff>
        <aff><institution>Department of Molecular Cell Biology, Sungkyunkwan University School of Medicine</institution>, Suwon 16419, South <country country="KR">Korea</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-5916-6799</contrib-id>
        <name>
          <surname>Kim</surname>
          <given-names>Dongsup</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/conceptualization/" degree-contribution="lead">Conceptualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Funding acquisition" vocab-term-identifier="http://credit.niso.org/contributor-roles/funding-acquisition/" degree-contribution="lead">Funding acquisition</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Supervision" vocab-term-identifier="http://credit.niso.org/contributor-roles/supervision/" degree-contribution="lead">Supervision</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing – review &amp; editing" vocab-term-identifier="http://credit.niso.org/contributor-roles/writing-review-editing/" degree-contribution="lead">Writing – review &amp; editing</role>
        <aff><institution>Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology</institution>, Daejeon 34141, South <country country="KR">Korea</country></aff>
        <xref rid="vbad011-cor1" ref-type="corresp"/>
        <!--kds@kaist.ac.kr-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Gromiha</surname>
          <given-names>Michael</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="vbad011-cor1">To whom correspondence should be addressed. Email: <email>kds@kaist.ac.kr</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-02-03">
      <day>03</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>03</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <volume>3</volume>
    <issue>1</issue>
    <elocation-id>vbad011</elocation-id>
    <history>
      <date date-type="received">
        <day>07</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>25</day>
        <month>1</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>26</day>
        <month>1</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>01</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>14</day>
        <month>2</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="vbad011.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Protein complex structure prediction is important for many applications in bioengineering. A widely used method for predicting the structure of protein complexes is computational docking. Although many tools for scoring protein–protein docking models have been developed, it is still a challenge to accurately identify near-native models for unknown protein complexes. A recently proposed model called the geometric vector perceptron–graph neural network (GVP-GNN), a subtype of equivariant graph neural networks, has demonstrated success in various 3D molecular structure modeling tasks.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>Herein, we present G-RANK, a GVP-GNN-based method for the scoring of protein-protein docking models. When evaluated on two different test datasets, G-RANK achieved a performance competitive with or better than the state-of-the-art scoring functions. We expect G-RANK to be a useful tool for various applications in biological engineering.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>Source code is available at <ext-link xlink:href="https://github.com/ha01994/grank" ext-link-type="uri">https://github.com/ha01994/grank</ext-link>.</p>
      </sec>
      <sec id="s4">
        <title>Contact</title>
        <p>
          <email>kds@kaist.ac.kr</email>
        </p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics Advances</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Research Foundation of Korea</institution>
            <institution-id institution-id-type="DOI">10.13039/501100003725</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>NRF-2022R1A2C1006609</award-id>
        <award-id>NRF-2021M3H9A2097443</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Korean Government</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="5"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Protein–protein interactions play key roles in many biological processes. Knowledge on the 3D structures of protein complexes is key for understanding protein–protein interactions, which can be useful in various applications such as protein design or drug discovery. As experimental approaches pose limitations in terms of time and cost, computational docking is commonly used to predict the structures of protein complexes. Computational docking involves the generation of a large number of candidate structural models, from which final models are selected according to a certain scoring function. The scoring function is highly important for the successful identification of near-native docking models among all generated candidates.</p>
    <p>Various scoring functions have been developed based on physics-based, statistical potential-based, or machine learning-based methods (<xref rid="vbad011-B5" ref-type="bibr">Geng <italic toggle="yes">et al.</italic>, 2020</xref>). Examples of physics-based methods include HADDOCK (<xref rid="vbad011-B2" ref-type="bibr">Dominguez <italic toggle="yes">et al.</italic>, 2003</xref>), ZDock (<xref rid="vbad011-B12" ref-type="bibr">Pierce <italic toggle="yes">et al.</italic>, 2014</xref>) and pyDock (<xref rid="vbad011-B1" ref-type="bibr">Cheng <italic toggle="yes">et al.</italic>, 2007</xref>). Examples of methods based on knowledge-based statistical potentials include GOAP (<xref rid="vbad011-B23" ref-type="bibr">Zhou and Skolnick, 2011</xref>) and ITScore (<xref rid="vbad011-B6" ref-type="bibr">Huang and Zou, 2008</xref>). Finally, machine learning-based methods include iScore (<xref rid="vbad011-B5" ref-type="bibr">Geng <italic toggle="yes">et al.</italic>, 2020</xref>), DeepRank (<xref rid="vbad011-B15" ref-type="bibr">Renaud <italic toggle="yes">et al.</italic>, 2021</xref>), DOVE (<xref rid="vbad011-B22" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2020</xref>), GNN-DOVE (<xref rid="vbad011-B21" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021</xref>), PAUL (<xref rid="vbad011-B3" ref-type="bibr">Eismann <italic toggle="yes">et al.</italic>, 2021</xref>) and DeepRank-GNN (<xref rid="vbad011-B13" ref-type="bibr">Réau <italic toggle="yes">et al.</italic>, 2023</xref>). Currently, there is no comprehensive benchmarking study on the performances of the more recently developed machine learning methods. However, these machine learning-based methods show high predictive performances in their own assessment studies, often outperforming the traditional scoring functions.</p>
    <p>The models introduced above have achieved considerable success in scoring protein-protein docking models, but there is still room for improvement (<xref rid="vbad011-B13" ref-type="bibr">Réau <italic toggle="yes">et al.</italic>, 2023</xref>). Recently, a new type of neural network called the equivariant graph neural network (EGNN) has been proposed (<xref rid="vbad011-B16" ref-type="bibr">Satorras <italic toggle="yes">et al.</italic>, 2021</xref>). If a function is equivariant to some transformation, then the transformation of the input results in an equivalent transformation of the function’s output (<xref rid="vbad011-B17" ref-type="bibr">Townshend <italic toggle="yes">et al.</italic>, 2021</xref>). EGNNs are E(3)-equivariant; that is, they are equivariant to translation, rotation and reflection in 3D Euclidean space (<xref rid="vbad011-B16" ref-type="bibr">Satorras <italic toggle="yes">et al.</italic>, 2021</xref>). Equivariance is a desired property because neural networks are needed to recognize proteins in different positions and orientations. A subtype of EGNN, geometric vector perceptron–graph neural network (GVP-GNN), has recently shown success in various 3D molecular structure modeling tasks (<xref rid="vbad011-B7" ref-type="bibr">Jing <italic toggle="yes">et al.</italic>, 2020</xref>, <xref rid="vbad011-B8" ref-type="bibr">2021</xref>).</p>
    <p>Herein, we propose G-RANK, a new GVP-GNN-based method, for ranking protein–protein docking models. We compare our model with DeepRank-GNN (<xref rid="vbad011-B13" ref-type="bibr">Réau <italic toggle="yes">et al.</italic>, 2023</xref>), GNN-DOVE (<xref rid="vbad011-B21" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2021</xref>), iScore (<xref rid="vbad011-B5" ref-type="bibr">Geng <italic toggle="yes">et al.</italic>, 2020</xref>), HADDOCK (<xref rid="vbad011-B19" ref-type="bibr">Van Zundert <italic toggle="yes">et al.</italic>, 2016</xref>) and GOAP (<xref rid="vbad011-B23" ref-type="bibr">Zhou and Skolnick, 2011</xref>). When tested on two different test datasets, our model’s performance is competitive with or better than the compared scoring functions. We expect this model to be a useful tool for predicting the structures of protein–protein complexes.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Model architecture</title>
      <p>We used the GVP-GNN model architecture from <xref rid="vbad011-B8" ref-type="bibr">Jing <italic toggle="yes">et al.</italic> (2021)</xref>. GVP-GNNs differ from typical EGNNs in that the node and edge embeddings are tuples of scalar and vector features. Multi-layer perceptrons in standard EGNNs are replaced with GVPs in GVP-GNNs. A GVP is a module with a scalar channel and a vector channel that can process scalar and vector features, respectively. This module involves information propagation from a scalar channel to a vector channel and vice versa. Details on the formulation of GVP can be found in the original article (<xref rid="vbad011-B8" ref-type="bibr">Jing <italic toggle="yes">et al.</italic>, 2021</xref>).</p>
      <p>The architecture of the model is shown in <xref rid="vbad011-F1" ref-type="fig">Figure 1</xref>. Nodes are defined as atoms, and edges are defined for all pairs of atoms within 4.5 Å. The initial node embedding is the atom type in one-hot encoding. The initial edge embedding consists of the Gaussian radial basis function encoding of the edge length and the unit vector in the edge direction. These edge embeddings are computed from the atom coordinates. After the node and edge embeddings are each passed through a GVP layer, they are provided as input to a GVPConvLayer block which is repeated five times. This block consists of two layers: a graph propagation layer and a feed-forward layer.</p>
      <fig position="float" id="vbad011-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Architecture of GVP-GNN developed by <xref rid="vbad011-B8" ref-type="bibr">Jing <italic toggle="yes">et al.</italic> (2021)</xref>. GVPConvLayer block is shown in blue. Node embedding is indicated by h_V, and edge embedding is indicated by h_E</p>
        </caption>
        <graphic xlink:href="vbad011f1" position="float"/>
      </fig>
      <p>The graph propagation layer first computes messages from node and edge embeddings and then uses the message to update node embeddings. This layer can be formulated as:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msup><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>j</mml:mi><mml:mo>→</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mo>ϕ</mml:mo><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi mathvariant="normal">concat</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>j</mml:mi><mml:mo>→</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mi mathvariant="normal"> </mml:mi><mml:mi mathvariant="normal">for</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:msup><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">'</mml:mi></mml:mrow></mml:msup><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mi mathvariant="normal">in</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mi>N</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>←</mml:mo><mml:mi mathvariant="normal">LayerNorm</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">'</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mi mathvariant="normal">Dropout</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>→</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>→</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> is the message from node <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mi>j</mml:mi></mml:math></inline-formula> to node <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula>, <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula> is a sequence of 3 GVP layers, <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> is the embedding of node <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mi>j</mml:mi></mml:math></inline-formula>, <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>j</mml:mi><mml:mo>→</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:math></inline-formula> is the embedding of edge <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>j</mml:mi><mml:mo>→</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> is the set of neighboring nodes of node <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mi>i</mml:mi></mml:math></inline-formula>, and <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>′</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> is the size of <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>.</p>
      <p>The feed-forward layer then updates node embeddings in a point-wise manner. This layer can be formulated as:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>←</mml:mo><mml:mi mathvariant="normal">LayerNorm</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Dropout</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mo>ϕ</mml:mo><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math></disp-formula>
where <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula> is a sequence of 2 GVP layers. The updated node embeddings are repeatedly used as the input node embeddings for the next GVPConvLayer block.</p>
      <p>After five repetitions of the GVPConvLayer block, the final node embeddings are passed through a GVP layer, after which all node embeddings are reduced to scalars. This is followed by a mean pooling layer that averages the embeddings across all nodes. The embeddings finally pass through two dense layers, thus resulting in a single scalar value.</p>
    </sec>
    <sec>
      <title>2.2 Datasets</title>
      <sec>
        <title>2.2.1 BM5 cross-validation dataset</title>
        <p>The authors of DeepRank (<xref rid="vbad011-B15" ref-type="bibr">Renaud <italic toggle="yes">et al.</italic>, 2021</xref>) conducted docking by using HADDOCK version 2.2 (<xref rid="vbad011-B2" ref-type="bibr">Dominguez <italic toggle="yes">et al.</italic>, 2003</xref>; <xref rid="vbad011-B19" ref-type="bibr">Van Zundert <italic toggle="yes">et al.</italic>, 2016</xref>) on the docking benchmark dataset version 5 (BM5) (<xref rid="vbad011-B20" ref-type="bibr">Vreven <italic toggle="yes">et al.</italic>, 2015</xref>). The authors of DeepRank obtained 232 non-redundant complexes from the BM5 dataset, from which they excluded antibody–antigen complexes and complexes involving more than two chains, which resulted in 142 complexes. The dataset was made available by the authors of DeepRank (available at <ext-link xlink:href="https://data.sbgrid.org/dataset/843/" ext-link-type="uri">https://data.sbgrid.org/dataset/843/</ext-link>), and the details on the dataset generation can be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary Note S1</xref>. The dataset was used by the authors of DeepRank-GNN (<xref rid="vbad011-B13" ref-type="bibr">Réau <italic toggle="yes">et al.</italic>, 2023</xref>) for 10-fold cross-validation. The cross-validation is performed in the following manner: 15 complexes are left out as the test set. For each fold, 102 and 25 complexes are assigned to the training and validation sets, respectively. We use the same cross-validation dataset as DeepRank-GNN to ensure a fair comparison. Details on the size and composition of the 10-fold cross-validation dataset can be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>.</p>
      </sec>
      <sec>
        <title>2.2.2 Independent test dataset</title>
        <p>We assessed our model on an independent test dataset called the CAPRI score set (<xref rid="vbad011-B10" ref-type="bibr">Lensink and Wodak, 2014</xref>), which was also made available by the authors of DeepRank (available at <ext-link xlink:href="https://data.sbgrid.org/dataset/843/" ext-link-type="uri">https://data.sbgrid.org/dataset/843/</ext-link>). This dataset consists of more than 16 000 docking models for 13 protein–protein complexes, which were generated using a variety of docking methods by more than 40 research groups. We left out one complex containing no positive samples, resulting in 12 complexes. Details on the size and composition of this dataset can be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref>.</p>
      </sec>
    </sec>
    <sec>
      <title>2.3 Model inputs and training</title>
      <p>As in DeepRank-GNN (<xref rid="vbad011-B13" ref-type="bibr">Réau <italic toggle="yes">et al.</italic>, 2023</xref>), we constructed the graph only on the interface of the protein–protein complex, rather than the full complex. The interface was determined with pdb2sql (<xref rid="vbad011-B14" ref-type="bibr">Renaud and Geng, 2020</xref>) at a cutoff of 8.5 Å. Some models for which no contact atoms were found were excluded. Five atoms, C, N, O, S and H, were included in the model inputs. The ATOM3D package (<xref rid="vbad011-B18" ref-type="bibr">Townshend <italic toggle="yes">et al.</italic>, 2020</xref>) was used to convert the PDB files into the LMDB data format required for model inputs.</p>
      <p>We trained G-RANK to predict the <italic toggle="yes">f-nat</italic> (fraction of native contacts) (<xref rid="vbad011-B11" ref-type="bibr">Méndez <italic toggle="yes">et al.</italic>, 2003</xref>) values of docking models. <italic toggle="yes">f-nat</italic> ranges from 0 to 1, with higher <italic toggle="yes">f-nat</italic> values indicating higher model quality. The cutoff for discriminating between near-native and wrong models was defined as 0.3, as done in DeepRank-GNN (<xref rid="vbad011-B13" ref-type="bibr">Réau <italic toggle="yes">et al.</italic>, 2023</xref>). The mean squared error was used as the loss function, and Adam optimizer was used for optimization. The models were trained by using a batch size of 64 and a learning rate of 0.0001. We trained the models for 50 epochs, saved the model in each epoch and retained the model with the lowest validation loss for final evaluation on the test set.</p>
    </sec>
    <sec>
      <title>2.4 Assessment metrics</title>
      <p>We used the area under the receiver operating characteristic curve (ROC-AUC) and the precision-recall area under the curve (PR-AUC) to assess model performance. We also used a per-complex assessment metric called the hit rate (<xref rid="vbad011-B15" ref-type="bibr">Renaud <italic toggle="yes">et al.</italic>, 2021</xref>), which is defined as follows:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mi mathvariant="normal">hit</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mi mathvariant="normal">rate</mml:mi><mml:mfenced open="(" close=")" separators="|"><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi mathvariant="normal"> </mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">hits</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo><mml:mi mathvariant="normal"> </mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">pos</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math></disp-formula>
where <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">hits</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> is the number of hits (positive models) among the top <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mi>k</mml:mi></mml:math></inline-formula> ranked models predicted by the predictor, and <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">pos</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the total number of positive models for this complex. We also assess using the success rate, which is the number of docking cases with at least one near-native model among the top-<italic toggle="yes">k</italic> predicted models, divided by the total number of cases.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Results on the BM5 test set</title>
      <p>We trained G-RANK on the BM5 10-fold cross-validation dataset (training and validation loss curves shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S4</xref>). Afterwards, we used an ensemble method to compare the performance of the model with that of DeepRank-GNN by averaging the predictions of all models from the 10 folds for final evaluation on the left-out test set. DeepRank-GNN predictions were also obtained using the same ensemble method. The left-out test set consisted of 15 complexes with 22 099 positive models and 342 096 negative models. The boxplots in <xref rid="vbad011-F2" ref-type="fig">Figure 2</xref> show the distributions of per-complex ROC-AUC values and per-complex PR-AUC values. Both G-RANK and DeepRank-GNN tended to achieve high ROC-AUC values. In terms of PR-AUC, G-RANK achieved a lower 75% quantile than DeepRank-GNN (0.864 &lt; 0.918) but a significantly higher median value (0.785 &gt; 0.581). <xref rid="vbad011-F3" ref-type="fig">Figure 3</xref> shows the per-complex hit rates for the top-<italic toggle="yes">k</italic> ranked models, for values of <italic toggle="yes">k</italic> ranging from 0 to 1000. The performance of G-RANK is similar to that of DeepRank-GNN in terms of the median but outperforms DeepRank-GNN in terms of the 75% quantile.</p>
      <fig position="float" id="vbad011-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Distributions of per-complex ROC-AUC and PR-AUC on the BM5 test set</p>
        </caption>
        <graphic xlink:href="vbad011f2" position="float"/>
      </fig>
      <fig position="float" id="vbad011-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Distributions of per-complex hit rates on the BM5 test set, where <italic toggle="yes">k</italic> ranges from 0 to 1000. The thick lines denote the median hit rates, and the shaded areas denote the 25–75% quantile interval of the hit rates</p>
        </caption>
        <graphic xlink:href="vbad011f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.2 Results on the independent test dataset</title>
      <p>We used the ensemble method described above to evaluate our model on the CAPRI score set consisting of 1970 positive models and 14 113 negative models. We compared our model with DeepRank-GNN, GOAP, GNN-DOVE, HADDOCK and iScore. <xref rid="vbad011-F4" ref-type="fig">Figure 4</xref> shows the distributions of per-complex ROC-AUC and PR-AUC values. In terms of both metrics, G-RANK achieved a higher distribution of scores than other methods. <xref rid="vbad011-F5" ref-type="fig">Figure 5</xref> shows the median of per-complex hit rates for the top-<italic toggle="yes">k</italic> ranked models, for values of <italic toggle="yes">k</italic> ranging from 0 to 500, and <xref rid="vbad011-F6" ref-type="fig">Figure 6</xref> shows the distributions of per-complex hit rates for <italic toggle="yes">k = </italic>1, 10, 25, 50, 100. In both figures, it can be seen that the median hit rates of G-RANK are overall higher compared to other methods. Also, <xref rid="vbad011-T1" ref-type="table">Table 1</xref> shows the success rates when <italic toggle="yes">k = </italic>1, 10, 25, 50, 100. G-RANK demonstrates the highest success rate among all predictors for values of <italic toggle="yes">k = </italic>1, 10, 25, 50.</p>
      <fig position="float" id="vbad011-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Distributions of per-complex ROC-AUC and PR-AUC on the CAPRI score set</p>
        </caption>
        <graphic xlink:href="vbad011f4" position="float"/>
      </fig>
      <fig position="float" id="vbad011-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>Distributions of the median of the per-complex hit rates on the CAPRI score set, where <italic toggle="yes">k</italic> ranges from 0 to 500</p>
        </caption>
        <graphic xlink:href="vbad011f5" position="float"/>
      </fig>
      <fig position="float" id="vbad011-F6">
        <label>Fig. 6.</label>
        <caption>
          <p>Distributions of per-complex hit rates on the CAPRI score set (<italic toggle="yes">k </italic>=<italic toggle="yes"> </italic>1, 10, 25, 50, 100)</p>
        </caption>
        <graphic xlink:href="vbad011f6" position="float"/>
      </fig>
      <table-wrap position="float" id="vbad011-T1">
        <label>Table 1.</label>
        <caption>
          <p>Assessment of success rates on the CAPRI score set (<italic toggle="yes">k </italic>=<italic toggle="yes"> </italic>1, 10, 25, 50, 100)</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">G-RANK</th>
              <th rowspan="1" colspan="1">DeepRank-GNN</th>
              <th rowspan="1" colspan="1">GOAP</th>
              <th rowspan="1" colspan="1">GNN-DOVE</th>
              <th rowspan="1" colspan="1">HADDOCK</th>
              <th rowspan="1" colspan="1">iScore</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Top 1</td>
              <td rowspan="1" colspan="1">
                <bold>0.25</bold>
              </td>
              <td rowspan="1" colspan="1">0.17</td>
              <td rowspan="1" colspan="1">0.00</td>
              <td rowspan="1" colspan="1">0.08</td>
              <td rowspan="1" colspan="1">0.00</td>
              <td rowspan="1" colspan="1">0.00</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Top 10</td>
              <td rowspan="1" colspan="1">
                <bold>0.5</bold>
              </td>
              <td rowspan="1" colspan="1">0.42</td>
              <td rowspan="1" colspan="1">0.42</td>
              <td rowspan="1" colspan="1">
                <bold>0.5</bold>
              </td>
              <td rowspan="1" colspan="1">0.17</td>
              <td rowspan="1" colspan="1">0.17</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Top 25</td>
              <td rowspan="1" colspan="1">
                <bold>0.58</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.58</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.58</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.58</bold>
              </td>
              <td rowspan="1" colspan="1">0.42</td>
              <td rowspan="1" colspan="1">0.25</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Top 50</td>
              <td rowspan="1" colspan="1">
                <bold>0.75</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.75</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.75</bold>
              </td>
              <td rowspan="1" colspan="1">0.58</td>
              <td rowspan="1" colspan="1">0.5</td>
              <td rowspan="1" colspan="1">0.5</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Top 100</td>
              <td rowspan="1" colspan="1">0.83</td>
              <td rowspan="1" colspan="1">
                <bold>0.92</bold>
              </td>
              <td rowspan="1" colspan="1">0.83</td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.58</td>
              <td rowspan="1" colspan="1">0.58</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic toggle="yes">Note</italic>: Success rate refers to the percentage of cases in which a correct model is found within the top <italic toggle="yes">k</italic> ranked models.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Additionally, we performed a model assessment by labeling the correct and incorrect models using the CAPRI scoring criteria (<xref rid="vbad011-B9" ref-type="bibr">Lensink <italic toggle="yes">et al.</italic>, 2018</xref>), instead of <italic toggle="yes">f-nat</italic> values. CAPRI classes are computed based on iRMSD (interface RMSD), lRMSD (ligand RMSD) and <italic toggle="yes">f-nat</italic> values, and each docking model is classified as ‘high’, ‘medium’, ‘acceptable’ or ‘incorrect’ (<xref rid="sup1" ref-type="supplementary-material">Supplementary Note S5</xref>). In this assessment, we consider a model correct if it is at least of ‘acceptable’ quality. The per-complex ROC-AUC, PR-AUC, hit rates and the success rates are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figures S6 and S7</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S8</xref>. In terms of ROC-AUC and PR-AUC, G-RANK still achieved the highest performance. In terms of the hit rates, when the value of <italic toggle="yes">k</italic> is small, it shows a slightly lower performance compared to other models, but it generally shows a good predictive performance. In terms of the success rates, its performance is similar to other methods in general.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>In this study, we developed G-RANK, a new method based on GVP-GNN for assessing the quality of protein–protein docking models. When tested on two different test sets, G-RANK’s performance was competitive with or outperformed the existing state-of-the-art methods. Analysis on hit rates and success rates demonstrated that G-RANK performs well in identifying near-native models among a large pool of candidate models. Our results confirm the previous finding (<xref rid="vbad011-B8" ref-type="bibr">Jing <italic toggle="yes">et al.</italic>, 2021</xref>) that GVP-GNNs perform well across prediction tasks involving 3D molecular structures. The equivariance property of the neural network, as well as the representation of 3D structures as both scalar and vectors, is important factors that led to G-RANK’s outstanding performance.</p>
    <p>As shown by the generally low PR-AUC of the predictors on the CAPRI score set, the identification of several near-native models among a large pool of candidate models remains a difficult problem. Development of more advanced equivariant neural network architectures in the future may help overcome this problem. In addition, the continual accumulation of experimentally determined protein complex structures may enable better prediction in the future. Also, the recent development of AlphaFold2-Multimer (<xref rid="vbad011-B4" ref-type="bibr">Evans <italic toggle="yes">et al.</italic>, 2022</xref>), a fold-and-dock approach, has shown significant success in the prediction of protein complex structures. We expect that the scoring function developed in this work can collaborate with such model to help advance our knowledge on protein complex structures.</p>
    <p>The GVP-GNN model used in this study could be further modified and applied to other research objectives related to protein structure and function, such as ranking of protein–ligand docking models. We expect that G-RANK may contribute to various applications in biological engineering, such as protein design and drug discovery.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>vbad011_Supplementary_Data</label>
      <media xlink:href="vbad011_supplementary_data.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Author contributions</title>
    <p>Ha Young Kim (Investigation [lead], Methodology [lead], Software [lead], Writing – original draft [lead]), Sungsik Kim (Software [supporting]), Woong-Yang Park (Software [supporting]), and Dongsup Kim (Conceptualization [lead], Funding acquisition [lead], Supervision [lead], Writing – review &amp; editing [lead])</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the National Research Foundation of Korea (NRF) [NRF-2022R1A2C1006609 and NRF-2021M3H9A2097443] funded by the Korean Government (MSIT).</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: S.K. and W.-Y.P. report personal fees and other support from Geninus Inc.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>Data is made available by the authors of DeepRank and can be accessed at <ext-link xlink:href="https://data.sbgrid.org/dataset/843/" ext-link-type="uri">https://data.sbgrid.org/dataset/843/</ext-link>.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="vbad011-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheng</surname><given-names>T.M.K.</given-names></string-name></person-group><etal>et al</etal> (<year>2007</year>) <article-title>pyDock: electrostatics and desolvation for effective scoring of rigid‐body protein–protein docking</article-title>. <source>Proteins</source>, <volume>68</volume>, <fpage>503</fpage>–<lpage>515</lpage>.<pub-id pub-id-type="pmid">17444519</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dominguez</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2003</year>) <article-title>HADDOCK: a protein–protein docking approach based on biochemical or biophysical information</article-title>. <source>J. Am. Chem. Soc</source>., <volume>125</volume>, <fpage>1731</fpage>–<lpage>1737</lpage>.<pub-id pub-id-type="pmid">12580598</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eismann</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Hierarchical, rotation‐equivariant neural networks to select structural models of protein complexes</article-title>. <source>Proteins</source>, <volume>89</volume>, <fpage>493</fpage>–<lpage>501</lpage>.<pub-id pub-id-type="pmid">33289162</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B4">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Evans</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) Protein complex prediction with AlphaFold-Multimer. BioRxiv <pub-id pub-id-type="doi">10.1101/2021.10.04.463034</pub-id>.</mixed-citation>
    </ref>
    <ref id="vbad011-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Geng</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>iScore: a novel graph kernel-based function for scoring protein–protein docking models</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>112</fpage>–<lpage>121</lpage>.<pub-id pub-id-type="pmid">31199455</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname><given-names>S.Y.</given-names></string-name>, <string-name><surname>Zou</surname><given-names>X.</given-names></string-name></person-group> (<year>2008</year>) <article-title>An iterative knowledge‐based scoring function for protein–protein recognition</article-title>. <source>Proteins</source>, <volume>72</volume>, <fpage>557</fpage>–<lpage>579</lpage>.<pub-id pub-id-type="pmid">18247354</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B7">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jing</surname><given-names>B.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) Learning from protein structure with geometric vector perceptrons. arXiv, arXiv:2009.01411 2020, preprint: not peer reviewed. <pub-id pub-id-type="doi">10.48550/arXiv.2009.01411</pub-id>.</mixed-citation>
    </ref>
    <ref id="vbad011-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jing</surname><given-names>B.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) Equivariant graph neural networks for 3d macromolecular structure. arXiv, arXiv:2106.03843 2021, preprint: not peer reviewed. <pub-id pub-id-type="doi">10.48550/arXiv.2106.03843</pub-id>.</mixed-citation>
    </ref>
    <ref id="vbad011-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lensink</surname><given-names>M.F.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>The challenge of modeling protein assemblies: the CASP12‐CAPRI experiment</article-title>. <source>Proteins</source>, <volume>86</volume>, <fpage>257</fpage>–<lpage>273</lpage>.<pub-id pub-id-type="pmid">29127686</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lensink</surname><given-names>M.F.</given-names></string-name>, <string-name><surname>Wodak</surname><given-names>S.J.</given-names></string-name></person-group> (<year>2014</year>) <article-title>Score_set: a CAPRI benchmark for scoring protein complexes</article-title>. <source>Proteins</source>, <volume>82</volume>, <fpage>3163</fpage>–<lpage>3169</lpage>.<pub-id pub-id-type="pmid">25179222</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Méndez</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2003</year>) <article-title>Assessment of blind predictions of protein–protein interactions: current status of docking methods</article-title>. <source>Proteins</source>, <volume>52</volume>, <fpage>51</fpage>–<lpage>67</lpage>.<pub-id pub-id-type="pmid">12784368</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pierce</surname><given-names>B.G.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) <article-title>ZDOCK server: interactive docking prediction of protein–protein complexes and symmetric multimers</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>1771</fpage>–<lpage>1773</lpage>.<pub-id pub-id-type="pmid">24532726</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Réau</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2023</year>) <article-title>DeepRank-GNN: a graph neural network framework to learn patterns in protein-protein interfaces</article-title>. <source>Bioinformatics</source>, <volume>39</volume>, btac759.</mixed-citation>
    </ref>
    <ref id="vbad011-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Renaud</surname><given-names>N.</given-names></string-name>, <string-name><surname>Geng</surname><given-names>C.</given-names></string-name></person-group> (<year>2020</year>) <article-title>The pdb2sql python package: parsing, manipulation and analysis of PDB files using SQL queries</article-title>. <source>J. Open Source Softw</source>., <volume>5</volume>, <fpage>2077</fpage>.</mixed-citation>
    </ref>
    <ref id="vbad011-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Renaud</surname><given-names>N.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>DeepRank: a deep learning framework for data mining 3D protein-protein interfaces</article-title>. <source>Nat. Commun</source>., <volume>12</volume>, <fpage>1</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">33397941</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B16">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Satorras</surname><given-names>V.G.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) E (n) equivariant graph neural networks. In: <italic toggle="yes">International Conference on Machine Learning, PMLR</italic>, pp. <fpage>9323</fpage>–<lpage>9332</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad011-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Townshend</surname><given-names>R.J.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Geometric deep learning of RNA structure</article-title>. <source>Science</source>, <volume>373</volume>, <fpage>1047</fpage>–<lpage>1051</lpage>.<pub-id pub-id-type="pmid">34446608</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B18">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Townshend</surname><given-names>R.J.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) Atom3d: tasks on molecules in three dimensions. arXiv, arXiv:2012.04035 2020. <pub-id pub-id-type="doi">10.48550/arXiv.2012.04035</pub-id>.</mixed-citation>
    </ref>
    <ref id="vbad011-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van Zundert</surname><given-names>G.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>The HADDOCK2. 2 web server: user-friendly integrative modeling of biomolecular complexes</article-title>. <source>J. Mol. Biol</source>., <volume>428</volume>, <fpage>720</fpage>–<lpage>725</lpage>.<pub-id pub-id-type="pmid">26410586</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vreven</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) <article-title>Updates to the integrated protein–protein interaction benchmarks: docking benchmark version 5 and affinity benchmark version 2</article-title>. <source>J. Mol. Biol</source>., <volume>427</volume>, <fpage>3031</fpage>–<lpage>3041</lpage>.<pub-id pub-id-type="pmid">26231283</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Protein docking model evaluation by graph neural networks</article-title>. <source>Front. Mol. Biosci</source>., <fpage>402</fpage>.</mixed-citation>
    </ref>
    <ref id="vbad011-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>X.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Protein docking model evaluation by 3D deep convolutional neural networks</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>2113</fpage>–<lpage>2118</lpage>.<pub-id pub-id-type="pmid">31746961</pub-id></mixed-citation>
    </ref>
    <ref id="vbad011-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>H.</given-names></string-name>, <string-name><surname>Skolnick</surname><given-names>J.</given-names></string-name></person-group> (<year>2011</year>) <article-title>GOAP: a generalized orientation-dependent, all-atom statistical potential for protein structure prediction</article-title>. <source>Biophys. J</source>., <volume>101</volume>, <fpage>2043</fpage>–<lpage>2052</lpage>.<pub-id pub-id-type="pmid">22004759</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
