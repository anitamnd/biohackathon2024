<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-id journal-id-type="pmc">plosone</journal-id>
    <journal-title-group>
      <journal-title>PLoS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6710032</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-19-10117</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0221487</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Optimization</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Statistical Methods</subject>
            <subj-group>
              <subject>Test Statistics</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical Methods</subject>
              <subj-group>
                <subject>Test Statistics</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and analysis methods</subject>
        <subj-group>
          <subject>Mathematical and statistical techniques</subject>
          <subj-group>
            <subject>Statistical methods</subject>
            <subj-group>
              <subject>Monte Carlo method</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical methods</subject>
              <subj-group>
                <subject>Monte Carlo method</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Materials Science</subject>
          <subj-group>
            <subject>Materials</subject>
            <subj-group>
              <subject>Fibers</subject>
              <subj-group>
                <subject>Carbon Fiber</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Cognitive Science</subject>
            <subj-group>
              <subject>Cognitive Psychology</subject>
              <subj-group>
                <subject>Intelligence</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Psychology</subject>
          <subj-group>
            <subject>Cognitive Psychology</subject>
            <subj-group>
              <subject>Intelligence</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Social Sciences</subject>
        <subj-group>
          <subject>Psychology</subject>
          <subj-group>
            <subject>Cognitive Psychology</subject>
            <subj-group>
              <subject>Intelligence</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Algebra</subject>
            <subj-group>
              <subject>Linear Algebra</subject>
              <subj-group>
                <subject>Vector Spaces</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>AdequacyModel: An R package for probability distributions and general purpose optimization</article-title>
      <alt-title alt-title-type="running-head">AdequacyModel: An R package for probability distributions and general purpose optimization</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1591-8300</contrib-id>
        <name>
          <surname>Marinho</surname>
          <given-names>Pedro Rafael D.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <role content-type="http://credit.casrai.org/">Writing – original draft</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Silva</surname>
          <given-names>Rodrigo B.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Writing – original draft</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bourguignon</surname>
          <given-names>Marcelo</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cordeiro</surname>
          <given-names>Gauss M.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Formal analysis</role>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff003">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Nadarajah</surname>
          <given-names>Saralees</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff004">
          <sup>4</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Department of Statistics, Federal University of Paraíba, João Pessoa, Paraíba, Brazil</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Department of Statistics, Federal University of Rio Grande do Norte, Natal, Rio Grande do Norte, Brazil</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Department of Statistics, Federal University of Pernambuco, Recife, Pernambuco, Brazil</addr-line>
    </aff>
    <aff id="aff004">
      <label>4</label>
      <addr-line>School of Mathematics, University of Manchester, Manchester, United Kingdom</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Mirjalili</surname>
          <given-names>Seyedali</given-names>
        </name>
        <role>Editor</role>
        <xref ref-type="aff" rid="edit1"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Griffith University, AUSTRALIA</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>pedro.rafael.marinho@gmail.com</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>26</day>
      <month>8</month>
      <year>2019</year>
    </pub-date>
    <volume>14</volume>
    <issue>8</issue>
    <elocation-id>e0221487</elocation-id>
    <history>
      <date date-type="received">
        <day>9</day>
        <month>4</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>7</day>
        <month>8</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2019 Marinho et al</copyright-statement>
      <copyright-year>2019</copyright-year>
      <copyright-holder>Marinho et al</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pone.0221487.pdf"/>
    <abstract>
      <p>Several lifetime distributions have played an important role to fit survival data. However, for some of these models, the computation of maximum likelihood estimators is quite difficult due to presence of flat regions in the search space, among other factors. Several well-known derivative-based optimization tools are unsuitable for obtaining such estimates. To circumvent this problem, we introduce the <bold>AdequacyModel</bold> computational library version 2.0.0 for the R statistical environment with two major contributions: a general optimization technique based on the Particle Swarm Optimization (PSO) method (with a minor modification of the original algorithm) and a set of statistical measures for assessment of the adequacy of the fitted model. This library is very useful for researchers in probability and statistics and has been cited in various papers in these areas. It serves as the basis for the <bold>Newdistns</bold> library (version 2.1) published in an impact journal in the area of computational statistics, see <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=Newdistns">https://CRAN.R-project.org/package=Newdistns</ext-link>. It is also the basis of the <bold>Wrapped</bold> library (version 2.0), see <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=Wrapped">https://CRAN.R-project.org/package=Wrapped</ext-link>. A third package making use of the <bold>AdequacyModel</bold> library can be found in <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=sglg">https://CRAN.R-project.org/package=sglg</ext-link>. In addition, the proposed library has proved to be very useful for maximizing log-likelihood functions with complex search regions. The library provides a greater control of the optimization process by introducing a stop criterion based on a minimum number of iterations and the variance of a given proportion of optimal values. We emphasize that the new library can be used not only in statistics but in physics and mathematics as proved in several examples throughout the paper.</p>
    </abstract>
    <funding-group>
      <funding-statement>The author(s) received no specific funding for this work.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="11"/>
      <table-count count="0"/>
      <page-count count="30"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>The data set “carbone” was considered. A data set corresponds to an uncensored datas from Nichols and Padgett (2006) on breaking stress of carbon fibres (in Gba). Nichols, M.D, Padgett, W.J. (2006). A Bootstrap control chart for Weibull percentiles. Quality and Reliability Engineering International 22, 141-151. This is a free data set used in various papers and softwares.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>The data set “carbone” was considered. A data set corresponds to an uncensored datas from Nichols and Padgett (2006) on breaking stress of carbon fibres (in Gba). Nichols, M.D, Padgett, W.J. (2006). A Bootstrap control chart for Weibull percentiles. Quality and Reliability Engineering International 22, 141-151. This is a free data set used in various papers and softwares.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>1 Introduction</title>
    <p>In survival analysis, practitioners are usually interested in choosing the distribution providing the best fit from a broad class of candidate models. In this sense, lifetime distributions are continually evolving in parallel with computer-based tools, which allow for using more complex distributions with a larger number of parameters to better study sizable masses of data. The last two decades have been very prolific in generating new parametric models for lifetime data and several methods to generate new distributions can be found in the literature. In addition to extending traditional models, the relevance of new distributions relies on the fact that some of them can provide better fits to real data sets. For a survey on the most important recent lifetime distributions, the readers are referred to [<xref rid="pone.0221487.ref001" ref-type="bibr">1</xref>] and [<xref rid="pone.0221487.ref002" ref-type="bibr">2</xref>].</p>
    <p>The main problem about recently proposed models is that in several cases one can obtain different solutions from different initial values when optimizing the corresponding likelihood functions, thus indicating the presence of flat regions in the search space. The term “flat” is used here to indicate that the minimum modulus of a function in a region is (in some sense) of the same order as the maximum modulus. In this case, most derivative-based optimization tools usually encounter difficulties such as getting trapped in local minima, which makes such approaches unsuitable to obtain the corresponding maximum likelihood estimates (MLEs). This is not, however, an exclusive problem of recent lifetime models. Several univariate and multivariate functions present the same issue. To circumvent this problem, some optimization algorithms based on swarm intelligence have been proposed over the last decades. This class of methods have shown simplicity, efficiency and robustness. One very popular swarm intelligence method is the Particle Swarm Optimization (PSO) for finding optimized solutions. The PSO is a stochastic search method introduced by [<xref rid="pone.0221487.ref003" ref-type="bibr">3</xref>] based on simple social behavior exhibited by birds and insects and, due to its simplicity in implementation, it has gained great popularity in optimization. It also has high level of convergence and low computational cost compared with other heuristic search methods. It traditionally uses a random sampling to find the optima, but it is superior, if compared with derivative-based methods, when the information about localization of the minimum (or maximum) is poor, which is the case when we have functions with flat regions. Further details about the PSO method can be found in [<xref rid="pone.0221487.ref004" ref-type="bibr">4</xref>].</p>
    <p>Some variants of the PSO algorithm have been studied in the literature in order to fit different types of problems. [<xref rid="pone.0221487.ref005" ref-type="bibr">5</xref>] proposed a mirror-extended Curvelet transform and PSO to solve the problem of speckle noise and low contrast in Synthetic Aperture Radar images. Since data mining demands fast and precise partitioning of large data sets, they usually come with a wide range of attributes or features, requiring serious computational restrictions on the relevant clustering techniques. [<xref rid="pone.0221487.ref006" ref-type="bibr">6</xref>] presented an overview of PSO techniques for cluster analysis. The issue of choosing the most adequate values in the Support Vector Machine (SVM) methodology can be structured in terms of an optimization problem in order to minimize a prediction error. [<xref rid="pone.0221487.ref007" ref-type="bibr">7</xref>] introduced an integrated PSO algorithm (PSO + SVM) to solve this problem. [<xref rid="pone.0221487.ref008" ref-type="bibr">8</xref>] presented a PSO overview from a Bayesian perspective, providing a formal framework for incorporation of prior knowledge about the problem that is being solved. [<xref rid="pone.0221487.ref009" ref-type="bibr">9</xref>] adopted maximum likelihood via PSO algorithm to estimate the mixture of two Weibull distributions with complete and multiple censored data.</p>
    <p>The main idea behind the proposed R package is to provide a set of tools for the assessment of the adequacy of lifetime models through a robust optimization method for determining the MLEs for lifetime distributions. Our contribution to the PSO algorithm is to replace the particles that eventually fall outside of the search region, which is a subtle variation of the original approach. By doing this, we expect to keep the viability of the algorithm and prevent all particles from converging to a local optimum. Furthermore, we provide more control over some aspects of the algorithm, such as the number of particles and iterations and a conditional stop criterion, based on a minimum number of iterations and the variance of a given proportion of optimal values. However, rather than focusing in the PSO itself, we provide an easy-to-use set of statistical measures to assess the adequacy of lifetime models for a given dataset. In addition to the MLEs, the package provides useful statistics to assess the goodness-of-fit of probabilistic models including Cramér-von Mises and Anderson-Darling statistics. These statistics are often used to compare non-nested models. The proposed package also gives other goodness-of-fit measures such as the Akaike information criterion and Bayesian information criterion, as well as the Kolmogorov-Smirnov test, through the <monospace>goodness.fit()</monospace> function. Even though our focus lies in lifetime models, the proposed optimization package can be used in several other areas as proved in some examples throughout the paper.</p>
    <p>This paper is organized as follows. Section 2 describes some theoretical background of swarm intelligence and general ideas underlying the PSO approach. Section 3 presents the PSO algorithm designed for the <bold>AdequacyModel</bold> package. Section 4 provides practical examples showing effectiveness of our PSO algorithm compared to results from other techniques, especially those based on derivatives. Section 4 contains an application using real (not simulated) data. In Section 5, a Monte Carlo simulation study is presented to verify the behavior of the optimization obtained by the <monospace>pso()</monospace> function provided by the package. Finally, Section 6 gives concluding remarks on the main findings of the paper and the current package usage.</p>
  </sec>
  <sec id="sec002">
    <title>2 Conceptual design of the framework</title>
    <sec id="sec003">
      <title>2.1 Swarm intelligence</title>
      <p>Swarm intelligence is an exciting research field still in its infancy compared to other paradigms in artificial intelligence. It is a branch of artificial intelligence concerned to the study of collective behavior of decentralized and self-organized systems in a social structure. These kinds of systems are composed by agents that interact in a small organization (swarm) wherein each individual is a particle. The main idea behind swarm intelligence is that an isolated particle has a very limited action in searching an ideal point for the solution of an nondeterministic polynomial (NP) time complete problem. However, the joint behavior of the particles in the search region shows evidence of artificial intelligence, i.e., the ability to take decisions to respond to changes. In this sense, the swarm intelligence concept arises directly from nature and is based on, for example, the self-organizing exploratory pattern of the schools of fish, flocks of birds and ant colonies. This collective behavior can not be described simply by aggregating the behavior of each element. Such situations have encouraged practitioners to obtain a satisfactory effect in the search for solutions to complex problems by studying methods that promote intelligent behavior through collaboration and competition among individuals. Swarm-based algorithms have been widely developed in the last decade and many successful applications in a variety of complex problems make them very promising, efficient and robust optimization tools, although very simple to implement. The idea is modeling very simple local interactions among individuals from which complex problem-solving behaviors arise.</p>
    </sec>
    <sec id="sec004">
      <title>2.2 Proposed PSO algorithm</title>
      <p>The PSO algorithm is conceptually based on the social behavior of biological organisms that move in groups, such as birds and fishes. It has provided good solutions for problems of global optimization of box-constrained functions. The fundamental component of the PSO algorithm is a particle, which can move around in the search space in direction of an optimum by making use of its own information as well as that obtained from other particles within its neighborhood. The performance of a particle is affected by its fitness, which is evaluated by calculating the objective function of the problem to be solved. The particle’s movement in the search space is randomized. For each iteration of the PSO algorithm, the leader particle is set by minimizing the objective function in the corresponding iteration. The remaining particles arranged in the search region will randomly follow the leader particle and sweep the area around the leader particle. In this local search process, another particle may become the new leader and the other particles will follow the new leader randomly.</p>
      <p>Mathematically, a particle <italic>i</italic> is featured by three vectors, namely:
<list list-type="bullet"><list-item><p>Its current location in the <italic>n</italic>-dimensional search space denoted by <bold><italic>x</italic></bold><sub><italic>i</italic></sub> = (<italic>x</italic><sub><italic>i</italic>1</sub>, …, <italic>x</italic><sub><italic>in</italic></sub>).</p></list-item><list-item><p>The best individual position it has held so far denoted by <bold><italic>p</italic></bold><sub><italic>i</italic></sub> = (<italic>p</italic><sub><italic>i</italic>1</sub>, …, <italic>p</italic><sub><italic>in</italic></sub>).</p></list-item><list-item><p>Its velocity <bold><italic>v</italic></bold><sub><italic>i</italic></sub> = (<italic>v</italic><sub><italic>i</italic>1</sub>, …, <italic>v</italic><sub><italic>in</italic></sub>).</p></list-item></list></p>
      <p>Usually, the current location <bold><italic>x</italic></bold><sub><italic>i</italic></sub> and velocity <bold><italic>v</italic></bold><sub><italic>i</italic></sub> are initialized by sampling from uniform distributions throughout the search space and setting a maximum velocity value <italic>v</italic><sub>max</sub>. Then, the particles move over the search space in sequential iterations driven by the following set of update equations:
<list list-type="bullet"><list-item><p><italic>v</italic><sub><italic>i</italic>,<italic>d</italic></sub>(<italic>t</italic> + 1) = <italic>v</italic><sub><italic>i</italic>,<italic>d</italic></sub>(<italic>t</italic>) + <italic>c</italic><sub>1</sub>
<italic>r</italic><sub>1</sub> [<italic>p</italic><sub><italic>i</italic>,<italic>d</italic></sub>(<italic>t</italic>) − <italic>x</italic><sub><italic>i</italic>,<italic>d</italic></sub>(<italic>t</italic>)] + <italic>c</italic><sub>2</sub>
<italic>r</italic><sub>2</sub> [<italic>p</italic><sub><italic>g</italic>,<italic>d</italic></sub>(<italic>t</italic>) − <italic>x</italic><sub><italic>i</italic>,<italic>d</italic></sub>(<italic>t</italic>)];</p></list-item><list-item><p><italic>x</italic><sub><italic>i</italic>,<italic>d</italic></sub>(<italic>t</italic> + 1) = <italic>x</italic><sub><italic>i</italic>,<italic>d</italic></sub>(<italic>t</italic>) + <italic>v</italic><sub><italic>i</italic>,<italic>d</italic></sub>(<italic>t</italic> + 1), <italic>d</italic> = 1, …, <italic>n</italic>,</p></list-item></list>
where <italic>c</italic><sub>1</sub> and <italic>c</italic><sub>2</sub> are constants, <italic>r</italic><sub>1</sub> and <italic>r</italic><sub>2</sub> are independent uniform random numbers generated at every update along each individual direction <italic>d</italic> = 1, …, <italic>n</italic> and <italic>p</italic><sub><italic>g</italic></sub>(<italic>t</italic>) is the <italic>n</italic>-dimensional vector of the best position encountered by any neighbor of the particle <italic>i</italic>. The velocities and positions at time <italic>t</italic> + 1 are influenced by the distances of the particle’s current location from its individual best historical experience <italic>p</italic><sub><italic>i</italic></sub>(<italic>t</italic>) and its neighborhoods best historical experience <italic>p</italic><sub><italic>g</italic></sub>(<italic>t</italic>) in a cooperative way.</p>
      <p>The proposed PSO algorithm is a small modification of the standard PSO algorithm pioneered by [<xref rid="pone.0221487.ref003" ref-type="bibr">3</xref>], where <inline-formula id="pone.0221487.e001"><alternatives><graphic xlink:href="pone.0221487.e001.jpg" id="pone.0221487.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>↦</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> with <inline-formula id="pone.0221487.e002"><alternatives><graphic xlink:href="pone.0221487.e002.jpg" id="pone.0221487.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:mrow><mml:mi mathvariant="script">R</mml:mi><mml:mo>⊆</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> is the objective function to be minimized, <italic>S</italic> is the number of particles of the swarm (set of feasible points), each particle having a location vector <inline-formula id="pone.0221487.e003"><alternatives><graphic xlink:href="pone.0221487.e003.jpg" id="pone.0221487.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="script">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> in the search space and a velocity vector defined by <inline-formula id="pone.0221487.e004"><alternatives><graphic xlink:href="pone.0221487.e004.jpg" id="pone.0221487.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="script">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. Let <italic>p</italic><sub><italic>i</italic></sub> be the best known position of the particle <italic>i</italic> and <italic>g</italic> the best position of all particles. The small modifications are highlighted in the algorithm below. The default optimization does not address the optimization problem restricted to a region <inline-formula id="pone.0221487.e005"><alternatives><graphic xlink:href="pone.0221487.e005.jpg" id="pone.0221487.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mi mathvariant="script">R</mml:mi></mml:math></alternatives></inline-formula>. In the course of the iterations, it is common for several particles to fall outside the search region <inline-formula id="pone.0221487.e006"><alternatives><graphic xlink:href="pone.0221487.e006.jpg" id="pone.0221487.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:mi mathvariant="script">R</mml:mi></mml:math></alternatives></inline-formula>. The strategy of eliminating these particles and randomly relocating them in the search region increases the viability of the algorithm by preventing all particles from converging to a local minimum.</p>
      <p>1. For each particle <italic>i</italic> = 1, …, <italic>S</italic> do:
<list list-type="bullet"><list-item><p>Initialize the particle’s position with a uniformly distributed random vector: <italic>x</italic><sub><italic>i</italic></sub> ∼ <italic>U</italic>(<italic>b</italic><sub><italic>lo</italic></sub>, <italic>b</italic><sub><italic>up</italic></sub>), where <italic>b</italic><sub><italic>lo</italic></sub> and <italic>b</italic><sub><italic>up</italic></sub> are the lower and upper boundaries of the search-space.</p></list-item><list-item><p>Initialize the particle’s best known position to its initial position: <inline-formula id="pone.0221487.e007"><alternatives><graphic xlink:href="pone.0221487.e007.jpg" id="pone.0221487.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>↢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p></list-item><list-item><p>If <italic>f</italic>(<italic>p</italic><sub><italic>i</italic></sub>) &lt; <italic>f</italic>(<italic>g</italic>) update the swarm’s best known position: <inline-formula id="pone.0221487.e008"><alternatives><graphic xlink:href="pone.0221487.e008.jpg" id="pone.0221487.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:mrow><mml:mi>g</mml:mi><mml:mo>↢</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p></list-item><list-item><p>Initialize the particle’s velocity: <italic>v</italic><sub><italic>i</italic></sub> ∼ <italic>U</italic>(−|<italic>b</italic><sub><italic>up</italic></sub> − <italic>b</italic><sub><italic>lo</italic></sub>|, |<italic>b</italic><sub><italic>up</italic></sub> − <italic>b</italic><sub><italic>lo</italic></sub>|).</p></list-item></list></p>
      <p>2. Until a termination criterion is met (e.g. number of iterations performed, or a solution with adequate objective function value found), repeat:
<list list-type="bullet"><list-item><p>For each particle <italic>i</italic> = 1, …, <italic>S</italic> do:
<list list-type="bullet"><list-item><p>Pick random numbers: <italic>r</italic><sub><italic>p</italic></sub>, <italic>r</italic><sub><italic>g</italic></sub> ∼ <italic>U</italic>(0, 1).</p></list-item><list-item><p>For each dimension <italic>d</italic> = 1, …, <italic>n</italic> do:
<list list-type="bullet"><list-item><p>Update the particle’s velocity: <inline-formula id="pone.0221487.e009"><alternatives><graphic xlink:href="pone.0221487.e009.jpg" id="pone.0221487.e009g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M9"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>↢</mml:mo><mml:mi>ω</mml:mi><mml:mspace width="0.166667em"/><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mo>φ</mml:mo><mml:mi>p</mml:mi></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mo>φ</mml:mo><mml:mi>g</mml:mi></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p></list-item></list></p></list-item><list-item><p>Update the particle’s position: <inline-formula id="pone.0221487.e010"><alternatives><graphic xlink:href="pone.0221487.e010.jpg" id="pone.0221487.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>↢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p></list-item><list-item><p>If <inline-formula id="pone.0221487.e011"><alternatives><graphic xlink:href="pone.0221487.e011.jpg" id="pone.0221487.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∉</mml:mo><mml:mi mathvariant="script">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>
<list list-type="bullet"><list-item><p>Eliminate <italic>x</italic><sub><italic>i</italic></sub>.</p></list-item><list-item><p>Generate new values <inline-formula id="pone.0221487.e012"><alternatives><graphic xlink:href="pone.0221487.e012.jpg" id="pone.0221487.e012g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M12"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="script">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> (random values).</p></list-item></list></p></list-item><list-item><p>If <italic>f</italic>(<italic>x</italic><sub><italic>i</italic></sub>) &lt; <italic>f</italic>(<italic>p</italic><sub><italic>i</italic></sub>) do:
<list list-type="bullet"><list-item><p>Update the particle’s best known position: <inline-formula id="pone.0221487.e013"><alternatives><graphic xlink:href="pone.0221487.e013.jpg" id="pone.0221487.e013g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M13"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>↢</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p></list-item><list-item><p>If <italic>f</italic>(<italic>p</italic><sub><italic>i</italic></sub>) &lt; <italic>f</italic>(<italic>g</italic>) update the swarm’s best known position: <inline-formula id="pone.0221487.e014"><alternatives><graphic xlink:href="pone.0221487.e014.jpg" id="pone.0221487.e014g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M14"><mml:mrow><mml:mi>g</mml:mi><mml:mo>↢</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>.</p></list-item></list></p></list-item></list></p></list-item></list></p>
      <p>3. Now <italic>g</italic> holds the best found solution.</p>
      <p>The parameter <italic>ω</italic> is called inertia coefficient and, as the name implies, controls the inertia of each particle arranged in the search space. The quantities φ<sub><italic>p</italic></sub> and φ<sub><italic>g</italic></sub> control the acceleration of each particle and are called acceleration coefficients. The PSO algorithm described above and implemented in the R programming language is given in the next section. A conditional stopping criterion will be discussed.</p>
      <p>The choices of constants <italic>ω</italic>, φ<sub><italic>p</italic></sub> and φ<sub><italic>g</italic></sub> can dramatically affect the performance of the algorithm in the optimization process. Discussions about appropriate parameter choices have been the subject of some research, see [<xref rid="pone.0221487.ref004" ref-type="bibr">4</xref>] and [<xref rid="pone.0221487.ref010" ref-type="bibr">10</xref>].</p>
      <p>One possible method is not to assess the fitness of the particles outside the search region and expect that these particles return to the search region due to some social interaction with other particles, see [<xref rid="pone.0221487.ref011" ref-type="bibr">11</xref>]. However, many problems involving likelihood-based inference require numerical constrained optimization. For example, the log-likelihood function is maximized subject to the constraint that the parameter of interest takes on the null-hypothesized value in the likelihood ratio test. In such problems, replacing the particles outside the feasible search region is a way to keep the viability of the algorithm.</p>
    </sec>
  </sec>
  <sec id="sec005">
    <title>3 The AdequacyModel package</title>
    <sec id="sec006">
      <title>3.1 Multi-parameter global optimization</title>
      <p>The above algorithm has been implemented in the <bold>AdequacyModel</bold> package available in the R website. It is quite general and can be applied to maximize or minimize any objective function involving restriction vectors delimiting the search space. We want to make clear that the PSO function is constructed to minimize an objective function. Maximizing <italic>f</italic> is equivalent to minimizing −<italic>f</italic>. A brief description of the <bold>AdequacyModel</bold> package is as follows:
<list list-type="bullet"><list-item><p><monospace>func</monospace>: an objective function to be minimized;</p></list-item><list-item><p><monospace>S</monospace>: number of considered particles. By default, the number of particles is equal to 150;</p></list-item><list-item><p><monospace>lim_inf</monospace> and <monospace>lim_sup</monospace>: define the inferior and superior boundaries of the search space, respectively;</p></list-item><list-item><p><monospace>e</monospace>: current error. The algorithm stops if the variance in the last iterations is less than or equal to <monospace>e</monospace>;</p></list-item><list-item><p><monospace>data</monospace>: by default <monospace>data = NULL</monospace>. However, when the <monospace>func</monospace> is a log-likelihood function, <monospace>data</monospace> is a data vector;</p></list-item><list-item><p><monospace>N</monospace>: minimum number of iterations (default <monospace>N = 500</monospace>);</p></list-item><list-item><p><monospace>prop</monospace>: Proportion of the last optimal values whose variance is computed and used as a stop criterion. If the number of iterations is greater than or equal to the minimum number of iterations <monospace>N</monospace>, then compute the variance of the last optimal values, where 0 ≤ <monospace>prop</monospace> ≤ 1.</p></list-item></list></p>
      <p>One advantage of the PSO method is that we do not need to be concerned with initial values. Problems with initial values are frequent in iterative methods such as the BFGS when the objective function involves flat or nearly flat regions. We can obtain totally different results depending on the chosen initial values. This issue is not usual in heuristic-based methods, where the updated steps include randomness (generation of pseudo-random numbers). The following example presents issues related to initial guesses for the algorithm and shows the use of the <monospace>pso</monospace> function, especially when the argument <monospace>func</monospace> specifies the objective function. In order to provide a greater control of the optimization process, we define <italic>N</italic> as the stop criterion giving the minimum number of iterations. The number of optimal values considered for computing the variance is given by the proportion of optimal values given by the argument prop, which is equal to 0.2 by default. In other words, if 20% of the last optimal values has variance less than or equal to <code position="float" orientation="portrait" xml:space="preserve">e</code>, the algorithm will stop the global search, thus indicating convergence according to the fixed criteria. These stop criteria indicate that there is no significant improvements in the global search for this proportion of iterations. Thus, if the variance is less than or equal to <italic>ε</italic> &gt; 0 assigned to the argument <code position="float" orientation="portrait" xml:space="preserve">e</code> of the <monospace>pso()</monospace> function, the algorithm will stop the iterations and return the best point that minimizes the objective function.</p>
    </sec>
    <sec id="sec007">
      <title>3.2 Examples</title>
      <sec id="sec008">
        <title>3.2.1 Trigonometric function</title>
        <p>Initially, we consider the case of a global search in a univariate function to estimate a one-dimensional vector. Consider the objective function <italic>f</italic>(<italic>θ</italic>) = 6 + <italic>θ</italic><sup>2</sup> sin(14<italic>θ</italic>). This function has local minima at <italic>θ</italic> = 2.3605 which globally minimizes <italic>f</italic>(<italic>θ</italic>) with <italic>f</italic>(2.3605) = −11.5618. <xref ref-type="fig" rid="pone.0221487.g001">Fig 1</xref> plots <italic>f</italic>(<italic>θ</italic>) over <italic>θ</italic> ∈ [−2.5, 2.5]. The blue square symbol indicates the global minimum obtained by the BFGS, SANN and Nelder-Mead methods. The red bullet represents the global minimum obtained by the PSO method.</p>
        <p>
          <monospace>R&gt; f &lt;- function(x){</monospace>
        </p>
        <p>
          <monospace>+  -(6 + x ^ 2 * sin(14 * x))</monospace>
        </p>
        <p>
          <monospace>+ }</monospace>
        </p>
        <p>
          <monospace>R&gt; f_pso &lt;- function(x, par){</monospace>
        </p>
        <p>
          <monospace>+  theta &lt;- par[1]</monospace>
        </p>
        <p>
          <monospace>+  -(6 + theta ^ 2 * sin(14 * theta))</monospace>
        </p>
        <p>
          <monospace>+ }</monospace>
        </p>
        <p>
          <monospace>R&gt; set.seed(9)</monospace>
        </p>
        <p>
          <monospace>R&gt; result_pso_f &lt;- pso(func = f_pso, S = 500, lim_inf = -2.5,</monospace>
        </p>
        <p>
          <monospace>+             lim_sup = 2.5, e = 0.0001)</monospace>
        </p>
        <p>
          <monospace>R&gt; set.seed(9)</monospace>
        </p>
        <p>
          <monospace>R&gt; result_sann_f &lt;- optim(par = 0, fn = f, lower = -2.5, upper = 2.5,</monospace>
        </p>
        <p>
          <monospace>+                method = “SANN”)</monospace>
        </p>
        <p>
          <monospace>R&gt; result_bfgs_f &lt;- optim(par = 0, fn = f, lower = -2.5, upper = 2.5,</monospace>
        </p>
        <p>
          <monospace>+                method = “BFGS”)</monospace>
        </p>
        <p>
          <monospace>R&gt; result_nelder_f &lt;- optim(par = 0, fn = f, lower = -2.5, upper = 2.5,</monospace>
        </p>
        <p>
          <monospace>+                method = “Nelder-Mead”)</monospace>
        </p>
        <fig id="pone.0221487.g001" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0221487.g001</object-id>
          <label>Fig 1</label>
          <caption>
            <title><italic>f</italic>(<italic>θ</italic>) = 6 + <italic>θ</italic><sup>2</sup> sin(14<italic>θ</italic>) with global minimum estimates.</title>
          </caption>
          <graphic xlink:href="pone.0221487.g001"/>
        </fig>
        <p>Note that the global minimum estimates obtained by the BFGS, SANN and Nelder-Mead methods through the <monospace>optim()</monospace> function (for more details, execute <monospace>?optim</monospace>) are heavily influenced by initial values. It is quite clear from <xref ref-type="fig" rid="pone.0221487.g001">Fig 1</xref> that there is a <italic>ε</italic> &gt; 0 such that <italic>f</italic> has derivative close to 0 around (−<italic>ε</italic>, <italic>ε</italic>). On the other hand, the <monospace>pso</monospace> function from the <bold>AdequacyModel</bold> script provides the true global minimum, which obviously coincides with the analytic solution. Note that all evaluated methods converge according to their associated stop criteria. For the BFGS, SANN and Nelder-Mead methods, we set the initial value as 0. For the SANN method and <monospace>pso</monospace> function, which involve randomization, we set a seed equal to 9, i.e. <monospace>set.seed(9)</monospace>. The global minimum values obtained by the BFGS, Nelder-Mead and SANN methods are identical and influenced by the starting values. Unlike these methods, the PSO method implemented by the <monospace>pso()</monospace> function does not require initial values. These results can be replicated using the <bold>AdequacyModel</bold> package and the examples that follow. There is no need for initial information for optimizations through the <monospace>pso()</monospace> function.</p>
      </sec>
      <sec id="sec009">
        <title>3.2.2 Easom function</title>
        <p>We now consider the Easom function <italic>f</italic>(<italic>x</italic>, <italic>y</italic>) = −cos(<italic>x</italic>) cos(<italic>y</italic>) exp{−[(<italic>x</italic> − <italic>π</italic>)<sup>2</sup> + (<italic>y</italic> − <italic>π</italic>)<sup>2</sup>]} for −10 ≤ <italic>x</italic>, <italic>y</italic> ≤ 10. <xref ref-type="fig" rid="pone.0221487.g002">Fig 2a and 2b</xref> display different angles of the function. The Easom function is minimized at <italic>x</italic> = <italic>y</italic> = <italic>π</italic> with <italic>f</italic>(<italic>π</italic>, <italic>π</italic>) = −1. The <monospace>pso()</monospace> function to minimize <italic>f</italic>(<italic>x</italic>, <italic>y</italic>) is</p>
        <p>
          <monospace>R&gt; easom &lt;- function(x, par){</monospace>
        </p>
        <p>
          <monospace>+  x1 &lt;- par[1]</monospace>
        </p>
        <p>
          <monospace>+  x2 &lt;- par[2]</monospace>
        </p>
        <p>
          <monospace>+  -cos(x1) * cos(x2) * exp(-((x1 − pi) ^ 2 + (x2 − pi) ^ 2))</monospace>
        </p>
        <p>
          <monospace>+ }</monospace>
        </p>
        <p>
          <monospace>R&gt; set.seed(9)</monospace>
        </p>
        <p>
          <monospace>R&gt; results_pso &lt;- pso(func = easom, S = 500, lim_inf = c(-10, -10),</monospace>
        </p>
        <p>
          <monospace>+            lim_sup = c(10, 10), e = 0.0001)</monospace>
        </p>
        <fig id="pone.0221487.g002" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0221487.g002</object-id>
          <label>Fig 2</label>
          <caption>
            <title>Easom function from two different angles.</title>
          </caption>
          <graphic xlink:href="pone.0221487.g002"/>
        </fig>
        <p>Before execution of the <monospace>pso</monospace> function, we set <monospace>set.seed(9)</monospace>, for which the same results can be replicated. The estimated minimum points of the <monospace>pso</monospace> function are <inline-formula id="pone.0221487.e015"><alternatives><graphic xlink:href="pone.0221487.e015.jpg" id="pone.0221487.e015g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M15"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mo>.</mml:mo><mml:mn>139752</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0221487.e016"><alternatives><graphic xlink:href="pone.0221487.e016.jpg" id="pone.0221487.e016g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M16"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mo>.</mml:mo><mml:mn>141564</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, which are very close to <italic>x</italic> = <italic>y</italic> = <italic>π</italic>. The convergence of the algorithm for values very close to the global optimum can be noted from the level curves in <xref ref-type="fig" rid="pone.0221487.g003">Fig 3</xref>.</p>
        <fig id="pone.0221487.g003" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0221487.g003</object-id>
          <label>Fig 3</label>
          <caption>
            <title>Levels of the Easom function.</title>
            <p>The white point is the minimum value obtained by the <monospace>pso()</monospace> function.</p>
          </caption>
          <graphic xlink:href="pone.0221487.g003"/>
        </fig>
        <p>We use the BFGS method through the <monospace>optim()</monospace> function and take initial values as <italic>x</italic> = −9 and <italic>y</italic> = 9. Note that the convergence is achieved in the BFGS method and the estimated minimum points coincide with the fixed initial values (<inline-formula id="pone.0221487.e017"><alternatives><graphic xlink:href="pone.0221487.e017.jpg" id="pone.0221487.e017g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M17"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0221487.e018"><alternatives><graphic xlink:href="pone.0221487.e018.jpg" id="pone.0221487.e018g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M18"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>), which is quite different from the true minimum point <italic>x</italic> = <italic>y</italic> = <italic>π</italic>. Thus, the BFGS method is very sensitive to initial values. The reader can observe this fact from the code below.</p>
        <p>
          <monospace>R&gt; easom1 &lt;- function(x){</monospace>
        </p>
        <p>
          <monospace>+  x1 &lt;- x[1]</monospace>
        </p>
        <p>
          <monospace>+  x2 &lt;- x[2]</monospace>
        </p>
        <p>
          <monospace>+  -cos(x1) * cos(x2) * exp(-((x1 − pi) ^ 2 + (x2 − pi) ^ 2))</monospace>
        </p>
        <p>
          <monospace>+}</monospace>
        </p>
        <p>
          <monospace>R&gt; result_bfgs_easom &lt;- optim(par = c(9, 9), fn = easom1, method = “BFGS”)</monospace>
        </p>
        <p>Notice that <monospace>result_bfgs_easom$convergence == 0</monospace> equal to <monospace>TRUE</monospace> indicates convergence. Execute <monospace>help(optim)</monospace> for more details about the convergence criterion of the BFGS method implemented in the <monospace>optim</monospace> function. For the Easom function, convergence is harmed by the existence of infinite candidates for the minimum point distributed over a flat region. The output stored in the object <monospace>result_bfgs_easom</monospace> is presented below:</p>
        <p>
          <monospace>R&gt; result_bfgs_easom</monospace>
        </p>
        <p>
          <monospace>$par</monospace>
        </p>
        <p>
          <monospace>[1] -9 9</monospace>
        </p>
        <p>
          <monospace>$value</monospace>
        </p>
        <p>
          <monospace>[1] -1.283436e-30</monospace>
        </p>
        <p>
          <monospace>$counts</monospace>
        </p>
        <p>
          <monospace>function gradient</monospace>
        </p>
        <p>
          <monospace>1   1</monospace>
        </p>
        <p>
          <monospace>$convergence</monospace>
        </p>
        <p>
          <monospace>[1] 0</monospace>
        </p>
        <p>
          <monospace>$message</monospace>
        </p>
        <p>
          <monospace>NULL</monospace>
        </p>
        <p>Setting <monospace>result_nelder_easom &lt;- optim(par = c(-9, 9), fn = easom1, method = “Nelder-Mead”)</monospace>, we also obtain a distant point from the true global minimum point, where <inline-formula id="pone.0221487.e019"><alternatives><graphic xlink:href="pone.0221487.e019.jpg" id="pone.0221487.e019g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M19"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0221487.e020"><alternatives><graphic xlink:href="pone.0221487.e020.jpg" id="pone.0221487.e020g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M20"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> giving a minimum value approximately equal to zero. The results stored in <monospace>result_nelder_easom</monospace> are given below:</p>
        <p>
          <monospace>R&gt; result_nelder_easom</monospace>
        </p>
        <p>
          <monospace>$par</monospace>
        </p>
        <p>
          <monospace>[1] -8.1 9.0</monospace>
        </p>
        <p>
          <monospace>$value</monospace>
        </p>
        <p>
          <monospace>[1] -3.609875e-71</monospace>
        </p>
        <p>
          <monospace>$counts</monospace>
        </p>
        <p>
          <monospace>function gradient</monospace>
        </p>
        <p>
          <monospace>3   NA</monospace>
        </p>
        <p>
          <monospace>$convergence</monospace>
        </p>
        <p>
          <monospace>[1] 0</monospace>
        </p>
        <p>
          <monospace>$message</monospace>
        </p>
        <p>
          <monospace>NULL</monospace>
        </p>
        <p>A similar fact based on the simulated method can be found in the script below:</p>
        <p>
          <monospace>R&gt; set.seed(9)</monospace>
        </p>
        <p>
          <monospace>R&gt; result_sann_easom &lt;- optim(par = c(-9, 9), fn = easom1,</monospace>
        </p>
        <p>
          <monospace>+          method = “SANN”)</monospace>
        </p>
        <p>As in the previous cases, we note that <monospace>result_sann_easom$convergence == 0</monospace> is <monospace>TRUE</monospace> (there is convergence) and the estimated minimum point has coordinates distant from the coordinates of the true minimum point. The estimated coordinates are <inline-formula id="pone.0221487.e021"><alternatives><graphic xlink:href="pone.0221487.e021.jpg" id="pone.0221487.e021g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M21"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mn>110688</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0221487.e022"><alternatives><graphic xlink:href="pone.0221487.e022.jpg" id="pone.0221487.e022g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M22"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>13</mml:mn><mml:mo>.</mml:mo><mml:mn>934928</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> with the seed fixed at 9, i.e. <monospace>set.seed(9)</monospace>.</p>
      </sec>
      <sec id="sec010">
        <title>3.2.3 Cross-in-tray function</title>
        <p>Now, we use the <monospace>pso</monospace> function to minimize the Cross-in-tray function. This is a difficult function to be minimized for different reasons from those presented in the previous examples. The Cross-in-tray function has many local minima as can be seen in <xref ref-type="fig" rid="pone.0221487.g004">Fig 4a and 4b</xref>. This fact can certainly harm the convergence of various algorithms that search for a global optimum. The Cross-in-tray function is
<disp-formula id="pone.0221487.e023"><alternatives><graphic xlink:href="pone.0221487.e023.jpg" id="pone.0221487.e023g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M23"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>0001</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mo>|</mml:mo><mml:mtext>sin</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="2pt"/><mml:mtext>sin</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="2pt"/><mml:mtext>exp</mml:mtext><mml:mo>(</mml:mo><mml:mo>|</mml:mo><mml:mn>100</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:msqrt><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt><mml:mi>π</mml:mi></mml:mfrac><mml:mo>|</mml:mo><mml:mo>)</mml:mo><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msup><mml:mo>)</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where −10 ≤ <italic>x</italic>, <italic>y</italic> ≤ 10 and
<disp-formula id="pone.0221487.e024"><alternatives><graphic xlink:href="pone.0221487.e024.jpg" id="pone.0221487.e024g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M24"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>Min</mml:mtext><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mn>34941</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mn>34941</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>.</mml:mo><mml:mn>06261</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mn>34941</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mn>34941</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>.</mml:mo><mml:mn>06261</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mn>34941</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mn>34941</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>.</mml:mo><mml:mn>06261</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mn>34941</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mn>34941</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>.</mml:mo><mml:mn>06261</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo/></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
        <fig id="pone.0221487.g004" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0221487.g004</object-id>
          <label>Fig 4</label>
          <caption>
            <title>Cross-in-tray function from two different angles.</title>
          </caption>
          <graphic xlink:href="pone.0221487.g004"/>
        </fig>
        <p>This function has four points of global minimum. Any estimate of the minimum point <inline-formula id="pone.0221487.e025"><alternatives><graphic xlink:href="pone.0221487.e025.jpg" id="pone.0221487.e025g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M25"><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> with a minimum value close to −2.0626 can be regarded as a good solution.</p>
        <p>By means of the <monospace>optim</monospace> function, we note the convergence of the BFGS, SANN and Nelder-Mead methods with initial values at <italic>x</italic> = 0 and <italic>y</italic> = 0. The estimated values of <italic>x</italic> and <italic>y</italic> are equal to <inline-formula id="pone.0221487.e026"><alternatives><graphic xlink:href="pone.0221487.e026.jpg" id="pone.0221487.e026g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M26"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0221487.e027"><alternatives><graphic xlink:href="pone.0221487.e027.jpg" id="pone.0221487.e027g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M27"><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>0001</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> for the three approaches. The minimization of the Cross-in-tray function adopting the PSO algorithm achieves a satisfactory outcome as shown in <xref ref-type="fig" rid="pone.0221487.g005">Fig 5</xref>. The estimated minimum point is (1.3490, 1.3490) yielding the minimum value <italic>f</italic>(1.3490, 1.3490) = −2.0626. The results can be obtained with the script below:</p>
        <p>
          <monospace>R&gt; cross &lt;- function(x, par){</monospace>
        </p>
        <p>
          <monospace>+  x1 &lt;- par[1]</monospace>
        </p>
        <p>
          <monospace>+  x2 &lt;- par[2]</monospace>
        </p>
        <p>
          <monospace>+  -0.0001 * (abs(sin(x1) * sin(x2) *</monospace>
        </p>
        <p>
          <monospace>+         exp(abs(100 − sqrt(x1 ^ 2 + x2 ^ 2) / pi))) + 1) ^ 0.1</monospace>
        </p>
        <p>
          <monospace>+ }</monospace>
        </p>
        <p>
          <monospace>R&gt; set.seed(9)</monospace>
        </p>
        <p>
          <monospace>R&gt; result_pso_cross &lt;- pso(func = cross, S = 500, lim_inf = c(-10, -10),</monospace>
        </p>
        <p>
          <monospace>+               lim_sup = c(10, 10), e = 0.0001)</monospace>
        </p>
        <fig id="pone.0221487.g005" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0221487.g005</object-id>
          <label>Fig 5</label>
          <caption>
            <title>Levels of the Cross-in-tray function.</title>
            <p>The white point is the minimum value obtained by the <monospace>pso()</monospace> function.</p>
          </caption>
          <graphic xlink:href="pone.0221487.g005"/>
        </fig>
        <p><bold>Note</bold>: The results of the optimization using the <monospace>optim()</monospace> function and the Nelder-Mead, BFGS and simulated annealing methods can be determined from the code below. For all three methods, the initial value is chosen as (0, 0).</p>
        <p>
          <monospace>R&gt; cross1 &lt;- function(x){</monospace>
        </p>
        <p>
          <monospace>+  x1 &lt;- x[1]</monospace>
        </p>
        <p>
          <monospace>+  x2 &lt;- x[2]</monospace>
        </p>
        <p>
          <monospace>+  -0.0001 * (abs(sin(x1) * sin(x2) *</monospace>
        </p>
        <p>
          <monospace>+        exp(abs(100 − sqrt(x1 ^ 2 + x2 ^ 2) / pi))) + 1) ^ 0.1</monospace>
        </p>
        <p>
          <monospace>+ }</monospace>
        </p>
        <p>
          <monospace>R&gt; result_bfgs_cross &lt;- optim(par = c(0, 0), fn = cross1, lower = -10,</monospace>
        </p>
        <p>
          <monospace>+                upper = 10, method = “BFGS”)</monospace>
        </p>
        <p>
          <monospace>R&gt; result_nelder_cross &lt;- optim(par = c(0, 0), fn = cross1, lower = -10,</monospace>
        </p>
        <p>
          <monospace>+                upper = 10, method = “Nelder-Mead”)</monospace>
        </p>
        <p>
          <monospace>R&gt; set.seed(9)</monospace>
        </p>
        <p>
          <monospace>R&gt; result_sann_cross &lt;- optim(par = c(0, 0), fn = cross1, lower = -10,</monospace>
        </p>
        <p>
          <monospace>+                upper = 10, method = “SANN”)</monospace>
        </p>
      </sec>
      <sec id="sec011">
        <title>3.2.4 Hölder function</title>
        <p>We consider the Hölder function, a very peculiar function that is difficult to be optimized, defined by
<disp-formula id="pone.0221487.e028"><alternatives><graphic xlink:href="pone.0221487.e028.jpg" id="pone.0221487.e028g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M28"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mo>|</mml:mo><mml:mtext>sin</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="2pt"/><mml:mtext>cos</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="2pt"/><mml:mtext>exp</mml:mtext><mml:mo>(</mml:mo><mml:mo>|</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:msqrt><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt><mml:mi>π</mml:mi></mml:mfrac><mml:mo>|</mml:mo><mml:mo>)</mml:mo><mml:mo>|</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where
<disp-formula id="pone.0221487.e029"><alternatives><graphic xlink:href="pone.0221487.e029.jpg" id="pone.0221487.e029g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M29"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>Min</mml:mtext><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>05502</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mn>9</mml:mn><mml:mo>.</mml:mo><mml:mn>66459</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mn>19</mml:mn><mml:mo>.</mml:mo><mml:mn>2085</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>05502</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mn>9</mml:mn><mml:mo>.</mml:mo><mml:mn>66459</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mn>19</mml:mn><mml:mo>.</mml:mo><mml:mn>2085</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>05502</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mo>−</mml:mo><mml:mn>9</mml:mn><mml:mo>.</mml:mo><mml:mn>66459</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mn>19</mml:mn><mml:mo>.</mml:mo><mml:mn>2085</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mn>8</mml:mn><mml:mo>.</mml:mo><mml:mn>05502</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mo>−</mml:mo><mml:mn>9</mml:mn><mml:mo>.</mml:mo><mml:mn>66459</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:mn>19</mml:mn><mml:mo>.</mml:mo><mml:mn>2085</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo/></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
and −10 ≤ <italic>x</italic>, <italic>y</italic> ≤ 10. <xref ref-type="fig" rid="pone.0221487.g006">Fig 6</xref> plots the Hölder function defined above.</p>
        <fig id="pone.0221487.g006" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0221487.g006</object-id>
          <label>Fig 6</label>
          <caption>
            <title>Hölder function at two different angles.</title>
          </caption>
          <graphic xlink:href="pone.0221487.g006"/>
        </fig>
        <p>For the Hölder function, the results obtained from the BFGS, SANN and Nelder-Mead methods, as in the previous examples, are not good. However, in all cases, there is convergence following the methods implemented in the <monospace>optim()</monospace> function. For initial values at (0, 0), the convergence leads to (0, 0), i.e., the three methods estimate the minimum point as <inline-formula id="pone.0221487.e030"><alternatives><graphic xlink:href="pone.0221487.e030.jpg" id="pone.0221487.e030g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M30"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0221487.e031"><alternatives><graphic xlink:href="pone.0221487.e031.jpg" id="pone.0221487.e031g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M31"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. For the SANN method, we set <monospace>set.seed(9)</monospace>. However, the problem is easily circumvented by increasing the number of iterations. <xref ref-type="fig" rid="pone.0221487.g007">Fig 7</xref> plots the levels of the Hölder function versus the point of convergence of the PSO algorithm. We used the following script:</p>
        <p>
          <monospace>R&gt; holder &lt;- function(x, par){</monospace>
        </p>
        <p>
          <monospace>+  x1 &lt;- par[1]</monospace>
        </p>
        <p>
          <monospace>+  x2 &lt;- par[2]</monospace>
        </p>
        <p>
          <monospace>+  -abs(sin(x1) * cos(x2) * exp(abs(1 − sqrt(x1 ^ 2 + x2 ^ 2) / pi)))</monospace>
        </p>
        <p>
          <monospace>+ }</monospace>
        </p>
        <p>
          <monospace>R&gt; set.seed(9)</monospace>
        </p>
        <p>
          <monospace>R&gt; result_pso_holder &lt;- pso(func = holder, S = 500,</monospace>
        </p>
        <p>
          <monospace>+               lim_inf = c(-10, -10),</monospace>
        </p>
        <p>
          <monospace>+               lim_sup = c(10, 10), e = 0.0001)</monospace>
        </p>
        <fig id="pone.0221487.g007" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0221487.g007</object-id>
          <label>Fig 7</label>
          <caption>
            <title>Levels of the Hölder function.</title>
            <p>The white point is the minimum value obtained by the <monospace>pso()</monospace> function.</p>
          </caption>
          <graphic xlink:href="pone.0221487.g007"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec id="sec012">
    <title>4 Fitting distributions with the AdequacyModel</title>
    <p>The problem of deciding on the suitability of an unknown cumulative distribution function (cdf) <italic>F</italic><sub><italic>θ</italic></sub> from a sample <italic>x</italic><sub>1</sub>, …, <italic>x</italic><sub><italic>n</italic></sub> is equivalent to the decision problem on an unknown parameter <italic>θ</italic>. Let <inline-formula id="pone.0221487.e032"><alternatives><graphic xlink:href="pone.0221487.e032.jpg" id="pone.0221487.e032g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M32"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mspace width="0.166667em"/><mml:mi>θ</mml:mi><mml:mo>∈</mml:mo><mml:mo>Θ</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> be a family of distributions, where Θ is the parameter space of <italic>θ</italic>. The best element <italic>F</italic><sub><italic>θ</italic></sub> in <inline-formula id="pone.0221487.e033"><alternatives><graphic xlink:href="pone.0221487.e033.jpg" id="pone.0221487.e033g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M33"><mml:mi mathvariant="script">F</mml:mi></mml:math></alternatives></inline-formula> can be determined from the MLE <inline-formula id="pone.0221487.e034"><alternatives><graphic xlink:href="pone.0221487.e034.jpg" id="pone.0221487.e034g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M34"><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula> of <italic>θ</italic>. Suppose there exists a <italic>F</italic><sub><italic>θ</italic></sub> for <italic>F</italic> evaluated at <inline-formula id="pone.0221487.e035"><alternatives><graphic xlink:href="pone.0221487.e035.jpg" id="pone.0221487.e035g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M35"><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula>.</p>
    <p>Some statistics are commonly used to verify the adequacy of the cdf <italic>F</italic><sub><italic>θ</italic></sub> to fit the observations. Alternatives to the likelihood ratio test were proposed by [<xref rid="pone.0221487.ref012" ref-type="bibr">12</xref>] by correcting the Cramér-von Mises (<italic>W</italic><sup>2</sup>) and Anderson-Darling (<italic>A</italic><sup>2</sup>) statistics. Let <italic>F</italic><sub><italic>n</italic></sub>(<italic>x</italic>) be the empirical distribution function and <inline-formula id="pone.0221487.e036"><alternatives><graphic xlink:href="pone.0221487.e036.jpg" id="pone.0221487.e036g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M36"><mml:mrow><mml:mi>F</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> the postulated cdf evaluated at <inline-formula id="pone.0221487.e037"><alternatives><graphic xlink:href="pone.0221487.e037.jpg" id="pone.0221487.e037g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M37"><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula>. According to [<xref rid="pone.0221487.ref012" ref-type="bibr">12</xref>], the usual Cramér-von Mises (<italic>W</italic><sup>2</sup>) and Anderson-Darling (<italic>A</italic><sup>2</sup>) statistics can be expressed as
<disp-formula id="pone.0221487.e038"><alternatives><graphic xlink:href="pone.0221487.e038.jpg" id="pone.0221487.e038g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M38"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>W</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>12</mml:mn><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula>
and
<disp-formula id="pone.0221487.e039"><alternatives><graphic xlink:href="pone.0221487.e039.jpg" id="pone.0221487.e039g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M39"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="2pt"/><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="2pt"/><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(2)</label></disp-formula>
respectively, where <inline-formula id="pone.0221487.e040"><alternatives><graphic xlink:href="pone.0221487.e040.jpg" id="pone.0221487.e040g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M40"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>Φ</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover><mml:mi>y</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> (Φ is the standard normal cdf), <inline-formula id="pone.0221487.e041"><alternatives><graphic xlink:href="pone.0221487.e041.jpg" id="pone.0221487.e041g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M41"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, <italic>y</italic><sub><italic>i</italic></sub> = Φ<sup>−1</sup>(<italic>v</italic><sub><italic>i</italic></sub>) and <italic>s</italic><sub><italic>y</italic></sub> is the sample standard deviation of the <italic>y</italic><sub><italic>i</italic></sub>’s for <italic>i</italic> = 1, …, <italic>n</italic>.</p>
    <p>The corrected statistics <italic>W</italic>* and <italic>A</italic>* are given by
<disp-formula id="pone.0221487.e042"><alternatives><graphic xlink:href="pone.0221487.e042.jpg" id="pone.0221487.e042g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M42"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msup><mml:mi>W</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>{</mml:mo><mml:mi>n</mml:mi><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi>d</mml:mi><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:mfrac><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:mfrac><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(3)</label></disp-formula>
<disp-formula id="pone.0221487.e043"><alternatives><graphic xlink:href="pone.0221487.e043.jpg" id="pone.0221487.e043g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M43"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msup><mml:mi>A</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>{</mml:mo><mml:mi>n</mml:mi><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:msubsup><mml:mfrac><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mfrac><mml:mi>d</mml:mi><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>75</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>.</mml:mo><mml:mn>25</mml:mn></mml:mrow><mml:msup><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>75</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>.</mml:mo><mml:mn>25</mml:mn></mml:mrow><mml:msup><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfrac><mml:mo>)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(4)</label></disp-formula></p>
    <p>The statistics <italic>W</italic>* and <italic>A</italic>* measure the difference between <italic>F</italic><sub><italic>n</italic></sub>(<italic>x</italic>) and <inline-formula id="pone.0221487.e044"><alternatives><graphic xlink:href="pone.0221487.e044.jpg" id="pone.0221487.e044g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M44"><mml:mrow><mml:mi>F</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Low values of them provide evidence that <inline-formula id="pone.0221487.e045"><alternatives><graphic xlink:href="pone.0221487.e045.jpg" id="pone.0221487.e045g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M45"><mml:mrow><mml:mi>F</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> generates the data. The null hypothesis tested using (<xref ref-type="disp-formula" rid="pone.0221487.e042">3</xref>) and (<xref ref-type="disp-formula" rid="pone.0221487.e043">4</xref>) is that the random sample has the cdf <italic>F</italic>(<italic>x</italic>;<italic>θ</italic>). The algorithm below can be adopted to compute <italic>W</italic>* and <italic>A</italic>*:
<list list-type="order"><list-item><p>Estimate <italic>θ</italic> by <inline-formula id="pone.0221487.e046"><alternatives><graphic xlink:href="pone.0221487.e046.jpg" id="pone.0221487.e046g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M46"><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, order the observations to compute <inline-formula id="pone.0221487.e047"><alternatives><graphic xlink:href="pone.0221487.e047.jpg" id="pone.0221487.e047g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M47"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>θ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>;</p></list-item><list-item><p>Compute <italic>y</italic><sub><italic>i</italic></sub> = Φ<sup>−1</sup>(<italic>v</italic><sub><italic>i</italic></sub>), where Φ<sup>−1</sup> is the standard normal quantile function;</p></list-item><list-item><p>Compute <inline-formula id="pone.0221487.e048"><alternatives><graphic xlink:href="pone.0221487.e048.jpg" id="pone.0221487.e048g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M48"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>Φ</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover><mml:mi>y</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pone.0221487.e049"><alternatives><graphic xlink:href="pone.0221487.e049.jpg" id="pone.0221487.e049g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M49"><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0221487.e050"><alternatives><graphic xlink:href="pone.0221487.e050.jpg" id="pone.0221487.e050g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M50"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover><mml:mi>y</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>;</p></list-item><list-item><p>Compute <italic>W</italic><sup>2</sup> and <italic>A</italic><sup>2</sup> using (<xref ref-type="disp-formula" rid="pone.0221487.e038">1</xref>) and (<xref ref-type="disp-formula" rid="pone.0221487.e039">2</xref>), respectively;</p></list-item><list-item><p>Compute <italic>W</italic>* = <italic>W</italic><sup>2</sup>(1 + 0.5/<italic>n</italic>) and <italic>A</italic>* = <italic>A</italic><sup>2</sup>(1 + 0.75/<italic>n</italic> + 2.25/<italic>n</italic><sup>2</sup>), where <italic>n</italic> is the sample size;</p></list-item><list-item><p>Reject <inline-formula id="pone.0221487.e051"><alternatives><graphic xlink:href="pone.0221487.e051.jpg" id="pone.0221487.e051g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M51"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></alternatives></inline-formula> at the significance level <italic>α</italic> if the test statistics exceed the critical values presented by [<xref rid="pone.0221487.ref012" ref-type="bibr">12</xref>].</p></list-item></list></p>
    <p>In practice, we can use <italic>W</italic>* and <italic>A</italic>* to compare two or more continuous distributions. The distribution that gives the lowest values of these statistics is the best suited to explain the random sample. The <monospace>goodness.fit()</monospace> function provides some useful statistics to assess the quality of fit of probabilistic models by including <italic>W</italic>* and <italic>A</italic>*. The function can also compute other measures such as the Akaike Information Criterion (AIC), Consistent Akaike Information Criterion (CAIC), Bayesian Information Criterion (BIC), Hannan-Quinn Information Criterion (HQIC) and Kolmogorov-Smirnov Test (KST). The general form for the function is given below:</p>
    <p>
      <monospace>goodness.fit(pdf, cdf, starts = NULL, data, method = “PSO”,</monospace>
    </p>
    <p>
      <monospace>       domain = c(0, Inf), mle = NULL)</monospace>
    </p>
    <p specific-use="continuation">where
<list list-type="bullet"><list-item><p><monospace>pdf</monospace>: probability density function (pdf);</p></list-item><list-item><p><monospace>cdf</monospace>: cumulative distribution function;</p></list-item><list-item><p><monospace>starts</monospace>: initial parameters to maximize the likelihood function;</p></list-item><list-item><p><monospace>data</monospace>: data vector;</p></list-item><list-item><p><monospace>method</monospace>: method used for minimization of the -log-likelihood function. The methods supported are: PSO (default), BFGS, Nelder-Mead, SANN, CG (conjugate gradient). We can also provide only the first letter of the methods, i.e., P, B, N, S or C, respectively;</p></list-item><list-item><p><monospace>domain</monospace>: domain of the pdf. By default the domain of the pdf is the open interval (0, ∞). This option must be a vector with two components;</p></list-item><list-item><p><monospace>mle</monospace>: vector with the MLEs. This option should be used if one already has knowledge of the MLEs. The default is NULL, i.e., the function will try to obtain the MLEs;</p></list-item><list-item><p><monospace>…</monospace>: If <monospace>method = “PSO”</monospace>, then all arguments of the <monospace>pso()</monospace> function could be passed to the <monospace>goodness.fit()</monospace> function.</p></list-item></list></p>
    <p>It is not necessary to define the likelihood function or log-likelihood but only the pdf or the cdf. The function will check the validity of the arguments passed to <monospace>goodness.fit()</monospace>. For example, if the supplied functions to the arguments <monospace>pdf</monospace> or <monospace>cdf</monospace> are not genuine pdfs or cdfs, a message will be given so that the user can check the arguments passed. We provide below two examples of the use of the <monospace>goodness.fit()</monospace> function.</p>
    <sec id="sec013">
      <title>4.1 Carbon fiber data</title>
      <p>Consider a data set of stress (until fracture) of carbon fibres (in Gba). The data can be obtained from [<xref rid="pone.0221487.ref013" ref-type="bibr">13</xref>]. The data and some details can be accessed with the command <monospace>data(carbone)</monospace> in the <bold>AdequacyModel</bold> package. Suppose also that we are interested in choosing the best model in <inline-formula id="pone.0221487.e052"><alternatives><graphic xlink:href="pone.0221487.e052.jpg" id="pone.0221487.e052g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M52"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>F</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mspace width="0.166667em"/><mml:mi>θ</mml:mi><mml:mo>∈</mml:mo><mml:mo>Θ</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> that can represent the distribution of observations in <monospace>carbone</monospace>. We suppose that <inline-formula id="pone.0221487.e053"><alternatives><graphic xlink:href="pone.0221487.e053.jpg" id="pone.0221487.e053g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M53"><mml:mi mathvariant="script">F</mml:mi></mml:math></alternatives></inline-formula> is exponentiated Weibull (Exp-Weibull) distributed with cdf
<disp-formula id="pone.0221487.e054"><alternatives><graphic xlink:href="pone.0221487.e054.jpg" id="pone.0221487.e054g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M54"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>[</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>α</mml:mi><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>β</mml:mi></mml:msup><mml:mo>]</mml:mo><mml:msup><mml:mo>}</mml:mo><mml:mi>a</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mspace width="0.166667em"/><mml:mspace width="0.166667em"/><mml:mi>x</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <italic>α</italic>, <italic>β</italic> and <italic>a</italic> are positive parameters. Thus, each element in <inline-formula id="pone.0221487.e055"><alternatives><graphic xlink:href="pone.0221487.e055.jpg" id="pone.0221487.e055g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M55"><mml:mi mathvariant="script">F</mml:mi></mml:math></alternatives></inline-formula> is of the form <italic>F</italic>(<italic>x</italic>; <italic>α</italic>, <italic>β</italic>, <italic>a</italic>). We initially implement the pdf <italic>f</italic>(<italic>x</italic>; <italic>α</italic>, <italic>β</italic>, <italic>a</italic>) and cdf <italic>F</italic>(<italic>x</italic>; <italic>α</italic>, <italic>β</italic>, <italic>a</italic>). They will serve as arguments for <monospace>pdf</monospace> and <monospace>cdf</monospace>, respectively. We present below the implementation of these functions input to the <monospace>goodness.fit()</monospace> function.</p>
      <p>
        <monospace>R&gt; # Probability density function.</monospace>
      </p>
      <p>
        <monospace>R&gt; pdf_expweibull &lt;- function(par, x) {</monospace>
      </p>
      <p>
        <monospace>+  alpha &lt;- par[1]</monospace>
      </p>
      <p>
        <monospace>+  beta &lt;- par[2]</monospace>
      </p>
      <p>
        <monospace>+  a &lt;- par[3]</monospace>
      </p>
      <p>
        <monospace>+  alpha * beta * a * exp(-(alpha * x) ^ beta) * (alpha * x) ^ (beta</monospace>
      </p>
      <p>
        <monospace>+  - 1) * (1 − exp(-(alpha * x) ^ beta)) ^ (a − 1)</monospace>
      </p>
      <p>
        <monospace>+ }</monospace>
      </p>
      <p>
        <monospace>R&gt; # Cumulative distribution function.</monospace>
      </p>
      <p>
        <monospace>R&gt; cdf_expweibull &lt;- function(par, x) {</monospace>
      </p>
      <p>
        <monospace>+  alpha &lt;- par[1]</monospace>
      </p>
      <p>
        <monospace>+  beta &lt;- par[2]</monospace>
      </p>
      <p>
        <monospace>+  a &lt;- par[3]</monospace>
      </p>
      <p>
        <monospace>+  (1 − exp(-(alpha * x) ^ beta)) ^ a</monospace>
      </p>
      <p>
        <monospace>+ }</monospace>
      </p>
      <p>
        <monospace>R&gt; data(carbone)</monospace>
      </p>
      <p>
        <monospace>R&gt; results &lt;- goodness.fit(pdf = pdf_expweibull, cdf = cdf_expweibull,</monospace>
      </p>
      <p>
        <monospace>+              starts = c(1, 1, 1), data = carbone,</monospace>
      </p>
      <p>
        <monospace>+              method = “BFGS”, domain = c(0, Inf),</monospace>
      </p>
      <p>
        <monospace>+              mle = NULL)</monospace>
      </p>
      <p>The object <monospace>results</monospace> features all goodness-of-fit statistics cited previously as well as the MLEs in case <monospace>mle = NULL</monospace> (default) and the standard errors of the MLEs if the argument <monospace>method</monospace> receives <monospace>PSO</monospace>, <monospace>BFGS</monospace>, <monospace>Nelder-Mead</monospace>, <monospace>SANN</monospace> or <monospace>CG</monospace>. Thus,
<list list-type="bullet"><list-item><p><monospace>R&gt; results$W</monospace> provides the statistic <italic>W</italic>*;</p></list-item><list-item><p><monospace>R&gt; results$A</monospace> provides the statistic <italic>A</italic>*;</p></list-item><list-item><p><monospace>R&gt; results$KS</monospace> provides the Kolmogorov-Smirnov statistic;</p></list-item><list-item><p><monospace>R&gt; results$mle</monospace> provides a vector with the MLEs of the model parameters given as arguments for the <monospace>pdf</monospace>;</p></list-item><list-item><p><monospace>R&gt; results$AIC</monospace>: provides the AIC statistic;</p></list-item><list-item><p><monospace>R&gt; results$CAIC</monospace>: provides the CAIC statistic;</p></list-item><list-item><p><monospace>R&gt; results$BIC</monospace>: provides the BIC statistic;</p></list-item><list-item><p><monospace>R&gt; results$HQIC</monospace>: provides the HQIC statistic;</p></list-item><list-item><p><monospace>R&gt; result$KS</monospace>: returns an object of class <monospace>htest</monospace> with information on the Kolmogorov-Smirnov test;</p></list-item><list-item><p><monospace>R&gt; results$Erro</monospace>: provides the standard errors of the MLEs of the parameters, given as arguments for <monospace>pdf</monospace> and <monospace>cdf</monospace>;</p></list-item><list-item><p><monospace>R&gt; results$value</monospace>: displays the minimum value of <monospace>-log(likelihood)</monospace>;</p></list-item><list-item><p><monospace>R&gt; result$Convergence</monospace>: provides information on the convergence of the method passed as an argument for <monospace>method</monospace>.
If <monospace>result$Convergence</monospace> == 0 is <monospace>TRUE</monospace>, there was convergence.</p></list-item></list></p>
      <p>In case <monospace>method = “PSO”</monospace> (default), the standard errors will not be provided. The researcher may obtain these standard errors using bootstrap, see [<xref rid="pone.0221487.ref014" ref-type="bibr">14</xref>]. We provide below the results stored in the object <monospace>results</monospace> (output of the <monospace>goodness.fit()</monospace> function) and a plot of the fitted Exp-Weibull pdf.</p>
      <p>
        <monospace>R&gt; results</monospace>
      </p>
      <p>
        <monospace>$W</monospace>
      </p>
      <p>
        <monospace>[1] 0.07047089</monospace>
      </p>
      <p>
        <monospace>$A</monospace>
      </p>
      <p>
        <monospace>[1] 0.4133608</monospace>
      </p>
      <p>
        <monospace>$KS</monospace>
      </p>
      <p>
        <monospace>One-sample Kolmogorov-Smirnov test</monospace>
      </p>
      <p>
        <monospace>data: data</monospace>
      </p>
      <p>
        <monospace>D = 0.064568, p-value = 0.7987</monospace>
      </p>
      <p>
        <monospace>alternative hypothesis: two-sided</monospace>
      </p>
      <p>
        <monospace>$mle</monospace>
      </p>
      <p>
        <monospace>[1] 0.3731249 2.4058010 1.3198053</monospace>
      </p>
      <p>
        <monospace>$AIC</monospace>
      </p>
      <p>
        <monospace>[1] 288.6641</monospace>
      </p>
      <p>
        <monospace>$CAIC</monospace>
      </p>
      <p>
        <monospace>[1] 288.9141</monospace>
      </p>
      <p>
        <monospace>$BIC</monospace>
      </p>
      <p>
        <monospace>[1] 296.4796</monospace>
      </p>
      <p>
        <monospace>$HQIC</monospace>
      </p>
      <p>
        <monospace>[1] 291.8272</monospace>
      </p>
      <p>
        <monospace>$Erro</monospace>
      </p>
      <p>
        <monospace>[1] 0.06265212 0.60467076 0.59835491</monospace>
      </p>
      <p>
        <monospace>$Value</monospace>
      </p>
      <p>
        <monospace>[1] 141.332</monospace>
      </p>
      <p>
        <monospace>$Convergence</monospace>
      </p>
      <p>
        <monospace>[1] 0</monospace>
      </p>
      <p><bold>Notes</bold>: (<italic>i</italic>) The Kolmogorov-Smirnov statistic may return <monospace>NA</monospace> with a certain frequency, meaning that this statistic is not reliable for the current data. More details about this issue can be read from <monospace>help(ks.test)</monospace>. In situations where <monospace>results$Convergence==0</monospace> is <monospace>TRUE</monospace>, there is convergence for the method passed as an argument to <monospace>method</monospace> that minimizes the log-likelihood function multiplied by -1, that is, the method minimizes <monospace>-log(likelihood)</monospace>. (<italic>ii</italic>) The convergence criterion as well as other details about possible values returned by <monospace>results$Convergence</monospace> can be obtained with <monospace>help(optim)</monospace> if the argument <monospace>method</monospace> of the <monospace>goodness.fit()</monospace> function receives the strings <monospace>“BFGS”</monospace>, <monospace>“Nelder-Mead”</monospace>, <monospace>“SANN”</monospace> or <monospace>“CG”</monospace> (or the initial letters <monospace>“B”</monospace>, <monospace>“N”</monospace>, <monospace>“S”</monospace> or <monospace>“C”</monospace>). For the PSO method (default <monospace>method = “PSO”</monospace>), the convergence criterion is displayed as discussed in Section 2, which is normally satisfied. (<italic>iii</italic>) The script for <xref ref-type="fig" rid="pone.0221487.g008">Fig 8</xref> is:</p>
      <p>
        <monospace>R&gt; pdf(file = “plot_adjustment.pdf”, width = 9, height = 9, paper = “special”,</monospace>
      </p>
      <p>
        <monospace>+   family = “Bookman”, pointsize = 14)</monospace>
      </p>
      <p>
        <monospace>x = seq(0, 6, length.out = 250)</monospace>
      </p>
      <p>
        <monospace>hist(carbone, probability = TRUE, xlab = “x”, main = “”)</monospace>
      </p>
      <p>
        <monospace>lines(x, pdf_expweibull(par = results$mle, x), lwd = 2)</monospace>
      </p>
      <p>
        <monospace>legend(“topright”, legend = c(expression(paste(“Exp-Weibull”))), lwd = c(2.5),</monospace>
      </p>
      <p>
        <monospace>+   inset = 0.03, lty = c(1), cex = 1.1, col = c(“black”))</monospace>
      </p>
      <p>
        <monospace>dev.off()</monospace>
      </p>
      <fig id="pone.0221487.g008" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0221487.g008</object-id>
        <label>Fig 8</label>
        <caption>
          <title>Fitted Exp-Weibull pdf to stress data (until fracture) of carbon fibers in Gba.</title>
        </caption>
        <graphic xlink:href="pone.0221487.g008"/>
      </fig>
    </sec>
    <sec id="sec014">
      <title>4.2 Flood level data</title>
      <p>As a second example, we shall analyse a data set from [<xref rid="pone.0221487.ref015" ref-type="bibr">15</xref>] which refers to 20 observations of the maximum ood level (in millions of cubic feet per second) for the Susquehanna River in Harrisburg, Pennsylvania. The data are: 0.26, 0.27, 0.30, 0.32, 0.32, 0.34, 0.38, 0.38, 0.39, 0.40, 0.41, 0.42, 0.42, 0.42, 0.45, 0.48, 0.49, 0.61, 0.65, 0.74. These data were fitted by using the Kumaraswamy beta (Kw-beta) distribution.</p>
      <p>A random variable <italic>X</italic> follows a Kw-beta distribution with parameters <italic>a</italic>, <italic>b</italic>, <italic>α</italic>, <italic>β</italic> &gt; 0 if its cdf and pdf are given by
<disp-formula id="pone.0221487.e056"><alternatives><graphic xlink:href="pone.0221487.e056.jpg" id="pone.0221487.e056g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M56"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>G</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>a</mml:mi></mml:msup><mml:mo>}</mml:mo></mml:mrow><mml:mi>b</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
and
<disp-formula id="pone.0221487.e057"><alternatives><graphic xlink:href="pone.0221487.e057.jpg" id="pone.0221487.e057g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M57"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mspace width="0.166667em"/><mml:mi>b</mml:mi><mml:mspace width="0.166667em"/><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>G</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>G</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>a</mml:mi></mml:msup><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
respectively, where <italic>G</italic>(<italic>x</italic>; <italic>α</italic>, <italic>β</italic>) = I<sub><italic>x</italic></sub>(<italic>α</italic>, <italic>β</italic>), <italic>g</italic>(<italic>x</italic>; <italic>α</italic>, <italic>β</italic>) = <italic>x</italic><sup><italic>α</italic>−1</sup>(1 − <italic>x</italic>)<sup><italic>b</italic>−1</sup>/B(<italic>a</italic>, <italic>b</italic>), I<sub><italic>x</italic></sub>(<italic>a</italic>, <italic>b</italic>) denotes the incomplete beta function ratio <inline-formula id="pone.0221487.e058"><alternatives><graphic xlink:href="pone.0221487.e058.jpg" id="pone.0221487.e058g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M58"><mml:mrow><mml:msub><mml:mtext>I</mml:mtext><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mtext>B</mml:mtext><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>y</mml:mi></mml:msubsup><mml:msup><mml:mi>ω</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ω</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mtext>d</mml:mtext><mml:mi>ω</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> and B(⋅, ⋅) denotes the beta function.</p>
      <p>Obviously, due to the genesis of the Kw-beta distribution, the flood levels are ideally modelled by this distribution. Thus, the use of the Kw-beta distribution for fitting this data set is well justified. We present below the implementation of the functions input to the <monospace>goodness.fit()</monospace> function.</p>
      <p>
        <monospace>R&gt; # Kumaraswamy Beta—Probability density function.</monospace>
      </p>
      <p>
        <monospace>R&gt; pdf_kwbeta &lt;- function(par, x){</monospace>
      </p>
      <p>
        <monospace>+  beta &lt;- par[1]</monospace>
      </p>
      <p>
        <monospace>+  a &lt;- par[2]</monospace>
      </p>
      <p>
        <monospace>+  alpha &lt;- par[3]</monospace>
      </p>
      <p>
        <monospace>+  b &lt;- par[4]</monospace>
      </p>
      <p>
        <monospace>+  (a * b * x ^ (alpha − 1) * (1 − x) ^ (beta- 1) *</monospace>
      </p>
      <p>
        <monospace>+  (pbeta(x,alpha,beta)) ^ (a − 1) *</monospace>
      </p>
      <p>
        <monospace>+  (1 − pbeta(x, alpha, beta) ^ a) ^ (b − 1)) / beta(alpha, beta)</monospace>
      </p>
      <p>
        <monospace>+ }</monospace>
      </p>
      <p>
        <monospace>R&gt;</monospace>
      </p>
      <p>
        <monospace>R&gt; # Kumaraswamy Beta − Cumulative distribution function.</monospace>
      </p>
      <p>
        <monospace>R&gt; cdf_kwbeta &lt;- function(par, x){</monospace>
      </p>
      <p>
        <monospace>+  beta &lt;- par[1]</monospace>
      </p>
      <p>
        <monospace>+  a &lt;- par[2]</monospace>
      </p>
      <p>
        <monospace>+  alpha &lt;- par[3]</monospace>
      </p>
      <p>
        <monospace>+  b &lt;- par[4]</monospace>
      </p>
      <p>
        <monospace>+  1 − (1 − pbeta(x, alpha, beta) ^ a) ^ b</monospace>
      </p>
      <p>
        <monospace>+ }</monospace>
      </p>
      <p>
        <monospace>R&gt;</monospace>
      </p>
      <p>
        <monospace>R&gt; # Data set</monospace>
      </p>
      <p>
        <monospace>R&gt; data_unit &lt;- c(0.26, 0.27, 0.30, 0.32, 0.32, 0.34, 0.38, 0.38, 0.39,</monospace>
      </p>
      <p>
        <monospace>+         0.40, 0.41, 0.42, 0.42, 0.42, 0.45, 0.48, 0.49, 0.61,</monospace>
      </p>
      <p>
        <monospace>+         0.65, 0.74)</monospace>
      </p>
      <p>
        <monospace>R&gt;</monospace>
      </p>
      <p>
        <monospace>R&gt; results &lt;- goodness.fit(pdf = pdf_kwbeta, cdf = cdf_kwbeta,</monospace>
      </p>
      <p>
        <monospace>+               starts = c(1, 1, 1, 1), data = data_unit,</monospace>
      </p>
      <p>
        <monospace>+               method = “BFGS”, domain = c(0,1),</monospace>
      </p>
      <p>
        <monospace>+               lim_inf = c(0, 0, 0, 0),</monospace>
      </p>
      <p>
        <monospace>+               lim_sup = c(10, 10, 10, 10), S = 200,</monospace>
      </p>
      <p>
        <monospace>+               prop = 0.1, N = 40)</monospace>
      </p>
      <p>
        <monospace>R&gt; results</monospace>
      </p>
      <p>
        <monospace>$‘W’</monospace>
      </p>
      <p>
        <monospace>[1] 0.06228039</monospace>
      </p>
      <p>
        <monospace>$A</monospace>
      </p>
      <p>
        <monospace>[1] 0.3483813</monospace>
      </p>
      <p>
        <monospace>$KS</monospace>
      </p>
      <p>
        <monospace>   One-sample Kolmogorov-Smirnov test</monospace>
      </p>
      <p>
        <monospace>data: data</monospace>
      </p>
      <p>
        <monospace>D = 0.14992, p-value = 0.7596</monospace>
      </p>
      <p>
        <monospace>alternative hypothesis: two-sided</monospace>
      </p>
      <p>
        <monospace>$mle</monospace>
      </p>
      <p>
        <monospace>[1] 28.3805432 29.0062276 5.2899143 0.1774844</monospace>
      </p>
      <p>
        <monospace>$AIC</monospace>
      </p>
      <p>
        <monospace>[1] -24.71882</monospace>
      </p>
      <p>
        <monospace>$‘CAIC’</monospace>
      </p>
      <p>
        <monospace>[1] -22.05215</monospace>
      </p>
      <p>
        <monospace>$BIC</monospace>
      </p>
      <p>
        <monospace>[1] -20.73589</monospace>
      </p>
      <p>
        <monospace>$HQIC</monospace>
      </p>
      <p>
        <monospace>[1] -23.94131</monospace>
      </p>
      <p>
        <monospace>$Erro</monospace>
      </p>
      <p>
        <monospace>[1] 1.93409776 30.74704316 1.92556208 0.04377468</monospace>
      </p>
      <p>
        <monospace>$Value</monospace>
      </p>
      <p>
        <monospace>[1] -16.35941</monospace>
      </p>
      <p>
        <monospace>$Convergence</monospace>
      </p>
      <p>
        <monospace>[1] 0</monospace>
      </p>
      <p>The estimates of the parameters are <inline-formula id="pone.0221487.e059"><alternatives><graphic xlink:href="pone.0221487.e059.jpg" id="pone.0221487.e059g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M59"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>b</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>α</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>29</mml:mn><mml:mo>.</mml:mo><mml:mn>0062</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>1775</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>.</mml:mo><mml:mn>2899</mml:mn><mml:mo>,</mml:mo><mml:mn>28</mml:mn><mml:mo>.</mml:mo><mml:mn>3805</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, and the standard errors for the estimates <inline-formula id="pone.0221487.e060"><alternatives><graphic xlink:href="pone.0221487.e060.jpg" id="pone.0221487.e060g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M60"><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>b</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>α</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0221487.e061"><alternatives><graphic xlink:href="pone.0221487.e061.jpg" id="pone.0221487.e061g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M61"><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> are 30.747, 0.0438, 1.9256 and 1.9341, respectively.</p>
    </sec>
    <sec id="sec015">
      <title>4.3 TTT plot</title>
      <p>Several aspects of an absolutely continuous distribution can be seen more clearly from the hazard rate function (hrf) than from either the cdf or the pdf. The hrf is an important quantity characterizing life phenomena. Let <italic>X</italic> be a random variable with pdf <italic>f</italic>(<italic>x</italic>) and cdf <italic>F</italic>(<italic>x</italic>). The hrf of <italic>X</italic> is defined by
<disp-formula id="pone.0221487.e062"><alternatives><graphic xlink:href="pone.0221487.e062.jpg" id="pone.0221487.e062g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M62"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where 1 − <italic>F</italic>(<italic>x</italic>) is the survival function.</p>
      <p>The hrf may increase, decrease, be a constant, upside-down bathtub shaped, bathtub shaped or indicate a more complicated process. In many applications there is a qualitative information about the hazard rate shape, which can help in selecting a specified model. In this context, a device called the <italic>total time on test</italic> (TTT) or its scaled TTT transform proposed by [<xref rid="pone.0221487.ref016" ref-type="bibr">16</xref>] may be used for assessing the empirical behavior of the hrf. The scaled TTT transform is defined by (0 &lt; <italic>u</italic> &lt; 1)
<disp-formula id="pone.0221487.e063"><alternatives><graphic xlink:href="pone.0221487.e063.jpg" id="pone.0221487.e063g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M63"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>X</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mi>X</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mi>X</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <inline-formula id="pone.0221487.e064"><alternatives><graphic xlink:href="pone.0221487.e064.jpg" id="pone.0221487.e064g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M64"><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mi>X</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>Q</mml:mi><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> and <italic>Q</italic>(<italic>u</italic>) is the quantile function of <italic>X</italic>. The quantity <italic>ϕ</italic><sub><italic>X</italic></sub>(⋅) can be empirically approximated by
<disp-formula id="pone.0221487.e065"><alternatives><graphic xlink:href="pone.0221487.e065.jpg" id="pone.0221487.e065g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M65"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>T</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>/</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>i</mml:mi></mml:msubsup><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>:</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mi>X</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <italic>i</italic> = 1, …, <italic>n</italic> and <italic>X</italic><sub><italic>k</italic>:<italic>n</italic></sub>, <italic>k</italic> = 1, …, <italic>n</italic>, are the order statistics of the sample. The TTT plot is obtained by plotting <italic>T</italic>(<italic>i</italic>/<italic>n</italic>) against <italic>i</italic>/<italic>n</italic>. The plot can detect the type of the hazard rate of the data. It is a straight diagonal for constant hazrd rates, it is convex for decreasing hazard rates and concave for increasing hazard rates. It is first convex and then concave if the hazard rate is bathtub-shaped. It is first concave and then convex if the hazard rate is upside-down bathtub. For more details, see [<xref rid="pone.0221487.ref016" ref-type="bibr">16</xref>].</p>
      <p>The computation of the TTT plot is addressed in the <bold>AdequacyModel</bold> package. The real data set named <monospace>carbone</monospace> is used to illustrate the TTT plot function <monospace>TTT()</monospace> of this package. <monospace>carbone</monospace> refers to breaking stress of carbon fibres (in Gba) from [<xref rid="pone.0221487.ref013" ref-type="bibr">13</xref>]:</p>
      <p>
        <monospace>R&gt; library(AdequacyModel)</monospace>
      </p>
      <p>
        <monospace>R&gt; data(carbone)</monospace>
      </p>
      <p>
        <monospace>R&gt; TTT(carbone, col = “red”, lwd = 2.5, grid = TRUE, lty = 2)</monospace>
      </p>
      <p>The TTT plot for the carbone data [<xref rid="pone.0221487.ref013" ref-type="bibr">13</xref>] is displayed in <xref ref-type="fig" rid="pone.0221487.g009">Fig 9</xref>, which reveals an increasing hrf. This plot reveals that distributions with increasing hrf could be good candidates for modeling the carbone data, see the theoretical plot in Fig 1 in [<xref rid="pone.0221487.ref016" ref-type="bibr">16</xref>].</p>
      <fig id="pone.0221487.g009" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0221487.g009</object-id>
        <label>Fig 9</label>
        <caption>
          <title>TTT-plot for carbon data.</title>
        </caption>
        <graphic xlink:href="pone.0221487.g009"/>
      </fig>
    </sec>
  </sec>
  <sec id="sec016">
    <title>5 Simulations</title>
    <p>In order to study the consistency of the PSO method, implemented in the <monospace>pso()</monospace> function of the <bold>AdequacyModel</bold> package, two Monte Carlo (MC) simulations are performed considering the Rastrigin and Himmelblau’s functions. All the results can be reproduced with the code in the Appendix A. The functions are quite peculiar, both being multimodal. Multimodal functions belong to a class of functions that impose great challenges on optimization methods.</p>
    <p>The Rastringin function considered here is defined by −5.12 ≤ <italic>x</italic><sub><italic>i</italic></sub> ≤ 5.12, ∀<italic>x</italic><sub><italic>i</italic></sub> ∈ <italic><bold>x</bold></italic>, such that
<disp-formula id="pone.0221487.e066"><alternatives><graphic xlink:href="pone.0221487.e066.jpg" id="pone.0221487.e066g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M66"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:mi>A</mml:mi><mml:mspace width="2pt"/><mml:mtext>cos</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(5)</label></disp-formula>
where <italic>A</italic> = 10. Further, we take <italic>n</italic> = 2 in (<xref ref-type="disp-formula" rid="pone.0221487.e066">5</xref>) in order to construct a three-dimensional chart. This function has the minimum value <italic>f</italic>(0, 0) = 0. On the other hand, the Himmelblau’s function is defined on −5 ≤ <italic>x</italic> ≤ 5, such that
<disp-formula id="pone.0221487.e067"><alternatives><graphic xlink:href="pone.0221487.e067.jpg" id="pone.0221487.e067g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M67"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>y</mml:mi><mml:mo>−</mml:mo><mml:mn>11</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mn>7</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(6)</label></disp-formula></p>
    <p>This function has four global minimum points, with zero being the global minimum value. The four global minimum points are:
<disp-formula id="pone.0221487.e068"><alternatives><graphic xlink:href="pone.0221487.e068.jpg" id="pone.0221487.e068g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M68"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>Min</mml:mtext><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mn>3</mml:mn><mml:mo>.</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>.</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>.</mml:mo><mml:mn>805118</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>.</mml:mo><mml:mn>131312</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mn>3</mml:mn><mml:mo>.</mml:mo><mml:mn>779310</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>3</mml:mn><mml:mo>.</mml:mo><mml:mn>283186</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mn>3</mml:mn><mml:mo>.</mml:mo><mml:mn>584428</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mn>848126</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo/></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
    <p>The peculiarities of the surfaces of Rastringin and Himmelblau’s functions can be seen in <xref ref-type="fig" rid="pone.0221487.g010">Fig 10(a) and 10(b)</xref>, respectively. The <xref ref-type="fig" rid="pone.0221487.g010">Fig 10(a)</xref> exemplifies situations in which we have an objective function with multiple local minimums and this may cause confusion to many optimization algorithms, specially those based on derivatives. In the second scenario, the <monospace>pso()</monospace> function was submitted to a function with four global optimums, in which we have a region of decrease less accentuated, as can be seen in <xref ref-type="fig" rid="pone.0221487.g010">Fig 10(b)</xref>.</p>
    <fig id="pone.0221487.g010" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0221487.g010</object-id>
      <label>Fig 10</label>
      <caption>
        <title>Surfaces of the Rastrigin and Himmelblau functions, respectively, used to evaluate the <monospace>pso()</monospace> function of the AdequacyModel package.</title>
      </caption>
      <graphic xlink:href="pone.0221487.g010"/>
    </fig>
    <p>It is important to make it clear that all metaheuristic methods aim to provide the best solution to a problem. However, we cannot guarantee that any optimization method will always find the best solution for complicated functions, such as the Rastringin e Hemmelblau functions. So, we will be satisfied to obtain reasonable solutions for the examples considered here.</p>
    <p>Here, we show that the <monospace>pso()</monospace> function can be very useful, for example, in the detection of valley patterns on surfaces, since the <monospace>pso()</monospace> behavior implemented in the <bold>AdequacyModel</bold> package will make it difficult the attraction of all particles to the same valley, that is, to the same solution candidate to the global minimum. This is probably due to the random substitution of particles leaving the search region, which gives greater variability without removing the precision of the method.</p>
    <p>In order to greatly reduce the time of the simulations, the code was implemented to make use of shared memory (multicore) parallelism, using the <bold>parallel</bold> package available in any R installation. In this class of parallelism, we have that the cores are distributed on the same chip. Thus, even if it runs on a computer with more than one processor, only the processor cores that will be running the R environment will be considered. This is sufficient for the simulations in question and will facilitate the checking of the results obtained in this section, since it will significantly reduce the execution time of both simulations when performed on multicore processors that are common today.</p>
    <p>Since the iterations of MC are mathematically independent, the idea is to write the loops of MC simulations through the <monospace>mclaplly()</monospace> function of the <bold>parallel</bold> package. The <monospace>mclapply</monospace> funcional is quite similar to the <monospace>lapply()</monospace>, funcional of the base package, where the prefix <monospace>mc</monospace> in the functional name refers to the term “multicore”. Unlike <monospace>lapply()</monospace>, the functional <monospace>mcapply()</monospace> will simultaneously trigger each iteration of the MC loop (thread) over each of the colors of a same processor. In interpreted programming languages, such as the R language, replacing the traditional <monospace>for</monospace> repetition structure with a functional one can improve the computational efficiency of the code. The use of functionalities for code repetition is commonplace in programming languages with functional paradigm, which is also one of the paradigms available in the R language.</p>
    <p>MC simulations were performed on a computer with an Intel (R) Core i7-4710MQ processor operating between 2.50 GHz (minimum frequency) at 3.50 GHz (maximum frequency), 6 MB cache, 8 threads and 32 RAM memory GB DDR3. For each of the functions, 20 thousand MC simulations were considered. Because it is a randomized methodology, a seed, <monospace>set.seed(1L)</monospace>, has been set so that the results are reproducible.</p>
    <p>To further facilitate the reproduction of the simulations for the considered objective functions, MC simulations can be reproduced by calling the function <monospace>simulation_mc()</monospace> which has 8 (eight) arguments:
<list list-type="bullet"><list-item><p><monospace>mc</monospace>: number of MC simulations, with standard in <monospace>mc = 20e3L</monospace>;</p></list-item><list-item><p><monospace>FUN</monospace>: can assume the strings <monospace>“rastrigin”</monospace> (default) or <monospace>“himmelblaus”</monospace> and refers to the objective function considered;</p></list-item><list-item><p><monospace>seed</monospace>: seed to be considered, where the default is <monospace>seed = 1L</monospace>;</p></list-item><list-item><p><monospace>plot.curve</monospace>: if <monospace>TRUE</monospace> (default) will construct the graph with level curves and superimpose the estimated optimal values at each iteration of MC (white dots);</p></list-item><list-item><p><monospace>S</monospace>: quantity of particles considered, where <monospace>S = 150</monospace> is the standard;</p></list-item><list-item><p><monospace>e</monospace>: minimum variance of the optimal values of the last iterations, with <monospace>e = 1e-4</monospace> by default;</p></list-item><list-item><p><monospace>N</monospace>: minimum number of iterations of the PSO method, with <monospace>N = 50</monospace> set by default;</p></list-item><list-item><p><monospace>prop</monospace>: proportion of the last minimum values that will be considered for the calculated of the variance used as stopping criterion.</p></list-item></list></p>
    <p>With the code attached (see A), the simulations of MC for the Rastrigin (<xref ref-type="disp-formula" rid="pone.0221487.e066">Eq 5</xref>) and function of Himmelblau’s (<xref ref-type="disp-formula" rid="pone.0221487.e067">Eq 6</xref>) simulations can be reproduced making <monospace>simulation_mc(mc = 2e4L, FUN = “rastrigin”)</monospace> and <monospace>simulation_mc(mc = 2e4L, FUN = “himmelblaus”)</monospace>, respectively. The MC simulation that subjected the <monospace>pso()</monospace> function to optimize the Rastringin function took approximately 3.77 hours with the hardwares considered. A much shorter time was required to perform MC simulations for the Himmelblau’s function (<xref ref-type="disp-formula" rid="pone.0221487.e067">Eq 6</xref>) because of its simplicity compared to the Rastrigin function (<xref ref-type="disp-formula" rid="pone.0221487.e066">Eq 5</xref>), taking about 4.58 minutes.</p>
    <p>The first MC simulation considered the Rastringin function (<xref ref-type="disp-formula" rid="pone.0221487.e066">Eq 5</xref>). The results of each iteration of MC are represented as white dots in the graph of surface level curves, as shown in <xref ref-type="fig" rid="pone.0221487.g011">Fig 11(a)</xref>. Similarly, each of the 20,000 MC simulations that submitted the <monospace>pso()</monospace> function to the optimization process of the Himmelblau’s function (<xref ref-type="disp-formula" rid="pone.0221487.e067">Eq 6</xref>) are shown in the graph of the level curves of the function of Himmelblau’s, as can be seen in <xref ref-type="fig" rid="pone.0221487.g011">Fig 11(b)</xref>.</p>
    <fig id="pone.0221487.g011" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0221487.g011</object-id>
      <label>Fig 11</label>
      <caption>
        <title>Level curves of the Rastringin and Himmelblau’s functions, respectively, with optimal points (white dots) obtained by the 20 thousand MC simulations (<italic>N</italic> = 20000).</title>
      </caption>
      <graphic xlink:href="pone.0221487.g011"/>
    </fig>
    <p>The PSO algorithm given in Section 2.2 and encoded in the <monospace>pso()</monospace> function of the <bold>AdequacyModel</bold> package presented satisfactory results in obtaining global minimums in both cases. For the case of the Rastringin function (<xref ref-type="disp-formula" rid="pone.0221487.e066">Eq 5</xref>), not always the best solution is obtained, but good solutions are reached. The dot cloud, as shown in <xref ref-type="fig" rid="pone.0221487.g011">Fig 11(a)</xref>, has been concentrated in regions with good candidates to the point of global minimum.</p>
    <p>The function <monospace>pso()</monospace> also provides good results when submitted to the optimization of the Himmelblau’s function (<xref ref-type="disp-formula" rid="pone.0221487.e067">Eq 6</xref>). In this case, particles are attracted to the valleys containing the four global optimum points. In addition, it has been realized that the <monospace>pso()</monospace> function may be useful in detecting cavities on a surface (valleys detection). This is most likely due to the fact that particles are randomly replaced in the search space, which allows the particles to divide into groups that will not necessarily be attracted to the same cavity. In the situation where there is a mathematical representation of the image of a surface, the <monospace>pso()</monospace> function of the <bold>AdequacyModel</bold> package may be useful in detecting cavities (valleys). In addition, the <monospace>pso()</monospace> function returns a history of global optimal values that may be useful in detecting these regions.</p>
  </sec>
  <sec sec-type="conclusions" id="sec017">
    <title>6 Conclusions</title>
    <p>In this paper we describe the <bold>AdequacyModel</bold> package developed for the R statistical environment with an easy-to-use set of statistical measures to assess the adequacy of lifetime models for a given data set using the PSO as the underlying optimization method. Our contribution to the PSO is to give more control over some aspects of the algorithm, such as the number of particles and iterations and a stop criterion based on the minimum number of iterations and the variance of a given proportion of optimal values. Simulation studies show that the results obtained by the PSO are not affected by perturbation in initial values. Regarding data analysis, our proposed package allows for easy entering of a data set. Further, the <monospace>goodness.fit()</monospace> function provides measures that allow comparison of non-nested models models using the classic AIC, CAIC, BIC statistics. Two empirical applications were presented in order to illustrate the importance and usefulness of the proposed package.</p>
    <p>In the future version of the package, the function <monospace>pso()</monospace> will be rewritten using the C/C++ language. Rewriting the function in C/C++ will bring benefits regarding the computational performance of the function, since depending on the values of the <monospace>N</monospace>, <monospace>e</monospace> and <monospace>prop</monospace> parameters of the <monospace>pso()</monospace> function, we can easily encounter computationally intensive situations.</p>
  </sec>
  <sec id="sec018">
    <title>A Monte Carlo simulation code</title>
    <p>
      <monospace>#!/usr/bin/env Rscript</monospace>
    </p>
    <p>
      <monospace># install.packages(“purrr”)</monospace>
    </p>
    <p>
      <monospace># install.packages(“AdequacyModel”)</monospace>
    </p>
    <p>
      <monospace># install.packages(“plot3D”)</monospace>
    </p>
    <p>
      <monospace># install.packages(“fields”)</monospace>
    </p>
    <p>
      <monospace># install.packages(“parallel”)</monospace>
    </p>
    <p>
      <monospace># Monte Carlo Simulation --------------------------------------------------</monospace>
    </p>
    <p>
      <monospace>simulation_mc &lt;- function(mc = 20e3L, FUN = “rastrigin”,</monospace>
    </p>
    <p>
      <monospace>           seed = 1L, plot.curve = TRUE,</monospace>
    </p>
    <p>
      <monospace>           S = 150, e = 1e-4, N = 50L,</monospace>
    </p>
    <p>
      <monospace>           prop = 0.1){</monospace>
    </p>
    <p>
      <monospace> if (FUN != “rastrigin” &amp;&amp; FUN != “himmelblaus”)</monospace>
    </p>
    <p>
      <monospace> stop(“The argument ”, FUN, ” It is not valid.\n</monospace>
    </p>
    <p>
      <monospace>    Choice \“rastrigin\” or \“himmelblaus\””)</monospace>
    </p>
    <p>
      <monospace> if (FUN == “rastrigin”){</monospace>
    </p>
    <p>
      <monospace> # Rastrigin Function ----------------------------------------------------</monospace>
    </p>
    <p>
      <monospace> obj &lt;- function(par, x, A = 10L) {</monospace>
    </p>
    <p>
      <monospace>  expr_to_eval &lt;-
</monospace>
    </p>
    <p>
      <monospace>  purrr::map(.x = 1:length(par),</monospace>
    </p>
    <p>
      <monospace>  .f = ~ parse(text = paste(“x”, .x, “ &lt;- par[”, .x, “]”, sep = “”)))</monospace>
    </p>
    <p>
      <monospace>  x_vector &lt;- NULL</monospace>
    </p>
    <p>
      <monospace>  for (i in 1:length(par)) {</monospace>
    </p>
    <p>
      <monospace>    eval(expr_to_eval[[i]])</monospace>
    </p>
    <p>
      <monospace>    x_vector[i] &lt;- eval(rlang::parse_expr(paste(“x”, i, sep = “”)))</monospace>
    </p>
    <p>
      <monospace>  }</monospace>
    </p>
    <p>
      <monospace>  return(A * length(x_vector) +</monospace>
    </p>
    <p>
      <monospace>  sum(x_vector ^ 2 − A * cos(2 * pi * x_vector)))</monospace>
    </p>
    <p>
      <monospace> }</monospace>
    </p>
    <p>
      <monospace> args &lt;- list(</monospace>
    </p>
    <p>
      <monospace>     func = obj,</monospace>
    </p>
    <p>
      <monospace>     S = S,</monospace>
    </p>
    <p>
      <monospace>     lim_inf = rep(-5.12, 2),</monospace>
    </p>
    <p>
      <monospace>     lim_sup = rep(5.12, 2),</monospace>
    </p>
    <p>
      <monospace>     e = e,</monospace>
    </p>
    <p>
      <monospace>     N = N,</monospace>
    </p>
    <p>
      <monospace>     prop = prop</monospace>
    </p>
    <p>
      <monospace>   )</monospace>
    </p>
    <p>
      <monospace> } else {</monospace>
    </p>
    <p>
      <monospace> # Hummelblaus Function: -------------------------------------------------</monospace>
    </p>
    <p>
      <monospace> obj &lt;- function(par, x) {</monospace>
    </p>
    <p>
      <monospace>  x &lt;- par[1]</monospace>
    </p>
    <p>
      <monospace>  y &lt;- par[2]</monospace>
    </p>
    <p>
      <monospace>  (x ^ 2 + y − 11) ^ 2 + (x + y ^ 2 − 7) ^ 2</monospace>
    </p>
    <p>
      <monospace> }</monospace>
    </p>
    <p>
      <monospace> args &lt;- list(</monospace>
    </p>
    <p>
      <monospace>     func = obj,</monospace>
    </p>
    <p>
      <monospace>     S = S,</monospace>
    </p>
    <p>
      <monospace>     lim_inf = rep(-5, 2),</monospace>
    </p>
    <p>
      <monospace>     lim_sup = rep(5, 2),</monospace>
    </p>
    <p>
      <monospace>     e = e,</monospace>
    </p>
    <p>
      <monospace>     N = N,</monospace>
    </p>
    <p>
      <monospace>     prop = prop</monospace>
    </p>
    <p>
      <monospace>   )</monospace>
    </p>
    <p>
      <monospace>}</monospace>
    </p>
    <p>
      <monospace> # One step (Monte Carlo)</monospace>
    </p>
    <p>
      <monospace> onestep &lt;- function(x, list_args) {</monospace>
    </p>
    <p>
      <monospace> result &lt;-
</monospace>
    </p>
    <p>
      <monospace>  do.call(getExportedValue(“AdequacyModel”, “pso”), args = list_args)</monospace>
    </p>
    <p>
      <monospace> list(par = result$par, value = result$f[length(result$f)])</monospace>
    </p>
    <p>
      <monospace> }</monospace>
    </p>
    <p>
      <monospace> # A combined multiple-recursive generator’ from L’Ecuyer (1999),</monospace>
    </p>
    <p>
      <monospace> # each element of which is a feedback multiplicative generator with</monospace>
    </p>
    <p>
      <monospace> # three integer elements: thus the seed is a (signed) integer vector of</monospace>
    </p>
    <p>
      <monospace> # length 6. The period is around 2^191.</monospace>
    </p>
    <p>
      <monospace> set.seed(seed = seed, kind = “L’Ecuyer-CMRG”)</monospace>
    </p>
    <p>
      <monospace> time &lt;- system.time(</monospace>
    </p>
    <p>
      <monospace>  results_mc &lt;-</monospace>
    </p>
    <p>
      <monospace>  parallel::mclapply(</monospace>
    </p>
    <p>
      <monospace>  X = 1:mc,</monospace>
    </p>
    <p>
      <monospace>  FUN = onestep,</monospace>
    </p>
    <p>
      <monospace>  mc.cores = parallel::detectCores(),</monospace>
    </p>
    <p>
      <monospace>  list_args = args</monospace>
    </p>
    <p>
      <monospace>  )</monospace>
    </p>
    <p>
      <monospace> ) # End system.time().</monospace>
    </p>
    <p>
      <monospace> results &lt;- unlist(results_mc)</monospace>
    </p>
    <p>
      <monospace> par_1 &lt;- results[names(results) == “par1”]</monospace>
    </p>
    <p>
      <monospace> par_2 &lt;- results[names(results) == “par2”]</monospace>
    </p>
    <p>
      <monospace> value &lt;- results[names(results) == “value”]</monospace>
    </p>
    <p>
      <monospace> if (plot.curve &amp;&amp; FUN == “rastrigin”){</monospace>
    </p>
    <p>
      <monospace> rastrigin_plot &lt;- function(x,y){</monospace>
    </p>
    <p>
      <monospace>  20 + (x ^ 2 − 10 * cos(2 * pi * x)) +</monospace>
    </p>
    <p>
      <monospace>  (y ^ 2 − 10 * cos(2 * pi * y))</monospace>
    </p>
    <p>
      <monospace> }</monospace>
    </p>
    <p>
      <monospace> M &lt;- plot3D::mesh(seq(-5.12, 5.12, length.out = 500), seq(-5.12, 5.12, length.out = 500))</monospace>
    </p>
    <p>
      <monospace> x &lt;- M$x; y &lt;- M$y</monospace>
    </p>
    <p>
      <monospace> pdf(file = “monte_carlo_rastrigin.pdf”, width = 9,</monospace>
    </p>
    <p>
      <monospace>   height = 9, paper = “special”,</monospace>
    </p>
    <p>
      <monospace>   family = “Bookman”, pointsize = 14)</monospace>
    </p>
    <p>
      <monospace>   z &lt;- rastrigin_plot(x, y)</monospace>
    </p>
    <p>
      <monospace>   fields::image.plot(x, y, z, xlab = bquote(x[1]), ylab = bquote(x[2]), main = paste0(“N =”, length(par_1)))</monospace>
    </p>
    <p>
      <monospace>   contour(seq(-5.12, 5.12, length.out = nrow(z)), seq(-5.12, 5.12, length.out = nrow(z)), z, add = TRUE)</monospace>
    </p>
    <p>
      <monospace>   points(par_1, par_2, pch = 20, col = rgb(1, 1, 1))</monospace>
    </p>
    <p>
      <monospace> dev.off()</monospace>
    </p>
    <p>
      <monospace> }</monospace>
    </p>
    <p>
      <monospace> else if (plot.curve &amp;&amp; FUN == “himmelblaus”){</monospace>
    </p>
    <p>
      <monospace>  himmelblaus_plot &lt;- function(x, y){</monospace>
    </p>
    <p>
      <monospace>   (x ^ 2 + y − 11) ^ 2 + (x + y ^ 2 − 7) ^ 2</monospace>
    </p>
    <p>
      <monospace>  }</monospace>
    </p>
    <p>
      <monospace> M &lt;- plot3D::mesh(seq(-5, 5, length.out = 500), seq(-5, 5, length.out = 500))</monospace>
    </p>
    <p>
      <monospace> x &lt;- M$x; y &lt;- M$y</monospace>
    </p>
    <p>
      <monospace> pdf(file = “monte_carlo_himmelblaus.pdf”, width = 9,</monospace>
    </p>
    <p>
      <monospace>   height = 9, paper = “special”, family = “Bookman”,</monospace>
    </p>
    <p>
      <monospace>   pointsize = 14)</monospace>
    </p>
    <p>
      <monospace>  z &lt;- himmelblaus_plot(x, y)</monospace>
    </p>
    <p>
      <monospace>  fields::image.plot(x, y, z, xlab = bquote(x[1]), ylab = bquote(x[2]), main = paste0(“N =”, length(par_1)))</monospace>
    </p>
    <p>
      <monospace>  contour(seq(-5, 5, length.out = nrow(z)), seq(-5, 5, length.out = nrow(z)), z, add = TRUE, nlevels = 30)</monospace>
    </p>
    <p>
      <monospace>  points(par_1, par_2, pch = 20, col = rgb(1, 1, 1))</monospace>
    </p>
    <p>
      <monospace> dev.off()</monospace>
    </p>
    <p>
      <monospace> }</monospace>
    </p>
    <p>
      <monospace> list(x = par_1, y = par_2, value = value, time = time)</monospace>
    </p>
    <p>
      <monospace>}</monospace>
    </p>
    <p>
      <monospace># Saving Results ----------------------------------------------------------</monospace>
    </p>
    <p>
      <monospace>result_rastrigin &lt;- simulation_mc(mc = 2e4L, FUN = “rastrigin”)</monospace>
    </p>
    <p>
      <monospace>save(file = “simulation_rastrigin.RData”, result_rastrigin)</monospace>
    </p>
    <p>
      <monospace>result_himmelblaus &lt;- simulation_mc(mc = 2e4L, FUN = “himmelblaus”)</monospace>
    </p>
    <p>
      <monospace>save(file = “simulation_himmelblaus.RData”, result_himmelblaus)</monospace>
    </p>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pone.0221487.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Almalki</surname><given-names>SJ</given-names></name>, <name><surname>Nadarajah</surname><given-names>S</given-names></name>. <article-title>Modifications of the Weibull distribution: a review</article-title>. <source>Reliability Engineering and System Safety</source>. <year>2014</year>;<volume>124</volume>:<fpage>32</fpage>–<lpage>55</lpage>. <pub-id pub-id-type="doi">10.1016/j.ress.2013.11.010</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0221487.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Tahir</surname><given-names>MH</given-names></name>, <name><surname>Cordeiro</surname><given-names>GM</given-names></name>. <article-title>Compounding of distributions: a survey and new generalized classes</article-title>. <source>Journal of Statistical Distributions and Applications</source>. <year>2016</year>; p. <fpage>3</fpage>–<lpage>13</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0221487.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Kennedy</surname><given-names>J</given-names></name>, <name><surname>Eberhart</surname><given-names>RC</given-names></name>. <article-title>Particle swarm optimization</article-title>. <source>Proceedings of the 1995 IEEE international conference on neural networks (Perth, Australia)</source>. <year>1995</year>; p. <fpage>1942</fpage>–<lpage>1948</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0221487.ref004">
      <label>4</label>
      <mixed-citation publication-type="other">Kennedy J, Eberhart RC, Shi Y. Swarm intelligence. The Morgan Kaufmann: San Francisco, U.S.A.; 2001.</mixed-citation>
    </ref>
    <ref id="pone.0221487.ref005">
      <label>5</label>
      <mixed-citation publication-type="other">Ying L, Hongli G, Qing W. Adaptive Enhancement with Speckle Reduction for SAR Images Using Mirror-Extended Curvelet and PSO. In: 20th International Conference on Pattern Recognition (ICPR); 2010. p. 4520–4523.</mixed-citation>
    </ref>
    <ref id="pone.0221487.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Khan</surname><given-names>A</given-names></name>, <name><surname>Bawane</surname><given-names>NG</given-names></name>, <name><surname>Bodkhe</surname><given-names>S</given-names></name>. <article-title>An Analysis of Particle Swarm Optimization with Data Clustering-Technique for Optimization in Data Mining</article-title>. <source>International Journal on Computer Science and Engineering</source>. <year>2010</year>;<volume>02</volume>(<issue>07</issue>):<fpage>2223</fpage>–<lpage>2226</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0221487.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Lins</surname><given-names>ID</given-names></name>, <name><surname>Moura</surname><given-names>MC</given-names></name>, <name><surname>Zio</surname><given-names>E</given-names></name>, <name><surname>Droguett</surname><given-names>EL</given-names></name>. <article-title>A Particle Swarm-optimized Support Vector Machine for Reliability Prediction</article-title>. <source>Quality and Reliability Engineering International</source>. <year>2012</year>; p. <fpage>141</fpage>–<lpage>158</lpage>. <pub-id pub-id-type="doi">10.1002/qre.1221</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0221487.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Andras</surname><given-names>P</given-names></name>. <article-title>A Bayesian Interpretation of the Particle Swarm Optimization and Its Kernel Extension</article-title>. <source>PLoS One</source>. <year>2012</year>;<volume>7</volume>(<issue>11</issue>). <pub-id pub-id-type="doi">10.1371/journal.pone.0048710</pub-id><?supplied-pmid 23144937?><pub-id pub-id-type="pmid">23144937</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0221487.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>FK</given-names></name>, <name><surname>Huang</surname><given-names>PR</given-names></name>. <article-title>Implementing particle swarm optimization algorithm to estimate the mixture of two Weibull parameters with</article-title>. <source>Journal of Statistical Computation and Simulation</source>. <year>2013</year>;<volume>84</volume>(<issue>9</issue>):<fpage>1975</fpage>–<lpage>1989</lpage>. <pub-id pub-id-type="doi">10.1080/00949655.2013.778992</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0221487.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Bratton</surname><given-names>D</given-names></name>, <name><surname>Blackwell</surname><given-names>T</given-names></name>. <article-title>A simplified recombinant PSO</article-title>. <source>Journal of Artificial Evolution and Applications</source>. <year>2008</year>;<volume>2008</volume>:<fpage>14</fpage><pub-id pub-id-type="doi">10.1155/2008/654184</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0221487.ref011">
      <label>11</label>
      <mixed-citation publication-type="other">Bratton D, Kennedy J. Defining a Standard for Particle Swarm Optimization. In: 2007 IEEE Swarm Intelligence Symposium; 2007. p. 120–127.</mixed-citation>
    </ref>
    <ref id="pone.0221487.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>G</given-names></name>, <name><surname>Balakrishnan</surname><given-names>N</given-names></name>. <article-title>A general purpose approximate goodness-of-fit test</article-title>. <source>Journal of Quality Technology</source>. <year>1995</year>;<volume>27</volume>:<fpage>154</fpage>–<lpage>161</lpage>. <pub-id pub-id-type="doi">10.1080/00224065.1995.11979578</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0221487.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Nichols</surname><given-names>MD</given-names></name>, <name><surname>Paggett</surname><given-names>W</given-names></name>. <article-title>A bootstrap control chart for Weibull percentiles</article-title>. <source>Quality and Reliability Engineering International</source>. <year>2006</year>;<volume>22</volume>:<fpage>141</fpage>–<lpage>151</lpage>. <pub-id pub-id-type="doi">10.1002/qre.691</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0221487.ref014">
      <label>14</label>
      <mixed-citation publication-type="book"><name><surname>Davison</surname><given-names>A</given-names></name>, <name><surname>Hinkley</surname><given-names>D</given-names></name>. <source>Bootstrap methods and their applications</source>. <volume>vol. 1</volume><publisher-name>Cambridge University Press</publisher-name>; <year>1997</year>.</mixed-citation>
    </ref>
    <ref id="pone.0221487.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Dumonceaux</surname><given-names>R</given-names></name>, <name><surname>Antle</surname><given-names>CE</given-names></name>. <article-title>Discrimination Between the Log-Normal and the Weibull Distribution</article-title>. <source>Technometrics</source>. <year>2012</year>;<volume>15</volume>:<fpage>923</fpage>–<lpage>926</lpage>. <pub-id pub-id-type="doi">10.1080/00401706.1973.10489124</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0221487.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Aarset</surname><given-names>MV</given-names></name>. <article-title>How to identify bathtub hazard rate</article-title>. <source>IEEE Transactions Reliability</source>. <year>1987</year>;<volume>36</volume>:<fpage>106</fpage>–<lpage>108</lpage>. <pub-id pub-id-type="doi">10.1109/TR.1987.5222310</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
