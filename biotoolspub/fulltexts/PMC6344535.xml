<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Nat Commun</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id>
    <journal-title-group>
      <journal-title>Nature Communications</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2041-1723</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6344535</article-id>
    <article-id pub-id-type="publisher-id">7931</article-id>
    <article-id pub-id-type="doi">10.1038/s41467-018-07931-2</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Single-cell RNA-seq denoising using a deep count autoencoder</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9579-2909</contrib-id>
        <name>
          <surname>Eraslan</surname>
          <given-names>Gökcen</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6148-8861</contrib-id>
        <name>
          <surname>Simon</surname>
          <given-names>Lukas M.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1935-8665</contrib-id>
        <name>
          <surname>Mircea</surname>
          <given-names>Maria</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mueller</surname>
          <given-names>Nikola S.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2419-1943</contrib-id>
        <name>
          <surname>Theis</surname>
          <given-names>Fabian J.</given-names>
        </name>
        <address>
          <email>fabian.theis@helmholtz-muenchen.de</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 0483 2525</institution-id><institution-id institution-id-type="GRID">grid.4567.0</institution-id><institution>Institute of Computational Biology, </institution><institution>Helmholtz Zentrum München, </institution></institution-wrap>Neuherberg, Germany </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000000123222966</institution-id><institution-id institution-id-type="GRID">grid.6936.a</institution-id><institution>TUM School of Life Sciences Weihenstephan, </institution><institution>Technische Universität München, </institution></institution-wrap>Freising, Germany </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000000123222966</institution-id><institution-id institution-id-type="GRID">grid.6936.a</institution-id><institution>Department of Mathematics, </institution><institution>Technische Universität München, </institution></institution-wrap>Garching, Germany </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>23</day>
      <month>1</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>23</day>
      <month>1</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>10</volume>
    <elocation-id>390</elocation-id>
    <history>
      <date date-type="received">
        <day>13</day>
        <month>4</month>
        <year>2018</year>
      </date>
      <date date-type="accepted">
        <day>22</day>
        <month>11</month>
        <year>2018</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Single-cell RNA sequencing (scRNA-seq) has enabled researchers to study gene expression at a cellular resolution. However, noise due to amplification and dropout may obstruct analyses, so scalable denoising methods for increasingly large but sparse scRNA-seq data are needed. We propose a deep count autoencoder network (DCA) to denoise scRNA-seq datasets. DCA takes the count distribution, overdispersion and sparsity of the data into account using a negative binomial noise model with or without zero-inflation, and nonlinear gene-gene dependencies are captured. Our method scales linearly with the number of cells and can, therefore, be applied to datasets of millions of cells. We demonstrate that DCA denoising improves a diverse set of typical scRNA-seq data analyses using simulated and real datasets. DCA outperforms existing methods for data imputation in quality and speed, enhancing biological discovery.</p>
    </abstract>
    <abstract id="Abs2" abstract-type="web-summary">
      <p id="Par2">Single-cell RNA sequencing is a powerful method to study gene expression, but noise in the data can obstruct analysis. Here the authors develop a denoising method based on a deep count autoencoder network that scales linearly with the number of cells, and therefore is compatible with large data sets.</p>
    </abstract>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par3">Advances in single-cell transcriptomics have enabled researchers to discover novel celltypes<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR2">2</xref></sup>, study complex differentiation and developmental trajectories<sup><xref ref-type="bibr" rid="CR3">3</xref>–<xref ref-type="bibr" rid="CR5">5</xref></sup> and improve understanding of human disease<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR6">6</xref></sup>.</p>
    <p id="Par4">Despite improvements in measuring technologies, various technical factors, including amplification bias, cell cycle effects<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, library size differences<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> and especially low RNA capture rate<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> lead to substantial noise in scRNA-seq experiments. Recent droplet-based scRNA-seq technologies can profile up to millions of cells in a single experiment<sup><xref ref-type="bibr" rid="CR10">10</xref>–<xref ref-type="bibr" rid="CR12">12</xref></sup>. These technologies are particularly sparse due to relatively shallow sequencing<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>. Overall, these technical factors introduce substantial noise, which may corrupt the underlying biological signal and obstruct analysis<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>.</p>
    <p id="Par5">The low RNA capture rate leads to failure of detection of an expressed gene resulting in a “false” zero count observation, defined as dropout event. It is important to note the distinction between “false” and “true” zero counts. True zero counts represent the lack of expression of a gene in a specific celltype, thus true celltype-specific expression. Therefore, not all zeros in scRNA-seq data can be considered missing values. In statistics, missing data values are typically imputed. In this process missing values are substituted for values either randomly or by adapting to the data structure, to improve statistical inference or modeling<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. Due to the non-trivial distinction between true and false zero counts, classical imputation methods with defined missing values may not be suitable for scRNA-seq data.</p>
    <p id="Par6">The concept of denoising is commonly used to delineate signal from noise in imaging<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. Denoising enhances image quality by suppressing or removing noise in raw images. We assume that the data originates from a noiseless data manifold, representing the underlying biological processes and/or cellular states<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. However, measurement techniques like imaging or sequencing generate a corrupted representation of this manifold (Fig. <xref rid="Fig1" ref-type="fig">1a</xref>).<fig id="Fig1"><label>Fig. 1</label><caption><p>DCA denoises scRNA-seq data by learning the underlying true zero-noise data manifold using an autoencoder framework. <bold>a</bold> Depicts a schematic of the denoising process adapted from Goodfellow et al.<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. Red arrows illustrate how a corruption process, i.e. measurement noise including dropout events, moves data points <italic>x</italic><sub><italic>j</italic></sub> away from the data manifold (black line). The autoencoder is trained to denoise the data by mapping measurement-corrupted data points <inline-formula id="IEq200"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\tilde{x}}_{i}$$\end{document}</tex-math><mml:math id="M2"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2018_7931_Article_IEq200.gif"/></alternatives></inline-formula> back onto the data manifold (green arrows). Filled blue dots represent corrupted data points. Empty blue points represent the data points without noise. <bold>b</bold> Shows the autoencoder with a ZINB loss function. Input is the original count matrix (pink rectangle; gene by cells matrix, with dark blue indicating zero counts) with six genes (pink nodes) for illustration purposes. The blue nodes depict the mean of the negative binomial distribution which is the main output of the method representing denoised data, whereas the green and red nodes represent the other two parameters of the ZINB distribution, namely dispersion and dropout. Note that output nodes for mean, dispersion and dropout also consist of six genes which match six input genes. The matrix highlighted in blue shows the mean value for all cells which denotes the denoised expression. and the mean matrix of the negative binomial component represents the denoised output (blue rectangle). Input counts, mean, dispersion and dropout probabilities are denoted as <italic>x</italic>, <italic>μ</italic>, <italic>θ</italic> and <italic>π</italic>, respectively</p></caption><graphic xlink:href="41467_2018_7931_Fig1_HTML" id="d29e391"/></fig></p>
    <p id="Par7">A number of scRNA-seq specific imputation or denoising methods exist<sup><xref ref-type="bibr" rid="CR18">18</xref>–<xref ref-type="bibr" rid="CR22">22</xref></sup>. These approaches rely on using the correlation structure of single-cell gene expression data to infer “corrected” gene expression values by leveraging information on similarities between cells and/or genes. For example, current approaches for scRNA-seq specific imputation include scImpute<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>, which defines likely dropout values using a mixture model and subsequently substitutes only the likely dropout values. MAGIC<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> and SAVER<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>, on the other hand, denoise single-cell gene expression data and generate a denoised output for each gene and cell entry. However, these methods may fail to account for non-linearity or the count structure in the data. Furthermore, with the increasing size of scRNA-seq datasets<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, methods need to scale to up to millions of cells and existing denoising methods are unable to process datasets of this magnitude.</p>
    <p id="Par8">An autoencoder is an artificial neural network which learns an efficient compression of data in an unsupervised fashion by minimizing the error between the compressed and subsequently reconstructed data set versus the original one. Generalizing linear approaches such as principal component analysis, it is commonly used for dimension reduction<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> (see Methods for the detailed description of autoencoders). Since the compression forces the autoencoder to learn only the essential latent features, the reconstruction ignores non-essential sources of variation such as random noise<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> (Fig. <xref rid="Fig1" ref-type="fig">1a</xref>). A number of recent studies describe applications of autoencoders in molecular biology<sup><xref ref-type="bibr" rid="CR25">25</xref>–<xref ref-type="bibr" rid="CR29">29</xref></sup>.</p>
    <p id="Par9">To solve denoising and imputation tasks in scRNA-seq data in one step, we extend the typical autoencoder approach and adapt it towards noise models applicable to sparse count data. To that end, we developed a deep learning based autoencoder with specialized loss functions targeted towards scRNA-seq data, the so-called “deep count autoencoder” (DCA). The trick is to define the reconstruction error as the likelihood of the distribution of the noise model instead of reconstructing the input data itself (Fig. <xref rid="Fig1" ref-type="fig">1b</xref>). During training, DCA learns gene-specific distribution parameters by minimizing the reconstruction error in an unsupervised manner. Due to the compression, DCA shares information across features, and thereby accounts for gene-gene dependencies. The deep learning framework (by default three hidden layers with 64, 32, 64 neurons) of DCA enables the capturing of the complexity and non-linearity in scRNA-seq data. Thirdly, the autoencoder framework is highly scalable and DCA can be applied to data sets of up to millions of cells. To increase speed even further DCA is parallelizable via graphical processing units (GPU).</p>
    <p id="Par10">One of the main advantages of DCA is that the user only needs to specify the noise model. Existing scRNA-seq methods are based on various distributional assumptions, including zero-inflated negative binomial models<sup><xref ref-type="bibr" rid="CR30">30</xref>,<xref ref-type="bibr" rid="CR31">31</xref></sup>. However, Chen et al.<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> proposed that zero-inflation is less likely in unique molecular identifier (UMI) based compared to read based scRNA-seq technologies. Therefore, to provide maximal flexibility, DCA implements a selection of scRNA-seq specific noise models including negative binomial distribution with (ZINB) and without zero-inflation (NB). For example, using the ZINB noise model, DCA learns gene-specific parameters mean, dispersion and dropout probability based on the input gene expression data. The inferred mean parameter of the distribution represents the denoised reconstruction and the output of DCA (Fig. <xref rid="Fig1" ref-type="fig">1b</xref>).</p>
    <p id="Par11">We extensively evaluate our approach with competing methods using simulated and real datasets. Altogether, we demonstrate that DCA shows high scalability and DCA denoising enhances biological discovery. The approach is implemented in Python and as a command line tool, publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/theislab/dca">https://github.com/theislab/dca</ext-link>. Alternatively, Scanpy<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> users can directly use the “dca” method in the preprocessing package[<ext-link ext-link-type="uri" xlink:href="https://scanpy.readthedocs.io/en/latest/api/index.html#imputation">https://scanpy.readthedocs.io/en/latest/api/index.html#imputation</ext-link>].</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <sec id="Sec3">
      <title>Count noise model is necessary to denoise scRNA-seq data</title>
      <p id="Par12">As a proof of principle and to explore the properties of our approach, we applied DCA to simulated scRNA-seq data generated using Splatter<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>. Both count data with and without dropout are available, which allows quantification of denoising using ground truth. We simulated two data sets with 200 genes and (1) two celltypes (2000 cells in total) and (2) six celltypes (2000 cells in total). For the two and six celltype simulations 63 and 35% of data values were set to zero, respectively. Dropout simulation probabilities are conditioned on mean gene expression, such that lowly expressed genes have a higher likelihood of dropout compared to highly expressed genes<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>.</p>
      <p id="Par13">To guide the user’s choice of the appropriate noise model, we propose to examine the relationship between the gene-wise mean and empirical dropout rate calculated for cells from the same cluster or cell type. By conducting a likelihood ratio test between the NB and ZINB fits the user can determine whether zero-inflation is present and which distribution to select for the DCA noise model parameter. For the simulation data, the ZINB distribution showed higher likelihood compared to NB distribution (Supplementary Fig. <xref rid="MOESM1" ref-type="media">1A</xref>). Therefore, we used the ZINB noise model for DCA denoising.</p>
      <p id="Par14">In our simulation results dropout adds substantial noise, obscuring celltype identities. Expectedly, after denoising using DCA the original celltypes can be recovered (Fig. <xref rid="Fig2" ref-type="fig">2a, b</xref>). To test whether a count-based loss function is necessary, we compared DCA to a typical autoencoder with a mean squared error (MSE) loss function using log-transformed count data. The MSE based autoencoder was unable to recover the celltypes, indicating that the specialized count loss function is necessary for scRNA-seq data. Confirmatory results were observed in the more complex six group simulation (Fig. <xref rid="Fig2" ref-type="fig">2c, d</xref>, Supplementary Fig. <xref rid="MOESM1" ref-type="media">2A &amp; B</xref>).<fig id="Fig2"><label>Fig. 2</label><caption><p>Count-based loss function is necessary to identify celltypes in simulated data with high levels of dropout noise. <bold>a</bold> depicts plots of principal components 1 and 2 derived from simulated data without dropout, with dropout, with dropout denoised using DCA and MSE based autoencoder from left to right. Cells are colored by celltype. <bold>b</bold> shows heatmaps of the underlying gene expression data. <bold>c</bold> illustrates tSNE visualization of simulated scRNA-seq data with six cell types. Cells are colored by celltype. <bold>d</bold> shows heatmaps of the underlying gene expression data</p></caption><graphic xlink:href="41467_2018_7931_Fig2_HTML" id="d29e526"/></fig></p>
      <p id="Par15">One advantage of simulated data is the ability to perform a large variety of evaluations, including the assessment of potential overimputation. Overimputation in denoising methods manifests itself by introducing spurious correlations, falsely generating correlations between genes. The simulations contain two sets of genes which 1) show differential expression (DE) between celltypes, i.e. marker genes, and 2) which show no DE, i.e. housekeeper genes. Spurious correlations could falsely change housekeeper genes into marker genes. The DE genes drive the PCA, whereas the non-DE genes are expected to show no effect on the PCA. Therefore, we performed PCA on the denoised data using the subset of only non-DE genes (housekeepers) as input. After DCA denoising, celltype identities were not recovered, indicating that the denoising process did not introduce spurious correlations and is robust to overimputing (Supplementary Fig. <xref rid="MOESM1" ref-type="media">2C &amp; D</xref>).</p>
      <p id="Par16">To test if DCA is capable of distinguishing true “celltype specific” from false “dropout” zero counts, we denoised the two group simulation data using hyperparameter settings that regularize for model complexity (see “Methods” section for details). Since the dropout effect is added on top of the simulation, the ground truth for each zero count is known. After DCA denoising we investigated the distribution of the inferred dropout probabilities as captured in the <italic>π</italic> parameter (Supplementary Fig. <xref rid="MOESM1" ref-type="media">2E</xref>, Fig. <xref rid="Fig1" ref-type="fig">1b</xref>). The inferred dropout probability for “dropout” zeros was much higher compared to “celltype specific” zeros, demonstrating the ability of DCA to discern zero counts (Supplementary Fig. <xref rid="MOESM1" ref-type="media">2F</xref>).</p>
    </sec>
    <sec id="Sec4">
      <title>DCA captures cell population structure in real data</title>
      <p id="Par17">Complex scRNA-seq datasets, such as those generated from a whole tissue, may show large cellular heterogeneity. Therefore, denoising methods must be able to capture the cell population structure and use cell population specific parameters for the denoising process. To test whether DCA was able to capture cell population structure in real data we denoised scRNA-seq data of 68,579 peripheral blood mononuclear cells<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> and 1,000 highly variable genes (92% zeros) (Fig. <xref rid="Fig3" ref-type="fig">3a</xref>). NB and ZINB model fits showed comparable goodness-of-fit based on likelihood ratio test (Supplementary Fig. <xref rid="MOESM1" ref-type="media">1B</xref>). In this situation, we advise using the NB noise model, since it is less complex and hence is easier to fit. For this analysis only, we restricted the autoencoder bottleneck layer to two neurons and visualized the activations of these two neurons for each cell in a two-dimensional scatter plot (Fig. <xref rid="Fig3" ref-type="fig">3b</xref>). When overlaying the original celltype information<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, celltype-specific clustering was observed. Furthermore, known celltype marker genes showed cluster-specific expression in the two-dimensional bottleneck visualization (Fig. <xref rid="Fig3" ref-type="fig">3c–f</xref>), indicating that DCA captures the data manifold in real data and consequently cell population structure.<fig id="Fig3"><label>Fig. 3</label><caption><p>DCA captures population structure in 68,579 peripheral blood mononuclear cells. <bold>a</bold> shows the tSNE visualization reproduced from Zheng et al.<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. <bold>b</bold> illustrates the activations from the two-dimensional bottleneck layer of the DCA. Colors represent celltype assignment from Zheng et al.<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, where CD4 + and CD8 + cells are combined into coarse groups. Silhouette coefficients are −0.01 and 0.07 for tSNE and DCA visualizations. <bold>c</bold>–<bold>f</bold> show two-dimensional bottleneck layer colored by the log-transformed expression of celltype marker genes CD8A (CD8 + T cells), CD14 (CD14 + Monocytes), NKG7 (CD56 + natural killer cells) and FCER1A (dendritic cells), respectively. DCA derived manifold robustly reconstructs continuous differentiation phenotype. <bold>g</bold>, <bold>h</bold> illustrate the activations from the two-dimensional bottleneck layer of DCA colored by celltype assignment from Paul et al. (<bold>g</bold>) and diffusion pseudotime (<bold>h</bold>), respectively. <bold>i</bold> shows the DPT as calculated using the standard DPT workflow and the two-dimensional bottleneck layer coordinates on the <italic>X</italic> and <italic>Y</italic> axis, respectively. Cells are colored by celltype assignment from Paul et al.<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>. Abbreviations Ery, Mk, DC, Baso, Mo, Neu, Eos, Lymph correspond to erythrocytes, megakaryocytes, dendritic cells, basophils, monocytes, neutrophils, eosinophils and lymphoid cells, respectively</p></caption><graphic xlink:href="41467_2018_7931_Fig3_HTML" id="d29e627"/></fig></p>
      <p id="Par18">To investigate whether DCA is also able to capture a continuous phenotype, we performed analogous analysis using scRNA-seq data from continuous blood differentiation<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>. When visualizing the two-neuron bottleneck layer, the two differentiation trajectories towards megakaryocyte–erythroid progenitors (MEP) and granulocyte-macrophage progenitors (GMP) were revealed (Fig. <xref rid="Fig3" ref-type="fig">3g</xref>). Additionally, diffusion pseudotime (DPT) was calculated based on the 1) two-neuron bottleneck coordinates (Fig. <xref rid="Fig3" ref-type="fig">3h</xref>) and 2) alternatively on the gene expression PCA coordinates as is suggested in the standard DPT workflow<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. We observed a strong correlation between the pseudotime values derived from the two manifolds, indicating that the DCA bottleneck layer can capture a continuous phenotype (Fig. <xref rid="Fig3" ref-type="fig">3i</xref>). Overall, these results demonstrate that DCA captures meaningful biological information. Therefore, DCA can derive cell population specific denoising parameters in an unsupervised fashion. Furthermore, the low-dimensional DCA representation can be used for downstream analyses, such as pseudotemporal ordering.</p>
    </sec>
    <sec id="Sec5">
      <title>Denoising recovers time-course patterns upon noise induction</title>
      <p id="Par19">Next, we evaluated DCA by performing a systematic comparison with MAGIC<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>, SAVER<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> and scImpute<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> (Supplementary Table <xref rid="MOESM1" ref-type="media">1</xref>). We adapted the evaluation approach from van Dijk et al.<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> and analyzed real bulk transcriptomics data from a developmental C. elegans time course experiment<sup><xref ref-type="bibr" rid="CR36">36</xref></sup> after simulating single-cell specific noise. Bulk contains less noise than single-cell transcriptomics data<sup><xref ref-type="bibr" rid="CR37">37</xref></sup> and can thus aid the evaluation of single-cell denoising methods by providing a good ground truth model. Gene expression was measured from 206 developmentally synchronized young adults over a twelve-hour period (Fig. <xref rid="Fig4" ref-type="fig">4a</xref>). Single-cell specific noise was added in silico by gene-wise subtracting values drawn from the exponential distribution such that 80% of values were zeros<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> (Fig. <xref rid="Fig4" ref-type="fig">4b</xref>). DCA denoising recovered original time course gene expression pattern while removing single-cell specific noise (Fig. <xref rid="Fig4" ref-type="fig">4c</xref>). To systematically evaluate the four methods, we tested which method would best recover the top 500 genes most strongly associated with development in the original data without noise. DCA demonstrated the strongest recovery of these genes, outperforming the other methods (Fig. <xref rid="Fig4" ref-type="fig">4d</xref>). Gene-level expression without, with noise and after DCA denoising for key developmental genes <italic>tbx-36</italic> and <italic>his-8</italic> is depicted in Fig. <xref rid="Fig4" ref-type="fig">4</xref>e, f, g, respectively. Expression data derived from denoising using MAGIC, SAVER and scImpute for these two genes is displayed in Supplementary Fig. <xref rid="MOESM1" ref-type="media">4</xref>. <italic>tbx-36</italic> and <italic>his-8</italic> represent transcription factor and histone gene classes, respectively, which are known to show opposing expression patterns during C.elegans development<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>.<fig id="Fig4"><label>Fig. 4</label><caption><p>DCA recovers gene expression trajectories in <italic>C</italic>. <italic>elegans</italic> time course experiments with simulated dropout. Heatmaps show the top 100 genes with positive and negative association with time course using expression data without noise (<bold>a</bold>), with noise (<bold>b</bold>) and after DCA denoising (<bold>c</bold>). Yellow and blue colors represent relative high and low expression levels, respectively. Zero values are colored grey. Distribution of Pearson correlation coefficients across the 500 most highly correlated genes before noise addition for the various expression matrices are depicted in <bold>d</bold>. The box represents the interquartile range, the horizontal line in the box is the median, and the whiskers represent 1.5 times the interquartile range. Panels <bold>e</bold>–<bold>g</bold> illustrate gene expression trajectory for exemplary anti-correlated gene pair <italic>tbx-36</italic> and <italic>his-8</italic> over time for data without, with noise and after denoising using DCA</p></caption><graphic xlink:href="41467_2018_7931_Fig4_HTML" id="d29e759"/></fig></p>
    </sec>
    <sec id="Sec6">
      <title>Denoising improves differential expression analysis</title>
      <p id="Par20">Motivated by the scRNA-seq denoising evaluation metrics proposed by Li et al.<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>, we compared differential expression analysis results between bulk and scRNA-seq data from the same experiment. Chu et al<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. generated bulk and scRNA-seq data from H1 human embryonic stem cells (H1) differentiated into definitive endoderm cells (DEC). The authors used a read-based scRNA-seq technology. Correspondingly, the examination of the mean and empirical dropout rate revealed that the data followed a ZINB distribution (Supplementary Fig. <xref rid="MOESM1" ref-type="media">1C</xref>). Therefore, we denoised the 1000 most highly variable genes using DCA with ZINB noise model. Next, we performed differential expression analysis comparing H1 to DEC of the bulk and scRNA-seq data independently using DESeq2, which models gene expression based on the NB distribution without zero inflation<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>. After DCA denoising, 4 outlier genes (Fig. <xref rid="Fig5" ref-type="fig">5a</xref>, red dots), showing a high discrepancy between bulk and single-cell derived log fold changes, are corrected in the denoised data. <italic>LEFTY1</italic> is a key gene in the development of the endoderm<sup><xref ref-type="bibr" rid="CR41">41</xref>,<xref ref-type="bibr" rid="CR42">42</xref></sup> and shows high expression in DEC compared to H1 in the bulk data (Fig. <xref rid="Fig5" ref-type="fig">5c</xref>). After DCA denoising, the median expression level of <italic>LEFTY1</italic> in DEC is shifted higher, more closely reflecting the observation in the bulk data (Fig. <xref rid="Fig5" ref-type="fig">5d, e</xref>).<fig id="Fig5"><label>Fig. 5</label><caption><p>DCA increases correspondence between single-cell and bulk differential expression analysis. Scatterplots depict the estimated log fold changes for each gene derived from differential expression analysis using bulk and original scRNA-seq count matrix (<bold>a</bold>), DCA denoised count matrix (<bold>b</bold>). Grey horizontal and vertical lines indicate zero log fold change. Black line indicates identity line. Points are colored by the absolute difference between log fold changes from bulk and single-cell data with red colors indicating relative high differences. <bold>c</bold>–<bold>e</bold> depict differential expression of an exemplary gene <italic>LEFTY1</italic> between H1 and DEC for the bulk, original and DCA denoised data, respectively. <bold>f</bold> illustrates boxplots of the distribution of Pearson correlation coefficients from bootstrapping differential expression analysis using 20 randomly selected cells from the H1 and DEC populations for all denoising methods</p></caption><graphic xlink:href="41467_2018_7931_Fig5_HTML" id="d29e830"/></fig></p>
      <p id="Par21">Next, we systematically compared the four denoising methods for robustness using a bootstrapping approach. 20 random cells were sampled from H1 and DEC populations one hundred times and differential expression analysis using DESeq2 performed. When comparing the estimated log fold changes across all bootstrap iterations, DCA showed the highest correspondence with bulk log fold changes (Fig. <xref rid="Fig5" ref-type="fig">5f</xref>), indicating increased agreement between the DCA denoised and purified bulk data manifolds.</p>
    </sec>
    <sec id="Sec7">
      <title>Denoising increases protein and RNA co-expression</title>
      <p id="Par22">CITE-seq enables simultaneous measurement of protein and RNA levels at cellular resolution. Per-cell protein levels are higher than mRNA levels for the corresponding genes and therefore less prone to dropout events<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>. Therefore, by using cell surface marker protein expressions as ‘ground truth’, denoising of mRNA levels can be evaluated. Stoeckius et al.<sup><xref ref-type="bibr" rid="CR43">43</xref></sup> used this CITE-seq method to profile cord blood mononuclear cells and identified major immunological celltypes (Fig. <xref rid="Fig6" ref-type="fig">6a</xref>). The original RNA count data was denoised using all four methods and evaluated. For DCA denoising the NB noise model was selected as the fits for NB and ZINB showed comparable goodness-of-fit (Supplementary Fig. <xref rid="MOESM1" ref-type="media">1E</xref>). Figure <xref rid="Fig6" ref-type="fig">6b</xref> shows tSNE visualization of the data colored by the expression levels of proteins CD3, CD11c, CD56 and corresponding RNAs <italic>CD3E</italic>, <italic>ITGAX</italic>, <italic>NCAM1</italic> by column, respectively. The rows correspond to the protein expression levels, RNA expression levels derived from the original and DCA denoised data. Visualizations for additional protein-mRNA pairs and other methods can be found in Supplementary Fig. <xref rid="MOESM1" ref-type="media">5</xref> and <xref rid="MOESM1" ref-type="media">6</xref>, respectively. For example, the CD3 protein is expressed in 99.9% of T cells. The corresponding RNA <italic>CD3E</italic>, however, is only detected in 80% of T cells in the original count data. After denoising using DCA, <italic>CD3E</italic> is expressed in 99.9% of all T cells (Fig. <xref rid="Fig6" ref-type="fig">6c</xref>). Some slight discrepancies between the protein and denoised expression can be observed. For example, in the denoised data <italic>ITGAX</italic> shows expression in the natural killer cells (NK) cell cluster while the corresponding CD11c protein levels are very low. Checking data from the website of the Immunological Genome project (immgen.com) confirmed expression of <italic>ITGAX</italic> in NK cells, indicating that the denoised data for this gene reflects better agreement with known biology which may be obscured in the CITE-seq protein data due to some unknown technical reasons. To statistically evaluate the denoising methods we performed co-expression analysis using Spearman correlation for all eight available protein-mRNA pairs across all cells. DCA showed the highest median correlation coefficient, indicating that denoising increases protein and RNA co-expression (Fig. <xref rid="Fig6" ref-type="fig">6d</xref>).<fig id="Fig6"><label>Fig. 6</label><caption><p>DCA increases protein and RNA co-expression. <bold>a</bold> depicts tSNE visualization of transcriptomic profiles of cord blood mononuclear cells from Stoeckius et al.<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>. Cells are colored by major immunological celltypes. <bold>b</bold> contains tSNE visualizations colored by protein expression (first row), RNA expression derived from the original (second row) and DCA denoised data (third row). Columns correspond to CD3 (first column), CD11c (second column), CD56 (third column) proteins and corresponding RNAs CD3E, ITGAX and NCAM1. <bold>c</bold> shows the distribution of expression values for CD3 protein (blue), original (green) and DCA denoised (pink) CD3E RNA in T cells. Spearman correlation coefficients for the eight protein-RNA pairs across all cells for the original and denoised data are plotted in <bold>d</bold></p></caption><graphic xlink:href="41467_2018_7931_Fig6_HTML" id="d29e916"/></fig></p>
    </sec>
    <sec id="Sec8">
      <title>DCA runtime scales linearly with the number of cells</title>
      <p id="Par23">As the number of cells profiled in a single experiment is increasing, it is essential that scRNA-seq methods show good scalability. To assess the scalability of the four methods, we analyzed the currently largest scRNA-seq data set, consisting of 1.3 million mouse brain cells, from 10X Genomics. The 1.3 million cell data matrix was downsampled to 100, 1,000, 2,000, 5,000, 10,000 and 100,000 cells and 1000 highly variable genes. Each subsampled matrix was denoised and the runtime measured (Fig. <xref rid="Fig7" ref-type="fig">7</xref>). The runtime of DCA scaled linearly with the number of cells (slope = 0.66 for a linear fit on DCA points in log-log scale). While it took DCA minutes to denoise 100,000 cells, the other methods took hours. Therefore, DCA possesses a considerable speed advantage over the competing methods.<fig id="Fig7"><label>Fig. 7</label><caption><p>DCA scales linearly with the number of cells. Plot shows the runtimes for denoising of various matrices with different numbers of cells down-sampled from 1.3 million mouse brain cells<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>. Colors indicate different methods. DCA (GPU) indicates the DCA method run on the GPU</p></caption><graphic xlink:href="41467_2018_7931_Fig7_HTML" id="d29e937"/></fig></p>
    </sec>
    <sec id="Sec9">
      <title>Denoising enables discovery of subtle cellular phenotypes</title>
      <p id="Par24">After having evaluated DCA against competing methods, we tested if DCA denoising could enhance biological discovery which is impossible or more challenging to obtain without denoising. Stoeckius et al<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>. highlight the potential for integrated and multimodal analyses to enhance the discovery of cellular phenotypes, particularly when differentiating between cell populations with subtle transcriptomic differences. The authors observed an opposing gradient of CD56 and CD16 protein levels within the transcriptomically derived NK cell cluster (Fig. <xref rid="Fig8" ref-type="fig">8</xref>a, b). Indeed, unsupervised clustering using Gaussian mixture model on the CD16 and CD56 protein expression levels revealed two sub-populations of cells (Fig. <xref rid="Fig8" ref-type="fig">8c</xref>). The corresponding RNAs <italic>NCAM1</italic> and <italic>FCGR3A</italic>, however, contained high levels of dropout obscuring the protein derived sub-population structure (Fig. <xref rid="Fig8" ref-type="fig">8d</xref>). After denoising, the two sub-populations of NK cells become visually more clearly evident based on DCA denoised <italic>NCAM1</italic> and <italic>FCGR3A</italic> RNA expression levels (Fig. <xref rid="Fig8" ref-type="fig">8e</xref>). To assess the agreement between the protein-derived sub-population structure and the expression data, we calculated the silhouette coefficients based on the Euclidean distance of the expression derived from the protein, original and denoised data (Average Silhouette widths: 0.47, 0.17, 0.58, respectively), which demonstrated higher correspondence between the protein and denoised compared to the original RNA data. Therefore, DCA denoising enabled the extraction of information which was exclusively contained in the CITE-seq proteins, demonstrating the ability to enable the discovery of subtle cellular phenotypes.<fig id="Fig8"><label>Fig. 8</label><caption><p>Denoising enhances discovery of cellular phenotypes. tSNE visualization of transcriptomically derived NK cell cluster colored by CD56 (<bold>a</bold>) and CD16 (<bold>b</bold>) protein expression levels. Grey and blue indicate relative low and high expression, respectively. <bold>c</bold> shows CD56 and CD16 protein expression across NK cells, revealing two distinct sub-populations defined as CD56dim (red) and CD56bright (bright). <bold>d</bold>, <bold>e</bold> depict expression of corresponding RNAs NCAM1 and FCGR3A using the original count data and DCA denoised data, respectively. Cells are colored by protein expression derived assignment to CD56bright (black) and CD56dim (red) NK cell sub-populations</p></caption><graphic xlink:href="41467_2018_7931_Fig8_HTML" id="d29e995"/></fig></p>
    </sec>
    <sec id="Sec10">
      <title>Denoising increases correlation structure of key regulators</title>
      <p id="Par25">Next, we tested if denoising enhances discovery of regulatory relationships for well-known transcription factors in blood development<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>. As previously mentioned, in Paul et al.<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> the authors describe the transcriptional differentiation landscape of blood development into MEP and GMP (Fig. <xref rid="Fig9" ref-type="fig">9a, b</xref>). After denoising, a set of well-known MEP and GMP regulators<sup><xref ref-type="bibr" rid="CR45">45</xref></sup> show enhanced regulatory correlations (Fig. <xref rid="Fig9" ref-type="fig">9c, d</xref>), for example, the anticorrelation between <italic>Pu.1</italic> and <italic>Gata1</italic> increases (Fig. <xref rid="Fig9" ref-type="fig">9e, f</xref>). These two transcription factors are important regulators in blood development and known to inhibit each other<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>. This regulatory relationship is identified in denoised data also in cells with zero expression for either gene in the original data, demonstrating the ability of DCA to extract meaningful information from otherwise non-informative zero count values (Supplementary Fig. <xref rid="MOESM1" ref-type="media">5</xref>). Overall, these results demonstrate that DCA enhances the modeling of gene regulatory correlations, and we expect future network inference methods to use denoising as a first preprocessing step.<fig id="Fig9"><label>Fig. 9</label><caption><p>Denoising by DCA increases correlation structure of key regulatory genes. <bold>a</bold>, <bold>b</bold> display diffusion maps of blood development into GMP and MEP colored by developmental trajectory and celltype, respectively. Abbreviations Ery, Mk, DC, Baso, Mo, Neu, Eos, Lymph correspond to erythrocytes, megakaryocytes, dendritic cells, basophils, monocytes, neutrophils, eosinophils and lymphoid cells, respectively. <bold>c</bold>, <bold>d</bold> display heatmaps of correlation coefficients for well-known blood regulators taken from Krumsiek et al.<sup><xref ref-type="bibr" rid="CR45">45</xref></sup>. Highlighted areas show <italic>Pu.1</italic> - <italic>Gata1</italic> correlation in the heatmap. <bold>e</bold>, <bold>f</bold> show anti-correlated gene expression patterns of <italic>Gata1</italic> and <italic>Pu.1</italic> transcription factors colored by pseudotime, respectively</p></caption><graphic xlink:href="41467_2018_7931_Fig9_HTML" id="d29e1079"/></fig></p>
    </sec>
    <sec id="Sec11">
      <title>Evaluation of hyperparameter selection</title>
      <p id="Par26">The choice of the noise model represents the only parameter the user has to specify. As previously mentioned, we describe an approach to guide the user in the selection of the noise model. Additionally, our DCA framework provides a large set of hyperparameters for tuning the model. To assess the impact of hyperparameter choice on the performance of DCA and to provide guidance to users we conducted the following analyses. We denoised the two group simulation data varying the size of the bottleneck layer. We tested five different bottleneck layer sizes (4, 8, 16, 32 and 64 neurons) and performed DCA denoising five times per size. During each iteration the final reconstruction error was saved, PCA performed on the denoised output and the Silhouette coefficient assessing the celltype clustering structure was calculated. Low reconstruction error indicates a good hyperparameter configuration, while high Silhouette coefficient indicates a good separation between the celltypes. The reconstruction error (Fig. <xref rid="Fig10" ref-type="fig">10a</xref>) and silhouette coefficient (Fig. <xref rid="Fig10" ref-type="fig">10b</xref>) show the minimum and maximum values at a bottleneck layer size of 32 neurons, respectively. Selecting too low or high dimensional bottleneck layer sizes decreases the performance of DCA as measured in the ability to separate the two simulated celltypes (Fig. <xref rid="Fig10" ref-type="fig">10c</xref>). Analogous results were obtained when applying this analysis scheme to real data. We denoised the Zheng et al.<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> data varying the bottleneck layer configuration as described above and calculated the Silhouette coefficient based on the Euclidean distance of the principal components and the original celltype labels from Zheng et al.<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> (Fig. <xref rid="Fig10" ref-type="fig">10d, e</xref>). The agreement between the DCA intrinsic reconstruction error and the downstream evaluation in both simulated and read data indicates that the reconstruction error can be used to guide hyperparameter selection. Therefore, DCA implements an automated hyperparameter search which identifies the set of hyperparameters that minimizes the reconstruction error.<fig id="Fig10"><label>Fig. 10</label><caption><p>ReconstructionTraining error correlates with DCA performance and can guide hyperparameter selection. <bold>a</bold>, <bold>b</bold> show the distribution of the reconstructiontraining error and Silhouette coefficients across five different bottleneck layer sizes, respectively. Error bars represent standard error across five iterations. <bold>c</bold> shows exemplary PCA results derived from denoised expression data across the five bottleneck layer configurations. Colors represent simulated celltypes. <bold>d</bold>, <bold>e</bold> show the distribution of the reconstruction error and Silhouette coefficients when applying analogous analysis to the Zheng et al.<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> data</p></caption><graphic xlink:href="41467_2018_7931_Fig10_HTML" id="d29e1134"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec12" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par27">One of the fundamental challenges in scRNA-seq analysis is technical variation. Recent research has shown that accounting for technical variation improves downstream analysis<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR47">47</xref>–<xref ref-type="bibr" rid="CR49">49</xref></sup> such as uncovering the cell differentiation structure, identification of highly variable genes, and clustering. Furthermore, some denoising/imputation methods have been implemented in scRNA-seq workbenches such as Granatum<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>, indicating that it is an important, frequently used processing or smoothing step e.g. for visualization.</p>
    <p id="Par28">Here, we introduce a robust and fast autoencoder-based denoising method tailored to scRNA-seq datasets, which represents one of the first applications of deep learning to scRNA-seq data. We demonstrate that denoising scRNA-seq data can remove technical variation improving five possible downstream analyses, namely clustering, time course modeling, differential expression, protein-RNA co-expression and pseudotime analyses. Furthermore, we show that DCA is highly scalable to datasets with up to millions of cells.</p>
    <p id="Par29">The evaluation of denoising is difficult because the definition of a ground truth can be challenging for real data. We, therefore, described a diverse set of evaluation scenarios, which may allow systematic assessment of other denoising techniques in the future. Furthermore, in order to avoid bias in comparisons, we adapted evaluation approaches and used corresponding data from competing methods for evaluation.</p>
    <p id="Par30">Note that in general, it may be difficult to determine when denoising improves scRNA-seq data. As expected, we observe increased gene-gene correlation after denoising; while in our examples this enriched for desired regulatory dependencies, this may also lead to overimputation in case of inadequate hyperparameter choices such as too low-dimensional bottleneck layer and hence data manifold. To alleviate overfitting and overimputation, a general and not yet extensively treated issue of imputation methods, we implemented a number of regularization methods, including dropout, encoder-specific and overall L1 and L2 regularization. This is required especially when training on data sets with limited sample size. DCA also allows users to conduct a hyperparameter search to find the optimal set of parameters for denoising to avoid poor generalization due to overfitting. However, we would like to point out that hyperparameters were not fine-tuned for any of the analyses described in the manuscript. Additionally, DCA enables parallelization using GPUs.</p>
    <p id="Par31">The proposed method can be easily integrated into existing workflows; in particular, it supports h5ad-formatted HDF5 files (<ext-link ext-link-type="uri" xlink:href="https://github.com/theislab/anndata">https://github.com/theislab/anndata</ext-link>) and the Python API is compatible with the Scanpy<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> package.</p>
  </sec>
  <sec id="Sec13">
    <title>Methods</title>
    <sec id="Sec14">
      <title>Autoencoders</title>
      <p id="Par32">Artificial neural networks were shown to outperform traditional approaches as they learn complex structure in the data to predict an outcome<sup><xref ref-type="bibr" rid="CR51">51</xref>,</sup>. A specialization is an “autoencoder” when no outcome information is available. An autoencoder learns to predict input data using three layers: an input layer, a hidden (“bottleneck”) layer and an output layer<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. It is characterized by the fact that both input and output layers are of the same size (i.e. same number of genes) and the bottleneck layer is of much lower dimensionality. By adjusting the weights of the neural network, the autoencoder learns in an unsupervised manner how to efficiently compress and subsequently reconstruct the data using typically MSE loss function. Since the compression forces the autoencoder to learn only the essential latent features, the reconstruction ignores non-essential sources of variation such as random noise (Fig. <xref rid="Fig1" ref-type="fig">1a</xref>). Therefore, the compressed representation reflects the high dimensional ambient data space in significantly lower dimensionality and captures the underlying true data manifold. For example, in a data set where snapshots of differentiating blood cells exist, the manifold captures the continuum of differentiation phenotypes<sup><xref ref-type="bibr" rid="CR17">17</xref></sup> in a zero-noise scenario. For an analogy, principal component analysis (PCA) can be interpreted as a linear autoencoder with MSE loss function. Reconstruction of the data with the first two principal components corresponds to the output of a linear autoencoder with a two-dimensional bottleneck layer.</p>
    </sec>
    <sec id="Sec15">
      <title>Noise model</title>
      <p id="Par33">The ZINB distribution models highly sparse and overdispersed count data. The ZINB mixture model consists of the following two components: (1) a point mass at zero which represents excess zero values in the data and (2) a negative binomial component representing the count distribution. For scRNA-seq data, the point mass at zero may capture dropout events while the negative binomial component of the distribution represents the process of sampling reads from underlying molecules.</p>
      <p id="Par34">The ZINB distribution is parameterized with mean and dispersion parameters of the negative binomial component (<italic>μ</italic> and <italic>θ</italic>) and the mixture coefficient that represents the weight of the point mass (<italic>π</italic>):<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\it{{\rm{NB}}}}\left( {{\it{x}};{\it{\mu }},{\it{\theta }}} \right) = \frac{{{\it{\Gamma }}\left( {{\it{x}} + {\it{\theta }}} \right)}}{{{\it{\Gamma }}\left( {\it{\theta }} \right)}}\left( {\frac{{\it{\theta }}}{{{\it{\theta }} + {\it{\mu }}}}} \right)^{\it{\theta }}\left( {\frac{{\it{\mu }}}{{{\it{\theta }} + {\it{\mu }}}}} \right)^{\it{x}}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mi>N</mml:mi><mml:mi>B</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>Γ</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>Γ</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:mi>μ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mfrac><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:mi>μ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:math><graphic xlink:href="41467_2018_7931_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\text{ZINB}}}\left( {{\it{x}};{\it{\pi }},{\it{\mu }},{\it{\theta }}} \right) = {\it{\pi \delta }}_0\left( {\it{x}} \right) + \left( {1 - {\it{\pi }}} \right){\text{NB}}\left( {{\it{x}};{\it{\mu }},{\it{\theta }}} \right)$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mi mathvariant="normal">ZINB</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>π</mml:mi><mml:mo>,</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>π</mml:mi></mml:mrow></mml:mfenced><mml:mi mathvariant="normal">NB</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="41467_2018_7931_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec16">
      <title>Architecture and training</title>
      <p id="Par35">Here we use the autoencoder framework to estimate three parameters of ZINB distribution conditioned on the input data for each gene. Therefore, unlike traditional autoencoders, our model also estimates dropout (<italic>π</italic>) and dispersion (<italic>θ</italic>) parameters in addition to the mean (<italic>μ</italic>). Each module corresponds to a parameter of the ZINB distribution, given as <italic>μ</italic>, <italic>θ</italic> and <italic>π</italic>. In this setting, the size of the input layer and three output layers corresponding to these parameters have the same number of features (genes). However, unlike typical autoencoders, there are three output layers instead of one, representing for each gene the three parameters (<italic>μ</italic>, <italic>θ</italic>, <italic>π</italic>) that make up the gene-specific loss function to compare to the original input of this gene. For an analogy, in binary classifiers, the output layer is interpreted as logistic regression using the features extracted from the previous layers. Similarly, the output layer in our approach can be interpreted as ZINB regression where predictors are new representations of cells.</p>
      <p id="Par36">The formulation of the architecture is given below:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{rcl}{\boldsymbol{E}} &amp;= {\it{{\rm{ReLU}}}}\left( {{\bar{\boldsymbol X}}{\boldsymbol{W}}_{\it{E}}} \right)\\ {\boldsymbol{B}} &amp;= {\it{\rm{ReLU}}}\left( {{\boldsymbol{EW}}_{\it{B}}} \right)\\ {\boldsymbol{D}} &amp;= {\it{{\rm{ReLU}}}}\left( {{\boldsymbol{BW}}_{\it{D}}} \right)\\ {\bar{\boldsymbol M}} &amp;= {\it{{\rm{exp}}}}\left( {{\boldsymbol{DW}}_{\it{\mu }}} \right)\\ {\boldsymbol{{\Pi}}} &amp;= {\it{{\rm{sigmoid}}}}\left( {{\boldsymbol{DW}}_{\it{\pi }}} \right)\\ {\boldsymbol{\Theta }} &amp;= {\it{{\rm{exp}}}}\left( {{\boldsymbol{DW}}_{\it{\theta }}} \right)\end{array},$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mi mathvariant="bold-italic">E</mml:mi></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">W</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mi mathvariant="bold-italic">B</mml:mi></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">EW</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mi mathvariant="bold-italic">D</mml:mi></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>L</mml:mi><mml:mi>U</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">BW</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">DW</mml:mi></mml:mrow><mml:mrow><mml:mi>μ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mi mathvariant="bold-italic">Π</mml:mi></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">DW</mml:mi></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mi mathvariant="bold-italic">Θ</mml:mi></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">DW</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2018_7931_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>where <bold>E</bold>, <bold>B</bold> and <bold>D</bold> represent the encoder, bottleneck and decoder layers, respectively. In this formulation, <inline-formula id="IEq1"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathop {{\mathbf{X}}}\limits^ -$$\end{document}</tex-math><mml:math id="M10"><mml:mover><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:mover></mml:math><inline-graphic xlink:href="41467_2018_7931_Article_IEq1.gif"/></alternatives></inline-formula> represents library size, log and <italic>z</italic> score normalized expression matrix, where rows and columns correspond to cells and genes, respectively. Size factors for every cell, <italic>s</italic><sub><italic>i</italic></sub>, is calculated as the total number of counts per cell divided by the median of total counts per cell. <inline-formula id="IEq2"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathop {{\mathbf{X}}}\limits^ -$$\end{document}</tex-math><mml:math id="M12"><mml:mover><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:mover></mml:math><inline-graphic xlink:href="41467_2018_7931_Article_IEq2.gif"/></alternatives></inline-formula> is defined as:<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bar{\boldsymbol X}} = {\it{{\rm{zscore}}}}({\it{{\rm{log}}}}({\rm{diag}}(s_i)^{ - 1}{\boldsymbol{X}} + 1))$$\end{document}</tex-math><mml:math id="M14" display="block"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>z</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">diag</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic xlink:href="41467_2018_7931_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <bold>X</bold> and "zscore" represent the raw count matrix and z-score normalization.</p>
      <p id="Par37">Output activations are shown here in matrix form as <inline-formula id="IEq3"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bar{\mathbf M}}$$\end{document}</tex-math><mml:math id="M16"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">M</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="41467_2018_7931_Article_IEq3.gif"/></alternatives></inline-formula>, <italic>Θ</italic> and ∏. Although the mini-batch stochastic gradient descent is used for optimization, for clarity we depict the matrices of size <italic>n</italic>×<italic>p</italic> where n and p represent the number of cells and genes, respectively.</p>
      <p id="Par38">The activation function of the mean and dispersion output layers is exponential since the mean and dispersion parameters are always non-negative. The third output ∏ estimates the dropout probability for every element of the input. The activation function of this layer is sigmoid as ∏ values represent the dropout probabilities and are therefore limited to the range between zero and one. The activation function of the three output layers is an inverse canonical link function of a ZINB regression model in the context of generalized linear models.</p>
      <p id="Par39">The loss function represents the likelihood of the ZINB distribution:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{rcl}{\hat{\boldsymbol {\Pi}}},{\hat{\boldsymbol M}},{\hat{\boldsymbol \Theta }} &amp;= {\it{{\rm{argmax}}}}_{{\boldsymbol{{\Pi}}},{\boldsymbol{M}},{\boldsymbol{\Theta }}}{\it{{\rm{ZINB}}}}\left( {{\boldsymbol{X}};{\boldsymbol{{\Pi}}},{\boldsymbol{M}},{\boldsymbol{\Theta }}} \right)\\ &amp;= {\it{{\rm{argmax}}}}_{{\boldsymbol{{\Pi}}},{\boldsymbol{M}},{\boldsymbol{\Theta }}}\mathop {\prod }\limits_{{\boldsymbol{i}} = 1}^{\boldsymbol{n}} \mathop {\prod }\limits_{{\boldsymbol{j}} = 1}^{\boldsymbol{p}} {\it{{\rm{ZINB}}}}({\it{x}}_{{\it{ij}}};{\it{\pi }}_{{\it{ij}}},{\it{\mu }}_{{\it{ij}}},{\it{\theta }}_{{\it{ij}}})\end{array},$$\end{document}</tex-math><mml:math id="M18" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">Π</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">Θ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">Π</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Θ</mml:mi></mml:mrow></mml:msub><mml:mi>Z</mml:mi><mml:mi>I</mml:mi><mml:mi>N</mml:mi><mml:mi>B</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">Π</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Θ</mml:mi></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"/><mml:mtd columnalign="center"><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">Π</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Θ</mml:mi></mml:mrow></mml:msub><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo> ∏</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">n</mml:mi></mml:mrow></mml:munderover><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo> ∏</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:munderover><mml:mi>Z</mml:mi><mml:mi>I</mml:mi><mml:mi>N</mml:mi><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2018_7931_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <italic>x</italic><sub><italic>ij</italic></sub> represents the elements in the raw count matrix <bold>X</bold>, <italic>i</italic> and <italic>j</italic> represent cell and gene indices and n and p represent the number of cells and genes. <bold>M</bold> represents the mean matrix multiplied by the size factors that are calculated before the training:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\boldsymbol{M}} = {\it{{\rm{diag}}}}\left( {{\it{s}}_{\it{i}}} \right)\mathop {{\boldsymbol{M}}}\limits^ -,$$\end{document}</tex-math><mml:math id="M20" display="block"><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mover><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo></mml:mrow></mml:mover><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2018_7931_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>which keeps the hidden representation of cells and the optimization process independent of library size differences.</p>
      <p id="Par40">Furthermore, our model contains a tunable zero-inflation regularization parameter that acts as a prior on the weight of the dropout process. This is achieved using the ridge prior on the dropout probabilities and zero inflation (∏ parameter):<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{array}{rcl}{\hat{\boldsymbol {\Pi}}},{\hat{\boldsymbol M}},{\hat{\boldsymbol \Theta }} &amp;= {\mathrm{argmin}}_{{\boldsymbol{{\Pi}}},{\boldsymbol{M}},{\boldsymbol{\Theta }}}{\text{NLL}}_{{\text{ZINB}}}\left( {{\boldsymbol{X}};{\boldsymbol{{\Pi}}},{\boldsymbol{M}},{\boldsymbol{\Theta }}} \right) + {\it{\lambda }}\left\| {\boldsymbol{{\Pi}}} \right\|_{\it{F}}^2\\ &amp; = {\mathrm{argmin}}_{{\boldsymbol{{\Pi}}},{\boldsymbol{M}},{\boldsymbol{\Theta }}}\mathop {\sum }\limits_{{\boldsymbol{i}} = 1}^{\boldsymbol{n}} \mathop {\sum }\limits_{{\boldsymbol{j}} = 1}^{\boldsymbol{p}} {\text{NLL}}_{{\text{ZINB}}}({\it{x}}_{{\it{ij}}};{\it{\pi }}_{{\it{ij}}},{\it{\mu }}_{{\it{ij}}},{\it{\theta }}_{{\it{ij}}}) + {\it{\lambda \pi }}_{{\it{ij}}}^2\end{array},$$\end{document}</tex-math><mml:math id="M22" display="block"><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">Π</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">Θ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mtd><mml:mtd columnalign="center"><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">argmin</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">Π</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Θ</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="normal">NLL</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">ZINB</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">Π</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Θ</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msubsup><mml:mrow><mml:mfenced close="∥" open="∥" separators=""><mml:mrow><mml:mi mathvariant="bold-italic">Π</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"/><mml:mtd columnalign="center"><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">argmin</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">Π</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Θ</mml:mi></mml:mrow></mml:msub><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo> ∑</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">n</mml:mi></mml:mrow></mml:munderover><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo> ∑</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi mathvariant="normal">NLL</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">ZINB</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>λ</mml:mi><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2018_7931_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>where NLL<sub>ZINB</sub> function represents the negative log likelihood of ZINB distribution.</p>
      <p id="Par41">To increase flexibility, we provide implementations of NB, ZINB, Poisson and MSE noise models. Furthermore, users are also allowed to choose whether the dispersion parameter is conditioned on the input. While n <italic>x</italic>
<italic>p</italic> dispersion matrix is estimated from the data in the conditional dispersion (default option), the alternative option estimates an independent dispersion parameter per gene.</p>
    </sec>
    <sec id="Sec17">
      <title>Hyperparameter search</title>
      <p id="Par42">Hyperparameter search allows users to find optimal <italic>λ</italic> value for a given data set along with other hyperparameters like hidden layer configuration, type of activation function, and the strength of L1/L2 regularization on the parameters. For the hyperparameter search, DCA is trained with one thousand hyperparameter configurations sampled from specified ranges for each hyperparameter and the hyperparameter configuration with the lowest reconstruction error is selected. Tree-structured Parzen Estimator (TPE) method implemented in hyperopt<sup><xref ref-type="bibr" rid="CR52">52</xref></sup> is used as the optimization method.</p>
    </sec>
    <sec id="Sec18">
      <title>Zero inflation analysis</title>
      <p id="Par43">To select a suitable noise model, we fit NB and ZINB models to the mean and empirical dropout rate dependence by minimizing the binary cross entropy (BCE) between the observed and predicted dropout rates. For the NB fit, the dispersion parameter is optimized, while for the ZINB model, the zero-inflation parameter (<italic>π</italic>) is modelled as an affine transformation of the observed mean. Therefore, in addition to the dispersion, two more parameters, the slope and the offset are jointly optimized to minimize the BCE. Finally, log-likelihood ratio test is performed using the difference between the negative BCE values of model fits.</p>
    </sec>
    <sec id="Sec19">
      <title>Denoising</title>
      <p id="Par44">The denoised matrix is generated by replacing the original count values with the mean of the negative binomial component (<inline-formula id="IEq4"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bar{\mathbf M}}$$\end{document}</tex-math><mml:math id="M24"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold">M</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="41467_2018_7931_Article_IEq4.gif"/></alternatives></inline-formula> matrix in Equation <xref rid="Equ3" ref-type="">3</xref>) as predicted in the output layer. This matrix represents the denoised and library size normalized expression matrix, the final output of the method. Intuitively, our approach can be interpreted as a two-step process. First, the data is summarized by extracting lower dimensional hidden features that are useful for denoising the data as well as identifying and correcting dropout zeros. Then, a ZINB regression is fitted using these new hidden features. However, these two steps are performed simultaneously during the training.</p>
    </sec>
    <sec id="Sec20">
      <title>Implementation</title>
      <p id="Par45">DCA is implemented in Python 3 using Keras<sup><xref ref-type="bibr" rid="CR53">53</xref></sup> and its TensorFlow<sup><xref ref-type="bibr" rid="CR54">54</xref></sup> backend. We used RMSProp for optimization with learning rate 0.001. Learning rate is multiplied by 0.1 if validation loss does not improve for 20 epochs. The training stops after no improvement in validation loss for 25 epochs. Gradient values are clipped to 5 and the batch size is set to 32 for all datasets. All hidden layers except for the bottleneck consist of 64 neurons. The bottleneck has 32 neurons. Training on CPU or GPU is supported using Keras and TensorFlow.</p>
      <p id="Par46">The hyperparameter search is implemented using hyperopt and kopt Python packages (<ext-link ext-link-type="uri" xlink:href="https://github.com/Avsecz/kopt">https://github.com/Avsecz/kopt</ext-link>).</p>
    </sec>
    <sec id="Sec21">
      <title>Simulated scRNA-seq data</title>
      <p id="Par47">Simulated datasets were generated using the Splatter R package<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>. For the two group simulation the following parameters were used in the <italic>splatSimulate()</italic> R function: groupCells = 2, nGenes = 200, dropout.present = TRUE, dropout.shape -1, dropout.mid = 5. For the six group simulation the following parameters were used in the <italic>splatSimulate()</italic> R function: groupCells = 6, nGenes = 200, dropout.present = TRUE, dropout.shape -1, dropout.mid = 1.</p>
    </sec>
    <sec id="Sec22">
      <title>68k peripheral blood mononuclear cell experiment</title>
      <p id="Par48">Single-cell gene expression count matrix and celltype labels from Zheng et al. were downloaded from <ext-link ext-link-type="uri" xlink:href="http://www.github.com/10XGenomics/single-cell-3prime-paper">http://www.github.com/10XGenomics/single-cell-3prime-paper</ext-link>. Since CD4+ and CD8+ subtype clusters are highly overlapping, they are combined into coarse groups. tSNE coordinates were obtained by reproducing the code from single-cell-3prime-paper repository. For the population structure analysis (Fig. <xref rid="Fig3" ref-type="fig">3</xref>), DCA was run using the following parameter: -s 16,2,16. For the hyperparameter search, various bottleneck layer sizes are compared using -s 64,<italic>i</italic>,64, where <italic>i</italic> represents the bottleneck size being tested.</p>
    </sec>
    <sec id="Sec23">
      <title>MAGIC</title>
      <p id="Par49">MAGIC (version 0.1.0) was downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/pkathail/magic">https://github.com/pkathail/magic</ext-link>. MAGIC was run using default parameters specified as 20 for the numbers of principal components, 6 for the parameter t for the power of the Markov affinity matrix, 30 the number of nearest neighbors, 10 the autotune parameter and 99th percentile to use for scaling.</p>
    </sec>
    <sec id="Sec24">
      <title>scImpute</title>
      <p id="Par50">scImpute (version 0.0.5) was downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/Vivianstats/scImpute">https://github.com/Vivianstats/scImpute</ext-link>. For the C. elegans development experiment, the Chu et al<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. definitive endoderm differentiation experiment, the CITE-seq cord blood mononuclear cells experiment and the scalability analysis, kCluster = 1, kCluster =2, kCluster = 13 and kCluster = 2 parameters were used, respectively.</p>
    </sec>
    <sec id="Sec25">
      <title>SAVER</title>
      <p id="Par51">SAVER (version 0.3.0) was downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/mohuangx/SAVER">https://github.com/mohuangx/SAVER</ext-link>. SAVER was run using default parameters specified as 300 for the maximum number of genes used in the prediction, 50 for the number of lambda to calculate in cross-validation and 5 for the number of folds used in cross-validation. For the scalability analysis, SAVER was run using the R package <italic>doParallel</italic> with 24 cores.</p>
    </sec>
    <sec id="Sec26">
      <title>DCA</title>
      <p id="Par52">For the two and six group simulation data, <italic>C</italic>. <italic>elegans</italic> development and the Chu et al.<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> definitive endoderm differentiation experiments the DCA default parameters were used. For the zero-count analysis, DCA was run using the --ridge 0.005 hyperparameter. This hyperparameter penalizes model complexity by shrinking inferred dropout probabilities (<italic>π</italic>). For the CITE-seq cord blood mononuclear cells experiment, Paul et al. early blood development experiment and the 68k peripheral blood mononuclear cell experiment following parameters were used -<italic>-type nb</italic>.</p>
    </sec>
    <sec id="Sec27">
      <title>C. elegans development experiment</title>
      <p id="Par53">Francesconi et al<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. data set contained 206 samples covering a 12-hour time-course. Similar to the evaluation proposed van Dijk et al<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>., expression values were exponentiated to create a count distribution and subsequently single-cell noise was added in silico by subtracting gene-specific artificial noise from each gene. Gene-specific artificial noise was generated using the exponential function where the mean was calculated as the gene expression median multiplied by five. Any negative values were set to zero so that on average 80% of the values were zero. Pearson correlation was calculated between the expression level of each gene and time course to identify top 500 development genes.</p>
    </sec>
    <sec id="Sec28">
      <title>Definitive endoderm differentiation experiment</title>
      <p id="Par54">The gene expression data from Chu et al.<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> was restricted to single cells and bulk samples from H1 and DEC using the provided annotation and the 1000 most highly variable genes. Differential expression analysis was performed using the R package DESeq2 (version 1.14.1). DESeq2 models gene expression based on a negative binomial distribution without zero-inflation. To retain count structure, denoised data for all methods was rounded prior to analysis. The dispersion was estimated using “mean” for the <italic>fitType</italic> parameter. To assess the robustness of the results, bootstrapping analysis was conducted. During each of 100 iterations, 20 cells from the H1 and DEC cells were randomly selected and differential expression analysis performed as described above. Next, concordance was evaluated using the Pearson correlation between the estimated fold changes derived from the single-cell bootstrap and bulk data.</p>
    </sec>
    <sec id="Sec29">
      <title>CITE-seq cord blood mononuclear cells experiment</title>
      <p id="Par55">The Seurat R package was used to perform the analysis. Following the instructions of the authors<sup><xref ref-type="bibr" rid="CR43">43</xref></sup> data were subset to 8,005 human cells by removing cells with less than 90% human UMI counts. Next, RNA data were normalized, highly variables genes were identified and expression data was scaled. First 13 principal components were calculated and used for clustering and tSNE visualization. A total of 13 clusters were identified. The <italic>genesCLR</italic> method was used for normalization of the protein data. For denoising, gene expression data was restricted to the top 5000 highly variable genes. Co-expression for eight known marker proteins (CD3, CD19, CD4, CD8, CD56, CD16, CD11c, CD14) and corresponding mRNAs (<italic>CD3E, CD19, CD4, CD8A, NCAM1, FCGR3A, ITGAX, CD14</italic>) was assessed using Spearman correlation on the scaled expression data across all 8,005 cells. It is important to note, that the correlation is calculated across all cells and not within a single celltype. Therefore, the correlation coefficient will capture the presence and absence of protein and mRNA more so than a direct linear dependency between the expression levels of the two.</p>
    </sec>
    <sec id="Sec30">
      <title>NK subset analysis</title>
      <p id="Par56">Stoeckius et al<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>. data were subset to 906 NK cells. Next, protein and RNA expression data were scaled. Using CD16 and CD56 protein expression levels, cells were clustered with the <italic>Mclust()</italic> function from the R <italic>mclust</italic> package and two mixture components. To quantitatively assess the correspondence between protein derived sub-populations and mRNA expression levels, the Silhouette coefficient was calculated. The Silhouette coefficient ranges from -1 to 1 and values close to zero indicate random clustering with regards to the specified indicator.</p>
    </sec>
    <sec id="Sec31">
      <title>Blood regulator analysis</title>
      <p id="Par57">Paul et al. blood differentiation data with 2730 cells and 3451 informative genes are used for the analysis. After log transformation with a pseudo-count of one, the kNN graph is constructed using the “<italic>scanpy.api.pp.neighbors</italic>” function. Diffusion map, diffusion pseudotime (DPT) and four diffusion pseudotime groups are computed with “<italic>scanpy.api.tl.dpt(adata, n_branchings=1)</italic>”. Pseudotime estimates of the two DPT groups corresponding to MEP and GMP branches are scaled between [0, 1] and [0, -1] in order to show the branching more distinctly. DCA is run with default parameters and Pearson correlation coefficients between marker genes are calculated with “<italic>numpy.corrcoef</italic>” function. For the 2-neuron bottleneck analysis, DCA was run using the following parameter: -s 16,2,16.</p>
    </sec>
    <sec id="Sec32">
      <title>Scalability analysis</title>
      <p id="Par58">First, cells and genes with zero expression are removed from the count matrix. Next, the top 1000 highly variable genes are selected using “filter_genes_dispersion” function of Scanpy with n_top_genes=1000 argument. The 1.3 million cell data matrix was downsampled to 100, 1000, 2000, 5000, 10,000 and 100,000 cells and these 1000 highly variable genes. Each subsampled matrix was denoised using the four methods and the runtimes measured. Scalability analysis was performed on a server with two Intel Xeon E5-2620 2.40 GHz CPUs. NVIDIA GeForce GTX TITAN X is used for denoising datasets on GPU with DCA.</p>
    </sec>
    <sec id="Sec33">
      <title>Code availability</title>
      <p id="Par59">DCA, including usage tutorial and code to reproduce the main figures in the manuscript, can be downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/theislab/dca">https://github.com/theislab/dca</ext-link>.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec34">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41467_2018_7931_MOESM1_ESM.pdf">
            <caption>
              <p>Supplementary Information</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="41467_2018_7931_MOESM2_ESM.pdf">
            <caption>
              <p>Reporting Summary</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Journal peer review information:</bold><italic>Nature Communications</italic> thanks the anonymous reviewers for their contribution to the peer review of this work</p>
      <p><bold>Publisher’s note:</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>These authors contributed equally: Gökcen Eraslan, Lukas M. Simon.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Electronic supplementary material</title>
    <p><bold>Supplementary Information</bold> accompanies this paper at 10.1038/s41467-018-07931-2.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>L.S. acknowledges funding from the European Union’s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 753039. This work was supported by the German Ministry of Education and Research LiSyM (No. 031L0047) to N.S.M. and by the German Research Foundation (DFG) within the Collaborative Research Centre 1243, Subproject A17 as well as by the Helmholtz Association (Incubator grant sparse2big, grant # ZT-I-0007) to F.J.T.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>F.J.T. designed the research. G.E., L.S. and M.M. carried out the data analysis. F.J.T., N.S.M., L.S. and G.E. contributed to the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The data sets analysed during the current study are publicly available. Bulk microarray gene expression of developing C.elegans embryos was downloaded the supplementary material of Francesconi et al<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. Chu et al.<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> single-cell and bulk RNA-seq data for definitive endoderm differentiation experiment are available at the Gene Expression Omnibus (GEO) under accession code GSE75748. Single-cell protein and RNA raw count expression matrices for CITE-seq cord blood mononuclear cells experiment are available at GEO under accession code GSE100866. Paul et al. blood differentiation data including the celltype annotations are obtained via “<italic>scanpy.api.datasets.paul15()”</italic> function of Scanpy Python package. 1.3 million mouse brain cell data were downloaded from <ext-link ext-link-type="uri" xlink:href="https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/1M_neurons">https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/1M_neurons</ext-link>. 68k PBMC data from Zheng et al.<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> is downloaded from <ext-link ext-link-type="uri" xlink:href="http://www.github.com/10XGenomics/single-cell-3prime-paper">http://www.github.com/10XGenomics/single-cell-3prime-paper</ext-link>.</p>
  </notes>
  <notes notes-type="COI-statement">
    <sec id="FPar1">
      <title>Competing interests</title>
      <p>The authors declare no competing interests.</p>
    </sec>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Keren-Shaul</surname>
            <given-names>H</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A unique microglia type associated with restricting development of Alzheimer’s disease</article-title>
        <source>Cell</source>
        <year>2017</year>
        <volume>169</volume>
        <fpage>1276</fpage>
        <lpage>1290.e17</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2017.05.018</pub-id>
        <pub-id pub-id-type="pmid">28602351</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stephenson</surname>
            <given-names>W</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Single-cell RNA-seq of rheumatoid arthritis synovial tissue using low-cost microfluidic instrumentation</article-title>
        <source>Nat. Commun.</source>
        <year>2018</year>
        <volume>9</volume>
        <fpage>791</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-017-02659-x</pub-id>
        <pub-id pub-id-type="pmid">29476078</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Haghverdi</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Büttner</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wolf</surname>
            <given-names>FA</given-names>
          </name>
          <name>
            <surname>Buettner</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Theis</surname>
            <given-names>FJ</given-names>
          </name>
        </person-group>
        <article-title>Diffusion pseudotime robustly reconstructs lineage branching</article-title>
        <source>Nat. Methods</source>
        <year>2016</year>
        <volume>13</volume>
        <fpage>845</fpage>
        <lpage>848</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.3971</pub-id>
        <pub-id pub-id-type="pmid">27571553</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Moignard</surname>
            <given-names>V</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Decoding the regulatory network of early blood development from single-cell gene expression measurements</article-title>
        <source>Nat. Biotechnol.</source>
        <year>2015</year>
        <volume>33</volume>
        <fpage>269</fpage>
        <lpage>276</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.3154</pub-id>
        <pub-id pub-id-type="pmid">25664528</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Herring</surname>
            <given-names>CA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Unsupervised trajectory analysis of single-cell rna-seq and imaging data reveals alternative tuft cell origins in the gut</article-title>
        <source>Cell Syst.</source>
        <year>2018</year>
        <volume>6</volume>
        <fpage>37</fpage>
        <lpage>51.e9</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2017.10.012</pub-id>
        <pub-id pub-id-type="pmid">29153838</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">Gladka, M. M. et al. Single-Cell Sequencing of the Healthy and Diseased Heart Reveals Ckap4 as a New Modulator of Fibroblasts Activation. <italic>Circulation</italic><bold>138</bold>, 166–180 (2018).</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Buettner</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Computational analysis of cell-to-cell heterogeneity in single-cell RNA-sequencing data reveals hidden subpopulations of cells</article-title>
        <source>Nat. Biotechnol.</source>
        <year>2015</year>
        <volume>33</volume>
        <fpage>155</fpage>
        <lpage>160</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.3102</pub-id>
        <pub-id pub-id-type="pmid">25599176</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vallejos</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Risso</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Scialdone</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Dudoit</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Marioni</surname>
            <given-names>JC</given-names>
          </name>
        </person-group>
        <article-title>Normalizing single-cell RNA sequencing data: challenges and opportunities</article-title>
        <source>Nat. Methods</source>
        <year>2017</year>
        <volume>14</volume>
        <fpage>565</fpage>
        <lpage>571</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.4292</pub-id>
        <pub-id pub-id-type="pmid">28504683</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kharchenko</surname>
            <given-names>PV</given-names>
          </name>
          <name>
            <surname>Silberstein</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Scadden</surname>
            <given-names>DT</given-names>
          </name>
        </person-group>
        <article-title>Bayesian approach to single-cell differential expression analysis</article-title>
        <source>Nat. Methods</source>
        <year>2014</year>
        <volume>11</volume>
        <fpage>740</fpage>
        <lpage>742</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2967</pub-id>
        <pub-id pub-id-type="pmid">24836921</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Macosko</surname>
            <given-names>EZ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Highly parallel genome-wide expression profiling of individual cells using nanoliter droplets</article-title>
        <source>Cell</source>
        <year>2015</year>
        <volume>161</volume>
        <fpage>1202</fpage>
        <lpage>1214</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2015.05.002</pub-id>
        <pub-id pub-id-type="pmid">26000488</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Klein</surname>
            <given-names>AM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Droplet barcoding for single-cell transcriptomics applied to embryonic stem cells</article-title>
        <source>Cell</source>
        <year>2015</year>
        <volume>161</volume>
        <fpage>1187</fpage>
        <lpage>1201</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2015.04.044</pub-id>
        <pub-id pub-id-type="pmid">26000487</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>GXY</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Massively parallel digital transcriptional profiling of single cells</article-title>
        <source>Nat. Commun.</source>
        <year>2017</year>
        <volume>8</volume>
        <fpage>14049</fpage>
        <pub-id pub-id-type="doi">10.1038/ncomms14049</pub-id>
        <pub-id pub-id-type="pmid">28091601</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Angerer</surname>
            <given-names>P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Single cells make big data: New challenges and opportunities in transcriptomics</article-title>
        <source>Curr. Opin. Syst. Biol.</source>
        <year>2017</year>
        <volume>4</volume>
        <fpage>85</fpage>
        <lpage>91</lpage>
        <pub-id pub-id-type="doi">10.1016/j.coisb.2017.07.004</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hicks</surname>
            <given-names>SC</given-names>
          </name>
          <name>
            <surname>William Townes</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Teng</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Irizarry</surname>
            <given-names>RA</given-names>
          </name>
        </person-group>
        <article-title>Missing data and technical variability in single-cell RNA-sequencing experiments</article-title>
        <source>Biostatistics</source>
        <year>2018</year>
        <volume>19</volume>
        <fpage>562</fpage>
        <lpage>578</lpage>
        <pub-id pub-id-type="doi">10.1093/biostatistics/kxx053</pub-id>
        <pub-id pub-id-type="pmid">29121214</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">van Buuren, S. <italic>Flexible Imputation of Missing Data</italic> (CRC Press, Boca Raton, 2012).</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shao</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>From heuristic optimization to dictionary learning: a review and comprehensive comparison of image denoising algorithms</article-title>
        <source>IEEE Trans. Cybern.</source>
        <year>2014</year>
        <volume>44</volume>
        <fpage>1001</fpage>
        <lpage>1013</lpage>
        <pub-id pub-id-type="doi">10.1109/TCYB.2013.2278548</pub-id>
        <pub-id pub-id-type="pmid">24002014</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Moon</surname>
            <given-names>KR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Manifold learning-based methods for analyzing single-cell RNA-sequencing data</article-title>
        <source>Curr. Opin. Syst. Biol.</source>
        <year>2018</year>
        <volume>7</volume>
        <fpage>36</fpage>
        <lpage>46</lpage>
        <pub-id pub-id-type="doi">10.1016/j.coisb.2017.12.008</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Azizi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Prabhakaran</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Carr</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Pe’er</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Bayesian inference for single-cell clustering and imputing</article-title>
        <source>Genom. Comput. Biol.</source>
        <year>2017</year>
        <volume>3</volume>
        <fpage>46</fpage>
        <pub-id pub-id-type="doi">10.18547/gcb.2017.vol3.iss1.e46</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ronen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Akalin</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>netSmooth: network-smoothing based imputation for single cell RNA-seq</article-title>
        <source>F1000Res.</source>
        <year>2018</year>
        <volume>7</volume>
        <fpage>8</fpage>
        <pub-id pub-id-type="doi">10.12688/f1000research.13511.3</pub-id>
        <pub-id pub-id-type="pmid">29511531</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">van Dijk, D. <italic>et al</italic> MAGIC: a diffusion-based imputation method reveals gene-gene interactions in single-cell RNA-sequencing data. <italic>bioRxiv</italic> (2017).</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>SAVER: gene expression recovery for single-cell RNA sequencing</article-title>
        <source>Nat. Methods</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>539</fpage>
        <lpage>542</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-018-0033-z</pub-id>
        <pub-id pub-id-type="pmid">29941873</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>WV</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>JJ</given-names>
          </name>
        </person-group>
        <article-title>An accurate and robust imputation method scImpute for single-cell RNA-seq data</article-title>
        <source>Nat. Commun.</source>
        <year>2018</year>
        <volume>9</volume>
        <fpage>997</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-018-03405-7</pub-id>
        <pub-id pub-id-type="pmid">29520097</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hinton</surname>
            <given-names>GE</given-names>
          </name>
        </person-group>
        <article-title>Reducing the dimensionality of data with neural networks</article-title>
        <source>Science</source>
        <year>2006</year>
        <volume>313</volume>
        <fpage>504</fpage>
        <lpage>507</lpage>
        <pub-id pub-id-type="doi">10.1126/science.1127647</pub-id>
        <pub-id pub-id-type="pmid">16873662</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Goodfellow, I., Bengio, Y. &amp; Courville, A. <italic>Deep Learning</italic>. (MIT Press, 2016).</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Wang, D. &amp; Gu, J. VASC: dimension reduction and visualization of single cell RNA sequencing data by deep variational autoencoder. Preprint at <italic>bioRxiv</italic>10.1101/199315 (2017).</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Tan, J., Hammond, J. H., Hogan, D. A. &amp; Greene, C. S. ADAGE-based integration of publicly available pseudomonas aeruginosa gene expression data with denoising autoencoders illuminates microbe-host interactions. <italic>MSystems</italic><bold>1</bold>, e00025 (2016).</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>YX</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>HB</given-names>
          </name>
        </person-group>
        <article-title>IPMiner: hidden ncRNA-protein interaction sequential pattern mining with stacked autoencoder for accurate computational prediction</article-title>
        <source>BMC Genom.</source>
        <year>2016</year>
        <volume>17</volume>
        <fpage>582</fpage>
        <pub-id pub-id-type="doi">10.1186/s12864-016-2931-8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Way</surname>
            <given-names>GP</given-names>
          </name>
          <name>
            <surname>Greene</surname>
            <given-names>CS</given-names>
          </name>
        </person-group>
        <article-title>Extracting a biologically relevant latent space from cancer transcriptomes with variational autoencoders</article-title>
        <source>Pac. Symp. Biocomput.</source>
        <year>2018</year>
        <volume>23</volume>
        <fpage>80</fpage>
        <lpage>91</lpage>
        <?supplied-pmid 29218871?>
        <pub-id pub-id-type="pmid">29218871</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Ding, J., Condon, A. E. &amp; Shah, S. P. Interpretable dimensionality reduction of single cell transcriptome data with deep generative models. <italic>Nat. Commun</italic>. <bold>9</bold>, 2002 (2018).</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Risso</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Perraudeau</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Gribkova</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Dudoit</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Vert</surname>
            <given-names>JP</given-names>
          </name>
        </person-group>
        <article-title>A general and flexible method for signal extraction from single-cell RNA-seq data</article-title>
        <source>Nat. Commun.</source>
        <year>2018</year>
        <volume>9</volume>
        <fpage>284</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-017-02554-5</pub-id>
        <pub-id pub-id-type="pmid">29348443</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Lopez, R., Regier, J., Cole, M. B., Jordan, M. &amp; Yosef, N. Bayesian inference for a generative model of transcriptome profiles from single-cell RNA sequencing. Preprint at <italic>bioRxiv</italic>10.1101/292037 (2018).</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>UMI-count modeling and differential expression analysis for single-cell RNA sequencing</article-title>
        <source>Genome Biol.</source>
        <year>2018</year>
        <volume>19</volume>
        <fpage>70</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-018-1438-9</pub-id>
        <pub-id pub-id-type="pmid">29855333</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wolf</surname>
            <given-names>FA</given-names>
          </name>
          <name>
            <surname>Angerer</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Theis</surname>
            <given-names>FJ</given-names>
          </name>
        </person-group>
        <article-title>SCANPY: large-scale single-cell gene expression data analysis</article-title>
        <source>Genome Biol.</source>
        <year>2018</year>
        <volume>19</volume>
        <fpage>15</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-017-1382-0</pub-id>
        <pub-id pub-id-type="pmid">29409532</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zappia</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Phipson</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Oshlack</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Splatter: simulation of single-cell RNA sequencing data</article-title>
        <source>Genome Biol.</source>
        <year>2017</year>
        <volume>18</volume>
        <fpage>174</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-017-1305-0</pub-id>
        <pub-id pub-id-type="pmid">28899397</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Paul</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Transcriptional heterogeneity and lineage commitment in myeloid progenitors</article-title>
        <source>Cell</source>
        <year>2015</year>
        <volume>163</volume>
        <fpage>1663</fpage>
        <lpage>1677</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2015.11.013</pub-id>
        <pub-id pub-id-type="pmid">26627738</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Francesconi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lehner</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>The effects of genetic variation on gene expression dynamics during development</article-title>
        <source>Nature</source>
        <year>2013</year>
        <volume>505</volume>
        <fpage>208</fpage>
        <lpage>211</lpage>
        <pub-id pub-id-type="doi">10.1038/nature12772</pub-id>
        <pub-id pub-id-type="pmid">24270809</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stegle</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Teichmann</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Marioni</surname>
            <given-names>JC</given-names>
          </name>
        </person-group>
        <article-title>Computational and analytical challenges in single-cell transcriptomics</article-title>
        <source>Nat. Rev. Genet.</source>
        <year>2015</year>
        <volume>16</volume>
        <fpage>133</fpage>
        <lpage>145</lpage>
        <pub-id pub-id-type="doi">10.1038/nrg3833</pub-id>
        <pub-id pub-id-type="pmid">25628217</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boeck</surname>
            <given-names>ME</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The time-resolved transcriptome of C. elegans</article-title>
        <source>Genome Res.</source>
        <year>2016</year>
        <volume>26</volume>
        <fpage>1441</fpage>
        <lpage>1450</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.202663.115</pub-id>
        <pub-id pub-id-type="pmid">27531719</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chu</surname>
            <given-names>LF</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Single-cell RNA-seq reveals novel regulators of human embryonic stem cell differentiation to definitive endoderm</article-title>
        <source>Genome Biol.</source>
        <year>2016</year>
        <volume>17</volume>
        <fpage>173</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-016-1033-x</pub-id>
        <pub-id pub-id-type="pmid">27534536</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Love</surname>
            <given-names>MI</given-names>
          </name>
          <name>
            <surname>Huber</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Anders</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2</article-title>
        <source>Genome Biol.</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>550</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-014-0550-8</pub-id>
        <pub-id pub-id-type="pmid">25516281</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Oulad-Abdelghani</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Stra3/lefty, a retinoic acid-inducible novel member of the transforming growth factor-beta superfamily</article-title>
        <source>Int. J. Dev. Biol.</source>
        <year>1998</year>
        <volume>42</volume>
        <fpage>23</fpage>
        <lpage>32</lpage>
        <?supplied-pmid 9496783?>
        <pub-id pub-id-type="pmid">9496783</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Rodriguez</surname>
            <given-names>RT</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ghodasara</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>SK</given-names>
          </name>
        </person-group>
        <article-title>Targeting SOX17 in human embryonic stem cells creates unique strategies for isolating and analyzing developing endoderm</article-title>
        <source>Cell. Stem. Cell.</source>
        <year>2011</year>
        <volume>8</volume>
        <fpage>335</fpage>
        <lpage>346</lpage>
        <pub-id pub-id-type="doi">10.1016/j.stem.2011.01.017</pub-id>
        <pub-id pub-id-type="pmid">21362573</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stoeckius</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Simultaneous epitope and transcriptome measurement in single cells</article-title>
        <source>Nat. Methods</source>
        <year>2017</year>
        <volume>14</volume>
        <fpage>865</fpage>
        <lpage>868</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.4380</pub-id>
        <pub-id pub-id-type="pmid">28759029</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <mixed-citation publication-type="other">Genomics, 10x. <italic>1.3 Million Brain Cells from E18 Mice</italic><ext-link ext-link-type="uri" xlink:href="https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/1M_neurons">https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/1M_neurons</ext-link> (2017).</mixed-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Krumsiek</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Marr</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Schroeder</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Theis</surname>
            <given-names>FJ</given-names>
          </name>
        </person-group>
        <article-title>Hierarchical differentiation of myeloid progenitors is encoded in the transcription factor network</article-title>
        <source>PLoS One</source>
        <year>2011</year>
        <volume>6</volume>
        <fpage>e22649</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0022649</pub-id>
        <pub-id pub-id-type="pmid">21853041</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Orkin</surname>
            <given-names>SH</given-names>
          </name>
          <name>
            <surname>Zon</surname>
            <given-names>LI</given-names>
          </name>
        </person-group>
        <article-title>Hematopoiesis: an evolving paradigm for stem cell biology</article-title>
        <source>Cell</source>
        <year>2008</year>
        <volume>132</volume>
        <fpage>631</fpage>
        <lpage>644</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2008.01.025</pub-id>
        <pub-id pub-id-type="pmid">18295580</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brennecke</surname>
            <given-names>P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Accounting for technical noise in single-cell RNA-seq experiments</article-title>
        <source>Nat. Methods</source>
        <year>2013</year>
        <volume>10</volume>
        <fpage>1093</fpage>
        <lpage>1095</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2645</pub-id>
        <pub-id pub-id-type="pmid">24056876</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vallejos</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Marioni</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Richardson</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>BASiCS: bayesian analysis of single-cell sequencing data</article-title>
        <source>PLoS Comput. Biol.</source>
        <year>2015</year>
        <volume>11</volume>
        <fpage>e1004333</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1004333</pub-id>
        <pub-id pub-id-type="pmid">26107944</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>B</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Normalization and noise reduction for single cell RNA-seq experiments</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>31</volume>
        <fpage>2225</fpage>
        <lpage>2227</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btv122</pub-id>
        <pub-id pub-id-type="pmid">25717193</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhu</surname>
            <given-names>X</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Granatum: a graphical single-cell RNA-Seq analysis pipeline for genomics scientists</article-title>
        <source>Genome Med.</source>
        <year>2017</year>
        <volume>9</volume>
        <fpage>108</fpage>
        <pub-id pub-id-type="doi">10.1186/s13073-017-0492-3</pub-id>
        <pub-id pub-id-type="pmid">29202807</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>LeCun</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Deep learning</article-title>
        <source>Nature</source>
        <year>2015</year>
        <volume>521</volume>
        <fpage>436</fpage>
        <lpage>444</lpage>
        <pub-id pub-id-type="doi">10.1038/nature14539</pub-id>
        <pub-id pub-id-type="pmid">26017442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bergstra</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Komer</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Eliasmith</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Yamins</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Cox</surname>
            <given-names>DD</given-names>
          </name>
        </person-group>
        <article-title>Hyperopt: a Python library for model selection and hyperparameter optimization</article-title>
        <source>Comput. Sci. Discov.</source>
        <year>2015</year>
        <volume>8</volume>
        <fpage>014008</fpage>
        <pub-id pub-id-type="doi">10.1088/1749-4699/8/1/014008</pub-id>
      </element-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <mixed-citation publication-type="other">Chollet, F. Keras. <italic>Github</italic><ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras">https://github.com/fchollet/keras</ext-link> (2015)</mixed-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <mixed-citation publication-type="other">Martín, A. A. <italic>et</italic><italic>al</italic>. <italic>TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems</italic><ext-link ext-link-type="uri" xlink:href="https://www.tensorflow.org/">https://www.tensorflow.org/</ext-link> (2015)</mixed-citation>
    </ref>
  </ref-list>
</back>
