<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9525007</article-id>
    <article-id pub-id-type="pmid">35972352</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btac544</article-id>
    <article-id pub-id-type="publisher-id">btac544</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Bioimage Informatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Stitching and registering highly multiplexed whole-slide images of tissues and tumors using ASHLAR</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-0811-637X</contrib-id>
        <name>
          <surname>Muhlich</surname>
          <given-names>Jeremy L</given-names>
        </name>
        <aff><institution>Human Tumor Atlas Network, Harvard Medical School</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
        <aff><institution>Harvard Ludwig Cancer Center and Laboratory of Systems Pharmacology, Harvard Medical School</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7228-4696</contrib-id>
        <name>
          <surname>Chen</surname>
          <given-names>Yu-An</given-names>
        </name>
        <aff><institution>Human Tumor Atlas Network, Harvard Medical School</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
        <aff><institution>Harvard Ludwig Cancer Center and Laboratory of Systems Pharmacology, Harvard Medical School</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yapp</surname>
          <given-names>Clarence</given-names>
        </name>
        <aff><institution>Human Tumor Atlas Network, Harvard Medical School</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
        <aff><institution>Harvard Ludwig Cancer Center and Laboratory of Systems Pharmacology, Harvard Medical School</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7446-2353</contrib-id>
        <name>
          <surname>Russell</surname>
          <given-names>Douglas</given-names>
        </name>
        <aff><institution>Human Tumor Atlas Network, Harvard Medical School</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
        <aff><institution>Harvard Ludwig Cancer Center and Laboratory of Systems Pharmacology, Harvard Medical School</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-7528-9668</contrib-id>
        <name>
          <surname>Santagata</surname>
          <given-names>Sandro</given-names>
        </name>
        <aff><institution>Human Tumor Atlas Network, Harvard Medical School</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
        <aff><institution>Harvard Ludwig Cancer Center and Laboratory of Systems Pharmacology, Harvard Medical School</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
        <aff><institution>Department of Pathology, Brigham and Women’s Hospital</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Sorger</surname>
          <given-names>Peter K</given-names>
        </name>
        <!--peter_sorger@hms.harvard.edu-->
        <aff><institution>Human Tumor Atlas Network, Harvard Medical School</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
        <aff><institution>Harvard Ludwig Cancer Center and Laboratory of Systems Pharmacology, Harvard Medical School</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
        <aff><institution>Department of Systems Biology, Harvard Medical School</institution>, Boston, MA 02115, <country country="US">USA</country></aff>
        <xref rid="btac544-cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Valencia</surname>
          <given-names>Alfonso</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btac544-cor1">To whom correspondence should be addressed. <email>peter_sorger@hms.harvard.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>10</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-08-16">
      <day>16</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>16</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <volume>38</volume>
    <issue>19</issue>
    <fpage>4613</fpage>
    <lpage>4621</lpage>
    <history>
      <date date-type="received">
        <day>07</day>
        <month>6</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>04</day>
        <month>4</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>02</day>
        <month>7</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>22</day>
        <month>9</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btac544.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Stitching microscope images into a mosaic is an essential step in the analysis and visualization of large biological specimens, particularly human and animal tissues. Recent approaches to highly multiplexed imaging generate high-plex data from sequential rounds of lower-plex imaging. These multiplexed imaging methods promise to yield precise molecular single-cell data and information on cellular neighborhoods and tissue architecture. However, attaining mosaic images with single-cell accuracy requires robust image stitching and image registration capabilities that are not met by existing methods.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We describe the development and testing of ASHLAR, a Python tool for coordinated stitching and registration of 10<sup>3</sup> or more individual multiplexed images to generate accurate whole-slide mosaics. ASHLAR reads image formats from most commercial microscopes and slide scanners, and we show that it performs better than existing open-source and commercial software. ASHLAR outputs standard OME-TIFF images that are ready for analysis by other open-source tools and recently developed image analysis pipelines.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>ASHLAR is written in Python and is available under the MIT license at <ext-link xlink:href="https://github.com/labsyspharm/ashlar" ext-link-type="uri">https://github.com/labsyspharm/ashlar</ext-link>. The newly published data underlying this article are available in Sage Synapse at <ext-link xlink:href="https://dx.doi.org/10.7303/syn25826362" ext-link-type="uri">https://dx.doi.org/10.7303/syn25826362</ext-link>; the availability of other previously published data re-analyzed in this article is described in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref>. An informational website with user guides and test data is available at <ext-link xlink:href="https://labsyspharm.github.io/ashlar/" ext-link-type="uri">https://labsyspharm.github.io/ashlar/</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>U2C-CA233262</award-id>
        <award-id>U2C-CA233280</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Ludwig Cancer Center</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Bill and Melinda Gates Foundation</institution>
            <institution-id institution-id-type="DOI">10.13039/100000865</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>INV-027106</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Multiple approaches have been described for performing 20–60 plex subcellular resolution microscopy on normal and diseased tissues for research and diagnostic purposes (<xref rid="btac544-B2" ref-type="bibr">Angelo <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btac544-B11" ref-type="bibr">Gerdes <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btac544-B13" ref-type="bibr">Giesen <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btac544-B14" ref-type="bibr">Goltsev et al., 2018</xref>; <xref rid="btac544-B26" ref-type="bibr">Lin <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac544-B39" ref-type="bibr">Tsujikawa <italic toggle="yes">et al.</italic>, 2017</xref>). These methods make it possible to image differentiation markers, signaling proteins, cell cycle regulators, oncogenes and drug targets in a preserved tissue context. The resulting data can be processed to determine the molecular and physical relationships of cells within the tissue to each other, to the local vasculature, and to the non-cellular components within connective tissue or basement membranes. Research has shown that spatial profiling by highly multiplexed microscopy can reveal features of normal and diseased tissues and their responses to therapy that cannot be discerned in other ways (<xref rid="btac544-B10" ref-type="bibr">Färkkilä <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac544-B14" ref-type="bibr">Goltsev et al., 2018</xref>; <xref rid="btac544-B23" ref-type="bibr">Launonen <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btac544-B36" ref-type="bibr">Schürch <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btac544-B40" ref-type="bibr">Wagner <italic toggle="yes">et al.</italic>, 2019</xref>). For this reason, multiplexed spatial profiling of proteins and mRNA is the cornerstone of large scale atlasing projects such as the Human Cell Atlas (<xref rid="btac544-B31" ref-type="bibr">Regev <italic toggle="yes">et al.</italic>, 2017</xref>), NIH HuBMAP consortium (<xref rid="btac544-B20" ref-type="bibr">HuBMAP Consortium, 2019</xref>) and NCI Human Tumor Atlas Network (HTAN) (<xref rid="btac544-B32" ref-type="bibr">Rozenblatt-Rosen <italic toggle="yes">et al.</italic>, 2020</xref>). Such atlases promise to fundamentally advance understanding of tissue development and physiology and improve how diseases are diagnosed and individual patients matched to optimal therapies.</p>
    <p>Highly multiplexed imaging of proteins in tissues uses antibodies to detect specific antigens, building on 80 years of experience with immunohistochemistry in research and diagnostic settings (<xref rid="btac544-B41" ref-type="bibr">Wick, 2012</xref>). Methods such as MxIF, CyCIF, CODEX, 4i and mIHC use conventional fluorescence and brightfield microscopes, whereas Multiplexed Ion Beam Imaging (MIBI) and Imaging Mass Cytometry (IMC) vaporize specimens with ion beams or lasers followed by atomic mass spectrometry (<xref rid="btac544-B2" ref-type="bibr">Angelo <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btac544-B11" ref-type="bibr">Gerdes <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btac544-B13" ref-type="bibr">Giesen <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btac544-B14" ref-type="bibr">Goltsev et al., 2018</xref>; <xref rid="btac544-B17" ref-type="bibr">Gut <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac544-B26" ref-type="bibr">Lin <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac544-B39" ref-type="bibr">Tsujikawa <italic toggle="yes">et al.</italic>, 2017</xref>). Approaches to imaging nucleic acids are based on hybridization (<xref rid="btac544-B7" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="btac544-B24" ref-type="bibr">Lee <italic toggle="yes">et al.</italic>, 2014</xref>) and sequencing (<xref rid="btac544-B37" ref-type="bibr">Ståhl <italic toggle="yes">et al.</italic>, 2016</xref>). Some methods require frozen samples, but methods that use Formaldehyde Fixed Paraffin Embedded specimens—the sample type universally acquired for diagnostic purposes—can tap into large archives of human biopsy and resection specimens (<xref rid="btac544-B4" ref-type="bibr">Burger <italic toggle="yes">et al.</italic>, 2021</xref>).</p>
    <p>Existing imaging methods differ in resolution, field of view and number of distinct antigens or genes that can be detected (the assay ‘plex’). Most immunofluorescence methods (e.g. MxIF, CyCIF, mIHC, CODEX and Immuno-SABER) are cyclic approaches in which high-plex data are generated by the repeated acquisition of lower-plex images, each of which has two to six channels of information. Each channel represents an image acquired with excitation and emission filters matching one antibody or oligo-coupled fluorophore. As such, cyclic imaging makes it possible to optimally exploit the optical properties of fluorescence microscopes while interrogating 60 or more distinct antigens from a single specimen. Conventional research-grade fluorescence microscopes can acquire data from up to six different channels, at resolutions down 0.25 µm (laterally) which makes a detailed analysis of intracellular structures possible. ‘Slide scanners’ are microscopes equipped with rigid slide holders that move in X and Y and use non-immersion (air) objectives to rapidly move across the specimen. At resolutions sufficient for subcellular imaging, collecting data from a whole slide involves acquiring an array of multiple image ‘tiles’ (10<sup>3</sup> or more for a large specimen of 6 cm<sup>2</sup>). Thus, each tile is a multi-wavelength megapixel-scale image that represents a different lateral (<italic toggle="yes">x</italic>, <italic toggle="yes">y</italic>) stage position. The number of wavelengths in each tile, the number of tiles and the number of imaging ‘cycles’ (each of which involves the acquisition of a full set of tiles), differs with the microscope and the multiplexing technology. However, it is universally true that tiles from all cycles must be merged accurately into a single high-plex ‘mosaic’ image.</p>
    <p>High-plex mosaic images represent the key ‘Level 2 or 3’ data type for all subsequent visualization and quantitative data analysis. The data level concept was introduced by dbGAP for genomics (<xref rid="btac544-B38" ref-type="bibr">Tryka <italic toggle="yes">et al.</italic>, 2014</xref>) and its implementation to tissue imaging is described in detail in the MITI guidelines (<xref rid="btac544-B33" ref-type="bibr">Schapiro <italic toggle="yes">et al.</italic>, 2022a</xref>). In this context, ‘data levels’ denote different degrees of data processing, with Level 1 corresponding to single, raw image tiles, Level 2 data to stitched, illumination corrected mosaics and Level 3 to mosaic images that have also been subjected to manual or automated quality control to improve interpretability and accuracy.</p>
    <p>It is increasingly clear that the greatest challenges in the acquisition and analysis of high-plex image data lies not in image acquisition <italic toggle="yes">per se</italic>, but in the subsequent image processing steps. For example, even the best microscopes require computational alignment of tiles to form a mosaic, since mechanical tolerances and imperfect calibration introduce uncertainty into recorded tile positions. To enable the assembly of a mosaic, tiles are slightly overlapped during acquisition so that each pair of adjacent tiles contains some identical cells. Image features in these cells are then used as reference points for ‘stitching’ adjacent tiles into a seamless mosaic. In cyclic imaging (<xref rid="btac544-B11" ref-type="bibr">Gerdes <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btac544-B26" ref-type="bibr">Lin <italic toggle="yes">et al.</italic>, 2018</xref>), all tiles from the second and subsequent cycles must also be aligned to the mosaic through ‘registration’ of image features across corresponding tiles. DNA-stained nuclei serve as an excellent image feature for alignment since they stain well with a variety of fluorescent dyes, are present at suitable density in most tissue types, and have sharp edges with high contrast. Multiple tools exist for registering image stacks and stitching image tiles (<xref rid="btac544-B6" ref-type="bibr">Chalfoun <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btac544-B18" ref-type="bibr">Holtkamp and Goshtasby, 2009</xref>; <xref rid="btac544-B19" ref-type="bibr">Hörl <italic toggle="yes">et al.</italic>, 2019</xref>) and some are available in common image analysis software such as ImageJ (<xref rid="btac544-B35" ref-type="bibr">Schneider <italic toggle="yes">et al.</italic>, 2012</xref>). However, we have found that open-source tools currently available for stitching and registering whole-slide images are unsatisfactory when applied to high-plex cyclic images with respect to speed, reliability and accuracy. Some commercial instruments have also integrated stitching routines, but we have found that these methods are only sufficient for visual review and are generally not accurate enough for quantitative single-cell analysis. Existing tools also struggle with very large images and generally require substantial format conversion and file renaming, a non-trivial task when confronted with 100 GB of data contained in 10<sup>4</sup> megapixel-scale image tiles (a large 10-cycle whole-slide image).</p>
    <p>In this article, we report the development of a new open-source Python package, ASHLAR (Alignment by Simultaneous Harmonization of Layer/Adjacency Registration), for coordinated stitching and registration of multiplexed, multi-tile images. The package offers both a command line file-oriented interface and a documented Application Programming Interface (API) for incorporation into other tools. ASHLAR can directly process any image format supported by the widely used Open Microscopy Environment (OME) BioFormats library (<xref rid="btac544-B25" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2016</xref>) and it outputs standard OME-TIFF files. We describe ASHLAR’s design and implementation and compare its performance to existing tools using high-plex CyCIF images. ASHLAR is available as a Docker or Singularity container and has been incorporated into MCMICRO (<xref rid="btac544-B33" ref-type="bibr">Schapiro <italic toggle="yes">et al.</italic>, 2022a</xref>), the Nextflow-based image processing pipeline developed by HTAN; as part of MCMICRO, ASHLAR has been tested with several hundred CyCIF, CODEX and mxIF images acquired from 12 types of mouse and human tissues at seven different institutions on five different microscopes and slide scanner platforms (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). ASHLAR is therefore a robust and practical tool for use with diverse spatial profiling methods.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Overview of the assembly process for cyclic multi-tile fluorescence images</title>
      <p>ASHLAR operates in three broad phases to convert a multi-cycle multi-tile (Level 1) dataset into a cohesive (Level 2) mosaic image (<xref rid="btac544-B34" ref-type="bibr">Schapiro <italic toggle="yes">et al.</italic>, 2022b</xref>) (<xref rid="btac544-F1" ref-type="fig">Fig. 1</xref>): (i) tiles within the first imaging cycle are stitched; (ii) tiles from the second and subsequent cycles are registered to corresponding tiles from the first cycle; and (iii) all tiles from all cycles are merged into a mosaic image. The output of stitching and registration is a list of new, corrected positions for all tiles in each cycle. Only in the final mosaic phase is the actual full-size many-channel mosaic image created. These mosaic images can be very large and contain information spanning length scales from &lt;1 µm (subcellular structures) to cm in dimension (gross tissue morphology). In many cases, the boundary of a tissue specimen is irregular, and a significant fraction of the tiles in a rectangular data collection grid contain few if any cells, posing a challenge for stitching as well as an opportunity to reduce data collection demands by creating irregular-shaped tile sets that closely follow the outlines of the tissue.</p>
      <fig position="float" id="btac544-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Schematic of cyclic whole-slide data acquisition, stitching and registration. (<bold>a</bold>) One cycle of whole-slide imaging (scanning) is achieved by moving the microscope stage along a controlled path and acquiring multichannel image tiles that overlap. Further cycles repeat the process after the specimens are re-labeled with new antibodies or other detection reagents. Note that the left-hand portion of this panel depicts just a single reference channel (blue) across three cycles for clarity—actual data contains multiple channels and an arbitrary number of cycles. To integrate information across a wide spatial context at high resolution, it is necessary to stitch neighboring image tiles within one cycle and also register tiles across different cycles. (<bold>b</bold>) The corners of four neighboring tiles (Hoechst 33342-stained channel, pseudocolored by tile) from one cycle are positioned using the recorded microscope stage positions (upper panel) and the corrected stitched positions (lower panel). Arrows indicate two individual cells in the tile overlap regions before and after stitching. (<bold>c</bold>) The centers of three Hoechst-channel image tiles (pseudocolored by cycle) from different cycles are positioned using recorded stage positions (upper panel) and post-ASHLAR registered positions (lower panel). Arrows indicate one cell before and after registration (A color version of this figure appears in the online version of this article.)</p>
        </caption>
        <graphic xlink:href="btac544f1" position="float"/>
      </fig>
      <p>To generate an initial estimate of tile positions, ASHLAR uses data from image tiles (grids of pixels), recorded stage positions and physical pixel dimensions. ASHLAR leverages the Open Microscopy Environment Bio-Formats library (<xref rid="btac544-B25" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2016</xref>) to extract the necessary image data and metadata (stage position and pixel size) directly from native image files produced by the great majority of commercial microscopes, obviating the need for image format conversion and manual metadata extraction. For microscopes that do not support BioFormats, ASHLAR accepts a set of TIFF files using a configurable naming convention along with an explicit specification of tile overlap and acquisition order. Subsequent stitching and registration involve aligning one image to another. In stitching, the small overlapping strips of adjacent tiles are aligned (<xref rid="btac544-F1" ref-type="fig">Fig. 1b</xref>), and in registration, full tiles that cover the same region of the sample but acquired in different cycles are aligned (<xref rid="btac544-F1" ref-type="fig">Fig. 1c</xref>). We performed stitching and registration only on the reference image channel (typically Hoechst 33342-stained nuclei) and applied the resulting positional corrections to all other channels recorded within that cycle. This is sufficient because the chromatic aberration exhibited by research-grade wide-field microscopes is not a major contributor to image inaccuracy at resolutions typically used for tissue imaging (10–40× magnification, 0.3–0.95 NA air objectives).</p>
    </sec>
    <sec>
      <title>2.2 Image alignment with sub-pixel precision phase correlation</title>
      <p>ASHLAR uses the phase correlation algorithm (<xref rid="btac544-B21" ref-type="bibr">Kuglin and Hines, 1975</xref>) for image alignment during both stitching and registration phases. Phase correlation is a fast, parameter-free method that computes the image alignment with maximum cross-correlation, but it is only suitable for aligning images that are translated relative to each other in X and Y; it cannot directly align images that differ by rotation, scaling, skew or non-affine transformations. This trade-off is acceptable for accurate stitching of multi-tile images on the five microscopes we have tested (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>) since the rigidity of the sample and the construction of modern stages ensures that almost all of the discrepancy between recorded stage positions and true positions can be modeled by translation alone. Stage position errors encountered between multiple imaging cycles are also purely translational, as long as the slide is always placed at exactly the same angle on the stage; this can routinely be achieved with kinematic mounts that positively register the slide in a consistent position (this is a standard feature of contemporary slide-scanning microscopes).</p>
      <p>ASHLAR uses an enhanced method of phase correlation that improves the precision of tile alignment. The accuracy of classical phase correlation is limited to whole pixels. At pixel sizes around 1 µm or larger, this represents a substantial error relative to the size of a single cell. We overcame this limitation by using an improved phase correlation algorithm (<xref rid="btac544-B16" ref-type="bibr">Guizar-Sicairos <italic toggle="yes">et al.</italic>, 2008</xref>) that offers arbitrary sub-pixel precision with minimal extra computation. An alignment precision of 0.1 pixels produced a discernible improvement in final mosaic quality over whole-pixel alignment, with diminishing returns beyond that. ASHLAR also enhances phase correlation by pre-filtering input images with the discrete Laplacian operator (or Laplacian of Gaussian operator—LoG—for noisy images) to eliminate auto-correlation. It has been understood for at least a century that computing cross-correlation can yield spurious results with signals that exhibit auto-correlation, but this fact is often overlooked in practice (<xref rid="btac544-B8" ref-type="bibr">Dean and Dunsmuir, 2016</xref>; <xref rid="btac544-B42" ref-type="bibr">Yule, 1926</xref>)—we are aware of only one open-source image stitching tool, ITKMontage (<xref rid="btac544-B43" ref-type="bibr">Zukić <italic toggle="yes">et al.</italic>, 2021</xref>), that performs decorrelation. Our work with ASHLAR shows that decorrelation substantially improves confidence in image tile alignments.</p>
    </sec>
    <sec>
      <title>2.3 Image stitching</title>
      <p>The stitching procedure begins with the creation of a node-edge adjacency graph in which nodes represent tiles (<xref rid="btac544-F2" ref-type="fig">Fig. 2</xref>, Step A1). Edges are added to the graph to connect overlapping tile pairs, which are initially identified by consulting recorded stage positions and other metadata. By reading recorded stage positions directly from BioFormats metadata, it is straightforward to support samples imaged with non-rectangular grids and irregular layouts. <xref rid="btac544-F3" ref-type="fig">Figure 3a</xref> shows the overlap in adjacent tiles associated with one edge in the adjacency graph and reveals that one image is slightly translated relative to the next—this translation represents the stage positioning error we are trying to correct. When the overlap region contains many cell nuclei or other alignment features, phase correlation can accurately and confidently compute the correct translation between the images. Phase correlation will always return <italic toggle="yes">some</italic> value for translation of any two tiles, even when the overlap region is uninformative and contains only incidental signal or background noise in the registration channel; in these cases, we rely on the recorded stage positions. Uninformative overlaps in tissue sections are most commonly encountered when nuclei are scant, such as in fat, connective tissue or regions of necrosis, and in areas in which no tissue is present, such as along the edge of a specimen, between separate pieces of tissue or between the circular cores that make up a tissue microarray (TMA) (a regular grid of 50–200 0.3–1.2 mm pieces of tissue arrayed on a single microscope slide).</p>
      <fig position="float" id="btac544-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>ASHLAR phases for aligning whole-slide scans. (<bold>a</bold>) Steps for stitching tiles within one cycle. (<bold>b</bold>) Steps for registering tiles across cycles. (<bold>c</bold>) Seamless mosaic generation enables whole-slide visualization and flexible re-tiling for downstream parallel processing. Blue-colored graphic components in each step depict the key elements or processes of that step. See text for details (A color version of this figure appears in the online version of this article.)</p>
        </caption>
        <graphic xlink:href="btac544f2" position="float"/>
      </fig>
      <fig position="float" id="btac544-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Visualizing stitching steps using a whole-slide scan from a colon specimen. All images and data in this figure derive from analysis of a large multi-tile image of human colon (see text for details). (<bold>a</bold>) Alignment of one pair of neighboring tiles from an image of human colon. Images of Hoechst 33342-stained nuclei in left and right tiles are pseudocolored in red and cyan, respectively. The red and cyan images are overlaid before and after stitching to demonstrate the effect at the single-cell level. For context, in the remaining panels the location of this tile pair is denoted with a yellow X. (<bold>b</bold>) Alignment shift distance versus E<sub>NCC</sub> for all neighboring pairs, with E<sub>NCC</sub> threshold and user-provided translation limit indicated. The null distribution generated by the permutation test (red) is overlaid on the E<sub>NCC</sub> marginal distribution. Note that while the E<sub>NCC</sub> threshold is computed as the 99th percentile of the null distribution NCC values, it appears at the <italic toggle="yes">left</italic> end of the null distribution in this figure due to transformation of NCC to E<sub>NCC</sub> by taking the negative logarithm (see text). (<bold>c</bold>) Adjacency graph with edges colored by E<sub>NCC</sub> overlaid on the Hoechst image. Edges corresponding to discarded alignments (E<sub>NCC</sub> or shift distance above the thresholds) are hidden. Hidden edges correlate with regions containing scant or no tissue. (<bold>d</bold>) Minimum spanning tree with edges colored by alignment shift distance (A color version of this figure appears in the online version of this article.)</p>
        </caption>
        <graphic xlink:href="btac544f3" position="float"/>
      </fig>
      <p>We use normalized cross-correlation (NCC) to score how well the translation returned by phase correlation aligns images, but the threshold dividing an effective alignment from a spurious one varies by dataset. We estimate this threshold by the 99th percentile of NCC values computed from a permutation test that considers 1000 randomly selected pairs of non-adjacent tiles (<xref rid="btac544-F2" ref-type="fig">Fig. 2a</xref>, Step A2); this corresponds to the unadjusted one-sided empirical <italic toggle="yes">P</italic>-value threshold of 0.01. For each tile pair represented by an edge in the adjacency graph, we crop the images to their mutually overlapping region based on recorded stage positions and align them using phase correlation as described above. This yields a corrected X, Y shift and NCC value (<xref rid="btac544-F2" ref-type="fig">Fig. 2</xref>, Step A3). For all downstream steps, we use the negative logarithm of the NCC values, hereafter referred to as E<sub>NCC</sub> (NCC error), which provides a more intuitive ‘lower is better’ error metric and empirically appears to have a more normal distribution. We use this E<sub>NCC</sub> threshold and a user-provided translation limit parameter to determine whether to discard low-quality tile pair alignments (<xref rid="btac544-F3" ref-type="fig">Fig. 3b</xref>). The value of the translation limit is not particularly critical, as physical translation distances for spurious alignments tend to be fairly extreme (note that the <italic toggle="yes">Y</italic>-axis in <xref rid="btac544-F3" ref-type="fig">Fig. 3b</xref> is on a log scale). When a low-quality alignment is discarded, we delete the corresponding edge from the adjacency graph (<xref rid="btac544-F2" ref-type="fig">Fig. 2</xref>, Step A3 and <xref rid="btac544-F3" ref-type="fig">Fig. 3c</xref>). At this point, there are almost always more remaining pairwise alignments than tiles, leading to an overconstrained system. We solve this by constructing a minimum spanning tree with the E<sub>NCC</sub> values as the edge weights and retaining only the alignments corresponding to edges in this tree (<xref rid="btac544-F2" ref-type="fig">Fig. 2</xref>, Step A4). This allows us to discard extraneous alignments so the position of every tile is unambiguous. Since the edge deletion process in Step A3 could split the graph into multiple disconnected pieces, we perform the spanning tree procedure independently for each piece.</p>
      <p>With this spanning tree, it is straightforward to obtain final corrected positions by walking along the edges from tile to tile (starting at the root) and adding up each pairwise alignment along the way (<xref rid="btac544-F3" ref-type="fig">Fig. 3d</xref>). Even though individual pairwise tile alignments correct primarily for local uncorrelated stage position error, taken collectively they also characterize systematic errors such as miscalibrated pixel size or <italic toggle="yes">Z</italic>-axis camera rotation. To quantify these types of errors, we perform multiple linear regression of the corrected tile positions after stitching (dependent variable) against the original tile positions recorded by the microscope (independent variable) to generate a single affine transformation. This affine transformation is then used to adjust the relative positions of tiles with adjacency graphs that were split into multiple pieces (from Step A3) to counteract systematic stage position error and improve accuracy (<xref rid="btac544-F2" ref-type="fig">Fig. 2</xref>, Step A5). At the end of Steps A1 to A5 (<xref rid="btac544-F2" ref-type="fig">Fig. 2a</xref>), optimized global positions have been determined for all tiles in the first cycle and the stitching is complete.</p>
    </sec>
    <sec>
      <title>2.4 Image registration</title>
      <p>The procedure for registering subsequent cycles against the first cycle uses many of the same tools as stitching, although the goal is aligning whole tiles across data acquisition cycles rather than aligning adjacent tiles edge-to-edge within a single cycle (<xref rid="btac544-F2" ref-type="fig">Fig. 2b</xref>). First, we establish a correspondence between each tile in the target cycle (the one to be registered) and the nearest tile in the first cycle by comparing recorded stage positions (<xref rid="btac544-F2" ref-type="fig">Fig. 2b</xref>, Step B1). Identifying these tile correspondences is trivial when recorded stage positions are consistent from run to run, and the geometry of the image acquisition grids is identical. However, a significant shift in stage positions can occur between cycles with microscopes that lack a physical ‘homing’ procedure to zero stage position encoders at start-up. Shifts also arise where the planned tile grid is significantly displaced or rearranged between runs. To account for this shift when comparing tile positions, we down-sample the data by a factor of 20 and assemble low-resolution ‘thumbnail’ mosaic images for each cycle using the recorded stage positions. We then align the thumbnails using phase correlation with sub-pixel precision to obtain a coarse alignment between the first and target cycles. Working with low-resolution images in this step saves compute time and memory while providing sufficient precision to accurately recover inter-cycle tile correspondences. Next, each corresponding tile pair is cropped to mutually overlapping regions and aligned using phase correlation (Step B3). The resulting alignments are then filtered using the user-specified translation limit. Note that we do not currently use a permutation test and E<sub>NCC</sub> threshold in the registration phase (Step B2) as the translation limit alone has been sufficient for all images processed to date. For alignments that pass the filter, the target-cycle tiles are positioned by adding the alignment translations to the corrected positions of the corresponding tiles from the first cycle (Step B4). The remaining tiles (generally those with sparse or no tissue, or where the tissue was damaged significantly during inter-cycle sample handling) are positioned using the affine transformation computed in the stitching phase, assuming that the same microscope and calibration conditions were used for both cycles (Step B5). The registration steps described above are then applied to all other cycles, establishing corrected global positions for all remaining tiles. Importantly, our method registers each cycle of tiles against the first cycle (rather than consecutively against each preceding cycle) because each successive alignment step incurs additional error.</p>
    </sec>
    <sec>
      <title>2.5 Mosaic image generation</title>
      <p>The result of the stitching and registration phases is a corrected global position for every image tile (<xref rid="btac544-F4" ref-type="fig">Fig. 4</xref>). To generate the final output image mosaic, we create an empty image large enough to encompass all corrected tile positions and copy each tile into it at the appropriate coordinates. Since each pairwise image registration is computed to a precision of 0.1 pixels as described above, the sum of these shifts for a given tile generally yields non-integer values for the final coordinates. ASHLAR defaults to applying sub-pixel translations on the tile images to account for this, but some users may prefer to round the final positions to the nearest pixel instead. Where neighboring image tiles overlap in the mosaic, they are combined with linear blending or one of several other user-selectable blending functions. The final many-channel image is then written out as a standard OME-TIFF file containing a multi-resolution image pyramid to support efficient visualization.</p>
      <fig position="float" id="btac544-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>ASHLAR mosaic results. All images and data in this figure derive from analysis of the multi-tile image of human colon shown in <xref rid="btac544-F3" ref-type="fig">Figure 3</xref>. (<bold>a</bold>) Pseudocolor image showing five channels from a 28-plex (9-cycle) t-CyCIF image of a normal human colon section acquired using the antibodies described in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref>. Tiles, denoted by the white grid, overlapped by ∼31 pixels (20 µm) Inset: Hematoxylin and eosin (H&amp;E) staining of an adjacent section of the same specimen. (<bold>b</bold>) Higher magnification view of the area surrounding a single tile showing seven channels from four different cycles to highlight stitching and registration accuracy. Insets 1–4 depict regions of the tile overlap areas at full resolution (note that the antibodies shown in panels a and b differ to make structures relevant to different spatial scales more apparent)</p>
        </caption>
        <graphic xlink:href="btac544f4" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>2.6 Implementation</title>
      <p>ASHLAR is implemented in Python 3 and utilizes many numerical and image processing routines from the numpy, scipy, scikit-image, scikit-learn and networkx packages. The pyjnius Python-to-Java connector provides access to the Java BioFormats library for reading microscopy image files. The user interface is mainly via command-line script, but the underlying Python modules may also be used directly.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Evaluation of stitching accuracy</title>
      <p>We identified MIST (<xref rid="btac544-B6" ref-type="bibr">Chalfoun <italic toggle="yes">et al.</italic>, 2017</xref>) as the current state-of-the-art public-domain tool for stitching large, tiled microscopy images. We used the evaluation framework described by Chalfoun <italic toggle="yes">et al.</italic> to compare the accuracy of stitching by ASHLAR and MIST using that manuscript’s most challenging dataset: a plate of widely-spaced GFP-labeled stem cell colonies that were grown for 2 days and imaged with 10% tile overlap. The Chalfoun <italic toggle="yes">et al.</italic> dataset contains two image sets acquired via separate mechanisms: (i) images acquired with ‘traditional’ overlapping tiles and (ii) ground-truth images—with each colony centered and wholly contained in a single image field—acquired with a closed-loop microscope stage control algorithm. The Chalfoun <italic toggle="yes">et al.</italic> evaluation framework assesses the accuracy of a stitching algorithm by applying the algorithm to the overlapping tile set, segmenting the stitched output mosaic into colonies, and finally comparing each colony’s area and position to the ground truth data. Four metrics are reported: <italic toggle="yes">False negative count</italic> (FN), <italic toggle="yes">false positive count</italic> (FP), per-colony <italic toggle="yes">size error</italic> (S<sub>err</sub>) and per-colony position <italic toggle="yes">distance error</italic> (D<sub>err</sub>) (see Chalfoun <italic toggle="yes">et al.</italic> for full details). MIST and ASHLAR yielded the same false negative and false positive counts (FN = 47, FP = 4), the size error distributions were nearly the same and had indistinguishable medians (median S<sub>err</sub> = 0.0474%), and the distance error distributions were also similar with a difference between medians that was not statistically significant (MIST median D<sub>err</sub> = 10.8 pixels, ASHLAR median D<sub>err</sub> = 11.5 pixels, Mood’s median test <italic toggle="yes">P</italic>-value = 0.32) (<xref rid="btac544-F5" ref-type="fig">Fig. 5a</xref>). We conclude that MIST and ASHLAR have similar stitching accuracy when applied to a previously described test set involving cells grown <italic toggle="yes">in vitro</italic>.</p>
      <fig position="float" id="btac544-F5">
        <label>Fig. 5.</label>
        <caption>
          <p>Performance comparison of ASHLAR and MIST software. (<bold>a</bold>) Stitching error metric distributions (kernel density estimate) for MIST and ASHLAR computed according to the stitching evaluation framework of <xref rid="btac544-B6" ref-type="bibr">Chalfoun <italic toggle="yes">et al.</italic> (2017)</xref>. Dotted lines indicate median values; neither difference in medians was statistically significant. (<bold>b</bold>–<bold>f</bold>) Images and data derive from analysis of the multi-tile image of human colon shown in <xref rid="btac544-F3" ref-type="fig">Figures 3</xref> and <xref rid="btac544-F4" ref-type="fig">4</xref>. (b) Local registration error distance distributions for MIST and ASHLAR mosaic images of two t-CyCIF cycles of a human colon section. Distances at the upper end in this plot as well as in panels d and f were clipped to the 90th percentile of the MIST error values (∼4 µm) to highlight the relevant data. (c) Full-resolution view of four regions from the MIST mosaics demonstrating local registration error in different directions. The Hoechst images of nuclei from cycles 1 and 2 are pseudocolored red and cyan, respectively, to visualize the effect of registration error at the single-cell level. The MIST median error of ∼2 µm is around one-quarter of the diameter of the average cell nucleus, a shift that is clearly visible at full resolution. (d) Heatmap of MIST local registration error direction (hue) and magnitude (intensity) at 200-pixel resolution overlaid on the Hoechst image (brighter colors indicate larger errors). Characteristic tile-sized scale of heatmap features suggests inconsistent stitching. Yellow X marks indicate locations highlighted in panel c. (e) The same regions as in panel c, but taken from ASHLAR mosaics. An identical pseudocoloring scheme is used; the red and cyan images, now more accurately registered, combine to appear nearly white. The ASHLAR median registration error of ∼0.1 µm is ∼1% of the diameter of a nucleus. (f) Heatmap of Ashlar local registration error using the same intensity and hue scale as in panel d showing overall lower error and no apparent tile-scale features. Remaining small-scale errors represent damaged tissue that could not be registered (A color version of this figure appears in the online version of this article.)</p>
        </caption>
        <graphic xlink:href="btac544f5" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.2 Benchmark dataset for evaluating registration accuracy</title>
      <p>As a first test of ASHLAR and MIST on high-plex, whole-slide tissue data, we acquired a ∼24 mm × 14 mm × 5 µm thick section of a human normal colon sample from the Cooperative Human Tumor Network (<ext-link xlink:href="https://www.chtn.org/" ext-link-type="uri">https://www.chtn.org/</ext-link>). This sample was subjected to 9-cycle t-CyCIF (<xref rid="btac544-B26" ref-type="bibr">Lin <italic toggle="yes">et al.</italic>, 2018</xref>) to generate a subcellular-resolution 28-plex image. Cell nuclei were stained with Hoechst 33342 in every cycle, providing reference features for image alignment. Imaging was performed on a RareCyte CyteFinder II HT Instrument with a 20X 0.75 numerical aperture (NA) objective and four excitation and emission filter pairs having peak and full-width at half-maximum bandpass wavelengths (in nm) of: 395/25–438/26, 485/25–522/20, 555/20–590/20 and 651/10–692/40, respectively. 2 × 2 pixel binning was used during acquisition yielding a four-channel tile with dimensions of 1280 × 1080 pixels and a pixel size of 0.65 µm per pixel. To image the entire specimen, a grid of 609 (29 × 21) tiles was used and each tile overlapped by ∼31 pixels (20 µm or 2–3%) in both directions. Each cycle yielded one OME BioFormats-compatible RCPNL file containing 16-bit imaging data from all 609 tiles, ∼7 GB in size. The entire 9-cycle dataset comprises 5481 image tiles and is 61 GB in size. The experimental protocol is documented on protocols.io (<ext-link xlink:href="https://dx.doi.org/10.17504/protocols.io.bjiukkew" ext-link-type="uri">https://dx.doi.org/10.17504/protocols.io.bjiukkew</ext-link>) and antibodies used are listed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref>. The primary unstitched image data are freely available for download from Synapse at <ext-link xlink:href="https://dx.doi.org/10.7303/syn25826362" ext-link-type="uri">https://dx.doi.org/10.7303/syn25826362</ext-link>. We ran both MIST and ASHLAR on this colon dataset, yielding mosaic images ∼36 000 × 22 000 pixels in dimension. <xref rid="btac544-F4" ref-type="fig">Figure 4a</xref> shows the resulting image mosaic following stitching and registration with ASHLAR; the quality of the alignment is highlighted at four regions of tile-tile overlap in <xref rid="btac544-F4" ref-type="fig">Figure 4b</xref>. We then used the Hoechst reference channel mosaic images from the first two cycles to evaluate whether the stitched and registered output from MIST and ASHLAR was aligned accurately enough for single-cell level quantitative analysis.</p>
    </sec>
    <sec>
      <title>3.3 Image registration of independently stitched mosaics</title>
      <p>Whereas ASHLAR performs stitching and registration in a coordinated process, it was necessary to globally register the MIST output mosaics before evaluating local registration accuracy. We first downsampled the MIST mosaic images by 10× to obtain a manageable image size and then aligned them with subpixel-precision phase correlation (phase correlation on the full-size images required a computer with more RAM than was readily available to us). We performed the same process on the ASHLAR mosaics to verify that their global registration was already optimal.</p>
    </sec>
    <sec>
      <title>3.4 Optical flow computation and evaluation of registration accuracy and robustness</title>
      <p>We used dense optical flow fields to quantify and visualize local registration errors in the Hoechst reference channel. Because we could not find any general-purpose dense optical flow implementations capable of processing gigapixel-scale images on a reasonable workstation computer, we implemented our own approximate method suitable for small-magnitude flow fields using a block-based approach which is memory-efficient and highly parallelizable. The two images to be compared are broken down into non-overlapping blocks of 200 × 200 pixels and the relative shift between each corresponding pair of blocks is computed using phase correlation. Any minor rotation, scaling, or shear between the full input images is then accounted for through a compensating affine transformation computed via multiple linear regression on the full set of per-block shift vectors. This phase correlation and transformation procedure yields a 200×-downsampled ‘block-dense’ flow vector field that characterizes the local registration error. It is important to note that there is no separate ground truth data in this method—it only measures the consistency of a stitching/registration algorithm against itself. Having previously established that Ashlar and MIST have equivalent stitching accuracy, we felt this approach was reasonable.</p>
      <p>We defined the local registration error as the magnitude of the flow vector field at each point. The median error was 1.94 µm for the MIST mosaics (∼3 pixels) and 0.119 µm (∼0.2 pixels) for the corresponding ASHLAR mosaics (<xref rid="btac544-F5" ref-type="fig">Fig. 5b</xref>). At a magnification sufficient to see individual cells, the error generated by MIST was readily apparent (<xref rid="btac544-F5" ref-type="fig">Fig. 5c</xref>). Visualizing the full vector field on top of the reference channel images (<xref rid="btac544-F5" ref-type="fig">Fig. 5d</xref>) showed that the field direction was often consistent across large regions but could change dramatically at tile boundaries. This most likely arises because small local stitching differences propagate across the mosaic in a manner that is uncorrelated between cycles, leading to inter-cycle shifts that cannot be corrected by any rigid adjustment of the entire mosaic. It is important to note that this is not a weakness of MIST <italic toggle="yes">per se</italic>, but rather a consequence of applying a tool designed for stitching alone to the combined process of stitching and registration, a use case for which MIST was not designed. With the ASHLAR-generated mosaic, vector field visualizations confirmed a much lower level of registration error (<xref rid="btac544-F5" ref-type="fig">Fig. 5e and f</xref>). Close inspection of the few regions with high error showed that they corresponded to parts of the tissue in which cells had become physically distorted or detached from the slide as a consequence of the cyclic staining procedure. Thus, the remaining errors are not a result of errors in registration and stitching but rather extrinsic processes that must be identified and accounted for by downstream error-checking procedures.</p>
      <p>To demonstrate ASHLAR’s robustness and versatility with different image types, we compared its registration accuracy against MIST on four further datasets encompassing two cyclic imaging techniques, three vendors’ microscopes, and two new tissue types plus a TMA that itself spans a multitude of tissue types and disease states. We also evaluated one additional open-source stitching algorithm, BigStitcher (<xref rid="btac544-B19" ref-type="bibr">Hörl <italic toggle="yes">et al.</italic>, 2019</xref>), on some of these datasets. The datasets are described in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref> and the evaluation results are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figures S1–S5</xref>. Overall, ASHLAR compared favorably to MIST and BigStitcher on all datasets with respect to registration of cyclic datasets.</p>
    </sec>
    <sec>
      <title>3.5 Evaluation of commercial stitching algorithms</title>
      <p>Slide scanning microscopes include stitching algorithms as part of their data acquisition and analysis software. These algorithms use proprietary file types and in most cases, they erase the original image tiles or strips after generating the final stitched output image. Thus, the detailed evaluation of their performance is not straightforward, but it is possible to evaluate their stitching consistency by using our optical flow method to examine two re-scans of the same specimen. We performed such an analysis using a human colorectal adenocarcinoma specimen retrieved from the archives of the Department of Pathology at Brigham and Women’s Hospital with Institutional Review Board (IRB) approval as part of a discarded/excess tissue protocol. The specimen was stained with H&amp;E and scanned in brightfield mode at the Brigham and Women’s Hospital Pathology Core Facility using three different slide scanning microscopes: a Leica Aperio GT450, Leica Aperio VERSA and Hamamatsu NanoZoomer 2.0-HT. We also imaged the adenocarcinoma specimen in brightfield mode using a GE INCell 6000 microscope to produce tiles suitable for processing with ASHLAR. The specimen was imaged twice on each instrument to emulate a cyclic imaging workflow. Pre-stitched mosaic image pairs generated by the three scanners and the ASHLAR-stitched mosaic pair assembled from the INCell 6000 tiles were subjected to the registration accuracy evaluation described above. The results, shown in <xref rid="btac544-F6" ref-type="fig">Figure 6</xref>, demonstrate that all of the tested systems exhibit worse stitching consistency than ASHLAR. Inspection of the underlying images reveals obvious stitching errors that would confound single-cell level analysis. We also observed that the error field images also contained ‘signatures’ of each instrument’s internal design, such as line sensor vs. area sensor and sensor size and orientation. Thus, commercial algorithms included with existing slide scanners do not appear to fully correct for intrinsic limitations of the instrumentation. Finally, we evaluated the registration accuracy of the stitching feature in Zeiss’s Zen software which was recently used to generate a publicly available 50-plex rat brain dataset (<xref rid="btac544-B28" ref-type="bibr">Maric <italic toggle="yes">et al.</italic>, 2021</xref>) based on cyclic fluorescence imaging on a Zeiss Axio Imager Z2 microscope. We compared the DNA channel images from two imaging cycles from this dataset with our evaluation framework and found conspicuous errors here as well (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S6</xref>). Thus, while commercial algorithms may stitch well enough for visual review and gross structural analysis, they have weaknesses that are very likely to impact single-cell quantification—especially with cyclic imaging methods.</p>
      <fig position="float" id="btac544-F6">
        <label>Fig. 6.</label>
        <caption>
          <p>Comparison of registration accuracy between ASHLAR and software included with various commercial slide scanners. All images and data in this figure derive from a single section of a human colorectal adenocarcinoma biopsy (see text for details). (<bold>a</bold>) Local registration error distance distributions for technical replicate slide scans on three dedicated slide scanning microscopes as well as an ASHLAR mosaic from a research-grade microscope. All scans used the same H&amp;E-stained section of a human colon adenocarcinoma biopsy to allow direct comparison of results. Distances in this panel as well as panels (<bold>c</bold>–<bold>f</bold>) were clipped to 1.5 µm at the upper end to highlight the relevant data. (<bold>b</bold>) H&amp;E staining of the sample used for this analysis. (c) Heatmap of ASHLAR local registration error direction (hue) and magnitude (intensity) at 200-pixel resolution overlaid on the blue channel of the brightfield image, inverted (bright becomes dark and vice versa). (d–f) Heatmap of the three slide scanners’ local registration error, as in panel (c). Engineering details of the different instruments are readily apparent in the error field patterns</p>
        </caption>
        <graphic xlink:href="btac544f6" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.6 Runtime and memory usage</title>
      <p>The runtime and RAM usage for the stitching and registration phases of ASHLAR are each comparable to that of MIST stitching running on a single CPU core. On the first two cycles of the human colon dataset, ASHLAR required 306 s (149 s to stitch cycle 1 and 157 s to register cycle 2) and 2.1 GB RAM. MIST-FFTW required 228 s (114 s per cycle) and 2.5 GB RAM to compute corrected tile positions. If we include the 30 s per cycle required to convert the datasets from the microscope vendor’s native file format into MIST’s required single-TIFF format (ASHLAR requires no such conversion step) the total for MIST is 288 s. MIST does execute more quickly when allowed to use multiple CPU cores or a GPU; we have not enabled parallel processing in ASHLAR but expect a similar increase in speed. ASHLAR’s runtime per imaging cycle varies linearly with the total number of pixels in all tiles of the reference channel (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S7</xref>). All measurements were taken on a 3.5 GHz Intel Xeon E5-1620 v3 CPU with 32 GB of RAM and an SK Hynix SH920 512 GB SSD running Ubuntu Linux 20.04. Software versions were as follows: ASHLAR 1.14.0, MIST 2.0.7, Python 3.8.10 and OpenJDK 1.8.0.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>To date, ASHLAR has been used to stitch several hundred whole-slide images collected using diverse acquisition technologies and instruments (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). ASHLAR, therefore, provides a robust and efficient way to generate large, multi-channel, mosaic images of tissues and other biological specimens by assembling individual megapixel image tiles collected at multiple wavelengths over multiple imaging cycles. The key innovation for image quality is joint optimization of stitching and registration as opposed to stitching individual cycles independently and then attempting to register mosaic images against each other. Joint optimization becomes increasingly important as the size of the specimen increases. Coupling ASHLAR with tile-based image acquisition and cyclic data collection makes it possible to optimally balance the resolution, size and plex of a tissue image for reliable analysis of spatial features on a wide variety of scales. Although many recent highly multiplexed studies have relied on small fields of view and TMAs, whole-slide imaging is emerging not only as a diagnostic necessity (<xref rid="btac544-B5" ref-type="bibr">Center for Devices and Radiological Health, 2015</xref>) but also as a key requirement for basic research into the spatial organization of tissue and tumor microenvironments (<xref rid="btac544-B27" ref-type="bibr">Lin <italic toggle="yes">et al.</italic>, 2021</xref>). ASHLAR is optimized for these data acquisition requirements and is more rapid and accurate than existing open-source methods we have tested as well as commercial software available with many slide scanners. ASHLAR reads and writes files in the OME-TIFF standard and can process images from almost all commercial microscopes using the OME Bio-Formats library (<xref rid="btac544-B25" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2016</xref>). This greatly streamlines the stitching and registration process since little manual intervention is required. Once an optimized whole-slide image mosaic has been generated, it is often convenient to visualize or analyze limited regions of the image. ASHLAR, therefore, supports re-tiling using adjustable block sizes and overlaps while retaining subpixel registration and without losing any information along the original tile seams (<xref rid="btac544-F2" ref-type="fig">Fig. 2c</xref>). This block-based processing is critical for downstream image processing such as single-cell quantification and pixel-level machine learning, as few methods can process gigapixel-scale images in a single pass.</p>
    <p>ASHLAR was designed as a general-purpose algorithm compatible with a wide variety of microscopes and image acquisition technologies. To establish that ASHLAR meets these requirements, we incorporated it into MCMICRO (<xref rid="btac544-B33" ref-type="bibr">Schapiro <italic toggle="yes">et al.</italic>, 2022a</xref>), a data processing pipeline leveraging either Docker or Singularity containers (<xref rid="btac544-B22" ref-type="bibr">Kurtzer <italic toggle="yes">et al.</italic>, 2017</xref>; Merkel, <xref rid="btac544-B29" ref-type="bibr">2014</xref>) and implemented it in the workflow systems Nextflow (<xref rid="btac544-B9" ref-type="bibr">Di Tommaso <italic toggle="yes">et al.</italic>, 2017</xref>) and Galaxy (<xref rid="btac544-B1" ref-type="bibr">Afgan <italic toggle="yes">et al.</italic>, 2018</xref>). MCMICRO makes it possible to process high-plex tissue images of raw data into a table of computed single-cell features; stitching and registration by ASHLAR is an essential early step in the MCMICRO pipeline. Via MCMICRO, ASHLAR has been made available to multiple research teams in the NCI HTAN consortium (<xref rid="btac544-B32" ref-type="bibr">Rozenblatt-Rosen <italic toggle="yes">et al.</italic>, 2020</xref>) and, to date, has been used successfully in 17 published manuscripts and three posted pre-prints by investigators at seven different institutions. These papers encompass a total of ∼240 whole-slide images and 11 TMAs that have been successfully stitched using data obtained with three data acquisition methods [CyCIF, CODEX and mIHC (<xref rid="btac544-B11" ref-type="bibr">Gerdes <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btac544-B14" ref-type="bibr">Goltsev et al., 2018</xref>; <xref rid="btac544-B26" ref-type="bibr">Lin <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btac544-B39" ref-type="bibr">Tsujikawa <italic toggle="yes">et al.</italic>, 2017</xref>)] and on five different types of microscopes (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). This experience demonstrates that ASHLAR operates as designed with most image data, but some edge cases may require tuning the algorithm’s parameters. This is most commonly encountered when tile overlaps are too small or the tissue has suffered grievous damage during processing. The online documentation for ASHLAR (available at <ext-link xlink:href="https://labsyspharm.github.io/ashlar/" ext-link-type="uri">https://labsyspharm.github.io/ashlar/</ext-link>) discusses these and related issues in greater detail. ASHLAR is available under the permissive MIT open-source software license, making it possible for commercial companies to modify and package it with their instruments.</p>
    <p>ASHLAR is effective not only with conventional rectangular image acquisition grids but also with images involving multiple non-overlapping regions of interest and tiles that do not form a rectangular grid. The ability to manage irregular and disconnected specimens has emerged as a key requirement in the broader application of tissue imaging. By instructing a microscope to avoid imaging empty space lying outside of the margins of the tissue, imaging time and file size can be reduced, often by a factor of two or more (a significant advantage as datasets approach terabyte scale). We have successfully used ASHLAR to assemble images of TMAs, in which 0.3–1 mm diameter ‘cores’ from multiple tissue specimens are positioned in a regular array on a glass slide, making it possible to analyze over 100 specimens in parallel. This represents a potentially challenging stitching problem since much of the slide is devoid of sample, and individual cores are often divided among multiple fields. Core biopsies and fine needle aspirations are other samples in which the collection of non-rectangular images is highly advantageous. Such biopsies are typically long and thin (0.3 × 10–20 mm) and rarely aligned along the axis of the slide, making it necessary to collect tiles on a diagonal. The ability of ASHLAR to reject spurious alignments using a permutation test followed by pruning of adjacency graphs make the algorithm robust to regions of the images such as these that contain little if any data in the registration channel.</p>
    <p>Much of the recent discussion about multiplexed tissue imaging has focused on the importance of the number of channels (assay plex) (<xref rid="btac544-B3" ref-type="bibr">Baharlou <italic toggle="yes">et al.</italic>, 2019</xref>), since more channels allow more proteins or genes to be assayed and yield more detailed molecular insights. However, two other considerations are at least as important: image resolution and field of view (speed also matters for high-volume applications). In the case of fluorescent imaging of a single tile, resolution and field of view are functions of the optics, primarily the numerical aperture of the objective lens, the properties of the transfer optics and the number of camera pixels—which together specify pixel size (<xref rid="btac544-B12" ref-type="bibr">Ghiran, 2011</xref>). For large whole-slide images assembled from many tiles, the accuracy of image stitching and registration also becomes critical. ASHLAR directly addresses this requirement. In most applications, it is also combined with other software to optimize the quality of image mosaics. Prior to stitching and registering tiles using ASHLAR we perform illumination correction using BaSiC (<xref rid="btac544-B30" ref-type="bibr">Peng <italic toggle="yes">et al.</italic>, 2017</xref>), which exploits low-rank and sparse decomposition to correct for uneven shading and background variation in microscope images. This is essential because the illumination of each tile is typically brightest at the center of the field (along the optical axis) and dimmer at the edges.</p>
    <sec>
      <title>4.1 Limitations</title>
      <p>We have found that the spanning tree approach used to combine individual pairwise tile alignments is broadly effective. However, one recurrent weakness observed with large specimens is that tiles at the margin of the tissue that are adjacent in physical space are often found to lie far apart in the adjacency graph. When corrected positions are determined, uncorrelated error accumulates as pairwise shifts are added up along the edges in the spanning tree. The resulting stitching error is rarely noticeable by eye in the resultant mosaic image, but we have identified this as an area for future improvement of the algorithm.</p>
      <p>To achieve reasonable processing speed, ASHLAR makes some compromises with respect to the factors it accounts for during stitching and registration. For example, ASHLAR currently performs only rectilinear correction of tile position and assumes tiles have the same magnification. When images from different microscopes must be combined it is usually necessary to account for changes in camera angle due to the rotation of individual cameras and their microscope stages relative to each other. Scaling is also frequently different across instruments, even when the same objective is used, due to differences in transfer optics and sensor configurations. We have never encountered the need to assemble an image from multiple microscopes (partly because many other batch effects are introduced) but corrections for image rotation and scaling can be performed through minor additions to the alignment procedure (<xref rid="btac544-B15" ref-type="bibr">Gonzalez, 2011</xref>); we will add these features to ASHLAR as the need arises, most likely arising from a requirement to combine multiple different imaging modalities.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btac544_Supplementary_Data</label>
      <media xlink:href="btac544_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We thank Jerry Lin, Zoltan Maliga, Connor Jacobson, Artem Sokolov and other members of the Laboratory of Systems Pharmacology for their assistance. The normal colon specimen used for this work was acquired from the Cooperative Human Tumor Network (<ext-link xlink:href="https://www.chtn.org/" ext-link-type="uri">https://www.chtn.org/</ext-link>). We thank the members of the HTAN Consortium for their support; a full list can be found at <ext-link xlink:href="http://www.humantumoratlas.org" ext-link-type="uri">humantumoratlas.org</ext-link>.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by the National Institutes of Health [U2C-CA233262 and U2C-CA233280]; the Ludwig Cancer Center; and the Bill and Melinda Gates Foundation [INV-027106].</p>
      <p><italic toggle="yes">Conflict of Interest</italic>: P.K.S. is a member of the scientific advisory board or board of directors of Glencoe Software (which supports a commercial version of the OME software), Applied Biomath and RareCyte Inc. (which built some of the microscopes used in this study) and has equity in these companies; he is on the Scientific Advisory Board of NanoString Inc. and a consultant to Montai Health and Merck. In the last 5 years, the P.K.S. lab has received research funding from Novartis and Merck. P.K.S. declares that none of these relationships altered the conduct or reporting of this research. The other authors report no outside activities.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btac544-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Afgan</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>The galaxy platform for accessible, reproducible and collaborative biomedical analyses: 2018 update</article-title>. <source>Nucleic Acids Res</source>., <volume>46</volume>, <fpage>W537</fpage>–<lpage>W544</lpage>.<pub-id pub-id-type="pmid">29790989</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Angelo</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Multiplexed ion beam imaging of human breast tumors</article-title>. <source>Nat. Med</source>., <volume>20</volume>, <fpage>436</fpage>–<lpage>442</lpage>.<pub-id pub-id-type="pmid">24584119</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baharlou</surname><given-names>H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Mass cytometry imaging for the study of human diseases—applications and data analysis strategies</article-title>. <source>Front. Immunol</source>., <volume>10</volume>, <fpage>2657</fpage>.<pub-id pub-id-type="pmid">31798587</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Burger</surname><given-names>M.L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Antigen dominance hierarchies shape TCF1+ progenitor CD8 T cell phenotypes in tumors</article-title>. <source>Cell</source>, <volume>184</volume>, <fpage>4996</fpage>–<lpage>5014.e26</lpage>.<pub-id pub-id-type="pmid">34534464</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B5">
      <mixed-citation publication-type="book"><collab>Center for Devices and Radiological Health</collab>. (<year>2015</year>) <source>Technical Performance Assessment of Digital Pathology Whole Slide Imaging Devices</source>. <publisher-name>US Food and Drug Administration. FDA-2015-D-0230</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btac544-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chalfoun</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>MIST: accurate and scalable microscopy image stitching tool with stage modeling and error minimization</article-title>. <source>Sci. Rep</source>., <volume>7</volume>, <fpage>4988</fpage>.<pub-id pub-id-type="pmid">28694478</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>K.H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>RNA imaging. Spatially resolved, highly multiplexed RNA profiling in single cells</article-title>. <source>Science</source>, <volume>348</volume>, <fpage>aaa6090</fpage>.<pub-id pub-id-type="pmid">25858977</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dean</surname><given-names>R.T.</given-names></string-name>, <string-name><surname>Dunsmuir</surname><given-names>W.T.M.</given-names></string-name></person-group> (<year>2016</year>) <article-title>Dangers and uses of cross-correlation in analyzing time series in perception, performance, movement, and neuroscience: the importance of constructing transfer function autoregressive models</article-title>. <source>Behav. Res. Methods</source>, <volume>48</volume>, <fpage>783</fpage>–<lpage>802</lpage>.<pub-id pub-id-type="pmid">26100765</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Di Tommaso</surname><given-names>P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Nextflow enables reproducible computational workflows</article-title>. <source>Nat. Biotechnol</source>., <volume>35</volume>, <fpage>316</fpage>–<lpage>319</lpage>.<pub-id pub-id-type="pmid">28398311</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Färkkilä</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Immunogenomic profiling determines responses to combined PARP and PD-1 inhibition in ovarian cancer</article-title>. <source>Nat. Commun</source>., <volume>11</volume>, <fpage>1459</fpage>.<pub-id pub-id-type="pmid">32193378</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gerdes</surname><given-names>M.J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) <article-title>Highly multiplexed single-cell analysis of formalin-fixed, paraffin-embedded cancer tissue</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>110</volume>, <fpage>11982</fpage>–<lpage>11987</lpage>.<pub-id pub-id-type="pmid">23818604</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ghiran</surname><given-names>I.C.</given-names></string-name></person-group> (<year>2011</year>) <article-title>Introduction to fluorescence microscopy</article-title>. <source>Methods Mol. Biol</source>., <volume>689</volume>, <fpage>93</fpage>–<lpage>136</lpage>.<pub-id pub-id-type="pmid">21153789</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Giesen</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Highly multiplexed imaging of tumor tissues with subcellular resolution by mass cytometry</article-title>. <source>Nat. Methods</source>, <volume>11</volume>, <fpage>417</fpage>–<lpage>422</lpage>.<pub-id pub-id-type="pmid">24584193</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goltsev</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Deep profiling of mouse splenic architecture with CODEX multiplexed imaging</article-title>. <source>Cell</source>, <volume>174</volume>, <fpage>968</fpage>–<lpage>981.e15</lpage>.<pub-id pub-id-type="pmid">30078711</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B15">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Gonzalez</surname><given-names>R.</given-names></string-name></person-group> (<year>2011</year>) <source>Improving Phase Correlation for Image Registration</source>. In: <italic toggle="yes">Proceedings of Image and Vision Computing New Zealand 2011</italic>. <publisher-name>University of Auckland</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btac544-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guizar-Sicairos</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2008</year>) <article-title>Efficient subpixel image registration algorithms</article-title>. <source>Opt. Lett</source>., <volume>33</volume>, <fpage>156</fpage>–<lpage>158</lpage>.<pub-id pub-id-type="pmid">18197224</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gut</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Multiplexed protein maps link subcellular organization to cellular states</article-title>. <source>Science</source>, <volume>361</volume>, <fpage>eaar7042</fpage>.<pub-id pub-id-type="pmid">30072512</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holtkamp</surname><given-names>D.J.</given-names></string-name>, <string-name><surname>Goshtasby</surname><given-names>A.A.</given-names></string-name></person-group> (<year>2009</year>) <article-title>Precision registration and mosaicking of multicamera images</article-title>. <source>IEEE Trans. Geosci. Remote Sensing</source>, <volume>47</volume>, <fpage>3446</fpage>–<lpage>3455</lpage>.</mixed-citation>
    </ref>
    <ref id="btac544-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hörl</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>BigStitcher: reconstructing high-resolution image datasets of cleared and expanded samples</article-title>. <source>Nat. Methods</source>, <volume>16</volume>, <fpage>870</fpage>–<lpage>874</lpage>.<pub-id pub-id-type="pmid">31384047</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B20">
      <mixed-citation publication-type="journal"><collab>HuBMAP Consortium</collab>. (<year>2019</year>) <article-title>The human body at cellular resolution: the NIH human biomolecular atlas program</article-title>. <source>Nature</source>, <volume>574</volume>, <fpage>187</fpage>–<lpage>192</lpage>.<pub-id pub-id-type="pmid">31597973</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kuglin</surname><given-names>C.D.</given-names></string-name>, <string-name><surname>Hines</surname><given-names>D.C.</given-names></string-name></person-group> (<year>1975</year>) <article-title>The phase correlation image alignment method</article-title>. <source>Proc. IEEE Int. Conf. Cybern. Soc</source>., <fpage>163</fpage>–<lpage>165</lpage>.</mixed-citation>
    </ref>
    <ref id="btac544-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kurtzer</surname><given-names>G.M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Singularity: scientific containers for mobility of compute</article-title>. <source>PLoS One</source>, <volume>12</volume>, <fpage>e0177459</fpage>.<pub-id pub-id-type="pmid">28494014</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Launonen</surname><given-names>I.-M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2022</year>) <article-title>Single-cell tumor-immune microenvironment of BRCA1/2 mutated high-grade serous ovarian cancer</article-title>. <source>Nat. Commun</source>., <volume>13</volume>, <fpage>835</fpage>.<pub-id pub-id-type="pmid">35149709</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>J.H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Highly multiplexed subcellular RNA sequencing <italic toggle="yes">in situ</italic></article-title>. <source>Science</source>, <volume>343</volume>, <fpage>1360</fpage>–<lpage>1363</lpage>.<pub-id pub-id-type="pmid">24578530</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Metadata management for high content screening in OMERO</article-title>. <source>Methods</source>, <volume>96</volume>, <fpage>27</fpage>–<lpage>32</lpage>.<pub-id pub-id-type="pmid">26476368</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>J.-R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Highly multiplexed immunofluorescence imaging of human tissues and tumors using t-CyCIF and conventional optical microscopes</article-title>. <source>eLife</source>, <volume>7</volume>, <fpage>e31657</fpage>.<pub-id pub-id-type="pmid">29993362</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B27">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lin</surname><given-names>J.-R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) Multiplexed 3D atlas of state transitions and immune interactions in colorectal cancer. https://doi.org/10.1101/2021.03.31.437984.</mixed-citation>
    </ref>
    <ref id="btac544-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maric</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>Whole-brain tissue mapping toolkit using large-scale highly multiplexed immunofluorescence imaging and deep neural networks</article-title>. <source>Nat. Commun</source>., <volume>12</volume>, <fpage>1550</fpage>.<pub-id pub-id-type="pmid">33692351</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Merkel</surname><given-names>D.</given-names></string-name></person-group> (<year>2014</year>) <article-title>Docker: lightweight Linux containers for consistent development and deployment</article-title>. <source>Linux J</source>., <volume>2</volume>.</mixed-citation>
    </ref>
    <ref id="btac544-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peng</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>A BaSiC tool for background and shading correction of optical microscopy images</article-title>. <source>Nat. Commun</source>., <volume>8</volume>, <fpage>14836</fpage>.<pub-id pub-id-type="pmid">28594001</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Regev</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal>; <collab>Human Cell Atlas Meeting Participants</collab>. (<year>2017</year>) <article-title>The human cell atlas</article-title>. <source>eLife</source>, <volume>6</volume>, <fpage>e27041</fpage>.<pub-id pub-id-type="pmid">29206104</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rozenblatt-Rosen</surname><given-names>O.</given-names></string-name></person-group>  <etal>et al</etal>; <collab>Human Tumor Atlas Network</collab>. (<year>2020</year>) <article-title>The human tumor atlas network: charting tumor transitions across space and time at Single-Cell resolution</article-title>. <source>Cell</source>, <volume>181</volume>, <fpage>236</fpage>–<lpage>249</lpage>.<pub-id pub-id-type="pmid">32302568</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schapiro</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2022a</year>) <article-title>MCMICRO: a scalable, modular image-processing pipeline for multiplexed tissue imaging</article-title>. <source>Nat. Methods</source>, <volume>19</volume>, <fpage>311</fpage>–<lpage>315</lpage>.<pub-id pub-id-type="pmid">34824477</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schapiro</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal>; <collab>Human Tumor Atlas Network</collab>. (<year>2022b</year>) <article-title>MITI minimum information guidelines for highly multiplexed tissue images</article-title>. <source>Nat. Methods</source>, <volume>19</volume>, <fpage>262</fpage>–<lpage>267</lpage>.<pub-id pub-id-type="pmid">35277708</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schneider</surname><given-names>C.A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) <article-title>NIH image to ImageJ: 25 years of image analysis</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>671</fpage>–<lpage>675</lpage>.<pub-id pub-id-type="pmid">22930834</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schürch</surname><given-names>C.M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>Coordinated cellular neighborhoods orchestrate antitumoral immunity at the colorectal cancer invasive front</article-title>. <source>Cell</source>, <volume>182</volume>, <fpage>1341</fpage>–<lpage>1359.e19</lpage>.<pub-id pub-id-type="pmid">32763154</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ståhl</surname><given-names>P.L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Visualization and analysis of gene expression in tissue sections by spatial transcriptomics</article-title>. <source>Science</source>, <volume>353</volume>, <fpage>78</fpage>–<lpage>82</lpage>.<pub-id pub-id-type="pmid">27365449</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tryka</surname><given-names>K.A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>NCBI’s database of genotypes and phenotypes: dbGaP</article-title>. <source>Nucleic Acids Res</source>., <volume>42</volume>, <fpage>D975</fpage>–<lpage>D979</lpage>. [PMC][10.1093/nar/gkt1211] [24297256][Mismatch<pub-id pub-id-type="pmid">24297256</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tsujikawa</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Quantitative multiplex immunohistochemistry reveals myeloid-inflamed tumor-immune complexity associated with poor prognosis</article-title>. <source>Cell Rep</source>., <volume>19</volume>, <fpage>203</fpage>–<lpage>217</lpage>.<pub-id pub-id-type="pmid">28380359</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wagner</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>A single-cell atlas of the tumor and immune ecosystem of human breast cancer</article-title>. <source>Cell</source>, <volume>177</volume>, <fpage>1330</fpage>–<lpage>1345.e18</lpage>.<pub-id pub-id-type="pmid">30982598</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wick</surname><given-names>M.R.</given-names></string-name></person-group> (<year>2012</year>) <article-title>Histochemistry as a tool in morphological analysis: a historical review</article-title>. <source>Ann. Diagn. Pathol</source>., <volume>16</volume>, <fpage>71</fpage>–<lpage>78</lpage>.<pub-id pub-id-type="pmid">22261397</pub-id></mixed-citation>
    </ref>
    <ref id="btac544-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yule</surname><given-names>G.U.</given-names></string-name></person-group> (<year>1926</year>) <article-title>Why do we sometimes get nonsense-correlations between time-series?—a study in sampling and the nature of Time-Series</article-title>. <source>J. R. Stat. Soc</source>., <volume>89</volume>, <fpage>1</fpage>.</mixed-citation>
    </ref>
    <ref id="btac544-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zukić</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>ITKMontage: a software module for image stitching</article-title>. <source>Integr. Mater. Manuf. Innov</source>., <volume>10</volume>, <fpage>115</fpage>–<lpage>124</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
