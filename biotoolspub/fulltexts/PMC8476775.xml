<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_MCPRO100140 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEgr5 jpg ?>
<?FILEgr6 jpg ?>
<?FILEfx1 jpg ?>
<?FILEfigs1 jpg ?>
<?FILEfigs2 jpg ?>
<?FILEmmc1 xlsx ?>
<?FILEmmc2 xlsx ?>
<?FILEmmc3 docx ?>
<?FILEsi1 svg ?>
<?FILEsi2 svg ?>
<?FILEsi3 svg ?>
<?FILEsi4 svg ?>
<?FILEsi5 svg ?>
<?FILEsi6 svg ?>
<?FILEsi7 svg ?>
<?FILEsi8 svg ?>
<?FILEsi9 svg ?>
<?FILEsi10 svg ?>
<?FILEsi11 svg ?>
<?FILEsi12 svg ?>
<?FILEsi13 svg ?>
<?FILEsi14 svg ?>
<?FILEsi16 svg ?>
<?FILEsi17 svg ?>
<?FILEsi18 svg ?>
<?FILEsi20 svg ?>
<?FILEsi21 svg ?>
<?FILEsi22 svg ?>
<?FILEsi23 svg ?>
<?FILEsi24 svg ?>
<?FILEsi25 svg ?>
<?FILEsi26 svg ?>
<?FILEsi27 svg ?>
<?FILEsi28 svg ?>
<?FILEsi29 svg ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Mol Cell Proteomics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Mol Cell Proteomics</journal-id>
    <journal-title-group>
      <journal-title>Molecular &amp; Cellular Proteomics : MCP</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1535-9476</issn>
    <issn pub-type="epub">1535-9484</issn>
    <publisher>
      <publisher-name>American Society for Biochemistry and Molecular Biology</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8476775</article-id>
    <article-id pub-id-type="pii">S1535-9476(21)00112-2</article-id>
    <article-id pub-id-type="doi">10.1016/j.mcpro.2021.100140</article-id>
    <article-id pub-id-type="publisher-id">100140</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DeepHistoClass: A Novel Strategy for Confident Classification of Immunohistochemistry Images Using Deep Learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au1">
        <name>
          <surname>Ghoshal</surname>
          <given-names>Biraja</given-names>
        </name>
        <email>biraja.ghoshal@brunel.ac.uk</email>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="cor1" ref-type="corresp">∗</xref>
      </contrib>
      <contrib contrib-type="author" id="au2">
        <name>
          <surname>Hikmet</surname>
          <given-names>Feria</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author" id="au3">
        <name>
          <surname>Pineau</surname>
          <given-names>Charles</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">3</xref>
        <xref rid="aff4" ref-type="aff">4</xref>
      </contrib>
      <contrib contrib-type="author" id="au4">
        <name>
          <surname>Tucker</surname>
          <given-names>Allan</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author" id="au5">
        <name>
          <surname>Lindskog</surname>
          <given-names>Cecilia</given-names>
        </name>
        <email>cecilia.lindskog@igp.uu.se</email>
        <xref rid="aff2" ref-type="aff">2</xref>
        <xref rid="cor1" ref-type="corresp">∗</xref>
      </contrib>
      <aff id="aff1"><label>1</label>Department of Computer Science, Brunel University London, Uxbridge, United Kingdom</aff>
      <aff id="aff2"><label>2</label>Rudbeck Laboratory, Department of Immunology, Genetics and Pathology, Uppsala University, Uppsala, Sweden</aff>
      <aff id="aff3"><label>3</label>Inserm, EHESP, Irset (Institut de recherche en santé, environnement et travail), UMR_S 1085, Univ Rennes, Rennes Cedex, France</aff>
      <aff id="aff4"><label>4</label>Protim, Univ Rennes, Rennes Cedex, France</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>∗</label>For correspondence: Biraja Ghoshal; Cecilia Lindskog <email>biraja.ghoshal@brunel.ac.uk</email><email>cecilia.lindskog@igp.uu.se</email></corresp>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>21</day>
      <month>8</month>
      <year>2021</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>21</day>
      <month>8</month>
      <year>2021</year>
    </pub-date>
    <volume>20</volume>
    <elocation-id>100140</elocation-id>
    <history>
      <date date-type="received">
        <day>8</day>
        <month>4</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>13</day>
        <month>8</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2021 The Authors</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="abs0010">
      <p>A multitude of efforts worldwide aim to create a single-cell reference map of the human body, for fundamental understanding of human health, molecular medicine, and targeted treatment. Antibody-based proteomics using immunohistochemistry (IHC) has proven to be an excellent technology for integration with large-scale single-cell transcriptomics datasets. The golden standard for evaluation of IHC staining patterns is manual annotation, which is expensive and may lead to subjective errors. Artificial intelligence holds much promise for efficient and accurate pattern recognition, but confidence in prediction needs to be addressed. Here, the aim was to present a reliable and comprehensive framework for automated annotation of IHC images. We developed a multilabel classification of 7848 complex IHC images of human testis corresponding to 2794 unique proteins, generated as part of the Human Protein Atlas (HPA) project. Manual annotation data for eight different cell types was generated as a basis for training and testing a proposed Hybrid Bayesian Neural Network. By combining the deep learning model with a novel uncertainty metric, DeepHistoClass (DHC) Confidence Score, the average diagnostic performance improved from 86.9% to 96.3%. This metric not only reveals which images are reliably classified by the model, but can also be utilized for identification of manual annotation errors. The proposed streamlined workflow can be developed further for other tissue types in health and disease and has important implications for digital pathology initiatives or large-scale protein mapping efforts such as the HPA project.</p>
    </abstract>
    <abstract abstract-type="graphical" id="abs0015">
      <title>Graphical Abstract</title>
      <fig id="undfig1" position="anchor">
        <graphic xlink:href="fx1"/>
      </fig>
    </abstract>
    <abstract abstract-type="author-highlights" id="abs0020">
      <title>Highlights</title>
      <p>
        <list list-type="simple" id="ulist0010">
          <list-item id="u0010">
            <label>•</label>
            <p id="p0010">A novel method for automated annotation of immunohistochemistry images.</p>
          </list-item>
          <list-item id="u0015">
            <label>•</label>
            <p id="p0015">Introduction of an uncertainty metric, the DeepHistoClass (DHC) confidence score.</p>
          </list-item>
          <list-item id="u0020">
            <label>•</label>
            <p id="p0020">Increased accuracy of automated image predictions.</p>
          </list-item>
          <list-item id="u0025">
            <label>•</label>
            <p id="p0025">Identification of manual annotation errors.</p>
          </list-item>
        </list>
      </p>
    </abstract>
    <abstract abstract-type="teaser" id="abs0025">
      <title>In Brief</title>
      <p>A novel method for automated annotation of immunohistochemistry images, combining the predictions with an uncertainty metric, the DeepHistoClass (DHC) confidence score. This metric not only reveals which images are reliably classified by the model, but can also be utilized for identification of manual annotation errors. The proposed streamlined workflow can be developed further for other tissue types in health and disease and has important implications for digital pathology initiatives or large-scale protein mapping efforts such as the HPA project.</p>
    </abstract>
    <kwd-group id="kwrds0010">
      <title>Keywords</title>
      <kwd>testis</kwd>
      <kwd>immunohistochemistry</kwd>
      <kwd>artificial intelligence</kwd>
      <kwd>machine learning</kwd>
      <kwd>histology</kwd>
    </kwd-group>
    <kwd-group id="kwrds0015">
      <title>Abbreviations</title>
      <kwd>AI, artificial intelligence</kwd>
      <kwd>AUC, area under the curve</kwd>
      <kwd>BNN, Bayesian neural network</kwd>
      <kwd>CNN, convolutional neural network</kwd>
      <kwd>CPPD, class predictive probability distance</kwd>
      <kwd>DHC, DeepHistoClass</kwd>
      <kwd>DNN, deep neural network</kwd>
      <kwd>FFPE, formalin-fixed, paraffin-embedded</kwd>
      <kwd>HBNet, hybrid Bayesian neural network</kwd>
      <kwd>HOG, histogram of oriented gradient</kwd>
      <kwd>HPA, Human Protein Atlas</kwd>
      <kwd>IHC, immunohistochemistry</kwd>
      <kwd>mAP, mean-average precision</kwd>
      <kwd>MC, Monte Carlo</kwd>
      <kwd>MCC, Matthews correlation coefficient</kwd>
      <kwd>MCMC, Markov chain MC</kwd>
      <kwd>ROC, receiver operating characteristic</kwd>
      <kwd>RT, room temperature</kwd>
      <kwd>TMA, tissue microarray</kwd>
      <kwd>VGG, Visual Geometry Group</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <p id="p0030">Human physiology depends on complex processes built on intercellular interactions and cell-type-specific functions unique to each tissue and organ. To fully understand the underlying mechanisms of disease, it is necessary to study tissue architecture and molecular constituents with a single-cell resolution. In the field of transcriptomics, dramatic improvements have been made in the single-cell RNA-seq (scRNA-seq) technology, which is a powerful approach due to its excellence in studying mRNAs in smaller subsets of cells that would fall below detection limits when mixed with other cell types in complex tissues samples (<xref rid="bib1" ref-type="bibr">1</xref>). One major initiative taking advantage of this new technology is the Human Cell Atlas consortium (<ext-link ext-link-type="uri" xlink:href="http://www.humancellatlas.org" id="intref0010">www.humancellatlas.org</ext-link>). While transcriptomics has the advantage of quantitative measurements and low abundance detection, it is important to note that validation at the protein level is necessary to understand the role in health and disease, as proteomics constitutes the functional representation of the genome. This has recently been shown for expression of the SARS-CoV-2 receptor ACE2, where low abundant measurements based on transcriptomics do not fully reveal the exact localization in tissues unless complemented with proteomics approaches (<xref rid="bib2" ref-type="bibr">2</xref>).</p>
  <p id="p0035">The standard method for visualizing proteins with a single-cell resolution is antibody-based proteomics and immunohistochemistry (IHC), which allows for studying the protein localization in histologically intact tissue samples. This not only allows for determining the localization in different compartments at a tissue, cellular, and subcellular level, but also provides important information in the context of neighboring cells. IHC thus constitutes an excellent method for direct validation of cell-type-specific expression patterns identified by scRNA-seq. The largest initiative for mapping the human proteome using IHC is the Human Protein Atlas (HPA) project (<xref rid="bib3" ref-type="bibr">3</xref>, <xref rid="bib4" ref-type="bibr">4</xref>, <xref rid="bib5" ref-type="bibr">5</xref>, <xref rid="bib6" ref-type="bibr">6</xref>, <xref rid="bib7" ref-type="bibr">7</xref>), covering all major normal tissues and organs, as well as the most common forms of cancer. The open-access database visualizes the expression of &gt;80% of all human proteins in &gt;10 million high-resolution images, constituting an excellent resource for comparison of cell-type-specific expression patterns identified with large-scale transcriptomics approaches, which has recently been shown in the new Single Cell Type Atlas <ext-link ext-link-type="uri" xlink:href="http://www.proteinatlas.org/humanproteome/celltype" id="intref0015">www.proteinatlas.org/humanproteome/celltype</ext-link> (<xref rid="bib8" ref-type="bibr">8</xref>).</p>
  <p id="p0040">Despite the IHC technology having been used for decades and is a standard method in clinical pathology, the main approach for evaluation of IHC staining patterns is still a rather subjective manual assessment. A manual observer has the advantage of identifying technical staining errors or artifacts, but it is both time-consuming and costly. Additionally, manual annotation is error-prone and poorly reproducible, as it may lead to fatigue or mislabeling of images due to lack of experience in detecting the correct cell types or structures or technological challenges related to staining intensity or identification of small objects. Manual annotation is commonly faced with two types of errors, i) false negatives where true positive staining is missed or neglected, and ii) false positives where lack of protein expression is falsely interpreted as positive. Histological samples consist of a mixture of different cell types that can be challenging to distinguish even by a trained eye, and setting a manual threshold of what is regarded as negative/positive is tedious and highly difficult. This leads to challenges in large-scale approaches aiming at aligning IHC datasets with data generated by other quantitative methods, such as scRNA-seq.</p>
  <p id="p0045">To increase accuracy and speed up the process of manual interpretation, the application of Artificial Intelligence (AI) in the evaluation of medical images has received increased attention both in research and diagnostics (<xref rid="bib9" ref-type="bibr">9</xref>, <xref rid="bib10" ref-type="bibr">10</xref>, <xref rid="bib11" ref-type="bibr">11</xref>, <xref rid="bib12" ref-type="bibr">12</xref>, <xref rid="bib13" ref-type="bibr">13</xref>). AI-driven and deep learning approaches hold much promise for efficient and accurate pattern recognition of histological images, and there have been several efforts based on IHC images. Most of these previous studies using IHC in machine learning however focused on a smaller number of markers, often well-known biomarkers. These markers were either used to train the algorithm recognizing and measuring the presence of certain cell types within the tissues (<xref rid="bib14" ref-type="bibr">14</xref>) or to quantify the number of cells positive for a certain marker (<xref rid="bib15" ref-type="bibr">15</xref>). No previous study has addressed the challenge presented here, training an AI model that distinguishes the cell-type-specific protein expression pattern in human IHC samples, applicable to stainings from any type of protein (<xref rid="bib16" ref-type="bibr">16</xref>, <xref rid="bib17" ref-type="bibr">17</xref>).</p>
  <p id="p0050">One of the challenges when implementing AI models for automated annotation of IHC is that IHC images typically consist of a complex mixture of multiple cell types of various shapes and sizes that can express a protein in different combinations. Additionally, a protein may not only be expressed in certain cell types, but could also be localized to different subcellular compartments, <italic>e.g.</italic>, cytoplasm or nucleus, or be expressed at different levels. As a result, training an algorithm to distinguish cell-type-specific localization of proteins based on IHC is a multilabel task. Since each class is not mutually exclusive, both the manual observer and the trained model must consider every possible label separately. Different approaches to address multilabel classification problems have been developed previously (<xref rid="bib18" ref-type="bibr">18</xref>), but none of these have been applied to IHC images. Another challenge is correctly addressing the accuracy of automated predictions, which is especially important when implementing algorithms in a clinical setting, but also in whole-proteome approaches such as the HPA project to be able to compare results between different proteins at a global, proteome-wide level. Addressing prediction accuracy requires a large dataset of manually annotated images, but also a method to score the confidence in the prediction. Few existing large-scale imaging datasets are labeled in detail at a cell-type-specific level, and methods for addressing prediction accuracy are not currently considered by many state-of-the-art algorithms. Bayesian neural networks (BNNs) learn a distribution with a prior distribution on its weights and are currently considered state-of-the-art for estimating uncertainty in model prediction, thereby constituting an important element when building automated workflows for annotation of histological images, which was shown in a recent pilot study (<xref rid="bib19" ref-type="bibr">19</xref>).</p>
  <p id="p0055">In the present investigation, the aim was to present a reliable and comprehensive framework for automated annotation of IHC images that addresses prediction accuracy and that can be used for large-scale approaches. As a model system, we focused on one particular organ—the testis—due to its complex histological features with as many as eight different cell types that can be distinguished by the human eye. These cell stages involved in spermatogenesis and sperm maturation require activation and suppression of thousands of genes and proteins, out of which a large proportion has an unknown function (<xref rid="bib20" ref-type="bibr">20</xref>, <xref rid="bib21" ref-type="bibr">21</xref>, <xref rid="bib22" ref-type="bibr">22</xref>, <xref rid="bib23" ref-type="bibr">23</xref>, <xref rid="bib24" ref-type="bibr">24</xref>). As a basis, we included a large set of 7848 human testis histology images, corresponding to IHC stainings of 2794 different proteins, generated as part of the HPA project. The previous standard HPA annotation in two different testicular cell types for these images was replaced by a new manual in-depth characterization in eight different cell types, which formed the basis for model training in the present investigation. Our automated framework was not only built for recognizing IHC staining patterns at a cell-type-specific level in each of these eight cell types, but also addresses uncertainty with a novel metric—DeepHistoClass (DHC) Confidence Score. The DHC Score is cell-type-specific and combines uncertainty with the predictive label probability, thereby revealing which images are reliably classified by the model, but also has the possibility to identify manual annotation errors.</p>
  <p id="p0060">The proposed streamlined workflow for automated annotation of IHC images constitutes an excellent method for large-scale approaches that currently rely on manual annotation. The method has the ability to discard highly uncertain predictions, highlight which images that need to be checked manually, and can identify unfamiliar patterns or manual errors corresponding to outliers in the data distribution. The method has important implications for large-scale protein mapping efforts such as the HPA project or other digital pathology initiatives, to both save time and lead to higher accuracy in exploration of cell-type-specific protein expression patterns in health and disease.</p>
  <sec id="sec1">
    <title>Experimental Procedures</title>
    <sec id="sec1.1">
      <title>Tissues and Protein Profiling</title>
      <p id="p0065">Human tissue samples for IHC analysis in the HPA dataset were collected and handled in accordance with Swedish laws and regulations. Tissues were obtained from the Clinical Pathology department, Uppsala University Hospital, Sweden, and collected within the Uppsala Biobank organization. All samples were anonymized for personal identity by following the approval and advisory report from the Uppsala Ethical Review Board (Ref # 2002-577, 2005-388, 2007-159). Informed consent was obtained from all subjects in the study, and the procedures follow the Declaration of Helsinki. Generation of tissue microarrays (TMAs), IHC staining, and digitization of stained TMA slides were performed essentially as previously described (<xref rid="bib25" ref-type="bibr">25</xref>). In brief, formalin-fixed, paraffin-embedded (FFPE) tissue blocks were assembled into TMAs based on 1 mm cores from 44 different normal tissue types corresponding to three individuals per tissue, including normal testis samples from adult individuals. TMA blocks were cut in 4 μm sections, dried overnight at room temperature (RT), and baked at 50 °C for at least 12 h. Automated IHC was performed by using Lab Vision Autostainer 480S Module (Thermo Fisher Scientific), as described in detail previously. The stained slides were digitized with ScanScope AT2 (Leica Aperio) using a 20× objective. All digital images corresponding to antibody data that passed HPA quality criteria were made publicly available on <ext-link ext-link-type="uri" xlink:href="http://www.proteinatlas.org" id="intref0020">www.proteinatlas.org</ext-link>.</p>
      <p id="p0070">An independent image dataset corresponding to 58 different large sections of clinical samples of human testis was acquired from Institut National de la Santé et de la Recherche Médicale (INSERM) in Rennes, France. Samples were collected over &gt;5 years either from patients undergoing therapeutic orchiectomy for metastatic prostate carcinoma, or from HIV-1-negative cadavers at autopsy at Rennes University Hospital. The protocol for orchiectomy was approved by the Ethical Committee of Rennes, France (authorization n°DC-2010− 1155, June 15, 2011), and written informed consent was obtained from all donors. IHC stainings corresponded to 31 different proteins using HPA antibodies. All stained sections were digitized with a Hamamatsu slide scanner using a 20× objective. Each of the digital images was cropped into multiple images of 3000 × 3000 pixels, to equal the size of the TMA cores in the HPA dataset, and thereby comprising 1218 images used as an independent dataset.</p>
    </sec>
    <sec id="sec1.2">
      <title>Experimental Design and Statistical Rationale</title>
      <p id="p0075">We used a BNN-based approach to detect cell-type-specific protein expression from multilabel IHC images. High-resolution digital images of IHC stained testis TMA cores corresponding to 512 testis elevated proteins (<xref rid="bib24" ref-type="bibr">24</xref>), publicly available on the HPA version 18 (<ext-link ext-link-type="uri" xlink:href="http://v18.proteinatlas.org" id="intref0025">v18.proteinatlas.org</ext-link>), were downloaded along with images from 2282 proteins published in version 19 (<ext-link ext-link-type="uri" xlink:href="http://v19.proteinatlas.org" id="intref0030">v19.proteinatlas.org</ext-link>) that previously had been manually annotated as showing IHC staining of moderate intensity in at least a subset of cells in testis. All proteins were analyzed with at least one antibody that was approved according to HPA criteria for antibody validation. For most of the proteins, three different images were available, and the total dataset comprised 7848 images corresponding to 2794 unique human proteins. Each antibody staining was manually reannotated in eight different testicular cell types, including five germ cell types (spermatogonia, preleptotene spermatocytes, pachytene spermatocytes, round/early spermatids, and elongated/late spermatids), and three somatic cell types (Sertoli cells, Leydig cells. and peritubular cells). The annotation considered staining intensity (negative, weak, moderate, strong) and subcellular localization (cytoplasmic, nuclear, membranous, or a combination of those). The entire dataset was divided into three sets: a training set of 5411 images, a validation set of 1063 images, and a test set of 1374 images. The three sets represent how the entire dataset was divided into work batches as part of the manual annotation workflow, where the validation set corresponding to 1063 images was the original dataset published previously (<xref rid="bib24" ref-type="bibr">24</xref>). This dataset was manually annotated by one observer and then quality controller by two observers including an expert in testis histology, thereby most likely representing a dataset with little risk of manual errors. The training set, which constituted the largest dataset of 5411 images, was manually annotated by one observer, but not yet quality controlled. Finally, the test set of 1374 images was manually annotated by one observer and quality controlled by one more junior independent observer, but this may not be sufficient to identify all manual errors.</p>
      <p id="p0080">The independent dataset of 1218 images acquired from another laboratory was manually annotated by one observer based on staining intensity and subcellular localization, in the same manner as the training set.</p>
    </sec>
    <sec id="sec1.3">
      <title>The Hybrid Bayesian Neural Network (HBNet)</title>
      <p id="p0085">For decades, hand-crafted image features such as Histogram of Oriented Gradients (HOG) (<xref rid="bib26" ref-type="bibr">26</xref>), Haralick (<xref rid="bib27" ref-type="bibr">27</xref>), and HU Moments (<xref rid="bib28" ref-type="bibr">28</xref>) have been widely used in computer vision. The extracted handcrafted features reflect the limited aspects of the problem, yielding low model accuracy and performance depending on the characteristics of the images. Recently we have witnessed a breakthrough in Convolutional Neural Networks (CNN) for image classification and localization tasks. CNNs automatically learn features from high-dimensional images. However, it is difficult to describe what features are learned due to the limited interpretability of CNNs. There is little research on combining CNN features with hand-crafted features for classification tasks. It has been demonstrated that handcrafted features help to provide complementary information for CNNs (<xref rid="bib29" ref-type="bibr">29</xref>, <xref rid="bib30" ref-type="bibr">30</xref>). We propose a Hybrid Bayesian Neural Network (HBNet) method that uses a combination of CNN features (<xref rid="bib31" ref-type="bibr">31</xref>, <xref rid="bib32" ref-type="bibr">32</xref>) and handcrafted features extracted from the all images to provide not only its predicted cell-type-specific protein expression levels, but also a measure of uncertainty estimated using variational Drop Weights to calculate our DHC Score.</p>
      <p id="p0090">In this study, we constructed our HBNet, for extracting deep image features, based on a very deep CNN architecture called VGG Net-19 network. VGGNet was proposed by the Visual Geometry Group (VGG) from the University of Oxford. VGGNet-16 beats the GoogLeNet and obtains an 8.8% error rate. The output of the last convolution layer is the CNN feature. We kept the main characteristics of the VGG Net-19 architecture and connected handcrafted features to the end of the CNN feature as input to the fully connected layers. Handcrafted features were extracted separately from the CNN. These handcraft features mainly reflect color, shape, and texture features of the image as complementary to the CNN features. Drop Weights regularization allowed us to apply variational inference during test time to achieve improved performance. We applied Drop Weights followed by a sigmoid activated layer to the network in the fully connected layer as an approximation to the Gaussian Process (GP), to cast it as approximate Bayesian inference for the meaningful estimation of model uncertainty.</p>
      <p id="p0095">The original JPEG images of 3000 × 3000 pixels were resized to 1024 × 1024 pixels using a bicubic interpolation over a 4 × 4 pixel neighborhood. The handcrafted approaches used were HOG (<xref rid="bib26" ref-type="bibr">26</xref>), Haralick (<xref rid="bib27" ref-type="bibr">27</xref>), and HU Moments (<xref rid="bib28" ref-type="bibr">28</xref>). HOG was applied to all images equally, with eight orientation bins, 8 × 8 pixels forming a single cell, and those cells organized in 8 × 8 formation to form a block. This feature vector containing the image descriptions is the input into the feature selection and classification algorithm. A hybrid feature vector increases the dimensionality of image features. Thus, we used the subspace method to reduce the dimensionality of the hybrid feature vector using PCA to classify and estimate uncertainty in classification. We therefore extracted a 3732-component feature vector by using the HU, Haralick, HOG method post PCA, and a 256-component feature vector using the CNN method.</p>
    </sec>
    <sec id="sec1.4">
      <title>Model Training</title>
      <p id="p0100">It should be noted that there are many methods to increase the complexity of the neural network architecture, such as different activation and loss functions, hyperparameter optimization, regularization, spatial and channel information, number of hidden layers of architecture, and multipath information processing, likely to increase overfitting and in turn not necessarily guarantee improvement in accuracy. Finding an optimal neural network architecture, which can be found by trial and error, is therefore an active research area.</p>
      <p id="p0105">During the training process, we used “he_uniform” as the default kernel initializer and the Adam optimizer with AMSGrad = True. The base learning rate was 0.000001 and decreased with the number of iterations. The minibatch size was 32 for 250 epochs and the weight decay factor was 0.2 for the reliability of binary cross-entropy loss decreasing. Overfitting was reduced by using Drop Weights with a rate of 0.3, which means that during both training and inference, approximately one-third of all weights were turned off and set to 0. After training, the output of the last convolution layer was the learned CNN feature. We combined the three handcrafted features (HU, Haralick, HOG) with the CNN features and trained only the fully connected layers and the sigmoid layer. A training dataset (5411 images) and a validation dataset (1063 images) were used for model evaluation. We monitored the validation accuracy after every epoch and saved the model with the best accuracy on the validation dataset. All nonlinearities were ReLU except for the sigmoid output layer. The models were trained and evaluated using Keras with a Tensorflow backend.</p>
      <p id="p0110">During test time (1374 images), Drop Weights were active and Monte Carlo (MC) sampling was performed by feeding the input image with 1000 MC samples through the HBNet. This in turn allowed us to apply variational Drop Weights during testing (<xref rid="bib19" ref-type="bibr">19</xref>). For every tested image, the model provided not only its predicted class but also a measure of uncertainty estimated using variational Drop Weights (see DHC Confidence Score below). In multilabel classification, a misclassification is no longer necessarily right or wrong, since a correct prediction, containing a subset of the actual labels, is considered better than a prediction containing none of them. We have observed that the use of class weighting during model fitting degrades the performance. In this multilabel detection task, there were many labels that could be present—therefore, we did not want to penalize other classes in favor of only one being present to address class imbalance. The cell type labels in multilabel datasets may be correlated and a prediction for a cell type is not mutually exclusive. Therefore, we utilized label correlation information during classification. For the cost function for multilabel classification, we selected the sigmoid function with the addition of binary cross-entropy. A grid search scheme was adopted based on Matthews Correlation Coefficients (MCC) to determine the optimal thresholds for each dimension on the model outcome, which improves the accuracy of the model. This metric is commonly used to assess multilabel classifiers and can naturally handle asymmetry and class imbalance.</p>
    </sec>
    <sec id="sec1.5">
      <title>Multilabel Cross-validation</title>
      <p id="p0115">A Multilabel Stratified Shuffle Split cross-validation merge of Multi-label Stratified KFold and Shuffle Split (<xref rid="bib33" ref-type="bibr">33</xref>) were used for returning stratified, randomized folds for multilabel data using machine learning classifiers. The folds were made by preserving the percentage of samples for each label repeated ten times in the process of tenfold cross-validation, with different randomization in each repetition.</p>
    </sec>
    <sec id="sec1.6">
      <title>Approximate Bayesian Neural Network With Drop Weights Variational Inference for Estimating Model Uncertainty</title>
      <p id="p0120">BNNs provide a natural framework for modeling uncertainty. BNN methods are however intractable in computing the posterior of a network’s parameters. The most common approach to estimate uncertainty in deep learning places distributions over each of the network’s weight parameters. There are many methods proposed for quantifying uncertainty or confidence estimates approximated by MC dropout, including Laplace approximation, Markov chain MC (MCMC) methods, stochastic gradient MCMC variants such as Langevin Dynamics, Hamiltonian methods including Multiplicative Normalizing Flows, Stochastic Batch Normalization, Maximum Softmax Probability, Heteroscedastic Classifier, and Learned Confidence Estimates including Deep Ensembles (<xref rid="bib34" ref-type="bibr">34</xref>).</p>
      <p id="p0125">Given a dataset <inline-formula><mml:math id="M1" altimg="si29.svg"><mml:mrow><mml:mi>X</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>…</mml:mo><mml:mo>.</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>x</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>
<inline-formula><mml:math id="M2" altimg="si1.svg"><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>…</mml:mo><mml:mo>.</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>y</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> and the corresponding labels <inline-formula><mml:math id="M3" altimg="si2.svg"><mml:mrow><mml:mi>Y</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="M4" altimg="si3.svg"><mml:mrow><mml:mi>X</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">∈</mml:mo><mml:mspace width="0.25em"/><mml:msup><mml:mi>R</mml:mi><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="M5" altimg="si4.svg"><mml:mrow><mml:mi>x</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">∈</mml:mo><mml:mspace width="0.25em"/><mml:msup><mml:mi>R</mml:mi><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> is a d-dimensioned input vector and <inline-formula><mml:math id="M6" altimg="si5.svg"><mml:mrow><mml:mi>Y</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">∈</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mo>…</mml:mo><mml:mo>.</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo stretchy="true">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>
<inline-formula><mml:math id="M7" altimg="si6.svg"><mml:mrow><mml:mi>y</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">∈</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mo>…</mml:mo><mml:mo>.</mml:mo><mml:mi>K</mml:mi></mml:mrow><mml:mo stretchy="true">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="M8" altimg="si7.svg"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">∈</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mo>…</mml:mo><mml:mi>K</mml:mi></mml:mrow><mml:mo stretchy="true">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>
<inline-formula><mml:math id="M9" altimg="si8.svg"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">∈</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mo>…</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo stretchy="true">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <italic>C</italic> class label, a set of independent and identically distributed (i.i.d.) training samples size <inline-formula><mml:math id="M10" altimg="si9.svg"><mml:mi>N</mml:mi><mml:mfenced open="{" close="}"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> for <inline-formula><mml:math id="M11" altimg="si10.svg"><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>1</mml:mn><mml:mspace width="0.25em"/><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mspace width="0.25em"/><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula>, the task is to find a function <inline-formula><mml:math id="M12" altimg="si11.svg"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:mi>X</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">→</mml:mo><mml:mi>Y</mml:mi><mml:mspace width="0.25em"/></mml:mrow></mml:math></inline-formula> using weights of neural net parameters <italic>w</italic> as close as possible to the original function that has generated the outputs <italic>Y</italic>. The principled predictive distribution of an unknown label <inline-formula><mml:math id="M13" altimg="si12.svg"><mml:mover><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:math></inline-formula> of a test input data <inline-formula><mml:math id="M14" altimg="si13.svg"><mml:mover><mml:mi>x</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:math></inline-formula> by marginalizing the parameters:<disp-formula id="ufd1"><mml:math id="M15" altimg="si14.svg"><mml:mspace width="0.25em"/><mml:mi>P</mml:mi><mml:mfenced><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo stretchy="true">|</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>Y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:munder><mml:mo>∫</mml:mo><mml:mi>w</mml:mi></mml:munder><mml:mi>P</mml:mi><mml:mfenced><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo stretchy="true">|</mml:mo><mml:mover><mml:mi>x</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mfenced><mml:mi>P</mml:mi><mml:mfenced><mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="true">|</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>Y</mml:mi></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi>w</mml:mi></mml:math></disp-formula></p>
      <p id="p0130">The expectation of <inline-formula><mml:math id="M16" altimg="si12.svg"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is called the predictive mean of the model, and its variance is called the predictive uncertainty.</p>
      <p id="p0135">Unfortunately, finding the posterior distribution <inline-formula><mml:math id="M17" altimg="si16.svg"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="true">|</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>Y</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is often computationally intractable. Recently, Gal (<xref rid="bib34" ref-type="bibr">34</xref>) proved that a gradient-based optimization procedure on the dropout neural network is equivalent to a specific variational approximation on an HBNet. Following Gal (<xref rid="bib34" ref-type="bibr">34</xref>), Ghoshal <italic>et al.</italic> (<xref rid="bib35" ref-type="bibr">35</xref>) also showed similar results for neural networks with MC Drop Weights (MCDW). The model uncertainty was approximated by averaging stochastic feed forward MC sampling during inference. During test time, the unseen samples were passed through the network before the Softmax predictions were analyzed. Practically, the expectation of <inline-formula><mml:math id="M18" altimg="si12.svg"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> is called the predictive mean of the model. The predictive mean <inline-formula><mml:math id="M19" altimg="si17.svg"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> over the MC iterations is then used as the final prediction on the test sample: where <inline-formula><mml:math id="M20" altimg="si18.svg"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mspace width="0.25em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo stretchy="true">|</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. For each test sample <inline-formula><mml:math id="M21" altimg="si13.svg"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>ˆ</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, the class with the largest predictive mean <inline-formula><mml:math id="M22" altimg="si17.svg"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is selected as the predictive probabilities.</p>
    </sec>
    <sec id="sec1.7">
      <title>DeepHistoClass (DHC) Confidence Score</title>
      <p id="p0140">Based on the input sample, a network can be certain with high or low confidence of its decision, indicated by the predictive posterior distribution. Traditionally, it has been difficult to implement model validation under epistemic uncertainty. Thus, we predicted that epistemic uncertainty could inform model uncertainty. One of the measures of model uncertainty is predictive entropy <italic>H</italic> of the predictive distribution:<disp-formula id="ufd2"><mml:math id="M23" altimg="si20.svg"><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo stretchy="true">|</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>Y</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>C</mml:mi></mml:msubsup><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="true">|</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>Y</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mspace width="0.25em"/><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mspace width="0.25em"/><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="true">|</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>Y</mml:mi></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>where <italic>C</italic> ranges over all class labels. In general, the range of the obtained uncertainty values is dependent on, <italic>e.g.</italic>, the dataset, network architectures, and the number of MC samples. Therefore, we normalized the estimated uncertainty to report our results and facilitate comparison across various sets and configurations. Estimation of entropy from the finite set of data suffers from a severe downward bias when the data is undersampled. Even small biases can result in significant inaccuracies when estimating entropy. We leveraged the plug-in estimate of entropy and the Jackknife resampling method to calculate bias-reduced entropy (<xref rid="bib19" ref-type="bibr">19</xref>, <xref rid="bib36" ref-type="bibr">36</xref>, <xref rid="bib37" ref-type="bibr">37</xref>, <xref rid="bib38" ref-type="bibr">38</xref>). The entropy was based on maximizing mutual information between the model posterior density function and the prediction density function, approximated as the difference between the entropy of the predictive distribution and the mean entropy of predictions across samples. Test points that maximize mutual information are points over which the model is uncertain on average, but there are model parameters that produce erroneous predictions with high confidence. This is equivalent to points with high variance in the input to the sigmoid layer (the logits). Thus, each stochastic forward pass through the model would have the highest probability assigned to a different class.</p>
      <p id="p0145">Each prediction from our trained model returned a set of labels. We calculated the DHC Score for each label. We employed the maximum class predictive probability distance (CPPD), which is the difference between the probability values of the highest and the second highest predictive probability value as a measure of a representativeness heuristic. The vector of class probabilities <inline-formula><mml:math id="M24" altimg="si21.svg"><mml:mrow><mml:mspace width="0.25em"/><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:msup><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> obtained after the <italic>t</italic> the stochastic forward pass is denoted <inline-formula><mml:math id="M25" altimg="si22.svg"><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="true">|</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="M26" altimg="si23.svg"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mspace width="0.25em"/></mml:mrow></mml:math></inline-formula> denotes the sampled parameters resulting from Drop Weights. Thus, the class probabilities of estimates are given by <inline-formula><mml:math id="M27" altimg="si24.svg"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo stretchy="true">|</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. We obtain the CPPD:<disp-formula id="ufd3"><mml:math id="M28" altimg="si28.svg"><mml:mrow><mml:mi>C</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi><mml:mi>D</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mrow><mml:mi>B</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true">|</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:mo linebreak="badbreak">−</mml:mo><mml:mspace width="0.25em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mrow><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>B</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="true">|</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>w</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p>
      <p id="p0150">The MCDW estimate of the vector of class probabilities aimed to decompose the source of uncertainty. The main idea was to select samples that were not only highly uncertain but also highly representative. Based on this strategy, we defined the DHC Score as an approximation of semiautomated sample selection as below:</p>
      <p id="p0155"><inline-formula><mml:math id="M29" altimg="si25.svg"><mml:mrow><mml:mi>D</mml:mi><mml:mi>H</mml:mi><mml:mi>C</mml:mi><mml:mspace width="0.25em"/><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mspace width="0.25em"/><mml:mfrac><mml:mrow><mml:mi>C</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi><mml:mi>D</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mi>J</mml:mi></mml:msub></mml:mfrac></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="M30" altimg="si26.svg"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo>ˆ</mml:mo></mml:mover><mml:mi>J</mml:mi></mml:msub><mml:mspace width="0.25em"/></mml:mrow></mml:math></inline-formula> is bias-corrected entropy using the Jackknife method. In practice, DHC ≈1 means that class predictive probability distance and uncertainty are relatively similar. This happens if a) the model has failed to reach a consensus (class membership difference is small) but model uncertainty is low, or b) the models have reached a consensus (class membership difference is large) but model uncertainty is high. DHC &gt; 0 means that uncertainty is much larger than class membership difference. This set of images represents uncertain predictions. DHC --&gt; ∞ means that uncertainty is much smaller than difference. This represents predictions with high confidence.</p>
      <p id="p0160">We ranked all unlabeled samples in ascending order of DHC Score. The formulation for the sample selection measure can be given as <inline-formula><mml:math id="M31" altimg="si27.svg"><mml:mrow><mml:mspace width="0.25em"/><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>H</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mspace width="0.25em"/><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mi>D</mml:mi><mml:mi>H</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo stretchy="true">}</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mo>:</mml:mo><mml:mspace width="0.25em"/><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="true">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The higher the DHC Score, the higher the information content of the corresponding sample images, which should represent certainty in predictions. The DHC Score was used along with the predictive probabilities, to identify and discard images for which specific cell types did not express a particular protein, as well as images that expressed the protein with high confidence.</p>
    </sec>
  </sec>
  <sec id="sec2">
    <title>Results</title>
    <sec id="sec2.1">
      <title>Generation of a Semiautomated Image Annotation Framework</title>
      <p id="p0165">A total of 7848 IHC stained high-resolution images of human testis available as part of the HPA project (<ext-link ext-link-type="uri" xlink:href="http://www.proteinatlas.org" id="intref0035">www.proteinatlas.org</ext-link>), corresponding to 3046 different antibody stainings and 2794 unique proteins, were divided into three different sets: a training set (5411 images), a validation set (1063 images), and a test set (1374 images). All images were annotated manually in five germ cell types (spermatogonia, preleptotene spermatocytes, pachytene spermatocytes, round/early spermatids, and elongated/late spermatids) and three somatic cell types (Sertoli cells, Leydig cells, and peritubular cells), taking into consideration staining intensity (negative, weak, moderate, strong) and subcellular localization of the staining (cytoplasm, nucleus, membrane). This novel refined scoring in eight different cell types formed the basis for a semiautomated image annotation framework, as presented in <xref rid="fig1" ref-type="fig">Figure 1</xref>.<fig id="fig1"><label>Fig. 1</label><caption><p><bold>Overview of the image annotation framework.</bold> A Hybrid Bayesian Neural Network (HBNet) model was trained taking into consideration both handcrafted features and deep learning features. The input IHC high-resolution images consisted of 1 to 3 human testis TMA punch-outs for each antibody comprising a total of 7848 images. For each antibody, eight different cell types were manually inspected with regard to staining intensity (negative, weak, moderate, strong) and subcellular location (cytoplasm, nucleus, membrane); 1: Spermatogonia; 2: Preleptotene spermatocytes; 3: Pachytene spermatocytes; 4: Round/early spermatids; 5: Elongated/late spermatids; 6: Sertoli cells; 7: Leydig cells; 8: Peritubular cells. The manual data was used as a basis for machine learning, combining handcrafted features with standard deep learning features. The mean predictive probability and bias-corrected estimated uncertainty were used for generation of DeepHistoClass (DHC) Confidence Score, which allowed for dividing the images into those that were reliably predicted by the model, and those of high uncertainty that need manual inspection.</p></caption><graphic xlink:href="gr1"/></fig></p>
    </sec>
    <sec id="sec2.2">
      <title>Cell-type-specific Expression Based on Manual Annotation</title>
      <p id="p0170">To get an overview of the protein expression pattern across the entire dataset, and determine the relationship between the eight different cell types, pairwise Kendall correlation was used to create a heatmap of the protein expression correlations and the associated clusters (<xref rid="fig2" ref-type="fig">Fig. 2</xref><italic>A</italic>).<fig id="fig2"><label>Fig. 2</label><caption><p><bold>Input image data distribution based on manual annotation.</bold><italic>A</italic>, heatmap and cluster analysis of testicular cell types. <italic>B</italic>, all 7848 images were grouped based on the number of positive cell types (or lack of positive cell types) and visualized as a waffle distribution plot, which shows that most images contain 2 to 5 positive cell types. In (<italic>C</italic>), the number of positive cell types is visualized separately by each dataset. The training set consisted of 5411 images, validation set 1063 images, and testing set 1374 images. <italic>D</italic>, the distribution of subcellular location (and lack of subcellular location due to no antibody staining) for each cell type in all 7848 images showed that Leydig cells more often showed cytoplasmic staining, while Sertoli cells and peritubular cells had the highest proportion of images that were negative/lacked protein expression in these cell types.</p></caption><graphic xlink:href="gr2"/></fig></p>
      <p id="p0175">The analysis was based on the manual annotation of staining intensity across the entire dataset of 7848 images. As expected, based on functional characteristics (<xref rid="bib24" ref-type="bibr">24</xref>), there were three main clusters: i) somatic cells (Sertoli cells, Leydig cells, and peritubular cells), ii) premeiotic cells (spermatogonia and preleptotene spermatocytes), and iii) meiotic/postmeiotic cells (pachytene spermatocytes, round/early spermatids, and elongated/late spermatids). Of the 7848 images analyzed, only 815 (10%) showed immunoreactivity in 1 cell type only, while most of the images were positive in 2 to 5 cell types (<xref rid="fig2" ref-type="fig">Fig. 2</xref><italic>B</italic>). In 35 images, the human observer had marked all cell types as negative. When separated, the three different sets showed slightly different proportions of the number of positive cell types (<xref rid="fig2" ref-type="fig">Fig. 2</xref><italic>C</italic>), where the test set consisted of more cell-type-specific images and the validation set contained a higher proportion of images with 5 to 8 cell types that had been labeled (<xref rid="fig2" ref-type="fig">Fig. 2</xref><italic>C</italic>). There were large differences in the presence of different cell type labels (<xref rid="fig2" ref-type="fig">Fig. 2</xref><italic>D</italic>), with Leydig cells being labeled in as many as 5218 (66%) of the images, while peritubular cells represented the most unusual staining pattern, positive in only 755 (10%) of the images. The staining was mostly localized to the cytoplasm, both cytoplasm and the plasma membrane, or the nucleus, but there were clear differences between cell types. Sertoli cells more often showed positivity in the plasma membrane or a combination of nucleus + membrane, in most cases referred to as the nuclear membrane. A majority of the staining observed in Leydig cells was cytoplasmic (<xref rid="fig2" ref-type="fig">Fig. 2</xref><italic>D</italic>).</p>
    </sec>
    <sec id="sec2.3">
      <title>Training of Neural Network and Overall Model Performance</title>
      <p id="p0180">The manually annotated images from the training set of 5411 images and the validation set of 1063 images were used for training a HBNet model, exploiting Drop Weights and combining the features from a standard deep neural network (DNN) with handcrafted features. The output of the neural network is an eight-dimensional probability vector, where each dimension indicates how likely each cell type in a given image expresses the protein. The neural network was then applied to the test set of 1374 images, for which the accuracy was evaluated.</p>
      <p id="p0185">Evaluation metrics for multilabel classification performances are different from those used in binary or multiclass classification (<xref rid="bib39" ref-type="bibr">39</xref>). In multilabel classification, a misclassification is no longer a definite right or wrong, since a correct prediction containing a subset of the actual labels is considered better than a prediction containing none of them. Here, four different metrics were used for evaluating the multilabel classification performance: i) Hamming loss, ii) F1-score, iii) Exact Match ratio, and iv) mean-Average Precision (mAP). <xref rid="tbl1" ref-type="table">Table 1</xref> presents the statistics for each of these metrics for the standard DNN and the proposed HBNet, as well as a host of other state-of-the-art classifiers using our hybrid features. Hamming loss is the most common evaluation metric in multilabel classification, which takes into account both prediction errors (false positives) and missed predictions (false negatives), normalized over the total number of classes and total number of samples analyzed. The smaller the value of Hamming loss (closer to 0), the better the performance of the learning algorithm. F1 score is the harmonic mean of recall and precision, where Macro F1 score calculates the metric independently for each label and then takes an average, and Micro F1 score aggregates the contributions of all labels when calculating the average metric. The Exact Match ratio is the strictest metric, indicating the percentage of all analyzed samples that have all their labels classified correctly. mAP takes into account both the average precision (AP) separately for each label and the average over the class. It provides a measure of quality across recall levels and was shown to be stable and able to distinguish between cell types. The higher the mAP (closer to 100), the better the quality. In the present investigation, there was considerable improvement using HBNet across all metrics used (<xref rid="tbl1" ref-type="table">Table 1</xref>). Based on HBNet, the Exact Match ratio showed that 67% of the 1374 images were correctly classified in all eight cell types.<table-wrap position="float" id="tbl1"><label>Table 1</label><caption><p>Overall model performance</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Metrics</th><th>Neural network (handcrafted features)</th><th>Multilabel k nearest neighbours (hybrid features)</th><th>Random forest classifier (hybrid features)</th><th>Support vector machine (hybrid features)</th><th>Hybrid features DNN (%)</th><th>Hybrid features BNN HBNet (%)</th></tr></thead><tbody><tr><td>Hamming Loss</td><td align="char">17.0</td><td align="char">13.0</td><td align="char">15.0</td><td align="char">14.0</td><td align="char">17.0</td><td align="char">13.0</td></tr><tr><td>Macro F1 Score</td><td align="char">77.0</td><td align="char">82.0</td><td align="char">77.0</td><td align="char">81.0</td><td align="char">81.0</td><td align="char">84.0</td></tr><tr><td>Micro F1 Score</td><td align="char">78.0</td><td align="char">83.0</td><td align="char">79.0</td><td align="char">81.0</td><td align="char">80.0</td><td align="char">84.0</td></tr><tr><td>Exact Match ratio</td><td align="char">41.0</td><td align="char">70.0</td><td align="char">47.0</td><td align="char">61.0</td><td align="char">48.0</td><td align="char">67.0</td></tr><tr><td>mean-Average Precision (mAP)</td><td align="char">70.0</td><td align="char">73.0</td><td align="char">69.0</td><td align="char">72.0</td><td align="char">71.0</td><td align="char">76.0</td></tr></tbody></table><table-wrap-foot><fn><p>Evaluation of classification performance for a Handcrafted features with Neural Network, CNN features Neural Network, Hybrid features Multilabel k Nearest Neighbors, Hybrid features Random Forest Classifier, Hybrid features Support Vector Machine, Hybrid features deep neural network (DNN), and the proposed Hybrid Bayesian Neural network (HBNet), based on five different metrics. The results for each metric are shown as a percent.</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="sec2.4">
      <title>Cell-type-specific Model Performance</title>
      <p id="p0190">Next, we evaluated the model’s performance on a cell-type-specific level. In <xref rid="fig3" ref-type="fig">Figure 3</xref>, a confusion matrix is shown, comparing the output of the neural network with the manual observer, summarizing the false positives and negatives of the DNN and the HBNet for each cell type. For all cell types, HBNet had a higher accuracy than DNN, with &gt;80% overall accuracy, and &gt;90% for Sertoli cells and peritubular cells. The largest difference between DNN and HBNet was seen for pachytene spermatocytes and round/early spermatids, where the accuracy improved from 75.6 to 82.6% and from 69.3 to 80.5%, respectively. HBNet dramatically reduced the number of false negatives compared with DNN, but also showed a decrease in the number of false positives. The total number of false positives (n = 444) across all cell types was lower compared with the number of false negatives (n = 993), indicating that the model performed better at accurately detecting positive labels, but more often differed with the human observer in classifying cell types as negative. This is expected, due to the human observer deliberately neglecting very weak staining patterns that can be considered unspecific or being due to artifacts. The ratios between false positives and false negatives were however opposite for Sertoli cells and peritubular cells, for which false negatives were rare. Positivity in these cell types was not only less common in general (<xref rid="fig2" ref-type="fig">Fig. 2</xref><italic>D</italic>), but also to a larger extent cell-type-specific and not as often showing simultaneous staining in other cell types (<xref rid="fig2" ref-type="fig">Fig. 2</xref><italic>A</italic>). This suggests that positivity in these cell types was mostly considered as specific by the human observer.<fig id="fig3"><label>Fig. 3</label><caption><p><bold>Confusion matrix for each of the eight testicular cell types based on standard deep neural network (DNN) and hybrid Bayesian neural network (HBNet).</bold> Each quadrant shows the number of images that were true negative (<italic>upper left</italic>), false negative (<italic>upper right</italic>), false positive (<italic>bottom left</italic>), and true positive (<italic>bottom right</italic>), color-coded based on the number of images.</p></caption><graphic xlink:href="gr3"/></fig></p>
    </sec>
    <sec id="sec2.5">
      <title>Estimation of Model Certainty</title>
      <p id="p0195">To rank all images based on model confidence over eight cell types, each prediction included an uncertainty measurement, presented as a DHC Score. <xref rid="appsec1" ref-type="sec">Supplemental Table S1</xref> shows the predictions per cell type for each of the 1374 images in the test set, along with DHC Score, predictive probability, and manual annotation. The DHC Scores ranged from 0 to 1 for each HBNet prediction over the eight cell types. All predictions were then plotted in confidence maps (<xref rid="fig4" ref-type="fig">Fig. 4</xref>), where images for which the model agreed with the human observer, <italic>i.e.</italic>, the cell type was truly positive or truly negative, were marked in green, while images with disagreement between the model and the human observer were marked in red. Images suggested to be misclassified tend to have lower DHC Scores, compared with correctly classified images. The shape of the DHC curves varies for each cell type, and the curves for Sertoli cells and peritubular cells stood out as having a higher proportion of images with low DHC Scores than the other cell types. This is because staining in these cell types was less common (<xref rid="fig2" ref-type="fig">Fig. 2</xref><italic>D</italic>), and cell types classified as lacking staining often have low DHC Scores. The spread of misclassifications determined the cutoff for reliable classification, which was marked as a blue line. Note that this cutoff was set at a DHC Score between 0.0 and 0.11 for all types except pachytene spermatocytes, round/early spermatids, and elongated/late spermatids, for which it was set at 0.22, 0.78, and 0.22, respectively. The protein expression patterns of these three cell types showed a high correlation (<xref rid="fig2" ref-type="fig">Fig. 2</xref><italic>A</italic>), suggesting that many proteins were coexpressed in these cells. Since they were not mutually exclusive, this may explain why the model would have more difficulties to distinguish these cell types from each other. Round/early spermatids are particularly challenging to distinguish manually from the transition into elongated/late spermatids. In the present investigation there were only 67 images with expression restricted to round/early spermatids, while 254 images showed expression specific to elongated/late spermatids and 212 images had expression in both of these two. This likely causes the particularly high DHC Score for round/early spermatids.<fig id="fig4"><label>Fig. 4</label><caption><p><bold>Confidence maps of all automated predictions for each of the eight cell types.</bold> Each <italic>dot</italic> corresponds to one prediction, with <italic>green</italic> = correct and <italic>red</italic> = incorrect. The predictions were sorted based on their DHC Score, showing the confidence in prediction. The <italic>blue lines</italic> depict the determined cutoff for each cell type where classification is considered too unreliable.</p></caption><graphic xlink:href="gr4"/></fig></p>
      <p id="p0200">When only considering thresholded samples above the DHC cutoff, including classifications of high reliability, the classification accuracy of the HBNet model was substantially improved and considerably higher than all other classifiers (<xref rid="tbl2" ref-type="table">Table 2</xref>). The HBNet DHC-thresholded accuracy was &gt;92% for all cell types except for round/early spermatids, which had an accuracy of 83.5%. For most cell types, approximately 30 to 39% of the images were below the DHC cutoff, except for peritubular cells where only 1.3% of the images were discarded, and Sertoli cells, where none were. Predictions above cutoff can be considered reliably annotated by the model, which means that manual annotation is only needed for on average 28.1% of the predictions. Note that there is a direct trade-off for choice of DHC threshold between accuracy and number of discarded images (<xref rid="appsec1" ref-type="sec">supplemental Fig. S1</xref>). Also note, accuracy is an orthogonal measure to uncertainty. Similar performance to HBNET may sometimes be obtained with other deterministic classification methods, particularly if they have hybrid features as input, but they do not provide the added value of confidence in their prediction, which enables the identification of images that can be automatically labeled.<table-wrap position="float" id="tbl2"><label>Table 2</label><caption><p>Model performance on a cell-type-specific level</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Cell type</th><th colspan="6">Model performance accuracy (%)<hr/></th><th>Discard tradeoff<hr/></th></tr><tr><th>Deep neural network (DNN) with only handcrafted features</th><th>Multilabel k nearest neighbours with hybrid features</th><th>Random forest classifier with hybrid features</th><th>Support vector machine with hybrid features</th><th>HBNet (std. dev. Across folds)</th><th>HBNet-DHC</th><th>HBNet—DHC percentage discarded</th></tr></thead><tbody><tr><td>Spermatogonia (0.11)</td><td align="char">85.9</td><td align="char">83.8</td><td align="char">80.2</td><td align="char">81.2</td><td align="char">85.7 (0.24)</td><td align="char">99.4</td><td align="char">37.2%</td></tr><tr><td>Preleptotene spermatocytes (0.11)</td><td align="char">74.8</td><td align="char">85.5</td><td align="char">71.9</td><td align="char">73.1</td><td align="char">84.9 (0.38)</td><td align="char">99.2</td><td align="char">37.2%</td></tr><tr><td>Pachytene spermatocytes (0.22)</td><td align="char">69.9</td><td align="char">82.4</td><td align="char">72.1</td><td align="char">73.3</td><td align="char">82.6 (0.24)</td><td align="char">99.2</td><td align="char">31.7%</td></tr><tr><td>Round/early spermatids (0.78)</td><td align="char">68.1</td><td align="char">79.0</td><td align="char">72.8</td><td align="char">74.3</td><td align="char">80.5 (0.55)</td><td align="char">83.5</td><td align="char">39.1%</td></tr><tr><td>Elongated/late spermatids (0.22)</td><td align="char">77.4</td><td align="char">79.8</td><td align="char">76.9</td><td align="char">76.7</td><td align="char">85.2 (0.36)</td><td align="char">98.7</td><td align="char">30.1%</td></tr><tr><td>Sertoli cells (1.00E-10)</td><td align="char">74.1</td><td align="char">86.3</td><td align="char">65.9</td><td align="char">57.6</td><td align="char">92.2 (0.16)</td><td align="char">92.2</td><td align="char">0.0%</td></tr><tr><td>Leydig cells (0.11)</td><td align="char">80.4</td><td align="char">81.6</td><td align="char">80.3</td><td align="char">76.2</td><td align="char">85.7 (0.34)</td><td align="char">99.2</td><td align="char">38.3%</td></tr><tr><td>Peritubular cells (1.00E-10)</td><td align="char">84.3</td><td align="char">95.9</td><td align="char">67.4</td><td align="char">67.9</td><td align="char">98.6 (0.09)</td><td align="char">98.7</td><td align="char">1.3%</td></tr></tbody></table><table-wrap-foot><fn><p>The % accuracy for predicting the labels for each cell type is shown for standard deep neural network (DNN) with only handcrafted features, three standard classification approaches including our hybrid features (K-nearest neighbors, random forest, and support vector machines), our hybrid Bayesian neural network (HBNet), and DHC-thresholded HBNet (HBNet—DHC) along with the percentage of discarded images based on low DHC confidence. The standard deviation (std dev.) between each cross-validation fold is included for HBNet to indicate sampling variance.</p></fn></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="sec2.6">
      <title>Evaluation of Correctly Classified and Misclassified Images</title>
      <p id="p0205">The DHC confidence metric allowed us to identify both correctly classified images and images where the model disagreed with the human observer for one or several cell types. In <xref rid="fig5" ref-type="fig">Figure 5</xref>, examples of correctly classified images are provided, <italic>i.e.</italic>, these images were among the 67% that according to the Exact Match Ratio had all eight cell types annotated as either true positive or true negative. The images show that the model performed well both for proteins with distinct and selective staining and for more complex images where the protein was expressed in several cell types of varying intensity and staining patterns. The IHC stained images are presented along with heatmaps (<xref rid="bib40" ref-type="bibr">40</xref>) highlighting which area of the images that the model focused on for making the labeling decision. For the correctly classified images, it is evident that the model focused on several different areas within the image, including areas where cells were intact and well represented.<fig id="fig5"><label>Fig. 5</label><caption><p><bold>Examples of correctly classified images.</bold> Heatmaps (<italic>left</italic>), IHC staining patterns (<italic>middle</italic>), with an overview of HBNet prediction and manual annotation of the eight different cell types (<italic>right</italic>). The colors of the heatmaps indicate where the HBNet model focuses on making a labeling decision from purple (no activation) through <italic>blue</italic>, <italic>green</italic>, <italic>yellow</italic>, to <italic>red</italic> (high activation). IHC images show positive staining in <italic>brown</italic> (protein expressed) and counterstaining in <italic>blue</italic> (protein not expressed). Cell type names: Spermatogonia (SPG), preleptotene spermatocytes (Prel SPC), pachytene spermatocytes (Pach SPC), round/early spermatids (RE SPT), elongated/late spermatids (EL SPT), Sertoli cells (Sertoli), Leydig cells (Leydig), and peritubular cells (Peritub.). <italic>Green dots</italic>, correct classification. Melanoma-associated antigen B18 (MAGEB18) and Synuclein beta (SNCB) showed selective expression in 1 cell type only, while Apoptosis-associated tyrosine kinase (AATK) and T cell leukemia translocation altered protein (TCTA) were expressed in several testicular cell types. MAGEB18 showed a speckled nuclear staining pattern in pachytene spermatocytes (<italic>arrows</italic>), with clearly visible nucleoli. SNCB was positive in elongated/late spermatids and sperm flagella (<italic>arrows</italic>), seen in the lumen of seminiferous ducts. AATK displayed cytoplasmic staining in pachytene spermatocytes (<italic>black arrows</italic>), round/early spermatids (<italic>white</italic>/<italic>black arrows</italic>), and Leydig cells (<italic>double-headed arrow</italic>). TCTA showed mainly cytoplasmic staining in Sertoli cells (<italic>arrows</italic>), Leydig cells (<italic>white</italic>/<italic>black arrows</italic>), and peritubular cells (<italic>double-headed arrows</italic>), accompanied with distinct positivity of nuclear membranes in Sertoli cells.</p></caption><graphic xlink:href="gr5"/></fig></p>
      <p id="p0210">Misclassified predictions included both falsely positive and falsely negative images and could be further divided into cases with high certainty (high DHC Score) and low certainty (low DHC Score). Several misclassified predictions represented clear errors made by the manual observer (<xref rid="fig6" ref-type="fig">Fig. 6</xref><italic>A</italic>). Such misclassifications often had high DHC Scores, and in these cases, the model can be used for identifying manual mistakes. Other misclassified predictions were due to unspecific staining deliberately neglected by the human observer (<xref rid="fig6" ref-type="fig">Fig. 6</xref><italic>B</italic>). Such stainings in need of further protocol optimization were often represented by false-negative predictions with high DHC Scores, indicating that the model performed a correct prediction, but based on experience, the positivity was interpreted as unspecific by the human observer. Some misclassified images corresponded to proteins expressed in small structures including nuclear membranes, nucleoli, or centrosomes (<xref rid="fig6" ref-type="fig">Fig. 6</xref><italic>C</italic>). Such staining patterns are rare and may be particularly challenging for the model to interpret due to limitations in the current pixel resolution. These predictions were often false positives with low DHC Scores. Finally, some misclassified images contained artifacts, such as damaged tissue sections, or sections that contained areas where the testicular samples were not completely healthy (<xref rid="fig6" ref-type="fig">Fig. 6</xref><italic>D</italic>). Such misclassifications, both false positives and false negatives, often had low DHC Scores, and it was evident from the model heatmaps that the labeling decisions were mostly made on areas of the images where not all cell types were clearly represented, or the image/visible cells had poor quality.<fig id="fig6"><label>Fig. 6</label><caption><p><bold>Examples of misclassified images.</bold> Heatmaps (<italic>left</italic>) and IHC staining patterns (<italic>right</italic>), exemplified by one cell type each where HBNet prediction and manual annotation disagreed. The colors of the heatmaps indicate where the HBNet model focuses on making a labeling decision from <italic>purple</italic> (no activation) through <italic>blue</italic>, <italic>green</italic>, <italic>yellow</italic>, to <italic>red</italic> (high activation). IHC images show positive staining in <italic>brown</italic> (protein expressed) and counterstaining in <italic>blue</italic> (protein not expressed). Cell type names: Spermatogonia (SPG), pachytene spermatocytes (Pach SPC), round/early spermatids (RE SPT), elongated/late spermatids (EL SPT), Sertoli cells (Sertoli), and Leydig cells (Leydig). <italic>Green dots</italic>, correct classification. <italic>Orange dots</italic>, correct classification, but can be considered incorrect based on human knowledge. <italic>Red dots</italic>, incorrect classification. <italic>A</italic>, polycomb group ring finger 3 (PCGF3) and SPANX family member D (SPANXD) represent manual errors. For PCGF3, the manual observer missed Sertoli cells that showed clear nuclear staining (<italic>arrows</italic>), while for SPANXD, Leydig cells had been annotated as positive, despite being completely negative (<italic>arrows</italic>). <italic>B</italic>, FUN14 domain containing 2 (FUNDC2) and Minichromosome maintenance complex component 6 (MCM6) showed staining neglected by the human observer. FUNDC2 displayed weak cytoplasmic positivity in spermatogonia (<italic>arrows</italic>), but due to strong staining in elongated/late spermatids (<italic>white</italic>/<italic>black arrow</italic>), the spermatogonia staining was considered unspecific. Similarly, MCM6 showed weak nuclear staining in pachytene spermatocytes and considered unspecific compared with the strongly positive preleptotene spermatocytes (<italic>white</italic>/<italic>black arrows</italic>). <italic>C</italic>, the uncharacterized protein KIAA1324 and Spectrin repeat containing nuclear envelope family member 3 (SYNE3) were stained in small structures missed by the HBNet prediction. KIAA1324 showed positivity in small perinuclear structures of round/early spermatids most likely representing centrosomes (<italic>arrows</italic>). SYNE3 was stained in nuclear membranes of Sertoli cells (<italic>arrows</italic>). <italic>D</italic>, leucine-rich repeat containing 39 (LRRC39) and Rho related BTB domain containing 2 (RHOBTB2) correspond to images of poor quality. The area for which the HBNet model focused on for prediction of LRRC39 staining only contained unhealthy seminiferous ducts without the correct cell types. Similarly, RHOBTB2 had damaged seminiferous ducts where the cells had been separated from each other and several cell types were missing.</p></caption><graphic xlink:href="gr6"/></fig></p>
    </sec>
    <sec id="sec2.7">
      <title>Model Performance Based on Subcellular Localization and Staining Intensity</title>
      <p id="p0215">The manual annotation of the cell-type-specific protein expression did not only take into consideration which cell types were positive, but also in which subcellular organelle the staining was observed. In <xref rid="tbl3" ref-type="table">Table 3</xref>, the DHC-thresholded model performance in the test dataset is presented on a subcellular level. Similarly, as in the whole dataset, (<xref rid="fig2" ref-type="fig">Fig. 2</xref><italic>D</italic>), it was clear that some organelles were more common in certain testicular cell types, which may affect the overall accuracy, but it should also be noted that the patterns of different subcellular localizations appear differently in the various cell types based on the cell shape. In total, the best accuracy was found for staining patterns where all subcellular localizations (cytoplasmic, membranous, and nuclear) were present. This is not surprising, as clear outlining of each cell structure increases the likelihood of the model identifying the correct cell types. Sertoli cells had lower accuracy of certain subcellular localizations compared with other cell types. Staining of Sertoli cells is challenging to interpret as these cells have extended cytoplasmic protrusions that occupy the interspaces between the germ cells to provide structural and functional support for their development. Thus, Sertoli cell staining may be difficult to distinguish from other cell types.<table-wrap position="float" id="tbl3"><label>Table 3</label><caption><p>Model performance based on subcellular localization</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Cell type</th><th rowspan="2">#DHC-thresholded labels/#actual labels with subcellular localization</th><th colspan="7">HBNet—DHC % accuracy (#labels)<hr/></th></tr><tr><th>Cyt</th><th>Cyt, Mem</th><th>Mem</th><th>Nucl</th><th>Nucl, Cyt</th><th>Nucl, Cyt, Mem</th><th>Nucl, Mem</th></tr></thead><tbody><tr><td>Spermatogonia</td><td align="char">518/521</td><td align="char">99.5 (204/205)</td><td align="char">97.6 (41/42)</td><td align="char">100.0 (5/5)</td><td align="char">99.5 (201/202)</td><td align="char">100.0 (40/40)</td><td align="char">100.0 (25/25)</td><td>100.0(2/2)</td></tr><tr><td>Preleptotene spermatocytes</td><td align="char">357/360</td><td align="char">100.0 (121/121)</td><td align="char">100.0 (30/30)</td><td align="char">100.0(2/2)</td><td align="char">98.17 (161/164)</td><td align="char">100.0(15/15)</td><td align="char">100.0(28/28)</td><td align="char">0</td></tr><tr><td>Pachytene spermatocytes</td><td align="char">388/391</td><td align="char">99.3 (145/146)</td><td align="char">100.0 (66/66)</td><td align="char">100.0 (4/4)</td><td align="char">98.5 (135/137)</td><td align="char">100.0 (9/9)</td><td align="char">100.0 (29/29)</td><td align="char">0</td></tr><tr><td>Round/early spermatids</td><td align="char">361/362</td><td align="char">99.2 (131/132)</td><td align="char">100.0 (57/57)</td><td>0</td><td align="char">100.0 (147/147)</td><td align="char">100.0 (10/10)</td><td align="char">100.0 (16/16)</td><td align="char">0</td></tr><tr><td>Elongated/late spermatids</td><td align="char">405/409</td><td align="char">98.2 (215/219)</td><td align="char">100.0 (83/83)</td><td>0</td><td align="char">100.0 (67/67)</td><td align="char">100.0 (22/22)</td><td align="char">100.0 (18/18)</td><td align="char">0</td></tr><tr><td>Sertoli cells</td><td align="char">225/231</td><td align="char">97.8 (87/89)</td><td align="char">100.0 (31/31)</td><td align="char">100.0 (6/6)</td><td align="char">95.2 (79/83)</td><td align="char">100.0 (1/1)</td><td align="char">100.0 (11/11)</td><td>100.0 (10/10)</td></tr><tr><td>Leydig cells</td><td align="char">466/470</td><td align="char">98.9 (277/280)</td><td align="char">100.0 (71/71)</td><td align="char">100.0 (5/5)</td><td align="char">100.0 (81/81)</td><td align="char">100.0 (25/25)</td><td align="char">100.0 (7/7)</td><td align="char">0</td></tr><tr><td>Peritubular cells</td><td align="char">105/120</td><td align="char">89.3 (50/56)</td><td align="char">100.0 (9/9)</td><td align="char">83.7 (46/55)</td><td>0</td><td>0</td><td>0</td><td align="char">0</td></tr><tr><td>Average all cell types</td><td align="char">2825/2864</td><td>97.78</td><td>99.7</td><td>97.28</td><td>98.77</td><td>100</td><td>100</td><td>100</td></tr></tbody></table></table-wrap></p>
      <p id="p0220">In addition to cell-type-specific pattern and subcellular localization of the staining, the human observer also takes into consideration the intensity of the staining. This rather subjective measurement that determines the brown saturation level is considered to represent the amount of protein expression ranging from low levels (weak staining/beige color), through moderate levels (medium brown) to high levels (dark brown/black). As seen in <xref rid="tbl4" ref-type="table">Table 4</xref>, it is evident that the DHC-thresholded accuracy did not depend on staining intensity, and there was no significant improvement in predictions performed on distinctly stained cells compared with those that showed more faint positivity.<table-wrap position="float" id="tbl4"><label>Table 4</label><caption><p>Model performance based on staining intensity</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Cell type</th><th colspan="3">HBNet—DHC % accuracy (#DHC-thresholded labels/#actual labels)<hr/></th></tr><tr><th>Only weak labels (intensity =1)</th><th>Only moderate labels (intensity = 2)</th><th>Only strong labels (intensity = 3)</th></tr></thead><tbody><tr><td>Spermatogonia</td><td align="char">100.0 (27/27)</td><td align="char">99.3 (142/143)</td><td align="char">99.4 (349/351)</td></tr><tr><td>Preleptotene spermatocytes</td><td align="char">100.0 (49/49)</td><td align="char">100.0 (150/150)</td><td align="char">98.14 (158/161)</td></tr><tr><td>Pachytene spermatocytes</td><td align="char">100.0 (70/70)</td><td align="char">99.3 (141/142)</td><td align="char">98.9 (177/179)</td></tr><tr><td>Round/early spermatids</td><td align="char">100.0 (53/53)</td><td align="char">100.0 (102/102)</td><td align="char">99.6 (206/207)</td></tr><tr><td>Elongated/late Spermatids</td><td align="char">100.0 (41/41)</td><td align="char">97.3 (145/149)</td><td align="char">100.0 (219/219)</td></tr><tr><td>Sertoli cells</td><td align="char">98.6 (72/73)</td><td align="char">86.1 (31/36)</td><td align="char">100.0 (122/122)</td></tr><tr><td>Leydig cells</td><td align="char">98.9 (172/174)</td><td align="char">99.5 (202/203)</td><td align="char">100.0 (92/92)</td></tr><tr><td>Peritubular cells</td><td align="char">100.0 (17/17)</td><td align="char">84.5 (49/58)</td><td align="char">86.7 (39/45)</td></tr><tr><td>Average all cell types</td><td>99.7</td><td>95.8</td><td>97.9</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="sec2.8">
      <title>Validation in an Independent Dataset of Clinical Samples</title>
      <p id="p0225">We also explored the use of the same models that were trained on the HPA dataset for classifying images corresponding to clinical samples from a different laboratory. <xref rid="tbl5" ref-type="table">Table 5</xref> documents the results of this independent dataset of 1218 images corresponding to 58 individual samples for the DNN and our proposed HBNet with and without using the DHC Score. The full graphs for trade-off between accuracy and retained images are presented in <xref rid="appsec1" ref-type="sec">supplemental Fig. S2</xref>, and <xref rid="appsec1" ref-type="sec">supplemental Table S2</xref> shows the predictions per cell type for each of the 1218 images in the independent dataset, along with DHC Score and manual annotation. As expected due to the small sample size and significant differences between the laboratories in tissue pretreatment, staining protocol, equipment, and digitization of images, the overall performance was lower with most cell types registering an accuracy of around 60%. When the DHC threshold from the HPA training was used, a general improvement of the accuracies (up to 92%) was observed, but at the expense of discarding a higher proportion of the images as compared with the HPA dataset. Nevertheless, the model did to some degree demonstrate generalizability to images from clinical samples generated from an independent laboratory by successfully identifying a number of images that can be automatically labeled by exploiting the DHC Score.<table-wrap position="float" id="tbl5"><label>Table 5</label><caption><p>Model performance based on independent dataset from another laboratory</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Cell types</th><th>DNN (Accuracy (%) (std dev.))</th><th>HBNet (5000 stochastic feedforward) (std dev.)</th><th>HBNet—DHC</th><th>HBNet—DHC percentage discarded</th></tr></thead><tbody><tr><td>Spermatogonia</td><td align="char">55.3 (0.78)</td><td align="char">60.4 (0.84)</td><td align="char">60.4</td><td>0%</td></tr><tr><td>Preleptotene spermatocytes</td><td align="char">61.1 (0.83)</td><td align="char">66.2 (1.66)</td><td align="char">67.6</td><td align="char">36.4%</td></tr><tr><td>Pachytene spermatocytes</td><td align="char">59.3 (5.4)</td><td align="char">55.4 (5.03)</td><td align="char">55.4</td><td>0%</td></tr><tr><td>Round/early spermatids</td><td align="char">60.5 (6.54)</td><td align="char">58.0 (6.45)</td><td align="char">58.2</td><td align="char">3.2%</td></tr><tr><td>Elongated/late spermatids</td><td align="char">61.9 (5.34)</td><td align="char">69.1 (8.79)</td><td align="char">70.1</td><td align="char">1.5%</td></tr><tr><td>Sertoli cells</td><td align="char">60.8 (3.68)</td><td align="char">65.0 (3.73)</td><td align="char">66.8</td><td align="char">77.2%</td></tr><tr><td>Leydig cells</td><td align="char">55.2 (3.31)</td><td align="char">52.1 (2.45)</td><td align="char">55.6</td><td align="char">25.6%</td></tr><tr><td>Peritubular cells</td><td align="char">68.4 (4.69)</td><td align="char">89.0 (11.79)</td><td align="char">92.7</td><td align="char">25.1%</td></tr></tbody></table></table-wrap></p>
    </sec>
  </sec>
  <sec id="sec3">
    <title>Discussion</title>
    <p id="p0230">In the evolving era of “big data”, integration of datasets from different omics technologies such as genomics, transcriptomics, and proteomics has shown increasing importance, paving the way for further understanding of the molecular processes involved in health and disease (<xref rid="bib1" ref-type="bibr">1</xref>). IHC constitutes the standard approach for spatial localization of proteins at a cell-type-specific level. The technology originates from the early 1940s (<xref rid="bib41" ref-type="bibr">41</xref>) and has emerged as a quick, simple, and cost-effective method applicable to both diagnostic routine, and basic and clinical research. The output of the IHC staining is typically a tissue section manually evaluated under a microscope, but with advances in digital pathology, large-scale digitization of stained sections is becoming more common. Furthermore, novel emerging technologies focusing on highly multiplex efforts, where many proteins are targeted simultaneously in a single tissue section, have received increased attention, further demanding machine learning approaches that can save both time and money and lead to more accurate predictions of IHC images.</p>
    <p id="p0235">Automated algorithms have been widely applied for the recognition of nuclei that can be used for segmentation of specific cells or tissue compartments, <italic>i.e.</italic>, distinguishing between epithelial and stromal cells or between benign and malignant (<xref rid="bib42" ref-type="bibr">42</xref>, <xref rid="bib43" ref-type="bibr">43</xref>, <xref rid="bib44" ref-type="bibr">44</xref>, <xref rid="bib45" ref-type="bibr">45</xref>, <xref rid="bib46" ref-type="bibr">46</xref>), detection of immune cells (<xref rid="bib47" ref-type="bibr">47</xref>, <xref rid="bib48" ref-type="bibr">48</xref>), classification or quantification of certain cell states, such as mitotic cells (<xref rid="bib49" ref-type="bibr">49</xref>), HER2 positive tumor cells in breast cancer (<xref rid="bib50" ref-type="bibr">50</xref>), or Ki67 positive proliferative cells (<xref rid="bib51" ref-type="bibr">51</xref>, <xref rid="bib52" ref-type="bibr">52</xref>, <xref rid="bib53" ref-type="bibr">53</xref>, <xref rid="bib54" ref-type="bibr">54</xref>). Until date, there are however no previous studies suggesting how such frameworks can be implemented for high-throughput annotation of complex tissue samples stained with IHC, applicable to stainings from any type of protein.</p>
    <p id="p0240">Despite impressive reported accuracy, deep learning models tend to require large training sample image sets. While this can be overcome to some degree for many image tasks by using transfer learning (<xref rid="bib46" ref-type="bibr">46</xref>), there is limited scope for this on IHC images due to the variation in protocols used to process tissue samples across different labs, though this is still a potential area for future work. Deep learning models tend to make overconfident predictions and lack the ability to report “I don’t know” for ambiguous or unknown cases. It is therefore not sufficient to depend on prediction scores alone from deep learning models, but critical to estimate bias-reduced uncertainty as an additional insight to the prediction.</p>
    <p id="p0245">The HPA database based on antibody-based proteomics constitutes the largest and most comprehensive knowledge resource for spatial localization of proteins in organs, tissues, cells, and organelles. The HPA project has characterized &gt;15,000 different proteins across &gt;40 different normal tissues and organs, and 20 types of cancer (<xref rid="bib3" ref-type="bibr">3</xref>, <xref rid="bib4" ref-type="bibr">4</xref>), with the publicly available database <ext-link ext-link-type="uri" xlink:href="http://www.proteinatlas.org" id="intref0040">www.proteinatlas.org</ext-link> containing &gt;10 million high-resolution images, thereby constituting a major resource for machine learning algorithms. In the present investigation, we focused on generating a novel in-depth annotation dataset based on images of normal testis generated as part of the HPA project, due to the complex architecture of this organ built up by several different cell types, and the unique nature of this tissue harboring a large number of proteins not expressed anywhere else in the human body (<xref rid="bib11" ref-type="bibr">11</xref>, <xref rid="bib22" ref-type="bibr">22</xref>, <xref rid="bib23" ref-type="bibr">23</xref>, <xref rid="bib55" ref-type="bibr">55</xref>). Selective pressure on most of the genes involved in spermatogenesis implies that different proteins are expressed in certain combinations of these cell types. Some proteins may be expressed in just one subset, while others are more ubiquitously expressed, and the expression of several proteins increases or decreases during differentiation, seen as a gradient in expression in cell states that undergo transformation with differences in size and shape. In addition, Sertoli cells maximize their membrane–membrane contacts with germ cells, resulting in highly entangled tissue. This results in complex IHC images that are very tedious and challenging to interpret manually.</p>
    <p id="p0250">We were careful of the potential impact of image resolution on the performance of the models. Most artificial intelligence or machine learning solutions use significantly downsampled images because of the size of neural networks, which contain millions of parameters. The size and number of images make analysis incredibly demanding, requiring vast computational power. Given the success of deep learning models in image classification, researchers have applied the downsampled techniques used in the ImageNet competitions to medical imaging. Downsampled images are much faster to train deep neural networks. Moreover, lower-resolution images may lead to less overfitting of deep learning models that focus on important high-level features. In the present investigation, a high performance was demonstrated despite using downsampled images, but we may see further improved performance by analyzing the full size images, particularly for staining patterns restricted to certain cellular or subcellular level features.</p>
    <p id="p0255">We here successfully associated deep-learning-based predictions on cell-type-specific protein expression patterns in histological testis sections stained with IHC. Quality metrics that are typically being used in binary classifications or single-label multiclassifications include area under the curve (AUC) or receiver operating characteristics (ROC). In multilabel classification, the predictions constitute a subset of actual class labels, and therefore, the prediction can be fully incorrect, partially correct, or fully correct. As a result, AUC cannot be directly calculated for multilabel classifications but separately computed for each label. Multiple ROC analyses can be carried out through aggregation, but this does not take into account class label imbalance. Here, we assessed multilabel classification using MCC, which is a common metric for analyzing such classifiers. This metric has the attractive property of managing imbalance and asymmetry.</p>
    <p id="p0260">The point predictions were combined with a Confidence Score (DHC), generated by an MC Drop Weights method in conjunction with an approximate BNN with hybrid image features. The proposed HBNet architecture showed outstanding performance in both simple images with clear cell-type-specific staining, and more complex images where several cell types showed positivity of varying intensity and staining patterns. The novel DHC Score adds another level of insight, particularly important for challenging cases where uncertain predictions can be highlighted. The model was tested on an independent dataset of IHC images corresponding to clinical samples from another laboratory, which showed lower overall accuracy. Independent datasets that are generated by different laboratories can be considered the most challenging approach for assessing if a model is fully generalizable, and despite acquiring all images that were digitally available by the other laboratory, it is a limitation that this independent dataset still only corresponded to 58 different samples. Furthermore, these images differed significantly in cell morphology, image quality, color settings during acquisition, as well as the overall brightness and contrast. It is therefore not surprising that the results differed significantly and led to a higher discard rate. Nevertheless, we could still prove the utility of our proposed workflow and achieved high accuracies when filtering the samples that can be automatically labeled based on the uncertainty metric. It should be noted that the proposed HBnet needs to be retrained on data from an individual laboratory before using it to automate labeling in a new setting, rather than trying to generalize between multiple laboratories, unless a universally accepted standardization of IHC staining workflows and digitization of images is introduced. To achieve such a standard is undoubtedly a difficult task, as even stainings generated by the same equipment and protocols may differ between laboratories due to the exact batch or brand of the reagents (<xref rid="bib56" ref-type="bibr">56</xref>). Additionally, there are several steps in the workflow that can never be controlled for, such as preprocessing and fixation of already existing archived tissue material, making standardization almost impossible. Another possibility for future projects utilizing the proposed workflow is to include images generated by multiple laboratories in the initial training of the model, which would likely improve the overall generalizability.</p>
    <p id="p0265">The unique framework for image annotation allows for dividing the dataset into images that are reliably classified by the model, and images that need to be examined by the manual observer, thereby reducing the manual burden. In addition, our proposed workflow has important implications for identifying images with manual annotation errors and thereby improving the overall accuracy. This is applicable to both research and clinical routine and may replace the otherwise common manual annotation workflow by which one observer first annotates each image, followed by quality control by a second observer, which is the current standard used by the HPA project. It may also be used for teaching purposes in the training of manual observers that have less experience, which saves both time and money as less quality control is needed from experienced personnel.</p>
    <p id="p0270">Weaknesses of an automated algorithm may be related to the fact that manual annotation is not only based on visual examination of staining intensity, but to a large extent also relies on experience, where the manual observer takes into consideration staining protocol, overall image quality, artifacts, and previous literature on the protein being analyzed. Unspecific staining may be neglected by the human observer, especially when accompanied with distinct staining in other structures that more likely represents the true protein expression. Challenges related to tissue processing, IHC staining procedure, and experience in identifying artifacts are however overcome in the presented framework, as uncertain predictions will be highlighted. Our proposed HBNet showed high accuracy for all eight cell types for samples generated by the same laboratory, with increased accuracy after applying a DHC Score threshold. When examining images above and below this threshold, it was evident that many images for which the model faced challenges constituted images expected to be particularly difficult, often due to the reasons described above. Three cell types needed a higher DHC Score threshold for reliable prediction: pachytene spermatocytes, round/early spermatids, and elongated/late spermatids. This is not surprising, as these cells correspond to the most common combination for proteins coexpressed in more than one testicular cell type, as described previously (<xref rid="bib24" ref-type="bibr">24</xref>).</p>
    <p id="p0275">Previous multilevel classification studies, including a recent Kaggle challenge (<xref rid="bib57" ref-type="bibr">57</xref>), have used immunofluorescence (IF) images of human cell lines, where antibody staining determined different subcellular localizations of the protein, related to the Subcellular Atlas of the HPA (<xref rid="bib7" ref-type="bibr">7</xref>, <xref rid="bib58" ref-type="bibr">58</xref>). While there are numerous studies focusing on machine learning and IHC, few of these studies aim at distinguishing cell-type-specific protein expression patterns using IHC, a no previous approach can be applied to any type of protein staining (<xref rid="bib16" ref-type="bibr">16</xref>, <xref rid="bib17" ref-type="bibr">17</xref>, <xref rid="bib59" ref-type="bibr">59</xref>, <xref rid="bib60" ref-type="bibr">60</xref>, <xref rid="bib61" ref-type="bibr">61</xref>). In addition to numerous research initiatives, there are several readily available commercial and open-source software supporting IHC images, such as QuPath (<xref rid="bib15" ref-type="bibr">15</xref>, <xref rid="bib62" ref-type="bibr">62</xref>), VisioPharm (<xref rid="bib63" ref-type="bibr">63</xref>, <xref rid="bib64" ref-type="bibr">64</xref>), Halo (<xref rid="bib65" ref-type="bibr">65</xref>), Aiforia (<ext-link ext-link-type="uri" xlink:href="https://www.aiforia.com/" id="intref0045">https://www.aiforia.com/</ext-link>), and Definiens (<ext-link ext-link-type="uri" xlink:href="https://oraclebio.com/" id="intref0050">https://oraclebio.com/</ext-link>). Some of these software require coding abilities, others are fully operational with custom algorithms or built-in easily trained applications by which certain structures are outlined and thresholds are set in a user-friendly interface. Tuning of the software parameters for different images and staining conditions could however be a tedious and time-consuming task in order to make such a workflow applicable to the multilevel task presented here, where each label is represented by a wide range of different staining patterns.</p>
    <p id="p0280">In the present investigation, healthy samples from one particular tissue, and undoubtedly anatomically the most complex in the human body—testis—were used. Based on the encouraging performance of our proposed model for what constitutes a particularly challenging tissue, we believe that the approach is applicable also on other simpler organs with larger structures and less variability in protein expression at the cell-type-specific level. There currently does not exist in any other cell-type-specific dataset as part of the HPA project or any other initiatives with the detailed resolution generated here, but generating more such in-depth characterizations is one of the objectives for future versions of the HPA, as an effort to directly align the protein-based data with single cell level information generated by scRNA-seq. This implies that the suggested workflow can be developed further for other organs in the future, but already now, the method can be used to cover the entire dataset of testis images corresponding to in total &gt;15,000 proteins that have been stained with IHC as part of the HPA project. The workflow can also be used in other large-scale projects focusing on distinguishing between healthy and diseased tissues, widely applicable to, <italic>e.g.</italic>, cancer research but also routine diagnostics, if retrained specifically on datasets from other laboratories. The daily pathology workflow largely depends on manual microscopic evaluation of tissue sections, which may not only lead to a delayed disease diagnosis with potential worsened patient prognosis but also to a false diagnosis (<xref rid="bib66" ref-type="bibr">66</xref>). Further advances in automated annotation of histological sections are therefore clearly warranted. Many pathology laboratories are now in the transition of starting to become fully digital, and recently the large European initiative BIGPICTURE was formed. This large-scale consortium with 70 million Euros of funding will until the year 2027 create a digital repository of 3 million slides corresponding to a wide range of disease areas. This will open up for new possibilities of linking bioimaging data to clinical parameters with the use of AI, where the proposed workflow that includes addressing of accuracy is an important method to consider.</p>
    <p id="p0285">To summarize, we present a novel method for automated annotation of IHC sections, combining the predictions with an uncertainty metric. The suggested streamlined framework constitutes an important approach for accurate large-scale efforts mapping the human proteome such as the HPA project and holds promise for both research and diagnostics aiming at analyzing the spatiotemporal expression of human proteins in health and disease.</p>
  </sec>
  <sec sec-type="data-availability" id="sec4">
    <title>Data Availability</title>
    <p id="p0290">JPEG files of all 7848 images of the HPA dataset used in the present investigation, as well as the manually annotated protein expression in eight different cell types are available on <ext-link ext-link-type="uri" xlink:href="http://v20.proteinatlas.org" id="intref0055">v20.proteinatlas.org</ext-link>. Manual errors identified as part of this study have been corrected, which means that some of the presented protein expression data on the HPA will differ from the input data used for model training. All images from the independent dataset from another laboratory have been uploaded to the BioStudies repository (<ext-link ext-link-type="uri" xlink:href="https://www.ebi.ac.uk/biostudies" id="intref0060">https://www.ebi.ac.uk/biostudies</ext-link>) under the accession S-BSST554. All codes are available in GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/birajaghoshal/DeepHistoClass" id="PC_linkEglYLqIFJi">https://github.com/birajaghoshal/DeepHistoClass</ext-link>).</p>
  </sec>
  <sec sec-type="supplementary-material" id="sec5">
    <title>Supplemental data</title>
    <p id="p0295">This article contains <xref rid="appsec1" ref-type="sec">supplemental data</xref>.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p id="p0300">The authors declare no competing interests.</p>
  </sec>
</body>
<back>
  <ref-list id="cebib0010">
    <title>References</title>
    <ref id="bib1">
      <label>1</label>
      <element-citation publication-type="journal" id="sref1">
        <person-group person-group-type="author">
          <name>
            <surname>Regev</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Teichmann</surname>
            <given-names>S.A.</given-names>
          </name>
          <name>
            <surname>Lander</surname>
            <given-names>E.S.</given-names>
          </name>
          <name>
            <surname>Amit</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Benoist</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Birney</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Bodenmiller</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Campbell</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Carninci</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Clatworthy</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Clevers</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Deplancke</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Dunham</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Eberwine</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Eils</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>The human cell atlas</article-title>
        <source>Elife</source>
        <volume>6</volume>
        <year>2017</year>
        <object-id pub-id-type="publisher-id">e27041</object-id>
      </element-citation>
    </ref>
    <ref id="bib2">
      <label>2</label>
      <element-citation publication-type="journal" id="sref2">
        <person-group person-group-type="author">
          <name>
            <surname>Hikmet</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Méar</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Edvinsson</surname>
            <given-names>Å.</given-names>
          </name>
          <name>
            <surname>Micke</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Uhlén</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Lindskog</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>The protein expression profile of ACE2 in human tissues</article-title>
        <source>Mol. Syst. Biol.</source>
        <volume>16</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">e9610</object-id>
      </element-citation>
    </ref>
    <ref id="bib3">
      <label>3</label>
      <element-citation publication-type="journal" id="sref3">
        <person-group person-group-type="author">
          <name>
            <surname>Uhlen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Fagerberg</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Hallstrom</surname>
            <given-names>B.M.</given-names>
          </name>
          <name>
            <surname>Lindskog</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Oksvold</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Mardinoglu</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sivertsson</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Kampf</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Sjostedt</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Asplund</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Olsson</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Edlund</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Lundberg</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Navani</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Szigyarto</surname>
            <given-names>C.A.</given-names>
          </name>
        </person-group>
        <article-title>Proteomics. Tissue-based map of the human proteome</article-title>
        <source>Science</source>
        <volume>347</volume>
        <year>2015</year>
        <fpage>1260419</fpage>
        <pub-id pub-id-type="pmid">25613900</pub-id>
      </element-citation>
    </ref>
    <ref id="bib4">
      <label>4</label>
      <element-citation publication-type="journal" id="sref4">
        <person-group person-group-type="author">
          <name>
            <surname>Uhlen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Sjostedt</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Fagerberg</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Bidkhori</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Benfeitas</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Arif</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Edfors</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Sanli</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>von Feilitzen</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Oksvold</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Lundberg</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Hober</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>A pathology atlas of the human cancer transcriptome</article-title>
        <source>Science</source>
        <volume>357</volume>
        <year>2017</year>
        <object-id pub-id-type="publisher-id">eaan2507</object-id>
      </element-citation>
    </ref>
    <ref id="bib5">
      <label>5</label>
      <element-citation publication-type="journal" id="sref5">
        <person-group person-group-type="author">
          <name>
            <surname>Uhlen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Karlsson</surname>
            <given-names>M.J.</given-names>
          </name>
          <name>
            <surname>Zhong</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Tebani</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Pou</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Mikes</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Lakshmikanth</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Forsstrom</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Edfors</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Odeberg</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Mardinoglu</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>von Feilitzen</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Mulder</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Sjostedt</surname>
            <given-names>E.</given-names>
          </name>
        </person-group>
        <article-title>A genome-wide transcriptomic analysis of protein-coding genes in human blood cells</article-title>
        <source>Science</source>
        <volume>366</volume>
        <year>2019</year>
        <object-id pub-id-type="publisher-id">eaax9198</object-id>
      </element-citation>
    </ref>
    <ref id="bib6">
      <label>6</label>
      <element-citation publication-type="journal" id="sref6">
        <person-group person-group-type="author">
          <name>
            <surname>Sjostedt</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Zhong</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Fagerberg</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Karlsson</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Mitsios</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Adori</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Oksvold</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Edfors</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Limiszewska</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Hikmet</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Dong</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>An atlas of the protein-coding genes in the human, pig, and mouse brain</article-title>
        <source>Science</source>
        <volume>367</volume>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">eaay5947</object-id>
      </element-citation>
    </ref>
    <ref id="bib7">
      <label>7</label>
      <element-citation publication-type="journal" id="sref7">
        <person-group person-group-type="author">
          <name>
            <surname>Thul</surname>
            <given-names>P.J.</given-names>
          </name>
          <name>
            <surname>Akesson</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Wiking</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Mahdessian</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Geladaki</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Ait Blal</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Alm</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Asplund</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Bjork</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Breckels</surname>
            <given-names>L.M.</given-names>
          </name>
          <name>
            <surname>Backstrom</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Danielsson</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Fagerberg</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Fall</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Gatto</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>A subcellular map of the human proteome</article-title>
        <source>Science</source>
        <volume>356</volume>
        <year>2017</year>
        <object-id pub-id-type="publisher-id">eaal3321</object-id>
      </element-citation>
    </ref>
    <ref id="bib8">
      <label>8</label>
      <element-citation publication-type="journal" id="optiSlbYJKyYP">
        <person-group person-group-type="author">
          <name>
            <surname>Karlsson</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Méar</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Zhong</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Digre</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Katona</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Sjöstedt</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Butler</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Odeberg</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Dusart</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Edfors</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Oksvold</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>von Feilitzen</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Zwahlen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Arif</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>A single-cell type transcriptomics map of human tissues</article-title>
        <source>Sci. Adv.</source>
        <volume>7</volume>
        <year>2021</year>
        <fpage>eabh2169</fpage>
        <pub-id pub-id-type="pmid">34321199</pub-id>
      </element-citation>
    </ref>
    <ref id="bib9">
      <label>9</label>
      <element-citation publication-type="journal" id="sref8">
        <person-group person-group-type="author">
          <name>
            <surname>Nagpal</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Foote</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>P.C.</given-names>
          </name>
          <name>
            <surname>Wulczyn</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Tan</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Olson</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>J.L.</given-names>
          </name>
          <name>
            <surname>Mohtashamian</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Wren</surname>
            <given-names>J.H.</given-names>
          </name>
          <name>
            <surname>Corrado</surname>
            <given-names>G.S.</given-names>
          </name>
          <name>
            <surname>MacDonald</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>L.H.</given-names>
          </name>
          <name>
            <surname>Amin</surname>
            <given-names>M.B.</given-names>
          </name>
          <name>
            <surname>Evans</surname>
            <given-names>A.J.</given-names>
          </name>
        </person-group>
        <article-title>Development and validation of a deep learning algorithm for improving Gleason scoring of prostate cancer</article-title>
        <source>NPJ Digit Med.</source>
        <volume>2</volume>
        <year>2019</year>
        <fpage>48</fpage>
        <pub-id pub-id-type="pmid">31304394</pub-id>
      </element-citation>
    </ref>
    <ref id="bib10">
      <label>10</label>
      <element-citation publication-type="journal" id="sref9">
        <person-group person-group-type="author">
          <name>
            <surname>Ehteshami Bejnordi</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Veta</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Johannes van Diest</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>van Ginneken</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Karssemeijer</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Litjens</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>van der Laak</surname>
            <given-names>J.</given-names>
          </name>
          <collab>the CAMELYON16 Consortium</collab>
          <name>
            <surname>Hermsen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Manson</surname>
            <given-names>Q.F.</given-names>
          </name>
          <name>
            <surname>Balkenhol</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Geessink</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Stathonikos</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>van Dijk</surname>
            <given-names>M.C.</given-names>
          </name>
          <name>
            <surname>Bult</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer</article-title>
        <source>JAMA</source>
        <volume>318</volume>
        <year>2017</year>
        <fpage>2199</fpage>
        <lpage>2210</lpage>
        <pub-id pub-id-type="pmid">29234806</pub-id>
      </element-citation>
    </ref>
    <ref id="bib11">
      <label>11</label>
      <element-citation publication-type="journal" id="sref10">
        <person-group person-group-type="author">
          <name>
            <surname>Esteva</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Kuprel</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Novoa</surname>
            <given-names>R.A.</given-names>
          </name>
          <name>
            <surname>Ko</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Swetter</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Blau</surname>
            <given-names>H.M.</given-names>
          </name>
          <name>
            <surname>Thrun</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Dermatologist-level classification of skin cancer with deep neural networks</article-title>
        <source>Nature</source>
        <volume>542</volume>
        <year>2017</year>
        <fpage>115</fpage>
        <lpage>118</lpage>
        <pub-id pub-id-type="pmid">28117445</pub-id>
      </element-citation>
    </ref>
    <ref id="bib12">
      <label>12</label>
      <element-citation publication-type="journal" id="sref11">
        <person-group person-group-type="author">
          <name>
            <surname>Gulshan</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Coram</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Stumpe</surname>
            <given-names>M.C.</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Narayanaswamy</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Venugopalan</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Widner</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Madams</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Cuadros</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Raman</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Nelson</surname>
            <given-names>P.C.</given-names>
          </name>
          <name>
            <surname>Mega</surname>
            <given-names>J.L.</given-names>
          </name>
          <name>
            <surname>Webster</surname>
            <given-names>D.R.</given-names>
          </name>
        </person-group>
        <article-title>Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs</article-title>
        <source>JAMA</source>
        <volume>316</volume>
        <year>2016</year>
        <fpage>2402</fpage>
        <lpage>2410</lpage>
        <pub-id pub-id-type="pmid">27898976</pub-id>
      </element-citation>
    </ref>
    <ref id="bib13">
      <label>13</label>
      <element-citation publication-type="journal" id="sref12">
        <person-group person-group-type="author">
          <name>
            <surname>Jackson</surname>
            <given-names>C.R.</given-names>
          </name>
          <name>
            <surname>Sriharan</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Vaickus</surname>
            <given-names>L.J.</given-names>
          </name>
        </person-group>
        <article-title>A machine learning algorithm for simulating immunohistochemistry: Development of SOX10 virtual IHC and evaluation on primarily melanocytic neoplasms</article-title>
        <source>Mod. Pathol.</source>
        <volume>33</volume>
        <year>2020</year>
        <fpage>1638</fpage>
        <lpage>1648</lpage>
        <pub-id pub-id-type="pmid">32238879</pub-id>
      </element-citation>
    </ref>
    <ref id="bib14">
      <label>14</label>
      <element-citation publication-type="journal" id="sref13">
        <person-group person-group-type="author">
          <name>
            <surname>Bulten</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Bándi</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Hoven</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>van de Loo</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Lotz</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Weiss</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>van der Laak</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>van Ginneken</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Hulsbergen-van de Kaa</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Litjens</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Epithelium segmentation using deep learning in H&amp;E-stained prostate specimens with immunohistochemistry as reference standard</article-title>
        <source>Sci. Rep.</source>
        <volume>9</volume>
        <year>2019</year>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="pmid">30626917</pub-id>
      </element-citation>
    </ref>
    <ref id="bib15">
      <label>15</label>
      <element-citation publication-type="journal" id="sref14">
        <person-group person-group-type="author">
          <name>
            <surname>Morriss</surname>
            <given-names>N.J.</given-names>
          </name>
          <name>
            <surname>Conley</surname>
            <given-names>G.M.</given-names>
          </name>
          <name>
            <surname>Ospina</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Meehan</surname>
            <given-names>W.P.</given-names>
            <suffix>III</suffix>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Mannix</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>Automated quantification of immunohistochemical staining of large animal brain tissue using QuPath software</article-title>
        <source>Neuroscience</source>
        <volume>429</volume>
        <year>2020</year>
        <fpage>235</fpage>
        <lpage>244</lpage>
        <pub-id pub-id-type="pmid">31982467</pub-id>
      </element-citation>
    </ref>
    <ref id="bib16">
      <label>16</label>
      <element-citation publication-type="journal" id="sref15">
        <person-group person-group-type="author">
          <name>
            <surname>Long</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H.B.</given-names>
          </name>
        </person-group>
        <article-title>ImPLoc: A multi-instance deep learning model for the prediction of protein subcellular localization based on immunohistochemistry images</article-title>
        <source>Bioinformatics</source>
        <volume>36</volume>
        <year>2020</year>
        <fpage>2244</fpage>
        <lpage>2250</lpage>
        <pub-id pub-id-type="pmid">31804670</pub-id>
      </element-citation>
    </ref>
    <ref id="bib17">
      <label>17</label>
      <element-citation publication-type="journal" id="sref16">
        <person-group person-group-type="author">
          <name>
            <surname>Raczkowski</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Mozejko</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Zambonelli</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Szczurek</surname>
            <given-names>E.</given-names>
          </name>
        </person-group>
        <article-title>ARA: Accurate, reliable and active histopathological image classification framework with Bayesian deep learning</article-title>
        <source>Sci. Rep.</source>
        <volume>9</volume>
        <year>2019</year>
        <fpage>14347</fpage>
        <pub-id pub-id-type="pmid">31586139</pub-id>
      </element-citation>
    </ref>
    <ref id="bib18">
      <label>18</label>
      <element-citation publication-type="journal" id="sref17">
        <person-group person-group-type="author">
          <name>
            <surname>Gonzalez-Lopez</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Ventura</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Cano</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Distributed selection of continuous features in multilabel classification using mutual information</article-title>
        <source>IEEE Trans. Neural Netw. Learn. Syst.</source>
        <volume>31</volume>
        <year>2020</year>
        <fpage>2280</fpage>
        <lpage>2293</lpage>
        <pub-id pub-id-type="pmid">31634850</pub-id>
      </element-citation>
    </ref>
    <ref id="bib19">
      <label>19</label>
      <element-citation publication-type="book" id="sref18">
        <person-group person-group-type="author">
          <name>
            <surname>Ghoshal</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Lindskog</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Tucker</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <part-title>Estimating uncertainty in deep learning for reporting confidence: An application on cell type prediction in testes based on proteomics</part-title>
        <source>International Symposium on Intelligent Data Analysis</source>
        <year>2020</year>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>Cham, Switzerland</publisher-loc>
        <fpage>223</fpage>
        <lpage>234</lpage>
      </element-citation>
    </ref>
    <ref id="bib20">
      <label>20</label>
      <element-citation publication-type="journal" id="sref19">
        <person-group person-group-type="author">
          <name>
            <surname>Djureinovic</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Fagerberg</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Hallstrom</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Danielsson</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Lindskog</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Uhlen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Ponten</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>The human testis-specific proteome defined by transcriptomics and antibody-based profiling</article-title>
        <source>Mol. Hum. Reprod.</source>
        <volume>20</volume>
        <year>2014</year>
        <fpage>476</fpage>
        <lpage>488</lpage>
        <pub-id pub-id-type="pmid">24598113</pub-id>
      </element-citation>
    </ref>
    <ref id="bib21">
      <label>21</label>
      <element-citation publication-type="journal" id="sref20">
        <person-group person-group-type="author">
          <name>
            <surname>Fagerberg</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Hallstrom</surname>
            <given-names>B.M.</given-names>
          </name>
          <name>
            <surname>Oksvold</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Kampf</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Djureinovic</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Odeberg</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Habuka</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Tahmasebpoor</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Danielsson</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Edlund</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Asplund</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sjostedt</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Lundberg</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Szigyarto</surname>
            <given-names>C.A.</given-names>
          </name>
          <name>
            <surname>Skogs</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Analysis of the human tissue-specific expression by genome-wide integration of transcriptomics and antibody-based proteomics</article-title>
        <source>Mol. Cell. Proteomics</source>
        <volume>13</volume>
        <year>2014</year>
        <fpage>397</fpage>
        <lpage>406</lpage>
      </element-citation>
    </ref>
    <ref id="bib22">
      <label>22</label>
      <element-citation publication-type="journal" id="sref21">
        <person-group person-group-type="author">
          <name>
            <surname>Jumeau</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Com</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Lane</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Duek</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Lagarrigue</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Lavigne</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Guillot</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Rondel</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Gateau</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Melaine</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Guevel</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Sergeant</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Mitchell</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Pineau</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Human spermatozoa as a model for detecting missing proteins in the context of the chromosome-centric human proteome project</article-title>
        <source>J. Proteome Res.</source>
        <volume>14</volume>
        <year>2015</year>
        <fpage>3606</fpage>
        <lpage>3620</lpage>
        <pub-id pub-id-type="pmid">26168773</pub-id>
      </element-citation>
    </ref>
    <ref id="bib23">
      <label>23</label>
      <element-citation publication-type="journal" id="sref22">
        <person-group person-group-type="author">
          <name>
            <surname>Vandenbrouck</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Lane</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Carapito</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Duek</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Rondel</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Bruley</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Macron</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Gonzalez de Peredo</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Coute</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Chaoui</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Com</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Gateau</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Hesse</surname>
            <given-names>A.M.</given-names>
          </name>
          <name>
            <surname>Marcellin</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Mear</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>Looking for missing proteins in the proteome of human spermatozoa: An update</article-title>
        <source>J. Proteome Res.</source>
        <volume>15</volume>
        <year>2016</year>
        <fpage>3998</fpage>
        <lpage>4019</lpage>
        <pub-id pub-id-type="pmid">27444420</pub-id>
      </element-citation>
    </ref>
    <ref id="bib24">
      <label>24</label>
      <element-citation publication-type="journal" id="sref23">
        <person-group person-group-type="author">
          <name>
            <surname>Pineau</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Hikmet</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Oksvold</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Fagerberg</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Uhlen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Lindskog</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Cell type-specific expression of testis elevated genes based on transcriptomics and antibody-based proteomics</article-title>
        <source>J. Proteome Res.</source>
        <volume>18</volume>
        <year>2019</year>
        <fpage>4215</fpage>
        <lpage>4230</lpage>
        <pub-id pub-id-type="pmid">31429579</pub-id>
      </element-citation>
    </ref>
    <ref id="bib25">
      <label>25</label>
      <element-citation publication-type="journal" id="sref24">
        <person-group person-group-type="author">
          <name>
            <surname>Kampf</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Olsson</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Ryberg</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Sjostedt</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Ponten</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>Production of tissue microarrays, immunohistochemistry staining and digitalization within the human protein atlas</article-title>
        <source>J. Vis. Exp.</source>
        <year>2012</year>
        <pub-id pub-id-type="doi">10.3791/3620</pub-id>
      </element-citation>
    </ref>
    <ref id="bib26">
      <label>26</label>
      <element-citation publication-type="book" id="sref25">
        <person-group person-group-type="author">
          <name>
            <surname>Dalal</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Triggs</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <part-title>Histograms of oriented gradients for human detection</part-title>
        <source>2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)</source>
        <year>2005</year>
        <publisher-name>IEEE</publisher-name>
        <publisher-loc>San Diego, CA</publisher-loc>
        <fpage>886</fpage>
        <lpage>893</lpage>
      </element-citation>
    </ref>
    <ref id="bib27">
      <label>27</label>
      <element-citation publication-type="journal" id="sref26">
        <person-group person-group-type="author">
          <name>
            <surname>Haralick</surname>
            <given-names>R.M.</given-names>
          </name>
        </person-group>
        <article-title>Statistical and structural approaches to texture</article-title>
        <source>Proc. IEEE</source>
        <volume>67</volume>
        <year>1979</year>
        <fpage>786</fpage>
        <lpage>804</lpage>
      </element-citation>
    </ref>
    <ref id="bib28">
      <label>28</label>
      <element-citation publication-type="journal" id="sref27">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>M.-K.</given-names>
          </name>
        </person-group>
        <article-title>Visual pattern recognition by moment invariants</article-title>
        <source>IRE Trans. Inf. Theory</source>
        <volume>8</volume>
        <year>1962</year>
        <fpage>179</fpage>
        <lpage>187</lpage>
      </element-citation>
    </ref>
    <ref id="bib29">
      <label>29</label>
      <element-citation publication-type="book" id="sref28">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Tai</surname>
            <given-names>Y.-W.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <part-title>Deep saliency with encoded low level distance map and high level features</part-title>
        <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source>
        <year>2016</year>
        <publisher-name>IEEE</publisher-name>
        <publisher-loc>Las Vegas, NV</publisher-loc>
        <fpage>660</fpage>
        <lpage>668</lpage>
      </element-citation>
    </ref>
    <ref id="bib30">
      <label>30</label>
      <element-citation publication-type="journal" id="sref29">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>Q.</given-names>
          </name>
        </person-group>
        <article-title>SIFT meets CNN: A decade survey of instance retrieval</article-title>
        <source>IEEE Trans. Pattern Anal. Mach. Intell.</source>
        <volume>40</volume>
        <year>2017</year>
        <fpage>1224</fpage>
        <lpage>1244</lpage>
      </element-citation>
    </ref>
    <ref id="bib31">
      <label>31</label>
      <element-citation publication-type="journal" id="sref30">
        <person-group person-group-type="author">
          <name>
            <surname>LeCun</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Deep learning</article-title>
        <source>Nature</source>
        <volume>521</volume>
        <year>2015</year>
        <fpage>436</fpage>
        <lpage>444</lpage>
        <pub-id pub-id-type="pmid">26017442</pub-id>
      </element-citation>
    </ref>
    <ref id="bib32">
      <label>32</label>
      <element-citation publication-type="journal" id="sref31">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>Dropout: A simple way to prevent neural networks from overfitting</article-title>
        <source>J. Mach. Learn. Res.</source>
        <volume>15</volume>
        <year>2014</year>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
    <ref id="bib33">
      <label>33</label>
      <element-citation publication-type="book" id="sref32">
        <person-group person-group-type="author">
          <name>
            <surname>Sechidis</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Tsoumakas</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Vlahavas</surname>
            <given-names>I.</given-names>
          </name>
        </person-group>
        <part-title>On the stratification of multi-label data</part-title>
        <source>Joint European Conference on Machine Learning and Knowledge Discovery in Databases</source>
        <year>2011</year>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>Berlin, Heidelberg</publisher-loc>
        <fpage>145</fpage>
        <lpage>158</lpage>
      </element-citation>
    </ref>
    <ref id="bib34">
      <label>34</label>
      <element-citation publication-type="book" id="sref33">
        <person-group person-group-type="author">
          <name>
            <surname>Gal</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <series>Uncertainty in Deep Learning, PhD thesis</series>
        <year>2016</year>
        <publisher-name>University of Cambridge</publisher-name>
        <publisher-loc>Cambridge</publisher-loc>
      </element-citation>
    </ref>
    <ref id="bib35">
      <label>35</label>
      <element-citation publication-type="book" id="sref34">
        <person-group person-group-type="author">
          <name>
            <surname>Ghoshal</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Tucker</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sanghera</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Wong</surname>
            <given-names>W.L.</given-names>
          </name>
        </person-group>
        <part-title>Estimating uncertainty in deep learning for reporting confidence to clinicians when segmenting nuclei image data</part-title>
        <source>2019 IEEE 32nd International Symposium on Computer-Based Medical Systems (CBMS)</source>
        <year>2019</year>
        <publisher-name>IEEE</publisher-name>
        <publisher-loc>Cordoba, Spain</publisher-loc>
        <fpage>318</fpage>
        <lpage>324</lpage>
      </element-citation>
    </ref>
    <ref id="bib36">
      <label>36</label>
      <element-citation publication-type="journal" id="sref35">
        <person-group person-group-type="author">
          <name>
            <surname>Quenouille</surname>
            <given-names>M.H.</given-names>
          </name>
        </person-group>
        <article-title>Notes on bias in estimation</article-title>
        <source>Biometrika</source>
        <volume>43</volume>
        <year>1956</year>
        <fpage>353</fpage>
        <lpage>360</lpage>
      </element-citation>
    </ref>
    <ref id="bib37">
      <label>37</label>
      <element-citation publication-type="journal" id="sref36">
        <person-group person-group-type="author">
          <name>
            <surname>Shannon</surname>
            <given-names>C.E.</given-names>
          </name>
        </person-group>
        <article-title>A mathematical theory of communication</article-title>
        <source>Bell Syst. Tech. J.</source>
        <volume>27</volume>
        <year>1948</year>
        <fpage>379</fpage>
        <lpage>423</lpage>
      </element-citation>
    </ref>
    <ref id="bib38">
      <label>38</label>
      <element-citation publication-type="journal" id="sref37">
        <person-group person-group-type="author">
          <name>
            <surname>Yeung</surname>
            <given-names>R.W.</given-names>
          </name>
        </person-group>
        <article-title>A new outlook on Shannon's information measures</article-title>
        <source>IEEE Trans. Inf. Theory</source>
        <volume>37</volume>
        <year>1991</year>
        <fpage>466</fpage>
        <lpage>474</lpage>
      </element-citation>
    </ref>
    <ref id="bib39">
      <label>39</label>
      <element-citation publication-type="book" id="sref38">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>X.-Z.</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Z.-H.</given-names>
          </name>
        </person-group>
        <part-title>A unified view of multi-label performance measures</part-title>
        <source>International Conference on Machine Learning</source>
        <year>2017</year>
        <publisher-name>ML Research Press</publisher-name>
        <publisher-loc>Sydney, NSW, Australia</publisher-loc>
        <fpage>3780</fpage>
        <lpage>3788</lpage>
      </element-citation>
    </ref>
    <ref id="bib40">
      <label>40</label>
      <element-citation publication-type="book" id="sref39">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Khosla</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Lapedriza</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Oliva</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Torralba</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <part-title>Learning deep features for discriminative localization</part-title>
        <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source>
        <year>2016</year>
        <publisher-name>IEEE</publisher-name>
        <publisher-loc>Las Vegas, NV</publisher-loc>
        <fpage>2921</fpage>
        <lpage>2929</lpage>
      </element-citation>
    </ref>
    <ref id="bib41">
      <label>41</label>
      <element-citation publication-type="journal" id="sref40">
        <person-group person-group-type="author">
          <name>
            <surname>Coons</surname>
            <given-names>A.H.</given-names>
          </name>
          <name>
            <surname>Creech</surname>
            <given-names>H.J.</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>R.N.</given-names>
          </name>
        </person-group>
        <article-title>Immunological properties of an antibody containing a fluorescent group</article-title>
        <source>Proc. Soc. Exp. Biol. Med.</source>
        <volume>47</volume>
        <year>1941</year>
        <fpage>200</fpage>
        <lpage>202</lpage>
      </element-citation>
    </ref>
    <ref id="bib42">
      <label>42</label>
      <element-citation publication-type="book" id="sref41">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Chefd’Hotel</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <part-title>Deep learning based automatic immune cell detection for immunohistochemistry images</part-title>
        <source>International Workshop on Machine Learning in Medical Imaging</source>
        <year>2014</year>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>Cham, Switzerland</publisher-loc>
        <fpage>17</fpage>
        <lpage>24</lpage>
      </element-citation>
    </ref>
    <ref id="bib43">
      <label>43</label>
      <element-citation publication-type="journal" id="sref42">
        <person-group person-group-type="author">
          <name>
            <surname>Blom</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Erickson</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Ostman</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Rannikko</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Mirtti</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Kallioniemi</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Pellinen</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>Fibroblast as a critical stromal cell type determining prognosis in prostate cancer</article-title>
        <source>Prostate</source>
        <volume>79</volume>
        <year>2019</year>
        <fpage>1505</fpage>
        <lpage>1513</lpage>
        <pub-id pub-id-type="pmid">31269283</pub-id>
      </element-citation>
    </ref>
    <ref id="bib44">
      <label>44</label>
      <element-citation publication-type="journal" id="sref43">
        <person-group person-group-type="author">
          <name>
            <surname>Stenman</surname>
            <given-names>S.E.</given-names>
          </name>
          <name>
            <surname>Bychkov</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Kucukel</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Linder</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Haglund</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Arola</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Johan</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>Antibody supervised training of a deep learning based algorithm for leukocyte segmentation in papillary thyroid carcinoma</article-title>
        <source>IEEE J. Biomed. Health Inform.</source>
        <volume>25</volume>
        <year>2020</year>
        <fpage>422</fpage>
        <lpage>428</lpage>
      </element-citation>
    </ref>
    <ref id="bib45">
      <label>45</label>
      <element-citation publication-type="journal" id="sref44">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>P.C.</given-names>
          </name>
          <name>
            <surname>Gadepalli</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>MacDonald</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Kadowaki</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Nagpal</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Kohlberger</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Dean</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Corrado</surname>
            <given-names>G.S.</given-names>
          </name>
          <name>
            <surname>Hipp</surname>
            <given-names>J.D.</given-names>
          </name>
          <name>
            <surname>Mermel</surname>
            <given-names>C.H.</given-names>
          </name>
          <name>
            <surname>Stumpe</surname>
            <given-names>M.C.</given-names>
          </name>
        </person-group>
        <article-title>An augmented reality microscope with real-time artificial intelligence integration for cancer diagnosis</article-title>
        <source>Nat. Med.</source>
        <volume>25</volume>
        <year>2019</year>
        <fpage>1453</fpage>
        <lpage>1457</lpage>
        <pub-id pub-id-type="pmid">31406351</pub-id>
      </element-citation>
    </ref>
    <ref id="bib46">
      <label>46</label>
      <element-citation publication-type="journal" id="sref45">
        <person-group person-group-type="author">
          <name>
            <surname>Van Eycke</surname>
            <given-names>Y.-R.</given-names>
          </name>
          <name>
            <surname>Balsat</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Verset</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Debeir</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Salmon</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Decaestecker</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Segmentation of glandular epithelium in colorectal tumours to automatically compartmentalise IHC biomarker quantification: A deep learning approach</article-title>
        <source>Med. Image Anal.</source>
        <volume>49</volume>
        <year>2018</year>
        <fpage>35</fpage>
        <lpage>45</lpage>
        <pub-id pub-id-type="pmid">30081241</pub-id>
      </element-citation>
    </ref>
    <ref id="bib47">
      <label>47</label>
      <element-citation publication-type="journal" id="sref46">
        <person-group person-group-type="author">
          <name>
            <surname>Swiderska-Chadaj</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Pinckaers</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>van Rijthoven</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Balkenhol</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Melnikova</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Geessink</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Manson</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Sherman</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Polonia</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Parry</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Learning to detect lymphocytes in immunohistochemistry with deep learning</article-title>
        <source>Med. Image Anal.</source>
        <volume>58</volume>
        <year>2019</year>
        <fpage>101547</fpage>
        <pub-id pub-id-type="pmid">31476576</pub-id>
      </element-citation>
    </ref>
    <ref id="bib48">
      <label>48</label>
      <element-citation publication-type="journal" id="sref47">
        <person-group person-group-type="author">
          <name>
            <surname>Aprupe</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Litjens</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Brinker</surname>
            <given-names>T.J.</given-names>
          </name>
          <name>
            <surname>van der Laak</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Grabe</surname>
            <given-names>N.</given-names>
          </name>
        </person-group>
        <article-title>Robust and accurate quantification of biomarkers of immune cells in lung cancer micro-environment using deep convolutional neural networks</article-title>
        <source>PeerJ</source>
        <volume>7</volume>
        <year>2019</year>
        <object-id pub-id-type="publisher-id">e6335</object-id>
      </element-citation>
    </ref>
    <ref id="bib49">
      <label>49</label>
      <element-citation publication-type="journal" id="sref48">
        <person-group person-group-type="author">
          <name>
            <surname>Tellez</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Balkenhol</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Otte-Höller</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>van de Loo</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Vogels</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Bult</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Wauters</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Vreuls</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Mol</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Karssemeijer</surname>
            <given-names>N.</given-names>
          </name>
        </person-group>
        <article-title>Whole-slide mitosis detection in H&amp;E breast histology using PHH3 as a reference to train distilled stain-invariant convolutional networks</article-title>
        <source>IEEE Trans. Med. Imaging</source>
        <volume>37</volume>
        <year>2018</year>
        <fpage>2126</fpage>
        <lpage>2136</lpage>
      </element-citation>
    </ref>
    <ref id="bib50">
      <label>50</label>
      <element-citation publication-type="journal" id="sref49">
        <person-group person-group-type="author">
          <name>
            <surname>Tewary</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Arun</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Ahmed</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Chatterjee</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Mukhopadhyay</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>AutoIHC-analyzer: Computer-assisted microscopy for automated membrane extraction/scoring in HER2 molecular markers</article-title>
        <source>J. Microsc.</source>
        <volume>281</volume>
        <year>2021</year>
        <fpage>87</fpage>
        <lpage>96</lpage>
        <pub-id pub-id-type="pmid">32803890</pub-id>
      </element-citation>
    </ref>
    <ref id="bib51">
      <label>51</label>
      <element-citation publication-type="journal" id="sref50">
        <person-group person-group-type="author">
          <name>
            <surname>Geread</surname>
            <given-names>R.S.</given-names>
          </name>
          <name>
            <surname>Morreale</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Dony</surname>
            <given-names>R.D.</given-names>
          </name>
          <name>
            <surname>Brouwer</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Wood</surname>
            <given-names>G.A.</given-names>
          </name>
          <name>
            <surname>Androutsos</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Khademi</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>IHC colour histograms for unsupervised Ki67 proliferation index calculation</article-title>
        <source>Front. Bioeng. Biotechnol.</source>
        <volume>7</volume>
        <year>2019</year>
        <fpage>226</fpage>
        <pub-id pub-id-type="pmid">31632956</pub-id>
      </element-citation>
    </ref>
    <ref id="bib52">
      <label>52</label>
      <element-citation publication-type="journal" id="sref51">
        <person-group person-group-type="author">
          <name>
            <surname>Feng</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Jing</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Xiang</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>Automated quantitative analysis of Ki-67 staining and HE images recognition and registration based on whole tissue sections in breast carcinoma</article-title>
        <source>Diagn. Pathol.</source>
        <volume>15</volume>
        <year>2020</year>
        <fpage>1</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="pmid">31900180</pub-id>
      </element-citation>
    </ref>
    <ref id="bib53">
      <label>53</label>
      <element-citation publication-type="journal" id="sref52">
        <person-group person-group-type="author">
          <name>
            <surname>Joseph</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Roudier</surname>
            <given-names>M.P.</given-names>
          </name>
          <name>
            <surname>Narayanan</surname>
            <given-names>P.L.</given-names>
          </name>
          <name>
            <surname>Augulis</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Ros</surname>
            <given-names>V.R.</given-names>
          </name>
          <name>
            <surname>Pritchard</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Gerrard</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Laurinavicius</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Harrington</surname>
            <given-names>E.A.</given-names>
          </name>
          <name>
            <surname>Barrett</surname>
            <given-names>J.C.</given-names>
          </name>
        </person-group>
        <article-title>Proliferation Tumour Marker Network (PTM-NET) for the identification of tumour region in Ki67 stained breast cancer whole slide images</article-title>
        <source>Sci. Rep.</source>
        <volume>9</volume>
        <year>2019</year>
        <fpage>1</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="pmid">30626917</pub-id>
      </element-citation>
    </ref>
    <ref id="bib54">
      <label>54</label>
      <element-citation publication-type="journal" id="sref53">
        <person-group person-group-type="author">
          <name>
            <surname>Saha</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Chakraborty</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Arun</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Ahmed</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Chatterjee</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>An advanced deep learning approach for Ki-67 stained hotspot detection and proliferation rate scoring for prognostic evaluation of breast cancer</article-title>
        <source>Sci. Rep.</source>
        <volume>7</volume>
        <year>2017</year>
        <fpage>1</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="pmid">28127051</pub-id>
      </element-citation>
    </ref>
    <ref id="bib55">
      <label>55</label>
      <element-citation publication-type="journal" id="sref54">
        <person-group person-group-type="author">
          <name>
            <surname>Vandenbrouck</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Pineau</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Lane</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>The functionally unannotated proteome of human male tissues: A shared resource to uncover new protein functions associated with reproductive biology</article-title>
        <source>J. Proteome Res.</source>
        <volume>19</volume>
        <year>2020</year>
        <fpage>4782</fpage>
        <lpage>4794</lpage>
        <pub-id pub-id-type="pmid">33064489</pub-id>
      </element-citation>
    </ref>
    <ref id="bib56">
      <label>56</label>
      <element-citation publication-type="journal" id="sref55">
        <person-group person-group-type="author">
          <name>
            <surname>Mengel</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>von Wasielewski</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Wiese</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Rudiger</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Muller-Hermelink</surname>
            <given-names>H.K.</given-names>
          </name>
          <name>
            <surname>Kreipe</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <article-title>Inter-laboratory and inter-observer reproducibility of immunohistochemical assessment of the Ki-67 labelling index in a large multi-centre trial</article-title>
        <source>J. Pathol.</source>
        <volume>198</volume>
        <year>2002</year>
        <fpage>292</fpage>
        <lpage>299</lpage>
        <pub-id pub-id-type="pmid">12375261</pub-id>
      </element-citation>
    </ref>
    <ref id="bib57">
      <label>57</label>
      <element-citation publication-type="journal" id="sref56">
        <person-group person-group-type="author">
          <name>
            <surname>Ouyang</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Winsnes</surname>
            <given-names>C.F.</given-names>
          </name>
          <name>
            <surname>Hjelmare</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Cesnik</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Akesson</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Sullivan</surname>
            <given-names>D.P.</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lan</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Jinmo</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Galib</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Henkel</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Hwang</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Poplavskiy</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Tunguz</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>Analysis of the human protein atlas image classification competition</article-title>
        <source>Nat. Methods</source>
        <volume>16</volume>
        <year>2019</year>
        <fpage>1254</fpage>
        <lpage>1261</lpage>
        <pub-id pub-id-type="pmid">31780840</pub-id>
      </element-citation>
    </ref>
    <ref id="bib58">
      <label>58</label>
      <element-citation publication-type="journal" id="sref57">
        <person-group person-group-type="author">
          <name>
            <surname>Sullivan</surname>
            <given-names>D.P.</given-names>
          </name>
          <name>
            <surname>Winsnes</surname>
            <given-names>C.F.</given-names>
          </name>
          <name>
            <surname>Akesson</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Hjelmare</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Wiking</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Schutten</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Campbell</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Leifsson</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Rhodes</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Nordgren</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Revaz</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Finnbogason</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Szantner</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Lundberg</surname>
            <given-names>E.</given-names>
          </name>
        </person-group>
        <article-title>Deep learning is combined with massive-scale citizen science to improve large-scale image classification</article-title>
        <source>Nat. Biotechnol.</source>
        <volume>36</volume>
        <year>2018</year>
        <fpage>820</fpage>
        <lpage>828</lpage>
        <pub-id pub-id-type="pmid">30125267</pub-id>
      </element-citation>
    </ref>
    <ref id="bib59">
      <label>59</label>
      <element-citation publication-type="journal" id="sref58">
        <person-group person-group-type="author">
          <name>
            <surname>Kumar</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Rao</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Bhavani</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Newberg</surname>
            <given-names>J.Y.</given-names>
          </name>
          <name>
            <surname>Murphy</surname>
            <given-names>R.F.</given-names>
          </name>
        </person-group>
        <article-title>Automated analysis of immunohistochemistry images identifies candidate location biomarkers for cancers</article-title>
        <source>Proc. Natl. Acad. Sci. U. S. A.</source>
        <volume>111</volume>
        <year>2014</year>
        <fpage>18249</fpage>
        <lpage>18254</lpage>
        <pub-id pub-id-type="pmid">25489103</pub-id>
      </element-citation>
    </ref>
    <ref id="bib60">
      <label>60</label>
      <element-citation publication-type="journal" id="sref59">
        <person-group person-group-type="author">
          <name>
            <surname>Newberg</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Murphy</surname>
            <given-names>R.F.</given-names>
          </name>
        </person-group>
        <article-title>A framework for the automated analysis of subcellular patterns in human protein atlas images</article-title>
        <source>J. Proteome Res.</source>
        <volume>7</volume>
        <year>2008</year>
        <fpage>2300</fpage>
        <lpage>2308</lpage>
        <pub-id pub-id-type="pmid">18435555</pub-id>
      </element-citation>
    </ref>
    <ref id="bib61">
      <label>61</label>
      <element-citation publication-type="journal" id="sref60">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>Y.Y.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H.B.</given-names>
          </name>
        </person-group>
        <article-title>An image-based multi-label human protein subcellular localization predictor (iLocator) reveals protein mislocalizations in cancer tissues</article-title>
        <source>Bioinformatics</source>
        <volume>29</volume>
        <year>2013</year>
        <fpage>2032</fpage>
        <lpage>2040</lpage>
        <pub-id pub-id-type="pmid">23740749</pub-id>
      </element-citation>
    </ref>
    <ref id="bib62">
      <label>62</label>
      <element-citation publication-type="journal" id="sref61">
        <person-group person-group-type="author">
          <name>
            <surname>Bankhead</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Loughrey</surname>
            <given-names>M.B.</given-names>
          </name>
          <name>
            <surname>Fernández</surname>
            <given-names>J.A.</given-names>
          </name>
          <name>
            <surname>Dombrowski</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>McArt</surname>
            <given-names>D.G.</given-names>
          </name>
          <name>
            <surname>Dunne</surname>
            <given-names>P.D.</given-names>
          </name>
          <name>
            <surname>McQuaid</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Gray</surname>
            <given-names>R.T.</given-names>
          </name>
          <name>
            <surname>Murray</surname>
            <given-names>L.J.</given-names>
          </name>
          <name>
            <surname>Coleman</surname>
            <given-names>H.G.</given-names>
          </name>
        </person-group>
        <article-title>QuPath: Open source software for digital pathology image analysis</article-title>
        <source>Sci. Rep.</source>
        <volume>7</volume>
        <year>2017</year>
        <fpage>1</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="pmid">28127051</pub-id>
      </element-citation>
    </ref>
    <ref id="bib63">
      <label>63</label>
      <element-citation publication-type="journal" id="sref62">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Beck</surname>
            <given-names>C.A.</given-names>
          </name>
          <name>
            <surname>Schwarz</surname>
            <given-names>E.M.</given-names>
          </name>
          <name>
            <surname>Boyce</surname>
            <given-names>B.F.</given-names>
          </name>
        </person-group>
        <article-title>Analysis of new bone, cartilage, and fibrosis tissue in healing murine allografts using whole slide imaging and a new automated histomorphometric algorithm</article-title>
        <source>Bone Res.</source>
        <volume>4</volume>
        <year>2016</year>
        <fpage>1</fpage>
        <lpage>9</lpage>
      </element-citation>
    </ref>
    <ref id="bib64">
      <label>64</label>
      <element-citation publication-type="journal" id="sref63">
        <person-group person-group-type="author">
          <name>
            <surname>Stålhammar</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Martinez</surname>
            <given-names>N.F.</given-names>
          </name>
          <name>
            <surname>Lippert</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Tobin</surname>
            <given-names>N.P.</given-names>
          </name>
          <name>
            <surname>Mølholm</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Kis</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Rosin</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Rantalainen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Pedersen</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Bergh</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Digital image analysis outperforms manual biomarker assessment in breast cancer</article-title>
        <source>Mod. Pathol.</source>
        <volume>29</volume>
        <year>2016</year>
        <fpage>318</fpage>
        <lpage>329</lpage>
        <pub-id pub-id-type="pmid">26916072</pub-id>
      </element-citation>
    </ref>
    <ref id="bib65">
      <label>65</label>
      <element-citation publication-type="journal" id="sref64">
        <person-group person-group-type="author">
          <name>
            <surname>Thommen</surname>
            <given-names>D.S.</given-names>
          </name>
          <name>
            <surname>Koelzer</surname>
            <given-names>V.H.</given-names>
          </name>
          <name>
            <surname>Herzig</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Roller</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Trefny</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Dimeloe</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Kiialainen</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Hanhart</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Schill</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Hess</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>A transcriptionally and functionally distinct PD-1+ CD8+ T cell pool with predictive potential in non-small-cell lung cancer treated with PD-1 blockade</article-title>
        <source>Nat. Med.</source>
        <volume>24</volume>
        <year>2018</year>
        <fpage>994</fpage>
        <lpage>1004</lpage>
        <pub-id pub-id-type="pmid">29892065</pub-id>
      </element-citation>
    </ref>
    <ref id="bib66">
      <label>66</label>
      <element-citation publication-type="journal" id="sref65">
        <person-group person-group-type="author">
          <name>
            <surname>Goodman</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Ward</surname>
            <given-names>K.C.</given-names>
          </name>
          <name>
            <surname>Osunkoya</surname>
            <given-names>A.O.</given-names>
          </name>
          <name>
            <surname>Datta</surname>
            <given-names>M.W.</given-names>
          </name>
          <name>
            <surname>Luthringer</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Young</surname>
            <given-names>A.N.</given-names>
          </name>
          <name>
            <surname>Marks</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Cohen</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Kennedy</surname>
            <given-names>J.C.</given-names>
          </name>
          <name>
            <surname>Haber</surname>
            <given-names>M.J.</given-names>
          </name>
          <name>
            <surname>Amin</surname>
            <given-names>M.B.</given-names>
          </name>
        </person-group>
        <article-title>Frequency and determinants of disagreement and error in gleason scores: A population-based study of prostate cancer</article-title>
        <source>Prostate</source>
        <volume>72</volume>
        <year>2012</year>
        <fpage>1389</fpage>
        <lpage>1398</lpage>
        <pub-id pub-id-type="pmid">22228120</pub-id>
      </element-citation>
    </ref>
  </ref-list>
  <sec id="appsec1" sec-type="supplementary-material">
    <title>Supplemental Data</title>
    <p id="p0315">
      <fig id="dfig1" position="anchor">
        <label>Supplemental Figure S1</label>
        <graphic xlink:href="figs1"/>
      </fig>
      <fig id="dfig2" position="anchor">
        <label>Supplemental Figure S2</label>
        <graphic xlink:href="figs2"/>
      </fig>
      <supplementary-material content-type="local-data" id="mmc1">
        <caption>
          <title>Supplemental Table S1</title>
        </caption>
        <media xlink:href="mmc1.xlsx"/>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="mmc2">
        <caption>
          <title>Supplemental Table S2</title>
        </caption>
        <media xlink:href="mmc2.xlsx"/>
      </supplementary-material>
      <supplementary-material content-type="local-data" id="mmc3">
        <caption>
          <title>MMC1</title>
        </caption>
        <media xlink:href="mmc3.docx"/>
      </supplementary-material>
    </p>
  </sec>
  <ack id="ack0010">
    <title>Acknowledgments</title>
    <p id="p0305">The project was funded by the <funding-source id="gs1"><institution-wrap><institution-id institution-id-type="doi">10.13039/501100004063</institution-id><institution>Knut and Alice Wallenberg Foundation</institution></institution-wrap></funding-source>. Pathologists and staff at the Department of Clinical Pathology, Uppsala University Hospital, are acknowledged for providing the tissues used for IHC. The authors would also like to thank all staff of the Human Protein Atlas for their work, with special thanks to Jimmy Vuu and Rutger Schutten for their help with annotation. We also thank Marine Seffals and Alain Fautrel at the H2P2 core facility (University of Rennes 1, US18, UMS3480 Biosit, Rennes, France) for data retrieval from past IHC experiments.</p>
    <sec id="sec6">
      <title>Author contributions</title>
      <p id="p0310">C. L. conceptualization; B. G. data curation; B. G. formal analysis; F. H. investigation; B. G. methodology; C. P. resources; A. T. and C. L. supervision; F. H., C. P., A. T., and C. L. validation; F. H. and C. L. visualization; B. G. and C. L. writing—original draft; F. H., C. P., and A. T. writing—review and editing.</p>
    </sec>
  </ack>
</back>
