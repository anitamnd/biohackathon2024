<?DTDIdentifier.IdentifierValue article.dtd?>
<?DTDIdentifier.IdentifierType system?>
<?SourceDTD.DTDName article.dtd?>
<?SourceDTD.Version 1.0?>
<?ConverterInfo.XSLTName bmc2nlm.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Struct Biol</journal-id>
    <journal-title>BMC Structural Biology</journal-title>
    <issn pub-type="epub">1472-6807</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">2777163</article-id>
    <article-id pub-id-type="publisher-id">1472-6807-9-66</article-id>
    <article-id pub-id-type="pmid">19840377</article-id>
    <article-id pub-id-type="doi">10.1186/1472-6807-9-66</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Machine learning integration for predicting the effect of single amino acid substitutions on protein stability</article-title>
    </title-group>
    <contrib-group>
      <contrib id="A1" equal-contrib="yes" contrib-type="author">
        <name>
          <surname>Özen</surname>
          <given-names>Ayşegül</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <email>aozen@prc.boun.edu.tr</email>
      </contrib>
      <contrib id="A2" equal-contrib="yes" contrib-type="author">
        <name>
          <surname>Gönen</surname>
          <given-names>Mehmet</given-names>
        </name>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>gonen@boun.edu.tr</email>
      </contrib>
      <contrib id="A3" corresp="yes" contrib-type="author">
        <name>
          <surname>Alpaydın</surname>
          <given-names>Ethem</given-names>
        </name>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>alpaydin@boun.edu.tr</email>
      </contrib>
      <contrib id="A4" corresp="yes" contrib-type="author">
        <name>
          <surname>Haliloğlu</surname>
          <given-names>Türkan</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <email>turkan@prc.boun.edu.tr</email>
      </contrib>
    </contrib-group>
    <aff id="I1"><label>1</label>Department of Chemical Engineering, Polymer Research Center, Boğaziçi University, İstanbul, Turkey</aff>
    <aff id="I2"><label>2</label>Department of Computer Engineering, Boğaziçi University, İstanbul, Turkey</aff>
    <pub-date pub-type="collection">
      <year>2009</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>19</day>
      <month>10</month>
      <year>2009</year>
    </pub-date>
    <volume>9</volume>
    <fpage>66</fpage>
    <lpage>66</lpage>
    <ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1472-6807/9/66"/>
    <history>
      <date date-type="received">
        <day>3</day>
        <month>2</month>
        <year>2009</year>
      </date>
      <date date-type="accepted">
        <day>19</day>
        <month>10</month>
        <year>2009</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2009 Özen et al; licensee BioMed Central Ltd.</copyright-statement>
      <copyright-year>2009</copyright-year>
      <copyright-holder>Özen et al; licensee BioMed Central Ltd.</copyright-holder>
      <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0">
        <p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p>
        <!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>
               &#x000d6;zen
               Ay&#x0015f;eg&#x000fc;l
               
               aozen@prc.boun.edu.tr
            </dc:author><dc:title>
            Machine learning integration for predicting the effect of single amino acid substitutions on protein stability
         </dc:title><dc:date>2009</dc:date><dcterms:bibliographicCitation>BMC Structural Biology 9(1): 66-. (2009)</dcterms:bibliographicCitation><dc:identifier type="sici">1472-6807(2009)9:1&#x0003c;66&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1472-6807</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>-->
      </license>
    </permissions>
    <abstract>
      <sec>
        <title>Background</title>
        <p>Computational prediction of protein stability change due to single-site amino acid substitutions is of interest in protein design and analysis. We consider the following four ways to improve the performance of the currently available predictors: (1) We include additional sequence- and structure-based features, namely, the amino acid substitution likelihoods, the equilibrium fluctuations of the alpha- and beta-carbon atoms, and the packing density. (2) By implementing different machine learning integration approaches, we combine information from different features or representations. (3) We compare classification vs. regression methods to predict the sign vs. the output of stability change. (4) We allow a reject option for doubtful cases where the risk of misclassification is high.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>We investigate three different approaches: early, intermediate and late integration, which respectively combine features, kernels over feature subsets, and decisions. We perform simulations on two data sets: (1) S1615 is used in previous studies, (2) S2783 is the updated version (as of July 2, 2009) extracted also from ProTherm. For S1615 data set, our highest accuracy using both sequence and structure information is 0.842 on cross-validation and 0.904 on testing using early integration. Newly added features, namely, local compositional packing and the mobility extent of the mutated residues, improve accuracy significantly with intermediate integration. For S2783 data set, we also train regression methods to estimate not only the sign but also the amount of stability change and apply risk-based classification to reject when the learner has low confidence and the loss of misclassification is high. The highest accuracy is 0.835 on cross-validation and 0.832 on testing using only sequence information. The percentage of false positives can be decreased to less than 0.005 by rejecting 10 per cent using late integration.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p>We find that in both early and late integration, combining inputs or decisions is useful in increasing accuracy. Intermediate integration allows assessing the contributions of individual features by looking at the assigned weights. Overall accuracy of regression is not better than that of classification but it has less false positives, especially when combined with the reject option. The server for stability prediction for three integration approaches and the data sets are available at <ext-link ext-link-type="uri" xlink:href="http://www.prc.boun.edu.tr/appserv/prc/mlsta"/>.</p>
      </sec>
    </abstract>
  </article-meta>
</front>
<body>
  <sec>
    <title>Background</title>
    <p>In protein design and analysis, understanding the stability in sequence, structure, and function paradigms is of importance [<xref ref-type="bibr" rid="B1">1</xref>] and hence there is a need for predicting the protein stability change due to mutation. Single amino acid mutations can significantly change the stability of a protein structure [<xref ref-type="bibr" rid="B2">2</xref>]. To acquire a set of experimental annotations for every possible random mutation is combinatorial and requires significant resources and time. Thus, accurate computational prediction would be of use for suggesting the destructive mutations as well as the most favorable and stable novel protein sequences. To this end, the prediction of protein stability change due to amino acid substitutions remains a challenging task in the field of molecular biology.</p>
    <p>Recent approaches fall into two major types: energy-based methods and machine learning approaches. Energy-based methods using physical, statistical, or empirical forcefields perform a direct computation of the magnitude of the relative change in the free energy [<xref ref-type="bibr" rid="B3">3</xref>-<xref ref-type="bibr" rid="B8">8</xref>]. Average assignment method [<xref ref-type="bibr" rid="B7">7</xref>] and different machine learning algorithms, such as support vector machines [<xref ref-type="bibr" rid="B2">2</xref>], neural networks [<xref ref-type="bibr" rid="B9">9</xref>], and decision trees [<xref ref-type="bibr" rid="B7">7</xref>] are trained on a data set to predict protein stability change. There are also hybrid approaches that combine energy-based and machine learning methods [<xref ref-type="bibr" rid="B10">10</xref>-<xref ref-type="bibr" rid="B12">12</xref>]; they basically generate the input features fed into machine learning algorithms using energy-based models.</p>
    <p>One can predict the direction towards which the mutation shifts the stability of the protein (namely the sign of ΔΔ<italic>G</italic>). It could be positive or negative, corresponding to an increase or decrease in stability, respectively. From a machine learning perspective, this is a binary classification task, where given <bold><italic>x</italic></bold>, information about the single-site amino acid substitution, the aim is to decide whether this is a positive or negative example, depending on whether the mutation is favorable or not. A third class of "doubt" can be defined for small changes that may be considered insignificant, and in such a case, one can train a three-class classifier [<xref ref-type="bibr" rid="B13">13</xref>] or a two-class classifier with the reject option.</p>
    <p>Given a sample of <italic>n </italic>independent and identically distributed training instances, (<bold><italic>x</italic></bold><sub><bold>1</bold></sub>, <italic>y</italic><sub>1</sub>),(<bold><italic>x</italic></bold><sub><bold>2</bold></sub>, <italic>y</italic><sub>2</sub>), ...,(<bold><italic>x</italic></bold><sub><bold><italic>n</italic></bold></sub>, <italic>y</italic><sub><italic>n</italic></sub>), where <bold><italic>x</italic></bold><sub><bold><italic>i </italic></bold></sub>is the <italic>d</italic>-dimensional input vector coding the relevant information and <italic>y</italic><sub><italic>i </italic></sub>∈ {-1, +1} is its class label, <italic>i </italic>= 1, ..., <italic>n</italic>, a classifier estimates <italic>P</italic>(+|<bold><italic>x</italic></bold>) and assigns the test instance to the positive class if <italic>P</italic>(+|<bold><italic>x</italic></bold>) &gt; 0.5, and to the negative class otherwise. There can be different representations in coding <bold><italic>x</italic></bold>. Deciding on the best data representation used is as important as selecting the classification algorithm.</p>
    <p>Another possibility in solving this using machine learning is to define it as a regression problem with ΔΔ<italic>G </italic>directly as the numeric output. One can then decide based on whether the prediction is positive or negative, and again predictions that are close to zero can be rejected if the risk of misclassification is high. No single machine learning algorithm nor representation, in classification or regression, induces always the most accurate learner in any domain. The usual approach is to try many and choose the one that performs the best on a separate validation set unused during training. Recently, it has been shown that accuracy may be improved by combining multiple learners [<xref ref-type="bibr" rid="B14">14</xref>,<xref ref-type="bibr" rid="B15">15</xref>]. There are three possible methods for combining multiple learners: early, late, and intermediate integration [<xref ref-type="bibr" rid="B16">16</xref>].</p>
    <p>In early integration, inputs are concatenated as one large vector and a single learner (classifier or regressor) is used. In late integration, multiple classifiers/regressors are trained over different inputs and their decisions are combined by a trained learner. These two approaches can be applied with any classification/regression algorithm.</p>
    <p>Late integration has been extensively used in bioinformatics. Weighted voting was used in classifier combination for protein fold recognition [<xref ref-type="bibr" rid="B17">17</xref>]. Majority voting was used for prediction of the drug resistance of HIV protease mutants [<xref ref-type="bibr" rid="B18">18</xref>], secondary structure prediction [<xref ref-type="bibr" rid="B19">19</xref>], detecting rare events in human genomic DNA [<xref ref-type="bibr" rid="B20">20</xref>] and identification of new tumor classes using gene expression profiles [<xref ref-type="bibr" rid="B21">21</xref>]. A trained combiner was used for secondary structure prediction [<xref ref-type="bibr" rid="B22">22</xref>,<xref ref-type="bibr" rid="B23">23</xref>]. A mixture of localized experts was used for gene identification [<xref ref-type="bibr" rid="B24">24</xref>]. Cascading, which is a multi-stage sequential combination method, was used for secondary structure prediction [<xref ref-type="bibr" rid="B25">25</xref>].</p>
    <p>Support vector machines allow combination in a third way, using multiple kernels; this is also called intermediate integration [<xref ref-type="bibr" rid="B16">16</xref>]. Kernel functions basically measure similarity between data instances and a single learner can combine separate kernels for different data sources, instead of combining data before training a single learner (as in early integration) or combining decisions from multiple learners (as in late integration).</p>
    <p>Intermediate integration was used for protein location prediction and protein function prediction tasks, respectively, by combining kernels applied to different representations such as protein sequences, hydropathy profile, protein interactions, and gene expressions [<xref ref-type="bibr" rid="B26">26</xref>,<xref ref-type="bibr" rid="B27">27</xref>]. This method is also used in glycan classification by combining different tree kernels [<xref ref-type="bibr" rid="B28">28</xref>].</p>
    <p>Our work has four aspects: (1) Introduction of new protein residue features: The temperature factors of the backbone and side-chain carbon atoms (<italic>B-factor</italic>) that reflect the thermal mobility/flexibility of the mutated residue; the local packing information in a higher resolution than that has previously been incorporated by considering the side-chain atoms as well; amino acid substitution likelihoods from P<sc>AM</sc>250 matrix. (2) Implementation of three different machine learning approaches (early, late, and intermediate integration), two of which, namely late and intermediate, have not been used before in the computational prediction of protein stability change. (3) Comparison of classification and regression methods. (4) The use of a reject option in both classification and regression to check for cases where the learner has low confidence.</p>
  </sec>
  <sec>
    <title>Data</title>
    <sec>
      <title>Data Sets</title>
      <p>The first data set (S1615) was compiled from the data available online [<xref ref-type="bibr" rid="B29">29</xref>], originally extracted [<xref ref-type="bibr" rid="B9">9</xref>] from the ProTherm database [<xref ref-type="bibr" rid="B30">30</xref>]. This data set has been used previously and provides a basis for comparison [<xref ref-type="bibr" rid="B2">2</xref>,<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B31">31</xref>]. The set originally contains 1615 single-site mutation data from 42 different proteins. Each instance has the following features: PDB code of the protein, mutated position and mutation itself, solvent accessibility, pH value, temperature (T), and the change in the free energy, ΔΔ<italic>G</italic>, due to a mutation in a single position. As there are instances for the same mutation and position where ΔΔ<italic>G </italic>differs with T and pH values, T and pH are kept as features in our data set. A subset (388 instances) of the training set (1615 instances) was previously used as a test set for comparison between different predictors [<xref ref-type="bibr" rid="B2">2</xref>]. Though some studies include the test set also in the training set, we remove it from the training set to have disjoint training and test sets, as done in [<xref ref-type="bibr" rid="B2">2</xref>].</p>
      <p>We also extract an up-to-date version (as of July 2, 2009) (S2783) that contains 2783 single-site mutations with known PDB code of the protein and ΔΔ<italic>G </italic>values also from the ProTherm database. On this larger data set, we implement and compare both classification and regression integration methods and also their versions with the reject option.</p>
    </sec>
    <sec>
      <title>Added Features</title>
      <p>The substitution frequency of an amino acid for another is considered here as an additional feature with the Point Accepted Mutation (P<sc>AM</sc>) matrix [<xref ref-type="bibr" rid="B32">32</xref>]. P<sc>AM</sc>250 is chosen for the score of each amino acid substitution and is based on the frequency of that substitution in closely related proteins that have experienced a certain amount of evolutionary divergence.</p>
      <p>Another feature considered is the mobility/flexibility of the amino acid position in a given structure. The <italic>B-factor</italic>s reported in the PDB file is a good and quick indicator of this feature. Neighbors of the mutated residue in both amino acid sequence and 3D structure are the two other features that have been used recently [<xref ref-type="bibr" rid="B2">2</xref>,<xref ref-type="bibr" rid="B9">9</xref>]. A window size of seven in the sequence [<xref ref-type="bibr" rid="B2">2</xref>] and a cutoff distance of 9Å in space was previously used to find the neighbors of the mutated position as the optimum sequence length and distance, respectively [<xref ref-type="bibr" rid="B9">9</xref>]. In our implementation, in addition to alpha-carbon atoms (<italic>C</italic><sub><italic>α</italic></sub>), beta-carbon (<italic>C</italic><sub><italic>β</italic></sub>) atoms are also considered to reflect the packing at a relatively higher resolution.</p>
      <p>A mutation in a position of a protein sequence will change the number of side-chain atoms of the residue in that position. This may trigger a conformational change or local readjustments that may result also in a change in the atomic packing around that residue and the fluctuations of the surrounding residues and the mutated residue itself. Nevertheless, as in other studies [<xref ref-type="bibr" rid="B2">2</xref>,<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B31">31</xref>], we neglect this effect.</p>
      <p>Removing the instances with non-available features and the redundant instances from S1615 leaves us with training and test sets of 1122 and 383 instances with total of 31 and 14 proteins. Stabilizing mutations are 32.35 per cent and 11.49 per cent, respectively. After removing the instances with non-available features, S2783 reduces to 2471 instances from 68 different proteins and 755 of them (30.55 per cent) are stabilizing mutations. Both data sets are available online.</p>
      <p>Table <xref ref-type="table" rid="T1">1</xref> gives a list of the representations, original features, and the new features that we introduce. The information coming only from the sequence (S<sc>O</sc>), and the topology of the protein structure (T<sc>O</sc>), and both (S<sc>T</sc>) are encoded in the same way as defined in previous studies [<xref ref-type="bibr" rid="B2">2</xref>]. An added asterisk, for example, (S<sc>O</sc>*), denotes the representation with newly added features. Neighbors of the mutated position in the sequence, mutation, T, and pH are encoded in S<sc>O</sc>/S<sc>O</sc>*. Sequence information is not used in T<sc>O</sc>/T<sc>O</sc>*; instead, spatial neighbors and the solvent accessibility of the mutated position are encoded. In S<sc>T</sc>/S<sc>T</sc>*, all information are combined. The substitution likelihood of an amino acid is added to the existing data as a new feature in all three representations. Crystallographic <italic>B-factor</italic>s of the <italic>C</italic><sub><italic>α </italic></sub>and <italic>C</italic><sub><italic>β </italic></sub>atoms are used in T<sc>O</sc>* and S<sc>T</sc>*. For discrete features like amino acid identities, <italic>1-of-n encoding </italic>is used, that is, if the variable can take one of <italic>n </italic>different values, one is set to 1 and all others to 0.</p>
      <table-wrap position="float" id="T1">
        <label>Table 1</label>
        <caption>
          <p>Representations, original features, and the new features. </p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <td align="center">
                <bold>Repr.</bold>
              </td>
              <td align="center">
                <bold>Original Feat.</bold>
              </td>
              <td align="center">
                <bold>New Repr.</bold>
              </td>
              <td align="center">
                <bold>New Feat.</bold>
              </td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center">S<sc>O</sc></td>
              <td align="center">± 3 neighbors (± 3 N<sc>E</sc>)<break/>Mutation (M<sc>UT</sc>)<break/>T/pH</td>
              <td align="center">S<sc>O</sc>*</td>
              <td align="center">P<sc>AM</sc>250 (P<sc>AM</sc>)</td>
            </tr>
            <tr>
              <td colspan="4">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="center">T<sc>O</sc></td>
              <td align="center">Mutation (M<sc>UT</sc>)<break/><italic>C</italic><sub><italic>α </italic></sub>contacts (C<sc>A</sc>)<break/>S<sc>A</sc>/T/pH</td>
              <td align="center">T<sc>O</sc>*</td>
              <td align="center">P<sc>AM</sc>250 (P<sc>AM</sc>)<break/><italic>C</italic><sub><italic>α </italic></sub>B-factor (B<sc>FA</sc>)<break/><italic>C</italic><sub><italic>α </italic></sub>B-factor (B<sc>FB</sc>)<break/><italic>C</italic><sub><italic>α </italic></sub>and <italic>C</italic><sub><italic>β </italic></sub>contacts (C<sc>B</sc>)</td>
            </tr>
            <tr>
              <td colspan="4">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="center">S<sc>T</sc></td>
              <td align="center">± 3 neighbors (± 3 N<sc>E</sc>)<break/>Mutation (M<sc>UT</sc>)<break/><italic>C</italic><sub><italic>α </italic></sub>contacts (C<sc>A</sc>)<break/>S<sc>A</sc>/T/pH</td>
              <td align="center">S<sc>T</sc>*</td>
              <td align="center">P<sc>AM</sc>250 (P<sc>AM</sc>)<break/><italic>C</italic><sub><italic>α </italic></sub>B-factor (B<sc>FA</sc>)<break/><italic>C</italic><sub><italic>α </italic></sub>B-factor (B<sc>FB</sc>)<break/><italic>C</italic><sub><italic>α </italic></sub>and <italic>C</italic><sub><italic>β </italic></sub>contacts (C<sc>B</sc>)</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>In all three representations, amino acid substitution likelihood is used as a feature. <italic>B-factors</italic> of the C<sub><italic>α</italic></sub> and C<sub><italic>β </italic></sub>atoms and spatial neighbor determined using both C<sub><italic>α </italic></sub> and C<sub><italic>β </italic></sub>atoms are features introduced into T<sc>O</sc> and S<sc>T</sc>. The abbreviations are given only for the features that we add.</p>
        </table-wrap-foot>
      </table-wrap>
    </sec>
  </sec>
  <sec sec-type="methods">
    <title>Methods</title>
    <sec>
      <title>The Effect of Adding New Features to the Original Data Sets</title>
      <p>To each of the three representations (S<sc>O</sc>, T<sc>O</sc>, or S<sc>T</sc>), the new features are added one at a time and as combinations of two and three (see Table <xref ref-type="table" rid="T2">2</xref>). Since all the new features except P<sc>AM</sc> are structure-related, they are not added to S<sc>O</sc>. All of the new features, including P<sc>AM</sc>, are added to both T<sc>O</sc> and S<sc>T</sc>. We end up with (2<sup>1 </sup>(P<sc>AM</sc>) for S<sc>O</sc> and 2<sup>4 </sup>(P<sc>AM</sc>, C<sc>B</sc>, B<sc>FA</sc>, B<sc>FB</sc>) for each of T<sc>O</sc> and S<sc>T</sc> combinations) a total of 34 possible feature sets (all of which include the mutation, T, and pH information).</p>
      <table-wrap position="float" id="T2">
        <label>Table 2</label>
        <caption>
          <p>The list of 34 possible input feature sets. </p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <td align="center">
                <bold>#</bold>
              </td>
              <td align="center">
                <bold>Representation</bold>
              </td>
              <td align="center">
                <bold>P<sc>AM</sc></bold>
              </td>
              <td align="center">
                <bold>C<sc>B</sc></bold>
              </td>
              <td align="center">
                <bold>B<sc>FA</sc></bold>
              </td>
              <td align="center">
                <bold>B<sc>FB</sc></bold>
              </td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center">1</td>
              <td align="center">S<sc>O</sc></td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">2</td>
              <td align="center">S<sc>O</sc></td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td colspan="6">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="center">3</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">4</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">5</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">6</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">7</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">8</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">9</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">10</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">11</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">12</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">13</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">14</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">15</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">16</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">17</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">18</td>
              <td align="center">T<sc>O</sc></td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td colspan="6">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="center">19</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">20</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">21</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">22</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">23</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">24</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">25</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">26</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">27</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">28</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">29</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">-</td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">30</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">-</td>
            </tr>
            <tr>
              <td align="center">31</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">32</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">+</td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">33</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">-</td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">+</td>
            </tr>
            <tr>
              <td align="center">34</td>
              <td align="center">S<sc>T</sc></td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">+</td>
              <td align="center">+</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>The new features to each of the three representations (S<sc>O</sc>, T<sc>O</sc> or S<sc>T</sc>) are added one at a time and as combinations of two and more. The original features are already given in Table 1 and are not shown here.</p>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>Performance Assessment</title>
      <p>Having already left 383 test instances out as the test set for S1615, we use 20-fold cross-validation (cv) on the 1122 training instances using 19/20 = 95 per cent for training proper and 5 per cent for validation. The best cross-validation strategy, that is, the number of folds, gets the best trade-off between the total amount of computation and training set size. With <italic>k </italic>folds, one needs <italic>k </italic>sets of training and validation and uses (<italic>k </italic>- 1)/<italic>k </italic>of data for training. We decided that the best is with <italic>k </italic>= 20; with higher <italic>k </italic>(or using jackknife), there is too much computation and with smaller <italic>k</italic>, training set gets small and variance increases. Classes should be represented in the right proportions when subsets of data are held out, not to disturb the class prior probabilities and we fulfill this requirement by stratification. Repeating training 20 times, we choose the hyperparameter set that has the highest average validation accuracy. The 20 classifiers trained on the 20 training folds for that hyperparameter set are tested on the test set. If we are required to perform classifier combination, we use the same training and validation sets also for the combiner due to the small size of the training set [<xref ref-type="bibr" rid="B33">33</xref>].</p>
      <p>For all three integration methods, we use our own code; MOSEK [<xref ref-type="bibr" rid="B34">34</xref>] is used for solving the optimization problems of support vector machines. We report averages over 20 test results obtained by testing the trained classifier of each fold on the test set; for comparing classifiers, we use the paired <italic>t</italic>-test over these 20 results.</p>
      <p>We use a slightly different methodology for S2783 because we train both classification and regression methods. First, we determine 3 split points for both stabilizing and destabilizing mutations as shown in Figure <xref ref-type="fig" rid="F1">1</xref>. Each split contains approximately the same number of data instances as the other two splits of the same class. This splitting mechanism both maintains stratification and ensures that we give the regressors training instances with diverse output values. Then, we take one-third of each split randomly to the test set and the remaining two-third is reserved as the training set. We apply 20-fold cv on the training set and obtain 20 folds. The learners (both classifiers and regressors) are trained on the 20 training folds and tested on the test set. The hyperparameter set that has the highest average validation accuracy for classification or the lowest mean square error for regression is selected and tested on the test set 20 times with the trained learners. This whole process is replicated 10 times each time using a different random test set. As a result, we obtain 10 × 20 test set results and report the average of these results.</p>
      <fig position="float" id="F1">
        <label>Figure 1</label>
        <caption>
          <p><bold>Distribution of S2783 data over the free energy change due to single-site mutation, ΔΔ<italic>G</italic></bold>. The regions separated by dashed lines are used to obtain similar training and test splits. Random one-third of the instances in each region is reserved for testing and the remaining two-third is used in training.</p>
        </caption>
        <graphic xlink:href="1472-6807-9-66-1"/>
      </fig>
      <p>The accuracies on the test set are calculated as given in Table <xref ref-type="table" rid="T3">3</xref> where <italic>TP</italic>, <italic>FP</italic>, <italic>TN</italic>, and <italic>FN</italic>, respectively refer to the number of true positives, false positives, true negatives, and false negatives. Precision, recall, and <italic>FP </italic>rate are evaluation measures which give information about the reliability of the predictor. The same measures are also reported for regression methods after converting the output of the regressor to a class prediction by looking at the sign.</p>
      <table-wrap position="float" id="T3">
        <label>Table 3</label>
        <caption>
          <p>Performance evaluation measures.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <td align="left">Accuracy</td>
              <td align="center">
                <inline-formula>
                  <inline-graphic xlink:href="1472-6807-9-66-i1.gif"/>
                </inline-formula>
              </td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left">Error Rate</td>
              <td align="center">
                <inline-formula>
                  <inline-graphic xlink:href="1472-6807-9-66-i2.gif"/>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td colspan="2">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="left">Precision</td>
              <td align="center">
                <inline-formula>
                  <inline-graphic xlink:href="1472-6807-9-66-i3.gif"/>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td colspan="2">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="left">Recall</td>
              <td align="center">
                <inline-formula>
                  <inline-graphic xlink:href="1472-6807-9-66-i4.gif"/>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td colspan="2">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="left">FP Rate</td>
              <td align="center">
                <inline-formula>
                  <inline-graphic xlink:href="1472-6807-9-66-i5.gif"/>
                </inline-formula>
              </td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>As we can see from Figure <xref ref-type="fig" rid="F1">1</xref>, ΔΔ<italic>G </italic>values are clustered around zero and small changes in the prediction of a learner may change the predicted label for a test instance. When the risk of misclassification is high, we can allow a predictor to give a reject decision. We define a risk matrix in Table <xref ref-type="table" rid="T4">4</xref> where <italic>r </italic>is the reject option, and the rows and columns correspond to the true and predicted class labels, respectively.</p>
      <table-wrap position="float" id="T4">
        <label>Table 4</label>
        <caption>
          <p>Risk matrix.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <tbody>
            <tr>
              <td/>
              <td/>
              <td align="center" colspan="3">
                <bold>Decision</bold>
              </td>
            </tr>
            <tr>
              <td/>
              <td/>
              <td align="center">
                <bold>+</bold>
              </td>
              <td align="center">
                <bold>-</bold>
              </td>
              <td align="center">
                <bold>
                  <italic>r</italic>
                </bold>
              </td>
            </tr>
            <tr>
              <td/>
              <td colspan="4">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="center">
                <bold>Truth</bold>
              </td>
              <td align="center">+</td>
              <td align="center">0</td>
              <td align="center">
                <italic>λ</italic>
              </td>
              <td align="center">1</td>
            </tr>
            <tr>
              <td/>
              <td colspan="4">
                <hr/>
              </td>
            </tr>
            <tr>
              <td/>
              <td align="center">-</td>
              <td align="center">
                <italic>αλ</italic>
              </td>
              <td align="center">0</td>
              <td align="center">1</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>Predicting the class label correctly does not incur any cost at all. If the learner rejects, a unit cost incurs. If the learner makes a prediction error, it pays a misclassification cost <italic>λ </italic>for <italic>FN </italic>and <italic>αλ </italic>for <italic>FP </italic>where <italic>α </italic>is the trade-off parameter for <italic>FP </italic>and usually depends on the application. These misclassification costs should be larger than 1 in order to make the learner reject when it is not confident about its prediction. Given a risk matrix and <italic>P</italic>(+<italic>|</italic><bold><italic>x</italic></bold>), we can calculate the risks of three possible actions as follows:</p>
      <p>
        <disp-formula>
          <graphic xlink:href="1472-6807-9-66-i6.gif"/>
        </disp-formula>
      </p>
      <p>and the best action is selected as the action with minimum risk. One can then solve for the rejection thresholds based on the values of <italic>λ </italic>and <italic>α</italic>. For example, if <italic>λ </italic>= 2 and <italic>α </italic>= 2, then we choose</p>
      <p>
        <disp-formula>
          <graphic xlink:href="1472-6807-9-66-i7.gif"/>
        </disp-formula>
      </p>
      <p>We experiment with different <italic>λ </italic>(2, 5, 10) and <italic>α </italic>(1, 2, 5) values. If <italic>α </italic>= 1, this means that <italic>FP </italic>and <italic>FN </italic>have equal misclassification costs assigned to them. In our case, by taking <italic>α </italic>&gt; 1, we say that predicting a destabilizing mutation as a stabilizing one is costlier than the other way around.</p>
      <p>For regression where the output is not a probability but a number, we can not analytically solve for the two thresholds but need to do an exhaustive search. We search for two thresholds <italic>θ</italic><sub>1 </sub>(&lt; 0) and <italic>θ</italic><sub>2 </sub>(&gt; 0) on the validation sets given the values of <italic>λ </italic>and <italic>α </italic>that minimize the total classification risk. We choose the negative class if the regression output, <italic>y</italic>, for a specific test instance is less than <italic>θ</italic><sub>1</sub>, reject if <italic>θ</italic><sub>1 </sub>&lt;<italic> y </italic>&lt;<italic>θ</italic><sub>2</sub>, and choose the positive class if <italic>y </italic>&gt; <italic>θ</italic><sub>2</sub>.</p>
    </sec>
    <sec>
      <title>Early Integration</title>
      <p>Different classifiers make different assumptions about the data and may fail in different instances [<xref ref-type="bibr" rid="B14">14</xref>]. We train three classifiers, namely <italic>k</italic>-nearest neighbor estimator, decision tree, and support vector machine, using S<sc>O</sc>/S<sc>O</sc>*, T<sc>O</sc>/T<sc>O</sc>*, and S<sc>T</sc>/S<sc>T</sc>* representations. We use a single regression method, namely support vector regression, on all representations.</p>
      <sec>
        <title>
          <italic>k-Nearest Neighbor (k-NN) Classifier </italic>
        </title>
        <p>The <italic>k</italic>-<sc>NN</sc> classifier assigns the input to the class by taking a majority vote among its <italic>k </italic>neighbors. The best value of <italic>k </italic>is chosen from the set of 1, 3, 5, 7, 9, and 11 using 20-fold cv.</p>
      </sec>
      <sec>
        <title>Decision Tree (D<sc>T</sc>)</title>
        <p>A D<sc>T</sc> is a hierarchical model whereby the local region is identified in a sequence of recursive splits. When there is noise, growing the tree until it is purest, we may grow a very large tree. To alleviate such overfitting, tree construction ends when nodes contain few examples; this threshold, <italic>τ</italic>, is the hyperparameter to be tuned. <italic>τ </italic>parameter is selected from the trial values of 56 (5 per cent of the training set), 28, and 14 for S1615 (80, 40, and 20 for S2783).</p>
      </sec>
      <sec>
        <title>Support Vector Machine (S<sc>VM</sc>)</title>
        <p>S<sc>VM</sc> finds the linear discriminant in the feature space with the maximum margin [<xref ref-type="bibr" rid="B35">35</xref>]. S<sc>VM</sc> uses the training data in the form of dot products and allows embedding another feature space via kernel functions. The RBF (radial basis function) kernel was recently reported to work best for stability prediction [<xref ref-type="bibr" rid="B2">2</xref>]. The regularization parameter, <italic>C</italic>, is chosen from (0.01, 0.1, 1, 10, 100) and the kernel width, <italic>γ</italic>, is chosen from (0.25<italic>r</italic>, 0.5<italic>r</italic>, <italic>r</italic>, 2<italic>r</italic>, and 4<italic>r</italic>) where <italic>r </italic>is the average nearest neighbor distance over the training set.</p>
      </sec>
      <sec>
        <title>Support Vector Regression (S<sc>VR</sc>)</title>
        <p>S<sc>VR</sc> is an extension to S<sc>VM</sc> for regression problems [<xref ref-type="bibr" rid="B36">36</xref>]. The regularization parameter, <italic>C</italic>, is chosen from (0.01, 0.1, 1, 10, 100) and the width parameter of the RBF kernel, <italic>γ</italic>, is chosen from (0.25<italic>r</italic>, 0.5<italic>r</italic>, <italic>r</italic>, 2<italic>r</italic>, and 4<italic>r</italic>) where <italic>r </italic>is the average nearest neighbor distance over the training set, the regression tube width, ϵ, is selected from (0.05, 0.10, 0.15).</p>
      </sec>
    </sec>
    <sec>
      <title>Late Integration</title>
      <p>It is possible to learn to combine the decisions of classifiers by a combiner classifier. By training the three classifiers described above with 34 data sets (see Table <xref ref-type="table" rid="T2">2</xref>), we get 102 different combination triplets of (<italic>R.D.B</italic>) outputs where <italic>R</italic>, <italic>D</italic>, and <italic>B </italic>stand for <italic>Representation</italic>, <italic>Data set</italic>, and <italic>Base-learner</italic>. The output of the combiner is the best subset combination of these 102 triplets. The two criteria to select the best combination are accuracy and diversity, in that, we want (<italic>R.D.B</italic>) triplets that fail in different regions of the input space. In order to see to what extent any two classifiers are correlated, McNemar's test is used [<xref ref-type="bibr" rid="B15">15</xref>]. The same procedure can also be applied to combine regressors. We obtain 34 different regressors and the combiner chooses a subset from those. The correlation coefficient between the output of two regressors can be used to check the diversity between these regressors; a small correlation coefficient means that the two regressors are diverse.</p>
      <p>The algorithm for selecting the most accurate and most diverse (<italic>R.D.B</italic>) triplets is a greedy, forward algorithm for subset selection. We start with an initial (<italic>R.D.B</italic>) that is the most accurate and search through the rest of the (<italic>R.D.B</italic>) triplets for those that are different from the initial one at significance level of <italic>α </italic>= 0.05 by McNemar's test. We add the most accurate one among those and iterate until there is no further improvement. The posterior probability outputs of the selected classifiers are then used to train a combiner that is an S<sc>VM</sc> with the linear kernel. The pseudocode of the algorithm is given in Table <xref ref-type="table" rid="T5">5</xref>. The algorithm for combining regressors is very similar to Table <xref ref-type="table" rid="T5">5</xref> except three basic differences: (1) We select the regressor with the minimum mean squared error among candidate regressors. (2) We use correlation coefficient as the diversity measure between regressors. (3) We combine the outputs of selected regressors with a combiner that is an S<sc>VR</sc> with the linear kernel.</p>
      <table-wrap position="float" id="T5">
        <label>Table 5</label>
        <caption>
          <p>The algorithm to select the classifiers to be combined. </p>
        </caption>
        <table frame="hsides" rules="groups">
          <tbody>
            <tr>
              <td align="right">1: </td>
              <td align="left">Initialize the subset <italic>Z </italic>as empty set</td>
            </tr>
            <tr>
              <td align="right">2:</td>
              <td align="left">Initialize the subset <italic>R </italic>as all possible 102 (<italic>R.D.B</italic>) groups</td>
            </tr>
            <tr>
              <td align="right">3:</td>
              <td align="left">Remove the most accurate (<italic>R.D.B</italic>) from <italic>R </italic>and add to <italic>Z</italic></td>
            </tr>
            <tr>
              <td align="right">4:</td>
              <td align="left">Perform McNemar's test for all pairs between <italic>Z </italic>and <italic>R</italic></td>
            </tr>
            <tr>
              <td align="right">5:</td>
              <td align="left">Decrease the degree of confidence, <italic>α</italic>, for McNemar's test</td>
            </tr>
            <tr>
              <td align="right">6:</td>
              <td align="left"><bold>if </bold>There is at least one diverse (<italic>R.D.B</italic>) in <italic>R </italic><bold>then</bold></td>
            </tr>
            <tr>
              <td align="right">7:</td>
              <td align="left">Select the most accurate and most diverse (<italic>R.D.B</italic>) from <italic>R </italic>and add it to <italic>Z</italic></td>
            </tr>
            <tr>
              <td align="right">8:</td>
              <td align="left">Go to <bold>Step 4</bold></td>
            </tr>
            <tr>
              <td align="right">9:</td>
              <td align="left">
                <bold>else</bold>
              </td>
            </tr>
            <tr>
              <td align="right">10:</td>
              <td align="left">Use the (<italic>R.D.B</italic>) triplets in <italic>Z </italic>as the current base-learners to be combined</td>
            </tr>
            <tr>
              <td align="right">11:</td>
              <td align="left">
                <bold>end if</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>The aim is to select the most accurate and at the same time the most diverse classifiers.</p>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>Intermediate Integration</title>
      <p>When using multiple kernels in support vector machines, there are two different possibilities [<xref ref-type="bibr" rid="B16">16</xref>]: We can calculate kernel functions on different representations or calculate different kernel functions on the same representation.</p>
      <p>One can take a sum over different kernels and summation rule is applied successfully in computational biology [<xref ref-type="bibr" rid="B37">37</xref>] where heterogeneous data sets exist by the nature of the biological problems. </p>
      <p>Replacing the kernel function with a weighted summation of <italic>p </italic>kernel functions was proposed [<xref ref-type="bibr" rid="B38">38</xref>,<xref ref-type="bibr" rid="B39">39</xref>]:</p>
      <p>
        <disp-formula>
          <graphic xlink:href="1472-6807-9-66-i8.gif"/>
        </disp-formula>
      </p>
      <p>where the combination weights (<italic>η</italic><sub><italic>m</italic></sub>) are new parameters optimized in training. In addition to the flexibility of constructing weighted combination rules, using multikernel S<sc>VM</sc>s provides two important advantages: (1) Information can be extracted about the classification task at hand. The feature sets used in kernel functions with larger weights are understood to give more relevant information in terms of classification. For example, obtaining information about important features in biological problems such as disease diagnosis and drug development is as important as classification accuracy. (2) Kernel functions with zero weights can be eliminated. If such feature sets are obtained by using costly and time consuming experimental procedures, this decreases the overall complexity and cost.</p>
      <p>For regression using intermediate integration, we use a variant of the localized multiple kernel learning model [<xref ref-type="bibr" rid="B40">40</xref>]. Kernel combination weights can be modeled by using the softmax function as follows:</p>
      <p>
        <disp-formula>
          <graphic xlink:href="1472-6807-9-66-i9.gif"/>
        </disp-formula>
      </p>
      <p>where the softmax guarantees that <italic>η</italic><sub><italic>m </italic></sub>≥ 0 and <inline-formula><inline-graphic xlink:href="1472-6807-9-66-i10.gif"/></inline-formula>, and <italic>u</italic><sub><italic>m </italic></sub>are the kernel-specific parameters we need to learn. These parameters are optimized during training in an iterative manner.</p>
      <p>In intermediate integration, we combine RBF kernels over feature subsets that form S<sc>O</sc>/S<sc>O</sc>*, T<sc>O</sc>/T<sc>O</sc>*, and S<sc>T</sc>/S<sc>T</sc>*. Their width parameters are selected as the average nearest neighbor distances in the corresponding feature subsets.</p>
    </sec>
  </sec>
  <sec>
    <title>Results</title>
    <sec>
      <title>S1615 Data Set</title>
      <sec>
        <title>Early Integration</title>
        <p>We finetune the hyperparameters by inspecting the 20-fold cv misclassification error. For <italic>k</italic>-<sc>NN</sc>, <italic>k </italic>= 1 gives the most accurate cv results. The best parameter values for S<sc>VM</sc>s are (<italic>C </italic>= 100, <italic>γ </italic>= <italic>r</italic>), (<italic>C </italic>= 100, <italic>γ </italic>= <italic>r</italic>), and (<italic>C </italic>= 1, <italic>γ </italic>= <italic>r</italic>) for S<sc>O</sc>/S<sc>O</sc>*, T<sc>O</sc>/T<sc>O</sc>*, and S<sc>T</sc>/S<sc>T</sc>*, respectively. Decision tree parameter, <italic>τ</italic>, is validated to be 14 in all representations.</p>
        <p>Accuracies of the best <italic>(R.D.B) </italic>triplets for each representation of the data are given in Figure <xref ref-type="fig" rid="F2">2</xref>. The effect of adding each extra feature is observed by adding one at a time and in combinations of two or more. S<sc>VM</sc> yields the most accurate predictions in all three representations. The introduction of P<sc>AM</sc> into S<sc>O</sc> has no effect on accuracy, which is 0.904. The average testing accuracy for T<sc>O</sc> increases from 0.904 to 0.909 with the help of new features, which is not statistically significant. Our results show that adding extra features to S<sc>T</sc> does not improve the accuracy of 0.904. The best accuracies with original and extra features for early integration are given in Table <xref ref-type="table" rid="T6">6</xref>. Table <xref ref-type="table" rid="T7">7</xref> lists the precision, recall, and <italic>FP </italic>rate values on the test set for the best classifiers for all three representations.</p>
        <table-wrap position="float" id="T6">
          <label>Table 6</label>
          <caption>
            <p>Early integration results for S1615 data set. </p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td align="center" colspan="2">
                  <bold><italic>k</italic>-<sc>NN</sc></bold>
                </td>
                <td align="center" colspan="2">
                  <bold>D<sc>T</sc></bold>
                </td>
                <td align="center" colspan="2">
                  <bold>S<sc>VM</sc></bold>
                </td>
              </tr>
              <tr>
                <td/>
                <td align="center">
                  <bold>cv</bold>
                </td>
                <td align="center">
                  <bold>test</bold>
                </td>
                <td align="center">
                  <bold>cv</bold>
                </td>
                <td align="center">
                  <bold>test</bold>
                </td>
                <td align="center">
                  <bold>cv</bold>
                </td>
                <td align="center">
                  <bold>test</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc></bold>
                </td>
                <td align="center">0.814</td>
                <td align="center">0.778</td>
                <td align="center">0.752</td>
                <td align="center">0.703</td>
                <td align="center">0.838</td>
                <td align="center">0.904</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc>*</bold>
                </td>
                <td align="center">0.812</td>
                <td align="center">0.781</td>
                <td align="center">0.766</td>
                <td align="center">0.702</td>
                <td align="center">0.839</td>
                <td align="center">0.904</td>
              </tr>
              <tr>
                <td colspan="7">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc></bold>
                </td>
                <td align="center">0.812</td>
                <td align="center">0.819</td>
                <td align="center">0.770</td>
                <td align="center">0.739</td>
                <td align="center">0.822</td>
                <td align="center">0.905</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc>*</bold>
                </td>
                <td align="center">0.817</td>
                <td align="center">0.844</td>
                <td align="center">0.788</td>
                <td align="center">0.756</td>
                <td align="center">0.825</td>
                <td align="center">0.909</td>
              </tr>
              <tr>
                <td colspan="7">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc></bold>
                </td>
                <td align="center">0.814</td>
                <td align="center">0.777</td>
                <td align="center">0.771</td>
                <td align="center">0.734</td>
                <td align="center">0.838</td>
                <td align="center">0.904</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc>*</bold>
                </td>
                <td align="center">0.817</td>
                <td align="center">0.775</td>
                <td align="center">0.800</td>
                <td align="center">0.729</td>
                <td align="center">0.842</td>
                <td align="center">0.904</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p>The accuracy of each base-learner trained with original data and with extra features added in S<sc>O</sc>/S<sc>O</sc>*, T<sc>O</sc>/T<sc>O</sc>* or S<sc>T</sc>/S<sc>T</sc>*. The values reported for each classifier are respectively the validation and test accuracies of the original representation and the new representation.</p>
          </table-wrap-foot>
        </table-wrap>
        <table-wrap position="float" id="T7">
          <label>Table 7</label>
          <caption>
            <p>The precision, recall, and <italic>FP </italic>rates of the most accurate classifiers on the test set in early integration for S1615 data set.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td align="center" colspan="3">
                  <bold>S<sc>VM</sc></bold>
                </td>
              </tr>
              <tr>
                <td/>
                <td align="center">
                  <bold>S<sc>O</sc></bold>
                </td>
                <td align="center">
                  <bold>T<sc>O</sc>*</bold>
                </td>
                <td align="center">
                  <bold>S<sc>T</sc>*</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left">
                  <bold>Precision</bold>
                </td>
                <td align="center">0.711</td>
                <td align="center">0.800</td>
                <td align="center">0.702</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>Recall</bold>
                </td>
                <td align="center">0.284</td>
                <td align="center">0.282</td>
                <td align="center">0.284</td>
              </tr>
              <tr>
                <td align="left">
                  <bold><italic>FP </italic>rate</bold>
                </td>
                <td align="center">0.015</td>
                <td align="center">0.009</td>
                <td align="center">0.016</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <fig position="float" id="F2">
          <label>Figure 2</label>
          <caption>
            <p><bold>Accuracy of the best (R.D.B) triplets in early integration for each representation of the S1615 data set</bold>. Effect of adding each extra feature to the set of original features is observed by adding each, one at a time, and combinations of two or more. S<sc>VM</sc> is the best classifier for all representations.</p>
          </caption>
          <graphic xlink:href="1472-6807-9-66-2"/>
        </fig>
      </sec>
      <sec>
        <title>Late Integration</title>
        <p>For <italic>k</italic>-<sc>NN</sc>, we choose <italic>k </italic>= 5 to give more informative posterior probabilities, rather than 0/1 decisions, to the combiner in late integration.</p>
        <p>The most accurate (<italic>R.D.B</italic>) triplet among all 102 classifier triplets is (S<sc>T</sc>.P<sc>AM</sc>C<sc>B</sc>.S<sc>VM</sc>) that denotes a support vector machine (<italic>B</italic>) trained with S<sc>T</sc>* (<italic>R</italic>) with the additional new features, P<sc>AM</sc> and packing density from <italic>C</italic><sub><italic>α </italic></sub>and <italic>C</italic><sub><italic>β </italic></sub>(D). The best complements turn out to be (T<sc>O</sc>.B<sc>FA</sc>.S<sc>VM</sc>), (S<sc>T</sc>.C<sc>B</sc>B<sc>FB</sc>.D<sc>T</sc>), and (T<sc>O</sc>.C<sc>B</sc>B<sc>FA</sc>B<sc>FB</sc>.<italic>k</italic>-<sc>NN</sc>) using the selection method of Table <xref ref-type="table" rid="T5">5</xref>. When the outputs of the <italic>(R.D.B) </italic>triplets are given to the S<sc>VM</sc> Combiner, the average accuracy is 0.903 on the test set and 0.847 on the validation set (see Table <xref ref-type="table" rid="T8">8</xref>). This accuracy is comparable to the reported values in previous studies [<xref ref-type="bibr" rid="B2">2</xref>,<xref ref-type="bibr" rid="B7">7</xref>,<xref ref-type="bibr" rid="B31">31</xref>]. Similarities between selected <italic>(R.D.B) </italic>triplets calculated by McNemar's test are given in Table <xref ref-type="table" rid="T9">9</xref>.</p>
        <table-wrap position="float" id="T8">
          <label>Table 8</label>
          <caption>
            <p>Performance of late integration of the four triplets (S<sc>T</sc>.P<sc>AM</sc>C<sc>B</sc>.S<sc>VM</sc>), (T<sc>O</sc>.B<sc>FA</sc>.S<sc>VM</sc>), (S<sc>T</sc>.C<sc>B</sc>B<sc>FB</sc>.D<sc>T</sc>), and (T<sc>O</sc>.C<sc>B</sc>B<sc>FA</sc>B<sc>FB</sc>.k-<sc>NN</sc>) for S1615 data set.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td align="center">
                  <bold>cv</bold>
                </td>
                <td align="center">
                  <bold>test</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left">
                  <bold>Accuracy</bold>
                </td>
                <td align="center">0.847</td>
                <td align="center">0.903</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>Precision</bold>
                </td>
                <td align="center">0.819</td>
                <td align="center">0.694</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>Recall</bold>
                </td>
                <td align="center">0.677</td>
                <td align="center">0.284</td>
              </tr>
              <tr>
                <td align="left">
                  <bold><italic>FP </italic>rate</bold>
                </td>
                <td align="center">0.071</td>
                <td align="center">0.017</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T9">
          <label>Table 9</label>
          <caption>
            <p>McNemar's test results for the triplets (S<sc>T</sc>.P<sc>AM</sc>C<sc>B</sc>.S<sc>VM</sc>), (T<sc>O</sc>.B<sc>FA</sc>.S<sc>VM</sc>), (S<sc>T</sc>.C<sc>B</sc>B<sc>FB</sc>.D<sc>T</sc>), and (T<sc>O</sc>.C<sc>B</sc>B<sc>FA</sc>B<sc>FB</sc>.<italic>k</italic>-<sc>NN</sc>) for S1615 data set.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td align="right">
                  <bold>(2)</bold>
                </td>
                <td align="right">
                  <bold>(3)</bold>
                </td>
                <td align="right">
                  <bold>(4)</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left">
                  <bold>(1) S<sc>T</sc>.P<sc>AM</sc>C<sc>B</sc>.S<sc>VM</sc></bold>
                </td>
                <td align="right">11.72</td>
                <td align="right">66.61</td>
                <td align="right">154.10</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>(2) T<sc>O</sc>.B<sc>FA</sc>.S<sc>VM</sc></bold>
                </td>
                <td/>
                <td align="right">42.12</td>
                <td align="right">135.64</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>(3) S<sc>T</sc>.C<sc>B</sc>B<sc>FB</sc>.D<sc>T</sc></bold>
                </td>
                <td/>
                <td/>
                <td align="right">41.32</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>(4) T<sc>O</sc>.C<sc>B</sc>B<sc>FA</sc>B<sc>FB</sc>.<italic>k</italic>-<sc>NN</sc></bold>
                </td>
                <td/>
                <td/>
                <td/>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec>
        <title>Intermediate Integration</title>
        <p>The test results for all data representations are given in Table <xref ref-type="table" rid="T10">10</xref>. We can see that adding P<sc>AM</sc> to S<sc>O</sc> does not change the accuracy because P<sc>AM</sc> is assigned zero weight; but adding extra features to T<sc>O</sc> and S<sc>T</sc> increase the average accuracy by 4.6 per cent and 6.0 per cent, respectively; both improvements are statistically significant. The highest accuracy is obtained with T<sc>O</sc>* (0.879), which however is significantly less than 0.909 of early integration.</p>
        <table-wrap position="float" id="T10">
          <label>Table 10</label>
          <caption>
            <p>Multikernel S<sc>VM</sc> test results as intermediate integration for S1615 data set.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td align="center">
                  <bold>Accuracy</bold>
                </td>
                <td align="center">
                  <bold>Precision</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc></bold>
                </td>
                <td align="center">0.872</td>
                <td align="center">0.381</td>
                <td align="center">0.176</td>
                <td align="center">0.038</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc>*
</bold>
                </td>
                <td align="center">0.872</td>
                <td align="center">0.381</td>
                <td align="center">0.176</td>
                <td align="center">0.038</td>
              </tr>
              <tr>
                <td colspan="5">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc></bold>
                </td>
                <td align="center">0.833</td>
                <td align="center">0.343</td>
                <td align="center">0.485</td>
                <td align="center">0.122</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc>*
</bold>
                </td>
                <td align="center">0.879</td>
                <td align="center">0.459</td>
                <td align="center">0.258</td>
                <td align="center">0.040</td>
              </tr>
              <tr>
                <td colspan="5">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc></bold>
                </td>
                <td align="center">0.818</td>
                <td align="center">0.311</td>
                <td align="center">0.470</td>
                <td align="center">0.137</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc>*
</bold>
                </td>
                <td align="center">0.878</td>
                <td align="center">0.448</td>
                <td align="center">0.252</td>
                <td align="center">0.041</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>The kernel weights can be used to assess the relative importance of features (see Table <xref ref-type="table" rid="T11">11</xref>). In all three representations, each feature subset except P<sc>AM</sc> has a combination weight (<italic>η</italic><sub><italic>m</italic></sub>) greater than zero. The original representations have meaningful features for classification. The weights also show that ± 3 neighbors in the sequence carry as much information as ± 1 and ± 2 neighbors. In the modified representations (S<sc>O</sc>*, T<sc>O</sc>*, and S<sc>T</sc>*), the new weights indicate that the added features, except P<sc>AM</sc>, carry information for the stability of a protein. Local spatial composition with <italic>C</italic><sub><italic>α </italic></sub>and <italic>C</italic><sub><italic>β </italic></sub>(C<sc>B</sc>) has larger weight than <italic>C</italic><sub><italic>α</italic></sub> (C<sc>A</sc>), which highlights the contribution of side-chain packing to stability. Also, the information that reflects the extent of mobility/flexibility of each <italic>C</italic><sub><italic>α </italic></sub>(B<sc>FA</sc>) and <italic>C</italic><sub><italic>β </italic></sub>(B<sc>FB</sc>) have nonzero weights, implying that they are informative.</p>
        <table-wrap position="float" id="T11">
          <label>Table 11</label>
          <caption>
            <p>The combination weights obtained for the original and modified features for S1615 data set.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc></bold>
                </td>
                <td align="left">(0.19)1<sc>NE</sc> + (0.15)2<sc>NE</sc> + (0.31)3<sc>NE</sc> + (0.30)M<sc>UT</sc> + (0.03)T + (0.03)pH</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc>*</bold>
                </td>
                <td align="left">(0.19)1<sc>NE</sc> + (0.15)2<sc>NE</sc> + (0.31)3<sc>NE</sc> + (0.30)M<sc>UT</sc> + (0.03)T + (0.03)pH + (0.00)P<sc>AM</sc></td>
              </tr>
              <tr>
                <td colspan="2">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc></bold>
                </td>
                <td align="left">(0.36)M<sc>UT</sc> + (0.40)C<sc>A</sc> + (0.15)S<sc>A</sc> + (0.04)T + (0.04)pH</td>
              </tr>
              <tr>
                <td colspan="2">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc>*</bold>
                </td>
                <td align="left">(0.21)M<sc>UT</sc> + (0.21)C<sc>A</sc> + (0.10)S<sc>A</sc> + (0.01)T + (0.01)pH + (0.00)P<sc>AM</sc> + (0.30)C<sc>B</sc> + (0.09)B<sc>FA</sc> + (0.07)B<sc>FB</sc></td>
              </tr>
              <tr>
                <td colspan="2">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc></bold>
                </td>
                <td align="left">(0.04)1<sc>NE</sc> + (0.04)2<sc>NE</sc> + (0.09)3<sc>NE</sc> + (0.38)M<sc>UT</sc> + (0.25)C<sc>A</sc> + (0.11)S<sc>A</sc> + (0.04)T + (0.04)pH</td>
              </tr>
              <tr>
                <td colspan="2">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc>*
</bold>
                </td>
                <td align="left">(0.03)1<sc>NE</sc> + (0.02)2<sc>NE</sc> + (0.06)3<sc>NE</sc> + (0.20)M<sc>UT</sc> + (0.18)C<sc>A</sc> + (0.09)S<sc>A</sc> + (0.01)T + (0.01)pH + (0.00)P<sc>AM</sc> + (0.26)C<sc>B</sc> + (0.08)B<sc>FA</sc> + (0.06)B<sc>FB</sc></td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec>
        <title>Overall Comparison of Integration Methods</title>
        <p>To be able to compare the three integration methods, in all three representations, we chose the version that has the highest average validation accuracy and compared the three. The ones chosen are given in Table <xref ref-type="table" rid="T12">12</xref> that shows the averages and standard deviations of validation and test accuracies. According to 20-fold paired <italic>t</italic>-test on the test results, there is no significant difference between early and late integration; both are significantly more accurate than intermediate integration.</p>
        <table-wrap position="float" id="T12">
          <label>Table 12</label>
          <caption>
            <p>Comparison of best of three integration methods for S1615 data set.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td align="left">
                  <bold>early</bold>
                </td>
                <td align="left">
                  <bold>late</bold>
                </td>
                <td align="left">
                  <bold>intermediate</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td/>
                <td align="left">(S<sc>T</sc>.P<sc>AM</sc>C<sc>B</sc>.S<sc>VM</sc>)</td>
                <td align="left">(S<sc>T</sc>.P<sc>AM</sc>C<sc>B</sc>.S<sc>VM</sc>) + (T<sc>O</sc>.B<sc>FA</sc>.S<sc>VM</sc>) + (S<sc>T</sc>.C<sc>B</sc>B<sc>FB</sc>.D<sc>T</sc>) + (T<sc>O</sc>.C<sc>B</sc>B<sc>FA</sc>B<sc>FB</sc>.<italic>k</italic>-<sc>NN</sc>)</td>
                <td align="left">(T<sc>O</sc>.P<sc>AM</sc>C<sc>B</sc>B<sc>FA</sc>B<sc>FB</sc>.S<sc>VM</sc>)</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>cv</bold>
                </td>
                <td align="left">0.842 ± 0.047</td>
                <td align="left">0.847 ± 0.046</td>
                <td align="left">0.826 ± 0.044</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>test</bold>
                </td>
                <td align="left">0.904 ± 0.004</td>
                <td align="left">0.903 ± 0.005</td>
                <td align="left">0.879 ± 0.006</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p>early = late &gt; intermediate according to paired <italic>t</italic>-test</p>
          </table-wrap-foot>
        </table-wrap>
      </sec>
    </sec>
    <sec>
      <title>S2783 Data Set</title>
      <sec>
        <title>Early Integration</title>
        <p>We finetune the hyperparameters by inspecting the 20-fold cv misclassification error and mean squared error for classifiers and regressors, respectively. For <italic>k</italic>-<sc>NN</sc>, <italic>k </italic>= 1 gives the most accurate cv results. Decision tree parameter, <italic>τ</italic>, is validated to be 20 in all representations. The best parameter values for S<sc>VM</sc>s are (<italic>C </italic>= 100, <italic>γ </italic>= <italic>r</italic>), (<italic>C </italic>= 10, <italic>γ </italic>= <italic>r</italic>), and (<italic>C </italic>= 100, <italic>γ </italic>= <italic>r</italic>) for S<sc>O</sc>/S<sc>O</sc>*, T<sc>O</sc>/T<sc>O</sc>*, and S<sc>T</sc>/S<sc>T</sc>*, respectively. (<italic>C </italic>= 10, <italic>γ </italic>= <italic>r</italic>) set works best for all S<sc>VR</sc> simulations but the tube width, ϵ, is selected as 0.05 or 0.10. The cv and test accuracies for each representation with different learners are given in Table <xref ref-type="table" rid="T13">13</xref>. We see that S<sc>VM</sc> and S<sc>VR</sc> clearly outperform <italic>k</italic>-<sc>NN</sc> and D<sc>T</sc> by improving accuracy more than 1.5 per cent in all three representations. When we look at the effect of adding the new features to the original representations for S<sc>VM</sc> and S<sc>VR</sc>, we see that the new features do not change the test accuracy very much. The precision, recall, and <italic>FP </italic>rate values on the test set are also listed for S<sc>VM</sc> and S<sc>VR</sc> in Table <xref ref-type="table" rid="T14">14</xref>, where we see that though S<sc>VM</sc> and S<sc>VR</sc> have comparable accuracies, S<sc>VR</sc> almost halves the <italic>FP </italic>rate, for example on S<sc>T</sc>*, it reduces from 0.078 to 0.040.</p>
        <table-wrap position="float" id="T13">
          <label>Table 13</label>
          <caption>
            <p>Early integration results for S2783 data set. </p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td align="center" colspan="2">
                  <bold><italic>k</italic>-<sc>NN</sc></bold>
                </td>
                <td align="center" colspan="2">
                  <bold>D<sc>T</sc></bold>
                </td>
                <td align="center" colspan="2">
                  <bold>S<sc>VM</sc></bold>
                </td>
                <td align="center" colspan="2">
                  <bold>S<sc>VR</sc></bold>
                </td>
              </tr>
              <tr>
                <td/>
                <td align="center">
                  <bold>cv</bold>
                </td>
                <td align="center">
                  <bold>test</bold>
                </td>
                <td align="center">
                  <bold>cv</bold>
                </td>
                <td align="center">
                  <bold>test</bold>
                </td>
                <td align="center">
                  <bold>cv</bold>
                </td>
                <td align="center">
                  <bold>test</bold>
                </td>
                <td align="center">
                  <bold>cv</bold>
                </td>
                <td align="center">
                  <bold>test</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc></bold>
                </td>
                <td align="center">0.795</td>
                <td align="center">0.794</td>
                <td align="center">0.748</td>
                <td align="center">0.762</td>
                <td align="center">0.829</td>
                <td align="center">0.832</td>
                <td align="center">0.825</td>
                <td align="center">0.828</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc>*</bold>
                </td>
                <td align="center">0.793</td>
                <td align="center">0.794</td>
                <td align="center">0.751</td>
                <td align="center">0.756</td>
                <td align="center">0.829</td>
                <td align="center">0.829</td>
                <td align="center">0.824</td>
                <td align="center">0.827</td>
              </tr>
              <tr>
                <td colspan="9">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc></bold>
                </td>
                <td align="center">0.804</td>
                <td align="center">0.803</td>
                <td align="center">0.762</td>
                <td align="center">0.769</td>
                <td align="center">0.821</td>
                <td align="center">0.824</td>
                <td align="center">0.813</td>
                <td align="center">0.818</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc>*</bold>
                </td>
                <td align="center">0.806</td>
                <td align="center">0.799</td>
                <td align="center">0.770</td>
                <td align="center">0.780</td>
                <td align="center">0.826</td>
                <td align="center">0.829</td>
                <td align="center">0.818</td>
                <td align="center">0.824</td>
              </tr>
              <tr>
                <td colspan="9">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc></bold>
                </td>
                <td align="center">0.797</td>
                <td align="center">0.797</td>
                <td align="center">0.758</td>
                <td align="center">0.766</td>
                <td align="center">0.829</td>
                <td align="center">0.831</td>
                <td align="center">0.825</td>
                <td align="center">0.828</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc>*
</bold>
                </td>
                <td align="center">0.798</td>
                <td align="center">0.797</td>
                <td align="center">0.766</td>
                <td align="center">0.782</td>
                <td align="center">0.829</td>
                <td align="center">0.830</td>
                <td align="center">0.825</td>
                <td align="center">0.828</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <p>The accuracy of each base-learner trained with original data and with extra features added in S<sc>O</sc>/S<sc>O</sc>*, T<sc>O</sc>/T<sc>O</sc>* or S<sc>T</sc>/S<sc>T</sc>*. The values reported for each classifier and regressor are respectively the validation and test accuracies of the original representation and the new representation.</p>
          </table-wrap-foot>
        </table-wrap>
        <table-wrap position="float" id="T14">
          <label>Table 14</label>
          <caption>
            <p>The precision, recall, and <italic>FP </italic>rates of the most accurate classifiers and regressors on the test set in early integration for S2783 data set.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td align="center" colspan="3">
                  <bold>S<sc>VM</sc></bold>
                </td>
                <td align="center" colspan="3">
                  <bold>S<sc>VR</sc></bold>
                </td>
              </tr>
              <tr>
                <td/>
                <td align="center">
                  <bold>S<sc>O</sc></bold>
                </td>
                <td align="center">
                  <bold>T<sc>O</sc>*</bold>
                </td>
                <td align="center">
                  <bold>S<sc>T</sc>*</bold>
                </td>
                <td align="center">
                  <bold>S<sc>O</sc></bold>
                </td>
                <td align="center">
                  <bold>T<sc>O</sc>*</bold>
                </td>
                <td align="center">
                  <bold>S<sc>T</sc>*</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left">
                  <bold>Precision</bold>
                </td>
                <td align="center">0.790</td>
                <td align="center">0.807</td>
                <td align="center">0.784</td>
                <td align="center">0.854</td>
                <td align="center">0.868</td>
                <td align="center">0.855</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>Recall</bold>
                </td>
                <td align="center">0.612</td>
                <td align="center">0.579</td>
                <td align="center">0.614</td>
                <td align="center">0.527</td>
                <td align="center">0.501</td>
                <td align="center">0.529</td>
              </tr>
              <tr>
                <td align="left">
                  <bold><italic>FP </italic>rate</bold>
                </td>
                <td align="center">0.072</td>
                <td align="center">0.061</td>
                <td align="center">0.075</td>
                <td align="center">0.040</td>
                <td align="center">0.034</td>
                <td align="center">0.040</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec>
        <title>Late Integration</title>
        <p>First, 102 classifiers trained on S2873 data set are combined with the procedure explained in Table <xref ref-type="table" rid="T5">5</xref>. We obtain the average accuracy as 0.832 on the test set and 0.830 on the validation set (see Table <xref ref-type="table" rid="T15">15</xref>). Then, we combine 34 regressors trained, the average test set accuracy is 0.827 and the average validation accuracy is 0.819. Again, we see that in terms of accuracy, S<sc>VM</sc> and S<sc>VR</sc> are comparable, though the latter has higher precision and lower <italic>FP </italic>rate.</p>
        <table-wrap position="float" id="T15">
          <label>Table 15</label>
          <caption>
            <p>Performance of late integration for S2783 data set.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td align="center" colspan="2">
                  <bold>S<sc>VM</sc></bold>
                </td>
                <td align="center" colspan="2">
                  <bold>S<sc>VR</sc></bold>
                </td>
              </tr>
              <tr>
                <td/>
                <td align="center">
                  <bold>cv</bold>
                </td>
                <td align="center">
                  <bold>test</bold>
                </td>
                <td align="center">
                  <bold>cv</bold>
                </td>
                <td align="center">
                  <bold>Test</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left">
                  <bold>Accuracy</bold>
                </td>
                <td align="center">0.830</td>
                <td align="center">0.832</td>
                <td align="center">0.819</td>
                <td align="center">0.827</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>Precision</bold>
                </td>
                <td align="center">0.795</td>
                <td align="center">0.790</td>
                <td align="center">0.853</td>
                <td align="center">0.858</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>Recall</bold>
                </td>
                <td align="center">0.604</td>
                <td align="center">0.615</td>
                <td align="center">0.495</td>
                <td align="center">0.520</td>
              </tr>
              <tr>
                <td align="left">
                  <bold><italic>FP </italic>rate</bold>
                </td>
                <td align="center">0.071</td>
                <td align="center">0.073</td>
                <td align="center">0.038</td>
                <td align="center">0.038</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec>
        <title>Intermediate Integration</title>
        <p>The test results for all data representations using multikernel S<sc>VM</sc> and S<sc>VR</sc> are given in Table <xref ref-type="table" rid="T16">16</xref>. When we use multikernel S<sc>VM</sc>, we can see that adding extra features does not change accuracy. The highest accuracy is obtained with S<sc>T</sc> (0.806), which however is less than 0.832 of early integration. Using extra features in multikernel S<sc>VR</sc> does not help increase the accuracy either. The best accuracy performance is obtained with T<sc>O</sc> as 0.797.</p>
        <table-wrap position="float" id="T16">
          <label>Table 16</label>
          <caption>
            <p>Multikernel S<sc>VM</sc> and S<sc>VR</sc> test results as intermediate integration for S2783 data set.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td align="center" colspan="4">
                  <bold>S<sc>VM</sc></bold>
                </td>
                <td align="center" colspan="4">
                  <bold>S<sc>VR</sc></bold>
                </td>
              </tr>
              <tr>
                <td/>
                <td align="center">
                  <bold>Accuracy</bold>
                </td>
                <td align="center">
                  <bold>Precision</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
                <td align="center">
                  <bold>Accuracy</bold>
                </td>
                <td align="center">
                  <bold>Precision</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc></bold>
                </td>
                <td align="center">0.800</td>
                <td align="center">0.716</td>
                <td align="center">0.589</td>
                <td align="center">0.107</td>
                <td align="center">0.789</td>
                <td align="center">0.688</td>
                <td align="center">0.570</td>
                <td align="center">0.115</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc>*</bold>
                </td>
                <td align="center">0.799</td>
                <td align="center">0.708</td>
                <td align="center">0.604</td>
                <td align="center">0.114</td>
                <td align="center">0.790</td>
                <td align="center">0.692</td>
                <td align="center">0.569</td>
                <td align="center">0.113</td>
              </tr>
              <tr>
                <td colspan="9">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc></bold>
                </td>
                <td align="center">0.805</td>
                <td align="center">0.710</td>
                <td align="center">0.621</td>
                <td align="center">0.113</td>
                <td align="center">0.797</td>
                <td align="center">0.705</td>
                <td align="center">0.580</td>
                <td align="center">0.107</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc>*
</bold>
                </td>
                <td align="center">0.802</td>
                <td align="center">0.697</td>
                <td align="center">0.629</td>
                <td align="center">0.122</td>
                <td align="center">0.792</td>
                <td align="center">0.677</td>
                <td align="center">0.611</td>
                <td align="center">0.129</td>
              </tr>
              <tr>
                <td colspan="9">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc></bold>
                </td>
                <td align="center">0.806</td>
                <td align="center">0.705</td>
                <td align="center">0.636</td>
                <td align="center">0.119</td>
                <td align="center">0.793</td>
                <td align="center">0.681</td>
                <td align="center">0.607</td>
                <td align="center">0.126</td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc>*
</bold>
                </td>
                <td align="center">0.804</td>
                <td align="center">0.700</td>
                <td align="center">0.633</td>
                <td align="center">0.121</td>
                <td align="center">0.789</td>
                <td align="center">0.671</td>
                <td align="center">0.610</td>
                <td align="center">0.132</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>When we look at Tables <xref ref-type="table" rid="T17">17</xref> and <xref ref-type="table" rid="T18">18</xref>, we can say that the added features carry information for predicting the energy change for single-site mutations even though they do not improve the average testing accuracy. As in S1615 data set, local spatial composition with <italic>C</italic><sub><italic>α </italic></sub>and <italic>C</italic><sub><italic>β </italic></sub>(C<sc>B</sc>) has larger weight than <italic>C</italic><sub><italic>α </italic></sub>(C<sc>A</sc>) and the information that reflects the extent of mobility/flexibility of each <italic>C</italic><sub><italic>α </italic></sub>(B<sc>FA</sc>) and <italic>C</italic><sub><italic>β </italic></sub>(B<sc>FB</sc>) has nonzero weights.</p>
        <table-wrap position="float" id="T17">
          <label>Table 17</label>
          <caption>
            <p>The combination weights obtained with S<sc>VM</sc> for the original and modified features for S2783 data set.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc></bold>
                </td>
                <td align="left">(0.19)1<sc>NE</sc> + (0.20)2<sc>NE</sc> + (0.23)3<sc>NE</sc> + (0.27)M<sc>UT</sc> + (0.09)T + (0.03)pH</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc>*</bold>
                </td>
                <td align="left">(0.19)1<sc>NE</sc> + (0.20)2<sc>NE</sc> + (0.22)3<sc>NE</sc> + (0.27)M<sc>UT</sc> + (0.09)T + (0.03)pH + (0.00)P<sc>AM</sc></td>
              </tr>
              <tr>
                <td colspan="2">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc></bold>
                </td>
                <td align="left">(0.19)M<sc>UT</sc> + (0.56)C<sc>A</sc> + (0.17)S<sc>A</sc> + (0.05)T + (0.02)pH</td>
              </tr>
              <tr>
                <td colspan="2">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc>*
</bold>
                </td>
                <td align="left">(0.21)M<sc>UT</sc> + (0.23)C<sc>A</sc> + (0.12)S<sc>A</sc> + (0.06)T + (0.02)pH + (0.00)P<sc>AM</sc> + (0.23)C<sc>B</sc> + (0.07)B<sc>FA</sc> + (0.06)B<sc>FB</sc></td>
              </tr>
              <tr>
                <td colspan="2">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc></bold>
                </td>
                <td align="left">(0.04)1<sc>NE</sc> + (0.03)2<sc>NE</sc> + (0.04)3<sc>NE</sc> + (0.21)M<sc>UT</sc> + (0.45)C<sc>A</sc> + (0.15)S<sc>A</sc> + (0.06)T + (0.02)pH</td>
              </tr>
              <tr>
                <td colspan="2">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc>*</bold>
                </td>
                <td align="left">(0.02)1<sc>NE</sc> + (0.02)2<sc>NE</sc> + (0.03)3<sc>NE</sc> + (0.21)M<sc>UT</sc> + (0.21)C<sc>A</sc> + (0.11)S<sc>A</sc> + (0.06)T + (0.02)pH + (0.00)P<sc>AM</sc> + (0.19)C<sc>B</sc> + (0.06)B<sc>FA</sc> + (0.06)B<sc>FB</sc></td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T18">
          <label>Table 18</label>
          <caption>
            <p>The combination weights obtained with S<sc>VR</sc> for the original and modified features for S2783 data set.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc></bold>
                </td>
                <td align="left">(0.15)1<sc>NE</sc>+ (0.25)2<sc>NE</sc>+ (0.22)3<sc>NE</sc>+ (0.31)M<sc>UT</sc> + (0.04)T + (0.02)pH</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left">
                  <bold>S<sc>O</sc>*</bold>
                </td>
                <td align="left">(0.16)1<sc>NE</sc>+ (0.26)2<sc>NE</sc>+ (0.22)3<sc>NE</sc>+ (0.29)M<sc>UT</sc> + (0.05)T + (0.01)pH + (0.01)P<sc>AM</sc></td>
              </tr>
              <tr>
                <td colspan="2">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc></bold>
                </td>
                <td align="left">(0.25)M<sc>UT</sc> + (0.72)C<sc>A</sc> + (0.02)S<sc>A</sc> + (0.01)T + (0.00)pH</td>
              </tr>
              <tr>
                <td colspan="2">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>T<sc>O</sc>*
</bold>
                </td>
                <td align="left">(0.28)M<sc>UT</sc> + (0.10)C<sc>A</sc> + (0.05)S<sc>A</sc> + (0.08)T + (0.03)pH + (0.01)P<sc>AM</sc> + (0.43)C<sc>B</sc> + (0.01)B<sc>FA</sc> + (0.01)B<sc>FB</sc></td>
              </tr>
              <tr>
                <td colspan="2">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc></bold>
                </td>
                <td align="left">(0.02)1<sc>NE</sc>+ (0.02)2<sc>NE</sc>+ (0.02)3<sc>NE</sc>+ (0.26)M<sc>UT</sc> + (0.57)C<sc>A</sc> + (0.04)S<sc>A</sc> + (0.07)T + (0.03)pH</td>
              </tr>
              <tr>
                <td colspan="2">
                  <hr/>
                </td>
              </tr>
              <tr>
                <td align="left">
                  <bold>S<sc>T</sc>*</bold>
                </td>
                <td align="left">(0.01)1<sc>NE</sc>+ (0.01)2<sc>NE</sc>+ (0.01)3<sc>NE</sc>+ (0.30)M<sc>UT</sc> + (0.10)C<sc>A</sc> + (0.06)S<sc>A</sc> + (0.07)T + (0.01)pH + (0.00)P<sc>AM</sc> + (0.43)C<sc>B</sc> + (0.01)B<sc>FA</sc> + (0.01)B<sc>FB</sc></td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec>
        <title>Classification with Reject Option</title>
        <p>We also perform simulations with reject option both for classification and regression, and give the performance measures obtained with early integration using S<sc>O</sc> (see Tables <xref ref-type="table" rid="T19">19</xref> and <xref ref-type="table" rid="T20">20</xref>), late integration (see Tables <xref ref-type="table" rid="T21">21</xref> and <xref ref-type="table" rid="T22">22</xref>), and intermediate integration using T<sc>O</sc>* (see Tables <xref ref-type="table" rid="T23">23</xref> and <xref ref-type="table" rid="T24">24</xref>), respectively. We see that increasing <italic>λ </italic>and <italic>α </italic>values increases the accuracy of predictors and decreases <italic>FP </italic>rate at the cost of rejecting some instances. The selection of <italic>λ </italic>and <italic>α </italic>values is of crucial importance and depends on the loss incurred for making wrong decisions. Figures <xref ref-type="fig" rid="F3">3</xref> and <xref ref-type="fig" rid="F4">4</xref> show <italic>FP </italic>rate and rejection rate values for all integration approaches using S<sc>VM</sc> and S<sc>VR</sc> with the tried (<italic>λ</italic>, <italic>α</italic>) pairs. We see that using late integration for S<sc>VM</sc> case generally gives lower rejection rate than early and intermediate integration for a given <italic>FP </italic>rate; S<sc>VR</sc> can attain much lower <italic>FP </italic>rate but needs to reject more.</p>
        <table-wrap position="float" id="T19">
          <label>Table 19</label>
          <caption>
            <p>Performance measures of S<sc>VM</sc> early integration (S<sc>O</sc>) for S2783 data set with reject option.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td/>
                <td align="center" colspan="5">
                  <bold>cv</bold>
                </td>
                <td align="center" colspan="5">
                  <bold>test</bold>
                </td>
              </tr>
              <tr>
                <td align="center">
                  <bold>
                    <italic>λ</italic>
                  </bold>
                </td>
                <td align="center">
                  <bold>
                    <italic>α</italic>
                  </bold>
                </td>
                <td align="center">
                  <bold>Acc.</bold>
                </td>
                <td align="center">
                  <bold>Prec.</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
                <td align="center">
                  <bold>Reject</bold>
                </td>
                <td align="center">
                  <bold>Acc.</bold>
                </td>
                <td align="center">
                  <bold>Prec.</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
                <td align="center">
                  <bold>Reject</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center">2</td>
                <td align="center">1</td>
                <td align="center">0.829</td>
                <td align="center">0.793</td>
                <td align="center">0.602</td>
                <td align="center">0.071</td>
                <td align="center">0.000</td>
                <td align="center">0.831</td>
                <td align="center">0.788</td>
                <td align="center">0.615</td>
                <td align="center">0.073</td>
                <td align="center">0.000</td>
              </tr>
              <tr>
                <td align="center">2</td>
                <td align="center">2</td>
                <td align="center">0.834</td>
                <td align="center">0.813</td>
                <td align="center">0.582</td>
                <td align="center">0.059</td>
                <td align="center">0.024</td>
                <td align="center">0.839</td>
                <td align="center">0.816</td>
                <td align="center">0.596</td>
                <td align="center">0.058</td>
                <td align="center">0.025</td>
              </tr>
              <tr>
                <td align="center">2</td>
                <td align="center">5</td>
                <td align="center">0.840</td>
                <td align="center">0.839</td>
                <td align="center">0.544</td>
                <td align="center">0.043</td>
                <td align="center">0.059</td>
                <td align="center">0.845</td>
                <td align="center">0.844</td>
                <td align="center">0.560</td>
                <td align="center">0.042</td>
                <td align="center">0.060</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">1</td>
                <td align="center">0.842</td>
                <td align="center">0.815</td>
                <td align="center">0.599</td>
                <td align="center">0.058</td>
                <td align="center">0.064</td>
                <td align="center">0.847</td>
                <td align="center">0.821</td>
                <td align="center">0.615</td>
                <td align="center">0.057</td>
                <td align="center">0.066</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">2</td>
                <td align="center">0.848</td>
                <td align="center">0.839</td>
                <td align="center">0.569</td>
                <td align="center">0.044</td>
                <td align="center">0.092</td>
                <td align="center">0.852</td>
                <td align="center">0.844</td>
                <td align="center">0.587</td>
                <td align="center">0.044</td>
                <td align="center">0.094</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">5</td>
                <td align="center">0.854</td>
                <td align="center">0.871</td>
                <td align="center">0.531</td>
                <td align="center">0.029</td>
                <td align="center">0.122</td>
                <td align="center">0.857</td>
                <td align="center">0.874</td>
                <td align="center">0.545</td>
                <td align="center">0.030</td>
                <td align="center">0.127</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">1</td>
                <td align="center">0.884</td>
                <td align="center">0.839</td>
                <td align="center">0.735</td>
                <td align="center">0.058</td>
                <td align="center">0.298</td>
                <td align="center">0.884</td>
                <td align="center">0.844</td>
                <td align="center">0.743</td>
                <td align="center">0.058</td>
                <td align="center">0.303</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">2</td>
                <td align="center">0.891</td>
                <td align="center">0.863</td>
                <td align="center">0.712</td>
                <td align="center">0.043</td>
                <td align="center">0.322</td>
                <td align="center">0.892</td>
                <td align="center">0.870</td>
                <td align="center">0.717</td>
                <td align="center">0.042</td>
                <td align="center">0.329</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">5</td>
                <td align="center">0.897</td>
                <td align="center">0.863</td>
                <td align="center">0.621</td>
                <td align="center">0.028</td>
                <td align="center">0.364</td>
                <td align="center">0.894</td>
                <td align="center">0.885</td>
                <td align="center">0.620</td>
                <td align="center">0.031</td>
                <td align="center">0.371</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T20">
          <label>Table 20</label>
          <caption>
            <p>Performance measures of S<sc>VR</sc> early integration (S<sc>O</sc>) for S2783 data set with reject option.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td/>
                <td align="center" colspan="5">
                  <bold>cv</bold>
                </td>
                <td align="center" colspan="5">
                  <bold>test</bold>
                </td>
              </tr>
              <tr>
                <td align="center">
                  <bold>
                    <italic>λ</italic>
                  </bold>
                </td>
                <td align="center">
                  <bold>
                    <italic>α</italic>
                  </bold>
                </td>
                <td align="center">
                  <bold>Acc.</bold>
                </td>
                <td align="center">
                  <bold>Prec.</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
                <td align="center">
                  <bold>Reject</bold>
                </td>
                <td align="center">
                  <bold>Acc.</bold>
                </td>
                <td align="center">
                  <bold>Prec.</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
                <td align="center">
                  <bold>Reject</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center">2</td>
                <td align="center">1</td>
                <td align="center">0.835</td>
                <td align="center">0.862</td>
                <td align="center">0.538</td>
                <td align="center">0.038</td>
                <td align="center">0.020</td>
                <td align="center">0.836</td>
                <td align="center">0.859</td>
                <td align="center">0.544</td>
                <td align="center">0.039</td>
                <td align="center">0.019</td>
              </tr>
              <tr>
                <td align="center">2</td>
                <td align="center">2</td>
                <td align="center">0.838</td>
                <td align="center">0.883</td>
                <td align="center">0.519</td>
                <td align="center">0.030</td>
                <td align="center">0.038</td>
                <td align="center">0.839</td>
                <td align="center">0.878</td>
                <td align="center">0.526</td>
                <td align="center">0.031</td>
                <td align="center">0.036</td>
              </tr>
              <tr>
                <td align="center">2</td>
                <td align="center">5</td>
                <td align="center">0.839</td>
                <td align="center">0.947</td>
                <td align="center">0.280</td>
                <td align="center">0.003</td>
                <td align="center">0.147</td>
                <td align="center">0.839</td>
                <td align="center">0.963</td>
                <td align="center">0.278</td>
                <td align="center">0.004</td>
                <td align="center">0.149</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">1</td>
                <td align="center">0.931</td>
                <td align="center">0.894</td>
                <td align="center">0.887</td>
                <td align="center">0.051</td>
                <td align="center">0.513</td>
                <td align="center">0.926</td>
                <td align="center">0.886</td>
                <td align="center">0.880</td>
                <td align="center">0.054</td>
                <td align="center">0.516</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">2</td>
                <td align="center">0.952</td>
                <td align="center">0.947</td>
                <td align="center">0.750</td>
                <td align="center">0.007</td>
                <td align="center">0.608</td>
                <td align="center">0.947</td>
                <td align="center">0.963</td>
                <td align="center">0.743</td>
                <td align="center">0.010</td>
                <td align="center">0.612</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">5</td>
                <td align="center">0.954</td>
                <td align="center">0.857</td>
                <td align="center">0.571</td>
                <td align="center">0.001</td>
                <td align="center">0.640</td>
                <td align="center">0.949</td>
                <td align="center">0.997</td>
                <td align="center">0.530</td>
                <td align="center">0.000</td>
                <td align="center">0.646</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">1</td>
                <td align="center">0.966</td>
                <td align="center">0.947</td>
                <td align="center">0.827</td>
                <td align="center">0.008</td>
                <td align="center">0.656</td>
                <td align="center">0.961</td>
                <td align="center">0.963</td>
                <td align="center">0.826</td>
                <td align="center">0.010</td>
                <td align="center">0.658</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">2</td>
                <td align="center">0.968</td>
                <td align="center">0.913</td>
                <td align="center">0.749</td>
                <td align="center">0.003</td>
                <td align="center">0.677</td>
                <td align="center">0.963</td>
                <td align="center">0.976</td>
                <td align="center">0.749</td>
                <td align="center">0.006</td>
                <td align="center">0.678</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">5</td>
                <td align="center">0.969</td>
                <td align="center">0.775</td>
                <td align="center">0.586</td>
                <td align="center">0.000</td>
                <td align="center">0.695</td>
                <td align="center">0.965</td>
                <td align="center">0.999</td>
                <td align="center">0.566</td>
                <td align="center">0.000</td>
                <td align="center">0.699</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T21">
          <label>Table 21</label>
          <caption>
            <p>Performance measures of S<sc>VM</sc> late integration for S2783 data set with reject option.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td/>
                <td align="center" colspan="5">
                  <bold>cv</bold>
                </td>
                <td align="center" colspan="5">
                  <bold>test</bold>
                </td>
              </tr>
              <tr>
                <td align="center">
                  <bold>
                    <italic>λ</italic>
                  </bold>
                </td>
                <td align="center">
                  <bold>
                    <italic>α</italic>
                  </bold>
                </td>
                <td align="center">
                  <bold>Acc.</bold>
                </td>
                <td align="center">
                  <bold>Prec.</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
                <td align="center">
                  <bold>Reject</bold>
                </td>
                <td align="center">
                  <bold>Acc.</bold>
                </td>
                <td align="center">
                  <bold>Prec.</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
                <td align="center">
                  <bold>Reject</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center">2</td>
                <td align="center">1</td>
                <td align="center">0.829</td>
                <td align="center">0.792</td>
                <td align="center">0.606</td>
                <td align="center">0.072</td>
                <td align="center">0.000</td>
                <td align="center">0.831</td>
                <td align="center">0.787</td>
                <td align="center">0.617</td>
                <td align="center">0.074</td>
                <td align="center">0.000</td>
              </tr>
              <tr>
                <td align="center">2</td>
                <td align="center">2</td>
                <td align="center">0.833</td>
                <td align="center">0.806</td>
                <td align="center">0.597</td>
                <td align="center">0.064</td>
                <td align="center">0.012</td>
                <td align="center">0.836</td>
                <td align="center">0.804</td>
                <td align="center">0.609</td>
                <td align="center">0.065</td>
                <td align="center">0.013</td>
              </tr>
              <tr>
                <td align="center">2</td>
                <td align="center">5</td>
                <td align="center">0.838</td>
                <td align="center">0.825</td>
                <td align="center">0.581</td>
                <td align="center">0.054</td>
                <td align="center">0.031</td>
                <td align="center">0.840</td>
                <td align="center">0.820</td>
                <td align="center">0.594</td>
                <td align="center">0.056</td>
                <td align="center">0.030</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">1</td>
                <td align="center">0.839</td>
                <td align="center">0.812</td>
                <td align="center">0.609</td>
                <td align="center">0.062</td>
                <td align="center">0.032</td>
                <td align="center">0.841</td>
                <td align="center">0.808</td>
                <td align="center">0.621</td>
                <td align="center">0.064</td>
                <td align="center">0.035</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">2</td>
                <td align="center">0.842</td>
                <td align="center">0.825</td>
                <td align="center">0.595</td>
                <td align="center">0.055</td>
                <td align="center">0.048</td>
                <td align="center">0.844</td>
                <td align="center">0.820</td>
                <td align="center">0.610</td>
                <td align="center">0.057</td>
                <td align="center">0.049</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">5</td>
                <td align="center">0.847</td>
                <td align="center">0.845</td>
                <td align="center">0.566</td>
                <td align="center">0.043</td>
                <td align="center">0.073</td>
                <td align="center">0.849</td>
                <td align="center">0.844</td>
                <td align="center">0.582</td>
                <td align="center">0.045</td>
                <td align="center">0.076</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">1</td>
                <td align="center">0.849</td>
                <td align="center">0.825</td>
                <td align="center">0.618</td>
                <td align="center">0.056</td>
                <td align="center">0.072</td>
                <td align="center">0.851</td>
                <td align="center">0.820</td>
                <td align="center">0.634</td>
                <td align="center">0.058</td>
                <td align="center">0.075</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">2</td>
                <td align="center">0.852</td>
                <td align="center">0.837</td>
                <td align="center">0.599</td>
                <td align="center">0.048</td>
                <td align="center">0.089</td>
                <td align="center">0.856</td>
                <td align="center">0.837</td>
                <td align="center">0.617</td>
                <td align="center">0.049</td>
                <td align="center">0.094</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">5</td>
                <td align="center">0.859</td>
                <td align="center">0.836</td>
                <td align="center">0.492</td>
                <td align="center">0.027</td>
                <td align="center">0.147</td>
                <td align="center">0.861</td>
                <td align="center">0.866</td>
                <td align="center">0.507</td>
                <td align="center">0.029</td>
                <td align="center">0.154</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T22">
          <label>Table 22</label>
          <caption>
            <p>Performance measures of S<sc>VR</sc> late integration for S2783 data set with reject option.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td/>
                <td align="center" colspan="5">
                  <bold>cv</bold>
                </td>
                <td align="center" colspan="5">
                  <bold>test</bold>
                </td>
              </tr>
              <tr>
                <td align="center">
                  <bold>
                    <italic>λ</italic>
                  </bold>
                </td>
                <td align="center">
                  <bold>
                    <italic>α</italic>
                  </bold>
                </td>
                <td align="center">
                  <bold>Acc.</bold>
                </td>
                <td align="center">
                  <bold>Prec.</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
                <td align="center">
                  <bold>Reject</bold>
                </td>
                <td align="center">
                  <bold>Acc.</bold>
                </td>
                <td align="center">
                  <bold>Prec.</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
                <td align="center">
                  <bold>Reject</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center">2</td>
                <td align="center">1</td>
                <td align="center">0.828</td>
                <td align="center">0.862</td>
                <td align="center">0.512</td>
                <td align="center">0.036</td>
                <td align="center">0.021</td>
                <td align="center">0.834</td>
                <td align="center">0.862</td>
                <td align="center">0.532</td>
                <td align="center">0.037</td>
                <td align="center">0.019</td>
              </tr>
              <tr>
                <td align="center">2</td>
                <td align="center">2</td>
                <td align="center">0.834</td>
                <td align="center">0.907</td>
                <td align="center">0.472</td>
                <td align="center">0.021</td>
                <td align="center">0.053</td>
                <td align="center">0.837</td>
                <td align="center">0.897</td>
                <td align="center">0.484</td>
                <td align="center">0.023</td>
                <td align="center">0.056</td>
              </tr>
              <tr>
                <td align="center">2</td>
                <td align="center">5</td>
                <td align="center">0.833</td>
                <td align="center">0.961</td>
                <td align="center">0.327</td>
                <td align="center">0.005</td>
                <td align="center">0.123</td>
                <td align="center">0.838</td>
                <td align="center">0.963</td>
                <td align="center">0.328</td>
                <td align="center">0.005</td>
                <td align="center">0.130</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">1</td>
                <td align="center">0.938</td>
                <td align="center">0.916</td>
                <td align="center">0.856</td>
                <td align="center">0.032</td>
                <td align="center">0.474</td>
                <td align="center">0.940</td>
                <td align="center">0.909</td>
                <td align="center">0.865</td>
                <td align="center">0.033</td>
                <td align="center">0.477</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">2</td>
                <td align="center">0.949</td>
                <td align="center">0.961</td>
                <td align="center">0.770</td>
                <td align="center">0.009</td>
                <td align="center">0.535</td>
                <td align="center">0.952</td>
                <td align="center">0.963</td>
                <td align="center">0.779</td>
                <td align="center">0.009</td>
                <td align="center">0.541</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">5</td>
                <td align="center">0.952</td>
                <td align="center">0.937</td>
                <td align="center">0.620</td>
                <td align="center">0.001</td>
                <td align="center">0.570</td>
                <td align="center">0.953</td>
                <td align="center">0.979</td>
                <td align="center">0.630</td>
                <td align="center">0.003</td>
                <td align="center">0.575</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">1</td>
                <td align="center">0.966</td>
                <td align="center">0.961</td>
                <td align="center">0.872</td>
                <td align="center">0.010</td>
                <td align="center">0.604</td>
                <td align="center">0.965</td>
                <td align="center">0.963</td>
                <td align="center">0.860</td>
                <td align="center">0.010</td>
                <td align="center">0.606</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">2</td>
                <td align="center">0.970</td>
                <td align="center">0.936</td>
                <td align="center">0.757</td>
                <td align="center">0.001</td>
                <td align="center">0.638</td>
                <td align="center">0.966</td>
                <td align="center">0.977</td>
                <td align="center">0.748</td>
                <td align="center">0.004</td>
                <td align="center">0.638</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">5</td>
                <td align="center">0.970</td>
                <td align="center">0.860</td>
                <td align="center">0.660</td>
                <td align="center">0.000</td>
                <td align="center">0.652</td>
                <td align="center">0.967</td>
                <td align="center">0.984</td>
                <td align="center">0.675</td>
                <td align="center">0.002</td>
                <td align="center">0.652</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T23">
          <label>Table 23</label>
          <caption>
            <p>Performance measures of S<sc>VM</sc> intermediate integration (T<sc>O</sc>*) for S2783 data set with reject option.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td/>
                <td align="center" colspan="5">
                  <bold>cv</bold>
                </td>
                <td align="center" colspan="5">
                  <bold>test</bold>
                </td>
              </tr>
              <tr>
                <td align="center">
                  <bold>
                    <italic>λ</italic>
                  </bold>
                </td>
                <td align="center">
                  <bold>
                    <italic>α</italic>
                  </bold>
                </td>
                <td align="center">
                  <bold>Acc.</bold>
                </td>
                <td align="center">
                  <bold>Prec.</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
                <td align="center">
                  <bold>Reject</bold>
                </td>
                <td align="center">
                  <bold>Acc.</bold>
                </td>
                <td align="center">
                  <bold>Prec.</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
                <td align="center">
                  <bold>Reject</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center">2</td>
                <td align="center">1</td>
                <td align="center">0.807</td>
                <td align="center">0.712</td>
                <td align="center">0.632</td>
                <td align="center">0.116</td>
                <td align="center">0.000</td>
                <td align="center">0.802</td>
                <td align="center">0.693</td>
                <td align="center">0.636</td>
                <td align="center">0.124</td>
                <td align="center">0.000</td>
              </tr>
              <tr>
                <td align="center">2</td>
                <td align="center">2</td>
                <td align="center">0.823</td>
                <td align="center">0.755</td>
                <td align="center">0.598</td>
                <td align="center">0.083</td>
                <td align="center">0.051</td>
                <td align="center">0.822</td>
                <td align="center">0.749</td>
                <td align="center">0.603</td>
                <td align="center">0.086</td>
                <td align="center">0.055</td>
              </tr>
              <tr>
                <td align="center">2</td>
                <td align="center">5</td>
                <td align="center">0.836</td>
                <td align="center">0.802</td>
                <td align="center">0.540</td>
                <td align="center">0.053</td>
                <td align="center">0.108</td>
                <td align="center">0.837</td>
                <td align="center">0.804</td>
                <td align="center">0.548</td>
                <td align="center">0.052</td>
                <td align="center">0.112</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">1</td>
                <td align="center">0.851</td>
                <td align="center">0.769</td>
                <td align="center">0.678</td>
                <td align="center">0.082</td>
                <td align="center">0.165</td>
                <td align="center">0.849</td>
                <td align="center">0.765</td>
                <td align="center">0.679</td>
                <td align="center">0.084</td>
                <td align="center">0.168</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">2</td>
                <td align="center">0.862</td>
                <td align="center">0.802</td>
                <td align="center">0.636</td>
                <td align="center">0.058</td>
                <td align="center">0.207</td>
                <td align="center">0.862</td>
                <td align="center">0.804</td>
                <td align="center">0.639</td>
                <td align="center">0.058</td>
                <td align="center">0.211</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">5</td>
                <td align="center">0.874</td>
                <td align="center">0.725</td>
                <td align="center">0.357</td>
                <td align="center">0.022</td>
                <td align="center">0.309</td>
                <td align="center">0.872</td>
                <td align="center">0.796</td>
                <td align="center">0.351</td>
                <td align="center">0.021</td>
                <td align="center">0.318</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">1</td>
                <td align="center">0.878</td>
                <td align="center">0.802</td>
                <td align="center">0.717</td>
                <td align="center">0.066</td>
                <td align="center">0.300</td>
                <td align="center">0.879</td>
                <td align="center">0.804</td>
                <td align="center">0.728</td>
                <td align="center">0.065</td>
                <td align="center">0.308</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">2</td>
                <td align="center">0.891</td>
                <td align="center">0.787</td>
                <td align="center">0.550</td>
                <td align="center">0.034</td>
                <td align="center">0.372</td>
                <td align="center">0.892</td>
                <td align="center">0.813</td>
                <td align="center">0.562</td>
                <td align="center">0.034</td>
                <td align="center">0.383</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">5</td>
                <td align="center">0.898</td>
                <td align="center">0.399</td>
                <td align="center">0.224</td>
                <td align="center">0.013</td>
                <td align="center">0.436</td>
                <td align="center">0.899</td>
                <td align="center">0.579</td>
                <td align="center">0.244</td>
                <td align="center">0.012</td>
                <td align="center">0.445</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T24">
          <label>Table 24</label>
          <caption>
            <p>Performance measures of S<sc>VR</sc> intermediate integration (T<sc>O</sc>) for S2783 data set with reject option.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead>
              <tr>
                <td/>
                <td/>
                <td align="center" colspan="5">
                  <bold>cv</bold>
                </td>
                <td align="center" colspan="5">
                  <bold>test</bold>
                </td>
              </tr>
              <tr>
                <td align="center">
                  <bold>
                    <italic>λ</italic>
                  </bold>
                </td>
                <td align="center">
                  <bold>
                    <italic>α</italic>
                  </bold>
                </td>
                <td align="center">
                  <bold>Acc.</bold>
                </td>
                <td align="center">
                  <bold>Prec.</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
                <td align="center">
                  <bold>Reject</bold>
                </td>
                <td align="center">
                  <bold>Acc.</bold>
                </td>
                <td align="center">
                  <bold>Prec.</bold>
                </td>
                <td align="center">
                  <bold>Recall</bold>
                </td>
                <td align="center">
                  <bold><italic>FP </italic>Rate</bold>
                </td>
                <td align="center">
                  <bold>Reject</bold>
                </td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center">2</td>
                <td align="center">1</td>
                <td align="center">0.810</td>
                <td align="center">0.723</td>
                <td align="center">0.595</td>
                <td align="center">0.099</td>
                <td align="center">0.035</td>
                <td align="center">0.808</td>
                <td align="center">0.715</td>
                <td align="center">0.596</td>
                <td align="center">0.102</td>
                <td align="center">0.037</td>
              </tr>
              <tr>
                <td align="center">2</td>
                <td align="center">2</td>
                <td align="center">0.839</td>
                <td align="center">0.843</td>
                <td align="center">0.405</td>
                <td align="center">0.026</td>
                <td align="center">0.177</td>
                <td align="center">0.840</td>
                <td align="center">0.855</td>
                <td align="center">0.393</td>
                <td align="center">0.024</td>
                <td align="center">0.185</td>
              </tr>
              <tr>
                <td align="center">2</td>
                <td align="center">5</td>
                <td align="center">0.843</td>
                <td align="center">0.589</td>
                <td align="center">0.101</td>
                <td align="center">0.001</td>
                <td align="center">0.258</td>
                <td align="center">0.841</td>
                <td align="center">0.946</td>
                <td align="center">0.103</td>
                <td align="center">0.003</td>
                <td align="center">0.260</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">1</td>
                <td align="center">0.918</td>
                <td align="center">0.887</td>
                <td align="center">0.629</td>
                <td align="center">0.021</td>
                <td align="center">0.505</td>
                <td align="center">0.917</td>
                <td align="center">0.889</td>
                <td align="center">0.615</td>
                <td align="center">0.022</td>
                <td align="center">0.515</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">2</td>
                <td align="center">0.926</td>
                <td align="center">0.589</td>
                <td align="center">0.275</td>
                <td align="center">0.002</td>
                <td align="center">0.555</td>
                <td align="center">0.924</td>
                <td align="center">0.946</td>
                <td align="center">0.268</td>
                <td align="center">0.004</td>
                <td align="center">0.562</td>
              </tr>
              <tr>
                <td align="center">5</td>
                <td align="center">5</td>
                <td align="center">0.926</td>
                <td align="center">0.310</td>
                <td align="center">0.127</td>
                <td align="center">0.000</td>
                <td align="center">0.565</td>
                <td align="center">0.925</td>
                <td align="center">0.877</td>
                <td align="center">0.125</td>
                <td align="center">0.001</td>
                <td align="center">0.573</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">1</td>
                <td align="center">0.961</td>
                <td align="center">0.589</td>
                <td align="center">0.436</td>
                <td align="center">0.003</td>
                <td align="center">0.698</td>
                <td align="center">0.952</td>
                <td align="center">0.946</td>
                <td align="center">0.458</td>
                <td align="center">0.005</td>
                <td align="center">0.697</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">2</td>
                <td align="center">0.963</td>
                <td align="center">0.310</td>
                <td align="center">0.200</td>
                <td align="center">0.000</td>
                <td align="center">0.708</td>
                <td align="center">0.953</td>
                <td align="center">0.877</td>
                <td align="center">0.256</td>
                <td align="center">0.001</td>
                <td align="center">0.708</td>
              </tr>
              <tr>
                <td align="center">10</td>
                <td align="center">5</td>
                <td align="center">0.963</td>
                <td align="center">0.310</td>
                <td align="center">0.200</td>
                <td align="center">0.000</td>
                <td align="center">0.708</td>
                <td align="center">0.953</td>
                <td align="center">0.877</td>
                <td align="center">0.256</td>
                <td align="center">0.001</td>
                <td align="center">0.708</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <fig position="float" id="F3">
          <label>Figure 3</label>
          <caption>
            <p><bold><italic>FP </italic>rate vs. rejection rate for each integration method using S<sc>VM</sc> as the base learner with changing <italic>λ </italic>and <italic>α </italic>values</bold>.</p>
          </caption>
          <graphic xlink:href="1472-6807-9-66-3"/>
        </fig>
        <fig position="float" id="F4">
          <label>Figure 4</label>
          <caption>
            <p><bold><italic>FP </italic>rate vs. rejection rate for each integration method using S<sc>VR</sc> as the base learner with changing <italic>λ </italic>and <italic>α </italic>values</bold>.</p>
          </caption>
          <graphic xlink:href="1472-6807-9-66-4"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>Discussion</title>
    <p>We focus on the protein stability change prediction by adding new features and implementing the three different integration approaches, classification vs. regression, the effect of the reject option.</p>
    <sec>
      <title>Sufficiency of the Data Sets</title>
      <p>Training any classifier with an unbalanced data set in favor of negative instances makes it difficult to learn the positive instances. The unbalanced distribution in prior probabilities of the two classes in both training and test sets affects the reliability of the predictor in all integration approaches. Nevertheless, the abundance of one class remains with the nature of the stability problem. Stabilizing mutations are far less than destabilizing mutations. Higher accuracies might be achieved with balanced training and test tests. For example, the test sets of S1615 and S2783 data sets have 88.51 per cent and 69.45 per cent destabilizing mutations, respectively. S1615 data set does not have balanced training and test sets whereas we evenly distribute stabilizing and destabilizing mutations to training and test sets for S2783 data set. For S1615 dataset, we achieve 0.904 the average test accuracy which is 1.90 per cent higher than the percentage of destabilizing mutations. For S2783 data set, this improvement is around 14.05 per cent. ΔΔ<italic>G </italic>values for the majority of both training and test data are in the interval {-1, 1}. We would expect the predictor to learn the pattern in this region better than the other regions in the data space. However, Figure <xref ref-type="fig" rid="F5">5</xref> suggests that it is not the case, and this is in agreement with previous studies [<xref ref-type="bibr" rid="B9">9</xref>]. Even though the ΔΔ<italic>G </italic>values are not provided to the classification algorithm numerically, the error rate is higher for smaller changes and lower for larger ones. This may be due to two reasons: Either our predictor works best at dramatic stability changes; or possible experimental errors, being more significant for smaller ΔΔ<italic>G </italic>values than the larger ones, confused our predictor. In separating the mutations into two distinct classes as positive and negative, the prediction may be ambiguous for data points close to zero. If we test our best classifier for S1615 data set with the test instances outside of this interval (230 of 383 instances), we obtain 0.948 test accuracy. This last result shows the advantage of introducing a reject option and the approach we use by taking into account the losses of rejects and wrong decisions is the systematic way to choose the optimal thresholds.</p>
      <fig position="float" id="F5">
        <label>Figure 5</label>
        <caption>
          <p><bold>Distribution of the correctly classified (grey) and misclassified (black) instances of S1615 data set after the S<sc>VM</sc> combiner over the free energy change due to single-site mutation, ΔΔ<italic>G</italic></bold>. Misclassified instances are clustered mainly around zero. In the regions {-∞, -4} and {3, ∞} all instances are correctly classified.</p>
        </caption>
        <graphic xlink:href="1472-6807-9-66-5"/>
      </fig>
      <p>Furthermore, the mutations in the test set of S1615 data set were conducted in physiological conditions [<xref ref-type="bibr" rid="B2">2</xref>], having T in the range 20-30°C and pH in the range 6-8 whereas for the training set, the ranges are 0-86°C and 1-11 respectively. It is not ideal to train a learner with data within a wide range and test it only in a limited region; it is normally expected that the training and test sets follow the same probability distribution. In S2783 data set, the test data and the training data are split randomly to alleviate this problem. Because we do the splitting ten times and take the average, our results are more robust on S2783 data set.</p>
    </sec>
    <sec>
      <title>Integration Approaches</title>
      <p>The most accurate predictor in early integration for S1615 (S2783) data set is S<sc>VM</sc> (S<sc>VM</sc>) classifier trained with S<sc>T</sc>* (S<sc>O</sc>) achieving a validation set accuracy of 0.842 (0.829) and a test accuracy of 0.904 (0.832). We see in Tables <xref ref-type="table" rid="T6">6</xref> and <xref ref-type="table" rid="T13">13</xref> that using structural information is useful with <italic>k</italic>-<sc>NN</sc> and D<sc>T</sc>; adding new features such as P<sc>AM</sc> and C<sc>B</sc> improve cv accuracy, and in the case of T<sc>O</sc>*, also improves test accuracy using S<sc>VM</sc>, though not significantly. It may be said that T<sc>O</sc> does not have enough packing information intrinsically and using <italic>B-factor</italic>s and <italic>C</italic><sub><italic>β </italic></sub>may help.</p>
      <p>In late integration for S1615 data set, of the four triplets combined, two are S<sc>VM</sc>, one is D<sc>T</sc> and one is <italic>k</italic>-<sc>NN</sc>. The fact that four different learners are chosen show that the learning algorithm is a good source of diversity. Of the four, two use S<sc>T</sc>* and S<sc>O</sc>*, showing again that in terms of representations, there is also diversity for higher accuracy. Note that this diverse set is found automatically by the selection algorithm we use.</p>
      <p>The most accurate intermediate integration version for S1615 data set uses T<sc>O</sc>* with all new features; its test accuracy is 0.879, which is significantly more accurate than the version with old features only (T<sc>O</sc>) with test accuracy 0.833. Though it is not as accurate as the other integration methods, intermediate integration has the advantage of knowledge extraction through weights assigned to features. The kernel weights (see Tables <xref ref-type="table" rid="T11">11</xref>, <xref ref-type="table" rid="T13">13</xref>, <xref ref-type="table" rid="T17">17</xref>, and <xref ref-type="table" rid="T18">18</xref>) show that when the protein structure is available, C<sc>A</sc> and C<sc>B</sc> are always preferred as a more valuable information source than any other features including sequence neighbors. Based on the kernel weights, we can say that stability change is mostly a structure-driven phenomenon: For example, when we sum up the weights of structural features for S1615 data set, using S<sc>T</sc>*, we get (0.18)C<sc>A</sc> + (0.09)S<sc>A</sc> + (0.26)C<sc>B</sc> + (0.08)B<sc>FA</sc> + (0.06)B<sc>FB</sc> = 0.67 of 1.00.</p>
    </sec>
    <sec>
      <title>Prediction Using Only the Amino Acid Sequence</title>
      <p>We analyze simulation results to see how accuracy changes if we have only the sequence information. For both data sets, the best performance in early integration is obtained with (S<sc>O</sc>. O<sc>RIGINAL</sc>.S<sc>VM</sc>). The average test accuracies are 0.904 and 0.832 for S1615 and S2783 data sets, respectively. Intermediate integration for S1615 data set achieves 0.872 average testing accuracy with S<sc>O</sc>, which is higher than those of T<sc>O</sc> and S<sc>T</sc> (0.833 and 0.818, respectively). With the extra features, the accuracies are 0.872, 0.879, and 0.878 for S<sc>O</sc>*, T<sc>O</sc>*, and S<sc>T</sc>*, respectively (see Table <xref ref-type="table" rid="T10">10</xref>). The improvement with additional information in T<sc>O</sc>* and S<sc>T</sc>* is not significant when compared with S<sc>O</sc>. For S2783 data set, intermediate integration achieves 0.800 test accuracy with S<sc>O</sc>. All feature representations achieve statistically similar test set accuracies for both multikernel S<sc>VM</sc> and S<sc>VR</sc>.</p>
      <p>Prediction from only the sequence information could be considered more valuable at present as sequence-based data are more readily available. Even if the average accuracy is increased by extra structural features, these features are obtained through costly experimental procedures like x-ray crystallography or NMR spectroscopy. Spending more effort on making better use of sequence-only features with different learning methods might be more beneficial.</p>
    </sec>
    <sec>
      <title>Classification with Reject Option</title>
      <p>When we compare the results of classification with reject option, we see that early and late integration methods tends to reject fewer test instances than intermediate integration with late rejects the least. For example, in order to achieve 0.850 test set accuracy, early and late integration need to reject around 10 per cent of the test instances whereas intermediate integration rejects around 15 per cent of the test instances (see Tables <xref ref-type="table" rid="T19">19</xref>, <xref ref-type="table" rid="T21">21</xref>, and <xref ref-type="table" rid="T23">23</xref>). Another target can be achieving a specific <italic>FP </italic>rate. In this case, for example, early and late integration reject 10 per cent of the test instances and intermediate integration rejects 35 per cent of the test instances to get a <italic>FP </italic>rate less than 0.05. The same behavior can also be observed for regression (see Tables <xref ref-type="table" rid="T20">20</xref>, <xref ref-type="table" rid="T22">22</xref>, and <xref ref-type="table" rid="T24">24</xref>).</p>
    </sec>
    <sec>
      <title>Comparison with Other Studies</title>
      <p>Our methodology using 20-fold cv has comparable accuracy to previous studies [<xref ref-type="bibr" rid="B2">2</xref>,<xref ref-type="bibr" rid="B7">7</xref>,<xref ref-type="bibr" rid="B9">9</xref>,<xref ref-type="bibr" rid="B41">41</xref>]. S1615 data set is based on Protherm that has been also used by those studies. Nevertheless, it is not exactly the same data set as we remove the test set from the training set, thus we represent our comparison with this caveat in Table <xref ref-type="table" rid="T25">25</xref>. Early integration approach is used in all referred works. They all report the performance of their predictors based on <italic>k</italic>-fold cv, also including the test set in cross-validation. The highest accuracy reported so far is 0.930 evaluated on a subset of the training data [<xref ref-type="bibr" rid="B9">9</xref>]; our early integration has the accuracy of 0.904 on the independent test set. In those studies, higher accuracies are reported in the presence of structural information, which is in agreement with our findings though the difference is not significant in our case. Ours is the first study that compares early, intermediate, and late integration to incorporate knowledge from different data sources for the problem of predicting protein stability, also analyzing the effect of different types of sequence and structural information.</p>
      <table-wrap position="float" id="T25">
        <label>Table 25</label>
        <caption>
          <p>Comparison of our results for S1615 data set with previously published studies. </p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <td align="center">
                <bold>Ref.</bold>
              </td>
              <td align="left">
                <bold>Method</bold>
              </td>
              <td align="left">
                <bold>Data Set Size</bold>
              </td>
              <td align="left">
                <bold>Accuracy</bold>
              </td>
              <td align="left">
                <bold>Information</bold>
              </td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center">[<xref ref-type="bibr" rid="B41">41</xref>]</td>
              <td align="left">SVM</td>
              <td align="left">2048</td>
              <td align="left">0.77 (20-fold cv)</td>
              <td align="left">Seq</td>
            </tr>
            <tr>
              <td colspan="5">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="center">[<xref ref-type="bibr" rid="B42">42</xref>]</td>
              <td align="left">SVM</td>
              <td align="left">1383 *</td>
              <td align="left">0.73 (20-fold cv)</td>
              <td align="left">Seq</td>
            </tr>
            <tr>
              <td colspan="5">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="center">[<xref ref-type="bibr" rid="B9">9</xref>]</td>
              <td align="left">NN<break/>NN+FOLDX</td>
              <td align="left">1615</td>
              <td align="left">0.79 (20-fold cv)<break/>0.87 (test set†)<break/>0.93 (test set†)</td>
              <td align="left">Seq+Str</td>
            </tr>
            <tr>
              <td colspan="5">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="center">[<xref ref-type="bibr" rid="B2">2</xref>]</td>
              <td align="left">SVM</td>
              <td align="left">1496‡</td>
              <td align="left">S<sc>O</sc>: 0.84, T<sc>O</sc>: 0.85, S<sc>T</sc>: 0.85 (20-fold cv)<break/>S<sc>O</sc>: 0.86, T<sc>O</sc>: 0.86, S<sc>T</sc>: 0.86 (test set)</td>
              <td align="left">Seq+Str</td>
            </tr>
            <tr>
              <td colspan="5">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="center">[<xref ref-type="bibr" rid="B31">31</xref>]</td>
              <td align="left">iPTREE</td>
              <td align="left">1615</td>
              <td align="left">0.87 (10-fold cv)</td>
              <td align="left">Seq+Str</td>
            </tr>
            <tr>
              <td colspan="5">
                <hr/>
              </td>
            </tr>
            <tr>
              <td align="center">Ours</td>
              <td align="left">Early<break/>Late<break/>Intermediate</td>
              <td align="left">1122 (training)<break/>383 (test)</td>
              <td align="left"><bold>0.842 </bold>(20-fold cv), <bold>0.904 </bold>(test set)<break/>0.847 (20-fold cv), 0.903 (test set)<break/>0.826 (20-fold cv), 0.879 (test set)</td>
              <td align="left">Seq+Str</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>*Filtered from the set of 2048 mutations [<xref ref-type="bibr" rid="B41">41</xref>].</p>
          <p>† A subset of the training set that was previously used in training.</p>
          <p>‡ Filtered from the set of 1615 mutations [<xref ref-type="bibr" rid="B9">9</xref>].</p>
          <p>Machine learning method, data set, performance assessment are the main features to be compared. (Seq: Sequence-based information, Seq+Str: Sequence- and structure-based information)</p>
        </table-wrap-foot>
      </table-wrap>
    </sec>
  </sec>
  <sec>
    <title>Conclusion</title>
    <p>In protein stability prediction, we investigate three approaches for combining multiple representations/learners, namely, early, intermediate, and late integration. These approaches can be used in both classification and regression. Early integration uses a single learner to combine multiple inputs whereas late integration combines the decisions of learners using different inputs. Intermediate integration combines inputs at the kernel level. We find that early and late integration are significantly more accurate than intermediate integration and intermediate integration allows knowledge extraction in the sense that it can pinpoint the features that are useful and how much they contribute. One advantage of combination is that if a new feature set, a kernel or a method for learning is proposed (using machine learning or some other approach), it is always possible to include it among the set we use and thereby improve accuracy even further.</p>
    <p>In general, we would expect early integration to suffer more from the curse of dimensionality when many input sources are concatenated. Late integration combines decisions and therefore is expected to be more robust; the disadvantage would be the need to train/store/use multiple learners. Intermediate integration is in between these two extremes where separate features are not used in a raw manner (as in early integration) nor are decisions extracted from them (as in late integration) but are converted to similarities (using kernels) and fed to a single learner. The relative weights of features can be measured using intermediate integration. Of course, ours is a single study and further research is needed before one can explain with enough confidence where and why each integration method works the best. Of the three which one should be chosen depends on the application and other criteria, such as how much time and space can be afforded.</p>
    <p>We see that in terms of accuracy there is no significant difference between interpreting this as a classification or regression problem except that a regressor tends to have a lower <italic>FP </italic>rate. We also conclude that introducing a reject option is useful to reject cases where a classifier or a regressor is not confident; it allows achieving a much lower <italic>FP </italic>rate taking into account the loss incurred for rejections and misclassifications.</p>
    <p>As a future direction, we can add features, for example, to reflect the side chain conformation change due to a single-site mutation by a simple modeling.</p>
  </sec>
  <sec>
    <title>Authors' contributions</title>
    <p>AO and MG developed the concept and the method under the guidance of EA and TH. MG developed the web server. AO and MG drafted the paper. EA and TH finalized the draft. All authors read and approved the final manuscript.</p>
  </sec>
</body>
<back>
  <ack>
    <sec>
      <title>Acknowledgements</title>
      <p>This work was supported by the Turkish Academy of Sciences in the framework of the Young Scientist Award Program (EA-TÜBA-GEBİP/2001-1-1 and TH-TÜBA-GEBİP/2001-1-1), Boğaziçi University Scientific Research Projects (BAP 04A502, 06A508, and 07HA101), the Turkish State Planning Organization (DPT 03K120250), the Turkish Scientific Technical Research Council (TÜBİTAK EEEAG 107E222). T. Haliloğlu acknowledges Betil Fund. A. Özen acknowledges TÜBİTAK-BİDEB SSA-2 Project Fellowship. The work of M. Gönen was supported by the PhD scholarship (2211) from TÜBİTAK.</p>
    </sec>
  </ack>
  <ref-list>
    <ref id="B1">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Levitt</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Accurate prediction of the stability and activity effects of site-directed mutagenesis on a protein core</article-title>
        <source>Nature</source>
        <year>1991</year>
        <volume>352</volume>
        <fpage>448</fpage>
        <lpage>451</lpage>
        <pub-id pub-id-type="pmid">1861725</pub-id>
        <pub-id pub-id-type="doi">10.1038/352448a0</pub-id>
      </citation>
    </ref>
    <ref id="B2">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Randall</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Baldi</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein stability changes for single-site mutations using support vector machines</article-title>
        <source>Proteins</source>
        <year>2006</year>
        <volume>62</volume>
        <fpage>1125</fpage>
        <lpage>1132</lpage>
        <pub-id pub-id-type="pmid">16372356</pub-id>
        <pub-id pub-id-type="doi">10.1002/prot.20810</pub-id>
      </citation>
    </ref>
    <ref id="B3">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bordner</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Abagyan</surname>
            <given-names>RA</given-names>
          </name>
        </person-group>
        <article-title>Large-scale prediction of protein geometry and stability changes for arbitrary single point mutations</article-title>
        <source>Proteins</source>
        <year>2004</year>
        <volume>57</volume>
        <fpage>400</fpage>
        <lpage>413</lpage>
        <pub-id pub-id-type="pmid">15340927</pub-id>
        <pub-id pub-id-type="doi">10.1002/prot.20185</pub-id>
      </citation>
    </ref>
    <ref id="B4">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gilis</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Rooman</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Stability changes upon mutation of solvent-accessible residues in proteins evaluated by database-derived potentials</article-title>
        <source>Journal of Molecular Biology</source>
        <year>1996</year>
        <volume>257</volume>
        <fpage>1112</fpage>
        <lpage>1126</lpage>
        <pub-id pub-id-type="pmid">8632471</pub-id>
        <pub-id pub-id-type="doi">10.1006/jmbi.1996.0226</pub-id>
      </citation>
    </ref>
    <ref id="B5">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guerois</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Nielsen</surname>
            <given-names>JE</given-names>
          </name>
          <name>
            <surname>Serrano</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Predicting changes in the stability of proteins and protein complexes: A study of more than 1000 mutations</article-title>
        <source>Journal of Molecular Biology</source>
        <year>2002</year>
        <volume>320</volume>
        <fpage>369</fpage>
        <lpage>387</lpage>
        <pub-id pub-id-type="pmid">12079393</pub-id>
        <pub-id pub-id-type="doi">10.1016/S0022-2836(02)00442-4</pub-id>
      </citation>
    </ref>
    <ref id="B6">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kwasigroch</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Gilis</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Dehouck</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Rooman</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>PoPMuSiC, rationally designing point mutations in protein structures</article-title>
        <source>Bioinformatics</source>
        <year>2002</year>
        <volume>18</volume>
        <fpage>1701</fpage>
        <lpage>1702</lpage>
        <pub-id pub-id-type="pmid">12490462</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/18.12.1701</pub-id>
      </citation>
    </ref>
    <ref id="B7">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gromiha</surname>
            <given-names>MM</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein stability upon point mutations</article-title>
        <source>Biochemical Society Transactions</source>
        <year>2007</year>
        <volume>35</volume>
        <fpage>1569</fpage>
        <lpage>1573</lpage>
        <pub-id pub-id-type="pmid">18031268</pub-id>
        <pub-id pub-id-type="doi">10.1042/BST0351569</pub-id>
      </citation>
    </ref>
    <ref id="B8">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Distance-scaled, finite ideal-gas reference state improves structure-derived potentials of mean force for structure selection and stability prediction</article-title>
        <source>Protein Science</source>
        <year>2002</year>
        <volume>11</volume>
        <fpage>2714</fpage>
        <lpage>2726</lpage>
        <pub-id pub-id-type="pmid">12381853</pub-id>
        <pub-id pub-id-type="doi">10.1110/ps.0217002</pub-id>
      </citation>
    </ref>
    <ref id="B9">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Capriotti</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Fariselli</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Casadio</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>A neural-network-based method for predicting protein stability changes upon single point mutations</article-title>
        <source>Bioinformatics</source>
        <year>2004</year>
        <volume>20</volume>
        <fpage>i63</fpage>
        <lpage>i68</lpage>
        <pub-id pub-id-type="pmid">15262782</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bth928</pub-id>
      </citation>
    </ref>
    <ref id="B10">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Masso</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Vaisman</surname>
            <given-names>II</given-names>
          </name>
        </person-group>
        <article-title>Accurate prediction of enzyme mutant activity based on a multibody statistical potential</article-title>
        <source>Bioinformatics</source>
        <year>2007</year>
        <volume>23</volume>
        <fpage>3155</fpage>
        <lpage>3161</lpage>
        <pub-id pub-id-type="pmid">17977887</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btm509</pub-id>
      </citation>
    </ref>
    <ref id="B11">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Masso</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Vaisman</surname>
            <given-names>II</given-names>
          </name>
        </person-group>
        <article-title>Accurate prediction of stability changes in protein mutants by combining machine learning with structure based computational mutagenesis</article-title>
        <source>Bioinformatics</source>
        <year>2008</year>
        <volume>24</volume>
        <fpage>2002</fpage>
        <lpage>2009</lpage>
        <pub-id pub-id-type="pmid">18632749</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btn353</pub-id>
      </citation>
    </ref>
    <ref id="B12">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fox</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Huisman</surname>
            <given-names>GW</given-names>
          </name>
        </person-group>
        <article-title>Enzyme optimization: Moving from blind evolution to statistical exploration of sequence-function space</article-title>
        <source>Trends in Biotechnology</source>
        <year>2008</year>
        <volume>26</volume>
        <fpage>132</fpage>
        <lpage>138</lpage>
        <pub-id pub-id-type="pmid">18222559</pub-id>
        <pub-id pub-id-type="doi">10.1016/j.tibtech.2007.12.001</pub-id>
      </citation>
    </ref>
    <ref id="B13">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Capriotti</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Fariselli</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Rossi</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Casadio</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>A three-state prediction of single point mutations on protein stability changes</article-title>
        <source>BMC Bioinformatics</source>
        <year>2008</year>
        <volume>9</volume>
        <fpage>S6</fpage>
        <pub-id pub-id-type="pmid">18387208</pub-id>
        <pub-id pub-id-type="doi">10.1186/1471-2105-9-S2-S6</pub-id>
      </citation>
    </ref>
    <ref id="B14">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Kuncheva</surname>
            <given-names>LI</given-names>
          </name>
        </person-group>
        <source>Combining Pattern Classifiers: Methods and Algorithms</source>
        <year>2004</year>
        <publisher-name>Hoboken, NJ: John Wiley &amp; Sons, Inc</publisher-name>
      </citation>
    </ref>
    <ref id="B15">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Alpaydın</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <source>Introduction to Machine Learning</source>
        <year>2004</year>
        <publisher-name>Cambridge, MA: The MIT Press</publisher-name>
      </citation>
    </ref>
    <ref id="B16">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Noble</surname>
            <given-names>WS</given-names>
          </name>
        </person-group>
        <person-group person-group-type="editor">
          <name>
            <surname>Schölkopf B, Tsuda K, Vert J</surname>
          </name>
        </person-group>
        <article-title>Support vector machine applications in computational biology</article-title>
        <source>Kernel Methods in Computational Biology</source>
        <year>2004</year>
        <publisher-name>Cambridge, MA: The MIT Press</publisher-name>
        <fpage>71</fpage>
        <lpage>92</lpage>
      </citation>
    </ref>
    <ref id="B17">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shen</surname>
            <given-names>HB</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>Ensemble classifier for protein fold pattern recognition</article-title>
        <source>Bioinformatics</source>
        <year>2006</year>
        <volume>22</volume>
        <fpage>1717</fpage>
        <lpage>1722</lpage>
        <pub-id pub-id-type="pmid">16672258</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btl170</pub-id>
      </citation>
    </ref>
    <ref id="B18">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Drağhici</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Potter</surname>
            <given-names>RB</given-names>
          </name>
        </person-group>
        <article-title>Predicting HIV drug resistance with neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2003</year>
        <volume>19</volume>
        <fpage>98</fpage>
        <lpage>107</lpage>
        <pub-id pub-id-type="pmid">12499299</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/19.1.98</pub-id>
      </citation>
    </ref>
    <ref id="B19">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Guermeur</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Geourjon</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Gallinari</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Deléage</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Improved performance in protein secondary structure prediction by inhomogeneous score combination</article-title>
        <source>Bioinformatics</source>
        <year>1999</year>
        <volume>15</volume>
        <fpage>413</fpage>
        <lpage>421</lpage>
        <pub-id pub-id-type="pmid">10366661</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/15.5.413</pub-id>
      </citation>
    </ref>
    <ref id="B20">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Choe</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Ersoy</surname>
            <given-names>OK</given-names>
          </name>
          <name>
            <surname>Bina</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Neural network schemes for detecting rare events in human genomic DNA</article-title>
        <source>Bioinformatics</source>
        <year>2000</year>
        <volume>16</volume>
        <fpage>1062</fpage>
        <lpage>1072</lpage>
        <pub-id pub-id-type="pmid">11159325</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/16.12.1062</pub-id>
      </citation>
    </ref>
    <ref id="B21">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dudoit</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Fridlyand</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Bagging to improve the accuracy of a clustering procedure</article-title>
        <source>Bioinformatics</source>
        <year>2003</year>
        <volume>19</volume>
        <fpage>1090</fpage>
        <lpage>1099</lpage>
        <pub-id pub-id-type="pmid">12801869</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btg038</pub-id>
      </citation>
    </ref>
    <ref id="B22">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Robles</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Larrañaga</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Peña</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Menasalvas</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Pérez</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Herves</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Wasilewska</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Bayesian network multi-classifiers for protein secondary structure prediction</article-title>
        <source>Artificial Intelligence in Medicine</source>
        <year>2004</year>
        <volume>31</volume>
        <fpage>117</fpage>
        <lpage>136</lpage>
        <pub-id pub-id-type="pmid">15219290</pub-id>
        <pub-id pub-id-type="doi">10.1016/j.artmed.2004.01.009</pub-id>
      </citation>
    </ref>
    <ref id="B23">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Mesirov</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Waltz</surname>
            <given-names>DL</given-names>
          </name>
        </person-group>
        <article-title>Hybrid system for protein secondary structure prediction</article-title>
        <source>Journal of Molecular Biology</source>
        <year>1992</year>
        <volume>225</volume>
        <fpage>1049</fpage>
        <lpage>1063</lpage>
        <pub-id pub-id-type="pmid">1613789</pub-id>
        <pub-id pub-id-type="doi">10.1016/0022-2836(92)90104-R</pub-id>
      </citation>
    </ref>
    <ref id="B24">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pavlović</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Garg</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kasif</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>A Bayesian framework for combining gene predictions</article-title>
        <source>Bioinformatics</source>
        <year>2002</year>
        <volume>18</volume>
        <fpage>19</fpage>
        <lpage>27</lpage>
        <pub-id pub-id-type="pmid">11836207</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/18.1.19</pub-id>
      </citation>
    </ref>
    <ref id="B25">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ouali</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>King</surname>
            <given-names>RD</given-names>
          </name>
        </person-group>
        <article-title>Cascaded multiple classifiers for secondary structure prediction</article-title>
        <source>Protein Science</source>
        <year>2000</year>
        <volume>9</volume>
        <fpage>1162</fpage>
        <lpage>1176</lpage>
        <pub-id pub-id-type="pmid">10892809</pub-id>
        <pub-id pub-id-type="doi">10.1110/ps.9.6.1162</pub-id>
      </citation>
    </ref>
    <ref id="B26">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lanckriet</surname>
            <given-names>GRG</given-names>
          </name>
          <name>
            <surname>De Bie</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Cristianini</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Jordan</surname>
            <given-names>MI</given-names>
          </name>
          <name>
            <surname>Noble</surname>
            <given-names>WS</given-names>
          </name>
        </person-group>
        <article-title>A statistical framework for genomic data fusion</article-title>
        <source>Bioinformatics</source>
        <year>2004</year>
        <volume>20</volume>
        <fpage>2626</fpage>
        <lpage>2635</lpage>
        <pub-id pub-id-type="pmid">15130933</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bth294</pub-id>
      </citation>
    </ref>
    <ref id="B27">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sonnenburg</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Rätsch</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Schäfer</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Schölkopf</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Large scale multiple kernel learning</article-title>
        <source>Journal of Machine Learning Research</source>
        <year>2006</year>
        <volume>7</volume>
        <fpage>1531</fpage>
        <lpage>1565</lpage>
      </citation>
    </ref>
    <ref id="B28">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yamanishi</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bach</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Vert</surname>
            <given-names>JP</given-names>
          </name>
        </person-group>
        <article-title>Glycan classification with tree kernels</article-title>
        <source>Bioinformatics</source>
        <year>2007</year>
        <volume>23</volume>
        <fpage>1211</fpage>
        <lpage>1216</lpage>
        <pub-id pub-id-type="pmid">17344232</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btm090</pub-id>
      </citation>
    </ref>
    <ref id="B29">
      <citation citation-type="other">
        <article-title>MUpro: Prediction of Protein Stability Changes for Single-Site Mutations from Sequences</article-title>
        <year>2009</year>
        <ext-link ext-link-type="uri" xlink:href="http://www.ics.uci.edu/~baldig/mutation.html"/>
      </citation>
    </ref>
    <ref id="B30">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gromiha</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>An</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kono</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Oobatake</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Uedaira</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Prabakaran</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Sarai</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>ProTherm, version 2.0: Thermodynamic database for proteins and mutants</article-title>
        <source>Nucleic Acids Research</source>
        <year>2000</year>
        <volume>28</volume>
        <fpage>283</fpage>
        <lpage>285</lpage>
        <pub-id pub-id-type="pmid">10592247</pub-id>
        <pub-id pub-id-type="doi">10.1093/nar/28.1.283</pub-id>
      </citation>
    </ref>
    <ref id="B31">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Gromiha</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>Hwang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ho</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Knowledge acquisition and development of accurate rules for predicting protein stability change</article-title>
        <source>Computational Biology and Chemistry</source>
        <year>2006</year>
        <volume>30</volume>
        <fpage>408</fpage>
        <lpage>415</lpage>
        <pub-id pub-id-type="pmid">17000135</pub-id>
        <pub-id pub-id-type="doi">10.1016/j.compbiolchem.2006.06.004</pub-id>
      </citation>
    </ref>
    <ref id="B32">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dayhoff</surname>
            <given-names>MO</given-names>
          </name>
          <name>
            <surname>Schwartz</surname>
            <given-names>RM</given-names>
          </name>
          <name>
            <surname>Orcutt</surname>
            <given-names>BC</given-names>
          </name>
        </person-group>
        <article-title>A model of evolutionary change in proteins</article-title>
        <source>Atlas of Protein Sequence and Structure</source>
        <year>1978</year>
        <volume>5</volume>
        <fpage>345</fpage>
        <lpage>358</lpage>
      </citation>
    </ref>
    <ref id="B33">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Duin</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>The combining classifier: To train or not to train?</article-title>
        <source>Proceedings of the 16th International Conference on Pattern Recognition, Québec</source>
        <year>2002</year>
        <fpage>765</fpage>
        <lpage>770</lpage>
      </citation>
    </ref>
    <ref id="B34">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Mosek</surname>
            <given-names/>
          </name>
        </person-group>
        <source>The MOSEK Optimization Tools Manual Version 50 (Revision 137) MOSEK ApS, Denmark</source>
        <year>2009</year>
      </citation>
    </ref>
    <ref id="B35">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boser</surname>
            <given-names>BE</given-names>
          </name>
          <name>
            <surname>Guyon</surname>
            <given-names>IM</given-names>
          </name>
          <name>
            <surname>Vapnik</surname>
            <given-names>VN</given-names>
          </name>
        </person-group>
        <article-title>A training algorithm for optimal margin classifiers</article-title>
        <source>Proceedings of the 5th Annual ACM Workshop on Computational Learning Theory, Pittsburgh, PA</source>
        <year>1992</year>
        <fpage>144</fpage>
        <lpage>152</lpage>
        <comment>full_text</comment>
      </citation>
    </ref>
    <ref id="B36">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Drucker</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Burges</surname>
            <given-names>CJC</given-names>
          </name>
          <name>
            <surname>Kaufman</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Smola</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Vapnik</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Support Vector Regression Machines</article-title>
        <source>Advances in Neural Information Processing Systems</source>
        <year>1997</year>
        <volume>9</volume>
        <fpage>155</fpage>
        <lpage>161</lpage>
      </citation>
    </ref>
    <ref id="B37">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Pavlidis</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Cai</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Weston</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Grundy</surname>
            <given-names>WN</given-names>
          </name>
        </person-group>
        <article-title>Gene functional classification from heterogeneous data</article-title>
        <source>Proceedings of the 5th Annual International Conference on Computational Molecular Biology, Montreal, Québec</source>
        <year>2001</year>
        <fpage>242</fpage>
        <lpage>248</lpage>
      </citation>
    </ref>
    <ref id="B38">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lanckriet</surname>
            <given-names>GRG</given-names>
          </name>
          <name>
            <surname>Cristianini</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Bartlett</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Ghaoui</surname>
            <given-names>LE</given-names>
          </name>
          <name>
            <surname>Jordan</surname>
            <given-names>MI</given-names>
          </name>
        </person-group>
        <article-title>Learning the kernel matrix with semidefinite programming</article-title>
        <source>Journal of Machine Learning Research</source>
        <year>2004</year>
        <volume>5</volume>
        <fpage>27</fpage>
        <lpage>72</lpage>
      </citation>
    </ref>
    <ref id="B39">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Bach</surname>
            <given-names>FR</given-names>
          </name>
          <name>
            <surname>Lanckriet</surname>
            <given-names>GRG</given-names>
          </name>
          <name>
            <surname>Jordan</surname>
            <given-names>MI</given-names>
          </name>
        </person-group>
        <article-title>Multiple kernel learning, conic duality, and the SMO algorithm</article-title>
        <source>Proceedings of the 21st International Conference on Machine learning, Banff</source>
        <year>2004</year>
        <fpage>41</fpage>
        <lpage>48</lpage>
      </citation>
    </ref>
    <ref id="B40">
      <citation citation-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Gönen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Alpaydın</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Localized multiple kernel learning</article-title>
        <source>Proceedings of the 25st International Conference on Machine learning, Helsinki</source>
        <year>2008</year>
        <fpage>352</fpage>
        <lpage>359</lpage>
      </citation>
    </ref>
    <ref id="B41">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Capriotti</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Fariselli</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Calabrese</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Casadio</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Predicting protein stability changes from sequences using support vector machines</article-title>
        <source>Bioinformatics</source>
        <year>2005</year>
        <volume>21</volume>
        <fpage>i54</fpage>
        <lpage>i58</lpage>
      </citation>
    </ref>
    <ref id="B42">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fernández</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Caballero</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Fernández</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Abreu</surname>
            <given-names>JI</given-names>
          </name>
          <name>
            <surname>Acosta</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Classification of conformational stability of protein mutants from 3D pseudo-folding graph representation of protein sequences using support vector machines</article-title>
        <source>Proteins: Structure, Function, and Bioinformatics</source>
        <year>2008</year>
        <volume>70</volume>
        <fpage>167</fpage>
        <lpage>175</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.21524</pub-id>
      </citation>
    </ref>
  </ref-list>
</back>
