<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">5998898</article-id>
    <article-id pub-id-type="pmid">29745828</article-id>
    <article-id pub-id-type="publisher-id">2065</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-018-2065-x</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>RaptorX-Angle: real-value prediction of protein backbone dihedral angles through a hybrid method of clustering and deep learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Gao</surname>
          <given-names>Yujuan</given-names>
        </name>
        <address>
          <email>ygao@ttic.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Sheng</given-names>
        </name>
        <address>
          <email>wangsheng@ttic.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Deng</surname>
          <given-names>Minghua</given-names>
        </name>
        <address>
          <email>dengmh@pku.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Xu</surname>
          <given-names>Jinbo</given-names>
        </name>
        <address>
          <email>jinbo.xu@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2256 9319</institution-id><institution-id institution-id-type="GRID">grid.11135.37</institution-id><institution>Center for Quantitative Biology, </institution><institution>Peking University, </institution></institution-wrap>Beijing, China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 0613 2258</institution-id><institution-id institution-id-type="GRID">grid.287491.1</institution-id><institution>Toyota Technological Institute at Chicago, </institution></institution-wrap>6045 S Kenwood Ave., Chicago, USA </aff>
      <aff id="Aff3"><label>3</label>School of Mathematical Sciences, Beijing, China </aff>
      <aff id="Aff4"><label>4</label>Center for Statistical Sciences, Beijing, China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>8</day>
      <month>5</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>8</day>
      <month>5</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2018</year>
    </pub-date>
    <volume>19</volume>
    <issue>Suppl 4</issue>
    <issue-sponsor>Publication of this supplement has not been supported by sponsorship. Information about the source of funding for publication charges can be found in the individual articles. The articles have undergone the journal's standard peer review process for supplements. The Supplement Editors declare that they have no competing interests.</issue-sponsor>
    <elocation-id>100</elocation-id>
    <permissions>
      <copyright-statement>© The Author(s) 2018</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p>Protein dihedral angles provide a detailed description of protein local conformation. Predicted dihedral angles can be used to narrow down the conformational space of the whole polypeptide chain significantly, thus aiding protein tertiary structure prediction. However, direct angle prediction from sequence alone is challenging.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>In this article, we present a novel method (named RaptorX-Angle) to predict real-valued angles by combining clustering and deep learning. Tested on a subset of PDB25 and the targets in the latest two Critical Assessment of protein Structure Prediction (CASP), our method outperforms the existing state-of-art method SPIDER2 in terms of Pearson Correlation Coefficient (PCC) and Mean Absolute Error (MAE). Our result also shows approximately linear relationship between the real prediction errors and our estimated bounds. That is, the real prediction error can be well approximated by our estimated bounds.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p>Our study provides an alternative and more accurate prediction of dihedral angles, which may facilitate protein structure prediction and functional study.</p>
      </sec>
      <sec>
        <title>Electronic supplementary material</title>
        <p>The online version of this article (10.1186/s12859-018-2065-x) contains supplementary material, which is available to authorized users.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Dihedral angle prediction</kwd>
      <kwd>Protein structure prediction</kwd>
      <kwd>Clustering</kwd>
      <kwd>Residual network</kwd>
      <kwd>Deep learning</kwd>
    </kwd-group>
    <conference xlink:href="http://apbc2018.bio.keio.ac.jp/">
      <conf-name>The Sixteenth Asia Pacific Bioinformatics Conference</conf-name>
      <conf-acronym>APBC 2018</conf-acronym>
      <conf-loc>Yokohama, Japan</conf-loc>
      <conf-date>15-17 January 2018</conf-date>
    </conference>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2018</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p>It has been shown that sequences contain rich information for protein tertiary structure prediction as well as functional study [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. But it is challenging to directly predict tertiary structure from primary sequence, so the hierarchical approach has been widely accepted as one of the most efficient methods. That means to transform the ultimate goal into several sub-problems, such as secondary structure prediction, solvent accessibility prediction, residue-residue contact prediction, etc. [<xref ref-type="bibr" rid="CR3">3</xref>] reviewed the progress in the field of intermediate state or one-dimensional property prediction. It has been shown that predicted secondary structure is useful in the prediction of disordered and flexible regions, fold recognition and function prediction. However, secondary structure states are described as discrete classes and there is no clear boundary between coil and helical/strand states. It is a significant step towards establishing the structure and function of a protein to predict local conformation of the polypeptide chain. The local structural bias information restricts the possible conformations of a sequence segment and therefore narrows down the conformation space of the whole polypeptide chain significantly. Thus, prediction of dihedral angles is especially useful for protein tertiary structure prediction.</p>
    <p>On the whole, dihedral angle prediction may benefit protein tertiary structure prediction in several aspects. Firstly, dihedral angle prediction may act as substitute or supplement for secondary structure prediction [<xref ref-type="bibr" rid="CR4">4</xref>–<xref ref-type="bibr" rid="CR6">6</xref>]. Secondly, It can be used in generation of sequence/structure alignment. For one thing, it can be directly applied to structure alignment methods based on dihedral angles [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>] and may aid refinement of target-template structure alignment. For another, considering predicted angles to refine multiple sequence alignment may narrow the gap between sequence and structure alignment, thus aiding de novo prediction of structural properties. In addition, dihedral angle prediction may also find applications in protein structure prediction that includes but not limits to fold recognition approaches [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>], fragment-free tertiary structure prediction [<xref ref-type="bibr" rid="CR11">11</xref>], tertiary structure refinement and structure quality assessment [<xref ref-type="bibr" rid="CR12">12</xref>] and functional study, such as ligand-binding site prediction [<xref ref-type="bibr" rid="CR13">13</xref>].</p>
    <p>There are mainly two kinds of problems in dihedral angle prediction: angle region prediction and real value prediction, which corresponds to two different representations of protein backbone local structural bias.</p>
    <p>Initially, Ramachandran basin is an intuitive description of local structural bias [<xref ref-type="bibr" rid="CR14">14</xref>]. A Ramachandran basin is a specific region of a Ramachandran plot and illustrates the preference of torsion angle values. Each angle pair can be assigned a basin label. With more basins, the assignment would be harder but the representation would be more accurate and vice versa. Colubri et al. tested the ability to recover the native structure from a given basin assignment for each residue to investigate the level of representation required to simulate folding and predict structure, resulting in five basins [<xref ref-type="bibr" rid="CR15">15</xref>]. Gong et al. partitioned <italic>ϕ</italic>,<italic>ψ</italic>-space into a uniform grid of 36 squares, each 60° × 60°, thus resulting in 36 basins, and showed that they successfully reconstructed six proteins solely from their mesostate (basin label) sequences [<xref ref-type="bibr" rid="CR16">16</xref>]. There are also some other methods to define basins and do angle region prediction with different definitions of basins [<xref ref-type="bibr" rid="CR17">17</xref>–<xref ref-type="bibr" rid="CR20">20</xref>]. Although it is vital to determine the proper number of regions and clearly define the boundary, a universal algorithm to generate Ramachandran basins and assign basin labels remains to be developed. In our study, k-means clustering serves as the basin generator and label assigner.</p>
    <p>While Ramachandran basin provides an overall description of conformation, it is a coarse-grained representation and lacks statistical explanations describing the torsion angle distributions of each basin. In consideration of the circular nature of angles, traditional parametric or non-parametric density estimation methods cannot work properly to approximate Ramachandran distributions. Fortunately, directional distributions such as von Mises distribution could solve the problem [<xref ref-type="bibr" rid="CR21">21</xref>]. Bivariate von Mises distribution (mixtures) has been used to model protein dihedral angle distribution [<xref ref-type="bibr" rid="CR22">22</xref>, <xref ref-type="bibr" rid="CR23">23</xref>], which removes arbitrariness in defining the boundary between discrete states. In this study, we assume angle pairs in each basin follow a bivariate von Mises distribution to derive the log-likelihood of each clustering.</p>
    <p>Thanks to the rapid growth of Protein Data Bank and computational and algorithmic development in machine learning (especially deep learning), several supervised machine learning methods have been proposed to predict real values of dihedral angles. As <italic>ϕ</italic> values in <italic>α</italic>-helices and <italic>β</italic>-sheets are quite similar, <italic>ψ</italic> seems more informative. Wood et al. first developed a method DESTRUCT for prediction of real-valued dihedral angle <italic>ψ</italic> and used this information for prediction of the protein secondary structure with high accuracy [<xref ref-type="bibr" rid="CR4">4</xref>]. Wu et al.proposed a composite machine-learning algorithm called ANGLOR to predict real-value protein backbone torsion angles from protein sequences [<xref ref-type="bibr" rid="CR24">24</xref>]. The input features of ANGLOR include sequence profiles, predicted secondary structure and solvent accessibility. The mean absolute error (MAE) of the <italic>ϕ</italic>/ <italic>ψ</italic> prediction was reported to be 28° / 46°. Later Song et al. developed TANGLE based on a two-level support vector regression approach using a variety of features derived from amino acid sequences, including the evolutionary profiles and natively disordered region as well as other global sequence features [<xref ref-type="bibr" rid="CR25">25</xref>]. The MAE of the <italic>ϕ</italic>/ <italic>ψ</italic> was 27.8° / 44.6°. Xue et al. established a neural network method called Real-SPINE, with sequence profiles generated from multiple sequence alignment and predicted secondary structures as inputs [<xref ref-type="bibr" rid="CR26">26</xref>]. In 2015, they presented SPIDER2 [<xref ref-type="bibr" rid="CR27">27</xref>] by improving SPIDER [<xref ref-type="bibr" rid="CR28">28</xref>] through iterative learning, which used a deep artificial neural network (ANN) with three hidden layers of 150 nodes. They fed the predicted torsion angles of last layer as the input to the following generation and reported 19° and 30° for mean absolute errors of backbone <italic>ϕ</italic> and <italic>ψ</italic> angles, respectively. As it is impossible to introduce all methods here, interested readers can refer to excellent reviews [<xref ref-type="bibr" rid="CR29">29</xref>, <xref ref-type="bibr" rid="CR30">30</xref>].</p>
    <p>Although there has been tremendous development, their performance is still limited by their shallow architectures. Inspired by the excellent performance of convolution neural network in predicting secondary structure [<xref ref-type="bibr" rid="CR31">31</xref>] and order/disorder regions [<xref ref-type="bibr" rid="CR32">32</xref>] and also the success of residual framework to do contact prediction [<xref ref-type="bibr" rid="CR33">33</xref>], we adopt the ultra deep residual framework of convolutional neural network to do k-means basin label probability prediction.</p>
    <p>However, even though a protein backbone conformation can be highly accurately rebuilt from its respective native dihedral angles, accumulation of errors in predicted angles can lead to large deviation in three-dimensional structures, which prevents angle prediction from its direct use in building protein structures [<xref ref-type="bibr" rid="CR27">27</xref>]. It is of great significance to produce the corresponding confidence scores for the real value predictions, i.e., we need to know the confidence level of the predictions. Otherwise the effect of predicted dihedral angles as restraints for three dimensional structure prediction would be limited [<xref ref-type="bibr" rid="CR34">34</xref>]. Zhou et al. had developed SPIDER2 [<xref ref-type="bibr" rid="CR27">27</xref>] to predict real-valued angles and then separately SPIDER2-Delta [<xref ref-type="bibr" rid="CR35">35</xref>] to predict error of those predicted structural properties. Here we describe a simple hybrid technique to predict angles and confidence scores simultaneously.</p>
    <p>Another problem that need to be considered is the periodicity of angles. For example, if an angle <italic>θ</italic>=179° is predicted to be −179°, the error would be treated as 358° instead of 2°. There are some approaches proposed to reduce the impact of cyclic nature of angles. One was angle shifting to reduce confusion at 0° and 360° (or −180° and 180°), e.g., shifting <italic>ψ</italic> by 100° and <italic>ϕ</italic> by −10° [<xref ref-type="bibr" rid="CR26">26</xref>] or adding 100° to the angles between −100° and 180° and adding 460° to the angles between −180° and −100° [<xref ref-type="bibr" rid="CR34">34</xref>]. But the improvement was limited and strongly depended on the angle range. For amino acids such as alanine that had minimal residues in the affected range, angle shifting made little difference [<xref ref-type="bibr" rid="CR29">29</xref>]. A better choice was to take advantage of the inherent angle periodicity of trigonometric functions, that is, mapping the angles to their sine and cosine values [<xref ref-type="bibr" rid="CR27">27</xref>], which has achieved best performance so far. Inspired by this, we deal with equivalent trigonometric representations of dihedral angle pairs, rather than real value angles.</p>
    <p>Considering dihedral angles share similar patterns in alpha helix and beta strand, the acceptable (<italic>ϕ</italic>,<italic>ψ</italic>) patterns are limited. Moreover, it is much easier to do classification than regression. Also indebted to mixture models and Expectation-maximization algorithm, we develop a hybrid method of k-means clustering and deep learning to do angle prediction, combining advantages of discrete and continuous representation of dihedral angles. Specifically, we firstly generate a set of clusters of (<italic>ϕ</italic>,<italic>ψ</italic>) from training data, in which we could get the distribution of each cluster; then we use deep learning methods to predict discrete labels; lastly we predict real value angles by mixing empirical clusters with their predicted probabilities. We employ a residual framework of convolutional neuron network in RaptorX-Angle to predict the cluster label probabilities. We test our method on filtered PDB25 dataset as well as CASP (Critical Assessment of protein Structure Prediction) targets and compare with other three state-of-art methods. Tested on the subset of PDB25, our method gains about 0.5°and 1.4°for <italic>ϕ</italic> and <italic>ψ</italic> better MAE than SPIDER2, currently among the best backbone angle predictors. Our method also performs better than SPIDER2 on the CASP11 and CASP12 test targets. The advantage is even more obvious when looking into detailed secondary structural regions.</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>K-means clustering of angle vectors</title>
      <sec id="Sec4">
        <title>Genearating k-means “centers” from angle vectors</title>
        <p>For a dihedral angle pair (<italic>ϕ</italic>,<italic>ψ</italic>), we can equivalently denote it by an angle vector 
<disp-formula id="Equa"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\mathbf{v}=\left(\cos(\phi), \sin(\phi), \cos(\psi), \sin(\psi)\right). $$ \end{document}</tex-math><mml:math id="M2"><mml:mrow><mml:mi mathvariant="bold">v</mml:mi><mml:mo>=</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mo>cos</mml:mo><mml:mo>(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mo>sin</mml:mo><mml:mo>(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mo>cos</mml:mo><mml:mo>(</mml:mo><mml:mi>ψ</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mo>sin</mml:mo><mml:mo>(</mml:mo><mml:mi>ψ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced><mml:mi>.</mml:mi></mml:mrow></mml:math><graphic xlink:href="12859_2018_2065_Article_Equa.gif" position="anchor"/></alternatives></disp-formula></p>
        <p>Conversely, given the vector representation <bold>v</bold>, we can easily derive the corresponding angles <italic>ϕ</italic> and <italic>ψ</italic> (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: S1.1). We run k-means on angle vectors to cluster dihedral angle pairs in training set into <italic>K</italic>=10,20,…,100 clusters. Then we normalize the <italic>K</italic> centres <inline-formula id="IEq1"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\left \{\mathbf {C}_{k}\right \}_{k=1}^{K}$\end{document}</tex-math><mml:math id="M4"><mml:msubsup><mml:mrow><mml:mfenced close="}" open="{" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq1.gif"/></alternatives></inline-formula> and get the final “centers” <inline-formula id="IEq2"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\left \{\widetilde {\mathbf {C}}_{k} =(\widetilde {c}_{k0}, \widetilde {c}_{k1}, \widetilde {c}_{k2}, \widetilde {c}_{k3})\right \}_{k=1}^{K}$\end{document}</tex-math><mml:math id="M6"><mml:msubsup><mml:mrow><mml:mfenced close="}" open="{" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq2.gif"/></alternatives></inline-formula>, so that each “centre” <inline-formula id="IEq3"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\widetilde {\mathbf {C}}_{k}$\end{document}</tex-math><mml:math id="M8"><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq3.gif"/></alternatives></inline-formula> is a valid representation for some angle pair (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: S1.2).</p>
      </sec>
      <sec id="Sec5">
        <title>Predicting “true” labels from k-means</title>
        <p>Given the <italic>K</italic> normalised vector “centres” <inline-formula id="IEq4"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\left \{\widetilde {\mathbf {C}}_{k}\right \}_{k=1}^{K}$\end{document}</tex-math><mml:math id="M10"><mml:msubsup><mml:mrow><mml:mfenced close="}" open="{" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq4.gif"/></alternatives></inline-formula>, we could assign the “true” label for each dihedral angle pair as the one whose corresponding normalised centre was closest to its respective vector representation. Then the “true” labels can be used as the training labels to build a deep learning model as a classifier to predict labels for testing data.</p>
      </sec>
    </sec>
    <sec id="Sec6">
      <title>Deep learning model details</title>
      <sec id="Sec7">
        <title>Deep Convolutional Neural Network (DCNN)</title>
        <p>DCNN consists of multiple convolutional blocks. A convolutional block is a neural network that implements a composite of linear convolution and nonlinear activation transformation. Convolution is used in place of general matrix multiplication, which can better capture local dependency. It has been widely accepted that protein torsion angles strongly depend on neighbour residues [<xref ref-type="bibr" rid="CR36">36</xref>–<xref ref-type="bibr" rid="CR38">38</xref>]. So DCNN is ideal to abstract angle information from sequence.</p>
      </sec>
      <sec id="Sec8">
        <title>Residual Network (ResNet)</title>
        <p>DCNN can integrate features in hierarchical levels and some work has shown the significance of depth [<xref ref-type="bibr" rid="CR39">39</xref>]. However, with the depth increasing, accuracy gets saturated and even degraded. That is because adding more layers may lead to higher training error as identity mapping is difficult to fit with a stack of nonlinear layers [<xref ref-type="bibr" rid="CR40">40</xref>]. ResNet was proposed as a residual learning framework to ease the training of substantially deeper networks [<xref ref-type="bibr" rid="CR41">41</xref>]. Figure <xref rid="Fig1" ref-type="fig">1</xref> demonstrates the basic architecture of ResNet in RaptorX-Angle. Figure <xref rid="Fig1" ref-type="fig">1</xref><xref rid="Fig1" ref-type="fig">a</xref> is a residual block, which consists of 2 convolution layers and 2 activation layers, and the ResNet consists of stacked residual blocks (Fig. <xref rid="Fig1" ref-type="fig">1</xref><xref rid="Fig1" ref-type="fig">b</xref>). The activation layer conducts a simple nonlinear transformation of its input depending on the activation function with no additional parameters. In this work, we used the ReLU activation function [<xref ref-type="bibr" rid="CR42">42</xref>].
<fig id="Fig1"><label>Fig. 1</label><caption><p>Illustration of the ResNet model in RaptorX-Angle. <bold>a</bold> A building block of ResNet with <italic>x</italic><sub><italic>i</italic></sub> and <italic>x</italic><sub><italic>i</italic>+1</sub> being input and output, respectively. <bold>b</bold> The ResNet model architecture as a classifier with stacked residual blocks and a logistic regression layer. Here <italic>L</italic> is the sequence length of the protein or total number of residues under prediction and <italic>K</italic> is the number of clusters</p></caption><graphic xlink:href="12859_2018_2065_Fig1_HTML" id="MO1"/></fig>
</p>
      </sec>
      <sec id="Sec9">
        <title>Logistic regression layer</title>
        <p>DCNN and ResNet can capture information from data and output abstract features. To do classification for residues, a logistic regression layer is added as the final layer in RaptorX-Angle, which could output the marginal probability of <italic>K</italic> labels (Fig. <xref rid="Fig1" ref-type="fig">1</xref><xref rid="Fig1" ref-type="fig">b</xref>).</p>
      </sec>
      <sec id="Sec10">
        <title>Loss function</title>
        <p>We train model parameters through maximizing the probability of angle pairs belong to the “true” labels. Naturally, the loss function is defined as the negative log-likelihood averaged over all residues of the training proteins.</p>
      </sec>
      <sec id="Sec11">
        <title>Regularization and optimization</title>
        <p>As is widely used in machine learning, the log-likelihood objective function is penalized with a <italic>L</italic><sub>2</sub>-norm of the model parameters to prevent overfitting. Thus, the final objective function has two items: loss function and regularization item, with a regularization factor <italic>λ</italic> to balance the two items. That is, the final objective function is: 
<disp-formula id="Equb"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \max_{\theta}\quad\log{P_{\theta}(Y|X)}-\lambda\|\theta\|^{2} $$ \end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:munder><mml:mrow><mml:mo>max</mml:mo></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:munder><mml:mspace width="1em"/><mml:mo>log</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>Y</mml:mi><mml:mo>|</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>∥</mml:mo><mml:mi>θ</mml:mi><mml:msup><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math><graphic xlink:href="12859_2018_2065_Article_Equb.gif" position="anchor"/></alternatives></disp-formula> where <italic>X</italic> is the input features, <italic>Y</italic> is the output labels, <italic>θ</italic> is the model parameters and <italic>λ</italic> is the regularization factor used to balance the log likelihood and regularization. We use Adam [<xref ref-type="bibr" rid="CR43">43</xref>] to minimize the objective function, which usually can converge within 20 epochs. The whole algorithm has been implemented by Theano [<xref ref-type="bibr" rid="CR44">44</xref>] and mainly run on a GPU card.</p>
      </sec>
      <sec id="Sec12">
        <title>Input features</title>
        <p>For each residue in each protein sequence, we generate a total of 66 input features, of which 20 from position specific scoring matrix(PSSM) of PSI-BLAST [<xref ref-type="bibr" rid="CR45">45</xref>], 20 from position-specific frequency matrix (PSFM) of HHpred [<xref ref-type="bibr" rid="CR46">46</xref>, <xref ref-type="bibr" rid="CR47">47</xref>], 20 from primary sequence, 3 from predicted solvent accessibility (ACC) and 3 from predicted secondary structure(SS) probabilities (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: S1.3).</p>
      </sec>
    </sec>
    <sec id="Sec13">
      <title>Predicting real-value angles from predicted marginal probability</title>
      <p>From the last logistic regression layer of the deep learning model, we could predict the marginal probability <bold>P</bold>=(<italic>p</italic><sub>1</sub>,<italic>p</italic><sub>2</sub>,…,<italic>p</italic><sub><italic>K</italic></sub>) of an angle pair for each label. We use the marginal probability rather than the single predicted label to reduce bias. Concretely, we calculate the weighted mean by: 
<disp-formula id="Equc"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\widehat{\mathbf{v}}=(v_{0},v_{1},v_{2},v_{3})=\sum_{k=1}^{K}p_{k}\widetilde{\mathbf{C_{k}}}, $$ \end{document}</tex-math><mml:math id="M14"><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mover accent="false"><mml:mrow><mml:mstyle mathvariant="bold"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2018_2065_Article_Equc.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>Finally, we normalise <inline-formula id="IEq5"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\widehat {\mathbf {v}}$\end{document}</tex-math><mml:math id="M16"><mml:mover accent="false"><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq5.gif"/></alternatives></inline-formula> to get 
<disp-formula id="Equd"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\widehat{\cos(\phi)}=\frac{v_{0}}{\sqrt{{v_{0}}^{2} + {v_{1}}^{2} }}, \widehat{\sin(\phi)}=\frac{v_{1}}{\sqrt{{v_{0}}^{2} + {v_{1}}^{2} }}, $$ \end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mo>cos</mml:mo><mml:mo>(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mover accent="false"><mml:mrow><mml:mo>sin</mml:mo><mml:mo>(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2018_2065_Article_Equd.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Eque"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\widehat{\cos(\psi)}=\frac{v_{2}}{\sqrt{{v_{2}}^{2} + {v_{3}}^{2} }}, \widehat{\sin(\psi)}=\frac{v_{3}}{\sqrt{{v_{2}}^{2} + {v_{3}}^{2} }}. $$ \end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mover accent="false"><mml:mrow><mml:mo>cos</mml:mo><mml:mo>(</mml:mo><mml:mi>ψ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mover accent="false"><mml:mrow><mml:mo>sin</mml:mo><mml:mo>(</mml:mo><mml:mi>ψ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mi>.</mml:mi></mml:mrow></mml:math><graphic xlink:href="12859_2018_2065_Article_Eque.gif" position="anchor"/></alternatives></disp-formula> and we could derive the predicted real values <inline-formula id="IEq6"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\widehat {\phi },\widehat {\psi }$\end{document}</tex-math><mml:math id="M22"><mml:mover accent="false"><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="false"><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq6.gif"/></alternatives></inline-formula> from this angle vector (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: S1.1). We also tried to predict real-value angles from labels with top <italic>R</italic>(<italic>R</italic>&lt;<italic>K</italic>) probabilities when <italic>K</italic> is well chosen (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: S2.3).</p>
    </sec>
    <sec id="Sec14">
      <title>Programs to compare and evaluation metrics</title>
      <p>We compare our method with three available standalone softwares SPIDER2 [<xref ref-type="bibr" rid="CR27">27</xref>], SPINE X [<xref ref-type="bibr" rid="CR11">11</xref>], and ANGLOR [<xref ref-type="bibr" rid="CR24">24</xref>]. All the programs are run with parameters suggested in their respective papers.</p>
      <p>We evaluate the performance by Pearson Correlation Coefficient (PCC) and Mean Absolute Error (MAE) as described by [<xref ref-type="bibr" rid="CR48">48</xref>], for assessing the prediction of <italic>ϕ</italic>/ <italic>ψ</italic> angles. Considering the periodicity of angles, PCC is calculated between the cosine (sine) values of predicted and experimentally determined angles. MAE is the average absolute difference between predicted and experimentally determined angles. The periodicity of an angle has been taken care of by utilizing the smaller value of the absolute difference <italic>d</italic>(=|<italic>θ</italic><sub><italic>pred</italic></sub>−<italic>θ</italic><sub><italic>exp</italic></sub>|) and 360−<italic>d</italic> for average, where <italic>θ</italic><sub><italic>pred</italic></sub> is the predicted angle and <italic>θ</italic><sub><italic>exp</italic></sub> is the true angle value.</p>
    </sec>
  </sec>
  <sec id="Sec15" sec-type="results">
    <title>Results</title>
    <sec id="Sec16">
      <title>Datasets</title>
      <p>We use the targets from PDB25 updated in February, 2016. The set consists of 10820 non-redundant protein chains, in which any two chains share no more than 25% sequence identity. To remove impact of disordered regions, we filter out proteins with internal disordered regions by DSSP [<xref ref-type="bibr" rid="CR49">49</xref>]. Finally we get 7604 proteins. We then randomly select 5070 proteins as the candidate training set, 1267 as validation set (VL1267, see Additional file <xref rid="MOESM2" ref-type="media">2</xref>) and the remaining 1267 as test set (TS1267, see Additional file <xref rid="MOESM3" ref-type="media">3</xref>). We also test on 85 CASP11 targets (see Additional file <xref rid="MOESM4" ref-type="media">4</xref>) and the latest 40 CASP12 targets (see Additional file <xref rid="MOESM5" ref-type="media">5</xref>) with publicly released native structures. To remove redundancy between training proteins and CASP targets, we run MMseqs2 [<xref ref-type="bibr" rid="CR50">50</xref>], which is similar but more sensitive and faster than BLAST (PSI-BLAST) for protein sequence homology search, with <italic>seqID</italic> cutoff 0.25 and also E-value cutoff 0.001 to filter 5070 the candidate training proteins, resulting in 5046 training proteins (TR5046, see Additional file <xref rid="MOESM6" ref-type="media">6</xref>).</p>
    </sec>
    <sec id="Sec17">
      <title>Choosing a proper number of clusters</title>
      <p>A vital problem is how to select the number of clusters, which can be reduced to defining measures for clustering evaluation. Here we adopt two measures: (i) entropy loss based on discrete distribution; (ii) loglikelihood based on continuous distribution to evaluate 10 different clusterings (<italic>K</italic>=10,20,…,100). Firstly, we do k-means clustering on TR5046 and get <italic>K</italic> empirical clusters. Secondly, we train the deep learning models and do classification on VL1267, then we can obtain the predicted marginal probability of the <italic>K</italic> clusters <italic>P</italic><sub><italic>i</italic></sub>=(<italic>p</italic><sub><italic>i</italic>1</sub>,<italic>p</italic><sub><italic>i</italic>2</sub>,…,<italic>p</italic><sub><italic>iK</italic></sub>),<italic>i</italic>=1,2,…,<italic>N</italic>, where <italic>i</italic> is the index of residue and <italic>N</italic> is the total number of residues in VL1267.</p>
      <sec id="Sec18">
        <title>Entropy loss</title>
        <p>Entropy <italic>H</italic>(·) is always used to measure the information of a distribution. From k-means clustering on TR5046, the background distribution among clusters <italic>P</italic><sub>0</sub>=(<italic>p</italic><sub>01</sub>,<italic>p</italic><sub>02</sub>,…,<italic>p</italic><sub>0<italic>K</italic></sub>) could be derived. Then the entropy loss of this clustering on VL1267 can be calculated as the mean difference between entropy of background distribution and predicted marginal distribution: 
<disp-formula id="Equf"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}} EL &amp; = &amp; \frac{1}{N}\sum_{i=1}^{N}\left(H\left(\mathbf{P_{0}}\right)-H\left(\mathbf{P_{i}}\right)\right)\\ &amp; = &amp; \frac{1}{N}\sum_{i=1}^{N}\left(\sum_{k=1}^{K}p_{0k}\log\left(p_{0k}\right)-\sum_{k=1}^{K}p_{ik}\log\left(p_{ik}\right)\right) \end{array} $$ \end{document}</tex-math><mml:math id="M24"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:mtext mathvariant="italic">EL</mml:mtext></mml:mtd><mml:mtd class="eqnarray-2"><mml:mo>=</mml:mo></mml:mtd><mml:mtd class="eqnarray-3"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>H</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mstyle mathvariant="bold"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mfenced><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mstyle mathvariant="bold"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mtd><mml:mtd><mml:mtext/></mml:mtd></mml:mtr><mml:mtr><mml:mtd class="eqnarray-1"/><mml:mtd class="eqnarray-2"><mml:mo>=</mml:mo></mml:mtd><mml:mtd class="eqnarray-3"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>log</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>−</mml:mo><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ik</mml:mtext></mml:mrow></mml:msub><mml:mo>log</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ik</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mtd><mml:mtd><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2065_Article_Equf.gif" position="anchor"/></alternatives></disp-formula></p>
        <p>which can roughly evaluate the information gain from the clustering. Here <italic>N</italic> is the number of residues in VL1267.</p>
      </sec>
      <sec id="Sec19">
        <title>Loglikelihood</title>
        <p>To demonstrate the detailed information of each cluster, we need a continuous angular(circular) distribution defined on the torus. Mixture bivariate von Mises distributions are successfully used to describe the local bias of torsion angle pair (<italic>ϕ</italic>,<italic>ψ</italic>) [<xref ref-type="bibr" rid="CR21">21</xref>–<xref ref-type="bibr" rid="CR23">23</xref>], we assume that angle pairs belong to the same cluster <italic>k</italic> obey a common bivariate von Mises distribution <italic>f</italic><sub><italic>k</italic></sub> with parameters <inline-formula id="IEq7"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\Theta _{k}=\left (\kappa _{1}^{k}, \kappa _{2}^{k}, \kappa _{3}^{k}, \mu ^{k}, \nu ^{k}\right)$\end{document}</tex-math><mml:math id="M26"><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq7.gif"/></alternatives></inline-formula>. Here, 
<disp-formula id="Equg"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}} f_{k}\left(\phi, \psi \right) &amp; \,=\, &amp; c\left(\kappa_{1}^{k}, \kappa_{2}^{k}, \kappa_{3}^{k}\right)\exp \left\{ \kappa_{1}^{k}\cos\left(\phi-\mu^{k}\right)\right.\\ &amp; &amp; \left.+ \kappa_{2}^{k}\cos\left(\!\psi-\nu^{k}\!\right) \,+\, \kappa_{3}^{k}\cos\left(\!\phi-\mu^{k}-\psi+\nu^{k}\!\right)\! \right\} \end{array} $$ \end{document}</tex-math><mml:math id="M28"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi></mml:mrow></mml:mfenced></mml:mtd><mml:mtd class="eqnarray-2"><mml:mspace width="0.3em"/><mml:mo>=</mml:mo><mml:mspace width="0.3em"/></mml:mtd><mml:mtd class="eqnarray-3"><mml:mi>c</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mo>exp</mml:mo><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:munderover><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:mo>cos</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mtd><mml:mtd><mml:mtext/></mml:mtd></mml:mtr><mml:mtr><mml:mtd class="eqnarray-1"/><mml:mtd class="eqnarray-2"/><mml:mtd class="eqnarray-3"><mml:mfenced close="}" open="" separators=""><mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>cos</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mspace width="0.3em"/><mml:mi>ψ</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mspace width="0.3em"/></mml:mrow></mml:mfenced><mml:mspace width="0.3em"/><mml:mo>+</mml:mo><mml:mspace width="0.3em"/><mml:munderover><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munderover><mml:mo>cos</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mspace width="0.3em"/><mml:mi>ϕ</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi>ψ</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mspace width="0.3em"/></mml:mrow></mml:mfenced><mml:mspace width="0.3em"/></mml:mrow></mml:mfenced></mml:mtd><mml:mtd><mml:mtext/></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2065_Article_Equg.gif" position="anchor"/></alternatives></disp-formula></p>
        <p>where <italic>μ</italic><sup><italic>k</italic></sup> and <italic>ν</italic><sup><italic>k</italic></sup> are the mean value of <italic>ϕ</italic> and <italic>ψ</italic>, respectively; <inline-formula id="IEq8"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\kappa _{1}^{k}, \kappa _{2}^{k}$\end{document}</tex-math><mml:math id="M30"><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq8.gif"/></alternatives></inline-formula> are the concentrations, <inline-formula id="IEq9"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\kappa _{3}^{k}$\end{document}</tex-math><mml:math id="M32"><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq9.gif"/></alternatives></inline-formula> allows for the dependency between the two angles and <inline-formula id="IEq10"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$c\left (\kappa _{1}^{k}, \kappa _{2}^{k}, \kappa _{3}^{k}\right)$\end{document}</tex-math><mml:math id="M34"><mml:mi>c</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq10.gif"/></alternatives></inline-formula> is a normalization constant: 
<disp-formula id="Equh"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{aligned} c\left(\kappa_{1}^{k}, \kappa_{2}^{k}, \kappa_{3}^{k}\right) \!\,=\, \left(2\pi\right)^{2}\left\{\! I_{0}\left(\kappa_{1}^{k}\right)I_{0}\left(\!\kappa_{2}^{k}\!\right)I_{0}\left(\!\kappa_{3}^{k}\!\right) \,+\, 2\sum_{p=1}^{\infty}I_{p}\left(\!\kappa_{1}^{k}\!\right)I_{p}\left(\!\kappa_{2}^{k}\!\right)I_{p}\left(\kappa_{3}^{k}\right) \!\right\} \end{aligned} $$ \end{document}</tex-math><mml:math id="M36"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi>c</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mspace width="0.3em"/><mml:mspace width="0.3em"/><mml:mo>=</mml:mo><mml:mspace width="0.3em"/><mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfenced close="}" open="{" separators=""><mml:mrow><mml:mspace width="0.3em"/><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mspace width="0.3em"/><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mspace width="0.3em"/></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mspace width="0.3em"/><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mspace width="0.3em"/></mml:mrow></mml:mfenced><mml:mspace width="0.3em"/><mml:mo>+</mml:mo><mml:mspace width="0.3em"/><mml:mn>2</mml:mn><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>∞</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mspace width="0.3em"/><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mspace width="0.3em"/></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mspace width="0.3em"/><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mspace width="0.3em"/></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced><mml:mspace width="0.3em"/></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math><graphic xlink:href="12859_2018_2065_Article_Equh.gif" position="anchor"/></alternatives></disp-formula> in which <italic>I</italic><sub><italic>p</italic></sub>(<italic>κ</italic>) is the modified Bessel function of the first kind and order <italic>p</italic>. Parameters <inline-formula id="IEq11"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\left \{\Theta _{k}=\left (\kappa _{1}^{k}, \kappa _{2}^{k}, \kappa _{3}^{k}, \mu ^{k}, \nu ^{k}\right)\right \}_{k=1}^{K}$\end{document}</tex-math><mml:math id="M38"><mml:msubsup><mml:mrow><mml:mfenced close="}" open="{" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>κ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq11.gif"/></alternatives></inline-formula> can be intuitively estimated from the empirical clusters <inline-formula id="IEq12"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\left \{(\phi, \psi)_{k}\right \}_{k=1}^{K}$\end{document}</tex-math><mml:math id="M40"><mml:msubsup><mml:mrow><mml:mfenced close="}" open="{" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq12.gif"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="CR51">51</xref>]. Then the density function for the torsion angle pair (<italic>ϕ</italic>,<italic>ψ</italic>) can be approximately described as: 
<disp-formula id="Equi"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$f(\phi, \psi)=\sum_{k=1}^{K} p_{k}f_{k}(\phi,\psi) $$ \end{document}</tex-math><mml:math id="M42"><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:mi>ψ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2018_2065_Article_Equi.gif" position="anchor"/></alternatives></disp-formula> where <italic>p</italic><sub><italic>k</italic></sub> is the predicted marginal probability of (<italic>ϕ</italic>,<italic>ψ</italic>) belongs to cluster <italic>k</italic>. Then the log-likelihhod for the VL1267 can be calculated as: 
<disp-formula id="Equj"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$LL=\frac{1}{N}\sum_{i=1}^{N}\log{f(\phi_{i}, \psi_{i})}=\frac{1}{N}\sum_{i=1}^{N}\log{\sum_{k=1}^{K} p_{ik}f_{k}(\phi_{i},\psi_{i})} $$ \end{document}</tex-math><mml:math id="M44"><mml:mrow><mml:mtext mathvariant="italic">LL</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mo>log</mml:mo><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mo>log</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ik</mml:mtext></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>ψ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2018_2065_Article_Equj.gif" position="anchor"/></alternatives></disp-formula></p>
      </sec>
      <sec id="Sec20">
        <title>Selecting proper <italic>K</italic></title>
        <p>Figure <xref rid="Fig2" ref-type="fig">2</xref> shows the result of entropy loss and loglikelihood with respect to the number of clusters. As expected, the loglikelihood increases along with <italic>K</italic>, which means it can better describe the data with more clusters. But when <italic>K</italic> goes larger than 30, there is an obvious decrease in entropy loss. Maybe that is because the more clusters are used, the more challenging it would be to do angle prediction. As there is a soaring information gain when <italic>K</italic> goes from 10 to 20 and little difference when K increases from 20 to 30, we test every single clustering between 20 and 30 and there is no significant benefit with more clusters. So we just choose <italic>K</italic>=20 to do following studies.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Selecting proper number of clusters <italic>K</italic>. Left: relationship between entropy loss of discrete label probabilities and number of clusters <italic>K</italic>; Right: relationship between loglikelihood of mixture bivariate von Mises distribution and number of clusters <italic>K</italic></p></caption><graphic xlink:href="12859_2018_2065_Fig2_HTML" id="MO2"/></fig>
</p>
      </sec>
    </sec>
    <sec id="Sec21">
      <title>Feature contribution study</title>
      <p>The features can be divided into three categories: sequence information including amino acid (aa) and profile, predicted secondary structure (SS) and solvent accessibility (ACC). Sequence profile information are generated from PSI-BLAST (PSSM) and HHpred (PSFM) (See Additional file <xref rid="MOESM1" ref-type="media">1</xref>: S1.3 for more details). To test the impact of different feature combinations, we design six experiments: (1) basic1 = 20 PSSM + 20 aa; (2) basic2 = 20 PSFM + 20 aa; (3) basic = 20 PSSM + 20 PSFM + 20 aa; (4) basic + 3 ACC; (5) basic + 3 SS; (6) basic + 3 ACC + 3 SS. The network architecture is fixed as <italic>N</italic><sub><italic>layers</italic></sub>=5,<italic>N</italic><sub><italic>nodes</italic></sub>=100,<italic>h</italic><italic>a</italic><italic>l</italic><italic>f</italic><italic>W</italic><italic>i</italic><italic>n</italic><italic>S</italic><italic>i</italic><italic>z</italic><italic>e</italic>=3 (ResNet 5-100-3), and the regularization factor is fixed to be 0.0001.</p>
      <p>Table <xref rid="Tab1" ref-type="table">1</xref> shows the MAE performance of different feature combinations on TS1267. From the first three experiments with only sequence information involved, there is little performance difference between PSSM and PSFM, and the combination of PSSM and PSFM gains the best accuracy. So PSSM and PSFM are complementary and both unignorable. ACC and SS both contribute significantly and also the combination gain the best accuracy. Finally we use the whole set of features.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>The mean absolute error of different feature combinations with ResNet 5-100-3 on TS1267</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Feature combination</th><th align="left">Phi</th><th align="left">Psi</th><th align="left">Phi_H</th><th align="left">Psi_H</th><th align="left">Phi_E</th><th align="left">Psi_E</th><th align="left">Phi_C</th><th align="left">Psi_C</th></tr></thead><tbody><tr><td align="left">basic1=PSSM+aa</td><td align="left">19.97</td><td align="left">31.97</td><td align="left">9.82</td><td align="left">17.57</td><td align="left">20.70</td><td align="left">26.97</td><td align="left">29.84</td><td align="left">49.66</td></tr><tr><td align="left">basic2=PSFM+aa</td><td align="left">20.02</td><td align="left">31.78</td><td align="left">9.86</td><td align="left">17.68</td><td align="left">20.46</td><td align="left">26.38</td><td align="left">30.10</td><td align="left">49.39</td></tr><tr><td align="left">basic=PSSM+PSFM+aa</td><td align="left">19.27</td><td align="left">30.04</td><td align="left">9.11</td><td align="left">15.58</td><td align="left">19.70</td><td align="left">24.64</td><td align="left">29.35</td><td align="left">48.02</td></tr><tr><td align="left">basic+ACC</td><td align="left">19.08</td><td align="left">29.30</td><td align="left">9.07</td><td align="left">15.44</td><td align="left">19.36</td><td align="left">23.18</td><td align="left">29.11</td><td align="left">47.10</td></tr><tr><td align="left">basic+SS</td><td align="left">19.19</td><td align="left">28.73</td><td align="left">8.56</td><td align="left">13.76</td><td align="left">19.29</td><td align="left">22.43</td><td align="left">31.00</td><td align="left">47.95</td></tr><tr><td align="left">basic+ACC+SS</td><td align="left">18.58</td><td align="left">27.98</td><td align="left">8.45</td><td align="left">13.37</td><td align="left">19.03</td><td align="left">22.14</td><td align="left">28.61</td><td align="left">46.21</td></tr></tbody></table><table-wrap-foot><p>Phi and Psi denote MAE for all residues Phi_H and Psi_H denote MAE for residues in helix region Phi_E and Psi_E denote MAE for residues in beta strand region Phi_C and Psi_C denote MAE for residues in coil region</p></table-wrap-foot></table-wrap>
</p>
    </sec>
    <sec id="Sec22">
      <title>Overall PCC performance of cosine values compared with other methods</title>
      <p>To tune proper regularization factor and also network architectures, we perform 5-fold cross validation on TR5046 (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: S2.1 and S2.2). Finally, we choose an ensemble of 6 networks (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: S2.2). We test our method on TS1267 and also the popular CASP targets, including 85 CASP11 targets and 40 CASP12 targets. Table <xref rid="Tab2" ref-type="table">2</xref> shows the PCC performance of cosine values on the three benchmarks. RaptorX-Angle has gained the highest PCC on all datasets. We also evaluate PCC performance of sine values (See Additional file <xref rid="MOESM1" ref-type="media">1</xref>: S2.4) and get similar results.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Pearson correlation coefficient of cosine values between predicted and true angles</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">TS1267</th><th align="left">CASP11</th><th align="left">CASP12</th><th align="left"/><th align="left"/><th align="left"/></tr><tr><th align="left"/><th align="left">cos(<italic>ϕ</italic>)/cos(<italic>ψ</italic>)</th><th align="left">cos(<italic>ϕ</italic>)/cos(<italic>ψ</italic>)</th><th align="left">cos(<italic>ϕ</italic>)/cos(<italic>ψ</italic>)</th><th align="left"/><th align="left"/><th align="left"/></tr></thead><tbody><tr><td align="left">RaptorX-Angle</td><td align="left"><bold>0.7111</bold>/<bold>0.7576</bold></td><td align="left"><bold>0.6585</bold>/<bold>0.7103</bold></td><td align="left"><bold>0.6539</bold>/<bold>0.6979</bold></td><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">SPIDER2</td><td align="left">0.6893/0.7427</td><td align="left">0.6485/0.7095</td><td align="left">0.6299/0.6761</td><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">SPINE X</td><td align="left">0.6410/0.6543</td><td align="left">0.5015/0.4891</td><td align="left">0.4990/0.5039</td><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">ANGLOR</td><td align="left">0.4775/0.6226</td><td align="left">0.4437/0.5868</td><td align="left">0.4431/0.5772</td><td align="left"/><td align="left"/><td align="left"/></tr></tbody></table></table-wrap>
</p>
    </sec>
    <sec id="Sec23">
      <title>Overall MAE performance compared with other methods</title>
      <p>Table <xref rid="Tab3" ref-type="table">3</xref> shows the MAE performance on the three benchmarks in different secondary structural regions of our RaptorX-Angle comparing with other three methods. All methods have larger MAE on CASP targets than on TS1267. It is reasonable since CASP targets are usually hard to predict. It can be seen that RaptorX-Angle performs the best on all benchmarks, with about 0.5° and 1.4° for <italic>ϕ</italic> and <italic>ψ</italic> better MAE on both TS1267 and CASP12 and slightly better performance on CASP11 than the second best method SPIDER2. We perform Student’s t test of absolute errors between RaptorX-Angle and SPIDER2. As a result, the <italic>p</italic>-values for <italic>ϕ</italic>/<italic>ψ</italic> are 8.65<italic>e</italic>−12/2.79<italic>e</italic>−33, 5.13<italic>e</italic>−2/8.36<italic>e</italic>−2 and 1.28<italic>e</italic>−5/2.59<italic>e</italic>−8 on TS1267, CASP11 and CASP12, respectively. That is, the advantage of RaptorX-Angle over SPIDER2 on TS1267 and CASP12 is statistically more significant than on CASP11. These results demonstrate the rationality of representing the Ramachandran plot with a limited number of clusters, say 20 clusters, and also reflect the power of deep learning methods.
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Mean absolute error of four methods for different secondary structural regions on three benchmarks: TS1267, 85 CASP11 targets and 40 CASP12 targets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">(°)</th><th align="left">Phi</th><th align="left">Psi</th><th align="left">Phi_H</th><th align="left">Psi_H</th><th align="left">Phi_E</th><th align="left">Psi_E</th><th align="left">Phi_C</th><th align="left">Psi_C</th></tr></thead><tbody><tr><td align="left">TS1267</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">RaptorX-Angle</td><td align="left"><bold>18.08</bold></td><td align="left"><bold>26.68</bold></td><td align="left"><bold>8.35</bold></td><td align="left"><bold>12.98</bold></td><td align="left"><bold>18.24</bold></td><td align="left"><bold>20.94</bold></td><td align="left"><bold>27.88</bold></td><td align="left"><bold>44.11</bold></td></tr><tr><td align="left">SPIDER2</td><td align="left">18.57</td><td align="left">28.02</td><td align="left">8.59</td><td align="left">14.52</td><td align="left">19.28</td><td align="left">23.09</td><td align="left">28.28</td><td align="left">44.73</td></tr><tr><td align="left">SPINE X</td><td align="left">20.31</td><td align="left">34.05</td><td align="left">9.32</td><td align="left">16.69</td><td align="left">22.23</td><td align="left">31.23</td><td align="left">30.32</td><td align="left">53.42</td></tr><tr><td align="left">ANGLOR</td><td align="left">24.01</td><td align="left">43.59</td><td align="left">9.29</td><td align="left">26.41</td><td align="left">27.47</td><td align="left">40.88</td><td align="left">36.89</td><td align="left">62.72</td></tr><tr><td align="left">CASP11</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">RaptorX-Angle</td><td align="left"><bold>20.00</bold></td><td align="left"><bold>30.14</bold></td><td align="left"><bold>9.49</bold></td><td align="left"><bold>15.65</bold></td><td align="left"><bold>18.82</bold></td><td align="left"><bold>23.58</bold></td><td align="left"><bold>29.87</bold></td><td align="left">46.89</td></tr><tr><td align="left">SPIDER2</td><td align="left">20.18</td><td align="left">30.32</td><td align="left">9.53</td><td align="left">16.05</td><td align="left">19.77</td><td align="left">24.50</td><td align="left">29.88</td><td align="left"><bold>46.84</bold></td></tr><tr><td align="left">SPINE X</td><td align="left">24.85</td><td align="left">46.58</td><td align="left">13.57</td><td align="left">29.65</td><td align="left">26.25</td><td align="left">43.65</td><td align="left">33.88</td><td align="left">63.49</td></tr><tr><td align="left">ANGLOR</td><td align="left">25.69</td><td align="left">46.17</td><td align="left">9.99</td><td align="left">27.72</td><td align="left">28.08</td><td align="left">43.85</td><td align="left">37.96</td><td align="left">64.03</td></tr><tr><td align="left">CASP12</td><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/><td align="left"/></tr><tr><td align="left">RaptorX-Angle</td><td align="left"><bold>20.69</bold></td><td align="left"><bold>32.73</bold></td><td align="left">9.28</td><td align="left"><bold>16.73</bold></td><td align="left"><bold>19.94</bold></td><td align="left"><bold>26.06</bold></td><td align="left"><bold>31.22</bold></td><td align="left"><bold>51.02</bold></td></tr><tr><td align="left">SPIDER2</td><td align="left">21.13</td><td align="left">34.17</td><td align="left"><bold>9.13</bold></td><td align="left">17.19</td><td align="left">21.35</td><td align="left">28.56</td><td align="left">31.95</td><td align="left">52.76</td></tr><tr><td align="left">SPINE X</td><td align="left">24.85</td><td align="left">46.57</td><td align="left">11.52</td><td align="left">26.34</td><td align="left">26.98</td><td align="left">46.04</td><td align="left">35.85</td><td align="left">65.33</td></tr><tr><td align="left">ANGLOR</td><td align="left">25.79</td><td align="left">47.37</td><td align="left">9.69</td><td align="left">28.81</td><td align="left">29.11</td><td align="left">44.79</td><td align="left">38.65</td><td align="left">65.74</td></tr></tbody></table><table-wrap-foot><p>Same notations with Table <xref rid="Tab1" ref-type="table">1</xref></p></table-wrap-foot></table-wrap>
</p>
    </sec>
    <sec id="Sec24">
      <title>Mean absolute error performance study in VL1267</title>
      <p>In methodology, the conversion from angle pair to trigonometric vector is nonlinear, the prediction error may depend on angles. And in biology, prediction error may differ for different amino acids with different microscopic biochemical properties, and also for different protein classes with different macroscopic structures. So we perform detailed studies on prediction error in VL1267.</p>
      <sec id="Sec25">
        <title>Study mean absolute error performance for different clusters</title>
        <p>As each cluster corresponds to a certain angle region, we calculate the MAE for each cluster in VL1267. We observe that the 20 clusters are well consistent with Ramachandran plot and also the two peaks for <italic>ϕ</italic> and <italic>ψ</italic> [<xref ref-type="bibr" rid="CR11">11</xref>] (Fig. <xref rid="Fig3" ref-type="fig">3</xref> Left). And the prediction errors differ a lot between clusters. It turns out that clusters with more residues in coil region tend to result in larger prediction errors. Moreover, prediction error for <italic>ϕ</italic> is smaller than for <italic>ψ</italic>. But there are three uncommon clusters with larger MAE for <italic>ϕ</italic>, i.e., 5, 6 and 10 (Fig. <xref rid="Fig3" ref-type="fig">3</xref> Right). Clusters 5 and 6 are totally in one of the peak areas in Ramachandran plot, which may indicate some interesting biological discoveries.
<fig id="Fig3"><label>Fig. 3</label><caption><p>Mean absolute error performance for different clusters in VL1267. Left: visualization of 20 cluster centers on the Ramachandran plot with smaller number indicating smaller size. Right: mean absolute error for different clusters</p></caption><graphic xlink:href="12859_2018_2065_Fig3_HTML" id="MO3"/></fig>
</p>
      </sec>
      <sec id="Sec26">
        <title>Mean absolute error performance for each amino acid type</title>
        <p>As different amino acids have different stereochemical and physiochemical properties, they are anticipated to have different degrees of difficulty for the torsion angle prediction. In Table <xref rid="Tab4" ref-type="table">4</xref>, we examine the MAE performance for each of 20 amino acid types. Glycine, with no side-chain atom except for a proton, has least steric restriction to backbone dihedral angle motions. As a result, it has the largest prediction error (43.32° / 39.59° for <italic>ϕ</italic>/<italic>ψ</italic>). In contrast, Proline has the least MAE (8.84°) for <italic>ϕ</italic> but has an unusually large MAE (33.00°) for <italic>ψ</italic> prediction due to its special side-chain structure, which is consistent with [<xref ref-type="bibr" rid="CR24">24</xref>]. In addition, three of the amino acids (Ile, Leu and Val) with the smallest MAE are all hydrophobic.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Mean absolute error performance for each amino acid type in VL1267</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Amino acids</th><th align="left">Abundance</th><th align="left">Frequency (<italic>%</italic>)</th><th align="left"><italic>ϕ</italic>(°)</th><th align="left"><italic>ψ</italic>(°)</th></tr></thead><tbody><tr><td align="left">A (Ala)</td><td align="left">22527</td><td align="left">8.46</td><td align="left">13.87</td><td align="left">22.92</td></tr><tr><td align="left">C (Cys)</td><td align="left">3151</td><td align="left">1.18</td><td align="left">20.50</td><td align="left">28.66</td></tr><tr><td align="left">D (Asp)</td><td align="left">15946</td><td align="left">5.99</td><td align="left">20.71</td><td align="left">30.80</td></tr><tr><td align="left">E (Glu)</td><td align="left">18326</td><td align="left">6.89</td><td align="left">14.75</td><td align="left">23.97</td></tr><tr><td align="left">F (Phe)</td><td align="left">10812</td><td align="left">4.06</td><td align="left">18.13</td><td align="left">26.10</td></tr><tr><td align="left">G (Gly)</td><td align="left">19133</td><td align="left">7.19</td><td align="left">43.32</td><td align="left">39.59</td></tr><tr><td align="left">H (His)</td><td align="left">5989</td><td align="left">2.25</td><td align="left">22.04</td><td align="left">31.12</td></tr><tr><td align="left">I (Ile)</td><td align="left">15302</td><td align="left">5.75</td><td align="left">12.79</td><td align="left">20.12</td></tr><tr><td align="left">K (Lys)</td><td align="left">15299</td><td align="left">5.75</td><td align="left">16.71</td><td align="left">25.83</td></tr><tr><td align="left">L (Leu)</td><td align="left">24731</td><td align="left">9.29</td><td align="left">12.49</td><td align="left">21.37</td></tr><tr><td align="left">M (Met)</td><td align="left">5833</td><td align="left">2.19</td><td align="left">16.71</td><td align="left">24.86</td></tr><tr><td align="left">N (Asn)</td><td align="left">11383</td><td align="left">4.28</td><td align="left">27.38</td><td align="left">32.04</td></tr><tr><td align="left">P (Pro)</td><td align="left">11977</td><td align="left">4.50</td><td align="left">8.84</td><td align="left">33.00</td></tr><tr><td align="left">Q (Gln)</td><td align="left">10163</td><td align="left">3.82</td><td align="left">15.96</td><td align="left">24.72</td></tr><tr><td align="left">R (Arg)</td><td align="left">13529</td><td align="left">5.08</td><td align="left">16.81</td><td align="left">25.45</td></tr><tr><td align="left">S (Ser)</td><td align="left">15991</td><td align="left">6.01</td><td align="left">20.83</td><td align="left">33.92</td></tr><tr><td align="left">T (Thr)</td><td align="left">14309</td><td align="left">5.38</td><td align="left">17.12</td><td align="left">30.92</td></tr><tr><td align="left">V (Val)</td><td align="left">18612</td><td align="left">6.99</td><td align="left">13.70</td><td align="left">20.94</td></tr><tr><td align="left">W (Trp)</td><td align="left">3854</td><td align="left">1.45</td><td align="left">18.05</td><td align="left">27.61</td></tr><tr><td align="left">Y (Tyr)</td><td align="left">9287</td><td align="left">3.49</td><td align="left">18.83</td><td align="left">27.02</td></tr><tr><td align="left">Total</td><td align="left">266154</td><td align="left">100</td><td align="left">18.32</td><td align="left">27.15</td></tr></tbody></table></table-wrap>
</p>
      </sec>
      <sec id="Sec27">
        <title>Mean absolute error performance for different protein classes</title>
        <p>After studying on MAE performance in microcosmic view, we intend to study the performance for different macroscopical structures. We abstract 99, 117, 171, 117 proteins from VL1267 (resulted in 17696, 24874, 47304 and 19645 residues) in all <italic>α</italic>, all <italic>β</italic>, <italic>α</italic>/<italic>β</italic> and <italic>α</italic>+<italic>β</italic> classes, respectively. We calculate the absolute error for every residue in each class. Figure <xref rid="Fig4" ref-type="fig">4</xref> shows the violin plot of prediction error for <italic>ϕ</italic> (Left) and <italic>ψ</italic> (Right). A violin plot is similar to box plot except that it also shows the probability density of the data. We can see although the MAE for <italic>ϕ</italic> are smaller for all protein classes, prediction errors belong to each protein class have their own distribution pattern and the pattern is similar between <italic>ϕ</italic> and <italic>ψ</italic>. Overall, prediction errors are smallest in all <italic>α</italic> proteins and largest in all <italic>β</italic> for both <italic>ϕ</italic> and <italic>ψ</italic> predictions.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Mean absolute error performance for different protein classes in VL1267. Left: for <italic>ϕ</italic> prediction. Right: for <italic>ψ</italic> prediction</p></caption><graphic xlink:href="12859_2018_2065_Fig4_HTML" id="MO4"/></fig>
</p>
      </sec>
    </sec>
    <sec id="Sec28">
      <title>Estimating confidence score of predicted angles</title>
      <p>Generally, variance <italic>σ</italic><sup>2</sup> includes variance within cluster <inline-formula id="IEq13"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\sigma _{w}^{2}$\end{document}</tex-math><mml:math id="M46"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq13.gif"/></alternatives></inline-formula> and variance between cluster <inline-formula id="IEq14"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\sigma _{b}^{2}$\end{document}</tex-math><mml:math id="M48"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq14.gif"/></alternatives></inline-formula>. To produce the confidence score of our predicted angles, we calculate the standard deviation from variances within a cluster. Specifically, for each cluster <italic>k</italic>, we can get the in-cluster variance <inline-formula id="IEq15"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\sigma _{k}^{2}(\theta)$\end{document}</tex-math><mml:math id="M50"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:math><inline-graphic xlink:href="12859_2018_2065_Article_IEq15.gif"/></alternatives></inline-formula> from training data, where <italic>θ</italic>=<italic>ϕ</italic> or <italic>ψ</italic>. Then we derive the variance of prediction by: 
<disp-formula id="Equk"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$var(\theta)=\sigma^{2}(\theta)=\sum_{k=1}^{K}p_{k}\sigma_{k}^{2}(\theta) $$ \end{document}</tex-math><mml:math id="M52"><mml:mrow><mml:mtext mathvariant="italic">var</mml:mtext><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2018_2065_Article_Equk.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>Figure <xref rid="Fig5" ref-type="fig">5</xref> shows the mean standard deviation for <italic>ϕ</italic> and <italic>ψ</italic> in different regions. As expected, the smallest variance appears in helix region, and then strand and lastly coil region. The standard deviation in disordered regions are rather large and quite similar to coil regions, which is consistent with our prior knowledge that disordered region resembles loop region and is rather flexible.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Mean standard deviation for different secondary structural regions in TS1267</p></caption><graphic xlink:href="12859_2018_2065_Fig5_HTML" id="MO5"/></fig>
</p>
      <p>Figure <xref rid="Fig6" ref-type="fig">6</xref> demonstrates the relationship between MAE and mean standard deviation for <italic>ϕ</italic> and <italic>ψ</italic> in different regions on VL1267. Roughly, the relationship is linear (<italic>R</italic><sup>2</sup>=0.8911). So the MAE can be bounded well by the standard deviation. We predict the error for each residue in each target from TS1267 and calculate corresponding Pearson and Spearman correlation coefficients (<italic>PCC</italic> and <italic>SCC</italic>) between prediction errors and true errors, and also the mean absolute error for prediction errors (MAEPE). Finally, we obtain <italic>P</italic><italic>C</italic><italic>C</italic>=0.3109,<italic>S</italic><italic>S</italic><italic>C</italic>=0.5427,<italic>M</italic><italic>A</italic><italic>E</italic><italic>P</italic><italic>E</italic>=13.94 for <italic>ϕ</italic> and <italic>P</italic><italic>C</italic><italic>C</italic>=0.2597,<italic>S</italic><italic>C</italic><italic>C</italic>=0.4751,<italic>M</italic><italic>A</italic><italic>E</italic><italic>P</italic><italic>E</italic>=26.21 for <italic>ψ</italic>. We also try to fit two linear models for <italic>ϕ</italic> and <italic>ψ</italic> separately on the all data points in VL1267 and get similar testing results. This indicates that the mean for different secondary structural regions almost contains enough information about the relationship between the estimated standard deviation and prediction error (Additional file <xref rid="MOESM1" ref-type="media">1</xref>: S2.6).
<fig id="Fig6"><label>Fig. 6</label><caption><p>Relationship betwee n prediction error and standard deviation. Eight points are for two kinds of angles (<italic>ϕ</italic>,<italic>ψ</italic>) in four secondary structural regions (total, helix, strand, coil)</p></caption><graphic xlink:href="12859_2018_2065_Fig6_HTML" id="MO6"/></fig>
</p>
    </sec>
    <sec id="Sec29">
      <title>Computational cost analysis</title>
      <p>All mentioned methods could do angle prediction target by target, so the computational cost is bounded by the longest protein (i.e., protein with the largest number of residues). To generate angle predictions for 1xdoA, the largest protein in TS1267 with 685 residues, it takes 726s, 123s, 370s and 524s for ANGLOR, spineX, SPIDER2 and RaptorX-Angle, respectively.</p>
      <p>As far as we see, the computational cost is mainly determined by method outline, network complexity, feature engineering and technical resources. ANGLOR is a composite method and the technology was not so developed at that time, it needs the most time. While spineX just adopted a simple network, SPIDER2 used more features iteratively in a more complex network and it takes longer than spineX.</p>
      <p>Compared with the second best SPIDER2, RaptorX-Angle used much deeper networks and also adopted profile information from hhblits (PSFM), besides PSSM from PSI-BLAST harnessed by spineX and SPIDER2. As a result, it takes SPIDER2 360s to generate features with 4 CPUs and 20s to predict angles using a CPU, while it takes RaptorX-Angle 385s to generate features with 4 CPUs, and 200s to predict angles from the features using a GPU card.</p>
      <p>However, we can integrate the features of a total batch of proteins and run them all at once. Actually, it just takes 750s to do angle prediction for all proteins in TS1267, while other methods needs many CPUs in parallel. Overall, our method is faster for prediction of many proteins and has gained better prediction accuracy.</p>
    </sec>
  </sec>
  <sec id="Sec30" sec-type="discussion">
    <title>Discussion</title>
    <p>We have transformed the hard real-valued prediction problem into a discrete label assignment problem, which has simplified the problem and also gained better results. Overall, our RaptorX-Angle gains the best PCC in terms of cosine and sine of angles on all datasets. It has about 0.5° and 1.4° for <italic>ϕ</italic> and <italic>ψ</italic> better MAE than the second best method SPIDER2 on a subset of PDB25. We have also calculated the two-state accuracy to see how much improvement there would be in large angle errors. RaptorX-Angle performs the best and has about 0.15 and 1 percent improvement over SPIDER2 for <italic>ϕ</italic> and <italic>ψ</italic> on TS1267(See Additional file <xref rid="MOESM1" ref-type="media">1</xref>: S2.5). Our method also works very well on the CASP targets. Moreover, we have estimated the prediction errors at each residue by a mixture of the clusters with their predicted probabilities. It has been shown that there is approximately linear relationship between the real prediction error and in-cluster standard deviation. That is a unique feature of our method. In addition, we check the prediction for disordered regions. As there is no angle information, we just analyze the standard deviation and get quite large values and similar patterns to coil region. It is consistent with our prior knowledge that disordered region is rather flexible and resembles loop region. We also do comprehensive studies on prediction performance in VL1267, both in microscopic and macroscopic view.</p>
    <p>This simple technique has gained better performance than other state-of-art methods. It demonstrates that for protein structures, the 20 clusters contain enough information for (<italic>ϕ</italic>,<italic>ψ</italic>), which is an efficient compression of information. The idea that to predict dihedral angles from clustering has turned out to be successful due to three aspects. The first is the continuous growth of the solved structures [<xref ref-type="bibr" rid="CR52">52</xref>], so we have enough training data. The second is the novel idea to predict real-value angles by mixing a set of clusters with their respective predicted probabilities. Conversely, such good performance demonstrated that the distribution of protein backbone dihedral angles can be described through a set of clusters. Last but not the least, the everlasting development of deep learning models and optimization methods proves to be a powerful tool to promote new ideas and exploit new methods.</p>
    <p>But there is still room for improvement. RaptorX-Angle just used one-dimensional features and adopted 1D CNN. It cannot extract information of long range interaction. Heffernan et al. has developed more accurate SPIDER3 employing Long Short-Term Memory (LSTM) Bidirectional Recurrent Neural Networks (BRNNs), which are capable of capturing long range interactions [<xref ref-type="bibr" rid="CR53">53</xref>]. That is, considering pairwise interaction can further increase prediction accuracy. We will include two-dimensional features and exploit 2D CNN to see how much improvement could be achieved.</p>
    <p>Moreover, as mentioned before, accumulation of prediction errors has buried the usefulness of torsion angles to construct 3D models. There is a great demand to develop a proper technique to deal with the errors. A general pipeline to add angle restraints and confidence to improve protein tertiary structure prediction need to be developed.</p>
  </sec>
  <sec id="Sec31" sec-type="conclusion">
    <title>Conclusions</title>
    <p>In conclusion, this study has made a more reliable prediction of dihedral angles and may facilitate protein structure prediction and functional study. In the near future, we can use the angle restraints to do tertiary structure prediction, which should be considered carefully to deal with errors and flexibility. We can also adopt the angle prediction to aid structure alignment and fold recognition.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Additional files</title>
    <sec id="Sec32">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2018_2065_MOESM1_ESM.pdf">
            <label>Additional file 1</label>
            <caption>
              <p>Supplementary Material. This additional file contains two parts: S1. supplementary methods for vector representation and normalisation of angles, and also feature generation; S2. supplementary results for determining regularization factor, testing different network architectures, testing different number of labels to use for real value prediction and performance comparison. (PDF 250 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="12859_2018_2065_MOESM2_ESM.txt">
            <label>Additional file 2</label>
            <caption>
              <p>This additional file contains target list for the validation set from PDB25 consisting of 1267 proteins. (TXT 7.42 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="12859_2018_2065_MOESM3_ESM.txt">
            <label>Additional file 3</label>
            <caption>
              <p>This additional file contains target list for the testing set from PDB25 consisting of 1267 proteins. (TXT 7.42 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM4">
          <media xlink:href="12859_2018_2065_MOESM4_ESM.txt">
            <label>Additional file 4</label>
            <caption>
              <p>This additional file contains target list for the testing set from CASP11 consisting of 85 proteins. (TXT 0.51 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM5">
          <media xlink:href="12859_2018_2065_MOESM5_ESM.txt">
            <label>Additional file 5</label>
            <caption>
              <p>This additional file contains target list for the testing set from CASP12 consisting of 40 proteins. (TXT 0.24 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
      <p>
        <supplementary-material content-type="local-data" id="MOESM6">
          <media xlink:href="12859_2018_2065_MOESM6_ESM.txt">
            <label>Additional file 6</label>
            <caption>
              <p>This additional file contains target list for the training set from PDB25 consisting of 5046 proteins. (TXT 29.5 kb)</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>ACC</term>
        <def>
          <p>Solvent accessibility</p>
        </def>
      </def-item>
      <def-item>
        <term>CASP</term>
        <def>
          <p>Critical assessment of protein structure prediction</p>
        </def>
      </def-item>
      <def-item>
        <term>DCNN</term>
        <def>
          <p>Deep convolutional neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>MAE</term>
        <def>
          <p>Mean absolute error</p>
        </def>
      </def-item>
      <def-item>
        <term>PCC</term>
        <def>
          <p>Pearson correlation coefficient</p>
        </def>
      </def-item>
      <def-item>
        <term>ResNet</term>
        <def>
          <p>Residual network</p>
        </def>
      </def-item>
      <def-item>
        <term>SS</term>
        <def>
          <p>Secondary structure</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Electronic supplementary material</bold>
      </p>
      <p>The online version of this article (10.1186/s12859-018-2065-x) contains supplementary material, which is available to authorized users.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>None.</p>
    <sec id="d29e4613">
      <title>Funding</title>
      <p>This work has been partly supported by the National Key Research and Development Program of China(No.2016YFA0502303), the National Key Basic Research Project of China (No. 2015CB910303), the National Natural Science Foundation of China (No.31471246) and China Scholarship Council.</p>
      <p>It is also supported by National Institutes of Health grant R01GM089753 to JX and National Science Foundation grant DBI-1564955 to JX. The authors are also grateful to the support of Nvidia Inc. The publication costs of this manuscript were financially supported by National Institutes of Health grant R01GM089753 to JX and National Science Foundation grant DBI-1564955 to JX.</p>
    </sec>
    <sec id="d29e4620">
      <title>Availability of data and materials</title>
      <p>The software package for our method, including feature generation and angle prediction, is open source and freely available from <ext-link ext-link-type="uri" xlink:href="https://github.com/lacus2009/RaptorX-Angle.git">https://github.com/lacus2009/RaptorX-Angle.git</ext-link>. The target lists of datasets supporting the conclusions of this article are included as additional files. All the data are available upon request.</p>
    </sec>
    <sec id="d29e4630">
      <title>About this supplement</title>
      <p>This article has been published as part of <italic>BMC Bioinformatics</italic> Volume 19 Supplement 4, 2018: Selected articles from the 16th Asia Pacific Bioinformatics Conference (APBC 2018): bioinformatics. The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="https://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-19-supplement-4">https://bmcbioinformatics.biomedcentral.com/articles/supplements/volume-19-supplement-4</ext-link>.</p>
    </sec>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>YG carried out the experiments and drafted the manuscript. SW participated in the feature generation and data integration. YG and JX implemented the package. JX and MD participated in the design of the study. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="COI-statement">
    <sec id="d29e4649">
      <title>Ethics approval and consent to participate</title>
      <p>Not applicable.</p>
    </sec>
    <sec id="d29e4654">
      <title>Consent for publication</title>
      <p>Not applicable.</p>
    </sec>
    <sec id="d29e4659">
      <title>Competing interests</title>
      <p>The authors declare that they have no competing interests.</p>
    </sec>
    <sec id="d29e4664">
      <title>Publisher’s Note</title>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </sec>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Marks</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Hopf</surname>
            <given-names>TA</given-names>
          </name>
          <name>
            <surname>Sander</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Protein structure prediction from sequence variation</article-title>
        <source>Nat Biotechnol</source>
        <year>2012</year>
        <volume>30</volume>
        <issue>11</issue>
        <fpage>1072</fpage>
        <lpage>80</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.2419</pub-id>
        <?supplied-pmid 23138306?>
        <pub-id pub-id-type="pmid">23138306</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>De Juan</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Pazos</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Valencia</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Emerging methods in protein co-evolution</article-title>
        <source>Nat Rev Genet</source>
        <year>2013</year>
        <volume>14</volume>
        <issue>4</issue>
        <fpage>249</fpage>
        <lpage>61</lpage>
        <pub-id pub-id-type="doi">10.1038/nrg3414</pub-id>
        <?supplied-pmid 23458856?>
        <pub-id pub-id-type="pmid">23458856</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kurgan</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Miri Disfani</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Structural protein descriptors in 1-dimension and their sequence-based predictions</article-title>
        <source>Curr Protein Peptide Sci</source>
        <year>2011</year>
        <volume>12</volume>
        <issue>6</issue>
        <fpage>470</fpage>
        <lpage>89</lpage>
        <pub-id pub-id-type="doi">10.2174/138920311796957711</pub-id>
        <pub-id pub-id-type="pmid">21787299</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wood</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Hirst</surname>
            <given-names>JD</given-names>
          </name>
        </person-group>
        <article-title>Protein secondary structure prediction with dihedral angles</article-title>
        <source>PROTEINS: Struct Funct Bioinform</source>
        <year>2005</year>
        <volume>59</volume>
        <issue>3</issue>
        <fpage>476</fpage>
        <lpage>81</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.20435</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kountouris</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Hirst</surname>
            <given-names>JD</given-names>
          </name>
        </person-group>
        <article-title>Predicting <italic>β</italic>-turns and their types using predicted backbone dihedral angles and secondary structures</article-title>
        <source>BMC Bioinformatics</source>
        <year>2010</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>407</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-11-407</pub-id>
        <?supplied-pmid 20673368?>
        <pub-id pub-id-type="pmid">20673368</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Faraggi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Kurgan</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Spine x: improving protein secondary structure prediction by multistep learning coupled with prediction of solvent accessible surface area and backbone torsion angles</article-title>
        <source>J Comput Chem</source>
        <year>2012</year>
        <volume>33</volume>
        <issue>3</issue>
        <fpage>259</fpage>
        <lpage>67</lpage>
        <pub-id pub-id-type="doi">10.1002/jcc.21968</pub-id>
        <?supplied-pmid 22045506?>
        <pub-id pub-id-type="pmid">22045506</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Miao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Waddell</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Valafar</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Tali: local alignment of protein structures using backbone torsion angles</article-title>
        <source>J Bioinform Comput Biol</source>
        <year>2008</year>
        <volume>6</volume>
        <issue>01</issue>
        <fpage>163</fpage>
        <lpage>81</lpage>
        <pub-id pub-id-type="doi">10.1142/S0219720008003370</pub-id>
        <?supplied-pmid 18324751?>
        <pub-id pub-id-type="pmid">18324751</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jung</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Bae</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Son</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Validity of protein structure alignment method based on backbone torsion angles</article-title>
        <source>J Proteomics Bioinform</source>
        <year>2011</year>
        <volume>4</volume>
        <fpage>218</fpage>
        <lpage>26</lpage>
        <pub-id pub-id-type="doi">10.4172/jpb.1000192</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>SH</given-names>
          </name>
        </person-group>
        <article-title>Fold prediction of helical proteins using torsion angle dynamics and predicted restraints</article-title>
        <source>Proc Natl Acad Sci</source>
        <year>2002</year>
        <volume>99</volume>
        <issue>6</issue>
        <fpage>3581</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.052003799</pub-id>
        <?supplied-pmid 11904420?>
        <pub-id pub-id-type="pmid">11904420</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Sp 5: improving protein fold recognition by using torsion angle profiles and profile-based gap penalty model</article-title>
        <source>PloS ONE</source>
        <year>2008</year>
        <volume>3</volume>
        <issue>6</issue>
        <fpage>2325</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0002325</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Faraggi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Predicting continuous local structure and the effect of its substitution for secondary structure in fragment-free protein structure prediction</article-title>
        <source>Structure</source>
        <year>2009</year>
        <volume>17</volume>
        <issue>11</issue>
        <fpage>1515</fpage>
        <lpage>27</lpage>
        <pub-id pub-id-type="doi">10.1016/j.str.2009.09.006</pub-id>
        <?supplied-pmid 19913486?>
        <pub-id pub-id-type="pmid">19913486</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sims</surname>
            <given-names>GE</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>SH</given-names>
          </name>
        </person-group>
        <article-title>A method for evaluating the structural quality of protein models by using higher-order <italic>φ</italic>– <italic>ψ</italic> pairs scoring</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2006</year>
        <volume>103</volume>
        <issue>12</issue>
        <fpage>4428</fpage>
        <lpage>32</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.0511333103</pub-id>
        <?supplied-pmid 16537409?>
        <pub-id pub-id-type="pmid">16537409</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cao</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Improving the performance of the plb index for ligand-binding site prediction using dihedral angles and the solvent-accessible surface area</article-title>
        <source>Sci Rep</source>
        <year>2016</year>
        <volume>6</volume>
        <fpage>33232</fpage>
        <pub-id pub-id-type="doi">10.1038/srep33232</pub-id>
        <?supplied-pmid 27619067?>
        <pub-id pub-id-type="pmid">27619067</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ramachandran</surname>
            <given-names>GT</given-names>
          </name>
          <name>
            <surname>Sasisekharan</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Conformation of polypeptides and proteins</article-title>
        <source>Adv Protein Chem</source>
        <year>1968</year>
        <volume>23</volume>
        <fpage>283</fpage>
        <lpage>437</lpage>
        <pub-id pub-id-type="doi">10.1016/S0065-3233(08)60402-7</pub-id>
        <?supplied-pmid 4882249?>
        <pub-id pub-id-type="pmid">4882249</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Colubri</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jha</surname>
            <given-names>AK</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>M-Y</given-names>
          </name>
          <name>
            <surname>Sali</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Berry</surname>
            <given-names>RS</given-names>
          </name>
          <name>
            <surname>Sosnick</surname>
            <given-names>TR</given-names>
          </name>
          <name>
            <surname>Freed</surname>
            <given-names>KF</given-names>
          </name>
        </person-group>
        <article-title>Minimalist representations and the importance of nearest neighbor effects in protein folding simulations</article-title>
        <source>J Mol Biol</source>
        <year>2006</year>
        <volume>363</volume>
        <issue>4</issue>
        <fpage>835</fpage>
        <lpage>57</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmb.2006.08.035</pub-id>
        <?supplied-pmid 16982067?>
        <pub-id pub-id-type="pmid">16982067</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gong</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Fleming</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Rose</surname>
            <given-names>GD</given-names>
          </name>
        </person-group>
        <article-title>Building native protein conformation from highly approximate backbone torsion angles</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2005</year>
        <volume>102</volume>
        <issue>45</issue>
        <fpage>16227</fpage>
        <lpage>32</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.0508415102</pub-id>
        <?supplied-pmid 16251268?>
        <pub-id pub-id-type="pmid">16251268</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <mixed-citation publication-type="other">Dowe DL, Allison L, Dix TI, Hunter L, Wallace CS, et al. Circular clustering of protein dihedral angles by minimum message length. Proc. 1st Pacific Symp. Biocomput. 1996.</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kuang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Leslie</surname>
            <given-names>CS</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>AS</given-names>
          </name>
        </person-group>
        <article-title>Protein backbone angle prediction with machine learning approaches</article-title>
        <source>Bioinformatics</source>
        <year>2004</year>
        <volume>20</volume>
        <issue>10</issue>
        <fpage>1612</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bth136</pub-id>
        <?supplied-pmid 14988121?>
        <pub-id pub-id-type="pmid">14988121</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zimmermann</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Hansmann</surname>
            <given-names>UH</given-names>
          </name>
        </person-group>
        <article-title>Support vector machines for prediction of dihedral angle regions</article-title>
        <source>Bioinformatics</source>
        <year>2006</year>
        <volume>22</volume>
        <issue>24</issue>
        <fpage>3009</fpage>
        <lpage>15</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btl489</pub-id>
        <?supplied-pmid 17005536?>
        <pub-id pub-id-type="pmid">17005536</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Xue</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Accurate prediction of protein dihedral angles through conditional random field</article-title>
        <source>Front Biol</source>
        <year>2013</year>
        <volume>8</volume>
        <issue>3</issue>
        <fpage>353</fpage>
        <lpage>61</lpage>
        <pub-id pub-id-type="doi">10.1007/s11515-013-1261-3</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Singh</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Hnizdo</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Demchuk</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Probabilistic model for two dependent circular variables</article-title>
        <source>Biometrik</source>
        <year>2002</year>
        <volume>89</volume>
        <fpage>719</fpage>
        <lpage>23</lpage>
        <pub-id pub-id-type="doi">10.1093/biomet/89.3.719</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mardia</surname>
            <given-names>KV</given-names>
          </name>
          <name>
            <surname>Taylor</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Subramaniam</surname>
            <given-names>GK</given-names>
          </name>
        </person-group>
        <article-title>Protein bioinformatics and mixtures of bivariate von mises distributions for angular data</article-title>
        <source>Biometrics</source>
        <year>2007</year>
        <volume>63</volume>
        <issue>2</issue>
        <fpage>505</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1541-0420.2006.00682.x</pub-id>
        <?supplied-pmid 17688502?>
        <pub-id pub-id-type="pmid">17688502</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>SC</given-names>
          </name>
          <name>
            <surname>Bu</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Fragment-hmm: A new approach to protein structure prediction</article-title>
        <source>Protein Sci</source>
        <year>2008</year>
        <volume>17</volume>
        <issue>11</issue>
        <fpage>1925</fpage>
        <lpage>34</lpage>
        <pub-id pub-id-type="doi">10.1110/ps.036442.108</pub-id>
        <?supplied-pmid 18723665?>
        <pub-id pub-id-type="pmid">18723665</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Anglor: a composite machine-learning algorithm for protein backbone torsion angle prediction</article-title>
        <source>PLoS ONE</source>
        <year>2008</year>
        <volume>3</volume>
        <issue>10</issue>
        <fpage>3400</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0003400</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Song</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Tan</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Webb</surname>
            <given-names>GI</given-names>
          </name>
          <name>
            <surname>Akutsu</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Tangle: two-level support vector regression approach for protein backbone torsion angle prediction from primary sequences</article-title>
        <source>PloS ONE</source>
        <year>2012</year>
        <volume>7</volume>
        <issue>2</issue>
        <fpage>30361</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0030361</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xue</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Dor</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Faraggi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Real-value prediction of backbone torsion angles</article-title>
        <source>Proteins Struct Funct Bioinform</source>
        <year>2008</year>
        <volume>72</volume>
        <issue>1</issue>
        <fpage>427</fpage>
        <lpage>33</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.21940</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Heffernan</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Paliwal</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Lyons</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Dehzangi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sharma</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sattar</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Improving prediction of secondary structure, local backbone angles, and solvent accessible surface area of proteins by iterative deep learning</article-title>
        <source>Sci Rep</source>
        <year>2015</year>
        <volume>5</volume>
        <fpage>11476</fpage>
        <pub-id pub-id-type="doi">10.1038/srep11476</pub-id>
        <?supplied-pmid 26098304?>
        <pub-id pub-id-type="pmid">26098304</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lyons</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Dehzangi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Heffernan</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Sharma</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Paliwal</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Sattar</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Predicting backbone c <italic>α</italic> angles and dihedrals from protein sequences by stacked sparse auto-encoder deep neural network</article-title>
        <source>J Comput Chem</source>
        <year>2014</year>
        <volume>35</volume>
        <issue>28</issue>
        <fpage>2040</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1002/jcc.23718</pub-id>
        <?supplied-pmid 25212657?>
        <pub-id pub-id-type="pmid">25212657</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Singh</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Raghava</surname>
            <given-names>GP</given-names>
          </name>
        </person-group>
        <article-title>Evaluation of protein dihedral angle prediction methods</article-title>
        <source>PloS ONE</source>
        <year>2014</year>
        <volume>9</volume>
        <issue>8</issue>
        <fpage>105667</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0105667</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Zimmermann</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>Backbone dihedral angle prediction</article-title>
        <source>Prediction of Protein Secondary Structure</source>
        <year>2017</year>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>Humana Press</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31</label>
      <mixed-citation publication-type="other">Wang S, Peng J, Ma J, Xu J. Protein secondary structure prediction using deep convolutional neural fields. Sci Rep. 2016;:6.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Weng</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>Deepcnf-d: predicting protein order/disorder regions by weighted deep convolutional neural fields</article-title>
        <source>Int J Mol Sci</source>
        <year>2015</year>
        <volume>16</volume>
        <issue>8</issue>
        <fpage>17315</fpage>
        <lpage>30</lpage>
        <pub-id pub-id-type="doi">10.3390/ijms160817315</pub-id>
        <?supplied-pmid 26230689?>
        <pub-id pub-id-type="pmid">26230689</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Accurate de novo prediction of protein contact map by ultra-deep learning model</article-title>
        <source>PLOS Comput Biol</source>
        <year>2017</year>
        <volume>13</volume>
        <issue>1</issue>
        <fpage>1005324</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005324</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Faraggi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Xue</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Improving the prediction accuracy of residue solvent accessibility and real-value backbone torsion angles of proteins by guided-learning through a two-layer neural network</article-title>
        <source>Protein Struct Funct Bioinformatics</source>
        <year>2009</year>
        <volume>74</volume>
        <issue>4</issue>
        <fpage>847</fpage>
        <lpage>56</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.22193</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Predicting the errors of predicted local backbone angles and non-local solvent-accessibilities of proteins by deep neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <issue>24</issue>
        <fpage>3768</fpage>
        <lpage>73</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw549</pub-id>
        <?supplied-pmid 27551104?>
        <pub-id pub-id-type="pmid">27551104</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Betancourt</surname>
            <given-names>MR</given-names>
          </name>
          <name>
            <surname>Skolnick</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Local propensities and statistical potentials of backbone dihedral angles in proteins</article-title>
        <source>J Mol Biol</source>
        <year>2004</year>
        <volume>342</volume>
        <issue>2</issue>
        <fpage>635</fpage>
        <lpage>49</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmb.2004.06.091</pub-id>
        <?supplied-pmid 15327961?>
        <pub-id pub-id-type="pmid">15327961</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Keskin</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Yuret</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Gursoy</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Turkay</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Erman</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Relationships between amino acid sequence and backbone torsion angle preferences</article-title>
        <source>Proteins Struct Funct Bioinform</source>
        <year>2004</year>
        <volume>55</volume>
        <issue>4</issue>
        <fpage>992</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.20100</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jha</surname>
            <given-names>AK</given-names>
          </name>
          <name>
            <surname>Colubri</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Zaman</surname>
            <given-names>MH</given-names>
          </name>
          <name>
            <surname>Koide</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sosnick</surname>
            <given-names>TR</given-names>
          </name>
          <name>
            <surname>Freed</surname>
            <given-names>KF</given-names>
          </name>
        </person-group>
        <article-title>Helix, sheet, and polyproline ii frequencies and strong nearest neighbor effects in a restricted coil library</article-title>
        <source>Biochemistry</source>
        <year>2005</year>
        <volume>44</volume>
        <issue>28</issue>
        <fpage>9691</fpage>
        <lpage>702</lpage>
        <pub-id pub-id-type="doi">10.1021/bi0474822</pub-id>
        <?supplied-pmid 16008354?>
        <pub-id pub-id-type="pmid">16008354</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39</label>
      <mixed-citation publication-type="other">Szegedy C, Liu W, Jia Y, Sermanet P, Reed S, Anguelov D, Erhan D, Vanhoucke V, Rabinovich A. Going deeper with convolutions. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. CVPR: 2015. p. 1–9.</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40</label>
      <mixed-citation publication-type="other">Srivastava RK, Greff K, Schmidhuber J. Training very deep networks. In: Advances in Neural Information Processing Systems. NIPS: 2015. p. 2377–85.</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41</label>
      <mixed-citation publication-type="other">He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. CVPR: 2016. p. 770–8.</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42</label>
      <mixed-citation publication-type="other">Nair V, Hinton GE. Rectified linear units improve restricted boltzmann machines. In: Proceedings of the 27th International Conference on Machine Learning (ICML-10). ICML: 2010. p. 807–14.</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43</label>
      <mixed-citation publication-type="other">Kinga D, Adam JB. A method for stochastic optimization. In: International Conference on Learning Representations (ICLR). ICLR: 2015.</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44</label>
      <mixed-citation publication-type="other">Bergstra J, Breuleux O, Bastien F, Lamblin P, Pascanu R, Desjardins G, Turian J, Warde-Farley D, Bengio Y. Theano: A cpu and gpu math compiler in python. In: Proc. 9th Python in Science Conf. Scipy: 2010. p. 1–7.</mixed-citation>
    </ref>
    <ref id="CR45">
      <label>45</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Camacho</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Coulouris</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Avagyan</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Papadopoulos</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Bealer</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Madden</surname>
            <given-names>TL</given-names>
          </name>
        </person-group>
        <article-title>Blast+: architecture and applications</article-title>
        <source>BMC Bioinformatics</source>
        <year>2009</year>
        <volume>10</volume>
        <issue>1</issue>
        <fpage>421</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-10-421</pub-id>
        <?supplied-pmid 20003500?>
        <pub-id pub-id-type="pmid">20003500</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Söding</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Protein homology detection by hmm–hmm comparison</article-title>
        <source>Bioinformatics</source>
        <year>2004</year>
        <volume>21</volume>
        <issue>7</issue>
        <fpage>951</fpage>
        <lpage>60</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bti125</pub-id>
        <?supplied-pmid 15531603?>
        <pub-id pub-id-type="pmid">15531603</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Remmert</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Biegert</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hauser</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Söding</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Hhblits: lightning-fast iterative protein sequence searching by hmm-hmm alignment</article-title>
        <source>Nat Methods</source>
        <year>2012</year>
        <volume>9</volume>
        <issue>2</issue>
        <fpage>173</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.1818</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kountouris</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Hirst</surname>
            <given-names>JD</given-names>
          </name>
        </person-group>
        <article-title>Prediction of backbone dihedral angles and protein secondary structure using support vector machines</article-title>
        <source>BMC Bioinformatics</source>
        <year>2009</year>
        <volume>10</volume>
        <issue>1</issue>
        <fpage>437</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-10-437</pub-id>
        <?supplied-pmid 20025785?>
        <pub-id pub-id-type="pmid">20025785</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kabsch</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Sander</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Dictionary of protein secondary structure: pattern recognition of hydrogen-bonded and geometrical features</article-title>
        <source>Biopolymers</source>
        <year>1983</year>
        <volume>22</volume>
        <issue>12</issue>
        <fpage>2577</fpage>
        <lpage>637</lpage>
        <pub-id pub-id-type="doi">10.1002/bip.360221211</pub-id>
        <?supplied-pmid 6667333?>
        <pub-id pub-id-type="pmid">6667333</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50</label>
      <mixed-citation publication-type="other">Steinegger M, Söding J. Sensitive protein sequence searching for the analysis of massive data sets. bioRxiv. 2016. p. 079681.</mixed-citation>
    </ref>
    <ref id="CR51">
      <label>51</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Hamelryck</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Mardia</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Ferkinghoff-Borg</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <source>Bayesian Methods in Structural Bioinformatics</source>
        <year>2012</year>
        <publisher-loc>Cambridge</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>52</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Berman</surname>
            <given-names>HM</given-names>
          </name>
          <name>
            <surname>Westbrook</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Gilliland</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Bhat</surname>
            <given-names>TN</given-names>
          </name>
          <name>
            <surname>Weissig</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Shindyalov</surname>
            <given-names>IN</given-names>
          </name>
          <name>
            <surname>Bourne</surname>
            <given-names>PE</given-names>
          </name>
        </person-group>
        <article-title>The protein data bank</article-title>
        <source>Nucleic Acids Res</source>
        <year>2000</year>
        <volume>28</volume>
        <issue>1</issue>
        <fpage>235</fpage>
        <lpage>42</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/28.1.235</pub-id>
        <?supplied-pmid 10592235?>
        <pub-id pub-id-type="pmid">10592235</pub-id>
      </element-citation>
    </ref>
    <ref id="CR53">
      <label>53</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Heffernan</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Paliwal</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Capturing non-local interactions by long short term memory bidirectional recurrent neural networks for improving prediction of protein secondary structure, backbone angles, contact numbers, and solvent accessibility</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <fpage>218</fpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx218</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
