<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Database (Oxford)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Database (Oxford)</journal-id>
    <journal-id journal-id-type="publisher-id">databa</journal-id>
    <journal-title-group>
      <journal-title>Database: The Journal of Biological Databases and Curation</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-0463</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
      <publisher-loc>UK</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9650770</article-id>
    <article-id pub-id-type="doi">10.1093/database/baac096</article-id>
    <article-id pub-id-type="publisher-id">baac096</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Article</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI00960</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>NEMAR: an open access data, tools and compute resource operating on neuroelectromagnetic data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-0799-3557</contrib-id>
        <name>
          <surname>Delorme</surname>
          <given-names>Arnaud</given-names>
        </name>
        <!--arnodelorme@gmail.com-->
        <xref rid="COR0001" ref-type="corresp"/>
        <aff><institution content-type="department">Swartz Center of Computational Neuroscience, INC, UCSD</institution>, La Jolla, CA 92093-0559, <country country="US">USA</country></aff>
        <aff><institution content-type="department">CERCO, CNRS, Paul Sabatier University</institution>, Toulouse 31400, <country country="FR">France</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Truong</surname>
          <given-names>Dung</given-names>
        </name>
        <aff><institution content-type="department">Swartz Center of Computational Neuroscience, INC, UCSD</institution>, La Jolla, CA 92093-0559, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Youn</surname>
          <given-names>Choonhan</given-names>
        </name>
        <aff><institution content-type="department">San Diego Supercomputer Center, UCSD</institution>, La Jolla, CA 92093-0505, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sivagnanam</surname>
          <given-names>Subhashini</given-names>
        </name>
        <aff><institution content-type="department">San Diego Supercomputer Center, UCSD</institution>, La Jolla, CA 92093-0505, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Stirm</surname>
          <given-names>Claire</given-names>
        </name>
        <aff><institution content-type="department">San Diego Supercomputer Center, UCSD</institution>, La Jolla, CA 92093-0505, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yoshimoto</surname>
          <given-names>Kenneth</given-names>
        </name>
        <aff><institution content-type="department">San Diego Supercomputer Center, UCSD</institution>, La Jolla, CA 92093-0505, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Poldrack</surname>
          <given-names>Russell A</given-names>
        </name>
        <aff><institution content-type="department">Department of Psychology, Stanford University</institution>, Stanford, CA 94305, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Majumdar</surname>
          <given-names>Amitava</given-names>
        </name>
        <aff><institution content-type="department">San Diego Supercomputer Center, UCSD</institution>, La Jolla, CA 92093-0505, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Makeig</surname>
          <given-names>Scott</given-names>
        </name>
        <aff><institution content-type="department">Swartz Center of Computational Neuroscience, INC, UCSD</institution>, La Jolla, CA 92093-0559, <country country="US">USA</country></aff>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="COR0001">*Corresponding author: Tel: +858-822-7534; Fax: +858-822-7556; Email: <email xlink:href="arnodelorme@gmail.com">arnodelorme@gmail.com</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2022-11-11">
      <day>11</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>11</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <volume>2022</volume>
    <elocation-id>baac096</elocation-id>
    <history>
      <date date-type="received">
        <day>04</day>
        <month>8</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>26</day>
        <month>9</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>12</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="corrected-typeset">
        <day>11</day>
        <month>11</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Â© The Author(s) 2022. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="baac096.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>To preserve scientific data created by publicly and/or philanthropically funded research projects and to make it ready for exploitation using recent and ongoing advances in advanced and large-scale computational modeling methods, publicly available data must use in common, now-evolving standards for formatting, identifying and annotating should share data. The OpenNeuro.org archive, built first as a repository for magnetic resonance imaging data based on the Brain Imaging Data Structure formatting standards, aims to house and share all types of human neuroimaging data. Here, we present NEMAR.org, a web gateway to OpenNeuro data for human neuroelectromagnetic data. NEMAR allows users to search through, visually explore and assess the quality of shared electroencephalography (EEG), magnetoencephalography and intracranial EEG data and then to directly process selected data using high-performance computing resources of the San Diego Supercomputer Center via the Neuroscience Gateway (nsgportal.org, NSG), a freely available web portal to high-performance computing serving a variety of neuroscientific analysis environments and tools. Combined, OpenNeuro, NEMAR and NSG form an efficient, integrated data, tools and compute resource for human neuroimaging data analysis and meta-analysis.</p>
      <p><bold>Database URL</bold>: <ext-link xlink:href="https://nemar.org" ext-link-type="uri">https://nemar.org</ext-link></p>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NIH</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R01EB023297</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NIH</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R24MH117179</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NIH</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R24MH120037</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NIH</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>U24EB029005</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NSF</institution>
            <institution-id institution-id-type="DOI">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>U24EB029005</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="6"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="s3">
    <title>Introduction</title>
    <p>Although electroencephalography (EEG) was the first functional human brain monitoring modality (1926), EEG data analysis long lagged in adapting new data analysis approachesâboth in neurology, where visual pattern recognition applied to the raw scalp signal data is still the dominant approach, and in cognitive neuroscience, where event-related potential averages of individual scalp channel signals, collected from relatively small numbers of participants, long remained the predominant research measure. These methods, however, leave unrevealed much information about brain function contained in the data and also cannot exploit consistencies in complex data that can only be identified in and extracted from large to very large data collections using new statistical and machine learning methods. Sharing neuroelectromagnetic (NEM) data is critical to leveraging public research investment and to supporting rigor and reproducibility in funded research. Several funding bodies require data sharing. Data sharing also allows researchers to use modern research tools to evaluate new data in a new way, by directly comparing it to ever-accumulating stores of shared data collected in related or compatible paradigms.</p>
    <p>Because high-density EEG, magnetoencephalography (MEG), and intracranial EEG (iEEG) recordings have no sensors in common, and as important physical differences exist between the dozens of available EEG/iEEG data collection systems and several available MEG systems, a centralized archive of NEM data allowing direct comparison of NEM brain dynamics across studies and modalities has not previously been considered feasible. Furthermore, the broad point-spread function of cortical magnetic flux to scalp coils and the still broader and more variable point-spread function of cortical potentials to scalp electrodes mean that scalp and intracranial NEM recordings have no simply computable relationship. As a result, much valuable convergent information about human brain dynamics contained in the many large and small new and existing NEM data sets, each recorded with care at considerable expense, is at serious risk of being lost to science unless and until the data are integrated into an active integrated data, tools and compute resource (DATCOR) enabling advanced analysis within or across studies.</p>
    <p>Here, we report initial results of building NEMAR (nemar.org), a large, publicly available human NEM DATCOR tightly linked to a freely available high-performance computing resource, the Neuroscience Gateway (NSG). We aim to build a widely used and scientifically productive open resource for archiving, sharing and further analyzing and meta-analyzing NEM data.</p>
  </sec>
  <sec id="s4">
    <title>Data formats</title>
    <sec id="s4-s1">
      <title>The BIDS format</title>
      <p>In the past few years, the magnetic resonance imaging (MRI) community has worked jointly with the International Neuroinformatics Coordinating Facility, to develop community standards for describing and annotating MRI data, the Brain Imaging Data Structure (BIDS) (<xref rid="R1" ref-type="bibr">1</xref>). To speed adoption by the brain imaging community, community-driven BIDS standards use common file formats (for MRI, NIFTI, JSON and TSV) and simple directory structures and do not require additional database software. The BIDS MRI standard has now been adopted by several data repositories, including OpenNeuro, FCP INDI, SchizConnect and the Developing Human Connectome Project. The BIDS format for MRI has been responsible in large part for a recent rapid rise in data sharing in the MRI and functional Magnetic Resonance Imaging (fMRI) world (<xref rid="R2" ref-type="bibr">2</xref>, <xref rid="R3" ref-type="bibr">3</xref>). BIDS has gained rapid acceptance as an evolving, community-based standard for organizing neuroimaging data to enable efficient data search, advanced processing and data mining. The benefits of the OpenNeuro approach to fMRI data sharing and computation are becoming more apparent, prompting adoption from the NEM data research community. BIDS extensions to MEG data (<xref rid="R4" ref-type="bibr">4</xref>) and, more recently, to electrophysiological data including EEG (<xref rid="R5" ref-type="bibr">5</xref>) and iEEG data (<xref rid="R6" ref-type="bibr">6</xref>) have been developed. Although several small and dedicated NEM data repositories exist (e.g. HeadIT.org, iEEG.org and the OMEGA MEG data archive), these archives do not build around a common data format standard, thwarting cross-modality data co-registration and federation. NEMARâs support of the emerging BIDS NEM modality standards will allow storage of a wide variety of NEM data collection formats and protocols and make identification, storage and efficient search and retrieval of a wide variety of NEM data possible within a single archive or federated network of archives.</p>
    </sec>
    <sec id="s4-s2">
      <title>The HED standard</title>
      <p>Archived time series data typically require that standardized terms be used to describe the nature of all experimental events of interest identified in the recording session, either during its capture or after the fact, for potential search and re-use in further analysis and meta-analysis. Although BIDS-formatted data sets contain detailed metadata, the BIDS standards in themselves do not constitute a system for adequately describing the timeline of the recording, including occurrences of planned, unplanned or emergent experimental events. The Hierarchical Event Descriptor (HED) system provides a standardized, flexible and readily extensible set of descriptors for experimental events in brain imaging or behavioral experiments (<xref rid="R7" ref-type="bibr">7</xref>). HED tagging can be used to describe many types of experiment events in a uniform, but easily extensible and both human- and machine-readable manner. HED has been integrated into BIDS as the de facto standard for describing events in brain imaging experiments. The NEMAR archive is the first open data archive to leverage the use of HED tags to enable data discovery and integration based on experimental events.</p>
    </sec>
  </sec>
  <sec id="s5">
    <title>Implementation</title>
    <sec id="s5-s1">
      <title>NEMAR as an extension of the OpenNeuro project</title>
      <p>The OpenNeuro archive (<xref rid="R8" ref-type="bibr">8</xref>) currently offers more than 644 open neuroimaging datasets from more than 22â000 participants. Its success, to date, reveals that neuroscientists are willing to share their data, although the attractiveness of sharing remains limited as data sharing can require extra workânot currently required by journals or funding agenciesâand easy-to-use data meta-analysis and mining tools are not yet available. The OpenNeuro architecture has two main components: web front end and back end database. The custom web front end runs on an Amazon Web Services server. The OpenNeuro data are stored in an Amazon Web Services (AWS) S3 instance, backed by the open-source DataLad data management software. DataLad has a snapshot data mechanism allowing OpenNeuro users to version their data.</p>
      <p>The NEMAR project is capitalizing on the ongoing achievements of the OpenNeuro, NSG (<xref rid="R9" ref-type="bibr">9</xref>), Open EEGLAB Portal (<xref rid="R10" ref-type="bibr">10</xref>) and BIDS standards development projects by creating a community portal to a large and ever-growing archive of human NEM (EEG, MEG and iEEG) brain imaging data, data analysis tools and advanced computational resources. Our overall goal is to support the creation, maintenance, analysis and cross-study mining of human NEM data by seeding and growing a âminableâ archive of NEM data deposited in the OpenNeuro resource. After users upload NEM data to OpenNeuro, those data are automatically copied to the San Diego Supercomputer Center (SDSC) storage using the DataLad cloning mechanism. New DataLad snapshots from OpenNeuro are synched daily. NEM-relevant data measures are then automatically computed on the NSG and made available for display to users through the NEMAR web interface.</p>
      <p>The NEMAR website (nemar.org), maintained and developed at SDSC, uses the HUBzero web framework, an open-source software platform for building powerful websites that host analytical tools, publish data, share resources, collaborate and build communities in a single web-based ecosystem (<xref rid="R13" ref-type="bibr">13</xref>).</p>
    </sec>
    <sec id="s5-s2">
      <title>NEMAR BIDS-formatting tool</title>
      <p>We have released a bids-matlab-tools plug-in (version 6) to export EEG data to BIDS from our popular EEGLAB (<xref rid="R11" ref-type="bibr">11</xref>) software environment (sccn.ucsd.edu/eeglab) running on the MATLAB software package (The Mathworks, Inc.). The plug-in allows users to format their EEG raw data using the BIDS-EEG format either via (a) the BIDS export menu item, (b) a pop-up windowÂ (<xref rid="F1" ref-type="fig">FigureÂ 1</xref>) or (c) using a scripting interface. As of January 2022, the bids-matlab-tools plug-in, available from the EEGLAB plug-in manager, had been downloaded 844 times.</p>
      <fig position="float" id="F1" fig-type="figure">
        <label>FigureÂ 1.</label>
        <caption>
          <p>Users first format their data to BIDS and then upload their data to OpenNeuro web interface, which stores it on its AWS back end. The NEMAR SDSC Data Storage back end and then automatically sync/download the data from OpenNeuro. Data statistics and visualizations are precomputed for display by NSG Compute. The NEMAR web interface (bottom box) serves the data to NEMAR users. The NEMAR search engine allows users to search through and select data for analysis for their projects. Data identifiers found on NEMAR (for example, OpenNeuro dataset index ds123456) can then be used in analysis scripts the user sends through the NSG to retrieve and process the selected data without requiring data download and subsequent re-upload.</p>
        </caption>
        <graphic xlink:href="baac096f1" position="float"/>
      </fig>
      <p>The plug-in guides users through a series of questions to describe their experiment and populate the BIDS metadata fields, as well as to specify HED tags to record the nature of experiment events and other data timeline structures. Upon completion, the plug-in exports a fully compliant BIDS-formatted dataset that may be uploaded to the OpenNeuro using its web or command line interface, after which the data are automatically made available on NEMAR.</p>
    </sec>
    <sec id="s5-s3">
      <title>The NEMAR dataset web interface and metadata</title>
      <p>For each OpenNeuro NEM dataset, NEMAR automatically extracts and then makes available for display a variety of information extracted from BIDS including the number of EEG channels (and other channel types), the size of the data, the number of files, the BIDS and HED versions, authors, dataset Digital Object Identifier (from OpenNeuro) and other BIDS-related metadataÂ (<xref rid="F2" ref-type="fig">FigureÂ 2</xref>).</p>
      <fig position="float" id="F2" fig-type="figure">
        <label>FigureÂ 2.</label>
        <caption>
          <p>NEMAR dataset interface exposing some of the BIDS-required EEG metadata.</p>
        </caption>
        <graphic xlink:href="baac096f2" position="float"/>
      </fig>
      <p>As in OpenNeuro, NEMAR users can explore the BIDS folder content and visualize and/or download data files using the icons adjacent to the data files.</p>
      <p>As of February 2022, there were 72 EEG datasets (from 2664 participants) on NEMAR, 22 MEG datasets (from 365 participants) and 12 iEEG datasets (from 202 participants). Of the 72 EEG datasets, 37 use the EEGLAB data format and have likely been formatted using the bids-matlab-tools EEGLAB plug-in (see <xref rid="F3" ref-type="fig">Figure 3</xref>).</p>
      <fig position="float" id="F3" fig-type="figure">
        <label>FigureÂ 3.</label>
        <caption>
          <p>Graphic interface of the bids-matlab-tools plug-in for EEGLAB, a tool to format NEM data in EEGLAB STUDY format to BIDS format for OpenNeuro and NEMAR.</p>
        </caption>
        <graphic xlink:href="baac096f3" position="float"/>
      </fig>
    </sec>
    <sec id="s5-s4">
      <title>NEMAR data quality pipeline</title>
      <p>On NEMAR, we are implementing an automated processing pipeline to compute a variety of data quality metrics, including the percentage of âgoodâ channels and âgoodâ data, and the number of putative brain sources extracted by independent component analysis (ICA), as described in the study by Delorme etÂ al. (<xref rid="R12" ref-type="bibr">12</xref>). These measures will be displayed when users click a link next to each dataset (<xref rid="F4" ref-type="fig">FigureÂ 4</xref>).</p>
      <fig position="float" id="F4" fig-type="figure">
        <label>FigureÂ 4.</label>
        <caption>
          <p>Data quality information, channel log spectra and raw data segment for a selected dataset.</p>
        </caption>
        <graphic xlink:href="baac096f4" position="float"/>
      </fig>
    </sec>
    <sec id="s5-s5">
      <title>NEMAR data visualization</title>
      <p>For each data file of each BIDS dataset, NEMAR also plots the data spectrum and shows a few seconds of the raw data. More data-specific measures will be added in the future. Measures shown by NEMAR are computed running EEGLAB functions via the NSG gateway (see <xref rid="F2" ref-type="fig">Figure 1</xref>). Visualization measures are saved in .SVG vector format and are displayed using native SVG HTML tag capabilities, preserving vector graphic information for adaptive resolution on web browsers.</p>
      <p>As part of the data quality pipeline, brain sources are extracted using ICA. We will allow users to visualize ICA components on NEMAR, as well as the putative brain source they correspond to in 3D template head models. Although less accurate than using the subjectâs head model, source visualization on template head models may be computed automatically and also allow comparisons across both subjects and BIDS datasets.</p>
    </sec>
    <sec id="s5-s6">
      <title>NEMAR interface to the NSG</title>
      <p>Since 2013, the NSG (<xref rid="R9" ref-type="bibr">9</xref>) has been serving the neuroscience community by providing easy access to many software and pipelines running primarily on high-performance computing (HPC) resources provided by the Extreme Science and Engineering Discovery Environment (XSEDE) network that coordinates resources across the NSF-funded supercomputer centers.</p>
      <p>NSG has made available high-throughput computing (HTC) and academic cloud computing resources, and neuroscientists of all types have increasingly begun to take advantage of NSG and its easy-to-use interface for running tools and pipelines for processing their data. In addition to XSEDE HPC resources, implemented using singularity, NSG uses backend XSEDE HPC, HTC and cloud resources and makes available a range of computational neuroscience tools including NEURON, PyNN, GENESIS, Brian2, NEST, MOOSE, NetPyNE, BMTK, HNN-Core, etc. NSG has more recently made available environments widely used for human brain imaging research including Freesurfer, MATLAB and Python. In 2017, we ported to NSG our very widely used EEGLAB signal processing environment EEGLAB (<xref rid="R11" ref-type="bibr">11</xref>) and its many contributed tools and toolboxes, creating an Open EEGLAB Portal to high-performance data processing resources (<xref rid="R10" ref-type="bibr">10</xref>).</p>
      <p>The NEMAR gateway project shares the same infrastructure as NSG, and NSG capabilities have been expanded to allow users to run data processing tools and pipelines on NEM data of their own or from the OpenNeuro archive. NEMAR already uses NSG for computing NEM data quality metrics and also allows users to run custom MATLAB and Python scripts on NSG (nsgportal.org) using NEMAR dataÂ (<xref rid="F5" ref-type="fig">FigureÂ 5</xref>).</p>
      <fig position="float" id="F5" fig-type="figure">
        <label>FigureÂ 5.</label>
        <caption>
          <p>An example MATLAB script running on NSG using OpenNeuro/NEMAR dataset ds002691. The script, submitted by a user through the NSG interface, is executed on the Expanse supercomputer, for which the NEMAR datasets are immediately accessible via their âdsâ index (as below).</p>
        </caption>
        <graphic xlink:href="baac096f5" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec id="s6">
    <title>Conclusion</title>
    <p>The NEMAR (nemar.org) front-end portal to NEM neuroimaging data allows users to search for and optionally explore data submitted to OpenNeuro (openneuro.org) by viewing precomputed data quality metrics and visualized dataset information and then process selected data using the XSEDE high-performance resources in conjunction with the NSG (nsgportal.org) without requiring a data download and subsequent re-upload. NEM data will be stored in both raw and source-resolved formats that will allow source-level data and data measure visualization for user inspection, search, analysis and discovery within and also across studies using a common template brain modelâobtaining results largely independent of scalp sensor geometry and modality that can be directly compared to results of other structural and functional neuroimaging research. This feature will also make possible data meta-analyses and large-scale data mining, as tools for this become available. NEMAR thus also serves as an example of an integrated human neuroimaging DATCOR (âdata, tools and compute resourceâ). As the amount of available shared data grows, integrated computing will become more and more convenient and even necessary. What we here term âDATCORâ seems likely to become the basic unit of open science for advancing research using neuroimaging and other types of publicly shared data.</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The NEMAR project was supported by NIH grant R24MH120037. The OpenNeuro project is supported by NIH grant R24MH117179. The NSG project is supported by NIH grant U24EB029005, NSF grant 1935749, and NIH grant R01EB023297. We thank Erich Huebner and Claire Stirm of the HubZero team for their support of the NEMAR web interface.</p>
  </ack>
  <sec sec-type="data-availability" id="s7">
    <title>Data availability</title>
    <p>All data provided in the aforementioned database framework are publically available.</p>
  </sec>
  <sec id="s8">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="R1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gorgolewski</surname><given-names>K.J.</given-names></string-name>, <string-name><surname>Auer</surname><given-names>T.</given-names></string-name>, <string-name><surname>Calhoun</surname><given-names>V.D.</given-names></string-name></person-group> Â <etal>etÂ al.</etal> (<year>2016</year>) <article-title>The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments</article-title>. <source><italic toggle="yes">Sci. Data</italic></source>, <volume>3</volume>, <page-range>160044</page-range>.</mixed-citation>
    </ref>
    <ref id="R2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Poldrack</surname><given-names>R.A.</given-names></string-name> and <string-name><surname>Gorgolewski</surname><given-names>K.J.</given-names></string-name></person-group> (<year>2014</year>) <article-title>Making big data open: data sharing in neuroimaging</article-title>. <source><italic toggle="yes">Nat. Neurosci.</italic></source>, <volume>17</volume>, <fpage>1510</fpage>â<lpage>1517</lpage>.<pub-id pub-id-type="pmid">25349916</pub-id></mixed-citation>
    </ref>
    <ref id="R3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Poline</surname><given-names>J.-B.</given-names></string-name>, <string-name><surname>Breeze</surname><given-names>J.L.</given-names></string-name>, <string-name><surname>Ghosh</surname><given-names>S.</given-names></string-name></person-group> Â <etal>etÂ al.</etal> (<year>2012</year>) <article-title>Data sharing in neuroimaging research</article-title>. <source><italic toggle="yes">Front. Neuroinform.</italic></source>, <volume>6</volume>, <page-range>9</page-range>.</mixed-citation>
    </ref>
    <ref id="R4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niso</surname><given-names>G.</given-names></string-name>, <string-name><surname>Gorgolewski</surname><given-names>K.J.</given-names></string-name>, <string-name><surname>Bock</surname><given-names>E.</given-names></string-name></person-group> Â <etal>etÂ al.</etal> (<year>2018</year>) <article-title>MEG-BIDS, the brain imaging data structure extended to magnetoencephalography</article-title>. <source><italic toggle="yes">Sci. Data</italic></source>, <volume>5</volume>, <page-range>180110</page-range>.</mixed-citation>
    </ref>
    <ref id="R5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pernet</surname><given-names>C.R.</given-names></string-name>, <string-name><surname>Appelhoff</surname><given-names>S.</given-names></string-name>, <string-name><surname>Gorgolewski</surname><given-names>K.J.</given-names></string-name></person-group> Â <etal>etÂ al.</etal> (<year>2019</year>) <article-title>EEG-BIDS, an extension to the brain imaging data structure for electroencephalography</article-title>. <source><italic toggle="yes">Sci. Data</italic></source>, <volume>6</volume>, <page-range>103</page-range>.</mixed-citation>
    </ref>
    <ref id="R6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holdgraf</surname><given-names>C.</given-names></string-name>, <string-name><surname>Appelhoff</surname><given-names>S.</given-names></string-name>, <string-name><surname>Bickel</surname><given-names>S.</given-names></string-name></person-group> Â <etal>etÂ al.</etal> (<year>2019</year>) <article-title>iEEG-BIDS, extending the brain imaging data structure specification to human intracranial electrophysiology</article-title>. <source><italic toggle="yes">Sci. Data</italic></source>, <volume>6</volume>, <page-range>102</page-range>.</mixed-citation>
    </ref>
    <ref id="R7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Robbins</surname><given-names>K.</given-names></string-name>, <string-name><surname>Truong</surname><given-names>D.</given-names></string-name>, <string-name><surname>Appelhoff</surname><given-names>S.</given-names></string-name></person-group> Â <etal>etÂ al.</etal> (<year>2021</year>) <article-title>Capturing the nature of events and event context using hierarchical event descriptors (HED)</article-title>. <source><italic toggle="yes">NeuroImage</italic></source>, <volume>245</volume>, <page-range>118766</page-range>.</mixed-citation>
    </ref>
    <ref id="R8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Markiewicz</surname><given-names>C.J.</given-names></string-name>, <string-name><surname>Gorgolewski</surname><given-names>K.J.</given-names></string-name>, <string-name><surname>Feingold</surname><given-names>F.</given-names></string-name></person-group> Â <etal>etÂ al.</etal> (<year>2021</year>) <article-title>The OpenNeuro resource for sharing of neuroscience data</article-title>. <source><italic toggle="yes">eLife</italic></source>, <volume>10</volume>, <page-range>e71774</page-range>.</mixed-citation>
    </ref>
    <ref id="R9">
      <label>9.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Sivagnanam</surname><given-names>S.</given-names></string-name>, <string-name><surname>Yoshimoto</surname><given-names>K.</given-names></string-name>, <string-name><surname>Carnevale</surname><given-names>N.T.</given-names></string-name></person-group> Â <etal>etÂ al.</etal> (<year>2018</year>) <article-title>The neuroscience gatewayâenabling large scale modeling and data processing in neuroscience</article-title>. In: <italic toggle="yes">Proceedings of the Practice &amp; Experience in Advanced Research Computing PEARC18</italic>. <conf-loc>Pittsburgh, PA</conf-loc>. pp. <fpage>1</fpage>â<lpage>7</lpage>.</mixed-citation>
    </ref>
    <ref id="R10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>MartÃ­nez-Cancino</surname><given-names>R.</given-names></string-name>, <string-name><surname>Delorme</surname><given-names>A.</given-names></string-name>, <string-name><surname>Truong</surname><given-names>D.</given-names></string-name></person-group> Â <etal>etÂ al.</etal> (<year>2021</year>) <article-title>The open EEGLAB portal interface: high-performance computing with EEGLAB</article-title>. <source><italic toggle="yes">NeuroImage</italic></source>, <volume>224</volume>, <page-range>116778</page-range>.</mixed-citation>
    </ref>
    <ref id="R11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Delorme</surname><given-names>A.</given-names></string-name> and <string-name><surname>Makeig</surname><given-names>S.</given-names></string-name></person-group> (<year>2004</year>) <article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title>. <source><italic toggle="yes">J. Neurosci. Methods</italic></source>, <volume>134</volume>, <fpage>9</fpage>â<lpage>21</lpage>.<pub-id pub-id-type="pmid">15102499</pub-id></mixed-citation>
    </ref>
    <ref id="R12">
      <label>12.</label>
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Delorme</surname><given-names>A.</given-names></string-name>, <string-name><surname>Truong</surname><given-names>D.</given-names></string-name>, <string-name><surname>Martinez-Cancino</surname><given-names>R.</given-names></string-name></person-group> Â <etal>etÂ al.</etal> (<year>2021</year>) <article-title>Tools for importing and evaluating BIDS-EEG formatted data</article-title>. In: <italic toggle="yes">10th International IEEE/EMBS Conference on Neural Engineering (NER)</italic>. <conf-loc>Rome, Italy</conf-loc>. pp. <fpage>210</fpage>â<lpage>213</lpage>.</mixed-citation>
    </ref>
    <ref id="R13">
      <label>13.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>McLennan</surname><given-names>M.</given-names></string-name> and <string-name><surname>Kennell</surname><given-names>R.</given-names></string-name></person-group> (<year>2010</year>) <article-title>HUBzero: a platform for dissemination and collaboration in computational science and engineering</article-title>. In: <italic toggle="yes">Computing in Science &amp; Engineering 12.2</italic>. pp. <fpage>48</fpage>â<lpage>53</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
