<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_PATTER100577 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEgr5 jpg ?>
<?FILEgr6 jpg ?>
<?FILEsi1 gif ?>
<?FILEsi2 gif ?>
<?FILEsi3 gif ?>
<?FILEsi4 gif ?>
<?FILEsi5 gif ?>
<?FILEsi6 gif ?>
<?FILEsi7 gif ?>
<?FILEsi8 gif ?>
<?FILEsi9 gif ?>
<?FILEsi10 gif ?>
<?FILEsi11 gif ?>
<?FILEsi12 gif ?>
<?FILEsi13 gif ?>
<?FILEsi14 gif ?>
<?FILEsi15 gif ?>
<?FILEsi16 gif ?>
<?FILEsi17 gif ?>
<?FILEsi18 gif ?>
<?FILEsi19 gif ?>
<?FILEsi20 gif ?>
<?FILEsi21 gif ?>
<?FILEsi22 gif ?>
<?FILEsi23 gif ?>
<?FILEsi24 gif ?>
<?FILEsi25 gif ?>
<?FILEsi26 gif ?>
<?FILEsi27 gif ?>
<?FILEsi28 gif ?>
<?FILEsi29 gif ?>
<?FILEsi30 gif ?>
<?FILEsi31 gif ?>
<?FILEsi32 gif ?>
<?FILEsi33 gif ?>
<?FILEsi34 gif ?>
<?FILEsi35 gif ?>
<?FILEsi36 gif ?>
<?FILEsi37 gif ?>
<?FILEsi38 gif ?>
<?FILEsi39 gif ?>
<?FILEsi40 gif ?>
<?FILEsi41 gif ?>
<?FILEsi42 gif ?>
<?FILEsi43 gif ?>
<?FILEsi44 gif ?>
<?FILEsi45 gif ?>
<?FILEsi46 gif ?>
<?FILEsi47 gif ?>
<?FILEsi48 gif ?>
<?FILEsi49 gif ?>
<?FILEsi50 gif ?>
<?FILEsi51 gif ?>
<?FILEsi52 gif ?>
<?FILEsi53 gif ?>
<?FILEsi54 gif ?>
<?FILEsi55 gif ?>
<?FILEsi56 gif ?>
<?FILEsi57 gif ?>
<?FILEsi58 gif ?>
<?FILEsi59 gif ?>
<?FILEsi60 gif ?>
<?FILEsi61 gif ?>
<?FILEsi62 gif ?>
<?FILEsi63 gif ?>
<?FILEsi64 gif ?>
<?FILEsi65 gif ?>
<?FILEsi66 gif ?>
<?FILEsi67 gif ?>
<?FILEsi68 gif ?>
<?FILEsi69 gif ?>
<?FILEsi70 gif ?>
<?FILEsi71 gif ?>
<?FILEsi72 gif ?>
<?FILEsi73 gif ?>
<?FILEsi74 gif ?>
<?FILEsi75 gif ?>
<?FILEsi76 gif ?>
<?FILEsi77 gif ?>
<?FILEsi78 gif ?>
<?FILEsi79 gif ?>
<?FILEsi80 gif ?>
<?FILEsi81 gif ?>
<?FILEsi82 gif ?>
<?FILEsi83 gif ?>
<?FILEsi84 gif ?>
<?FILEsi85 gif ?>
<?FILEsi86 gif ?>
<?FILEsi87 gif ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Patterns (N Y)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Patterns (N Y)</journal-id>
    <journal-title-group>
      <journal-title>Patterns</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2666-3899</issn>
    <publisher>
      <publisher-name>Elsevier</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9481959</article-id>
    <article-id pub-id-type="pii">S2666-3899(22)00188-X</article-id>
    <article-id pub-id-type="doi">10.1016/j.patter.2022.100577</article-id>
    <article-id pub-id-type="publisher-id">100577</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Single-cell multi-modal GAN reveals spatial patterns in single-cell data from triple-negative breast cancer</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au1">
        <name>
          <surname>Amodio</surname>
          <given-names>Matthew</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author" id="au2">
        <name>
          <surname>Youlten</surname>
          <given-names>Scott E.</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">2</xref>
        <xref rid="aff5" ref-type="aff">5</xref>
      </contrib>
      <contrib contrib-type="author" id="au3">
        <name>
          <surname>Venkat</surname>
          <given-names>Aarthi</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au4">
        <name>
          <surname>San Juan</surname>
          <given-names>Beatriz P.</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">2</xref>
        <xref rid="aff4" ref-type="aff">4</xref>
        <xref rid="aff5" ref-type="aff">5</xref>
      </contrib>
      <contrib contrib-type="author" id="au5">
        <name>
          <surname>Chaffer</surname>
          <given-names>Christine L.</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">2</xref>
        <xref rid="aff4" ref-type="aff">4</xref>
        <xref rid="aff5" ref-type="aff">5</xref>
      </contrib>
      <contrib contrib-type="author" id="au6">
        <name>
          <surname>Krishnaswamy</surname>
          <given-names>Smita</given-names>
        </name>
        <email>smita.krishnaswamy@yale.edu</email>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="aff6" ref-type="aff">6</xref>
        <xref rid="fn1" ref-type="fn">7</xref>
        <xref rid="cor1" ref-type="corresp">∗</xref>
      </contrib>
      <aff id="aff1"><label>1</label>Yale University Department of Computer Science, New Haven, CT, USA</aff>
      <aff id="aff2"><label>2</label>Garvan Institute of Medical Research, Darlinghurst, NSW, Australia</aff>
      <aff id="aff3"><label>3</label>Yale University Computational Biology and Bioinformatics, New Haven, CT, USA</aff>
      <aff id="aff4"><label>4</label>St Vincent’s Clinical School, UNSW Medicine, UNSW Sydney, Sydney, NSW, Australia</aff>
      <aff id="aff5"><label>5</label>The Kinghorn Cancer Centre, Darlinghurst, NSW, Australia</aff>
      <aff id="aff6"><label>6</label>Yale University Department of Genetics, New Haven, CT, USA</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>∗</label>Corresponding author <email>smita.krishnaswamy@yale.edu</email></corresp>
      <fn id="fn1">
        <label>7</label>
        <p id="ntpara0010">Lead contact</p>
      </fn>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>01</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <day>09</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>01</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <volume>3</volume>
    <issue>9</issue>
    <elocation-id>100577</elocation-id>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>5</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>14</day>
        <month>6</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>4</day>
        <month>8</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 The Author(s)</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="abs0010">
      <title>Summary</title>
      <p>Exciting advances in technologies to measure biological systems are currently at the forefront of research. The ability to gather data along an increasing number of omic dimensions has created a need for tools to analyze all of this information together, rather than siloing each technology into separate analysis pipelines. To advance this goal, we introduce a framework called the single-cell multi-modal generative adversarial network (scMMGAN) that integrates data from multiple modalities into a unified representation in the ambient data space for downstream analysis using a combination of adversarial learning and data geometry techniques. The framework’s key improvement is an additional diffusion geometry loss with a new kernel that constrains the otherwise over-parameterized GAN. We demonstrate scMMGAN’s ability to produce more meaningful alignments than alternative methods on a wide variety of data modalities and that its output can be used to draw conclusions from real-world biological experimental data.</p>
    </abstract>
    <abstract abstract-type="author-highlights" id="abs0020">
      <title>Highlights</title>
      <p>
        <list list-type="simple" id="ulist0010">
          <list-item id="u0010">
            <label>•</label>
            <p id="p0010">Integrating data from multiple modalities into one analysis</p>
          </list-item>
          <list-item id="u0015">
            <label>•</label>
            <p id="p0015">Using data geometry to regularize cycle-consistent GANs</p>
          </list-item>
          <list-item id="u0020">
            <label>•</label>
            <p id="p0020">Quantifying uncertainty through noise augmentation</p>
          </list-item>
        </list>
      </p>
    </abstract>
    <abstract abstract-type="editor-highlights" id="abs0025">
      <title>The bigger picture</title>
      <p>Biological experimental data are increasingly being generated along multiple different axes, with new and more complex technologies specializing in particular measurements being developed every year. Measuring a single subject or system with multiple specialized data-collecting tools creates a natural interest in integrating the results of these individual instruments to form a single unified view. The model introduced here presents a computational technique designed for this purpose. With the single-cell multi-modal GAN (scMMGAN), there is an opportunity to measure along many different omic directions and synthesize the information from each into one larger understanding of the system under study.</p>
    </abstract>
    <abstract abstract-type="teaser" id="abs0030">
      <p>Combining single-cell data from different modalities is important for creating a holistic understanding of the system under study. This is demonstrated on a variety of example modalities with the scMMGAN model introduced in this paper.</p>
    </abstract>
    <kwd-group id="kwrds0010">
      <title>Keywords</title>
      <kwd>Deep Learning</kwd>
      <kwd>manifold learning</kwd>
      <kwd>generative adversarial networks</kwd>
      <kwd>GANs</kwd>
      <kwd>scRNAseq</kwd>
    </kwd-group>
  </article-meta>
  <notes>
    <p id="misc0010">Published: September 1, 2022</p>
  </notes>
</front>
<body>
  <sec id="sec1">
    <title>Introduction</title>
    <p id="p0030">Integrating data gathered from different sources is a critical challenge in computational genomics. Currently there are several single-cell technologies including RNA sequencing (RNA-seq), assay for transposase-accessible chromatin using sequencing (ATAC-seq), Hi-C, ChIP-seq (chromatin immunoprecipitation sequencing), and CITE-seq (cellular indexing of transcriptomes and epitopes by sequencing) as well as proteomic technologies such as cytometry by time of flight (CyTOF), imaging CyTOF, and multiplexed ion beam imaging that offer complementary cellular information.<xref rid="bib1" ref-type="bibr">1</xref>, <xref rid="bib2" ref-type="bibr">2</xref>, <xref rid="bib3" ref-type="bibr">3</xref>, <xref rid="bib4" ref-type="bibr">4</xref>, <xref rid="bib5" ref-type="bibr">5</xref>, <xref rid="bib6" ref-type="bibr">6</xref>, <xref rid="bib7" ref-type="bibr">7</xref> Of these modalities, only a fraction are available as simultaneous measurements—often with quality degradation factors such as reduced gene dimensions, lower throughput, and increased noise. The remaining measurements must be done on distinct cellular subsamples from the same population. This is the key problem that we tackle in this article: the prediction of missing or non-simultaneous modalities in order to generate a more complete set of features. Thus, given modalities such as single-cell RNA-seq (scRNA-seq), scATAC-seq, and spatial transcriptomics measured separately on different cells (from the same population), our single-cell multi-modal generative adversarial network (scMMGAN) generates a complete set of simultaneous measurements for downstream analyses.</p>
    <p id="p0035">Aligning the separately measured data computationally has many advantages over analyzing the data modalities individually. Combining data modalities allows us to leverage the advantages of each and mitigate the disadvantages. For example, combining a modality with a higher signal-to-noise ratio such as proteomic CyTOF measurements with one that has a lower signal-to-noise ratio such as scRNA-seq gives us the opportunity to resolve cell populations to a finer degree in the noisier dataset.<xref rid="bib7" ref-type="bibr"><sup>7</sup></xref> Even more compellingly, combining modalities allows us to measure variables only available in one domain combined with variables only available in another domain, thus simulating jointly measured technologies.</p>
    <p id="p0040">We base our method on the framework of cycle-consistent generative adversarial networks (CycleGANs).<xref rid="bib8" ref-type="bibr">8</xref>, <xref rid="bib9" ref-type="bibr">9</xref>, <xref rid="bib10" ref-type="bibr">10</xref>, <xref rid="bib11" ref-type="bibr">11</xref> In GAN-based domain adaptation frameworks, a generator network is trained to map data points of one modality into data points from another modality. During training, a discriminator is used to ensure that generated points are sampled from the high-dimensional distribution representing the second modality. In CycleGANs there are two back-to-back generators, one going from the first modality to the second modality and another going from the second modality to the first. A reconstruction error enforces that the result of two back-to-back domain adaptations results in the original distribution again, i.e., that the generators are inverses of each other over the regions of the data spaces where there are training points.</p>
    <p id="p0045">While CycleGAN frameworks can successfully generate points in each modality, the mapping they produce is not constrained enough. For instance in the original CycleGAN paper, images of zebras were mapped to images of horses, but nothing ensured that the background would be unaltered. While this may not be detrimental for natural image applications, it can be untenable for scientific applications where the scRNA-seq measurement must correspond with and corroborate the scATAC-seq measurement. Noting this key weakness, in earlier work we proposed the use of a correspondence loss and gave anecdotal examples on flow cytometry panels with overlapping measured markers.<xref rid="bib12" ref-type="bibr"><sup>12</sup></xref> However, here we both extend the application to multi-modal integration and specify a more powerful, generally applicable correspondence loss: the geometry-preserving loss. This loss enforces that the diffusion geometry, performed with a new kernel designed to pass gradients better than the Gaussian kernel, is preserved throughout the mapping. We note that this loss can be utilized even in cases where no measurements overlap.</p>
    <p id="p0050">We demonstrate the power of aligning data modalities with scMMGAN on a wide array of data types. We start by validating it on datasets where simultaneous measurements are available and use those as ground truth in evaluations. We then use scMMGAN to perform a thorough investigation into a novel triple-negative breast cancer dataset, where we have cells from the breast cancer culture HCC38 xenografted into mice and allowed to metastasize from the primary to secondary tumor locations. We show that scMMGAN can infer spatial locations of cellular structures.</p>
  </sec>
  <sec id="sec2">
    <title>Results</title>
    <sec id="sec2.1">
      <title>scMMGAN model results</title>
      <p id="p0055">The scMMGAN framework is depicted in <xref rid="fig1" ref-type="fig">Figure 1</xref>A. Each pair of data domains or modalities has a pair of generator networks that map in either direction between them, forming a diversified multi-modal mapping. For a generator mapping from Domain <inline-formula><mml:math id="M1" altimg="si1.gif"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> to Domain <inline-formula><mml:math id="M2" altimg="si2.gif"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> which we denote <inline-formula><mml:math id="M3" altimg="si3.gif"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, it functions as a traditional GAN guided by a discriminator in Domain <inline-formula><mml:math id="M4" altimg="si2.gif"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> which we denote <inline-formula><mml:math id="M5" altimg="si4.gif"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. The discriminator tries to distinguish between samples from the real data for that domain <inline-formula><mml:math id="M6" altimg="si5.gif"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and samples from the generator <inline-formula><mml:math id="M7" altimg="si6.gif"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, while the generator tries to fool the discriminator. They alternate trying to optimize the following minimax objective:<disp-formula id="fd1"><label>(Equation 1)</label><mml:math id="M8" altimg="si7.gif"><mml:mrow><mml:munder><mml:mi>min</mml:mi><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:munder><mml:munder><mml:mi>max</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:munder><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">+</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula><fig id="fig1"><label>Figure 1</label><caption><p>scMMGAN architecture and the correspondence loss</p><p>(A) The scMMGAN architecture mapping between multiple domains, each consisting of a pair of generators and discriminator.</p><p>(B) In addition to the discriminator loss, there are two additional losses within each domain.</p><p>(C) Hypothetical demonstration of the data geometry guiding alignment through the correspondence loss. In the depicted space, data in the two domains have been shifted and rotated, but the intrinsic data geometry is preserved with the values of the diffusion eigenvectors.</p><p>(D) Hypothetical illustration of a bad mapping that is invertible (has low reconstruction loss) but does not align analogous representations (has high correspondence loss) and a good mapping that is both invertible and aligns analogous representations. In the situation where minimally changing the value of genes is preferred, the mapping on the left unnecessarily changes the value of the gene on the x axis.</p></caption><graphic xlink:href="gr1"/></fig></p>
      <p id="p0060">In addition to this loss of the discriminator guiding the generator to transform its input modality into the output modality <inline-formula><mml:math id="M9" altimg="si8.gif"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>A</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, there are two other terms in the loss that ensure the learned mapping is informative and meaningful. These are depicted in <xref rid="fig1" ref-type="fig">Figure 1</xref>B. The reconstruction loss <inline-formula><mml:math id="M10" altimg="si9.gif"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the mean-squared error (MSE) between the original data <inline-formula><mml:math id="M11" altimg="si10.gif"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and the composition of the two paired generators between the domains <inline-formula><mml:math id="M12" altimg="si1.gif"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M13" altimg="si2.gif"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>:<disp-formula id="fd2"><label>(Equation 2)</label><mml:math id="M14" altimg="si11.gif"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msup><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo></mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p id="p0065">The correspondence loss <inline-formula><mml:math id="M15" altimg="si12.gif"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> imposes a constraint on a single point’s representation in Domain <inline-formula><mml:math id="M16" altimg="si1.gif"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> and Domain <inline-formula><mml:math id="M17" altimg="si2.gif"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>, as opposed to the reconstruction loss which imposes a constraint on points within the same domain:<disp-formula id="fd3"><label>(Equation 3)</label><mml:math id="M18" altimg="si13.gif"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p id="p0070">The motivation for the correspondence loss comes from the fact that previous models using cycle consistency for domain mapping with GANs included only two restrictions: (1) that the generators be able to reconstruct a point after it moves to the other domain and back; and (2) that the discriminators not be able to distinguish batches of true and mapped points. The generators can accomplish these goals in many different ways, including by learning arbitrarily complex mappings: as long as they align the two data manifolds at a distribution level. The family of paired inverse functions that can match the target distributions is large, and with existing frameworks the particular pair that results from training is determined by the vagaries of random weight initialization and mysterious biases in gradient descent.</p>
      <p id="p0075">The GAN loss is a probability-distribution matching objective.<xref rid="bib13" ref-type="bibr"><sup>13</sup></xref> In previous work it has been proven that under certain optimality conditions a GAN discriminator provides a Jensen-Shannon divergence between the true and generated distributions.<xref rid="bib14" ref-type="bibr"><sup>14</sup></xref> A Wasserstein GAN (WGAN), on the other hand, contains modifications that result in a Wasserstein distance being provided by the discriminator.<xref rid="bib15" ref-type="bibr"><sup>15</sup></xref></p>
      <p id="p0080">However, simply matching probability distributions can result in incoherent cell states (<xref rid="fig1" ref-type="fig">Figure 1</xref>D). A key insight we bring is that distributions must only be matched within correspondence constraints. These correspondences are essentially invariances in the underlying system that are reflected in every modality. In our previous work we used customized correspondence losses for each dataset. However, here we note that when matching single-cell data we can use a nearly universal constraint—that of manifold geometry preservation.</p>
      <p id="p0085">While our model incorporates signal from a data geometry loss into a larger framework, the data geometry is too rigid to be used on its own to guide alignment. It is heavily influenced by the properties of the domain data space, and thus when the two domains are very different it does not allow for sufficient flexibility in changing the shape of the distribution. Methods that use only the data geometry struggle to align domains that are significantly different.<xref rid="bib16" ref-type="bibr"><sup>16</sup></xref> An ideal mapping would have both the flexibility of a mapping that matches the probability distribution (as the GAN does) but preserves the data geometry as much as possible while doing so. By combining the existing GAN-based loss and a data geometry loss, the network can balance the tradeoff between these goals.</p>
      <p id="p0090">We thus introduce a correspondence loss that ensures the mappings have point-wise as well as distributional alignment by preserving the data geometry through the learned mapping. To do this, we use the diffusion map representation of the original data.</p>
      <p id="p0095">Here we give a brief overview of diffusion maps. Diffusion maps are a kernel-based method frequently used in manifold learning to produce low-dimensional embeddings that preserve intrinsic structure in the data.<xref rid="bib17" ref-type="bibr"><sup>17</sup></xref><sup>,</sup><xref rid="bib18" ref-type="bibr"><sup>18</sup></xref> The eigenvectors of the diffusion operator form an embedding where Euclidean distances correspond to diffusion distance, or the probability of getting from one point to another via random walk, on the original manifold.<xref rid="bib19" ref-type="bibr"><sup>19</sup></xref> Because these new coordinates represented by the diffusion eigenvectors abstract away much of the data-domain specific properties, they present a way of ensuring the underlying data geometry is preserved in the mapping.</p>
      <p id="p0100">By calculating the eigenvectors of the diffusion operator for the points in their original domain <inline-formula><mml:math id="M19" altimg="si14.gif"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub></mml:mrow></mml:math></inline-formula> and the eigenvectors of the diffusion operator for the points after being mapped to the other domain <inline-formula><mml:math id="M20" altimg="si15.gif"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mo>‖</mml:mo><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, we can directly compare the <inline-formula><mml:math id="M21" altimg="si16.gif"><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mtext>th</mml:mtext></mml:msup></mml:mrow></mml:math></inline-formula> eigenvectors to enforce that intrinsic data geometry, as measured by diffusion, be preserved by the mapping. For further detail about the calculation of <inline-formula><mml:math id="M22" altimg="si17.gif"><mml:mrow><mml:mi>φ</mml:mi></mml:mrow></mml:math></inline-formula>, see <xref rid="sec4" ref-type="sec">experimental procedures</xref>.</p>
      <p id="p0105">The correspondence geometry loss then penalizes the L2 distance between the two representations of each point:<disp-formula id="fd4"><label>(Equation 4)</label><mml:math id="M23" altimg="si18.gif"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msubsup><mml:mi>φ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>i</mml:mi></mml:msubsup><mml:mo linebreak="badbreak">−</mml:mo><mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p id="p0110">By enforcing this loss in the scMMGAN framework, we ensure that the intrinsic structure of the data is preserved in the otherwise underconstrained GAN setting.</p>
    </sec>
    <sec id="sec2.2">
      <title>Experimental results</title>
      <sec id="sec2.2.1">
        <title>Mapping between spatial, scRNA-seq, and proteomic data</title>
        <p id="p0115">As an initial validation of scMMGAN, we utilize simultaneously measured multi-modal data from the newly developed deterministic barcoding in tissue sequencing (DBIT-seq) technology as ground truth. DBIT-seq uses deterministic barcoding in tissue for spatially resolved measurements of both transcriptomics and proteomics.<xref rid="bib20" ref-type="bibr"><sup>20</sup></xref> Thus, in DBIT-seq, three things are measured jointly on every cell: an scRNA-seq profile, a protein profile, and spatial coordinates. The system being studied in these data is that of mouse embryos, particularly focused on early tissue development and organogenesis.</p>
        <p id="p0120">Often, in transcriptomic/proteomic alignment problems, no “ground truth” is available because each technology measures a distribution of cells in a destructive process. As a result, models such as scMMGAN that learn to map between two distributions without needing point-wise pairings are called unsupervised alignment models. We design an experiment with these data to show how scMMGAN could have been used to obtain this information without needing them to be measured jointly. We treat the spatially located scRNA-seq data and the spatially located protein data as two separate measurements and learn to map between them. We then utilize the fact that they were measured jointly and that some of the columns in each dataset are related (corresponding genes and proteins) to evaluate the accuracy of the learned mapping. We compare against both an autoencoder-based alignment method (cross-modal autoencoder [CMAE]) and a standard CycleGAN without a correspondence loss.<xref rid="bib9" ref-type="bibr"><sup>9</sup></xref><sup>,</sup><xref rid="bib21" ref-type="bibr"><sup>21</sup></xref> For detailed descriptions of the model architectures, see <xref rid="sec4" ref-type="sec">experimental procedures</xref>.</p>
        <p id="p0125"><xref rid="fig2" ref-type="fig">Figure 2</xref> shows example results of scMMGAN and baseline models on these data. Plotted on the given spatial coordinates, we show the ground-truth transcriptomic value along with generated proteomic values. There we see scMMGAN best models the ground-truth data. We further evaluate scMMGAN’s performance on this application quantitatively. To quantify the aspect of the generated distribution matching the target distribution as a whole, we employ the metric maximum mean discrepancy (MMD), a distance defined on distributions frequently used in both deep-learning and biological contexts to distinguish between distributions.<xref rid="bib22" ref-type="bibr">22</xref>, <xref rid="bib23" ref-type="bibr">23</xref>, <xref rid="bib24" ref-type="bibr">24</xref> To quantify the aspect of preserving information about the individual observation through the alignment, we use correlation between columns in the transcriptomic space and the proteomic space known to correspond to the same gene. Since these values correspond to the same gene, we would expect there to be a correlation between a point’s value before mapping and its value after mapping.<fig id="fig2"><label>Figure 2</label><caption><p>Results comparison from the DBIT-seq experiment</p><p>On the DBIT-seq data, shown are corresponding proteomic and transcriptomic expression for the gene shown. The x axis and y axis plotted are the measured spatial coordinates taken directly from the data. The ground-truth transcriptomic values are plotted alongside the generated proteomic values for each model, where we see scMMGAN best model the data.</p></caption><graphic xlink:href="gr2"/></fig></p>
        <p id="p0130">These scores confirm quantitatively what we saw graphically in these experiments (<xref rid="tbl1" ref-type="table">Table 1</xref>). All models are able to accurately match the target distribution (low MMDs), with very similar performance consisting of each model’s one or two SD interval overlapping. However, when looking at the preserved correlation, we see scMMGAN achieved the best alignment with an average correlation of <inline-formula><mml:math id="M24" altimg="si19.gif"><mml:mrow><mml:mi>r</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0.154</mml:mn></mml:mrow></mml:math></inline-formula> between columns known to correspond. We note that the absolute value of this correlation is relatively low compared with other datasets, and this is due to limited amount of shared correlation in the underlying “ground truth” pairings of points that are jointly measured.<table-wrap position="float" id="tbl1"><label>Table 1</label><caption><p>Results from the DBIT-seq experiment</p></caption><table frame="hsides" rules="groups"><thead><tr><th>DBIT-seq</th><th>scMMGAN</th><th>CycleGAN</th><th>CMAE</th></tr></thead><tbody><tr><td>MMD <inline-formula><mml:math id="M25" altimg="si86.gif"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td><bold>0</bold>.<bold>072</bold> ± 0.001</td><td>0.078 ± 0.006</td><td>0.082 ± 0.001</td></tr><tr><td>MMD <inline-formula><mml:math id="M26" altimg="si87.gif"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td><bold>0</bold>.<bold>060</bold> ± 0.001</td><td>0.066 ± 0.002</td><td>0.079 ± 0.001</td></tr><tr><td>Correlation <inline-formula><mml:math id="M27" altimg="si86.gif"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td><bold>0</bold>.<bold>155</bold> ± 0.006</td><td>−0.026 ± 0.021</td><td>0.003 ± 0.082</td></tr><tr><td>Correlation <inline-formula><mml:math id="M28" altimg="si87.gif"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td><bold>0</bold>.<bold>152</bold> ± 0.014</td><td>−0.088 ± 0.074</td><td>−0.012 ± 0.066</td></tr></tbody></table><table-wrap-foot><fn><p>Evaluation of each model on the DBIT-seq data. While the MMDs are close for each model (meaning the predicted distribution resembles the ground-truth distribution), scMMGAN is significantly more accurate at preserving correlation between columns known to correspond. The best values are in boldface.</p></fn></table-wrap-foot></table-wrap></p>
        <sec id="sec2.2.1.1">
          <title>Unique versus common information in measurement modalities</title>
          <p id="p0135">The scMMGAN is a generative framework, but when used in non-standard ways it can become a tool for analysis in addition to faithful generation. When measuring two aspects of a biological system with two different technologies, some of the information might be shared between the two modalities while other information might be unique to one of the modalities. For example, when mapping between a modality that measures the whole transcriptomic space such as scRNA-seq and one that measures only a subset of the proteomic space, we would expect for the genes with corresponding proteins to be more easily modeled than the genes without them.</p>
          <p id="p0140">We design our experiment as follows to test this on the transcriptomic and proteomic measurements in the DBIT-seq data (summarized in <xref rid="fig3" ref-type="fig">Figure 3</xref>, with further mathematical detail in <xref rid="sec4" ref-type="sec">experimental procedures</xref>). We train the model augmented with random noise input and then evaluate it on mapping the same points in proteomic space to the transcriptomic space, except with different random noise samples. We then calculate the variance of the different predicted values for each transcript count and for each given point in proteomic space. The mean across all points then gives us a measure of the uncertainty associated with a given transcript measurement. To factor out the influence the magnitude of counts of a given transcript would have on variance, we scale by the variance in the raw dataset for each one. We also filter out lowly expressed genes. We can then compare the stochasticity as measured in this experiment of the genes that have a corresponding proteomic measurement and those that do not.<fig id="fig3"><label>Figure 3</label><caption><p>Design of the uncertainty quantification experiment</p><p>(A) A depiction of how scMMGAN can be used to quantify how much uncertainty is associated with the mapping to each gene. A particular cell is mapped from Domain <inline-formula><mml:math id="M29" altimg="si1.gif"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> to Domain <inline-formula><mml:math id="M30" altimg="si2.gif"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> along with various different noise samples. The mapped values of Gene A change significantly with the noise, while the mapped values of Gene B change little for this cell. We interpret this as a quantification of how much information there is about each gene in Domain <inline-formula><mml:math id="M31" altimg="si1.gif"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula>.</p><p>(B) The genes identified by scMMGAN to have the most uncertainty associated with the mapping, and thus have the least common information with the proteomic measurements in this dataset.</p></caption><graphic xlink:href="gr3"/></fig></p>
          <p id="p0145">Just as expected, we find that the average variance of genes with an analogous proteomic measurement is 0.026 while the average variance of genes without an analogous proteomic measurement is 1.419. This is a logical result, as the relationship between transcript counts with corresponding proteomic measurements is more straightforward to model and can thus be done with more certainty. This corroborates our understanding of the process at work in this multi-modal setting.</p>
          <p id="p0150">Furthermore, this analytical process with scMMGAN allows us to inspect which genes are modeled with the most and least uncertainty and thus provide the most unique information and most common information with respect to the other modality. Unsurprisingly, the genes with the least uncertainty are related to early embryo development in mice, as that is the system being studied: for example, the three least are Gm5049, Gm37500, and Gm33051. Meanwhile, the genes with the most uncertainty are GM37686 and Rp1. It is possible that genes with higher observed uncertainty could also be of interest to the research, for example, Rp1, which is involved in the development of the retina while the study was focused on early tissue development.<xref rid="bib25" ref-type="bibr"><sup>25</sup></xref> The information that these genes had high uncertainty can help guide future experimental design decisions that would lead to the selection of proteins to measure, thus allowing for better alignment of these measurements.</p>
          <p id="p0155">In this way, scMMGAN can help provide insights into the system being studied as well as into experimental design and decisions.</p>
        </sec>
      </sec>
      <sec id="sec2.2.2">
        <title>Mapping between scRNA-seq and ATAC-seq data</title>
        <p id="p0160">We next perform an experiment on data consisting of paired ATAC-seq and RNA-seq measurements on the same cells. As with the previous experiment, since these two technologies both measure values related to a particular gene (chromatin availability for ATAC-seq and transcript expression for RNA-seq), we can expect there to be some correlation between the two spaces in their values for that gene, as in the prior case. The dataset we use comes from a public human blood dataset of granulocytes removed through cell sorting from peripheral blood mononuclear cells of a healthy donor.<xref rid="bib26" ref-type="bibr"><sup>26</sup></xref></p>
        <p id="p0165">A qualitative assessment of the results via plots of the output are shown in <xref rid="fig4" ref-type="fig">Figure 4</xref>, with the ground-truth ATAC value plotted in the first column and the generated corresponding RNA-seq values in the subsequent columns. As before, scMMGAN’s output best matches the ground truth. For the other models, while they have the appropriate amount of activation for each gene at a distribution level, they are inaccurate in terms of alignment at a point level (some populations have been inverted).<fig id="fig4"><label>Figure 4</label><caption><p>Results comparison from the ATAC-seq/RNA-seq experiment</p><p>Ground-truth values for held-out cells and the predictions for each model on the experiment mapping between ATAC and RNA sequencing. scMMGAN’s output matches the ground truth most accurately compared with the other models, which inverted populations through the mapping. Coordinates shown are from the first two principal component analysis (PCA) dimensions.</p></caption><graphic xlink:href="gr4"/></fig></p>
        <p id="p0170">Confirming this quantitatively, as seen in <xref rid="tbl2" ref-type="table">Table 2</xref>, while all of the models perform adequately at matching the ground truth at a distribution level (as seen by their low MMDs), a significant difference can be seen when evaluating them at a point-wise level. scMMGAN’s predictions have an average correlation with the ground truth of <inline-formula><mml:math id="M32" altimg="si20.gif"><mml:mrow><mml:mi>r</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>0.336</mml:mn></mml:mrow></mml:math></inline-formula> while the others are all essentially uncorrelated (0 is near the middle of each models’ 1 − <inline-formula><mml:math id="M33" altimg="si21.gif"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:math></inline-formula> interval).<table-wrap position="float" id="tbl2"><label>Table 2</label><caption><p>Results from the ATAC-seq/RNA-seq experiment</p></caption><table frame="hsides" rules="groups"><thead><tr><th>ATAC-seq</th><th>scMMGAN</th><th>CycleGAN</th><th>CMAE</th></tr></thead><tbody><tr><td>MMD <inline-formula><mml:math id="M34" altimg="si87.gif"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td><bold>0</bold>.<bold>033</bold> ± 0.001</td><td><bold>0</bold>.<bold>033</bold> ± 0.000</td><td>0.038 ± 0.000</td></tr><tr><td>MMD <inline-formula><mml:math id="M35" altimg="si86.gif"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td><bold>0</bold>.<bold>031</bold> ± 0.000</td><td>0.032 ± 0.000</td><td>0.051 ± 0.003</td></tr><tr><td>Correlation <inline-formula><mml:math id="M36" altimg="si87.gif"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td><bold>0</bold>.<bold>313</bold> ± 0.025</td><td>0.024 ± 0.140</td><td>−0.014 ± 0.108</td></tr><tr><td>Correlation <inline-formula><mml:math id="M37" altimg="si86.gif"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td><td><bold>0</bold>.<bold>358</bold> ± 0.016</td><td>0.034 ± 0.225</td><td>0.020 ± 0.111</td></tr></tbody></table><table-wrap-foot><fn><p>Evaluation of each model on the ATAC-seq/RNA-seq data. The MMDs for each model are close, as each models the ground truth at a whole-distribution level. scMMGAN is the only model whose predictions preserve the known correlation, however, because its alignment is also accurate point-wise. The best or tied-for-best values are in boldface.</p></fn></table-wrap-foot></table-wrap></p>
      </sec>
      <sec id="sec2.2.3">
        <title>Integration of triple-negative breast cancer data</title>
        <p id="p0175">Here, we apply scMMGAN to a dataset that comprises a human xenograft model of triple-negative breast cancer (MDA-MB-231) with transcriptomic measurements jointly in both a spatial RNA-seq modality and a scRNA-seq modality lacking the spatial information. The study consists of the MDA-MB-231 cell line grown in mouse models, with the measurements taken from primary site tumors in the tissue from the mammary gland. While the experimental models are replicates, they are different organisms and thus introduce an additional source of noise for the alignment.</p>
        <p id="p0180">Each of the two measurement modalities produces transcriptomic measurements, but each also has advantages and disadvantages. The spatial RNA-seq provides the ability to analyze the physical structure of the tissue sample and localize behavior to different regions of it via (x, y) spatial coordinates. As a drawback, however, each spatial coordinate is bigger than the size of a single cell, and as a result the transcriptomics are estimates of groups of multiple cells. For example, if a cell of one type that is expressing gene A and a cell of another type that is expressing gene B are spatially adjacent, this technology would observe gene A and gene B being expressed together, even if they are never jointly expressed in a single cell.</p>
        <p id="p0185">In contrast, the scRNA-seq provides the usual single-cell granularity of measurements that would be able to distinguish between the expression of each cell. By mapping the spatial data to the scRNA-seq space, we are in essence imputing it into single-cell resolution. However, the scRNA-seq does not have spatial orientation with respect to the original tissue sample. Thus, to combine the best of each modality (spatial information at the single-cell level), we use scMMGAN to integrate them by mapping a point from the spatial RNA-seq domain to the scRNA-seq domain while considering its aligned representation of its original spatial coordinates and its generated scRNA-seq expression values.</p>
        <p id="p0190">The spatial RNA-seq dataset consists of a tissue sampled across 1,170 spatial coordinates, each coordinate with measurements on 20,092 genes. Four different scRNA-seq samples were obtained from cancerous primary site tissue (from different mice), each measured across the same 20,092 genes, and consisting of 7,606, 5,118, 8,163, and 7,591 cells, respectively.</p>
        <p id="p0195">While the scRNA-seq and spatial RNA-seq data are both transcriptomic technologies measuring gene profiles, and thus their dimensions have the same meaning, the two datasets cannot be analyzed together as is. In <xref rid="fig5" ref-type="fig">Figure 5</xref>A, we see that the two data distributions are completely non-overlapping prior to the use of scMMGAN. Because the raw data are completely separable in the joint space, any downstream analysis would only be able to pick up on the difference between the two modalities and not the differences between cells within them. For an integrated analysis using information from both of them, we need the aligned output from scMMGAN (<xref rid="fig5" ref-type="fig">Figure 5</xref>B).<fig id="fig5"><label>Figure 5</label><caption><p>Analysis of scMMGAN alignment and clusters on the triple-negative breast cancer dataset</p><p>(A) Plotted are the PCA coordinates of the gene expression values from the two distributions. In the raw data, the spatial RNA-seq and scRNA-seq are not directly comparable, as they are entirely separable. After mapping with scMMGAN, they are aligned and comparable with downstream analysis.</p><p>(B) Mapping spatial RNA-seq to scRNA-seq, clustering the generated scRNA-seq values, and then plotting the cluster by the measured spatial coordinate on the x axis an y axis.</p><p>(C) Generated spatial RNA-seq data from scRNA-seq, including generated spatial coordinates. Same coordinates as previous plot.</p><p>(D) All generated clusters mapped to the spatial RNA-seq space. Same coordinates as previous plots.</p></caption><graphic xlink:href="gr5"/></fig></p>
        <p id="p0200">We analyze the scMMGAN alignment by taking the spatial RNA-seq, mapping it to the scRNA-seq space, and then clustering the generated scRNA-seq data (<xref rid="fig5" ref-type="fig">Figure 5</xref>B). We use spectral k-means clustering with a selected parameter of <inline-formula><mml:math id="M38" altimg="si22.gif"><mml:mrow><mml:mi>k</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>, and we then plot the clusters according to their original spatial coordinates. As we see, these scRNA-seq clusters preserve spatial patterns seen in the coordinates, demonstrating our ability to make new spatially informed conclusions by analyzing the generated scRNA-seq data in conjunction with the original spatial coordinates.</p>
        <p id="p0205">In <xref rid="fig5" ref-type="fig">Figure 5</xref>C, we look at the opposite mapping direction of taking the scRNA-seq data and generating spatial RNA-seq with it. By mapping scRNA-seq points to these generated coordinates, we can see spatial organization of particular cell types. For example, in this figure we plot the generated spatial coordinates for cells high in SLC2A1 and CDK11A and see spatial differentiation between these two types of cells. We show all of these clusters plotted in <xref rid="fig5" ref-type="fig">Figure 5</xref>D.</p>
        <p id="p0210">Now that we see scMMGAN has learned to map data between the two modalities in a way that preserves gene signals, we next compare this with the alternative alignment models. In <xref rid="fig6" ref-type="fig">Figure 6</xref>, we show the results of the learned mapping from spatial RNA-seq to scRNA-seq for each model. We first note that each model was able to generate a distribution that accurately matched the target distribution, an observation we will demonstrate quantitatively later. However, the alternative approaches to scMMGAN achieved this result by aligning a given spatial RNA-seq gene profile to an scRNA-seq observation that is very different.<fig id="fig6"><label>Figure 6</label><caption><p>Generated scMMGAN expression value results plotted on the spatial coordinates</p><p>The x axis and y axis plotted are the raw measured spatial coordinates from the spatial RNA-seq. The color is expression value, where we compare the original spatial RNA-seq of a gene with each generated scRNA-seq value of that gene for each method, showing scMMGAN best aligns the original and generated values.</p></caption><graphic xlink:href="gr6"/></fig></p>
        <p id="p0215">In the first column of <xref rid="fig6" ref-type="fig">Figure 6</xref>, we plot the value of five genes across the original spatial coordinates in the spatial RNA-seq data. We then plot the generated scRNA-seq value of that gene for each spatial coordinate for each model in the subsequent columns, starting with scMMGAN. With FAM87b in the first row, we see that scMMGAN’s generated values largely match the original spatial pattern, with some minimal changes that were necessary to match the target distribution as well. The CycleGAN matches much of the bottom half of the spatial coordinates, but the top half maps some coordinates that were low in the gene to scRNA-seq profiles that are high in the gene, and vice versa. The CMAE has even less correspondence between the original spatial RNA-seq value of the gene and the generated scRNA-seq value.</p>
        <p id="p0220">The preservation of signals by scMMGAN and not the other methods has important consequences for downstream analysis. In the first row of <xref rid="fig6" ref-type="fig">Figure 6</xref>, we show the values of SLC2A1. This gene encodes the glucose transporter type 1 (GLUT1) protein that is commonly upregulated in triple-negative breast cancers and is associated with high-grade tumors, having been previously shown to be a potential driver of metastasis in a broad array of breast and other cancers.<xref rid="bib27" ref-type="bibr">27</xref>, <xref rid="bib28" ref-type="bibr">28</xref>, <xref rid="bib29" ref-type="bibr">29</xref>, <xref rid="bib30" ref-type="bibr">30</xref>, <xref rid="bib31" ref-type="bibr">31</xref> Notably, in the spatial data, SLC2A1 activity has a strong spatial pattern in which areas in the tissue express it highly. With scMMGAN mapping, the spatial observations with high SLC2A1 also have high expression in the generated scRNA-seq data. With the other models, however, the SLC2A1-high spatial observations are mapped to SLC2A1-low scRNA-seq cells. This important signal has been lost, and the downstream analysis that seeks to understand the differential spatial distribution and function will have lost this key gene signal. The scMMGAN mapping produces aligned data that best preserves the original signal.</p>
        <p id="p0225">The bottom row showing RER1 demonstrates another canonical situation motivating scMMGAN’s correspondence loss. This gene is roughly bimodally distributed with equal numbers of observations high and low within it. Because flipping two populations is often as easy as introducing a single negative sign into a single weight in a neural network layer, CMAE maps all spatial coordinates high in the gene to scRNA-seq profiles low in the gene and vice versa. Only with scMMGAN’s correspondence loss is one of these equally-easy-to-learn mappings specified as preferable, with the training objective significantly lower for the one that does not flip the populations as opposed to it being equal. This is further corroborated by the results of the quantitative experiments shown in <xref rid="tbl3" ref-type="table">Table 3</xref>.<table-wrap position="float" id="tbl3"><label>Table 3</label><caption><p>Results from the triple-negative breast cancer experiment</p></caption><table frame="hsides" rules="groups"><thead><tr><th>scRNA-seq –&gt; Spatial</th><th>scMMGAN</th><th>CycleGAN</th><th>CMAE</th></tr></thead><tbody><tr><td/><td colspan="3">MMD <inline-formula><mml:math id="M39" altimg="si86.gif"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Sample 1</td><td><bold>0</bold>.<bold>072</bold> ± 0.003</td><td><bold>0</bold>.<bold>072</bold> ± <bold>0</bold>.<bold>001</bold></td><td>0.076 ± 0.002</td></tr><tr><td>Sample 2</td><td><bold>0</bold>.<bold>071</bold> ± 0.001</td><td>0.072 ± 0.002</td><td>0.075 ± 0.002</td></tr><tr><td>Sample 3</td><td><bold>0</bold>.<bold>072</bold> ± 0.002</td><td><bold>0</bold>.<bold>072</bold> ± 0.001</td><td>0.075 ± 0.002</td></tr><tr><td>Sample 4</td><td><bold>0</bold>.<bold>071</bold> ± 0.002</td><td>0.072 ± 0.004</td><td>0.076 ± 0.002</td></tr><tr><td/><td colspan="3">MMD <inline-formula><mml:math id="M40" altimg="si87.gif"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Sample 1</td><td>0.076 ± 0.002</td><td>0.080 ± 0.003</td><td><bold>0</bold>.<bold>075</bold> ± 0.001</td></tr><tr><td>Sample 2</td><td>0.085 ± 0.002</td><td><bold>0</bold>.<bold>074</bold> ± 0.002</td><td>0.078 ± 0.003</td></tr><tr><td>Sample 3</td><td><bold>0</bold>.<bold>081</bold> ± 0.002</td><td>0.082 ± 0.001</td><td>0.087 ± 0.004</td></tr><tr><td>Sample 4</td><td>0.079 ± 0.001</td><td><bold>0</bold>.<bold>076</bold> ± 0.001</td><td>0.086 ± 0.006</td></tr><tr><td/><td colspan="3">MSE <inline-formula><mml:math id="M41" altimg="si87.gif"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Sample 1</td><td><bold>0</bold>.<bold>987</bold> ± 0.128</td><td>2.001 ± 0.525</td><td>2.021 ± 0.323</td></tr><tr><td>Sample 2</td><td><bold>0</bold>.<bold>995</bold> ± 0.126</td><td>1.934 ± 0.235</td><td>1.771 ± 0.521</td></tr><tr><td>Sample 3</td><td><bold>0</bold>.<bold>887</bold> ± 0.026</td><td>2.097 ± 0.548</td><td>1.591 ± 0.728</td></tr><tr><td>Sample 4</td><td><bold>1</bold>.<bold>029</bold> ± 0.017</td><td>1.932 ± 0.353</td><td>1.823 ± 0.288</td></tr><tr><td/><td colspan="3">MSE <inline-formula><mml:math id="M42" altimg="si86.gif"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Sample 1</td><td><bold>0</bold>.<bold>931</bold> ± 0.101</td><td>1.972 ± 0.515</td><td>2.031 ± 0.275</td></tr><tr><td>Sample 2</td><td><bold>0</bold>.<bold>970</bold> ± 0.108</td><td>1.931 ± 0.195</td><td>1.843 ± 0.536</td></tr><tr><td>Sample 3</td><td><bold>0</bold>.<bold>878</bold> ± 0.024</td><td>2.068 ± 0.556</td><td>1.609 ± 0.756</td></tr><tr><td>Sample 4</td><td><bold>0</bold>.<bold>985</bold> ± 0.010</td><td>1.905 ± 0.366</td><td>1.872 ± 0.287</td></tr></tbody></table><table-wrap-foot><fn><p>Quantitative measurement of how well the generated distributions match the target distribution (MMD) and how well they preserve correspondence with the original input distribution (MSE). While all methods match the target distribution reasonably (top two sections), only scMMGAN minimally alters the points in the alignment (bottom two sections). Statistics reported on both mapping directions and across five independent trials. The best or tied-for-best values are in boldface.</p></fn></table-wrap-foot></table-wrap></p>
        <sec id="sec2.2.3.1">
          <title>Gene correlations</title>
          <p id="p0230">scMMGAN highlights the differences between the measurements of the two modalities by investigating the genes most highly correlated with a particular gene of interest in this system in both the original data and the generated data. Specifically, as the spatial data is an aggregate measurement of multiple cells in the same proximate area in the tissue (not a single cell), we can highlight some possibly spurious correlations by mapping them to the scRNA-seq space and recalculating the correlations.</p>
          <p id="p0235">Consider, for example, the glucose-transporter gene SLC2A1 that we have studied previously. If we look at the <inline-formula><mml:math id="M43" altimg="si23.gif"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> most correlated genes in the original spatial data, any of them that have low correlation in the generated scRNA-seq data are candidates for spurious data artifacts. Similarly, any of the <inline-formula><mml:math id="M44" altimg="si23.gif"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> most correlated genes in the generated scRNA-seq data that have low correlation in the original scRNA-seq are candidates for novel associations found by the scMMGAN.</p>
          <p id="p0240">Choosing <inline-formula><mml:math id="M45" altimg="si24.gif"><mml:mrow><mml:mi>n</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>700</mml:mn></mml:mrow></mml:math></inline-formula> and defining low correlation in the other space as being less than 0.1, we obtain a list of six genes that have spurious correlations: FRAT2, CAMK2A, CANX, LRRC66, ZMIZ1-AS1, and MTRNR2L8. We then have the following five genes that have been discovered by scMMGAN: AC092115.3, P2RX7, CCDC93, UTP25, and BBS10.</p>
          <p id="p0245">Among these genes whose correlation to the glucose transmitter SLC2A1 is discovered by scMMGAN, we see P2RX7, which has been identified in the literature as a precursor to glucose transporters.<xref rid="bib32" ref-type="bibr"><sup>32</sup></xref> This provides corroborating support in favor of the scMMGAN-discovered gene correlations.</p>
        </sec>
      </sec>
    </sec>
  </sec>
  <sec id="sec3">
    <title>Discussion</title>
    <p id="p0250">In this work we demonstrated that scMMGAN can align data from related experiments but different modalities in a way that best preserves the properties of the original cells through learned mapping. The addition of the correspondence loss in scMMGAN’s architecture resolves the ambiguity created by only stating a distribution-level loss in learning a mapping. This holds across a wide array of data types and modalities, distribution shapes, and other settings that arise in practical biological experiments.</p>
    <p id="p0255">We have shown how scMMGAN can be used to measure uncertainty in the mapping and use injected stochasticity to gauge which information is unique to one of the modalities and which information is common between them. This can be used to not only answer questions about the cellular samples in an experiment but also to answer questions about the technologies and modalities themselves in terms of their strengths and weaknesses.</p>
    <p id="p0260">Furthermore, we have shown how scMMGAN can be used to identify spurious correlations found in one modality as artifactual results, as opposed to real findings. Similarly, we demonstrated scMMGAN’s ability to identify novel correlations that are not visible in an individual modality but become apparent when the data are mapped to another modality. In these ways, scMMGAN can be added to traditional analysis pipelines to uncover further insights from complicated, multi-modal experimental data.</p>
    <sec id="sec3.1">
      <title>Limitations</title>
      <p id="p0265">There are limitations to the proposed approach that bear mentioning. Although GANs have been useful in mapping distributions, they suffer from key drawbacks. First, they are difficult to train because of the adversarial losses, which can lead to instability.<xref rid="bib33" ref-type="bibr"><sup>33</sup></xref> This instability means that the model can deteriorate from effective to ineffective quickly across training iterations. Second, they often suffer from mode collapse because they are not penalized by distribution-level losses to match the entire distribution.<xref rid="bib34" ref-type="bibr"><sup>34</sup></xref> The additional correspondence loss does not worsen these issues. We informally observe that early stopping, as a regularization, as well as our geometric loss helps mitigate these effects, but these effects may still be present in some contexts. Additionally, with our framework based on pairwise generators in each mapping direction, the number of generators necessary grows quadratically. This means that for a large number of input modalities to align, the networks would have to be made small or would have to be trained separately. Finally, our geometry-based loss is not completely “plug-and-play” in the sense that we still require a choice of distance between data points. In cellular data, we used Euclidean distance to compute the manifold. However, in other contexts, such as two image types, more complicated measures such as the structural similarity index may be used.<xref rid="bib35" ref-type="bibr"><sup>35</sup></xref><sup>,</sup><xref rid="bib36" ref-type="bibr"><sup>36</sup></xref></p>
      <p id="p0270">For this reason, we encourage continued evaluation of aligned results through external verification measures. For example, in this work we verified that known signals across genes and across cells are still preserved in the aligned data. Moreover, we point out that the novel gene correlations found by scMMGAN are potential discoveries that should be further investigated with experiments specifically designed for this aim.</p>
    </sec>
  </sec>
  <sec id="sec4">
    <title>Experimental procedures</title>
    <p id="p0275">In this section we further expand on the model, experimental regimes, and implementations used in this work.</p>
    <sec id="sec4.1">
      <title>Resource availability</title>
      <sec id="sec4.1.1">
        <title>Lead contact</title>
        <p id="p0280">The lead contact is Smita Krishnaswamy (<ext-link ext-link-type="uri" xlink:href="mailto:smita.krishnaswamy@yale.edu" id="intref0015">smita.krishnaswamy@yale.edu</ext-link>).</p>
      </sec>
      <sec id="sec4.1.2">
        <title>Materials availability</title>
        <p id="p0285">There are no newly generated materials.</p>
      </sec>
    </sec>
    <sec id="sec4.2">
      <title>Biological methods</title>
      <p id="p0290">This section describes the methods used to acquire the dataset of triple-negative breast cancer investigated in this paper.</p>
      <sec id="sec4.2.1">
        <title>Animal studies</title>
        <p id="p0295">All experiments were approved by and conducted in accordance with the National Health and Medical Research Council Statement on Animal Experimentation, the requirements of New South Wales State Government legislation, and the rules for animal experimentation of the Biological Testing Facility of the Garvan Institute and the Victor Chang Cardiac Research Institute (protocol #18/12).</p>
        <p id="p0300">Ten NOD/SCID mice at 6–8 weeks of age were purchased from Australian Bioresources (ABR). Mice were 8–9 weeks of age at time of injections. MDA-MB-231-GFP cells (1 × 10<sup>6</sup> cells) were prepared in 25 μL 20% Matrigel (BD Matrigel Matrix Growth Factor Reduced)/serum-free medium and injected orthotopically into the inguinal mammary fat pads. After 9.5 weeks, animals underwent survival surgery to remove the primary tumors (700–1,000 mm<sup>3</sup>), which were subsequently split into three parts: one chunk was used for scRNA-seq, one chunk was formalin fixed and embedded in paraffin for future analysis, and one chunk was frozen in optimal cutting temperature compound for spatial transcriptomics analysis. Animals were housed for 2 more weeks, after which the liver, lymph nodes, and lungs were harvested for analysis of metastatic cells in those tissues.</p>
      </sec>
      <sec id="sec4.2.2">
        <title>scRNA-seq preparation and analysis</title>
        <p id="p0305">Primary tumors, lungs, livers, and lymph nodes were chopped into small pieces, then incubated at 37°C for 40 min on a rotary shaker in DMEM/F12 containing collagenase A (300 U) and hyaluronidase (100 U). Following digestion, cell suspensions were pelleted, the DMEM removed, washed with PBS 2% (v/v) fetal bovine serum (FBS), and resuspended in 0.15% + 10% DNaseI trypsin for 1 min. Trypsin was quenched with 2% FBS/DMEM. Cells were resuspended in FACS buffer (2% [v/v] FBS in PBS). GFP<sup>+</sup> alive tumor cells were sorted and collected, and scRNA-seq was performed using Chromium 10X technology.</p>
      </sec>
      <sec id="sec4.2.3">
        <title>Spatial transcriptomics</title>
        <p id="p0310">Spatial transcriptomics was performed according to the published protocol.<xref rid="bib41" ref-type="bibr"><sup>37</sup></xref></p>
      </sec>
    </sec>
    <sec id="sec4.3">
      <title>Training objectives</title>
      <p id="p0315">Here we elaborate on the training objectives used in the scMMGAN framework learning. We define the formulation considering a pair of domains, with the definitions extending to multiple domains accordingly. It is composed of distinct GAN networks, each with a generator network <inline-formula><mml:math id="M46" altimg="si25.gif"><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:math></inline-formula> with input <inline-formula><mml:math id="M47" altimg="si26.gif"><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:math></inline-formula> and output <inline-formula><mml:math id="M48" altimg="si27.gif"><mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. We call each generator a mapping from the input domain to the output, or target, domain. Each generator attempts to make its output <inline-formula><mml:math id="M49" altimg="si28.gif"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> indistinguishable by <inline-formula><mml:math id="M50" altimg="si29.gif"><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:math></inline-formula> from <inline-formula><mml:math id="M51" altimg="si27.gif"><mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. Denote the two datasets <inline-formula><mml:math id="M52" altimg="si30.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M53" altimg="si31.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. Let the generator mapping from <inline-formula><mml:math id="M54" altimg="si30.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="M55" altimg="si31.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> be <inline-formula><mml:math id="M56" altimg="si32.gif"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mn>12</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and the generator mapping from <inline-formula><mml:math id="M57" altimg="si31.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="M58" altimg="si30.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> be <inline-formula><mml:math id="M59" altimg="si33.gif"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mn>21</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. The discriminator that tries to separate true samples from <inline-formula><mml:math id="M60" altimg="si30.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> from the generated output of <inline-formula><mml:math id="M61" altimg="si34.gif"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mn>21</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is <inline-formula><mml:math id="M62" altimg="si35.gif"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, and the discriminator that tries to separate true samples from <inline-formula><mml:math id="M63" altimg="si31.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> from generated samples from <inline-formula><mml:math id="M64" altimg="si36.gif"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mn>12</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is <inline-formula><mml:math id="M65" altimg="si37.gif"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>.</p>
      <p id="p0320">The loss for <inline-formula><mml:math id="M66" altimg="si38.gif"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> on minibatches <inline-formula><mml:math id="M67" altimg="si39.gif"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M68" altimg="si40.gif"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is<disp-formula id="ufd1"><mml:math id="M69" altimg="si41.gif"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mspace width="0.5em"/><mml:msub><mml:mi>x</mml:mi><mml:mn>12</mml:mn></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mn mathvariant="bold">12</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>121</mml:mn></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mn mathvariant="bold">21</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>12</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mspace width="0.5em"/><mml:msub><mml:mi>L</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mtext>MSE</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>121</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mspace width="0.5em"/><mml:msub><mml:mi>L</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mspace width="0.25em"/><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mn mathvariant="bold">2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>12</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mspace width="0.5em"/><mml:msub><mml:mi>L</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>12</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mn mathvariant="bold">1</mml:mn></mml:msub></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>where MSE is the mean-squared error and <inline-formula><mml:math id="M70" altimg="si42.gif"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula> is the correspondence loss discussed previously. The hyperparameters <inline-formula><mml:math id="M71" altimg="si43.gif"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="M72" altimg="si44.gif"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="M73" altimg="si45.gif"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are chosen to balance the reconstruction, discriminator, and correspondence losses. These can be chosen by default to be <inline-formula><mml:math id="M74" altimg="si46.gif"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, but <inline-formula><mml:math id="M75" altimg="si45.gif"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> increased if the observed correspondences are low and <inline-formula><mml:math id="M76" altimg="si43.gif"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> increased if the observed reconstructions are not accurate.</p>
      <p id="p0325">Similarly, the loss for <inline-formula><mml:math id="M77" altimg="si47.gif"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is<disp-formula id="ufd2"><mml:math id="M78" altimg="si48.gif"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mspace width="0.5em"/><mml:msub><mml:mi>x</mml:mi><mml:mn>21</mml:mn></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mn mathvariant="bold">21</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>212</mml:mn></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mn mathvariant="bold">12</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>21</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mspace width="0.5em"/><mml:msub><mml:mi>L</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mtext>MSE</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>212</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mspace width="0.5em"/><mml:msub><mml:mi>L</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mspace width="0.25em"/><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mn mathvariant="bold">1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>21</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mspace width="0.5em"/><mml:msub><mml:mi>L</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>21</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">L</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mn mathvariant="bold">2</mml:mn></mml:msub></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:mo linebreak="badbreak">+</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
      <p id="p0330">The losses for <inline-formula><mml:math id="M79" altimg="si35.gif"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M80" altimg="si37.gif"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> are<disp-formula id="ufd3"><mml:math id="M81" altimg="si49.gif"><mml:mrow><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">L</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mn mathvariant="bold">1</mml:mn></mml:msub></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mn mathvariant="bold">1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext>log</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mn mathvariant="bold">1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>121</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo linebreak="newline">−</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mn mathvariant="bold">1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>21</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"/></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">L</mml:mi><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mn mathvariant="bold">2</mml:mn></mml:msub></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mn mathvariant="bold">2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo linebreak="badbreak">+</mml:mo><mml:mtext>log</mml:mtext><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mn mathvariant="bold">2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>212</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow><mml:mrow><mml:mo linebreak="newline">−</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mn mathvariant="bold">2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>12</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"/></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
    </sec>
    <sec id="sec4.4">
      <title>Calculation of correspondence loss</title>
      <p id="p0335">For the following notation, consider one of the datasets <inline-formula><mml:math id="M82" altimg="si39.gif"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and its representation after being mapped to the other domain, <inline-formula><mml:math id="M83" altimg="si50.gif"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. First, matrices of pairwise distances <inline-formula><mml:math id="M84" altimg="si51.gif"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M85" altimg="si52.gif"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are constructed.</p>
      <p id="p0340">These are then transformed into matrices of pairwise affinities with an inverse-distance kernel <inline-formula><mml:math id="M86" altimg="si53.gif"><mml:mrow><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mtext>max</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mn>0,1</mml:mn><mml:mo linebreak="badbreak">−</mml:mo><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mo>|</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="badbreak">/</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="M87" altimg="si54.gif"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a k-nearest neighbor adaptive bandwidth. This kernel was necessary, as the standard Gaussian kernel suffered from gradients that saturated and suppressed learning. With this kernel, we are able to effectively perform diffusion geometry learning through gradient descent.</p>
      <p id="p0345">These affinity matrices are transformed into transition probability matrices <inline-formula><mml:math id="M88" altimg="si55.gif"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M89" altimg="si56.gif"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> through row normalization. Powering these matrices <inline-formula><mml:math id="M90" altimg="si57.gif"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> times then represents taking <inline-formula><mml:math id="M91" altimg="si57.gif"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> steps forward in the Markov chain. Let the eigenvectors of these two matrices be <inline-formula><mml:math id="M92" altimg="si14.gif"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M93" altimg="si58.gif"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, respectively. The <inline-formula><mml:math id="M94" altimg="si16.gif"><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mtext>th</mml:mtext></mml:msup></mml:mrow></mml:math></inline-formula> row of <inline-formula><mml:math id="M95" altimg="si14.gif"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M96" altimg="si58.gif"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> represents the diffusion coordinates of the point <inline-formula><mml:math id="M97" altimg="si59.gif"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> in the original space and <inline-formula><mml:math id="M98" altimg="si60.gif"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in the generated space, respectively. Because we are only seeking to match low-frequency structure of the data, we use only the first <inline-formula><mml:math id="M99" altimg="si61.gif"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> eigenvectors of the data as an approximation. The eigenvectors are then rescaled to be between −1 and 1.</p>
      <p id="p0350">We also perform a check before comparing the eigenvectors of the original data <inline-formula><mml:math id="M100" altimg="si62.gif"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and those of the generated data <inline-formula><mml:math id="M101" altimg="si63.gif"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Because the direction of the eigenvectors can be switched, two datasets with equivalent intrinsic geometry could have eigenvectors that are either highly correlated or highly anticorrelated. To combat this, we calculate the correlation of each pair of eigenvectors before computing the loss and whether the correlation is below a threshold <inline-formula><mml:math id="M102" altimg="si64.gif"><mml:mrow><mml:msub><mml:mi mathvariant="normal">ε</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>, then we multiply the values of <inline-formula><mml:math id="M103" altimg="si63.gif"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> by <inline-formula><mml:math id="M104" altimg="si65.gif"><mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> before computing the loss. We then also compare the eigenvectors at different scales by summing adjacent vectors and comparing the new combined representations that have half the number of vectors.</p>
    </sec>
    <sec id="sec4.5">
      <title>Noise-augmented model</title>
      <p id="p0355">Here we detail the noise-augmented model used in the section about distinguishing unique and common information. The core idea is that by providing additional noise as input, the model will be able to use the stochasticity when necessary or ignore it if not. In other words, some generated values will have more certainty behind them in the model and others greater uncertainty. We experiment with this notion by introducing a slight modification of the scMMGAN framework: additional random input. We calculate the generator’s output as <inline-formula><mml:math id="M105" altimg="si66.gif"><mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="M106" altimg="si67.gif"><mml:mrow><mml:mi>z</mml:mi><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0,1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">I</mml:mi><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, concatenating a draw from an isotropic normal distribution with the original input. The reconstruction and correspondence losses are then calculated as usual with just <inline-formula><mml:math id="M107" altimg="si10.gif"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. This allows the model to create more stochasticity around regions of the space where there is not enough information to pin down precisely the correct alignment, while it can ignore the noise and create a deterministic mapping in regions of the space where there is enough information.</p>
    </sec>
    <sec id="sec4.6">
      <title>Invariance and risk</title>
      <p id="p0360">In this section we connect our model in the domain alignment setting to existing literature on invariance and risk minimization.<xref rid="bib37" ref-type="bibr"><sup>38</sup></xref> Consider the domain alignment task as drawing a dataset <inline-formula><mml:math id="M108" altimg="si68.gif"><mml:mrow><mml:msubsup><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi></mml:msubsup><mml:mo>∼</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mi>e</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> from a distribution <inline-formula><mml:math id="M109" altimg="si69.gif"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mi>e</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> where the environment <inline-formula><mml:math id="M110" altimg="si70.gif"><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:math></inline-formula> determines how observations manifest <inline-formula><mml:math id="M111" altimg="si71.gif"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in <inline-formula><mml:math id="M112" altimg="si72.gif"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. The domains <inline-formula><mml:math id="M113" altimg="si30.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M114" altimg="si31.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> in our setting are drawn from <inline-formula><mml:math id="M115" altimg="si69.gif"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mi>e</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, then the datasets <inline-formula><mml:math id="M116" altimg="si73.gif"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M117" altimg="si74.gif"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> are drawn from the distributions <inline-formula><mml:math id="M118" altimg="si30.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M119" altimg="si31.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. Thus, we have two sources of randomness from sampling to consider in learning the desired mappings <inline-formula><mml:math id="M120" altimg="si25.gif"><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:math></inline-formula>, one from the points sampled from the distribution and the other from the distribution sampled from the distribution over settings. We want to minimize the risk of alignment:<disp-formula id="ufd4"><mml:math id="M121" altimg="si75.gif"><mml:mrow><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mi>P</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mn>12</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak">+</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>2</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mn>21</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>1</mml:mn><mml:mi>i</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p id="p0365">The inadequacy of solely a cycle-consistency loss should be obvious from this formation. While minimizing the cycle-consistency loss can optimize performance with respect to the expectation over <inline-formula><mml:math id="M122" altimg="si30.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M123" altimg="si31.gif"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, the formulation is equivalent for all datasets drawn from <inline-formula><mml:math id="M124" altimg="si76.gif"><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:math></inline-formula>. Thus, it is incapable of resolving correlations that are structurally related to the datasets versus those arising spuriously from sampling. These ideas are key to the extension beyond just using cycle consistency in the construction of domain mapping networks.</p>
    </sec>
    <sec id="sec4.7">
      <title>Diffusion maps</title>
      <p id="p0370">Diffusion maps define a process of Markovian diffusion over a dataset, whereby a set of local affinities capture the intrinsic data geometry as quantified by diffusion distances.<xref rid="bib18" ref-type="bibr"><sup>18</sup></xref> They operate on a matrix of pairwise distances that is transformed into a matrix of pairwise affinities, here via the commonly used Gaussian kernel <inline-formula><mml:math id="M125" altimg="si77.gif"><mml:mrow><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo></mml:mrow></mml:math></inline-formula> exp<inline-formula><mml:math id="M126" altimg="si78.gif"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo linebreak="badbreak">/</mml:mo><mml:mi mathvariant="normal">ε</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. A Markov chain transition matrix over the dataset <inline-formula><mml:math id="M127" altimg="si76.gif"><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:math></inline-formula> is constructed from the pairwise affinity matrix <inline-formula><mml:math id="M128" altimg="si79.gif"><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:math></inline-formula> via <inline-formula><mml:math id="M129" altimg="si80.gif"><mml:mrow><mml:mi>P</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>A</mml:mi></mml:mrow></mml:math></inline-formula>. Powering the matrix <inline-formula><mml:math id="M130" altimg="si81.gif"><mml:mrow><mml:msup><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> represents taking <inline-formula><mml:math id="M131" altimg="si57.gif"><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> forward steps in the Markov chain. Diffusion maps are then defined as <inline-formula><mml:math id="M132" altimg="si82.gif"><mml:mrow><mml:msub><mml:mi>Ψ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo linebreak="goodbreak" linebreakstyle="after">=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mn>1</mml:mn><mml:mi>t</mml:mi></mml:msubsup><mml:msub><mml:mi>ψ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:msub><mml:mi>ψ</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="M133" altimg="si83.gif"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M134" altimg="si84.gif"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are the <inline-formula><mml:math id="M135" altimg="si16.gif"><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mtext>th</mml:mtext></mml:msup></mml:mrow></mml:math></inline-formula> eigenvalue and eigenvector of <inline-formula><mml:math id="M136" altimg="si76.gif"><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="M137" altimg="si85.gif"><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:math></inline-formula> is a hyperparameter of the number of top eigenvectors to use. The diffusion map coordinates form a space where the Euclidean distance between points approximates the diffusion distance between those points.</p>
      <p id="p0375">In previous work, diffusion operators have been used in the context of multi-modal data integration.<xref rid="bib38" ref-type="bibr"><sup>39</sup></xref> This has been done for the related tasks of visualizing and denoising, rather than mapping between, the datasets. The approach there differs from ours in that it relies on combining diffusion operators from different modalities through algebraic operations as opposed to our method, which integrates them into a broader deep-learning framework.</p>
      <p id="p0380">The diffusion maps are a key foundational notion used in the construction of the data geometry loss.</p>
    </sec>
    <sec id="sec4.8">
      <title>Geometry-preserving correspondence loss</title>
      <p id="p0385">We now further elaborate on a few points about the geometry-preserving correspondence loss introduced in this paper. We only enforce the correspondence loss on the first eigenvectors because this ensures that basic low-frequency signals are largely aligned while still allowing the flexibility of changing high-frequency signals that are more likely to be idiosyncratic to each domain. In practice we find using 10–20 eigenvectors works best.</p>
      <p id="p0390">We note that any changes to the data geometry would cause a mismatch here, and thus the ideal alignment would not drive this term in the objective all the way to zero unless the two datasets being aligned have identical geometry. Despite the goal not being zero correspondence loss, there are many different mappings that achieve comparably low GAN losses, and among them the ones with lower correspondence losses are preferable. This is why using it as a regularization to lightly guide the transformation in addition to the GAN loss can achieve the best performance overall.</p>
    </sec>
    <sec id="sec4.9">
      <title>Architecture and baselines</title>
      <p id="p0395">We compare scMMGAN with alternative baseline deep-learning models used for alignment of this type: a CycleGAN, to motivate the need for the correspondence loss by showing the improper alignments obtained without it;<xref rid="bib9" ref-type="bibr"><sup>9</sup></xref> and CMAE, an autoencoder-based model that uses separate encoders/decoders that learn to map into a shared space and then generates by crossing the encoder of one domain with the decoder of another.<xref rid="bib21" ref-type="bibr"><sup>21</sup></xref> These alternative methods use distribution-level losses to ensure the generated distribution matches the target distribution, but do not impose any loss on the representation of a point and its representation in the aligned domain. As a result, they can produce alignments that unnecessarily invert signals and change values of individual points.</p>
      <p id="p0400">With scMMGAN, we use a generator consisting of three internal layers of 128, 256, and 512 neurons with batch norm and leaky rectified linear unit activations after each layer, and a discriminator consisting of three internal layers with 1,024, 512, and 256 neurons with the same batch norm and activations except with minibatching after the first layer.<xref rid="bib33" ref-type="bibr"><sup>33</sup></xref><sup>,</sup><xref rid="bib39" ref-type="bibr"><sup>40</sup></xref> We use a correspondence loss coefficient of 10, cycle-loss coefficient of 1, learning rate of 0.0001, and batch size of 256. As preprocessing steps prior to running each model on this dataset, we correct for dropout with the manifold smoothing method MAGIC,<xref rid="bib40" ref-type="bibr"><sup>41</sup></xref> zero-center and unit scale each dimension, and reduce to 50 principal components. We use these architectures and hyperparameters in all subsequent experiments except where otherwise stated.</p>
    </sec>
  </sec>
</body>
<back>
  <ref-list id="cebib0010">
    <title>References</title>
    <ref id="bib1">
      <label>1</label>
      <element-citation publication-type="journal" id="sref1">
        <person-group person-group-type="author">
          <name>
            <surname>Ozsolak</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Milos</surname>
            <given-names>P.M.</given-names>
          </name>
        </person-group>
        <article-title>Rna sequencing: advances, challenges and opportunities</article-title>
        <source>Nat. Rev. Genet.</source>
        <volume>12</volume>
        <year>2011</year>
        <fpage>87</fpage>
        <lpage>98</lpage>
        <pub-id pub-id-type="pmid">21191423</pub-id>
      </element-citation>
    </ref>
    <ref id="bib2">
      <label>2</label>
      <element-citation publication-type="journal" id="sref2">
        <person-group person-group-type="author">
          <name>
            <surname>Baek</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>I.</given-names>
          </name>
        </person-group>
        <article-title>Single-cell atac sequencing analysis: from data preprocessing to hypothesis generation</article-title>
        <source>Comput. Struct. Biotechnol. J.</source>
        <volume>18</volume>
        <year>2020</year>
        <fpage>1429</fpage>
        <lpage>1439</lpage>
        <pub-id pub-id-type="pmid">32637041</pub-id>
      </element-citation>
    </ref>
    <ref id="bib3">
      <label>3</label>
      <element-citation publication-type="journal" id="sref3">
        <person-group person-group-type="author">
          <name>
            <surname>Forcato</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Nicoletti</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Pal</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Livi</surname>
            <given-names>C.M.</given-names>
          </name>
          <name>
            <surname>Ferrari</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Bicciato</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Comparison of computational methods for hi-c data analysis</article-title>
        <source>Nat. Methods</source>
        <volume>14</volume>
        <year>2017</year>
        <fpage>679</fpage>
        <lpage>685</lpage>
        <pub-id pub-id-type="pmid">28604721</pub-id>
      </element-citation>
    </ref>
    <ref id="bib4">
      <label>4</label>
      <element-citation publication-type="journal" id="sref4">
        <person-group person-group-type="author">
          <name>
            <surname>Park</surname>
            <given-names>P.J.</given-names>
          </name>
        </person-group>
        <article-title>Chip–seq: advantages and challenges of a maturing technology</article-title>
        <source>Nat. Rev. Genet.</source>
        <volume>10</volume>
        <year>2009</year>
        <fpage>669</fpage>
        <lpage>680</lpage>
        <pub-id pub-id-type="pmid">19736561</pub-id>
      </element-citation>
    </ref>
    <ref id="bib5">
      <label>5</label>
      <element-citation publication-type="book" id="sref5">
        <person-group person-group-type="author">
          <name>
            <surname>Stoeckius</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Peter</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <part-title>Cite-seq</part-title>
        <year>2017</year>
      </element-citation>
    </ref>
    <ref id="bib6">
      <label>6</label>
      <element-citation publication-type="journal" id="sref6">
        <person-group person-group-type="author">
          <name>
            <surname>Moretti</surname>
            <given-names>J.L.</given-names>
          </name>
          <name>
            <surname>Hauet</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Caglar</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Rebillard</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Burak</surname>
            <given-names>Z.</given-names>
          </name>
        </person-group>
        <article-title>To use mibi or not to use mibi? that is the question when assessing tumour cells</article-title>
        <source>Eur. J. Nucl. Med. Mol. Imag.</source>
        <volume>32</volume>
        <year>2005</year>
        <fpage>836</fpage>
        <lpage>842</lpage>
      </element-citation>
    </ref>
    <ref id="bib7">
      <label>7</label>
      <element-citation publication-type="journal" id="sref7">
        <person-group person-group-type="author">
          <name>
            <surname>Cheung</surname>
            <given-names>R.K.</given-names>
          </name>
          <name>
            <surname>Utz</surname>
            <given-names>P.J.</given-names>
          </name>
        </person-group>
        <article-title>Cytof—the next generation of cell detection</article-title>
        <source>Nat. Rev. Rheumatol.</source>
        <volume>7</volume>
        <year>2011</year>
        <fpage>502</fpage>
        <lpage>503</lpage>
        <pub-id pub-id-type="pmid">21788983</pub-id>
      </element-citation>
    </ref>
    <ref id="bib8">
      <label>8</label>
      <element-citation publication-type="book" id="sref8">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Cha</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>Jung K.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <part-title>Learning to discover cross-domain relations with generative adversarial networks</part-title>
        <source>International Conference on Machine Learning</source>
        <year>2017</year>
        <publisher-name>PMLR</publisher-name>
        <fpage>1857</fpage>
        <lpage>1865</lpage>
      </element-citation>
    </ref>
    <ref id="bib9">
      <label>9</label>
      <element-citation publication-type="book" id="sref9">
        <person-group person-group-type="author">
          <name>
            <surname>Zhu</surname>
            <given-names>J.-Y.</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Isola</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Efros</surname>
            <given-names>A.A.</given-names>
          </name>
        </person-group>
        <part-title>Unpaired image-to-image translation using cycle-consistent adversarial networks</part-title>
        <source>Proceedings of the IEEE international conference on computer vision</source>
        <year>2017</year>
        <fpage>2223</fpage>
        <lpage>2232</lpage>
      </element-citation>
    </ref>
    <ref id="bib10">
      <label>10</label>
      <element-citation publication-type="book" id="sref10">
        <person-group person-group-type="author">
          <name>
            <surname>Almahairi</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Rajeshwar</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Sordoni</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Bachman</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Courville</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <part-title>Augmented cyclegan: learning many-to-many mappings from unpaired data</part-title>
        <source>International Conference on Machine Learning</source>
        <year>2018</year>
        <publisher-name>PMLR</publisher-name>
        <fpage>195</fpage>
        <lpage>204</lpage>
      </element-citation>
    </ref>
    <ref id="bib11">
      <label>11</label>
      <element-citation publication-type="journal" id="sref11">
        <person-group person-group-type="author">
          <name>
            <surname>Goodfellow</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Pouget-Abadie</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Mirza</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Warde-Farley</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Ozair</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Courville</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Generative adversarial networks</article-title>
        <source>Commun. ACM</source>
        <volume>63</volume>
        <year>2020</year>
        <fpage>139</fpage>
        <lpage>144</lpage>
      </element-citation>
    </ref>
    <ref id="bib12">
      <label>12</label>
      <element-citation publication-type="book" id="sref12">
        <person-group person-group-type="author">
          <name>
            <surname>Amodio</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Krishnaswamy</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <part-title>Magan: aligning biological manifolds</part-title>
        <source>International Conference on Machine Learning</source>
        <year>2018</year>
        <publisher-name>PMLR</publisher-name>
        <fpage>215</fpage>
        <lpage>223</lpage>
      </element-citation>
    </ref>
    <ref id="bib13">
      <label>13</label>
      <element-citation publication-type="book" id="sref13">
        <person-group person-group-type="author">
          <name>
            <surname>Arjovsky</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Chintala</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Bottou</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <part-title>Wasserstein generative adversarial networks</part-title>
        <source>International conference on machine learning</source>
        <year>2017</year>
        <publisher-name>PMLR</publisher-name>
        <fpage>214</fpage>
        <lpage>223</lpage>
      </element-citation>
    </ref>
    <ref id="bib14">
      <label>14</label>
      <element-citation publication-type="journal" id="sref14">
        <person-group person-group-type="author">
          <name>
            <surname>Gulrajani</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Ahmed</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Martin</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Vincent</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>C Courville</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Improved training of wasserstein gans</article-title>
        <source>Adv. Neural Inf. Process. Syst.</source>
        <volume>30</volume>
        <year>2017</year>
      </element-citation>
    </ref>
    <ref id="bib15">
      <label>15</label>
      <element-citation publication-type="book" id="sref15">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Thoma</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Acharya</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Van Gool</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <part-title>Wasserstein divergence for gans</part-title>
        <source>Proceedings of the European Conference on Computer Vision</source>
        <year>2018</year>
        <publisher-name>ECCV)</publisher-name>
        <fpage>653</fpage>
        <lpage>668</lpage>
      </element-citation>
    </ref>
    <ref id="bib16">
      <label>16</label>
      <element-citation publication-type="book" id="sref16">
        <person-group person-group-type="author">
          <name>
            <surname>Stanley</surname>
            <given-names>J.S.</given-names>
            <suffix>III</suffix>
          </name>
          <name>
            <surname>Scott</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Wolf</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Krishnaswamy</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <part-title>Harmonic alignment</part-title>
        <source>Proceedings of the 2020 SIAM International Conference on Data Mining</source>
        <year>2020</year>
        <publisher-name>SIAM</publisher-name>
        <fpage>316</fpage>
        <lpage>324</lpage>
      </element-citation>
    </ref>
    <ref id="bib17">
      <label>17</label>
      <element-citation publication-type="journal" id="sref17">
        <person-group person-group-type="author">
          <name>
            <surname>Coifman</surname>
            <given-names>R.R.</given-names>
          </name>
          <name>
            <surname>Lafon</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Diffusion maps</article-title>
        <source>Appl. Comput. Harmon. Anal.</source>
        <volume>21</volume>
        <year>2006</year>
        <fpage>5</fpage>
        <lpage>30</lpage>
      </element-citation>
    </ref>
    <ref id="bib18">
      <label>18</label>
      <element-citation publication-type="journal" id="sref18">
        <person-group person-group-type="author">
          <name>
            <surname>Coifman</surname>
            <given-names>R.R.</given-names>
          </name>
          <name>
            <surname>Lafon</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>A.B.</given-names>
          </name>
          <name>
            <surname>Maggioni</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Nadler</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Warner</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Zucker</surname>
            <given-names>S.W.</given-names>
          </name>
        </person-group>
        <article-title>Geometric diffusions as a tool for harmonic analysis and structure definition of data: diffusion maps</article-title>
        <source>Proc. Natl. Acad. Sci. USA</source>
        <volume>102</volume>
        <year>2005</year>
        <fpage>7426</fpage>
        <lpage>7431</lpage>
        <pub-id pub-id-type="pmid">15899970</pub-id>
      </element-citation>
    </ref>
    <ref id="bib19">
      <label>19</label>
      <element-citation publication-type="book" id="sref19">
        <person-group person-group-type="author">
          <name>
            <surname>De la Porte</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Herbst</surname>
            <given-names>B.M.</given-names>
          </name>
          <name>
            <surname>Hereman</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Van Der Walt</surname>
            <given-names>S.J.</given-names>
          </name>
        </person-group>
        <part-title>An introduction to diffusion maps</part-title>
        <source>Proceedings of the 19th symposium of the pattern recognition association of South Africa (PRASA 2008), Cape Town, South Africa</source>
        <year>2008</year>
        <fpage>15</fpage>
        <lpage>25</lpage>
      </element-citation>
    </ref>
    <ref id="bib20">
      <label>20</label>
      <element-citation publication-type="journal" id="sref20">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Enninful</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>C.C.</given-names>
          </name>
          <name>
            <surname>Tebaldi</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Bai</surname>
            <given-names>Z.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>High-spatial-resolution multi-omics sequencing via deterministic barcoding in tissue</article-title>
        <source>Cell</source>
        <volume>183</volume>
        <year>2020</year>
        <fpage>1665</fpage>
        <lpage>1681.e18</lpage>
        <pub-id pub-id-type="pmid">33188776</pub-id>
      </element-citation>
    </ref>
    <ref id="bib21">
      <label>21</label>
      <element-citation publication-type="journal" id="sref21">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>K.D.</given-names>
          </name>
          <name>
            <surname>Belyaeva</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Venkatachalapathy</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Damodaran</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Katcoff</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Radhakrishnan</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Shivashankar</surname>
            <given-names>G.V.</given-names>
          </name>
          <name>
            <surname>Uhler</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Multi-domain translation between single-cell imaging and sequencing data using autoencoders</article-title>
        <source>Nat. Commun.</source>
        <volume>12</volume>
        <year>2021</year>
        <fpage>31</fpage>
        <pub-id pub-id-type="pmid">33397893</pub-id>
      </element-citation>
    </ref>
    <ref id="bib22">
      <label>22</label>
      <element-citation publication-type="journal" id="sref22">
        <person-group person-group-type="author">
          <name>
            <surname>Borgwardt</surname>
            <given-names>K.M.</given-names>
          </name>
          <name>
            <surname>Gretton</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Rasch</surname>
            <given-names>M.J.</given-names>
          </name>
          <name>
            <surname>Kriegel</surname>
            <given-names>H.-P.</given-names>
          </name>
          <name>
            <surname>Schölkopf</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Smola</surname>
            <given-names>A.J.</given-names>
          </name>
        </person-group>
        <article-title>Integrating structured biological data by kernel maximum mean discrepancy</article-title>
        <source>Bioinformatics</source>
        <volume>22</volume>
        <year>2006</year>
        <fpage>e49</fpage>
        <lpage>e57</lpage>
        <pub-id pub-id-type="pmid">16873512</pub-id>
      </element-citation>
    </ref>
    <ref id="bib23">
      <label>23</label>
      <element-citation publication-type="journal" id="sref23">
        <person-group person-group-type="author">
          <name>
            <surname>Gao</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Niu</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Sugiyama</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Maximum mean discrepancy is aware of adversarial attacks</article-title>
        <comment>Preprint at</comment>
        <source>arXiv</source>
        <year>2020</year>
        <pub-id pub-id-type="doi">10.48550/arXiv.2010.11415</pub-id>
      </element-citation>
    </ref>
    <ref id="bib24">
      <label>24</label>
      <element-citation publication-type="journal" id="sref24">
        <person-group person-group-type="author">
          <name>
            <surname>Amodio</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>van Dijk</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Srinivasan</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W.S.</given-names>
          </name>
          <name>
            <surname>Mohsen</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Moon</surname>
            <given-names>K.R.</given-names>
          </name>
          <name>
            <surname>Campbell</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Venkataswamy</surname>
            <given-names>M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Exploring single-cell data with deep multitasking neural networks</article-title>
        <source>Nat. Methods</source>
        <volume>16</volume>
        <year>2019</year>
        <fpage>1139</fpage>
        <lpage>1145</lpage>
        <pub-id pub-id-type="pmid">31591579</pub-id>
      </element-citation>
    </ref>
    <ref id="bib25">
      <label>25</label>
      <element-citation publication-type="journal" id="sref25">
        <person-group person-group-type="author">
          <name>
            <surname>Bowne</surname>
            <given-names>S.J.</given-names>
          </name>
          <name>
            <surname>Daiger</surname>
            <given-names>S.P.</given-names>
          </name>
          <name>
            <surname>Hims</surname>
            <given-names>M.M.</given-names>
          </name>
          <name>
            <surname>Sohocki</surname>
            <given-names>M.M.</given-names>
          </name>
          <name>
            <surname>Malone</surname>
            <given-names>K.A.</given-names>
          </name>
          <name>
            <surname>McKie</surname>
            <given-names>A.B.</given-names>
          </name>
          <name>
            <surname>Heckenlively</surname>
            <given-names>J.R.</given-names>
          </name>
          <name>
            <surname>Birch</surname>
            <given-names>D.G.</given-names>
          </name>
          <name>
            <surname>Inglehearn</surname>
            <given-names>C.F.</given-names>
          </name>
          <name>
            <surname>Bhattacharya</surname>
            <given-names>S.S.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Mutations in the rp1 gene causing autosomal dominant retinitis pigmentosa</article-title>
        <source>Hum. Mol. Genet.</source>
        <volume>8</volume>
        <year>1999</year>
        <fpage>2121</fpage>
        <lpage>2128</lpage>
        <pub-id pub-id-type="pmid">10484783</pub-id>
      </element-citation>
    </ref>
    <ref id="bib26">
      <label>26</label>
      <element-citation publication-type="journal" id="sref26">
        <person-group person-group-type="author">
          <name>
            <surname>Satpathy</surname>
            <given-names>A.T.</given-names>
          </name>
          <name>
            <surname>Granja</surname>
            <given-names>J.M.</given-names>
          </name>
          <name>
            <surname>Yost</surname>
            <given-names>K.E.</given-names>
          </name>
          <name>
            <surname>Qi</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Meschi</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>McDermott</surname>
            <given-names>G.P.</given-names>
          </name>
          <name>
            <surname>Olsen</surname>
            <given-names>B.N.</given-names>
          </name>
          <name>
            <surname>Mumbach</surname>
            <given-names>M.R.</given-names>
          </name>
          <name>
            <surname>Pierce</surname>
            <given-names>S.E.</given-names>
          </name>
          <name>
            <surname>Corces</surname>
            <given-names>M.R.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Massively parallel single-cell chromatin landscapes of human immune cell development and intratumoral t cell exhaustion</article-title>
        <source>Nat. Biotechnol.</source>
        <volume>37</volume>
        <year>2019</year>
        <fpage>925</fpage>
        <lpage>936</lpage>
        <pub-id pub-id-type="pmid">31375813</pub-id>
      </element-citation>
    </ref>
    <ref id="bib27">
      <label>27</label>
      <element-citation publication-type="journal" id="sref27">
        <person-group person-group-type="author">
          <name>
            <surname>Hussein</surname>
            <given-names>Y.R.</given-names>
          </name>
          <name>
            <surname>Bandyopadhyay</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Semaan</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Ahmed</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Albashiti</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Jazaerly</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Nahleh</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Ali-Fehmi</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>Glut-1 expression correlates with basal-like breast cancer</article-title>
        <source>Transl. Oncol.</source>
        <volume>4</volume>
        <year>2011</year>
        <fpage>321</fpage>
        <lpage>327</lpage>
        <pub-id pub-id-type="pmid">22190995</pub-id>
      </element-citation>
    </ref>
    <ref id="bib28">
      <label>28</label>
      <element-citation publication-type="journal" id="sref28">
        <person-group person-group-type="author">
          <name>
            <surname>Min</surname>
            <given-names>K.-W.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>D.-H.</given-names>
          </name>
          <name>
            <surname>Son</surname>
            <given-names>B.K.</given-names>
          </name>
          <name>
            <surname>Moon</surname>
            <given-names>K.M.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Intazur Rahaman</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>S.W.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>E.K.</given-names>
          </name>
          <name>
            <surname>Kwon</surname>
            <given-names>M.J.</given-names>
          </name>
          <name>
            <surname>Koh</surname>
            <given-names>Y.W.</given-names>
          </name>
          <name>
            <surname>Oh</surname>
            <given-names>I.H.</given-names>
          </name>
        </person-group>
        <article-title>High slc2a1 expression associated with suppressing cd8 t cells and b cells promoted cancer survival in gastric cancer</article-title>
        <source>PLoS One</source>
        <volume>16</volume>
        <year>2021</year>
        <fpage>e0245075</fpage>
        <pub-id pub-id-type="pmid">33735188</pub-id>
      </element-citation>
    </ref>
    <ref id="bib29">
      <label>29</label>
      <element-citation publication-type="journal" id="sref29">
        <person-group person-group-type="author">
          <name>
            <surname>Noguchi</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Saito</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Miyagi</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Yamanaka</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Marat</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Doi</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Yoshikawa</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Tsuburaya</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Ito</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Satoh</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Suppression of facilitative glucose transporter 1 mrna can suppress tumor growth</article-title>
        <source>Cancer Lett.</source>
        <volume>154</volume>
        <year>2000</year>
        <fpage>175</fpage>
        <lpage>182</lpage>
        <pub-id pub-id-type="pmid">10806305</pub-id>
      </element-citation>
    </ref>
    <ref id="bib30">
      <label>30</label>
      <element-citation publication-type="journal" id="sref30">
        <person-group person-group-type="author">
          <name>
            <surname>Krzeslak</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Wojcik-Krowiranda</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Forma</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Jozwiak</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Romanowicz</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Bienkiewicz</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Brys</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Expression of glut1 and glut3 glucose transporters in endometrial and breast cancers</article-title>
        <source>Pathol. Oncol. Res.</source>
        <volume>18</volume>
        <year>2012</year>
        <fpage>721</fpage>
        <lpage>728</lpage>
        <pub-id pub-id-type="pmid">22270867</pub-id>
      </element-citation>
    </ref>
    <ref id="bib31">
      <label>31</label>
      <element-citation publication-type="journal" id="sref31">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Ba-Alawi</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Deblois</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Cruickshank</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lima-Fernandes</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Haight</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Tonekaboni</surname>
            <given-names>S.A.M.</given-names>
          </name>
          <name>
            <surname>Fortier</surname>
            <given-names>A.M.</given-names>
          </name>
          <name>
            <surname>Kuasne</surname>
            <given-names>H.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Glut1 inhibition blocks growth of rb1-positive triple negative breast cancer</article-title>
        <source>Nat. Commun.</source>
        <volume>11</volume>
        <year>2020</year>
        <fpage>4205</fpage>
        <lpage>4212</lpage>
        <pub-id pub-id-type="pmid">32826891</pub-id>
      </element-citation>
    </ref>
    <ref id="bib32">
      <label>32</label>
      <element-citation publication-type="journal" id="sref32">
        <person-group person-group-type="author">
          <name>
            <surname>Arguin</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Bourzac</surname>
            <given-names>J.F.</given-names>
          </name>
          <name>
            <surname>Placet</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Molle</surname>
            <given-names>C.M.</given-names>
          </name>
          <name>
            <surname>Paquette</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Beaudoin</surname>
            <given-names>J.F.</given-names>
          </name>
          <name>
            <surname>Rousseau</surname>
            <given-names>J.A.</given-names>
          </name>
          <name>
            <surname>Lecomte</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Plourde</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Gendron</surname>
            <given-names>F.-P.</given-names>
          </name>
        </person-group>
        <article-title>The loss of p2x7 receptor expression leads to increase intestinal glucose transit and hepatic steatosis</article-title>
        <source>Sci. Rep.</source>
        <volume>7</volume>
        <year>2017</year>
        <fpage>12917</fpage>
        <lpage>13016</lpage>
        <pub-id pub-id-type="pmid">29018292</pub-id>
      </element-citation>
    </ref>
    <ref id="bib33">
      <label>33</label>
      <element-citation publication-type="journal" id="sref33">
        <person-group person-group-type="author">
          <name>
            <surname>Salimans</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Goodfellow</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Zaremba</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Cheung</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Radford</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>X.</given-names>
          </name>
        </person-group>
        <article-title>Improved techniques for training gans</article-title>
        <source>Adv. Neural Inf. Process. Syst.</source>
        <volume>29</volume>
        <year>2016</year>
        <fpage>2234</fpage>
        <lpage>2242</lpage>
      </element-citation>
    </ref>
    <ref id="bib34">
      <label>34</label>
      <element-citation publication-type="book" id="sref34">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <part-title>Spectral regularization for combating mode collapse in gans</part-title>
        <source>Proceedings of the IEEE/CVF International Conference on Computer Vision</source>
        <year>2019</year>
        <fpage>6382</fpage>
        <lpage>6390</lpage>
      </element-citation>
    </ref>
    <ref id="bib35">
      <label>35</label>
      <element-citation publication-type="journal" id="sref35">
        <person-group person-group-type="author">
          <name>
            <surname>Brunet</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Vrscay</surname>
            <given-names>E.R.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z.</given-names>
          </name>
        </person-group>
        <article-title>On the mathematical properties of the structural similarity index</article-title>
        <source>IEEE Trans. Image Process.</source>
        <volume>21</volume>
        <year>2012</year>
        <fpage>1488</fpage>
        <lpage>1499</lpage>
        <pub-id pub-id-type="pmid">22042163</pub-id>
      </element-citation>
    </ref>
    <ref id="bib36">
      <label>36</label>
      <element-citation publication-type="book" id="sref36">
        <person-group person-group-type="author">
          <name>
            <surname>Hore</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Ziou</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <part-title>Image Quality Metrics: Psnr vs. Ssim</part-title>
        <source>In 2010 20th International Conference on Pattern Recognition</source>
        <year>2010</year>
        <publisher-name>IEEE</publisher-name>
        <fpage>2366</fpage>
        <lpage>2369</lpage>
      </element-citation>
    </ref>
    <ref id="bib41">
      <label>37</label>
      <element-citation publication-type="journal" id="optAfS5l5FvKq">
        <person-group person-group-type="author">
          <name>
            <surname>Vickovic</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Eraslan</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Salmén</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Klughammer</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Stenbeck</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Schapiro</surname>
            <given-names>D.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>High-definition spatial transcriptomics for in situ tissue profiling</article-title>
        <source>Nature methods</source>
        <volume>16</volume>
        <year>2019 Oct</year>
        <fpage>987</fpage>
        <lpage>990</lpage>
        <pub-id pub-id-type="pmid">31501547</pub-id>
      </element-citation>
    </ref>
    <ref id="bib37">
      <label>38</label>
      <element-citation publication-type="journal" id="sref37">
        <person-group person-group-type="author">
          <name>
            <surname>Arjovsky</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Bottou</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Gulrajani</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Lopez-Paz</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Invariant Risk Minimization</article-title>
        <source>Preprint at arXiv</source>
        <year>2019</year>
        <pub-id pub-id-type="doi">10.48550/arXiv.1907.02893</pub-id>
      </element-citation>
    </ref>
    <ref id="bib38">
      <label>39</label>
      <element-citation publication-type="book" id="sref38">
        <person-group person-group-type="author">
          <name>
            <surname>Kuchroo</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Godavarthi</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Tong</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Wolf</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Krishnaswamy</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <part-title>Multimodal data visualization and denoising with integrated diffusion</part-title>
        <source>2021 IEEE 31st International Workshop on Machine Learning for Signal Processing (MLSP)</source>
        <year>2021</year>
        <publisher-name>IEEE</publisher-name>
        <fpage>1</fpage>
        <lpage>6</lpage>
      </element-citation>
    </ref>
    <ref id="bib39">
      <label>40</label>
      <element-citation publication-type="book" id="sref39">
        <person-group person-group-type="author">
          <name>
            <surname>Santurkar</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Tsipras</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Ilyas</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Mądry</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <part-title>How does batch normalization help optimization?</part-title>
        <source>Proceedings of the 32nd international conference on neural information processing systems</source>
        <year>2018</year>
        <fpage>2488</fpage>
        <lpage>2498</lpage>
      </element-citation>
    </ref>
    <ref id="bib40">
      <label>41</label>
      <element-citation publication-type="journal" id="sref40">
        <person-group person-group-type="author">
          <name>
            <surname>Van Dijk</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Sharma</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Nainys</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Yim</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Kathail</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Carr</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Burdziak</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Moon</surname>
            <given-names>K.R.</given-names>
          </name>
          <name>
            <surname>Chaffer</surname>
            <given-names>C.L.</given-names>
          </name>
          <name>
            <surname>Pattabiraman</surname>
            <given-names>D.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Recovering gene interactions from single-cell data using data diffusion</article-title>
        <source>Cell</source>
        <volume>174</volume>
        <year>2018</year>
        <fpage>716</fpage>
        <lpage>729.e27</lpage>
        <pub-id pub-id-type="pmid">29961576</pub-id>
      </element-citation>
    </ref>
  </ref-list>
  <sec sec-type="data-availability" id="da0010">
    <title>Data and code availability</title>
    <p id="p0025">An implementation of the scMMGAN model written in Python and Tensorflow, which can be run on any user-loaded datasets, is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/KrishnaswamyLab/scMMGAN" id="intref0010">https://github.com/KrishnaswamyLab/scMMGAN</ext-link>. Direct further data availability inquiries to the <xref rid="sec4.1.1" ref-type="sec">lead contact</xref>.</p>
  </sec>
  <ack id="ack0010">
    <title>Acknowledgments</title>
    <p id="p0405">S.K. was supported by the <funding-source id="gs1"><institution-wrap><institution-id institution-id-type="doi">10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source> grants (R01MH118554-01A1, 1R01GM130847-01A1, 1R01GM1355929), <funding-source id="gs2"><institution-wrap><institution-id institution-id-type="doi">10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source> grant (FG-2021-15883), and the <funding-source id="gs3"><institution-wrap><institution-id institution-id-type="doi">10.13039/501100000930</institution-id><institution>NSF</institution></institution-wrap></funding-source> Career grant. C.L.C. was supported by the <funding-source id="gs4"><institution-wrap><institution-id institution-id-type="doi">10.13039/501100000925</institution-id><institution>National Health and Medical Research Council of Australia</institution></institution-wrap></funding-source> (GNT1088122 and GNT1181230), <funding-source id="gs5"><institution-wrap><institution-id institution-id-type="doi">10.13039/501100001026</institution-id><institution>National Breast Cancer Foundation</institution></institution-wrap></funding-source> research grant IIRS-19-092, <funding-source id="gs6"><institution-wrap><institution-id institution-id-type="doi">10.13039/501100001171</institution-id><institution>Cancer Institute New South Wales</institution></institution-wrap></funding-source> Fellowship (CDF181243), and philanthropic support from the <funding-source id="gs7">Nelune Foundation Rebecca Wilson</funding-source> Fellowship. S.E.Y. was supported by the <funding-source id="gs8"><institution-wrap><institution-id institution-id-type="doi">10.13039/501100022538</institution-id><institution>Kinghorn Foundation</institution></institution-wrap></funding-source>.</p>
    <sec id="sec5">
      <title>Author contributions</title>
      <p id="p0410">M.A. and S.K. designed the model and computational experiments, and wrote the text of the manuscript. M.A. wrote the code and performed the computational experiments. S.E.Y., A.V., and C.L.C. helped with the biological analysis of the breast cancer dataset. S.Y., B.P.S.J., and C.L.C. performed experiments to generate the breast cancer dataset.</p>
    </sec>
    <sec sec-type="COI-statement" id="sec6">
      <title>Declaration of interests</title>
      <p id="p0415">The authors declare no competing interests.</p>
    </sec>
  </ack>
</back>
