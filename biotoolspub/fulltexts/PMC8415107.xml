<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Neuroinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Neuroinform</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Neuroinform.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Neuroinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1662-5196</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8415107</article-id>
    <article-id pub-id-type="doi">10.3389/fninf.2021.689675</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Neuroscience</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Clinica: An Open-Source Software Platform for Reproducible Clinical Neuroscience Studies</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Routier</surname>
          <given-names>Alexandre</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/548958/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Burgos</surname>
          <given-names>Ninon</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/420683/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Díaz</surname>
          <given-names>Mauricio</given-names>
        </name>
        <xref ref-type="aff" rid="aff7">
          <sup>7</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bacci</surname>
          <given-names>Michael</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bottani</surname>
          <given-names>Simona</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/1318570/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>El-Rifai</surname>
          <given-names>Omar</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/1421484/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fontanella</surname>
          <given-names>Sabrina</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gori</surname>
          <given-names>Pietro</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Guillon</surname>
          <given-names>Jérémy</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Guyot</surname>
          <given-names>Alexis</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hassanaly</surname>
          <given-names>Ravi</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jacquemont</surname>
          <given-names>Thomas</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/820218/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lu</surname>
          <given-names>Pascal</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Marcoux</surname>
          <given-names>Arnaud</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Moreau</surname>
          <given-names>Tristan</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Samper-González</surname>
          <given-names>Jorge</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/301214/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Teichmann</surname>
          <given-names>Marc</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
        <xref ref-type="aff" rid="aff8">
          <sup>8</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Thibeau-Sutre</surname>
          <given-names>Elina</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/1069382/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Vaillant</surname>
          <given-names>Ghislain</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wen</surname>
          <given-names>Junhao</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/620057/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wild</surname>
          <given-names>Adam</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Habert</surname>
          <given-names>Marie-Odile</given-names>
        </name>
        <xref ref-type="aff" rid="aff9">
          <sup>9</sup>
        </xref>
        <xref ref-type="aff" rid="aff10">
          <sup>10</sup>
        </xref>
        <xref ref-type="aff" rid="aff11">
          <sup>11</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Durrleman</surname>
          <given-names>Stanley</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/369610/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Colliot</surname>
          <given-names>Olivier</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff6">
          <sup>6</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/10655/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>Inria, Aramis Project-Team</institution>, <addr-line>Paris</addr-line>, <country>France</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Sorbonne Université</institution>, <addr-line>Paris</addr-line>, <country>France</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Institut du Cerveau – Paris Brain Institute – ICM</institution>, <addr-line>Paris</addr-line>, <country>France</country></aff>
    <aff id="aff4"><sup>4</sup><institution>Inserm</institution>, <addr-line>Paris</addr-line>, <country>France</country></aff>
    <aff id="aff5"><sup>5</sup><institution>CNRS</institution>, <addr-line>Paris</addr-line>, <country>France</country></aff>
    <aff id="aff6"><sup>6</sup><institution>AP-HP, Hôpital de la Pitié-Salpêtrière</institution>, <addr-line>Paris</addr-line>, <country>France</country></aff>
    <aff id="aff7"><sup>7</sup><institution>Inria, Service d'Expérimentation et de Développement</institution>, <addr-line>Paris</addr-line>, <country>France</country></aff>
    <aff id="aff8"><sup>8</sup><institution>Department of Neurology, Institute for Memory and Alzheimer's Disease, Pitié-Salpêtrière Hospital, AP-HP</institution>, <addr-line>Paris</addr-line>, <country>France</country></aff>
    <aff id="aff9"><sup>9</sup><institution>Sorbonne Université, CNRS, INSERM, Laboratoire d'Imagerie Biomédicale (LIB)</institution>, <addr-line>Paris</addr-line>, <country>France</country></aff>
    <aff id="aff10"><sup>10</sup><institution>AP-HP, Hôpital Pitié-Salpêtrière, Médecine Nucléaire</institution>, <addr-line>Paris</addr-line>, <country>France</country></aff>
    <aff id="aff11"><sup>11</sup><institution>Centre d'Acquisition et Traitement des Images</institution>, <addr-line>Paris</addr-line>, <country>France</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Antonio Fernández-Caballero, University of Castilla-La Mancha, Spain</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Hugo Alexandre Ferreira, University of Lisbon, Portugal; Nathan Churchill, St. Michael's Hospital, Canada</p>
      </fn>
      <corresp id="c001">*Correspondence: Olivier Colliot <email>olivier.colliot@sorbonne-universite.fr</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>13</day>
      <month>8</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>15</volume>
    <elocation-id>689675</elocation-id>
    <history>
      <date date-type="received">
        <day>01</day>
        <month>4</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>19</day>
        <month>7</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2021 Routier, Burgos, Díaz, Bacci, Bottani, El-Rifai, Fontanella, Gori, Guillon, Guyot, Hassanaly, Jacquemont, Lu, Marcoux, Moreau, Samper-González, Teichmann, Thibeau-Sutre, Vaillant, Wen, Wild, Habert, Durrleman and Colliot.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Routier, Burgos, Díaz, Bacci, Bottani, El-Rifai, Fontanella, Gori, Guillon, Guyot, Hassanaly, Jacquemont, Lu, Marcoux, Moreau, Samper-González, Teichmann, Thibeau-Sutre, Vaillant, Wen, Wild, Habert, Durrleman and Colliot</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>We present Clinica (<ext-link ext-link-type="uri" xlink:href="http://www.clinica.run">www.clinica.run</ext-link>), an open-source software platform designed to make clinical neuroscience studies easier and more reproducible. Clinica aims for researchers to (i) spend less time on data management and processing, (ii) perform reproducible evaluations of their methods, and (iii) easily share data and results within their institution and with external collaborators. The core of Clinica is a set of automatic pipelines for processing and analysis of multimodal neuroimaging data (currently, T1-weighted MRI, diffusion MRI, and PET data), as well as tools for statistics, machine learning, and deep learning. It relies on the brain imaging data structure (BIDS) for the organization of raw neuroimaging datasets and on established tools written by the community to build its pipelines. It also provides converters of public neuroimaging datasets to BIDS (currently ADNI, AIBL, OASIS, and NIFD). Processed data include image-valued scalar fields (e.g., tissue probability maps), meshes, surface-based scalar fields (e.g., cortical thickness maps), or scalar outputs (e.g., regional averages). These data follow the ClinicA Processed Structure (CAPS) format which shares the same philosophy as BIDS. Consistent organization of raw and processed neuroimaging files facilitates the execution of single pipelines and of sequences of pipelines, as well as the integration of processed data into statistics or machine learning frameworks. The target audience of Clinica is neuroscientists or clinicians conducting clinical neuroscience studies involving multimodal imaging, and researchers developing advanced machine learning algorithms applied to neuroimaging data.</p>
    </abstract>
    <kwd-group>
      <kwd>neuroimaging</kwd>
      <kwd>software</kwd>
      <kwd>pipeline</kwd>
      <kwd>data processing and analysis</kwd>
      <kwd>machine learning</kwd>
      <kwd>multimodal neuroimaging data</kwd>
    </kwd-group>
    <counts>
      <fig-count count="3"/>
      <table-count count="1"/>
      <equation-count count="0"/>
      <ref-count count="67"/>
      <page-count count="16"/>
      <word-count count="12125"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>Introduction</title>
    <p>Neuroimaging plays an important role in clinical neuroscience studies. While the meaning of clinical neuroscience studies may vary, we use it to refer to studies involving human participants (i.e., patients with neurological and psychiatric diseases, and control subjects) explored with multimodal data (neuroimaging, clinical, and cognitive evaluations, genetic data.) and most often involving longitudinal follow-up. Carrying out such studies involves many data analysis steps including image pre-processing, extraction of image-derived measurements, and statistical analysis, thus requiring a wide range of expertise. A similar situation is faced by researchers in machine learning for neuroimaging: various steps are needed to extract features that are then fed to advanced learning algorithms.</p>
    <p>The first issue met when working on clinical studies concerns the organization of neuroimaging datasets within or between institutions. The lack of a consistent structure makes arduous the sharing or reuse of data. This is true for in-house, but also for publicly available neuroimaging datasets. Another consequence of the lack of standard is the difficulty to apply automatic pipelines (e.g., extraction of neuroimaging features, statistical analysis, or machine learning) and to perform quality assurance. The second issue faced by researchers processing data from clinical studies is related to the high number of software packages, such as FreeSurfer<xref ref-type="fn" rid="fn0001"><sup>1</sup></xref> (Fischl, <xref rid="B18" ref-type="bibr">2012</xref>), FMRIB Software Library (FSL)<xref ref-type="fn" rid="fn0002"><sup>2</sup></xref> (Jenkinson et al., <xref rid="B37" ref-type="bibr">2012</xref>), or Statistical Parametric Mapping<xref ref-type="fn" rid="fn0003"><sup>3</sup></xref> (SPM) (Friston et al., <xref rid="B28" ref-type="bibr">2007</xref>), that exist in the community. Researchers have to understand the methodology behind each tool (e.g., segmentation, registration, etc.) and master them from a programming perspective before being able to combine them and develop image processing pipelines. Moreover, such “handicraft” approach makes it difficult to transmit tools and knowledge, and to merge and share results of several studies due to the heterogeneous organization of outputs. Finally, the difficulty to access or share both raw and processed neuroimaging data hinders the reproducibility of neuroimaging studies (Poline et al., <xref rid="B49" ref-type="bibr">2012</xref>).</p>
    <p>Major progress has been made in the last years to ease neuroimaging studies. First, difficulties related to the heterogeneity of image processing tools have been partly handled by the Nipype (Neuroimaging in Python—Pipelines and Interfaces) software package<xref ref-type="fn" rid="fn0004"><sup>4</sup></xref> (Gorgolewski et al., <xref rid="B30" ref-type="bibr">2011</xref>). Nipype is an open-source Python project that provides a uniform environment facilitating interaction between neuroimaging software tools or algorithms, regardless of their programming language, within a single workflow. Later, the issues related to the organization of the clinical and imaging data have been tackled by the Brain Imaging Data Structure (BIDS) (Gorgolewski et al., <xref rid="B32" ref-type="bibr">2016</xref>), a new standard from the community for the community. The BIDS standard is based on a file hierarchy rather than on a database management system, thus facilitating its deployment in any environment. Thanks to its clear and simple way to describe neuroimaging and behavioral data, the BIDS standard has been easily adopted by the neuroimaging community. Organizing a dataset following the BIDS hierarchy simplifies the execution of neuroimaging software tools, resulting in the development of user-friendly software. For instance, BIDS Apps (Gorgolewski et al., <xref rid="B31" ref-type="bibr">2017</xref>) provides a set of pipelines for the processing of neuroimaging data that follow a BIDS hierarchy. Currently, it mainly wraps neuroimaging software packages from the community into a Docker image and is used via a command line interface. Moreover, the Nilearn<xref ref-type="fn" rid="fn0005"><sup>5</sup></xref> (Abraham et al., <xref rid="B1" ref-type="bibr">2014</xref>) package facilitates the application of advanced machine learning approaches to neuroimaging data. To that purpose, it leverages the scikit-learn library<xref ref-type="fn" rid="fn0006"><sup>6</sup></xref> (Pedregosa et al., <xref rid="B47" ref-type="bibr">2011</xref>) and provides tools for handling and visualizing different types of neuroimaging data and building predictive models.</p>
    <p>Nevertheless, carrying out a multimodal neuroimaging study remains challenging due to the know-how necessary to grasp each modality and tool involved. While technical implementation has been facilitated by Nipype, the development of a pipeline still requires substantial programming skills and time to master both the neuroimaging software tools and Nipype. While the BIDS standard is being adopted by the scientific community, not all public neuroimaging datasets provide a BIDS version of their data. Besides, performing a single or multimodal neuroimaging study will also require methodological expertise. For instance, a classification study of healthy subjects and patients with a neurodegenerative disease using <sup>18</sup>F-fluorodeoxyglucose positron emission tomography (FDG PET) could involve notions of multimodal registration between FDG PET and T1-weighted magnetic resonance imaging (MRI), tissue segmentation of T1-weighted (T1w) MRI, PET partial volume correction (PETPVC), normalization into a standard space, and machine learning-based classification, as well as know-how of the tools used to perform these steps. Moreover, the image processing steps need to be chained from one to the other and the absence of data organization for processed neuroimages makes data analysis more complex. Finally, the neuroimaging features generated by the pipelines need to be correctly connected to statistical or machine learning frameworks.</p>
    <p>Clinica (<ext-link ext-link-type="uri" xlink:href="http://www.clinica.run">www.clinica.run</ext-link>) aims to make clinical research studies easier and pursues the community effort of reproducibility. The core of Clinica is a set of automatic pipelines for processing and analysis of multimodal neuroimaging data (currently, T1w MRI, diffusion MRI, and PET data), as well as tools for statistics, machine learning, and deep learning. Clinica relies on tools written by the scientific community and provides converters of public neuroimaging datasets to BIDS, processing pipelines, and organization for processed files, statistical analysis, and machine learning algorithms.</p>
    <p>The target audience is mainly of two types. First, neuroscientists or clinicians conducting clinical neuroscience studies involving multimodal imaging, typically not experts in image processing for all of the involved imaging modalities or in statistical analysis. They will benefit from a unified set of tools covering the complete set of steps involved in a study (from raw data to statistical analysis). Second, researchers developing advanced machine learning algorithms, typically not experts in brain image analysis. They will benefit from tools to convert public datasets into BIDS, fully automatic feature extraction methods, and baseline classification algorithms to which they could compare their results. Overall, we hope that Clinica will allow users to spend less time on data management and processing, to perform reproducible evaluations of their methods, and to easily share data and results within their institution and with external collaborators.</p>
  </sec>
  <sec id="s2">
    <title>Clinica Overview</title>
    <p>Clinica is an open-source software platform for reproducible clinical neuroimaging studies. It can take as inputs different neuroimaging modalities, currently anatomical MRI, diffusion MRI, and PET. Clinica provides processing pipelines that involve the combination of different software packages. It currently relies on FreeSurfer (Fischl, <xref rid="B18" ref-type="bibr">2012</xref>), FSL (Jenkinson et al., <xref rid="B37" ref-type="bibr">2012</xref>), SPM (Frackowiak et al., <xref rid="B27" ref-type="bibr">1997</xref>), Advanced Normalization Tools (ANTs)<xref ref-type="fn" rid="fn0007"><sup>7</sup></xref> (Avants et al., <xref rid="B8" ref-type="bibr">2014</xref>), MRtrix3<xref ref-type="fn" rid="fn0008"><sup>8</sup></xref> (Tournier et al., <xref rid="B60" ref-type="bibr">2012</xref>), and the PET Partial Volume Correction (PETPVC) toolbox<xref ref-type="fn" rid="fn0009"><sup>9</sup></xref> (Thomas et al., <xref rid="B57" ref-type="bibr">2016</xref>). The pipelines are written using Nipype (Gorgolewski et al., <xref rid="B30" ref-type="bibr">2011</xref>). Features extracted with the different pipelines can be used as inputs to statistical analysis, which relies on SPM (Frackowiak et al., <xref rid="B27" ref-type="bibr">1997</xref>) and SurfStat<xref ref-type="fn" rid="fn0010"><sup>10</sup></xref> (Worsley et al., <xref rid="B67" ref-type="bibr">2009</xref>), or machine learning analysis, which relies on scikit-learn (Pedregosa et al., <xref rid="B47" ref-type="bibr">2011</xref>) and PyTorch (Paszke et al., <xref rid="B46" ref-type="bibr">2019</xref>).</p>
    <p>Input neuroimaging data are expected to follow the BIDS data structure (Gorgolewski et al., <xref rid="B32" ref-type="bibr">2016</xref>), as explained in section Input Data With the BIDS Standard. Since this new standard has only recently been adopted by the community, not all public neuroimaging datasets are yet proposed in BIDS format. To facilitate the adoption of BIDS, Clinica curates several publicly available neuroimaging datasets and provides tools to convert them into the BIDS format. Processed data are organized following the ClinicA Processed Structure (CAPS) format, detailed in section Input/Output Data With the CAPS Structure, which shares the same philosophy as BIDS. Finally, a set of tools is provided to handle input and output data generated by Clinica, thus facilitating data management or connection to statistical or machine learning analysis.</p>
    <p>A schematic overview of Clinica can be found in <xref ref-type="fig" rid="F1">Figure 1</xref>. The list of pipelines currently available in Clinica is presented in <xref ref-type="fig" rid="F2">Figure 2</xref>. The main functionalities of Clinica are described in the paper, but for further details the reader can refer to the documentation available on the website<xref ref-type="fn" rid="fn0011"><sup>11</sup></xref> For each pipeline, the reader will find a description of its functionalities, a list of the tools on which it relies, an example showing how to run the pipeline, and a description of the outputs generated. The documentation of a pipeline can have several levels of reading, which are, respectively, targeting people new or familiar with neuroimaging and scientists working on pattern recognition and machine learning. User support is handled through a forum<xref ref-type="fn" rid="fn0012"><sup>12</sup></xref> as well as using the issue tracker on GitHub<xref ref-type="fn" rid="fn0013"><sup>13</sup></xref>.</p>
    <fig id="F1" orientation="portrait" position="float">
      <label>Figure 1</label>
      <caption>
        <p>Overview of Clinica's functionalities. Clinica provides processing pipelines for MRI and PET images that involve the combination of different software packages, and whose outputs can be used for statistical or machine learning analysis. Clinica expects data to follow the Brain Imaging Data Structure (BIDS) and provides tools to convert public neuroimaging datasets into the BIDS format. Output data are stored using the ClinicA Processed Structure (CAPS).</p>
      </caption>
      <graphic xlink:href="fninf-15-689675-g0001"/>
    </fig>
    <fig id="F2" orientation="portrait" position="float">
      <label>Figure 2</label>
      <caption>
        <p>List of the pipelines currently available in Clinica with their dependencies and outputs. Explanations regarding the atlases can be found in section List of Atlases Available in Clinica. GM, gray matter; CSF, cerebrospinal fluid; WM, white matter; FA, fractional anisotropy; MD, mean diffusivity; AD, axial diffusivity; RD, radial diffusivity, SVM, Support Vector Machine; ICBM, International Consortium for Brain Mapping.</p>
      </caption>
      <graphic xlink:href="fninf-15-689675-g0002"/>
    </fig>
  </sec>
  <sec id="s3">
    <title>Clinica Environment</title>
    <sec>
      <title>Software Architecture of Clinica</title>
      <p>The core of Clinica is written in Python and mainly relies on the Nipype framework (Gorgolewski et al., <xref rid="B30" ref-type="bibr">2011</xref>) to create pipelines. Python dependencies also include NumPy (van der Walt et al., <xref rid="B63" ref-type="bibr">2011</xref>), NiBabel (Brett et al., <xref rid="B10" ref-type="bibr">2019</xref>), Pandas (McKinney, <xref rid="B44" ref-type="bibr">2010</xref>), NIPY, SciPy (Jones et al., <xref rid="B39" ref-type="bibr">2001</xref>), scikit-learn (Pedregosa et al., <xref rid="B47" ref-type="bibr">2011</xref>), scikit-image (van der Walt et al., <xref rid="B63" ref-type="bibr">2011</xref>), nilearn (Abraham et al., <xref rid="B1" ref-type="bibr">2014</xref>), and PyTorch (Paszke et al., <xref rid="B46" ref-type="bibr">2019</xref>).</p>
      <p>Clinica is provided to the end user in the form of a Python package distributed through Python Package Index (PyPI) and can simply be installed by typing <monospace>pip install clinica</monospace> through the terminal, within a virtual environment.</p>
      <p>The main usage of Clinica is through the command line, which is facilitated by the support of autocompletion. The commands are gathered into four main categories. The first category of command line (<monospace>clinica run</monospace>) allows the user to run the different pipelines on neuroimaging datasets following a BIDS or CAPS hierarchy. The <monospace>clinica convert</monospace> category allows the conversion of publicly available neuroimaging datasets into a BIDS hierarchy. To help with data management, the <monospace>clinica iotools</monospace> category comprises a set of tools that allows the user to handle BIDS and CAPS datasets, including generating lists of subjects or merging all tabular data into a single TSV file for analysis with external statistical software packages. Finally, the last category (<monospace>clinica generate</monospace>) is dedicated to developers and currently generates the skeleton for a new pipeline. Examples of command line can be found in <xref rid="T1" ref-type="table">Table 1</xref>.</p>
      <table-wrap id="T1" orientation="portrait" position="float">
        <label>Table 1</label>
        <caption>
          <p>Categories of command line.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Category of command line</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Description</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Example usage</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <monospace>run</monospace>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">Run pipelines on BIDS or CAPS datasets. <break/> The full list of pipelines is available in section Image Processing Pipelines (clinica run).</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <monospace>clinica run t1-linear bids_directory caps_directory</monospace>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <monospace>convert</monospace>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">Convert public neuroimaging datasets into BIDS. <break/> The list of the public datasets can be found in section Conversion of Neuroimaging Datasets Into a BIDS Hierarchy (clinica convert).</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <monospace>clinica convert adni-to-bids dataset_directory clinical_data_directory bids_directory</monospace>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <monospace>iotools</monospace>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">Set of tools to handle BIDS and CAPS datasets. <break/> The list of the I/O tools can be found in section Data Handling Tools (clinica iotools).</td>
              <td valign="top" align="left" rowspan="1" colspan="1"><monospace>clinica iotools merge-tsv bids_directory</monospace> −−<monospace>caps_directory caps_directory my_population.tsv</monospace></td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <monospace>generate</monospace>
              </td>
              <td valign="top" align="left" rowspan="1" colspan="1">(For developers) Generate the skeleton source code for a new pipeline.</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <monospace>clinica generate template “Modality Feature Extracted” pipeline_folder</monospace>
              </td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec>
      <title>Input Data With the BIDS Standard</title>
      <p>When dealing with multiple datasets, it is difficult to automate the execution of neuroimaging pipelines since their organization may vary from each other or even within each individual dataset. If we consider neuroimaging datasets involving many participants, the lack of a clear structure will necessitate a large amount of time to curate these databases and make them easily usable. Besides, large databases are often associated with database management systems, which involve additional technical and financial resources to be maintained.</p>
      <p>Brain imaging data structure (Gorgolewski et al., <xref rid="B32" ref-type="bibr">2016</xref>) is a community standard enabling the storage of multiple neuroimaging modalities and behavioral data. The BIDS standard provides a unified structure and makes easier the development and distribution of code that uses neuroimaging datasets. Moreover, the BIDS format is based on a file hierarchy rather than on a database management system, thus avoiding the installation and maintenance of additional software. As a result, BIDS can be easily deployed in any environment. The specification is intentionally based on simple file formats and folder structures to reflect current laboratory practices, which makes it accessible to a wide range of scientists coming from different backgrounds. People unfamiliar with the BIDS format can see an example of a BIDS folder in <xref ref-type="fig" rid="F3">Figure 3</xref>.</p>
      <fig id="F3" orientation="portrait" position="float">
        <label>Figure 3</label>
        <caption>
          <p>Diagram illustrating the Clinica pipelines involved when performing a group comparison of FDG PET data projected on the cortical surface between patients with Alzheimer's disease and healthy controls from the ADNI database. First, clinical and neuroimaging data are downloaded from the ADNI website and data are converted into BIDS with the <monospace>adni-to-bids</monospace> tool from Clinica (1). Estimation of the cortical and white surface is then produced by the <monospace>t1-freesurfer</monospace> pipeline in a single command line (2). Afterwards, FDG PET data can be projected on the subject's cortical surface and normalized to the FsAverage template from FreeSurfer using the <monospace>pet-surface</monospace> pipeline (3). Finally, a TSV file with demographic information of the population studied is given to the <monospace>statistics-surface</monospace> pipeline to generate the results of the group comparison between patients with Alzheimer's disease and healthy controls (4).</p>
        </caption>
        <graphic xlink:href="fninf-15-689675-g0003"/>
      </fig>
      <p>For these reasons, we also adopted this standard and Clinica expects that the input data are BIDS-compliant for the execution of pipelines. Note that if a cross-sectional dataset (i.e., with no <monospace>session</monospace> folder) is provided, Clinica will interactively propose to convert the cross-sectional dataset into a longitudinal dataset with a unique session.</p>
    </sec>
    <sec>
      <title>Input/Output Data With the CAPS Structure</title>
      <p>Clinica has its own specifications for storing processed data, called CAPS (ClinicA Processed Structure). Of note, there exists an ongoing initiative called BIDS-derivatives that aims to provide a BIDS standard for processed data. However, we wrote the CAPS specification before the start of the BIDS-derivatives which explains why Clinica does not use the latter. Moreover, in their current state, several outputs needed by Clinica are not covered or well-adapted. In particular, the notion of group does not exist yet. Nonetheless, we made humble contributions to BIDS-derivatives and we aim to increasingly contribute. Ultimately, the two specifications will probably converge.</p>
      <p>Processed data include image-valued scalar fields (e.g., segmentation labels, tissue maps), meshes, mesh-valued scalar fields (e.g., cortical thickness maps), deformation fields, scalar outputs (e.g., volumes, regional averages), etc. Carrying out a neuroimaging study often involves the combination of different pipelines or the chaining of a pipeline to another one. This is the case for multimodal studies where processed outputs from a modality will be inputs for another pipeline, but it is also true for studies involving a single modality: features extracted from one or several pipelines are usually connected to statistical or machine learning frameworks. Finally, a structured organization for processed data will ease the access and sharing of data, thus improving the reproducibility of neuroimaging studies.</p>
      <p>The CAPS format defines a hierarchy for the Clinica processed data. The idea is to include in a single folder all the results generated by the different pipelines and to organize the data following the main patterns of the BIDS specification. CAPS folders are kept separate from the raw data. Indeed, when processing data, it is very common to have the raw dataset located on a separated storage or read-only storage, while ongoing processed data are located on a separate location or on a faster data storage.</p>
      <p>Another notion we often meet in neuroimaging studies is the notion of group, e.g., template creation from a set of subjects or statistical analysis of a population. To handle these situations, we simply add a level to the CAPS folder hierarchy. While pipeline outputs for individuals are stored in the <monospace>subjects</monospace> folder, results of group studies are stored in the groups folder together with the set of participants involved. For instance, an <monospace>AD</monospace> group label could be used when a template is created for a group of Alzheimer's disease patients. Any time this <monospace>AD</monospace> template is used, the <monospace>group_label</monospace> is provided to identify the pipeline outputs obtained for this group. The group <monospace>HCvsAD</monospace> could be used as <monospace>group_label</monospace> for a statistical group comparison between healthy controls (<monospace>HC</monospace>) and Alzheimer's disease patients. An illustration showing the chaining of pipelines and the creation of a group label can be found in section Usage Example.</p>
    </sec>
    <sec>
      <title>Clinica Command Line Arguments</title>
      <p>For each pipeline, the command line interface will require a set of arguments which can be compulsory or optional. The number of mandatory arguments is kept as small as possible, to ease its use. This set of arguments is gathered into four categories.</p>
      <p>First, the user will be asked to provide the Clinica mandatory arguments. These arguments are in general the BIDS directory, the CAPS directory, and/or the Group label, which were described in the Clinica environment section (sections Input Data With the BIDS Standard and Input/Output Data With the CAPS Structure).</p>
      <p>Then, several options are common to every pipeline: the Clinica standard options. For instance, we can run a pipeline on a subset of participants and sessions by specifying a TSV file. Moreover, it is possible to specify the number of cores of your machine used to run pipelines in parallel thanks to the Nipype engine (Gorgolewski et al., <xref rid="B30" ref-type="bibr">2011</xref>). A working directory can be specified for each pipeline. This directory gathers all the inputs and outputs of the different steps of the pipeline, which is very useful for debugging. It is especially useful in case a pipeline execution crashes to relaunch it with the exact same parameters, allowing the execution to continue from the last successfully executed node.</p>
      <p>Other parameters, specific to each pipeline, are gathered in the category “Optional parameters.” For instance, when applying a smoothing filter with a specific full width at half maximum (FWHM), this parameter can be specified.</p>
      <p>Finally, advanced parameters for users with good knowledge of the pipeline itself or of the software behind the pipeline will be gathered in the category “Advanced pipeline options.”</p>
    </sec>
    <sec>
      <title>List of Atlases Available in Clinica</title>
      <p>Depending on the modality studied and the type of analysis (voxel-based or surface-based), different atlases can be used to generate regional features. These atlases are briefly listed below, and the reader can refer to the documentation available on the website for further details.</p>
      <p>When performing volumetric processing of T1w MRI and PET images, as done in the <monospace>t1-volume∗</monospace> and <monospace>pet-volume</monospace> pipelines, atlases defined in MNI space containing regions covering the whole cortex and the main subcortical structures available are used (Samper-González et al., <xref rid="B53" ref-type="bibr">2018</xref>), currently AAL2 (Tzourio-Mazoyer et al., <xref rid="B62" ref-type="bibr">2002</xref>), AICHA (Joliot et al., <xref rid="B38" ref-type="bibr">2015</xref>), Hammers (Hammers et al., <xref rid="B35" ref-type="bibr">2003</xref>; Gousias et al., <xref rid="B33" ref-type="bibr">2008</xref>), LPBA40 (Shattuck et al., <xref rid="B55" ref-type="bibr">2008</xref>), and Neuromorphometrics<xref ref-type="fn" rid="fn0014"><sup>14</sup></xref>.</p>
      <p>When running the <monospace>dwi-dti</monospace> pipeline, the JHUDTI81 (Wakana et al., <xref rid="B64" ref-type="bibr">2007</xref>; Hua et al., <xref rid="B36" ref-type="bibr">2008</xref>) and JHUTracts[0|25|50] (Mori et al., <xref rid="B45" ref-type="bibr">2005</xref>) atlases<xref ref-type="fn" rid="fn0015"><sup>15</sup></xref>, included in FSL (Jenkinson et al., <xref rid="B37" ref-type="bibr">2012</xref>), defined in MNI space, are used. JHUDTI81 contains 48 white matter tract labels and JHUTracts[0|25|50] contains 20 white matter probabilistic tract labels with a 0, 25, and 50% threshold.</p>
      <p>Moreover, surface atlases are used when processing T1w MRI (respectively, PET images) with the <monospace>t1-freesurfer∗</monospace> (respectively, <monospace>pet-surface∗</monospace>) pipelines. Currently, Clinica provides the Desikan-Killiany (Desikan et al., <xref rid="B15" ref-type="bibr">2006</xref>) atlas, which divides the cerebral cortex into gyri and contains 34 regions per hemisphere, and the Destrieux (Destrieux et al., <xref rid="B16" ref-type="bibr">2010</xref>) atlas, which divides the cerebral cortex into gyri and sulci and contains 74 regions per hemisphere.</p>
    </sec>
    <sec>
      <title>Continuous Integration, Testing, and Package Distribution</title>
      <p>The source code of the Clinica's platform follows the most standard current practices for software development. The code is hosted in a publicly available platform<xref ref-type="fn" rid="fn0016"><sup>16</sup></xref> and it uses a version control system. A rigorous code review is performed for every contribution. The project has adopted a commonly used workflow for development and the code is tested at different stages under controlled conditions. In order to do this, several pipelines are executed by the continuous integration setup at different levels.</p>
      <p>For each contribution proposal:</p>
      <list list-type="simple">
        <list-item>
          <p>- The most recent commit pushed to the repository triggers a first iteration of the test suite. This first round validates the package environment, the installation process, and the correct instantiation of the main tools proposed by Clinica.</p>
        </list-item>
        <list-item>
          <p>- A draft of the documentation is written and published once the first iteration is over.</p>
        </list-item>
      </list>
      <p>Then, the contribution proposal is reviewed and validated by a peer. Subsequently:</p>
      <list list-type="simple">
        <list-item>
          <p>- Nightly tests ensure that new contributions do not introduce regressions in the results of the software. This second iteration of the test suite runs the full set of Clinica's functionalities and, due to the long processing time, they are executed once a day.</p>
        </list-item>
        <list-item>
          <p>- Package construction and deployment is automatized by adding a tag with the version number to the VCS. Versioned packages are published in the Python Package Index<xref ref-type="fn" rid="fn0017"><sup>17</sup></xref>.</p>
        </list-item>
      </list>
      <p>The management of the continuous integration system is handled by a master server that creates the link between the code repository and the different virtual machines that execute the continuous integration tasks. Virtual machines are configured with Linux and macOS operating systems.</p>
      <p>Outputs from the continuous integration process are publicly available and contributors can easily consult them. Due to legal restrictions, the datasets used during the continuous integration cannot be publicly distributed but detailed instructions on how to obtain them are provided on demand.</p>
    </sec>
  </sec>
  <sec id="s4">
    <title>Image Processing Pipelines (Clinica Run)</title>
    <p>This section gives a brief description of the different pipelines currently provided by Clinica as well as the types of features Clinica can produce. An illustrative summary of the pipelines can be found in <xref ref-type="fig" rid="F2">Figure 2</xref>.</p>
    <p>For technical details, we refer the reader to the online user documentation available on the Clinica website where a longer description of each pipeline is provided.</p>
    <sec>
      <title>Anatomical MRI</title>
      <sec>
        <title>Linear Processing of T1-Weighted MR Images (t1-linear)</title>
        <p>The <monospace>t1-linear</monospace> pipeline performs a set of steps in order to affinely align T1w MR images to the MNI space using the ANTs software package (Avants et al., <xref rid="B8" ref-type="bibr">2014</xref>, p. 201). These steps include: bias field correction using N4ITK (Tustison et al., <xref rid="B61" ref-type="bibr">2010</xref>); affine registration to the MNI152NLin2009cSym template (Fonov et al., <xref rid="B24" ref-type="bibr">2009</xref>, <xref rid="B25" ref-type="bibr">2011</xref>) in MNI space with the SyN algorithm (Avants et al., <xref rid="B7" ref-type="bibr">2008</xref>); cropping of the registered images to remove the background.</p>
        <p>This pipeline was designed to be a prerequisite for the deeplearning-prepare-data pipeline.</p>
      </sec>
      <sec>
        <title>Processing of T1-Weighted MR Images for Volume Analyses Using SPM (t1-volume∗)</title>
        <p>The <monospace>t1-volume∗</monospace> pipelines extract voxel-based anatomical features from T1w MR images. Specifically, they perform segmentation of tissues [gray matter (GM), white matter (WM), cerebrospinal fluid (CSF)], normalization to MNI space and computation of regional measures using atlases. Their main outputs are voxel-based maps of tissue density and average measures within cortical regions stored as TSV files.</p>
        <p>To that purpose, the pipeline wraps the Segmentation, Run Dartel and Normalize to MNI Space routines implemented in SPM (Ashburner, <xref rid="B5" ref-type="bibr">2012</xref>). First, the Unified Segmentation procedure (Ashburner and Friston, <xref rid="B6" ref-type="bibr">2005</xref>) is used to simultaneously perform tissue segmentation, bias field correction and spatial normalization of the input image. Next, a group template is created using DARTEL, an algorithm for diffeomorphic image registration (Ashburner, <xref rid="B4" ref-type="bibr">2007</xref>), from the subjects' tissue probability maps on the native space, usually GM, WM, and CSF, obtained at the previous step. The DARTEL to MNI method (Ashburner, <xref rid="B4" ref-type="bibr">2007</xref>) is then applied, providing a registration of the native space images into the MNI space.</p>
      </sec>
      <sec>
        <title>Processing of T1-Weighted MR Images for Surface Analyses Using FreeSurfer (t1-freesurfer; t1-freesurfer-longitudinal)</title>
        <p>The <monospace>t1-freesurfer</monospace> pipeline is mainly a wrapper of the <monospace>recon-all</monospace> tool of FreeSurfer (Fischl, <xref rid="B18" ref-type="bibr">2012</xref>). It performs segmentation of subcortical structures (Fischl et al., <xref rid="B20" ref-type="bibr">2002</xref>, <xref rid="B21" ref-type="bibr">2004a</xref>), extraction of cortical surfaces, cortical thickness estimation (Fischl and Dale, <xref rid="B19" ref-type="bibr">2000</xref>), spatial normalization onto the FreeSurfer surface template (FsAverage) (Fischl et al., <xref rid="B22" ref-type="bibr">1999</xref>), and parcellation of cortical regions using the Desikan and Destrieux atlases (Fischl et al., <xref rid="B23" ref-type="bibr">2004b</xref>). Its main outputs are surface-based cortical thickness features and regional statistics (e.g., regional volume, mean cortical thickness).</p>
        <p>The <monospace>t1-freesurfer-longitudinal</monospace> pipeline processes a series of images acquired at different time points for the same subject with the longitudinal FreeSurfer stream (Reuter et al., <xref rid="B51" ref-type="bibr">2012</xref>) to increase the accuracy of volume and thickness estimates. It does so in a single command consisting of two consecutive steps: (1) within-subject template creation (<monospace>recon-all -base</monospace> command) to produce an unbiased template image from the different time points using robust and inverse consistent registration (Reuter et al., <xref rid="B50" ref-type="bibr">2010</xref>); (2) longitudinal correction (<monospace>recon-all -long</monospace> command): segmentation, surface extraction, and computation of measurements at each time point.</p>
      </sec>
    </sec>
    <sec>
      <title>Diffusion MRI</title>
      <sec>
        <title>DWI Pre-processing (dwi-preprocessing∗)</title>
        <p>The <monospace>dwi-preprocessing∗</monospace> pipelines correct diffusion-weighted MRI (DWI) datasets for motion, eddy current, magnetic susceptibility, and bias field distortions, assuming that the data have been acquired using an echo-planar imaging (EPI) sequence.</p>
        <p>Due to the heterogeneity in acquisitions of fieldmaps and techniques to correct magnetic susceptibility distortions, several pipelines are proposed. Currently, Clinica can handle DWI datasets with fieldmap data containing a phase-difference map (case “phase-difference map and at least one magnitude image” in the BIDS specifications<xref ref-type="fn" rid="fn0018"><sup>18</sup></xref>) (<monospace>dwi-preprocessing-using-fmap</monospace>) and DWI datasets with no extra data (<monospace>dwi-preprocessing-using-t1</monospace>), which is the case of the public Alzheimer's Disease Neuroimaging Initiative (ADNI)<xref ref-type="fn" rid="fn0019"><sup>19</sup></xref> dataset for instance.</p>
        <p>In all cases, motion and eddy motion corrections are performed with the FSL software (Jenkinson et al., <xref rid="B37" ref-type="bibr">2012</xref>) using the <monospace>eddy</monospace> tool (Andersson and Sotiropoulos, <xref rid="B3" ref-type="bibr">2016</xref>) with the replace outliers (−−<monospace>repol</monospace>) option (Andersson et al., <xref rid="B2" ref-type="bibr">2016</xref>) while bias field is corrected with the ANTs N4 bias correction (Tustison et al., <xref rid="B61" ref-type="bibr">2010</xref>). Regarding susceptibility correction, the FSL prelude/fugue tools were used for the <monospace>dwi-preprocessing-using-fmap</monospace> pipeline and the ANTs SyN registration algorithm (Leow et al., <xref rid="B41" ref-type="bibr">2007</xref>; Avants et al., <xref rid="B7" ref-type="bibr">2008</xref>) for the <monospace>dwi-preprocessing-using-t1</monospace> pipeline. The outputs of the pipelines are the corrected DWI datasets and a brain mask of the b = 0 image.</p>
        <p>These pipelines are prerequisites for the <monospace>dwi-dti</monospace> and <monospace>dwi-connectome</monospace> pipelines.</p>
      </sec>
      <sec>
        <title>Computation of DTI, DTI-Scalar Maps, and ROI Analysis (dwi-dti)</title>
        <p>The <monospace>dwi-dti</monospace> pipeline extracts voxel-based features from diffusion tensor imaging (DTI), namely the fractional anisotropy (FA), mean diffusivity (MD), axial diffusivity (AD), and radial diffusivity (RD) using MRtrix3 (Tournier et al., <xref rid="B60" ref-type="bibr">2012</xref>). Then, the DTI-derived scalar maps (FA, MD, AD, RD) are normalized with ANTs (Avants et al., <xref rid="B7" ref-type="bibr">2008</xref>) onto an FA-atlas with labeled tracts. Its main outputs are voxel-based maps from DTI and average measures within tracts stored as TSV files.</p>
      </sec>
      <sec>
        <title>Computation of Fiber Orientation Distributions, Tractogram, and Structural Connectome (dwi-connectome)</title>
        <p>The <monospace>dwi-connectome</monospace> pipeline computes a weighted graph encoding anatomical connections between a set of brain regions from corrected DWI datasets. To that aim, it relies on the MRtrix3 (Tournier et al., <xref rid="B60" ref-type="bibr">2012</xref>) software to compute the constrained spherical deconvolution diffusion model (Tournier et al., <xref rid="B58" ref-type="bibr">2007</xref>), perform probabilistic tractography (Tournier et al., <xref rid="B59" ref-type="bibr">2010</xref>) and computes a connectome using the Desikan and Destrieux atlases from FreeSurfer (Fischl, <xref rid="B18" ref-type="bibr">2012</xref>). Its main outputs are the diffusion model, the whole-brain tractography, and the connectivity matrices.</p>
      </sec>
    </sec>
    <sec>
      <title>Positron Emission Tomography</title>
      <p>Currently, Clinica is supporting amyloid and FDG PET data but other tracers will be added in the future.</p>
      <sec>
        <title>Linear Processing of PET Images (pet-linear)</title>
        <p>The <monospace>pet-linear</monospace> pipeline performs a spatial normalization to the MNI space and intensity normalization of PET images. The first step of the pipeline is an affine registration to the MNI152NLin2009cSym template (Fonov et al., <xref rid="B24" ref-type="bibr">2009</xref>, <xref rid="B25" ref-type="bibr">2011</xref>) in MNI space with the SyN algorithm (Avants et al., <xref rid="B7" ref-type="bibr">2008</xref>) from the ANTs software package (Avants et al., <xref rid="B8" ref-type="bibr">2014</xref>). Then, the registered image intensity is normalized using the mean intensity in reference regions resulting in a standardized uptake value ratio (SUVR) map. The normalized imaged is finally cropped to remove the background.</p>
      </sec>
      <sec>
        <title>Processing of PET Images for Volume Analyses (pet-volume)</title>
        <p>The <monospace>pet-volume</monospace> pipeline extracts voxel-based features from PET data. Specifically, it performs intra-subject registration of the PET image into the space of the subject's T1w MR image using SPM (Ashburner, <xref rid="B5" ref-type="bibr">2012</xref>). Optionally, partial volume correction (PVC) can be applied thanks to the PETPVC toolbox (Thomas et al., <xref rid="B57" ref-type="bibr">2016</xref>). Then, inter-subject spatial normalization of the PET image into MNI space is performed based on the DARTEL deformation model of SPM (Ashburner, <xref rid="B4" ref-type="bibr">2007</xref>) and intensity normalization is done using the average PET uptake in a reference region resulting in a SUVR map. Its main outputs are voxel-based maps of SUVR and average measures within cortical regions.</p>
      </sec>
      <sec>
        <title>Processing of PET Images for Surface Analyses (pet-surface; pet-surface-longitudinal)</title>
        <p>The <monospace>pet-surface</monospace> pipeline extracts the PET signal and projects it onto the cortical surface using the approach described in Marcoux et al. (<xref rid="B42" ref-type="bibr">2018</xref>). More precisely, it performs co-registration of PET and T1w MRI, intensity normalization, PVC with the PETPVC toolbox (Thomas et al., <xref rid="B57" ref-type="bibr">2016</xref>), robust projection of the PET signal onto the subject's cortical surface, parcellation of the cortical regions using the Desikan and Destrieux atlases, and spatial normalization onto the FreeSurfer (Fischl, <xref rid="B18" ref-type="bibr">2012</xref>) surface template (FsAverage). Its main outputs are surface-based PET uptake and regional statistics (mean PET uptake) stored as TSV files.</p>
        <p>The <monospace>pet-surface-longitudinal</monospace> pipeline performs the same steps as the <monospace>pet-surface</monospace> pipeline except that the cortical and white surfaces are estimated with the longitudinal pipeline of FreeSurfer (Reuter et al., <xref rid="B51" ref-type="bibr">2012</xref>).</p>
      </sec>
    </sec>
    <sec>
      <title>Statistics</title>
      <sec>
        <title>Voxel-Based Mass-Univariate Analysis With SPM (statistics-volume)</title>
        <p>The <monospace>statistics-volume</monospace> pipeline performs statistical analysis on volume-based features using the general linear model (GLM) and random field theory (Worsley et al., <xref rid="B67" ref-type="bibr">2009</xref>). To that aim, the pipeline wraps the statistical analysis toolbox implemented in SPM. Volume-based measurements can be gray matter maps from the <monospace>t1-volume</monospace> pipeline or PET measurements from the <monospace>pet-volume</monospace> pipeline. Currently, statistical analysis includes only group comparison. The pipeline is divided into two subpipelines: <monospace>statistics-volume</monospace> outputs an SPM-based report with uncorrected T-statistic maps as well as the computed thresholds for family-wise error or false discovery rate correction at the voxel or the vertex level; statistics-volume-correction outputs corrected T-statistic maps with each of the aforementioned corrections.</p>
      </sec>
      <sec>
        <title>Surface-Based Mass-Univariate Analysis With SurfStat (statistics-surface)</title>
        <p>The <monospace>statistics-surface</monospace> pipeline performs statistical analysis on surface-based features using the GLM. To that aim, the pipeline relies on the Matlab toolbox SurfStat designed for statistical analyses of univariate and multivariate surface and volumetric data using the GLM (Worsley et al., <xref rid="B67" ref-type="bibr">2009</xref>). Surface-based measurements are analyzed on the FsAverage surface template from FreeSurfer. The pipeline can handle cortical thickness from the <monospace>t1-freesurfer</monospace> pipeline or PET measurements from the <monospace>pet-surface</monospace> pipeline. Currently, statistical analysis includes group comparison and correlation. The main outputs are <italic>p</italic>-value maps with different corrections for multiple comparisons (at the cluster or the vertex level using random field theory, or using the false discovery rate) and a JSON file summarizing the specified model.</p>
      </sec>
    </sec>
    <sec>
      <title>Machine Learning</title>
      <sec>
        <title>Classification Based on Machine Learning (No Command Line)</title>
        <p>Clinica provides a modular way to perform classification based on machine learning. To build their own classification pipeline, the user can combine three modules based on the scikit-learn library (Pedregosa et al., <xref rid="B47" ref-type="bibr">2011</xref>):</p>
        <list list-type="simple">
          <list-item>
            <p>- Input module. The user can select the inputs from the features available in the CAPS directory, such as gray matter maps obtained from T1w MR images, or SUVR maps obtained from FDG PET images.</p>
          </list-item>
          <list-item>
            <p>- Algorithm module. The user can choose between different classifiers, currently support vector machine (SVM), logistic regression and random forest.</p>
          </list-item>
          <list-item>
            <p>- Validation module. Several cross-validation (CV) methods are available: k-fold CV, repeated k-fold CV and repeated hold-out CV.</p>
          </list-item>
        </list>
        <p>Note that no command line interface is available for these specific tools. They need to be used within Python code, for instance within a notebook (an example of such notebook is provided at: <ext-link ext-link-type="uri" xlink:href="https://github.com/aramis-lab/AD-ML/blob/master/Generic_Version/Experiments.ipynb">https://github.com/aramis-lab/AD-ML/blob/master/Generic_Version/Experiments.ipynb</ext-link>).</p>
        <p>The outputs are: the estimated model parameters, the optimal value of the hyper-parameters (if any), a set of metrics regarding the classification performance (balanced accuracy, AUC, accuracy, sensitivity, specificity…) as well as the predicted class for each subject thereby allowing to calculate any additional performance metric.</p>
        <p>More details regarding the different modules and a description of the way they can be used to perform reproducible evaluation of classification methods in Alzheimer's disease can be found in Samper-González et al. (<xref rid="B53" ref-type="bibr">2018</xref>) and its dedicated repository.<xref ref-type="fn" rid="fn0020"><sup>20</sup></xref></p>
      </sec>
      <sec>
        <title>Spatially-Regularized Support Vector Machine (machinelearning-prepare-spatial-svm)</title>
        <p>The <monospace>machinelearning-prepare-spatial-svm</monospace> pipeline allows the preparation of T1w MRI and PET data to perform classification with an SVM with spatial and anatomical regularization (Cuingnet et al., <xref rid="B14" ref-type="bibr">2013</xref>). In this approach, the standard regularization of the SVM is replaced with a regularization that accounts for the spatial and anatomical structure of neuroimaging data. More specifically, it is regularized with respect to the tissue maps (GM, WM, CSF). As a result, the decision function learned by the algorithm will be more regular and anatomically interpretable. Because the SVM is a kernel method, the spatial/anatomical regularization is done as a pre-processing on the feature maps and the result can then be fed to a standard linear SVM. This pipeline outputs spatially regularized maps that can then be entered into a standard SVM, providing the same type of outputs as in section Classification Based on Machine Learning (No Command Line).</p>
      </sec>
    </sec>
    <sec>
      <title>Deep Learning</title>
      <sec>
        <title>Prepare Data for Deep Learning (deeplearning-prepare-data)</title>
        <p>The <monospace>deeplearning-prepare-data</monospace> pipeline allows the preparation of data for subsequent training or inference of deep learning models. To that aim, it uses the outputs from <monospace>t1-linear or pet-linear</monospace> pipelines. Specifically, 3D images, 3D patches, or 2D slices can be extracted and converted into PyTorch tensors (Paszke et al., <xref rid="B46" ref-type="bibr">2019</xref>). The outputs are thus the corresponding extracted images, patches or slices as.pt (PyTorch tensors) files.</p>
      </sec>
      <sec>
        <title>Training and Validation of Deep Learning Models (ClinicaDL)</title>
        <p>The training and validation of deep learning models based on Clinica outputs can be performed using a dedicated Python library: ClinicaDL<xref ref-type="fn" rid="fn0021"><sup>21</sup></xref> This extension of Clinica contains essential features for deep learning application to 3D medical images:</p>
        <list list-type="simple">
          <list-item>
            <p>- modules to split data avoiding data leakage, which is a major problem in the domain (Wen et al., <xref rid="B66" ref-type="bibr">2020</xref>);</p>
          </list-item>
          <list-item>
            <p>- a training method for autoencoders, CNN, and a multi-CNN framework which allows the use of other networks trained with ClinicaDL for transfer learning;</p>
          </list-item>
          <list-item>
            <p>- a testing function to evaluate the performance of classifiers on independent test sets;</p>
          </list-item>
          <list-item>
            <p>- saliency maps generation (Simonyan et al., <xref rid="B56" ref-type="bibr">2013</xref>) extensively used to interpret the outputs of deep learning networks;</p>
          </list-item>
          <list-item>
            <p>- basic network architecture search tools, such as random search utilities and methods to generate trivial synthetic datasets for architecture debugging.</p>
          </list-item>
        </list>
        <p>This library is documented in an independent documentation<xref ref-type="fn" rid="fn0022"><sup>22</sup></xref> An online tutorial<xref ref-type="fn" rid="fn0023"><sup>23</sup></xref> allows beginners to better understand these functionalities by testing them locally, or on Google Colab if they do not have access to sufficient computational resources. Each function of ClinicaDL has specific outputs (training functions output models, classification functions output performance metrics, and classification results…). We refer the reader to this specific documentation for an exhaustive description.</p>
      </sec>
    </sec>
  </sec>
  <sec id="s5">
    <title>Clinica Utilities</title>
    <sec>
      <title>Conversion of Neuroimaging Datasets Into a BIDS Hierarchy (clinica convert)</title>
      <p>Clinica provides tools to curate several publicly available neuroimaging datasets and automatically convert them into the BIDS standardized data structure. This section explains what the user needs to download prior to running the converter and the rationale behind the selection of data when multiple acquisitions or pre-processing steps are available. For all converters, the user only needs to download the dataset. All subsequent conversion steps are performed automatically (no user intervention is required) and use parallelization for faster processing. For further details, the reader can refer to Samper-González et al. (<xref rid="B53" ref-type="bibr">2018</xref>). Clinica currently provides converters for the following studies: ADNI, AIBL, NIFD, and OASIS. We plan to continuously add new converters for other studies. In addition, Clinica can of course be used with any other dataset, provided that it has previously been converted to BIDS by the user.</p>
      <sec>
        <title>Conversion of the ADNI Dataset to BIDS (adni-to-bids)</title>
        <p>The ADNI to BIDS converter requires the user to have downloaded all the ADNI study data (tabular data in CSV format) and the imaging data of interest. Note that the downloaded files must be kept exactly as they were downloaded. The imaging modalities currently being converted to BIDS include T1w MRI, FLAIR, DWI, fMRI, FDG PET, PiB PET, Florbetapir (AV45) PET, and Flortaucipir (AV1451) PET. Clinical data are also converted to BIDS. They include data that do not change over time, such as the subject's sex, education level, or diagnosis at baseline, as well as session-dependent data, such as the clinical scores. The clinical data being converted are defined in a spreadsheet that is available with the code of the converter. The user can easily modify this file if they want to convert additional clinical data.</p>
      </sec>
      <sec>
        <title>Conversion of the AIBL Dataset to BIDS (aibl-to-bids)</title>
        <p>As for ADNI, the AIBL to BIDS converter requires the user to have downloaded the AIBL non-imaging data (tabular data in CSV format) and the imaging data of interest. For each AIBL participant, the T1w MRI and the Florbetapir, PiB, and Flutemetamol PET images are converted. As for the ADNI converter, clinical data converted to BIDS are defined in a spreadsheet available with the code of the converter, which the user can modify.</p>
      </sec>
      <sec>
        <title>Conversion of the NIFD Dataset to BIDS (nifd-to-bids)</title>
        <p>As for ADNI, the NIFD to BIDS converter requires the user to have downloaded the NIFD imaging data alongside the corresponding clinical data in CSV format. For each NIFD participant, the T1w MRI, FLAIR, PiB PET, and FDG PET images are converted. The clinical data conversion is as described in the previous sections.</p>
      </sec>
      <sec>
        <title>Conversion of the OASIS Dataset to BIDS (oasis-to-bids)</title>
        <p>As for ADNI, the OASIS to BIDS converter requires the user to have downloaded the OASIS-1 imaging data and the associated CSV file. For each subject, among the multiple T1w MR images available, we select the average of the motion-corrected co-registered individual images resampled to 1 mm isotropic voxels. The clinical data are converted as described in the previous sections.</p>
      </sec>
      <sec>
        <title>Syntax to Run the Converters</title>
        <p>After having downloaded the clinical and imaging data of one of these studies, the conversion of a dataset into BIDS is performed using the following syntax:</p>
        <preformat>clinica convert &lt;dataset&gt;-to-bids dataset_directory clinical_data_directory bids_directory</preformat>
        <p>where &lt; <monospace>dataset&gt;-to-bids</monospace> can be <monospace>adni-to-bids, aibl-to-bids, nifd-to-bids or oasis-to-bids</monospace>.</p>
      </sec>
    </sec>
    <sec>
      <title>Data Handling Tools (clinica iotools)</title>
      <p>We also propose a set of tools that allows the user to handle BIDS and CAPS datasets. For the moment, there are five different commands:</p>
      <list list-type="simple">
        <list-item>
          <p>- <monospace>center-nifti:</monospace> This command takes a BIDS directory as input and outputs the same BIDS with centered NifTI: the NifTI headers are modified to set the origin of the coordinate system at the center of the image. This correction is crucial for SPM which is especially sensitive to NifTI files whose origin does not correspond to the center of the image.</p>
        </list-item>
        <list-item>
          <p>- <monospace>check-missing-modalities</monospace>: This command checks missing modalities in a BIDS directory.</p>
        </list-item>
        <list-item>
          <p>- <monospace>check-missing-processing</monospace>: This command checks the outputs in a CAPS directory.</p>
        </list-item>
        <list-item>
          <p>- <monospace>create-subjects-visits</monospace>: This command generates a list of subjects with their sessions based on a BIDS directory and stores the outputs in a TSV file.</p>
        </list-item>
        <list-item>
          <p>- <monospace>merge-tsv</monospace>: This command merges all the tabular data including the clinical data of a BIDS directory and the regional features from a CAPS directory (e.g., mean GM density in AAL2 atlas) into a single TSV file. This file can then be easily plugged into machine learning tools via Clinica or other statistical/machine learning software packages.</p>
        </list-item>
      </list>
    </sec>
  </sec>
  <sec id="s6">
    <title>Usage Example</title>
    <p>In this section, we propose to show how Clinica can be used to perform a group comparison of FDG PET data projected on the cortical surface between patients with Alzheimer's disease and HCs from the ADNI database. An illustrative summary of this example can be found in <xref ref-type="fig" rid="F3">Figure 3</xref>.</p>
    <p>To download the ADNI dataset, it is necessary to register to the LONI Image &amp; Data Archive<xref ref-type="fn" rid="fn0024"><sup>24</sup></xref>, a secure research data repository, and request access to the ADNI dataset through the submission of an online application form. Both the imaging and clinical data need to be downloaded, each to a folder that we will call <monospace>imaging_data_dir</monospace> and <monospace>clinical_data_dir</monospace>, respectively. The following command can be used to convert the T1 and FDG PET data of the ADNI dataset into BIDS:</p>
    <p>
      <monospace>clinica convert adni-to-bids imaging_data_dir clinical_data_dir ADNI_BIDS –modalities T1 PET_FDG</monospace>
    </p>
    <p>where the <monospace>ADNI_BIDS</monospace> folder contains the conversion of ADNI into BIDS. We can now start processing the data. First, we need to extract the cortical surfaces from each anatomical image. To do so, we simply need to type on the terminal the following command:</p>
    <p>
      <monospace>clinica run t1-freesurfer ADNI_BIDS ADNI_CAPS</monospace>
    </p>
    <p>where the output data will be stored in the <monospace>ADNI_CAPS</monospace> folder. After visual inspection of the generated outputs, the FDG PET data can be projected onto the cortex. The command line will be:</p>
    <p>
      <monospace>clinica run pet-surface ADNI_BIDS ADNI_CAPS fdg pons pvc_psf.tsv</monospace>
    </p>
    <p>where fdg is the label given to the PET acquisition, pons is the reference region for the SUVR map computation and <monospace>pvc_psf.tsv</monospace> is the TSV file containing PSF information for each PET image. Finally, we can perform group comparison of cortical FDG PET data after having checked the outputs. The demographic information of the population studied will be stored in a TSV file, looking as follows:</p>
    <preformat>
participant_id session_id group age sex
sub-ADNI094S2201 ses-M00 HC 63.7 Female
sub-ADNI098S4018 ses-M00 HC 76.1 Male
sub-ADNI023S4020 ses-M00 HC 66.5 Male
sub-ADNI031S4021 ses-M00 HC 66.5 Male
sub-ADNI094S1397 ses-M00 AD 55.1 Female
sub-ADNI094S1402 ses-M00 AD 69.3 Male
sub-ADNI128S1409 ses-M00 AD 65.9 Male
sub-ADNI128S1430 ses-M00 AD 83.4 Female
…
</preformat>
    <p>where participants with Alzheimer's disease (respectively, HCs) have the <monospace>AD</monospace> label (respectively, <monospace>HC</monospace> label) in the group column. We will call this file <monospace>ADvsHC_participants.tsv.</monospace> Using age and sex as covariates, the command line will be:</p>
    <p>
      <monospace>clinica run statistics-surface ADNI_CAPS ADvsHC pet-surface\</monospace>
    </p>
    <p>
      <monospace>group_comparison ADvsHC_participants.tsv group –covariates “age + sex”</monospace>
    </p>
    <p>The results of the statistical analysis will be stored in the <monospace>ADNI_CAPS/groups/group-ADvsHC</monospace> folder.</p>
  </sec>
  <sec sec-type="discussion" id="s7">
    <title>Discussion</title>
    <p>We proposed a software platform that aims at making clinical neuroscience easier and more reproducible. Clinica automates the processing of pipelines involving several neuroimaging modalities (currently, anatomical MRI, diffusion MRI, and PET) as well as statistics, machine learning, and deep learning tools. Additionally, Clinica provides tools to convert public neuroimaging datasets focused on dementia (ADNI, AIBL, OASIS, and NIFD) into the BIDS standard, and tools to handle raw (BIDS) and processed datasets. The use of the BIDS standard as the only prerequisite on the data and the unified command line interface across the pipelines ease the processing automation. The image analysis automation is also improved by the use of the CAPS hierarchy, which facilitates the chaining of pipelines. The main target audience of Clinica is neuroscientists or clinicians conducting clinical neuroscience studies involving multimodal imaging, and researchers developing advanced machine or deep learning algorithms.</p>
    <p>The last three decades witnessed the development of many software packages for the processing of neuroimaging data. A first category of packages comprises those implementing innovative image processing methodologies (e.g., tissue segmentation, registration). Many tools fall into this category, for instance SPM (Friston et al., <xref rid="B28" ref-type="bibr">2007</xref>), AFNI (Cox, <xref rid="B13" ref-type="bibr">1996</xref>), FreeSurfer (Fischl, <xref rid="B18" ref-type="bibr">2012</xref>), FSL (Jenkinson et al., <xref rid="B37" ref-type="bibr">2012</xref>), PETPVC (Thomas et al., <xref rid="B57" ref-type="bibr">2016</xref>), Camino (Cook et al., <xref rid="B12" ref-type="bibr">2005</xref>), Dipy (Garyfallidis et al., <xref rid="B29" ref-type="bibr">2014</xref>), DTI-TK<xref ref-type="fn" rid="fn0025"><sup>25</sup></xref>, MRtrix (Tournier et al., <xref rid="B60" ref-type="bibr">2012</xref>), or ANTs (Avants et al., <xref rid="B8" ref-type="bibr">2014</xref>). Some of these tools cover a variety of modalities while others focus on a specific one (diffusion MRI for Camino, Dipy, DTI-TK, and MRtrix; fMRI for AFNI; PET for PETPVC). However, performing a multimodal study can be difficult because one needs to combine tools from different packages. This results in complex pipelines which can be difficult to build, maintain, and distribute. Even when analyzing a single modality, one often wants to combine tools from different packages, thus facing similar difficulties. Combination of tools is made even more difficult by the fact that the input and output data are organized differently by each tool.</p>
    <p>Efforts of the community have alleviated several of these difficulties. The NeuroDebian community<xref ref-type="fn" rid="fn0026"><sup>26</sup></xref> (Halchenko and Hanke, <xref rid="B34" ref-type="bibr">2012</xref>) aims to provide and ease the installation of a large collection of software packages for the Debian distribution. The Nipype (Gorgolewski et al., <xref rid="B30" ref-type="bibr">2011</xref>) system facilitates the building of complex pipelines through the wrapping of tools in Python. Brain imaging data structure (Gorgolewski et al., <xref rid="B31" ref-type="bibr">2017</xref>) provides a standard for organizing data. BIDS-Apps provides versions of software packages using BIDS for data organization. More generally, the NIPY community aims to provide a comprehensive set of tools for the analysis of neuroimaging data in a single language, Python. However, many useful tools and packages remain outside of the NIPY scope, being written in different languages. As mentioned above, Nipype allows wrapping these heterogeneous tools. It is a powerful and particularly useful tool for that aim. However, the building of pipelines remains left to the user. This requires substantial development efforts. Clinicians/neuroscientists often do not have the necessary programming expertise, while researchers in machine learning often do not have the necessary neuroimaging expertise. Therefore, Nipype and Clinica do not have the same objectives. Nipype provides a powerful way to write pipelines. As such, it is particularly flexible but requires some programming expertise. Clinica, on the other hand, offers a set of predefined pipelines: it is thus easier to use but less flexible.</p>
    <p>There are also software packages that integrate different tools within a single environment. This is for example the case of BCBtoolkit (Foulon et al., <xref rid="B26" ref-type="bibr">2018</xref>), BrainVISA (Cointepas et al., <xref rid="B11" ref-type="bibr">2001</xref>), BrainSuite<xref ref-type="fn" rid="fn0027"><sup>27</sup></xref>, BrainLife<xref ref-type="fn" rid="fn0028"><sup>28</sup></xref> (Avesani et al., <xref rid="B9" ref-type="bibr">2019</xref>), Flywheel<xref ref-type="fn" rid="fn0029"><sup>29</sup></xref>, fMRIPrep (Esteban et al., <xref rid="B17" ref-type="bibr">2019</xref>), MIBCA<xref ref-type="fn" rid="fn0030"><sup>30</sup></xref> (Ribeiro et al., <xref rid="B52" ref-type="bibr">2015</xref>), or Pypes (Savio et al., <xref rid="B54" ref-type="bibr">2017</xref>). Clinica falls within this category. It shares some characteristics with these tools but also has important differences. The BCBtoolkit wraps neuroimaging software packages from the community but also highlights new methodological developments to evaluate brain disconnections. BCBoolkit does not use any pipelining system but instead wraps bash scripts that are then made available through a GUI. The BrainVISA platform, even though it also wraps some existing tools, mainly provides innovative tools for the analysis of human or animal brain imaging data. Moreover, it includes its own pipelining system while Clinica relies on the community effort Nipype. Brainlife is a comprehensive and user-friendly cloud-based platform for neuroscience analysis and provides an interface for composable integration of different neuro-imaging tools. Unlike Clinica however, Brainlife is not available as a Python package. Additionally, both the upstream processing provided by Clinica (curation and transformation of common research dataset into BIDS) and downstream (preparation for ML pipelines) are not the focus of Brainlife. BrainSuite does not wrap existing tools but provides a set of innovative tools for the analysis of neuroimaging data. It can be executed using a GUI, a command line, a Nipype interface, or as a BIDS App. However, BrainSuite is limited to the processing of MRI images only. Flywheel is a cloud-based platform to capture, curate, and process medical data. In the spirit of Brainlife, it allows the composition of different components through a web-based interface. However, unlike Clinica, Flywheel is a proprietary software and does not share its source code with the community. fMRIPrep combines software components using Nipype (Gorgolewski et al., <xref rid="B30" ref-type="bibr">2011</xref>) to provide a robust pipeline for pre-processing of fMRI data. It assumes input data to follow the BIDS standard (Gorgolewski et al., <xref rid="B32" ref-type="bibr">2016</xref>) and outputs are organized following the ongoing BIDS-derivatives initiative. As the name implies, fMRIPrep focuses on fMRI data. MIBCA is a toolbox focused on brain connectivity analysis using multimodal imaging. It is developed in MATLAB and provides pipelines for popular neuroimaging software. Pypes is probably the closest in spirit to Clinica: it also focuses on the integration of existing tools into a set of reusable pipelines built with Nipype. The user needs to specify a configuration file to describe the input data even for BIDS datasets. The output data will then follow the same structure as the input data and can be chained to other pipelines from Pypes. Note that the ability to chain pipelines exists for a limited number of pipelines in the BIDS-App version of BrainSuite and is likely to be more present in BIDS Apps with the advent of BIDS-derivatives. Although Clinica does not provide a GUI, efforts were made to simplify as much as possible its command line interface, which is feasible thanks to the autocompletion, the structured organization of data, and the documentation which was designed in order to be readable by a newcomer.</p>
    <p>Machine learning is now widely used in the neuroimaging community, for cognitive neuroscience or computer-aided diagnosis applications. However, applying such approaches to neuroimaging data can be difficult for newcomers. Conversely, researchers in machine learning are often interested in applying and validating their approaches to clinical neuroimaging problems (e.g., diagnosis, prognosis). However, they often lack the necessary knowledge for preprocessing neuroimaging data and extracting features. Nilearn (Abraham et al., <xref rid="B1" ref-type="bibr">2014</xref>) has allowed major progress in that direction by providing in a single environment tools for preprocessing, data manipulation, feature extraction, and machine learning wrapping the scikit-learn library (Pedregosa et al., <xref rid="B47" ref-type="bibr">2011</xref>). However, Nilearn currently mostly targets cognitive neuroimaging and mainly deals with functional neuroimaging. On the other hand, Clinica is dedicated to clinical neuroimaging studies, such as biomarker design and clinical decision support systems. As a result, Clinica does not aim to deal with task-based fMRI and is currently mostly focused on the analysis of T1w MRI, diffusion MRI, and PET data. Deep learning methods are also increasingly applied to neuroimaging. Even though such methods usually do not rely on pre-extracted features, they will still require some preprocessing and data conversion tools in order to use neuroimaging data in frameworks such as PyTorch. Clinica provides such tools.</p>
    <p>Reproducibility has been highlighted as a major challenge in many scientific fields including neuroimaging (Poldrack et al., <xref rid="B48" ref-type="bibr">2017</xref>). This problem has also been highlighted in machine learning for healthcare in general (McDermott et al., <xref rid="B43" ref-type="bibr">2019</xref>) and for brain diseases in particular (Samper-González et al., <xref rid="B53" ref-type="bibr">2018</xref>; Wen et al., <xref rid="B65" ref-type="bibr">2021</xref>). Clinica aims to make reproducible research easier to perform. To that purpose, it combines: (1) use of a community standard for inputs; (2) the definition of a standardized organization for outputs; (3) standardized ways to extract features; (4) extensive software testing. As previously mentioned, it extensively relies on community achievements such as the BIDS standard and Nipype.</p>
    <p>As mentioned above, the main target audience of Clinica is neuroscientists or clinicians and researchers developing machine algorithms applied to neuroimaging. Clinica can also be useful to neuroimaging researchers even though they often have their own customized sets of pipelines that are specifically tailored to their needs. Nevertheless, it can still be useful to them by providing a comprehensive set of pipelines for various imaging modalities. This will for instance be beneficial if they need to perform a study for a specific imaging modality for which they do not already have their own pipelines. In addition, they will benefit from a standardized file organization and easy connection with machine learning or deep learning tools. As for the clinicians, we acknowledge that the use of a command line interface as well as the need to install third-party software may make it difficult for them to use Clinica. Our clinical collaborators were nevertheless able to successfully use Clinica but this is clearly a limitation. In the future, we aim to implement a visual dashboard that would simultaneously allow executing the pipelines and performing quality control (QC) as well as to ease or avoid the installation of third-party software.</p>
    <p>Clinica pipelines rely on third-party dependencies whose development and versioning are outside of our control. To avoid potential incompatibilities, each pipeline declares its (versioned) dependencies in the corresponding pipeline metadata, which are checked at runtime by Clinica. Nevertheless, the installation of third-party software may be difficult for the user and we acknowledge that this is a limitation. In order to limit as much as possible these difficulties, the Clinica documentation provides detailed instructions regarding the available download channels and installation steps required. Moreover, there is an on-going effort to make our third-party dependencies available through Anaconda, which will enable simpler deployments of Clinica in the near future. Nevertheless, some of the dependencies (e.g., FSL, FreeSurfer) cannot be distributed in that manner due to license issues. In the future, we plan to distribute a Docker version of Clinica as well as to make Clinica available as a cloud service to make its use easier for the users.</p>
    <p>The set of <italic>post-hoc</italic> analytic tools (statistics and machine learning) cannot cover all the potential techniques that can be applied to the extracted data. We have included what we believe are the most commonly used approaches so that they can be performed in a user-friendly way. Nevertheless, users may need additional analytical flexibility, for instance for applying other statistical models (e.g., mixed-effect models, survival analysis…) or machine learning tools. The standardized organization of the outputs as well as the presence of tools for generating a single tsv file from a hierarchy of outputs should facilitate the subsequent use of other statistical or machine learning packages.</p>
    <p>Clinica currently has the following additional limitations. First, it currently lacks pipelines for several important functional neuroimaging modalities (functional MRI, arterial spin labeling). Second, we will improve the enforcement of reproducibility by adding traceability features. Moreover, QC of processed data is currently done using standard image viewers which is clearly suboptimal. We plan to add more advanced QC of outputs in the spirit for instance of MindControl (Keshavan et al., <xref rid="B40" ref-type="bibr">2018</xref>). This is important in order to ease the QC of large datasets and to enforce the good practice of systematic QC among the users. Implementing an integrated QC system is among our priorities for the development of Clinica. The aim is to provide a visual dashboard that would allow the user to: (1) easily control which pipelines have been executed and whether they exited without error; (2) systematically review snapshots of the major outputs of each pipeline (together with typical examples of how a correct output should look like); (3) flag incorrect outputs so that they can be excluded from further statistical analysis. Another limitation is that, in order to use previously built templates, they currently need to be manually copied into the CAPS directory which is clearly suboptimal. This will be changed in the near future. Finally, new longitudinal analysis pipelines (beyond those already present for FreeSurfer and PET surface processing) will be developed.</p>
    <p>In conclusion, Clinica is an open-source software platform that provides a comprehensive set of processing pipelines for different neuroimaging modalities. It builds upon existing standards and software tools developed by the community. It can make clinical neuroimaging studies easier to perform and more reproducible.</p>
  </sec>
  <sec sec-type="data-availability" id="s8">
    <title>Data Availability Statement</title>
    <p>The original contributions presented in the study are included in the article/supplementary material, further inquiries can be directed to the corresponding author.</p>
  </sec>
  <sec id="s9">
    <title>Author Contributions</title>
    <p>All authors contributed to the study concepts/study design, literature search, manuscript drafting or manuscript revision for important intellectual content, approval of the final version of the submitted manuscript, and manuscript editing.</p>
  </sec>
  <sec sec-type="COI-statement" id="conf1">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s10">
    <title>Publisher's Note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn id="fn0001">
      <p>
        <sup>1</sup>
        <ext-link ext-link-type="uri" xlink:href="http://surfer.nmr.mgh.harvard.edu/">http://surfer.nmr.mgh.harvard.edu/</ext-link>
      </p>
    </fn>
    <fn id="fn0002">
      <p>
        <sup>2</sup>
        <ext-link ext-link-type="uri" xlink:href="https://fsl.fmrib.ox.ac.uk/">https://fsl.fmrib.ox.ac.uk/</ext-link>
      </p>
    </fn>
    <fn id="fn0003">
      <p>
        <sup>3</sup>
        <ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm/">http://www.fil.ion.ucl.ac.uk/spm/</ext-link>
      </p>
    </fn>
    <fn id="fn0004">
      <p>
        <sup>4</sup>
        <ext-link ext-link-type="uri" xlink:href="https://nipype.readthedocs.io">https://nipype.readthedocs.io</ext-link>
      </p>
    </fn>
    <fn id="fn0005">
      <p>
        <sup>5</sup>
        <ext-link ext-link-type="uri" xlink:href="https://nilearn.github.io">https://nilearn.github.io</ext-link>
      </p>
    </fn>
    <fn id="fn0006">
      <p>
        <sup>6</sup>
        <ext-link ext-link-type="uri" xlink:href="https://scikit-learn.org/">https://scikit-learn.org/</ext-link>
      </p>
    </fn>
    <fn id="fn0007">
      <p>
        <sup>7</sup>
        <ext-link ext-link-type="uri" xlink:href="https://stnava.github.io/ANTs/">https://stnava.github.io/ANTs/</ext-link>
      </p>
    </fn>
    <fn id="fn0008">
      <p>
        <sup>8</sup>
        <ext-link ext-link-type="uri" xlink:href="http://mrtrix.org">http://mrtrix.org</ext-link>
      </p>
    </fn>
    <fn id="fn0009">
      <p>
        <sup>9</sup>
        <ext-link ext-link-type="uri" xlink:href="https://github.com/UCL/PETPVC">https://github.com/UCL/PETPVC</ext-link>
      </p>
    </fn>
    <fn id="fn0010">
      <p>
        <sup>10</sup>
        <ext-link ext-link-type="uri" xlink:href="http://www.math.mcgill.ca/keith/surfstat/">http://www.math.mcgill.ca/keith/surfstat/</ext-link>
      </p>
    </fn>
    <fn id="fn0011">
      <p>
        <sup>11</sup>
        <ext-link ext-link-type="uri" xlink:href="http://www.clinica.run/doc">http://www.clinica.run/doc</ext-link>
      </p>
    </fn>
    <fn id="fn0012">
      <p>
        <sup>12</sup>
        <ext-link ext-link-type="uri" xlink:href="https://groups.google.com/g/clinica-user">https://groups.google.com/g/clinica-user</ext-link>
      </p>
    </fn>
    <fn id="fn0013">
      <p>
        <sup>13</sup>
        <ext-link ext-link-type="uri" xlink:href="https://github.com/aramis-lab/clinica/issues">https://github.com/aramis-lab/clinica/issues</ext-link>
      </p>
    </fn>
    <fn id="fn0014">
      <p>
        <sup>14</sup>
        <ext-link ext-link-type="uri" xlink:href="http://www.neuromorphometrics.com">www.neuromorphometrics.com</ext-link>
      </p>
    </fn>
    <fn id="fn0015">
      <p>
        <sup>15</sup>
        <ext-link ext-link-type="uri" xlink:href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Atlases">https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Atlases</ext-link>
      </p>
    </fn>
    <fn id="fn0016">
      <p>
        <sup>16</sup>
        <ext-link ext-link-type="uri" xlink:href="https://github.com/aramis-lab/clinica/">https://github.com/aramis-lab/clinica/</ext-link>
      </p>
    </fn>
    <fn id="fn0017">
      <p>
        <sup>17</sup>
        <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/clinica/">https://pypi.org/project/clinica/</ext-link>
      </p>
    </fn>
    <fn id="fn0018">
      <p>
        <sup>18</sup>
        <ext-link ext-link-type="uri" xlink:href="http://bids.neuroimaging.io/">http://bids.neuroimaging.io/</ext-link>
      </p>
    </fn>
    <fn id="fn0019">
      <p>
        <sup>19</sup>
        <ext-link ext-link-type="uri" xlink:href="http://adni.loni.usc.edu/">http://adni.loni.usc.edu/</ext-link>
      </p>
    </fn>
    <fn id="fn0020">
      <p>
        <sup>20</sup>
        <ext-link ext-link-type="uri" xlink:href="https://github.com/aramis-lab/AD-ML">https://github.com/aramis-lab/AD-ML</ext-link>
      </p>
    </fn>
    <fn id="fn0021">
      <p>
        <sup>21</sup>
        <ext-link ext-link-type="uri" xlink:href="https://github.com/aramis-lab/clinicadl">https://github.com/aramis-lab/clinicadl</ext-link>
      </p>
    </fn>
    <fn id="fn0022">
      <p>
        <sup>22</sup>
        <ext-link ext-link-type="uri" xlink:href="https://clinicadl.readthedocs.io/en/latest/">https://clinicadl.readthedocs.io/en/latest/</ext-link>
      </p>
    </fn>
    <fn id="fn0023">
      <p>
        <sup>23</sup>
        <ext-link ext-link-type="uri" xlink:href="https://aramislab.paris.inria.fr/clinicadl/tuto/intro.html">https://aramislab.paris.inria.fr/clinicadl/tuto/intro.html</ext-link>
      </p>
    </fn>
    <fn id="fn0024">
      <p>
        <sup>24</sup>
        <ext-link ext-link-type="uri" xlink:href="https://ida.loni.usc.edu">https://ida.loni.usc.edu</ext-link>
      </p>
    </fn>
    <fn id="fn0025">
      <p>
        <sup>25</sup>
        <ext-link ext-link-type="uri" xlink:href="http://dti-tk.sourceforge.net">http://dti-tk.sourceforge.net</ext-link>
      </p>
    </fn>
    <fn id="fn0026">
      <p>
        <sup>26</sup>
        <ext-link ext-link-type="uri" xlink:href="http://neuro.debian.net/">http://neuro.debian.net/</ext-link>
      </p>
    </fn>
    <fn id="fn0027">
      <p>
        <sup>27</sup>
        <ext-link ext-link-type="uri" xlink:href="http://brainsuite.org">http://brainsuite.org</ext-link>
      </p>
    </fn>
    <fn id="fn0028">
      <p>
        <sup>28</sup>
        <ext-link ext-link-type="uri" xlink:href="https://brainlife.io/">https://brainlife.io/</ext-link>
      </p>
    </fn>
    <fn id="fn0029">
      <p>
        <sup>29</sup>
        <ext-link ext-link-type="uri" xlink:href="https://flywheel.io/product/">https://flywheel.io/product/</ext-link>
      </p>
    </fn>
    <fn id="fn0030">
      <p>
        <sup>30</sup>
        <ext-link ext-link-type="uri" xlink:href="http://www.mibca.com">http://www.mibca.com</ext-link>
      </p>
    </fn>
  </fn-group>
  <fn-group>
    <fn fn-type="financial-disclosure">
      <p><bold>Funding.</bold> The research leading to these results has received funding from the programs Investissements d'avenir ANR-10-IAIHU-06 (Agence Nationale de la Recherche-10-IA Institut Hospitalo-Universitaire-6), ANR-11-IDEX-004 (Agence Nationale de la Recherche-11-Initiative d'Excellence-004, project LearnPETMR number SU-16-R-EMR-16), and ANR-19-P3IA-0001 (PRAIRIE 3IA Institute), from the European Union H2020 program (project EuroPOND, grant number 666992, project HBP SGA1 grant number 720270), from the joint NSF/NIH/ANR program Collaborative Research in Computational Neuroscience (project HIPLAY7, grant number ANR-16-NEUC-0001-01), from Agence Nationale de la Recherche (project PREVDEMALS, grant number ANR-14-CE15-0016-07), from the ICM Big Brain Theory Program (project DYNAMO), from the Inria Project Lab Program (project Neuromarkers), from the European Research Council (to SD project LEASP, grant number 678304), and from the Contrat d'Interface Local program (to OC) from Assistance Publique-Hôpitaux de Paris (AP-HP). NB received funding from the People Programme (Marie Curie Actions) of the European Union's Seventh Framework Programme (FP7/2007-2013) under REA grant agreement no. PCOFUND-GA-2013-609102, through the PRESTIGE programme coordinated by Campus France.</p>
    </fn>
  </fn-group>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname><given-names>A.</given-names></name><name><surname>Pedregosa</surname><given-names>F.</given-names></name><name><surname>Eickenberg</surname><given-names>M.</given-names></name><name><surname>Gervais</surname><given-names>P.</given-names></name><name><surname>Mueller</surname><given-names>A.</given-names></name><name><surname>Kossaifi</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Machine learning for neuroimaging with scikit-learn</article-title>. <source>Front. Neuroinform.</source><volume>8</volume>:<fpage>14</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2014.00014</pub-id><?supplied-pmid 24600388?><pub-id pub-id-type="pmid">24600388</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersson</surname><given-names>J. L. R.</given-names></name><name><surname>Graham</surname><given-names>M. S.</given-names></name><name><surname>Zsoldos</surname><given-names>E.</given-names></name><name><surname>Sotiropoulos</surname><given-names>S. N.</given-names></name></person-group> (<year>2016</year>). <article-title>Incorporating outlier detection and replacement into a non-parametric framework for movement and distortion correction of diffusion MR images</article-title>. <source>Neuroimage</source>
<volume>141</volume>, <fpage>556</fpage>–<lpage>572</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.06.058</pub-id><?supplied-pmid 27393418?><pub-id pub-id-type="pmid">27393418</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersson</surname><given-names>J. L. R.</given-names></name><name><surname>Sotiropoulos</surname><given-names>S. N.</given-names></name></person-group> (<year>2016</year>). <article-title>An integrated approach to correction for off-resonance effects and subject movement in diffusion MR imaging</article-title>. <source>Neuroimage</source>
<volume>125</volume>, <fpage>1063</fpage>–<lpage>1078</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.10.019</pub-id><?supplied-pmid 26481672?><pub-id pub-id-type="pmid">26481672</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J.</given-names></name></person-group> (<year>2007</year>). <article-title>A fast diffeomorphic image registration algorithm</article-title>. <source>Neuroimage</source>
<volume>38</volume>, <fpage>95</fpage>–<lpage>113</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.07.007</pub-id><?supplied-pmid 17761438?><pub-id pub-id-type="pmid">17761438</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J.</given-names></name></person-group> (<year>2012</year>). <article-title>SPM: a history</article-title>. <source>Neuroimage</source>
<volume>62</volume>, <fpage>791</fpage>–<lpage>800</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.10.025</pub-id><?supplied-pmid 22023741?><pub-id pub-id-type="pmid">22023741</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name></person-group> (<year>2005</year>). <article-title>Unified segmentation</article-title>. <source>Neuroimage</source>
<volume>26</volume>, <fpage>839</fpage>–<lpage>851</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.02.018</pub-id><?supplied-pmid 15955494?><pub-id pub-id-type="pmid">15955494</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avants</surname><given-names>B. B.</given-names></name><name><surname>Epstein</surname><given-names>C. L.</given-names></name><name><surname>Grossman</surname><given-names>M.</given-names></name><name><surname>Gee</surname><given-names>J. C.</given-names></name></person-group> (<year>2008</year>). <article-title>Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain</article-title>. <source>Med. Image Anal.</source>
<volume>12</volume>, <fpage>26</fpage>–<lpage>41</lpage>. <pub-id pub-id-type="doi">10.1016/j.media.2007.06.004</pub-id><?supplied-pmid 17659998?><pub-id pub-id-type="pmid">17659998</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avants</surname><given-names>B. B.</given-names></name><name><surname>Tustison</surname><given-names>N. J.</given-names></name><name><surname>Stauffer</surname><given-names>M.</given-names></name><name><surname>Song</surname><given-names>G.</given-names></name><name><surname>Wu</surname><given-names>B.</given-names></name><name><surname>Gee</surname><given-names>J. C.</given-names></name></person-group> (<year>2014</year>). <article-title>The Insight ToolKit image registration framework</article-title>. <source>Front. Neuroinform.</source>
<volume>8</volume>:<fpage>44</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2014.00044</pub-id><?supplied-pmid 24817849?><pub-id pub-id-type="pmid">24817849</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avesani</surname><given-names>P.</given-names></name><name><surname>McPherson</surname><given-names>B.</given-names></name><name><surname>Hayashi</surname><given-names>S.</given-names></name><name><surname>Caiafa</surname><given-names>C. F.</given-names></name><name><surname>Henschel</surname><given-names>R.</given-names></name><name><surname>Garyfallidis</surname><given-names>E.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>The open diffusion data derivatives, brain data upcycling via integrated publishing of derivatives and reproducible open cloud services</article-title>. <source>Sci. Data</source><volume>6</volume>:<fpage>69</fpage>. <pub-id pub-id-type="doi">10.1038/s41597-019-0073-y</pub-id><?supplied-pmid 31123325?><pub-id pub-id-type="pmid">31123325</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Brett</surname><given-names>M.</given-names></name><name><surname>Hanke</surname><given-names>M.</given-names></name><name><surname>Markiewicz</surname><given-names>C.</given-names></name><name><surname>Marc-Alexandre Côt</surname><given-names>é</given-names></name><name><surname>McCarthy</surname><given-names>P.</given-names></name><name><surname>Cheng</surname><given-names>C.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>nipy/nibabel: 2.3.3</article-title>. <source>Zenodo.</source><pub-id pub-id-type="doi">10.5281/zenodo.2541736</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cointepas</surname><given-names>Y.</given-names></name><name><surname>Mangin</surname><given-names>J.-F.</given-names></name><name><surname>Garnero</surname><given-names>L.</given-names></name><name><surname>Poline</surname><given-names>J.-B.</given-names></name><name><surname>Benali</surname><given-names>H.</given-names></name></person-group> (<year>2001</year>). <article-title>BrainVISA: software platform for visualization and analysis of multi-modality brain data</article-title>. <source>Neuroimage</source>
<volume>13</volume>:<fpage>S98</fpage>. <pub-id pub-id-type="doi">10.1016/S1053-8119(01)91441-7</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cook</surname><given-names>P. A.</given-names></name><name><surname>Bai</surname><given-names>Y.</given-names></name><name><surname>Nedjati-Gilani</surname><given-names>S.</given-names></name><name><surname>Seunarine</surname><given-names>K.</given-names></name><name><surname>Hall</surname><given-names>M.</given-names></name><name><surname>Parker</surname><given-names>G.</given-names></name><etal/></person-group>. (<year>2005</year>). <article-title>Camino: open-source diffusion-MRI reconstruction and processing,</article-title> in <source>4th Scientific Meeting of the International Society for Magnetic Resonance in Medicine</source> (<publisher-loc>Seattle, WA</publisher-loc>), p. <fpage>2759</fpage>.</mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>R. W.</given-names></name></person-group> (<year>1996</year>). <article-title>AFNI: software for analysis and visualization of functional magnetic resonance neuroimages</article-title>. <source>Comput. Biomed. Res.</source>
<volume>29</volume>, <fpage>162</fpage>–<lpage>173</lpage>. <pub-id pub-id-type="doi">10.1006/cbmr.1996.0014</pub-id><?supplied-pmid 8812068?><pub-id pub-id-type="pmid">8812068</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cuingnet</surname><given-names>R.</given-names></name><name><surname>Glaunès</surname><given-names>J. A.</given-names></name><name><surname>Chupin</surname><given-names>M.</given-names></name><name><surname>Benali</surname><given-names>H.</given-names></name><name><surname>Colliot</surname><given-names>O.</given-names></name><collab>Alzheimer's Disease Neuroimaging Initiative</collab></person-group> (<year>2013</year>). <article-title>Spatial and anatomical regularization of SVM: a general framework for neuroimaging data</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell.</source>
<volume>35</volume>, <fpage>682</fpage>–<lpage>696</lpage>. <pub-id pub-id-type="doi">10.1109/TPAMI.2012.142</pub-id><?supplied-pmid 22732664?><pub-id pub-id-type="pmid">22732664</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desikan</surname><given-names>R. S.</given-names></name><name><surname>Ségonne</surname><given-names>F.</given-names></name><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Quinn</surname><given-names>B. T.</given-names></name><name><surname>Dickerson</surname><given-names>B. C.</given-names></name><name><surname>Blacker</surname><given-names>D.</given-names></name><etal/></person-group>. (<year>2006</year>). <article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title>. <source>Neuroimage</source><volume>31</volume>, <fpage>968</fpage>–<lpage>980</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.021</pub-id><?supplied-pmid 16530430?><pub-id pub-id-type="pmid">16530430</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Destrieux</surname><given-names>C.</given-names></name><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Dale</surname><given-names>A.</given-names></name><name><surname>Halgren</surname><given-names>E.</given-names></name></person-group> (<year>2010</year>). <article-title>Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature</article-title>. <source>Neuroimage</source>
<volume>53</volume>, <fpage>1</fpage>–<lpage>15</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.06.010</pub-id><?supplied-pmid 20547229?><pub-id pub-id-type="pmid">20547229</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esteban</surname><given-names>O.</given-names></name><name><surname>Markiewicz</surname><given-names>C. J.</given-names></name><name><surname>Blair</surname><given-names>R. W.</given-names></name><name><surname>Moodie</surname><given-names>C. A.</given-names></name><name><surname>Isik</surname><given-names>A. I.</given-names></name><name><surname>Erramuzpe</surname><given-names>A.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title>. <source>Nat. Methods</source><volume>16</volume>, <fpage>111</fpage>–<lpage>116</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id><?supplied-pmid 30532080?><pub-id pub-id-type="pmid">30532080</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B.</given-names></name></person-group> (<year>2012</year>). <article-title>FreeSurfer</article-title>. <source>Neuroimage</source>
<volume>62</volume>, <fpage>774</fpage>–<lpage>781</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.021</pub-id><?supplied-pmid 22248573?><pub-id pub-id-type="pmid">22248573</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Dale</surname><given-names>A. M.</given-names></name></person-group> (<year>2000</year>). <article-title>Measuring the thickness of the human cerebral cortex from magnetic resonance images</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source>
<volume>97</volume>, <fpage>11050</fpage>–<lpage>11055</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.200033797</pub-id><?supplied-pmid 10984517?><pub-id pub-id-type="pmid">10984517</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Salat</surname><given-names>D. H.</given-names></name><name><surname>Busa</surname><given-names>E.</given-names></name><name><surname>Albert</surname><given-names>M.</given-names></name><name><surname>Dieterich</surname><given-names>M.</given-names></name><name><surname>Haselgrove</surname><given-names>C.</given-names></name><etal/></person-group>. (<year>2002</year>). <article-title>Whole brain segmentation: automated labeling of neuroanatomical structures in the human brain</article-title>. <source>Neuron</source><volume>33</volume>, <fpage>341</fpage>–<lpage>355</lpage>. <pub-id pub-id-type="doi">10.1016/S0896-6273(02)00569-X</pub-id><?supplied-pmid 11832223?><pub-id pub-id-type="pmid">11832223</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Salat</surname><given-names>D. H.</given-names></name><name><surname>van der Kouwe</surname><given-names>A. J. W.</given-names></name><name><surname>Makris</surname><given-names>N.</given-names></name><name><surname>Ségonne</surname><given-names>F.</given-names></name><name><surname>Quinn</surname><given-names>B. T.</given-names></name><etal/></person-group>. (<year>2004a</year>). <article-title>Sequence-independent segmentation of magnetic resonance images</article-title>. <source>Neuroimage</source><volume>23</volume>, <fpage>S69</fpage>–<lpage>S84</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.07.016</pub-id><?supplied-pmid 15501102?><pub-id pub-id-type="pmid">15501102</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Sereno</surname><given-names>M. I.</given-names></name><name><surname>Dale</surname><given-names>A. M.</given-names></name></person-group> (<year>1999</year>). <article-title>Cortical surface-based analysis: II: inflation, flattening, and a surface-based coordinate system</article-title>. <source>Neuroimage</source>
<volume>9</volume>, <fpage>195</fpage>–<lpage>207</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.1998.0396</pub-id><?supplied-pmid 9931269?><pub-id pub-id-type="pmid">9931269</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>van der Kouwe</surname><given-names>A.</given-names></name><name><surname>Destrieux</surname><given-names>C.</given-names></name><name><surname>Halgren</surname><given-names>E.</given-names></name><name><surname>Ségonne</surname><given-names>F.</given-names></name><name><surname>Salat</surname><given-names>D. H.</given-names></name><etal/></person-group>. (<year>2004b</year>). <article-title>Automatically parcellating the human cerebral cortex</article-title>. <source>Cereb. Cortex</source><volume>14</volume>, <fpage>11</fpage>–<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhg087</pub-id><?supplied-pmid 14654453?><pub-id pub-id-type="pmid">14654453</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fonov</surname><given-names>V.</given-names></name><name><surname>Evans</surname><given-names>A.</given-names></name><name><surname>McKinstry</surname><given-names>R.</given-names></name><name><surname>Almli</surname><given-names>C.</given-names></name><name><surname>Collins</surname><given-names>D.</given-names></name></person-group> (<year>2009</year>). <article-title>Unbiased nonlinear average age-appropriate brain templates from birth to adulthood</article-title>. <source>Neuroimage</source>
<volume>47</volume>:<fpage>S102</fpage>. <pub-id pub-id-type="doi">10.1016/S1053-8119(09)70884-5</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fonov</surname><given-names>V.</given-names></name><name><surname>Evans</surname><given-names>A. C.</given-names></name><name><surname>Botteron</surname><given-names>K.</given-names></name><name><surname>Almli</surname><given-names>C. R.</given-names></name><name><surname>McKinstry</surname><given-names>R. C.</given-names></name><name><surname>Collins</surname><given-names>D. L.</given-names></name></person-group> (<year>2011</year>). <article-title>Unbiased average age-appropriate atlases for pediatric studies</article-title>. <source>Neuroimage</source>
<volume>54</volume>, <fpage>313</fpage>–<lpage>327</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.07.033</pub-id><?supplied-pmid 20656036?><pub-id pub-id-type="pmid">20656036</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foulon</surname><given-names>C.</given-names></name><name><surname>Cerliani</surname><given-names>L.</given-names></name><name><surname>Kinkingnéhun</surname><given-names>S.</given-names></name><name><surname>Levy</surname><given-names>R.</given-names></name><name><surname>Rosso</surname><given-names>C.</given-names></name><name><surname>Urbanski</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Advanced lesion symptom mapping analyses and implementation as BCBtoolkit</article-title>. <source>GigaScience</source><volume>7</volume>, <fpage>1</fpage>–<lpage>17</lpage>. <pub-id pub-id-type="doi">10.1093/gigascience/giy004</pub-id><?supplied-pmid 29432527?><pub-id pub-id-type="pmid">29432527</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="book"><person-group person-group-type="editor"><name><surname>Frackowiak</surname><given-names>R. S. J.</given-names></name><name><surname>Friston</surname><given-names>K. J.</given-names></name><name><surname>Frith</surname><given-names>C.</given-names></name><name><surname>Dolan</surname><given-names>R.</given-names></name><name><surname>Mazziotta</surname><given-names>J. C.</given-names></name></person-group> (eds.). (<year>1997</year>). <source>Human Brain Function</source>. <publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Academic Press</publisher-name>. Available online at: <ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm/doc/books/hbf1/">http://www.fil.ion.ucl.ac.uk/spm/doc/books/hbf1/</ext-link> (accessed March 26, 2021).</mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Friston</surname><given-names>K.</given-names></name><name><surname>Ashburner</surname><given-names>J.</given-names></name><name><surname>Kiebel</surname><given-names>S.</given-names></name><name><surname>Nichols</surname><given-names>T.</given-names></name><name><surname>Penny</surname><given-names>W.</given-names></name></person-group> (<year>2007</year>). <source>Statistical Parametric Mapping</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Elsevier</publisher-name>. <pub-id pub-id-type="doi">10.1016/B978-0-12-372560-8.X5000-1</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garyfallidis</surname><given-names>E.</given-names></name><name><surname>Brett</surname><given-names>M.</given-names></name><name><surname>Amirbekian</surname><given-names>B.</given-names></name><name><surname>Rokem</surname><given-names>A.</given-names></name><name><surname>van der Walt</surname><given-names>S.</given-names></name><name><surname>Descoteaux</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Dipy, a library for the analysis of diffusion MRI data</article-title>. <source>Front. Neuroinform.</source><volume>8</volume>:<fpage>8</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2014.00008</pub-id><?supplied-pmid 24600385?><pub-id pub-id-type="pmid">24600385</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>K.</given-names></name><name><surname>Burns</surname><given-names>C. D.</given-names></name><name><surname>Madison</surname><given-names>C.</given-names></name><name><surname>Clark</surname><given-names>D.</given-names></name><name><surname>Halchenko</surname><given-names>Y. O.</given-names></name><name><surname>Waskom</surname><given-names>M. L.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in python</article-title>. <source>Front. Neuroinform.</source><volume>5</volume>:<fpage>13</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2011.00013</pub-id><?supplied-pmid 21897815?><pub-id pub-id-type="pmid">21897815</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>K. J.</given-names></name><name><surname>Alfaro-Almagro</surname><given-names>F.</given-names></name><name><surname>Auer</surname><given-names>T.</given-names></name><name><surname>Bellec</surname><given-names>P.</given-names></name><name><surname>Capotă</surname><given-names>M.</given-names></name><name><surname>Chakravarty</surname><given-names>M. M.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>BIDS apps: improving ease of use, accessibility, and reproducibility of neuroimaging data analysis methods</article-title>. <source>PLoS Comput. Biol.</source><volume>13</volume>:<fpage>e1005209</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005209</pub-id><?supplied-pmid 28278228?><pub-id pub-id-type="pmid">28278228</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>K. J.</given-names></name><name><surname>Auer</surname><given-names>T.</given-names></name><name><surname>Calhoun</surname><given-names>V. D.</given-names></name><name><surname>Craddock</surname><given-names>R. C.</given-names></name><name><surname>Das</surname><given-names>S.</given-names></name><name><surname>Duff</surname><given-names>E. P.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments</article-title>. <source>Sci. Data</source><volume>3</volume>:<fpage>160044</fpage>. <pub-id pub-id-type="doi">10.1038/sdata.2016.44</pub-id><?supplied-pmid 27326542?><pub-id pub-id-type="pmid">27326542</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gousias</surname><given-names>I. S.</given-names></name><name><surname>Rueckert</surname><given-names>D.</given-names></name><name><surname>Heckemann</surname><given-names>R. A.</given-names></name><name><surname>Dyet</surname><given-names>L. E.</given-names></name><name><surname>Boardman</surname><given-names>J. P.</given-names></name><name><surname>Edwards</surname><given-names>A. D.</given-names></name><etal/></person-group>. (<year>2008</year>). <article-title>Automatic segmentation of brain MRIs of 2-year-olds into 83 regions of interest</article-title>. <source>Neuroimage</source><volume>40</volume>, <fpage>672</fpage>–<lpage>684</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.11.034</pub-id><?supplied-pmid 18234511?><pub-id pub-id-type="pmid">18234511</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halchenko</surname><given-names>Y. O.</given-names></name><name><surname>Hanke</surname><given-names>M.</given-names></name></person-group> (<year>2012</year>). <article-title>Open is not enough. Let's take the next step: an integrated, community-driven computing platform for neuroscience</article-title>. <source>Front. Neuroinform.</source>
<volume>6</volume>:<fpage>22</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2012.00022</pub-id><?supplied-pmid 23055966?><pub-id pub-id-type="pmid">23055966</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hammers</surname><given-names>A.</given-names></name><name><surname>Allom</surname><given-names>R.</given-names></name><name><surname>Koepp</surname><given-names>M. J.</given-names></name><name><surname>Free</surname><given-names>S. L.</given-names></name><name><surname>Myers</surname><given-names>R.</given-names></name><name><surname>Lemieux</surname><given-names>L.</given-names></name><etal/></person-group>. (<year>2003</year>). <article-title>Three-dimensional maximum probability atlas of the human brain, with particular reference to the temporal lobe</article-title>. <source>Hum. Brain Mapp.</source><volume>19</volume>, <fpage>224</fpage>–<lpage>247</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.10123</pub-id><?supplied-pmid 12874777?><pub-id pub-id-type="pmid">12874777</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hua</surname><given-names>K.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Wakana</surname><given-names>S.</given-names></name><name><surname>Jiang</surname><given-names>H.</given-names></name><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Reich</surname><given-names>D. S.</given-names></name><etal/></person-group>. (<year>2008</year>). <article-title>Tract probability maps in stereotaxic spaces: analyses of white matter anatomy and tract-specific quantification</article-title>. <source>Neuroimage</source><volume>39</volume>, <fpage>336</fpage>–<lpage>347</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.07.053</pub-id><?supplied-pmid 17931890?><pub-id pub-id-type="pmid">17931890</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M.</given-names></name><name><surname>Beckmann</surname><given-names>C. F.</given-names></name><name><surname>Behrens</surname><given-names>T. E. J.</given-names></name><name><surname>Woolrich</surname><given-names>M. W.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name></person-group> (<year>2012</year>). <article-title>FSL</article-title>. <source>Neuroimage</source>
<volume>62</volume>, <fpage>782</fpage>–<lpage>790</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.09.015</pub-id><?supplied-pmid 21979382?><pub-id pub-id-type="pmid">21979382</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joliot</surname><given-names>M.</given-names></name><name><surname>Jobard</surname><given-names>G.</given-names></name><name><surname>Naveau</surname><given-names>M.</given-names></name><name><surname>Delcroix</surname><given-names>N.</given-names></name><name><surname>Petit</surname><given-names>L.</given-names></name><name><surname>Zago</surname><given-names>L.</given-names></name><etal/></person-group>. (<year>2015</year>). <article-title>AICHA: an atlas of intrinsic connectivity of homotopic areas</article-title>. <source>J. Neurosci. Methods</source><volume>254</volume>, <fpage>46</fpage>–<lpage>59</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2015.07.013</pub-id><?supplied-pmid 26213217?><pub-id pub-id-type="pmid">26213217</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>E.</given-names></name><name><surname>Oliphant</surname><given-names>T.</given-names></name><name><surname>Peterson</surname><given-names>P.</given-names></name><collab>others</collab></person-group> (<year>2001</year>). <source>SciPy: Open Source Scientific Tools for Python</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="http://www.scipy.org/">http://www.scipy.org/</ext-link> (accessed March 26, 2021).</mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keshavan</surname><given-names>A.</given-names></name><name><surname>Datta</surname><given-names>E. M.</given-names></name><name><surname>McDonough</surname><given-names>I.</given-names></name><name><surname>Madan</surname><given-names>C. R.</given-names></name><name><surname>Jordan</surname><given-names>K.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Mindcontrol: a web application for brain segmentation quality control</article-title>. <source>Neuroimage</source><volume>170</volume>, <fpage>365</fpage>–<lpage>372</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.03.055</pub-id><?supplied-pmid 28365419?><pub-id pub-id-type="pmid">28365419</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leow</surname><given-names>A. D.</given-names></name><name><surname>Yanovsky</surname><given-names>I.</given-names></name><name><surname>Chiang</surname><given-names>M. C.</given-names></name><name><surname>Lee</surname><given-names>A. D.</given-names></name><name><surname>Klunder</surname><given-names>A. D.</given-names></name><name><surname>Lu</surname><given-names>A.</given-names></name><etal/></person-group>. (<year>2007</year>). <article-title>Statistical properties of jacobian maps and the realization of unbiased large-deformation nonlinear image registration</article-title>. <source>IEEE Trans. Med. Imaging</source><volume>26</volume>, <fpage>822</fpage>–<lpage>832</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2007.892646</pub-id><?supplied-pmid 17679333?><pub-id pub-id-type="pmid">17679333</pub-id></mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marcoux</surname><given-names>A.</given-names></name><name><surname>Burgos</surname><given-names>N.</given-names></name><name><surname>Bertrand</surname><given-names>A.</given-names></name><name><surname>Teichmann</surname><given-names>M.</given-names></name><name><surname>Routier</surname><given-names>A.</given-names></name><name><surname>Wen</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>An automated pipeline for the analysis of PET data on the cortical surface</article-title>. <source>Front. Neuroinform.</source><volume>12</volume>:<fpage>94</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2018.00094</pub-id><?supplied-pmid 30618699?><pub-id pub-id-type="pmid">30618699</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>McDermott</surname><given-names>M. B. A.</given-names></name><name><surname>Wang</surname><given-names>S.</given-names></name><name><surname>Marinsek</surname><given-names>N.</given-names></name><name><surname>Ranganath</surname><given-names>R.</given-names></name><name><surname>Ghassemi</surname><given-names>M.</given-names></name><name><surname>Foschini</surname><given-names>L.</given-names></name></person-group> (<year>2019</year>). <article-title>Reproducibility in machine learning for health,</article-title> in ICLR 2019 Reproducibility in Machine Learning Workshop. Available online at: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1907.01463">http://arxiv.org/abs/1907.01463</ext-link> (accessed March 26, 2021).<?supplied-pmid 33762434?></mixed-citation>
    </ref>
    <ref id="B44">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>McKinney</surname><given-names>W.</given-names></name></person-group> (<year>2010</year>). <article-title>Data structures for statistical computing in python,</article-title> in <source>Proceedings of the 9th Python in Science Conference</source>, eds. <person-group person-group-type="editor"><name><surname>van der Walt</surname><given-names>S.</given-names></name><name><surname>Millman</surname><given-names>J.</given-names></name></person-group> (<publisher-loc>Austin, TX</publisher-loc>), <fpage>51</fpage>–<lpage>56</lpage>.</mixed-citation>
    </ref>
    <ref id="B45">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mori</surname><given-names>S.</given-names></name><name><surname>Wakana</surname><given-names>S.</given-names></name><name><surname>Nagae-Poetscher</surname><given-names>L.</given-names></name><name><surname>van Zijl</surname><given-names>P.</given-names></name></person-group> (<year>2005</year>). <source>MRI Atlas of Human White Matter</source>. <publisher-loc>Amsterdam</publisher-loc>: <publisher-name>Elsevier</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B46">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A.</given-names></name><name><surname>Gross</surname><given-names>S.</given-names></name><name><surname>Massa</surname><given-names>F.</given-names></name><name><surname>Lerer</surname><given-names>A.</given-names></name><name><surname>Bradbury</surname><given-names>J.</given-names></name><name><surname>Chanan</surname><given-names>G.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>PyTorch: an imperative style, high-performance deep learning library,</article-title> in <source>Advances in Neural Information Processing Systems 32</source>, eds <person-group person-group-type="editor"><name><surname>Wallach</surname><given-names>H.</given-names></name><name><surname>Larochelle</surname><given-names>H.</given-names></name><name><surname>Beygelzimer</surname><given-names>A.</given-names></name><name><surname>d'Alché-Buc</surname><given-names>F.</given-names></name><name><surname>Fox</surname><given-names>E.</given-names></name><name><surname>Garnett</surname><given-names>R.</given-names></name></person-group> (<publisher-loc>Red Hook, NY</publisher-loc>: <publisher-name>Curran Associates, Inc.</publisher-name>), <fpage>8024</fpage>–<lpage>8035</lpage>. Available online at: <ext-link ext-link-type="uri" xlink:href="http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf">http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf</ext-link> (accessed March 26, 2021).</mixed-citation>
    </ref>
    <ref id="B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F.</given-names></name><name><surname>Varoquaux</surname><given-names>G.</given-names></name><name><surname>Gramfort</surname><given-names>A.</given-names></name><name><surname>Michel</surname><given-names>V.</given-names></name><name><surname>Thirion</surname><given-names>B.</given-names></name><name><surname>Grisel</surname><given-names>O.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Scikit-learn: machine learning in python</article-title>. <source>J. Mach. Learn. Res.</source><volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poldrack</surname><given-names>R. A.</given-names></name><name><surname>Baker</surname><given-names>C. I.</given-names></name><name><surname>Durnez</surname><given-names>J.</given-names></name><name><surname>Gorgolewski</surname><given-names>K. J.</given-names></name><name><surname>Matthews</surname><given-names>P. M.</given-names></name><name><surname>Munafò</surname><given-names>M. R.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>Scanning the horizon: towards transparent and reproducible neuroimaging research</article-title>. <source>Nat. Rev. Neurosci.</source><volume>18</volume>, <fpage>115</fpage>–<lpage>126</lpage>. <pub-id pub-id-type="doi">10.1038/nrn.2016.167</pub-id><?supplied-pmid 28053326?><pub-id pub-id-type="pmid">28053326</pub-id></mixed-citation>
    </ref>
    <ref id="B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poline</surname><given-names>J.-B.</given-names></name><name><surname>Breeze</surname><given-names>J. L.</given-names></name><name><surname>Ghosh</surname><given-names>S. S.</given-names></name><name><surname>Gorgolewski</surname><given-names>K.</given-names></name><name><surname>Halchenko</surname><given-names>Y. O.</given-names></name><name><surname>Hanke</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2012</year>). <article-title>Data sharing in neuroimaging research</article-title>. <source>Front. Neuroinform.</source><volume>6</volume>:<fpage>9</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2012.00009</pub-id><?supplied-pmid 22493576?><pub-id pub-id-type="pmid">22493576</pub-id></mixed-citation>
    </ref>
    <ref id="B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reuter</surname><given-names>M.</given-names></name><name><surname>Rosas</surname><given-names>H. D.</given-names></name><name><surname>Fischl</surname><given-names>B.</given-names></name></person-group> (<year>2010</year>). <article-title>Highly accurate inverse consistent registration: a robust approach</article-title>. <source>Neuroimage</source>
<volume>53</volume>, <fpage>1181</fpage>–<lpage>1196</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.07.020</pub-id><?supplied-pmid 20637289?><pub-id pub-id-type="pmid">20637289</pub-id></mixed-citation>
    </ref>
    <ref id="B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reuter</surname><given-names>M.</given-names></name><name><surname>Schmansky</surname><given-names>N. J.</given-names></name><name><surname>Rosas</surname><given-names>H. D.</given-names></name><name><surname>Fischl</surname><given-names>B.</given-names></name></person-group> (<year>2012</year>). <article-title>Within-subject template estimation for unbiased longitudinal image analysis</article-title>. <source>Neuroimage</source>
<volume>61</volume>, <fpage>1402</fpage>–<lpage>1418</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.02.084</pub-id><?supplied-pmid 22430496?><pub-id pub-id-type="pmid">22430496</pub-id></mixed-citation>
    </ref>
    <ref id="B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ribeiro</surname><given-names>A. S.</given-names></name><name><surname>Lacerda</surname><given-names>L. M.</given-names></name><name><surname>Ferreira</surname><given-names>H. A.</given-names></name></person-group> (<year>2015</year>). <article-title>Multimodal Imaging Brain Connectivity Analysis (MIBCA) toolbox</article-title>. <source>PeerJ</source>
<volume>3</volume>:<fpage>e1078</fpage>. <pub-id pub-id-type="doi">10.7717/peerj.1078</pub-id><?supplied-pmid 26207191?><pub-id pub-id-type="pmid">26207191</pub-id></mixed-citation>
    </ref>
    <ref id="B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samper-González</surname><given-names>J.</given-names></name><name><surname>Burgos</surname><given-names>N.</given-names></name><name><surname>Bottani</surname><given-names>S.</given-names></name><name><surname>Fontanella</surname><given-names>S.</given-names></name><name><surname>Lu</surname><given-names>P.</given-names></name><name><surname>Marcoux</surname><given-names>A.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Reproducible evaluation of classification methods in Alzheimer's disease: framework and application to MRI and PET data</article-title>. <source>Neuroimage</source><volume>183</volume>, <fpage>504</fpage>–<lpage>521</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.08.042</pub-id><?supplied-pmid 30130647?><pub-id pub-id-type="pmid">30130647</pub-id></mixed-citation>
    </ref>
    <ref id="B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savio</surname><given-names>A. M.</given-names></name><name><surname>Schutte</surname><given-names>M.</given-names></name><name><surname>Graña</surname><given-names>M.</given-names></name><name><surname>Yakushev</surname><given-names>I.</given-names></name></person-group> (<year>2017</year>). <article-title>Pypes: workflows for processing multimodal neuroimaging data</article-title>. <source>Front. Neuroinform.</source>
<volume>11</volume>:<fpage>25</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2017.00025</pub-id><?supplied-pmid 28443013?><pub-id pub-id-type="pmid">28443013</pub-id></mixed-citation>
    </ref>
    <ref id="B55">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shattuck</surname><given-names>D. W.</given-names></name><name><surname>Mirza</surname><given-names>M.</given-names></name><name><surname>Adisetiyo</surname><given-names>V.</given-names></name><name><surname>Hojatkashani</surname><given-names>C.</given-names></name><name><surname>Salamon</surname><given-names>G.</given-names></name><name><surname>Narr</surname><given-names>K. L.</given-names></name><etal/></person-group>. (<year>2008</year>). <article-title>Construction of a 3D probabilistic atlas of human cortical structures</article-title>. <source>Neuroimage</source><volume>39</volume>, <fpage>1064</fpage>–<lpage>1080</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.09.031</pub-id><?supplied-pmid 18037310?><pub-id pub-id-type="pmid">18037310</pub-id></mixed-citation>
    </ref>
    <ref id="B56">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Simonyan</surname><given-names>K.</given-names></name><name><surname>Vedaldi</surname><given-names>A.</given-names></name><name><surname>Zisserman</surname><given-names>A.</given-names></name></person-group> (<year>2013</year>). <article-title>Deep inside convolutional networks: visualising image classification models and saliency maps</article-title>. <source>arXiv:1312.6034 [cs]</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1312.6034">http://arxiv.org/abs/1312.6034</ext-link> (accessed July 4, 2018).</mixed-citation>
    </ref>
    <ref id="B57">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>B. A.</given-names></name><name><surname>Cuplov</surname><given-names>V.</given-names></name><name><surname>Bousse</surname><given-names>A.</given-names></name><name><surname>Mendes</surname><given-names>A.</given-names></name><name><surname>Thielemans</surname><given-names>K.</given-names></name><name><surname>Hutton</surname><given-names>B. F.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>PETPVC: a toolbox for performing partial volume correction techniques in positron emission tomography</article-title>. <source>Phys. Med. Biol.</source><volume>61</volume>, <fpage>7975</fpage>–<lpage>7993</lpage>. <pub-id pub-id-type="doi">10.1088/0031-9155/61/22/7975</pub-id><?supplied-pmid 27779136?><pub-id pub-id-type="pmid">27779136</pub-id></mixed-citation>
    </ref>
    <ref id="B58">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tournier</surname><given-names>J.-D.</given-names></name><name><surname>Calamante</surname><given-names>F.</given-names></name><name><surname>Connelly</surname><given-names>A.</given-names></name></person-group> (<year>2007</year>). <article-title>Robust determination of the fibre orientation distribution in diffusion MRI: non-negativity constrained super-resolved spherical deconvolution</article-title>. <source>Neuroimage</source>
<volume>35</volume>, <fpage>1459</fpage>–<lpage>1472</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.02.016</pub-id><?supplied-pmid 17379540?><pub-id pub-id-type="pmid">17379540</pub-id></mixed-citation>
    </ref>
    <ref id="B59">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Tournier</surname><given-names>J.-D.</given-names></name><name><surname>Calamante</surname><given-names>F.</given-names></name><name><surname>Connelly</surname><given-names>A.</given-names></name></person-group> (<year>2010</year>). <article-title>Improved probabilistic streamlines tractography by 2nd order integration over fibre orientation distributions,</article-title> in Proceedings of the International Society for Magnetic Resonance in Medicine. Available online at: <ext-link ext-link-type="uri" xlink:href="https://cds.ismrm.org/protected/10MProceedings/files/1670_4298.pdf">https://cds.ismrm.org/protected/10MProceedings/files/1670_4298.pdf</ext-link> (accessed January 25, 2019).</mixed-citation>
    </ref>
    <ref id="B60">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tournier</surname><given-names>J.-D.</given-names></name><name><surname>Calamante</surname><given-names>F.</given-names></name><name><surname>Connelly</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>). <article-title>MRtrix: diffusion tractography in crossing fiber regions</article-title>. <source>Int. J. Imaging Syst. Technol.</source>
<volume>22</volume>, <fpage>53</fpage>–<lpage>66</lpage>. <pub-id pub-id-type="doi">10.1002/ima.22005</pub-id></mixed-citation>
    </ref>
    <ref id="B61">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tustison</surname><given-names>N. J.</given-names></name><name><surname>Avants</surname><given-names>B. B.</given-names></name><name><surname>Cook</surname><given-names>P. A.</given-names></name><name><surname>Zheng</surname><given-names>Y.</given-names></name><name><surname>Egan</surname><given-names>A.</given-names></name><name><surname>Yushkevich</surname><given-names>P. A.</given-names></name><etal/></person-group>. (<year>2010</year>). <article-title>N4ITK: improved N3 bias correction</article-title>. <source>IEEE Trans. Med. Imaging</source><volume>29</volume>, <fpage>1310</fpage>–<lpage>1320</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2010.2046908</pub-id><?supplied-pmid 20378467?><pub-id pub-id-type="pmid">20378467</pub-id></mixed-citation>
    </ref>
    <ref id="B62">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tzourio-Mazoyer</surname><given-names>N.</given-names></name><name><surname>Landeau</surname><given-names>B.</given-names></name><name><surname>Papathanassiou</surname><given-names>D.</given-names></name><name><surname>Crivello</surname><given-names>F.</given-names></name><name><surname>Etard</surname><given-names>O.</given-names></name><name><surname>Delcroix</surname><given-names>N.</given-names></name><etal/></person-group>. (<year>2002</year>). <article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</article-title>. <source>Neuroimage</source><volume>15</volume>, <fpage>273</fpage>–<lpage>289</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.2001.0978</pub-id><?supplied-pmid 11771995?><pub-id pub-id-type="pmid">11771995</pub-id></mixed-citation>
    </ref>
    <ref id="B63">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Walt</surname><given-names>S.</given-names></name><name><surname>Colbert</surname><given-names>S. C.</given-names></name><name><surname>Varoquaux</surname><given-names>G.</given-names></name></person-group> (<year>2011</year>). <article-title>The NumPy array: a structure for efficient numerical computation</article-title>. <source>Comput. Sci. Eng.</source>
<volume>13</volume>, <fpage>22</fpage>–<lpage>30</lpage>. <pub-id pub-id-type="doi">10.1109/MCSE.2011.37</pub-id></mixed-citation>
    </ref>
    <ref id="B64">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wakana</surname><given-names>S.</given-names></name><name><surname>Caprihan</surname><given-names>A.</given-names></name><name><surname>Panzenboeck</surname><given-names>M. M.</given-names></name><name><surname>Fallon</surname><given-names>J. H.</given-names></name><name><surname>Perry</surname><given-names>M.</given-names></name><name><surname>Gollub</surname><given-names>R. L.</given-names></name><etal/></person-group>. (<year>2007</year>). <article-title>Reproducibility of quantitative tractography methods applied to cerebral white matter</article-title>. <source>Neuroimage</source><volume>36</volume>, <fpage>630</fpage>–<lpage>644</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.02.049</pub-id><?supplied-pmid 17481925?><pub-id pub-id-type="pmid">17481925</pub-id></mixed-citation>
    </ref>
    <ref id="B65">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>J.</given-names></name><name><surname>Samper-González</surname><given-names>J.</given-names></name><name><surname>Bottani</surname><given-names>S.</given-names></name><name><surname>Routier</surname><given-names>A.</given-names></name><name><surname>Burgos</surname><given-names>N.</given-names></name><name><surname>Jacquemont</surname><given-names>T.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Reproducible evaluation of diffusion MRI features for automatic classification of patients with Alzheimer's disease</article-title>. <source>Neuroinformatics</source><volume>19</volume>, <fpage>57</fpage>–<lpage>78</lpage>. <pub-id pub-id-type="doi">10.1007/s12021-020-09469-5</pub-id><?supplied-pmid 32524428?><pub-id pub-id-type="pmid">32524428</pub-id></mixed-citation>
    </ref>
    <ref id="B66">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>J.</given-names></name><name><surname>Thibeau-Sutre</surname><given-names>E.</given-names></name><name><surname>Diaz-Melo</surname><given-names>M.</given-names></name><name><surname>Samper-González</surname><given-names>J.</given-names></name><name><surname>Routier</surname><given-names>A.</given-names></name><name><surname>Bottani</surname><given-names>S.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Convolutional neural networks for classification of Alzheimer's Disease: overview and reproducible evaluation</article-title>. <source>Med. Image Anal.</source><volume>2020</volume>:<fpage>101694</fpage>. <pub-id pub-id-type="doi">10.1016/j.media.2020.101694</pub-id><?supplied-pmid 32417716?><pub-id pub-id-type="pmid">32417716</pub-id></mixed-citation>
    </ref>
    <ref id="B67">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Worsley</surname><given-names>K.</given-names></name><name><surname>Taylor</surname><given-names>J.</given-names></name><name><surname>Carbonell</surname><given-names>F.</given-names></name><name><surname>Chung</surname><given-names>M.</given-names></name><name><surname>Duerden</surname><given-names>E.</given-names></name><name><surname>Bernhardt</surname><given-names>B.</given-names></name><etal/></person-group>. (<year>2009</year>). <article-title>SurfStat: a Matlab toolbox for the statistical analysis of univariate and multivariate surface and volumetric data using linear mixed effects models and random field theory</article-title>. <source>Neuroimage</source><volume>47</volume>:<fpage>S102</fpage>. <pub-id pub-id-type="doi">10.1016/S1053-8119(09)70882-1</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
