<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with OASIS Tables with MathML3 v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-archive-oasis-article1-mathml3.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jpoasis-nisons2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Res Synth Methods</journal-id>
    <journal-id journal-id-type="iso-abbrev">Res Synth Methods</journal-id>
    <journal-id journal-id-type="doi">10.1002/(ISSN)1759-2887</journal-id>
    <journal-id journal-id-type="publisher-id">JRSM</journal-id>
    <journal-title-group>
      <journal-title>Research Synthesis Methods</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1759-2879</issn>
    <issn pub-type="epub">1759-2887</issn>
    <publisher>
      <publisher-name>John Wiley and Sons Inc.</publisher-name>
      <publisher-loc>Hoboken</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7540394</article-id>
    <article-id pub-id-type="doi">10.1002/jrsm.1408</article-id>
    <article-id pub-id-type="publisher-id">JRSM1408</article-id>
    <article-categories>
      <subj-group subj-group-type="overline">
        <subject>Computational Tools and Methods</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Computational Tools and Methods</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>“<italic>statcheck</italic>”: Automatically detect statistical reporting inconsistencies to increase reproducibility of <styled-content style="fixed-case" toggle="no">meta‐analyses</styled-content>
</article-title>
      <alt-title alt-title-type="left-running-head">Nuijten and Polanin</alt-title>
    </title-group>
    <contrib-group>
      <contrib id="jrsm1408-cr-0001" contrib-type="author" corresp="yes">
        <name>
          <surname>Nuijten</surname>
          <given-names>Michèle B.</given-names>
        </name>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-1468-8585</contrib-id>
        <xref ref-type="aff" rid="jrsm1408-aff-0001">
          <sup>1</sup>
        </xref>
        <address>
          <email>m.b.nuijten@uvt.nl</email>
        </address>
      </contrib>
      <contrib id="jrsm1408-cr-0002" contrib-type="author">
        <name>
          <surname>Polanin</surname>
          <given-names>Joshua R.</given-names>
        </name>
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-5100-0164</contrib-id>
        <xref ref-type="aff" rid="jrsm1408-aff-0002">
          <sup>2</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="jrsm1408-aff-0001">
      <label>
        <sup>1</sup>
      </label>
      <institution>The Department of Methodology and Statistics, Tilburg University</institution>
      <city>Tilburg</city>
      <country country="NL">The Netherlands</country>
    </aff>
    <aff id="jrsm1408-aff-0002">
      <label>
        <sup>2</sup>
      </label>
      <institution>Research &amp; Evaluation, American Institutes for Research</institution>
      <city>Washington</city>
      <named-content content-type="country-part">DC</named-content>
      <country country="US">USA</country>
    </aff>
    <author-notes>
      <corresp id="correspondenceTo"><label>*</label><bold>Correspondence</bold><break/>
Michèle B. Nuijten, The Department of Methodology and Statistics, Tilburg University, Warandelaan 2, 5037 AB Tilburg, The Netherlands.<break/>
Email: <email>m.b.nuijten@uvt.nl</email><break/></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>27</day>
      <month>4</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <month>9</month>
      <year>2020</year>
    </pub-date>
    <volume>11</volume>
    <issue>5</issue>
    <issue-id pub-id-type="doi">10.1002/jrsm.v11.5</issue-id>
    <fpage>574</fpage>
    <lpage>579</lpage>
    <history>
      <date date-type="received">
        <day>13</day>
        <month>8</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>24</day>
        <month>1</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>26</day>
        <month>3</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <!--<copyright-statement content-type="issue-copyright"> &#x000a9; 2020 John Wiley & Sons, Ltd. <copyright-statement>-->
      <copyright-statement content-type="article-copyright">© 2020 The Authors. <italic>Research Synthesis Methods</italic> published by John Wiley &amp; Sons Ltd.</copyright-statement>
      <license license-type="creativeCommonsBy">
        <license-p>This is an open access article under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link> License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="file:JRSM-11-574.pdf"/>
    <abstract>
      <p>We present the R package and web app <italic>statcheck</italic> to automatically detect statistical reporting inconsistencies in primary studies and meta‐analyses. Previous research has shown a high prevalence of reported <italic>p</italic>‐values that are inconsistent ‐ meaning a re‐calculated <italic>p‐</italic>value, based on the reported test statistic and degrees of freedom, does not match the author‐reported <italic>p</italic>‐value. Such inconsistencies affect the reproducibility and evidential value of published findings. The tool <italic>statcheck</italic> can help researchers to identify statistical inconsistencies so that they may correct them. In this paper, we provide an overview of the prevalence and consequences of statistical reporting inconsistencies. We also discuss the tool <italic>statcheck</italic> in more detail and give an example of how it can be used in a meta‐analysis. We end with some recommendations concerning the use of <italic>statcheck</italic> in meta‐analyses and make a case for better reporting standards of statistical results.</p>
    </abstract>
    <kwd-group kwd-group-type="author-generated">
      <kwd id="jrsm1408-kwd-0001">meta‐analysis</kwd>
      <kwd id="jrsm1408-kwd-0002">reporting standards</kwd>
      <kwd id="jrsm1408-kwd-0003">reproducibility</kwd>
      <kwd id="jrsm1408-kwd-0004">statcheck</kwd>
      <kwd id="jrsm1408-kwd-0005">statistical error</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="funding-0001">
        <funding-source>Campbell Collaboration</funding-source>
        <award-id>CMG2.02</award-id>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="3"/>
      <table-count count="0"/>
      <page-count count="6"/>
      <word-count count="3545"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>source-schema-version-number</meta-name>
        <meta-value>2.0</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>cover-date</meta-name>
        <meta-value>September 2020</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>details-of-publishers-convertor</meta-name>
        <meta-value>Converter:WILEY_ML3GV2_TO_JATSPMC version:5.9.2 mode:remove_FC converted:07.10.2020</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <p content-type="self-citation">
      <mixed-citation publication-type="journal" id="jrsm1408-cit-9001"><string-name><surname>Nuijten</surname><given-names>MB</given-names></string-name>, <string-name><surname>Polanin</surname><given-names>JR</given-names></string-name>. <article-title>“<italic>statcheck</italic>”: Automatically detect statistical reporting inconsistencies to increase reproducibility of meta‐analyses</article-title>. <source xml:lang="en">Res Syn Meth</source>. <year>2020</year>;<volume>11</volume>:<fpage>574</fpage>–<lpage>579</lpage>. <pub-id pub-id-type="doi">10.1002/jrsm.1408</pub-id></mixed-citation>
    </p>
    <fn-group>
      <fn id="jrsm1408-note-1002">
        <p><bold>Funding information</bold> Campbell Collaboration, Grant/Award Number: CMG2.02</p>
      </fn>
    </fn-group>
  </notes>
</front>
<body id="jrsm1408-body-0001">
  <p>
    <boxed-text position="anchor" content-type="box" id="jrsm1408-blkfxd-1001" orientation="portrait">
      <caption>
        <title>Highlights</title>
      </caption>
      <sec id="jrsm1408-sec-1003">
        <p>
          <list list-type="bullet" id="jrsm1408-list-0001">
            <list-item id="jrsm1408-li-0001">
              <p>Reporting inconsistencies where the reported <italic>p</italic>‐value does not match the degrees of freedom and test statistic are widespread.</p>
            </list-item>
            <list-item id="jrsm1408-li-0002">
              <p>The R package and web app <italic>statcheck</italic> can automatically detect statistical reporting inconsistencies in meta‐analyses.</p>
            </list-item>
            <list-item id="jrsm1408-li-0003">
              <p>If meta‐analysts adhere to APA reporting style, <italic>statcheck</italic> provides a quick and easy tool to detect reporting inconsistencies and increase reproducibility.</p>
            </list-item>
          </list>
        </p>
      </sec>
    </boxed-text>
  </p>
  <sec id="jrsm1408-sec-0001">
    <label>1</label>
    <title>INTRODUCTION</title>
    <p>Researchers in the health and social sciences continue to draw conclusions in the health and social sciences based solely on Null Hypothesis Significance Tests (NHST).<xref rid="jrsm1408-bib-0001" ref-type="ref"><sup>1</sup></xref>, <xref rid="jrsm1408-bib-0002" ref-type="ref"><sup>2</sup></xref>, <xref rid="jrsm1408-bib-0003" ref-type="ref"><sup>3</sup></xref>, <xref rid="jrsm1408-bib-0004" ref-type="ref"><sup>4</sup></xref> Primary study authors use these tests often, yet meta‐analysts use them as well: NHST results in primary studies can also be used to calculate effect sizes to include in meta‐analyses, and a recent review of meta‐analyses published in the social sciences<xref rid="jrsm1408-bib-0005" ref-type="ref"><sup>5</sup></xref> revealed that the average review conducted nearly 60 NHSTs. NHSTs can therefore lead to policy and practice decisions, and as such, their accuracy is paramount.</p>
    <p>Extant evidence suggests that statistical reporting errors are widespread. A recent review of significance testing in primary studies found that one in eight primary studies published in eight high‐profile psychology journals had “grossly inconsistent <italic>p</italic>‐values that may have affected the statistical conclusion”.<xref rid="jrsm1408-bib-0006" ref-type="ref"><sup>6</sup></xref> The authors applied the phrase “grossly inconsistent” to represent cases in which conclusions of the significance test would change based on a recalculation of the <italic>p</italic>‐value. For example, a study's author said a <italic>p</italic>‐value was &lt;.05 but the test statistic and degrees of freedom indicated the <italic>p</italic>‐value was actually &gt;.05, or vice versa. An alarmingly high number of impactful results of statistical significance tests were inconsistent and potentially misleadingly inaccurate, too: the results indicated that gross inconsistencies favored statistically significant results.</p>
    <p>Detecting statistical reporting inconsistencies is time‐consuming and, ironically, error‐prone work. Because of that, Epskamp and Nuijten<xref rid="jrsm1408-bib-0007" ref-type="ref"><sup>7</sup></xref> developed the R package <italic>statcheck</italic>: an automated tool to extract NHST results from articles and recalculate <italic>p</italic>‐values. Recently, Polanin and Nuijten<xref rid="jrsm1408-bib-0008" ref-type="ref"><sup>8</sup></xref> extended <italic>statcheck</italic>'<italic>s</italic> functionality to include tests often used in meta‐analyses. In this paper, we elaborate on how <italic>statcheck</italic> can be useful in the context of meta‐analysis. We give a brief overview of the prevalence and consequences of statistical reporting inconsistencies based on a review of 402 meta‐analyses. We also discuss the tool <italic>statcheck</italic> in more detail and give an example of how it can be used in a meta‐analysis. We end with some recommendations concerning the use of <italic>statcheck</italic> in meta‐analyses and make a case for better reporting standards for statistical results.</p>
  </sec>
  <sec id="jrsm1408-sec-0002">
    <label>2</label>
    <title>WHY SHOULD RESEARCH SYNTHESISTS CARE ABOUT STATISTICAL REPORTING INCONSISTENCIES?</title>
    <p>We focus on a specific type of statistical error: statistical reporting inconsistencies, where the reported <italic>p</italic>‐value does not match the accompanying test statistic and degrees of freedom. Statistical reporting inconsistencies are harmful for several reasons. First, these inconsistencies can lead to wrong substantive conclusions when the reported <italic>p</italic>‐value is significant whereas the recalculated <italic>p</italic>‐value is not, or vice versa. Second, statistical reporting inconsistencies can also be symptoms of deeper, underlying problems. Reporting inconsistencies, for example, could signal human error, sloppiness,<xref rid="jrsm1408-bib-0009" ref-type="ref"><sup>9</sup></xref> or questionable research practices.<xref rid="jrsm1408-bib-0010" ref-type="ref"><sup>10</sup></xref> Third, regardless of their cause, statistical inconsistencies affect the overall reproducibility of a paper: the ability to obtain the same numbers with the same data and analyses. Results that appear erroneous and that cannot be reproduced by reanalysis are unreliable and, worse, might be considered invalid.<xref rid="jrsm1408-bib-0011" ref-type="ref"><sup>11</sup></xref>
</p>
    <p>Statistical reporting inconsistencies can also affect the quality of meta‐analyses in various ways. From the perspective of the primary studies included, reported NHST results can be used to calculate effect sizes to include in a meta‐analysis: reported results of <italic>t</italic> tests or <italic>F</italic> tests can be converted to Cohen's <italic>d</italic>. However, if the results of these NHSTs are inconsistent, it is possible that the test statistics are incorrect (e.g., a typo in a <italic>t</italic>‐value). If that erroneous test statistic is then used to calculate the effect size to include in the meta‐analysis, the eventual meta‐analytic effect size will also contain error.<xref rid="jrsm1408-bib-0012" ref-type="ref"><sup>12</sup></xref> Furthermore, from the perspective of the meta‐analytic results, the reported NHSTs of meta‐analytical averages, heterogeneity tests, and moderator analyses remain widely reported and widely used when drawing conclusions. As a result, the results of these statistical tests require additional scrutiny.</p>
  </sec>
  <sec id="jrsm1408-sec-0003">
    <label>3</label>
    <title>INTRODUCING “<styled-content style="fixed-case" toggle="no">statcheck</styled-content>” AS A SOLUTION FOR META‐ANALYSES</title>
    <p>To detect statistical reporting inconsistencies, Epskamp and Nuijten<xref rid="jrsm1408-bib-0007" ref-type="ref"><sup>7</sup></xref> developed the R package <italic>statcheck</italic>, with an accompanying web app at <ext-link ext-link-type="uri" xlink:href="https://statcheck.io">https://statcheck.io</ext-link>.<xref rid="jrsm1408-bib-0013" ref-type="ref"><sup>13</sup></xref> statcheckis a free and easy‐to‐use tool that automatically extracts statistical results from articles and recomputes <italic>p</italic>‐values to check their internal consistency. <italic>statcheck</italic> was developed to check results in primary studies, and we recently extended its functionality to meta‐analyses.<xref rid="jrsm1408-bib-0008" ref-type="ref"><sup>8</sup></xref>
</p>
    <sec id="jrsm1408-sec-0004">
      <label>3.1</label>
      <title>How does statcheck work?</title>
      <p>The algorithm behind <italic>statcheck</italic> consists of four steps. First, <italic>statcheck</italic> converts an article (or a folder of articles) from PDF or HTML to plain text. Second, using regular expressions, <italic>statcheck</italic> searches for specific combinations of letters, numbers, and symbols that signal the presence of an NHST result. Polanin and Nuijten<xref rid="jrsm1408-bib-0008" ref-type="ref"><sup>8</sup></xref> updated <italic>statcheck</italic> to recognize <italic>Q</italic> tests in addition to the original recognition of <italic>t</italic>, <italic>F</italic>, <italic>χ</italic>
<sup><italic>2</italic></sup>, <italic>Z</italic>, and correlations that are reported in the full text according to APA style (e.g., <italic>t</italic>(28) = 2.14, <italic>p</italic> = .04; 14). Third, <italic>statcheck</italic> uses the reported test statistic and degrees of freedom to recalculate the <italic>p</italic>‐value. Fourth, it compares the reported and computed <italic>p</italic>‐value to see if they match. If they do not match, the result is flagged as an “inconsistency.” If the reported <italic>p</italic>‐value is significant and the computed <italic>p</italic>‐value is not, or vice versa, the result is flagged as a “gross inconsistency.” By default, <italic>statcheck</italic> assumes an <italic>α</italic> of .05, but this can be manually adjusted.</p>
      <p>In flagging inconsistencies (or gross inconsistencies), <italic>statcheck</italic> takes rounding into account. A test statistic reported as <italic>t</italic> = 2.5, for example, could correspond to actual <italic>t</italic>‐values ranging from 2.45 to 2.54. <italic>statcheck</italic> will consider all <italic>p</italic>‐values as consistent if they belong to that range of possible test statistics. <italic>statcheck</italic> can also take one‐tailed testing into account. If <italic>statcheck</italic> finds the word one‐tailed, one‐sided, or directional in the full text, <italic>and</italic> the reported <italic>p</italic>‐value would have been correct if it belonged to a one‐tailed test, <italic>statcheck</italic> flags the result as consistent.</p>
    </sec>
    <sec id="jrsm1408-sec-0005">
      <label>3.2</label>
      <title><styled-content style="fixed-case" toggle="no"><italic>statcheck</italic>'<italic>s</italic></styled-content> accuracy and limitations</title>
      <p><italic>statcheck</italic> is specifically designed to recognize and check statistics reported in APA style in full text. This means that <italic>statcheck</italic> will not recognize statistics reported with deviations from APA style. Furthermore, <italic>statcheck</italic> will often not recognize statistics reported in tables, because statistics in tables are often not fully reported (e.g., the degrees of freedom for the entire table are in the table caption, rather than next to each test statistics and <italic>p</italic>‐value).</p>
      <p><italic>statcheck</italic> can detect statistics in both PDF and HTML files. However, the conversion of PDF to plain text is less reliable than HTML to plain text. This has to do with the wide variety of typesetting and text encoding in different journals. We therefore recommend to use HTML files, where possible.</p>
      <p>In flagging (gross) inconsistencies, <italic>statcheck</italic>'s accuracy is high. In a previous study,<xref rid="jrsm1408-bib-0014" ref-type="ref"><sup>14</sup></xref>
<italic>statcheck</italic>'s performance was compared with manual coding, and it was concluded that <italic>statcheck</italic>'s sensitivity (true positive rate) and specificity (true negative rate) were high: between 85.3% and 100%, and between 96.0% and 100%, respectively, depending on the assumptions and settings. The overall accuracy of <italic>statcheck</italic> ranged from 96.2% to 99.9%. (for details, see Ref.<xref rid="jrsm1408-bib-0014" ref-type="ref"><sup>14</sup></xref>)</p>
      <p>It is important to note that statistical inconsistencies can arise when some (but not all) of the elements of a reported results are adjusted for multiple testing, post hoc testing, or possible violations of assumptions. For example, to correct for multiple testing, authors often multiply the <italic>p</italic>‐value by the number of tests performed (a procedure tantamount to a Bonferroni correction). However, such a multiplied <italic>p</italic>‐value is then no longer consistent with the original, uncorrected, test statistic, and degrees of freedom. Similar inconsistencies can arise when authors adjust for violations of the sphericity assumption by reporting corrected degrees of freedom in combination with the uncorrected test statistic and <italic>p</italic>‐value. <italic>statcheck</italic> will flag such cases as inconsistencies. To avoid inconsistencies due to statistical corrections, we recommend that authors report the fully adjusted result (ie, the corrected degrees of freedom and the accompanying corrected test statistic and <italic>p</italic>‐value), or, in the case of a Bonferroni correction, to divide their α by the number of tests performed, instead of multiplying the <italic>p</italic>‐value.</p>
    </sec>
    <sec id="jrsm1408-sec-0006">
      <label>3.3</label>
      <title>Using <styled-content style="fixed-case" toggle="no"><italic>statcheck</italic></styled-content> in <styled-content style="fixed-case" toggle="no">meta‐analyses</styled-content>
</title>
      <p>NHST results are ubiquitous in meta‐analyses.<xref rid="jrsm1408-bib-0005" ref-type="ref"><sup>5</sup></xref> It is imaginable that the high prevalence of statistical reporting inconsistencies in primary studies also translates to meta‐analyses. To test this empirically, we adapted <italic>statcheck</italic> to also pick up NHST results in meta‐analyses.<xref rid="jrsm1408-bib-0008" ref-type="ref"><sup>8</sup></xref>
</p>
      <p>The types of statistical significance test that occur most in meta‐analyses are tests of the overall effect size, tests of homogeneity and heterogeneity, subgroup analyses, and meta‐regressions. In most cases, the test statistics belonging to these analyses are <italic>Z</italic>, <italic>χ</italic>
<sup><italic>2</italic></sup>, <italic>t</italic>, and <italic>F</italic>, which <italic>statcheck</italic> could theoretically already extract. One exception is the <italic>Q</italic> test for heterogeneity. Even though the <italic>Q</italic> test follows a <italic>χ</italic>
<sup><italic>2</italic></sup>‐distribution, previous versions of <italic>statcheck</italic> would not recognize it if it is reported with the statistic <italic>Q</italic>. To solve this, we adapted <italic>statcheck</italic> to recognize <italic>Q</italic> tests as well. <italic>statcheck</italic> recognizes the following types of <italic>Q</italic> tests: identifying heterogeneity (<italic>Q</italic> omnibus), and explaining heterogeneity (<italic>Q</italic>
<sub><italic>within</italic></sub> or <italic>Q</italic>
<sub><italic>w</italic></sub>, and <italic>Q</italic>
<sub><italic>between</italic></sub> or <italic>Q</italic>
<sub><italic>b</italic></sub>).</p>
      <p>After updating <italic>statcheck</italic>, we used it to analyze 402 meta‐analyses published in the social sciences. Our sample derived from three locations used in previous meta‐reviews<xref rid="jrsm1408-bib-0001" ref-type="ref"><sup>1</sup></xref>: Campbell Collaboration reviews published on or before May 2017 (<italic>n</italic> = 135) and used in Polanin and Nuijten<xref rid="jrsm1408-bib-0002" ref-type="ref"><sup>2</sup></xref>, <xref rid="jrsm1408-bib-0008" ref-type="ref"><sup>8</sup></xref>; reviews published in the <italic>Review of Educational Research</italic> or <italic>Psychological Bulletin</italic> on or before May 2013 and used in Polanin and Pigott<xref rid="jrsm1408-bib-0005" ref-type="ref"><sup>5</sup></xref> (<italic>n</italic> = 137)<xref rid="jrsm1408-bib-0005" ref-type="ref"><sup>5</sup></xref>; and<xref rid="jrsm1408-bib-0003" ref-type="ref"><sup>3</sup></xref> reviews on intelligence and IQ, found by searching the ISI Web of Knowledge and published on or before August 2014, used in Nuijten and colleagues (2018)<xref rid="jrsm1408-bib-0015" ref-type="ref"><sup>15</sup></xref> (<italic>n</italic> = 130). The results of using <italic>statcheck</italic> on this sample revealed that, of the 87 meta‐analyses with NHST results reported in APA style in the full text, 39.1% contained at least one statistical inconsistency and 8% contained at least one gross inconsistency where the statistical conclusion may have changed. Previous analyses conducted on primary studies<xref rid="jrsm1408-bib-0006" ref-type="ref"><sup>6</sup></xref> found a greater prevalence of inconsistences (50%) and gross inconsistencies (13%); however, the prevalence of inconsistences and gross inconsistencies in our sample remains concerning. The prevalence of APA‐reported statistics is also lower and potentially problematic, because it seemed to signal a lack of any formalized or consistent reporting style. See Polanin and Nuijten<xref rid="jrsm1408-bib-0008" ref-type="ref"><sup>8</sup></xref> for a full explanation of the methods and results.</p>
    </sec>
    <sec id="jrsm1408-sec-0007">
      <label>3.4</label>
      <title>How to use <styled-content style="fixed-case" toggle="no"><italic>statcheck</italic></styled-content> in R or in a browser</title>
      <p><italic>statcheck</italic> can be used as an R package<xref rid="jrsm1408-bib-0007" ref-type="ref"><sup>7</sup></xref> or as a web app at <ext-link ext-link-type="uri" xlink:href="https://statcheck.io">https://statcheck.io</ext-link>.<xref rid="jrsm1408-bib-0013" ref-type="ref"><sup>13</sup></xref> To use the <italic>statcheck</italic> R package, you first need to download a program called Xpdf, which converts PDF files into plain text. Xpdf is free and can be downloaded from <ext-link ext-link-type="uri" xlink:href="http://www.xpdfreader.com/download.html">http://www.xpdfreader.com/download.html</ext-link>. The binaries of this program need to be added to the system path. For detailed instructions on how to do this, see the <italic>statcheck</italic> manual at <ext-link ext-link-type="uri" xlink:href="https://rpubs.com/michelenuijten/statcheckmanual">https://rpubs.com/michelenuijten/statcheckmanual</ext-link>.</p>
      <p>After Xpdf is installed, <italic>statcheck</italic> can be installed from CRAN and loaded in R as follows:<code id="jrsm1408-code-0001" xml:space="preserve" position="float" orientation="portrait">
<monospace>

install.packages(“statcheck”)

library(statcheck)


</monospace></code>
</p>
      <p><italic>statcheck</italic> can be used on a string of text, on a PDF or HTML file, or on an entire folder of PDF and/or HTML files as follows:<code id="jrsm1408-code-0002" xml:space="preserve" position="float" orientation="portrait">
<monospace>

# check a string of text

statcheck(“Qb(1) = 3.78, p &lt; .05”)



# check a PDF or HTML article

checkPDF(“C:/MyDocuments/Research/Paper1.pdf”)

checkHTML(“C:/MyDocuments/Research/Paper1.html”)



# check all PDF and HTML articles in a directory

checkdir(“C:/MyDocuments/Research”)


</monospace></code>
</p>
      <p>All the functions above will print the same type of output to the console: a data frame where each row represents an extracted statistic. The data frame contains the extracted statistics, the recomputed <italic>p</italic>‐value, whether it is a (gross) inconsistency or not, and some additional variables. Figure <xref rid="jrsm1408-fig-0001" ref-type="fig">1</xref> shows an example of the <italic>statcheck</italic> output for an article called “Paper1,” in which <italic>statcheck</italic> detected four hypothesis tests. In addition to the base analyses, the user can specify several options. It is possible, for example, to be more or less stringent with what <italic>statcheck</italic> will count as an inconsistency by accounting for one‐tailed testing, or to assume a different alpha‐level. The output includes the main variables of interest are the extracted statistic (“Raw” in the output), the computed <italic>p</italic>‐value (“Computed” in the output), and whether it is an inconsistency (“Error” in the output), or gross inconsistency (“DecisionError” in the output). Note that when “Error = TRUE,” this means that the result is inconsistent.</p>
      <fig fig-type="FIGURE" xml:lang="en" id="jrsm1408-fig-0001" orientation="portrait" position="float">
        <label>FIGURE 1</label>
        <caption>
          <p>Example of the <italic>statcheck</italic> output for an article called “Paper1” [Colour figure can be viewed at <ext-link ext-link-type="uri" xlink:href="http://wileyonlinelibrary.com">wileyonlinelibrary.com</ext-link>]</p>
        </caption>
        <graphic id="nlm-graphic-1" xlink:href="JRSM-11-574-g001"/>
      </fig>
      <p>Alternatively, a meta‐analysts could also use <italic>statcheck</italic> in a browser via <ext-link ext-link-type="uri" xlink:href="http://statcheck.io">http://statcheck.io</ext-link>.<xref rid="jrsm1408-bib-0013" ref-type="ref"><sup>13</sup></xref> This user‐friendly app requires no programming skills and merely asks the user to upload a paper to check for inconsistencies (see Figure <xref rid="jrsm1408-fig-0002" ref-type="fig">2</xref>). The app also accepts papers in .docx format in addition to PDF and HTML files, but cannot be used to check an entire directory at once.</p>
      <fig fig-type="FIGURE" xml:lang="en" id="jrsm1408-fig-0002" orientation="portrait" position="float">
        <label>FIGURE 2</label>
        <caption>
          <p>Screenshot of the <italic>statcheck</italic> web app at <ext-link ext-link-type="uri" xlink:href="http://statcheck.io">http://statcheck.io</ext-link> [Colour figure can be viewed at <ext-link ext-link-type="uri" xlink:href="http://wileyonlinelibrary.com">wileyonlinelibrary.com</ext-link>]</p>
        </caption>
        <graphic id="nlm-graphic-3" xlink:href="JRSM-11-574-g002"/>
      </fig>
      <p>Once the meta‐analyst uploads a paper via “Browse,” a more concise version of the output, compared to the R package, is displayed (see Figure <xref rid="jrsm1408-fig-0003" ref-type="fig">3</xref>). The more extensive version of the output can be downloaded in CSV format with the button in the top right corner. The output in the browser identifies the source, the statistical test, the <italic>statcheck</italic> computed <italic>p</italic>‐value, and whether the computed <italic>p</italic>‐value matches the reported <italic>p</italic>‐value. For more information on both the browser and R package versions of <italic>statcheck</italic>, please see the <italic>statcheck</italic> manual at <ext-link ext-link-type="uri" xlink:href="https://rpubs.com/michelenuijten/statcheckmanual/">https://rpubs.com/michelenuijten/statcheckmanual/</ext-link>
</p>
      <fig fig-type="FIGURE" xml:lang="en" id="jrsm1408-fig-0003" orientation="portrait" position="float">
        <label>FIGURE 3</label>
        <caption>
          <p>Screenshot of the output of the <italic>statcheck</italic> web app [Colour figure can be viewed at <ext-link ext-link-type="uri" xlink:href="http://wileyonlinelibrary.com">wileyonlinelibrary.com</ext-link>]</p>
        </caption>
        <graphic id="nlm-graphic-5" xlink:href="JRSM-11-574-g003"/>
      </fig>
    </sec>
    <sec id="jrsm1408-sec-0008">
      <label>3.5</label>
      <title>Plans for further development</title>
      <p>We routinely update <italic>statcheck</italic> to improve its performance and increase functionality. Some concrete plans for future updates include a feature on the web app to allow users to simply copy‐paste a statistical result they want to check, and the option to also check .docx files with the R package. Furthermore, a new PDF to text converter is being tested, so that users do not have to download and install the program Xpdf anymore when they want to install <italic>statcheck</italic>. The latest development can be followed on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/MicheleNuijten/statcheck">https://github.com/MicheleNuijten/statcheck</ext-link>.</p>
    </sec>
  </sec>
  <sec id="jrsm1408-sec-0009">
    <label>4</label>
    <title>RECOMMENDATIONS</title>
    <p>We make two broad recommendations for meta‐analytic practice. The first is simply that meta‐analysts should strive to report statistical results completely and systematically, preferably using widely‐adopted reporting guidelines such as the APA guidelines.<xref rid="jrsm1408-bib-0016" ref-type="ref"><sup>16</sup></xref> If researchers always report statistics in the same way, it is easier for readers to quickly filter out important information and quicker for meta‐analysts attempting to locate vital information. The second recommendation is to use <italic>statcheck</italic> as a way to double check the reporting of results. While we recognize that recommending our product serves to further the use of the product and our research, we believe that <italic>statcheck</italic>, and perhaps additional programs like it, can help decrease the number of statistical reporting errors and increase the reliability of results. Editors of journals that focus on meta‐analyses could also consider making <italic>statcheck</italic> a standard part of their peer review process (following the journals <italic>Psychological Science</italic> and the <italic>Journal of Experimental Social Psychology</italic>).</p>
    <p>Meta‐analysts can use <italic>statcheck</italic> to detect potential inconsistencies in their meta‐analysis, but also to detect inconsistencies in the primary studies they intend to include. Detecting inconsistencies in primary studies is especially relevant if the meta‐analyst needs to calculate the effect size based on reported NHST results. However, even if the effect size could be literally copied from the primary paper, it could be useful to scan a paper for statistical inconsistencies. If <italic>statcheck</italic> flags many NHST results as inconsistent, it could reflect something about the overall statistical quality of the paper. Meta‐analysts might consider recalculating the effect size from the raw data, to avoid any errors in the included effect size.</p>
  </sec>
  <sec sec-type="COI-statement" id="jrsm1408-sec-0010">
    <title>CONFLICT OF INTEREST</title>
    <p>The authors reported no conflict of interest.</p>
  </sec>
</body>
<back>
  <sec sec-type="data-availability" id="jrsm1408-sec-0012">
    <title>DATA AVAILABILITY STATEMENT</title>
    <p>Data sharing is not applicable to this article as no new data were created or analyzed in this study.</p>
  </sec>
  <ref-list id="jrsm1408-bibl-0001" content-type="cited-references">
    <title>REFERENCES</title>
    <ref id="jrsm1408-bib-0001">
      <label>1</label>
      <mixed-citation publication-type="journal" id="jrsm1408-cit-0001"><string-name><surname>Cumming</surname><given-names>G</given-names></string-name>, <string-name><surname>Fidler</surname><given-names>F</given-names></string-name>, <string-name><surname>Leonard</surname><given-names>M</given-names></string-name>, et al. <article-title>Statistical reform in psychology: is anything changing?</article-title><source xml:lang="en">Psychol Sci</source>. <year>2007</year>;<volume>18</volume>(<issue>3</issue>):<fpage>230</fpage>‐<lpage>232</lpage>.<pub-id pub-id-type="pmid">17444919</pub-id></mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0002">
      <label>2</label>
      <mixed-citation publication-type="journal" id="jrsm1408-cit-0002"><string-name><surname>Hubbard</surname><given-names>R</given-names></string-name>, <string-name><surname>Ryan</surname><given-names>PA</given-names></string-name>. <article-title>The historical growth of statistical significance testing in psychology‐and its future prospects</article-title>. <source xml:lang="en">Educ Psychol Meas</source>. <year>2000</year>;<volume>60</volume>:<fpage>661</fpage>‐<lpage>681</lpage>.</mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0003">
      <label>3</label>
      <mixed-citation publication-type="journal" id="jrsm1408-cit-0003"><string-name><surname>Sterling</surname><given-names>TD</given-names></string-name>, <string-name><surname>Rosenbaum</surname><given-names>WL</given-names></string-name>, <string-name><surname>Weinkam</surname><given-names>JJ</given-names></string-name>. <article-title>Publication decisions revisited ‐ The effect of the outcome of statistical tests on the decision to publish and vice‐versa</article-title>. <source xml:lang="en">Am Stat</source>. <year>1995</year>;<volume>49</volume>(<issue>1</issue>):<fpage>108</fpage>‐<lpage>112</lpage>.</mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0004">
      <label>4</label>
      <mixed-citation publication-type="journal" id="jrsm1408-cit-0004"><string-name><surname>Sterling</surname><given-names>TD</given-names></string-name>. <article-title>Publication decisions and their possible effects on inferences drawn from tests of significance ‐ Or vice versa</article-title>. <source xml:lang="en">J Am Stat Assoc</source>. <year>1959</year>;<volume>54</volume>:<fpage>30</fpage>‐<lpage>34</lpage>.</mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0005">
      <label>5</label>
      <mixed-citation publication-type="journal" id="jrsm1408-cit-0005"><string-name><surname>Polanin</surname><given-names>JR</given-names></string-name>, <string-name><surname>Pigott</surname><given-names>TD</given-names></string-name>. <article-title>The use of meta‐analytic statistical significance testing</article-title>. <source xml:lang="en">Res Syn Meth</source>. <year>2015</year>;<volume>6</volume>(<issue>1</issue>):<fpage>63</fpage>‐<lpage>73</lpage>.</mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0006">
      <label>6</label>
      <mixed-citation publication-type="journal" id="jrsm1408-cit-0006"><string-name><surname>Nuijten</surname><given-names>MB</given-names></string-name>, <string-name><surname>Hartgerink</surname><given-names>CHJ</given-names></string-name>, <string-name><surname>Van Assen</surname><given-names>MALM</given-names></string-name>, <string-name><surname>Epskamp</surname><given-names>S</given-names></string-name>, <string-name><surname>Wicherts</surname><given-names>JM</given-names></string-name>. <article-title>The prevalence of statistical reporting errors in psychology (1985‐2013)</article-title>. <source xml:lang="en">Behav Res Methods</source>. <year>2016</year>;<volume>48</volume>(<issue>4</issue>):<fpage>1205</fpage>‐<lpage>1226</lpage>.<pub-id pub-id-type="pmid">26497820</pub-id></mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0007">
      <label>7</label>
      <mixed-citation publication-type="miscellaneous" id="jrsm1408-cit-0007"><string-name><surname>Epskamp</surname><given-names>S</given-names></string-name>, <string-name><surname>Nuijten</surname><given-names>MB</given-names></string-name>. Statcheck: extract statistics from articles and recompute p values. R package version 1.2.2. <ext-link ext-link-type="uri" xlink:href="http://cran.r-project.org/package=statcheck">http://CRAN.R-project.org/package=statcheck</ext-link>. 2016. Accessed April 15, 2020</mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0008">
      <label>8</label>
      <mixed-citation publication-type="journal" id="jrsm1408-cit-0008"><string-name><surname>Polanin</surname><given-names>JR</given-names></string-name>, <string-name><surname>Nuijten</surname><given-names>MB</given-names></string-name>. <article-title>Verifying the accuracy of statistical significance testing in Campbell Collaboration systematic reviews through the use of the R package <italic>statcheck</italic>
</article-title>. <source xml:lang="en">Campbell Syst Rev</source>. <year>2018</year>;<volume>14</volume>(<issue>1</issue>):<fpage>1</fpage>‐<lpage>36</lpage>.</mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0009">
      <label>9</label>
      <mixed-citation publication-type="journal" id="jrsm1408-cit-0009"><string-name><surname>Schuyt</surname><given-names>CJM</given-names></string-name>, <string-name><surname>Bensing</surname><given-names>JM</given-names></string-name>, <string-name><surname>Stoop</surname><given-names>IAL</given-names></string-name>, <string-name><surname>Vandenbroucke</surname><given-names>JP</given-names></string-name>, <string-name><surname>Zwaan</surname><given-names>GJ</given-names></string-name>, <string-name><surname>Klis</surname><given-names>MBM</given-names></string-name>. <article-title>Responsible research data management and the prevention of scientific misconduct: advisory report by the Committee on Scientific Research Data</article-title>. <source xml:lang="en">R Neth Acad Arts Sci</source>. <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0010">
      <label>10</label>
      <mixed-citation publication-type="journal" id="jrsm1408-cit-0010"><string-name><surname>John</surname><given-names>LK</given-names></string-name>, <string-name><surname>Loewenstein</surname><given-names>G</given-names></string-name>, <string-name><surname>Prelec</surname><given-names>D</given-names></string-name>. <article-title>Measuring the prevalence of questionable research practices with incentives for truth‐telling</article-title>. <source xml:lang="en">Psychol Sci</source>. <year>2012</year>;<volume>23</volume>(<issue>5</issue>):<fpage>524</fpage>‐<lpage>532</lpage>.<pub-id pub-id-type="pmid">22508865</pub-id></mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0011">
      <label>11</label>
      <mixed-citation publication-type="journal" id="jrsm1408-cit-0011"><string-name><surname>Nuijten</surname><given-names>MB</given-names></string-name>, <string-name><surname>Bakker</surname><given-names>M</given-names></string-name>, <string-name><surname>Maassen</surname><given-names>E</given-names></string-name>, <string-name><surname>Wicherts</surname><given-names>JM</given-names></string-name>. <article-title>Verify original results through reanalysis before replicating: a commentary on “Making Replication Mainstream” by Rolf A. Zwaan, Alexander Etz, Richard E. Lucas, &amp; M. Brent Donnellan</article-title>. <source xml:lang="en">Behav Brain Sci</source>. <year>2018</year>;<volume>41</volume>:<elocation-id>e143</elocation-id>.<pub-id pub-id-type="pmid">31064583</pub-id></mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0012">
      <label>12</label>
      <mixed-citation publication-type="journal" id="jrsm1408-cit-0012"><string-name><surname>Bakker</surname><given-names>M</given-names></string-name>, <string-name><surname>Wicherts</surname><given-names>JM</given-names></string-name>. <article-title>The (mis)reporting of statistical results in psychology journals</article-title>. <source xml:lang="en">Behav Res Methods</source>. <year>2011</year>;<volume>43</volume>(<issue>3</issue>):<fpage>666</fpage>‐<lpage>678</lpage>.<pub-id pub-id-type="pmid">21494917</pub-id></mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0013">
      <label>13</label>
      <mixed-citation publication-type="miscellaneous" id="jrsm1408-cit-0013"><string-name><surname>Rife</surname><given-names>SC</given-names></string-name>, <string-name><surname>Epskamp</surname><given-names>S</given-names></string-name>, <string-name><surname>Nuijten</surname><given-names>MB</given-names></string-name>. statcheck: Extract statistics from articles and recompute p‐values [web application]. <ext-link ext-link-type="uri" xlink:href="https://statcheck.io">https://statcheck.io</ext-link>. 2016 April 15, 2020.</mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0014">
      <label>14</label>
      <mixed-citation publication-type="book" id="jrsm1408-cit-0014"><string-name><surname>Nuijten</surname><given-names>MB</given-names></string-name>, <string-name><surname>Van Assen</surname><given-names>MALM</given-names></string-name>, <string-name><surname>Hartgerink</surname><given-names>CHJ</given-names></string-name>, <string-name><surname>Epskamp</surname><given-names>S</given-names></string-name>, <string-name><surname>Wicherts</surname><given-names>JM</given-names></string-name>. <source xml:lang="en">The Validity of the Tool “statcheck” in Discovering Statistical Reporting Inconsistencies</source>. <year>2017</year>. Accessed April 15, 2020.</mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0015">
      <label>15</label>
      <mixed-citation publication-type="book" id="jrsm1408-cit-0015"><string-name><surname>Nuijten</surname><given-names>MB</given-names></string-name>, <string-name><surname>van Assen</surname><given-names>MALM</given-names></string-name>, <string-name><surname>Augusteijn</surname><given-names>H</given-names></string-name>, <string-name><surname>Crompvoets</surname><given-names>EAV</given-names></string-name>, <string-name><surname>Wicherts</surname><given-names>JM.</given-names></string-name><source xml:lang="en">Effect Sizes</source>, <publisher-name>Power, and Biases in Intelligence Research</publisher-name>: A Meta‐Meta‐Analysis. <year>2018</year><pub-id pub-id-type="doi">10.31234/osf.io/ytsvw</pub-id></mixed-citation>
    </ref>
    <ref id="jrsm1408-bib-0016">
      <label>16</label>
      <mixed-citation publication-type="book" id="jrsm1408-cit-0016"><collab collab-type="authors">American Psychological Association</collab>
. <source xml:lang="en">Publication Manual of the American Psychological Association</source>. <edition designator="6">6th ed.</edition>
<publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Psychological Association</publisher-name>; <year>2010</year>.</mixed-citation>
    </ref>
  </ref-list>
</back>
