<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLoS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9499272</article-id>
    <article-id pub-id-type="pmid">36094961</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1010511</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-22-00851</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Immunology</subject>
          <subj-group>
            <subject>Vaccination and Immunization</subject>
            <subj-group>
              <subject>Antiviral Therapy</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Immunology</subject>
          <subj-group>
            <subject>Vaccination and Immunization</subject>
            <subj-group>
              <subject>Antiviral Therapy</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Public and Occupational Health</subject>
          <subj-group>
            <subject>Preventive Medicine</subject>
            <subj-group>
              <subject>Vaccination and Immunization</subject>
              <subj-group>
                <subject>Antiviral Therapy</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Statistical Methods</subject>
            <subj-group>
              <subject>Forecasting</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical Methods</subject>
              <subj-group>
                <subject>Forecasting</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Oncology</subject>
          <subj-group>
            <subject>Cancer Treatment</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Pharmaceutics</subject>
          <subj-group>
            <subject>Drug Therapy</subject>
            <subj-group>
              <subject>Cardiovascular Therapy</subject>
              <subj-group>
                <subject>Antihypertensive Drug Therapy</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Immunology</subject>
          <subj-group>
            <subject>Vaccination and Immunization</subject>
            <subj-group>
              <subject>Antiparasitic Therapy</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Immunology</subject>
          <subj-group>
            <subject>Vaccination and Immunization</subject>
            <subj-group>
              <subject>Antiparasitic Therapy</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Public and Occupational Health</subject>
          <subj-group>
            <subject>Preventive Medicine</subject>
            <subj-group>
              <subject>Vaccination and Immunization</subject>
              <subj-group>
                <subject>Antiparasitic Therapy</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Physiology</subject>
          <subj-group>
            <subject>Physiological Parameters</subject>
            <subj-group>
              <subject>Body Weight</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>PrMFTP: Multi-functional therapeutic peptides prediction based on multi-head self-attention mechanism and class weight optimization</article-title>
      <alt-title alt-title-type="running-head">PrMFTP</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Yan</surname>
          <given-names>Wenhui</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Tang</surname>
          <given-names>Wending</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wang</surname>
          <given-names>Lihua</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6122-5930</contrib-id>
        <name>
          <surname>Bin</surname>
          <given-names>Yannan</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="cor001" ref-type="corresp">*</xref>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3024-1705</contrib-id>
        <name>
          <surname>Xia</surname>
          <given-names>Junfeng</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="cor001" ref-type="corresp">*</xref>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <addr-line>Information Materials and Intelligent Sensing Laboratory of Anhui Province and Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, Institutes of Physical Science and Information Technology, Anhui University, Hefei, Anhui, China</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Fariselli</surname>
          <given-names>Piero</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Universita degli Studi di Torino, ITALY</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>ynbin@ahu.edu.cn</email> (YB); <email>jfxia@ahu.edu.cn</email> (JX)</corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>12</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <volume>18</volume>
    <issue>9</issue>
    <elocation-id>e1010511</elocation-id>
    <history>
      <date date-type="received">
        <day>3</day>
        <month>6</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>24</day>
        <month>8</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 Yan et al</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Yan et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1010511.pdf"/>
    <abstract>
      <p>Prediction of therapeutic peptide is a significant step for the discovery of promising therapeutic drugs. Most of the existing studies have focused on the mono-functional therapeutic peptide prediction. However, the number of multi-functional therapeutic peptides (MFTP) is growing rapidly, which requires new computational schemes to be proposed to facilitate MFTP discovery. In this study, based on multi-head self-attention mechanism and class weight optimization algorithm, we propose a novel model called PrMFTP for MFTP prediction. PrMFTP exploits multi-scale convolutional neural network, bi-directional long short-term memory, and multi-head self-attention mechanisms to fully extract and learn informative features of peptide sequence to predict MFTP. In addition, we design a class weight optimization scheme to address the problem of label imbalanced data. Comprehensive evaluation demonstrate that PrMFTP is superior to other state-of-the-art computational methods for predicting MFTP. We provide a user-friendly web server of PrMFTP, which is available at <ext-link xlink:href="http://bioinfo.ahu.edu.cn/PrMFTP%20" ext-link-type="uri">http://bioinfo.ahu.edu.cn/PrMFTP</ext-link>.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>Therapeutic peptides possess a wide range of biological properties, including anti-cancer, anti-hypertensive, anti-viral, and so forth. This is a prerequisite to understanding functional therapeutic peptides and ultimately designing these peptides for drug discovery and development. With the number of multi-functional therapeutic peptides (MFTP) growing, predicting these peptides is an urgent problem in the development of novel peptide-based therapeutics. We develope PrMFTP, an approach for MFTP prediction based on multi-label classification. Our method uses a deep neural network and multi-head self-attention that are able to optimize the features from the peptide sequences. Furthermore, for the imbalance problem in the multi-label dataset, a novel class weight optimization scheme is used to improve the performance of PrMFTP. We evaluate our approach using example-based measures and compare it with the top-performing MLBP method as well as the SOTA multi-functional peptides prediction approaches, demonstrating the improvement of PrMFTP over the existing methods.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution>National Key Research and Development Program of China</institution>
        </funding-source>
        <award-id>2020YFA0908700</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3024-1705</contrib-id>
          <name>
            <surname>Xia</surname>
            <given-names>Junfeng</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>62072003, 11835014, U19A2064</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3024-1705</contrib-id>
          <name>
            <surname>Xia</surname>
            <given-names>Junfeng</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award003">
        <funding-source>
          <institution>Academic and Technology Leaders and Backup Candidate of Anhui Province</institution>
        </funding-source>
        <award-id>2020H237</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3024-1705</contrib-id>
          <name>
            <surname>Xia</surname>
            <given-names>Junfeng</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award004">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100018628</institution-id>
            <institution>Scientific Research Foundation of Education Department of Anhui Province of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>KJ2020A0047</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6122-5930</contrib-id>
          <name>
            <surname>Bin</surname>
            <given-names>Yannan</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>We are grateful for receiving funding from the National Key Research and Development Program of China (2020YFA0908700), the National Natural Science Foundation of China (62072003, 11835014, U19A2064), and the Project of Academic and Technology Leaders and Backup Candidate of Anhui Province (2020H237) to J.X., and the Education Department of Anhui Province (KJ2020A0047) to Y.B. The funders played no role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="4"/>
      <table-count count="3"/>
      <page-count count="16"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>PLOS Publication Stage</meta-name>
        <meta-value>vor-update-to-uncorrected-proof</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>Publication Update</meta-name>
        <meta-value>2022-09-22</meta-value>
      </custom-meta>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>The data and code are available at <ext-link xlink:href="https://github.com/xialab-ahu/PrMFTP" ext-link-type="uri">https://github.com/xialab-ahu/PrMFTP</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>The data and code are available at <ext-link xlink:href="https://github.com/xialab-ahu/PrMFTP" ext-link-type="uri">https://github.com/xialab-ahu/PrMFTP</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>1. Introduction</title>
    <p>Over the last decades, the number of peptide drug approvals has increased steadily, and the global peptide therapy market has an average growth rate of 7.7% [<xref rid="pcbi.1010511.ref001" ref-type="bibr">1</xref>]. Peptide drugs have been used to treat cancer, diabetes, HIV infection and so on [<xref rid="pcbi.1010511.ref001" ref-type="bibr">1</xref>, <xref rid="pcbi.1010511.ref002" ref-type="bibr">2</xref>]. Compared with proteins and antibodies, therapeutic peptides have many advantages as potential therapeutic drugs: low production cost, low toxicity, and room temperature storage [<xref rid="pcbi.1010511.ref003" ref-type="bibr">3</xref>]. With the development of sequencing technologies and peptide synthesis methods in the post-genome era, more and more therapeutic peptides, with two or more functional characteristics, have been found. These multi-functional therapeutic peptides (MFTP) are very important for new peptide drug design. However, traditional experimental methods to screen therapeutic peptides are expensive and time-consuming, a fast and effective computational approach could be an excellent alternative [<xref rid="pcbi.1010511.ref004" ref-type="bibr">4</xref>].</p>
    <p>Data-driven computational methods, especially machine learning (ML) methods, have been widely used in the prediction of therapeutic peptides [<xref rid="pcbi.1010511.ref005" ref-type="bibr">5</xref>–<xref rid="pcbi.1010511.ref010" ref-type="bibr">10</xref>]. Thus far, random forest, extra trees and extreme gradient boosting algorithms have successfully identified tumor homing peptide (THP) [<xref rid="pcbi.1010511.ref011" ref-type="bibr">11</xref>], anti-cancer peptide (ACP) [<xref rid="pcbi.1010511.ref012" ref-type="bibr">12</xref>], and anti-parasitic peptide (APP) [<xref rid="pcbi.1010511.ref013" ref-type="bibr">13</xref>]. Furthermore, TPpred-ATMV used BioSeq-BLM tool to extract various peptide sequence features to optimize the prediction of therapeutic peptides [<xref rid="pcbi.1010511.ref014" ref-type="bibr">14</xref>, <xref rid="pcbi.1010511.ref015" ref-type="bibr">15</xref>]. Among these traditional ML methods, suitable feature sets are very important to distinguish functional and nonfunctional peptides and achieve excellent performance. However, manual feature selection requires prior knowledge, and high-dimensional features may cause overfitting. Recently, with the development of artificial intelligence technology, the importance and advantage of deep learning (DL) methods in the field of bioinformatics have been well demonstrated [<xref rid="pcbi.1010511.ref016" ref-type="bibr">16</xref>–<xref rid="pcbi.1010511.ref021" ref-type="bibr">21</xref>]. Various DL methods have been utilized for therapeutic peptides prediction [<xref rid="pcbi.1010511.ref022" ref-type="bibr">22</xref>–<xref rid="pcbi.1010511.ref025" ref-type="bibr">25</xref>], such as Fang <italic toggle="yes">et al</italic>. proposed a predictor based on DL combined with a character embedding layer for anti-fungal peptides identification [<xref rid="pcbi.1010511.ref024" ref-type="bibr">24</xref>], Li <italic toggle="yes">et al</italic>. developed a dual-channel deep neural network (DNN) model for identifying variable-length antiviral peptides [<xref rid="pcbi.1010511.ref025" ref-type="bibr">25</xref>]. Compared with the traditional ML methods that need to extract or select features manually, the DL models can automatically learn the feature representation with limited peptide knowledge [<xref rid="pcbi.1010511.ref026" ref-type="bibr">26</xref>]. Overall, numerous methods based on ML or DL have been proposed to predict the therapeutic peptides, but most of them focused on the mono-functional peptides, and could not rapidly and efficiently identify the therapeutic peptides with two or more functional characteristics. A multi-label classification model of therapeutic peptides prediction may make up for the shortcomings.</p>
    <p>To date, many multi-label classification algorithms have been proposed [<xref rid="pcbi.1010511.ref004" ref-type="bibr">4</xref>], and they can be divided into two categories: problem transformation and algorithm adaptation. (1) Problem transformation approach transforms the multi-label learning problem into a more single-label classification [<xref rid="pcbi.1010511.ref027" ref-type="bibr">27</xref>]. For example, multi-label classification can be transformed into multiple binary classifications by binary relevance (BR) [<xref rid="pcbi.1010511.ref028" ref-type="bibr">28</xref>], or label ranking tasks by calibrated label ranking (CLR) [<xref rid="pcbi.1010511.ref029" ref-type="bibr">29</xref>]. Furthermore, the random k-labelsets method (RKL) regards each independent label subset in the multi-label dataset as a new label, and classifies the datasets with the new labels [<xref rid="pcbi.1010511.ref030" ref-type="bibr">30</xref>]. Among these three algorithms, BR is the easiest one, but ignores the correlation between labels. CLR only considers the correlation between two labels. RKL considers the correlations among labels. However, RKL turns the multi-label problem into multi-classification, which is easy to cause labels in the test set not to appear in the training set. In addition, it may increase the model complexity. (2) Algorithm adaptation approach solves the multi-label learning problem by directly processing multi-label data using popular learning technologies [<xref rid="pcbi.1010511.ref027" ref-type="bibr">27</xref>], such as we previously proposed a DL-based multi-label approach for determining the multi-functional bioactive peptides [<xref rid="pcbi.1010511.ref004" ref-type="bibr">4</xref>], and Wu <italic toggle="yes">et al</italic>. proposed robust low-rank learning of jointing ranking support vector machine and binary relevance (RBRL) for text, images, music and bioinformatics fields [<xref rid="pcbi.1010511.ref031" ref-type="bibr">31</xref>].</p>
    <p>In this study, for MFTP identification, we proposed PrMFTP, a novel multi-label predictor based on DNN and multi-head self-attention mechanism (MHSA) [<xref rid="pcbi.1010511.ref032" ref-type="bibr">32</xref>]. PrMFTP model used MHSA to optimize and filter the features extracted from the deep network layer, so as to improve the prediction performance. For the class imbalance problem in the multi-label dataset, we proposed a novel class weight optimization method to learn complex characteristics from data. Compared with resampling methods, our method changed the loss value by adding new class weights for different classes to deal with the imbalance in the data set.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>2. Materials and methods</title>
    <sec id="sec003">
      <title>2.1 Datasets</title>
      <p>In order to train and evaluate our proposed model, we constructed a benchmark MFTP dataset. As July 2021, we conducted a literature query on Google Scholar with the keyword ‘therapeutic peptide’ and obtained 22 kinds of therapeutic peptide sequence datasets. There are a total of 22 types of therapeutic peptides: AAP [<xref rid="pcbi.1010511.ref033" ref-type="bibr">33</xref>], anti-bacterial peptide (ABP) [<xref rid="pcbi.1010511.ref033" ref-type="bibr">33</xref>, <xref rid="pcbi.1010511.ref034" ref-type="bibr">34</xref>], ACP [<xref rid="pcbi.1010511.ref012" ref-type="bibr">12</xref>, <xref rid="pcbi.1010511.ref034" ref-type="bibr">34</xref>], anti-coronavirus peptide (ACVP) [<xref rid="pcbi.1010511.ref009" ref-type="bibr">9</xref>], anti-diabetic peptide (ADP) [<xref rid="pcbi.1010511.ref035" ref-type="bibr">35</xref>], anti-endotoxin peptide (AEP) [<xref rid="pcbi.1010511.ref034" ref-type="bibr">34</xref>], anti-fungal peptide (AFP) [<xref rid="pcbi.1010511.ref024" ref-type="bibr">24</xref>, <xref rid="pcbi.1010511.ref034" ref-type="bibr">34</xref>], anti-HIV peptide (AHIVP) [<xref rid="pcbi.1010511.ref034" ref-type="bibr">34</xref>], anti-hypertensive peptide (AHP) [<xref rid="pcbi.1010511.ref005" ref-type="bibr">5</xref>], anti-inflammatory peptide (AIP) [<xref rid="pcbi.1010511.ref033" ref-type="bibr">33</xref>, <xref rid="pcbi.1010511.ref036" ref-type="bibr">36</xref>], anti-MRSA peptide (AMRSAP) [<xref rid="pcbi.1010511.ref034" ref-type="bibr">34</xref>], anti-parasitic peptide (APP) [<xref rid="pcbi.1010511.ref013" ref-type="bibr">13</xref>, <xref rid="pcbi.1010511.ref034" ref-type="bibr">34</xref>], anti-tubercular peptide (ATP) [<xref rid="pcbi.1010511.ref037" ref-type="bibr">37</xref>], anti-viral peptide (AVP) [<xref rid="pcbi.1010511.ref033" ref-type="bibr">33</xref>, <xref rid="pcbi.1010511.ref034" ref-type="bibr">34</xref>], blood-brain barrier peptide (BBP) [<xref rid="pcbi.1010511.ref007" ref-type="bibr">7</xref>], biofilm-inhibitory peptide (BIP) [<xref rid="pcbi.1010511.ref008" ref-type="bibr">8</xref>, <xref rid="pcbi.1010511.ref034" ref-type="bibr">34</xref>], chemotactic peptide (CP) [<xref rid="pcbi.1010511.ref034" ref-type="bibr">34</xref>], cell-penetrating peptide (CPP) [<xref rid="pcbi.1010511.ref033" ref-type="bibr">33</xref>], dipeptidyl peptidase IV peptide (DPPIP) [<xref rid="pcbi.1010511.ref038" ref-type="bibr">38</xref>], quorum-sensing peptide (QSP) [<xref rid="pcbi.1010511.ref033" ref-type="bibr">33</xref>], surface-binding peptide (SBP) [<xref rid="pcbi.1010511.ref033" ref-type="bibr">33</xref>] and THP [<xref rid="pcbi.1010511.ref011" ref-type="bibr">11</xref>].</p>
      <p>These datasets were processed according to the three criteria: (1) the peptides with sequence contained non-standard amino acids were abandoned; (2) the peptides with sequence length less than 5bp or more than 50bp were deleted. The reason is that long peptides are generally toxic and have low stability, while very short peptide sequences do not have good activity [<xref rid="pcbi.1010511.ref039" ref-type="bibr">39</xref>]; (3) the peptides with their number less than 40 were removed. In addition, CP was abandoned since there are too few CP to be statistically significant [<xref rid="pcbi.1010511.ref034" ref-type="bibr">34</xref>]. After these processes, we combined theses therapeutic peptide data and assigned the peptides with multi-label functions. A benchmark dataset was obtained, of which 8,415 peptides belong to one functional attribute, 981 with two different functional attributes, 329 with three different functional attributes, 91 with four different functional attributes, 31 with five different functional attributes and 27 with more than five different functional attributes. The summary of different therapeutic peptide data is shown in <xref rid="pcbi.1010511.t001" ref-type="table">Table 1</xref>, and the details of the multi-label dataset are summarized in <xref rid="pcbi.1010511.s001" ref-type="supplementary-material">S1 Fig</xref>. We sampled the training set with a ratio of 80% in this dataset, whereas the remaining 20% data were applied as the test set.</p>
      <table-wrap position="float" id="pcbi.1010511.t001">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010511.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>The summary of the dataset used in this work.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1010511.t001" id="pcbi.1010511.t001g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Type</th>
                <th align="left" rowspan="1" colspan="1">Original number</th>
                <th align="left" rowspan="1" colspan="1">Final number</th>
                <th align="left" rowspan="1" colspan="1">Type</th>
                <th align="left" rowspan="1" colspan="1">Original number</th>
                <th align="left" rowspan="1" colspan="1">Final number</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">AAP</td>
                <td align="left" rowspan="1" colspan="1">135</td>
                <td align="left" rowspan="1" colspan="1">133</td>
                <td align="left" rowspan="1" colspan="1">APP</td>
                <td align="left" rowspan="1" colspan="1">319</td>
                <td align="left" rowspan="1" colspan="1">279</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">ABP</td>
                <td align="left" rowspan="1" colspan="1">2,469</td>
                <td align="left" rowspan="1" colspan="1">2,154</td>
                <td align="left" rowspan="1" colspan="1">ATP</td>
                <td align="left" rowspan="1" colspan="1">246</td>
                <td align="left" rowspan="1" colspan="1">242</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">ACP</td>
                <td align="left" rowspan="1" colspan="1">1,052</td>
                <td align="left" rowspan="1" colspan="1">1,043</td>
                <td align="left" rowspan="1" colspan="1">AVP</td>
                <td align="left" rowspan="1" colspan="1">736</td>
                <td align="left" rowspan="1" colspan="1">711</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">ACVP</td>
                <td align="left" rowspan="1" colspan="1">137</td>
                <td align="left" rowspan="1" colspan="1">126</td>
                <td align="left" rowspan="1" colspan="1">BBP</td>
                <td align="left" rowspan="1" colspan="1">119</td>
                <td align="left" rowspan="1" colspan="1">117</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">ADP</td>
                <td align="left" rowspan="1" colspan="1">509</td>
                <td align="left" rowspan="1" colspan="1">509</td>
                <td align="left" rowspan="1" colspan="1">BIP</td>
                <td align="left" rowspan="1" colspan="1">339</td>
                <td align="left" rowspan="1" colspan="1">333</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">AEP</td>
                <td align="left" rowspan="1" colspan="1">70</td>
                <td align="left" rowspan="1" colspan="1">58</td>
                <td align="left" rowspan="1" colspan="1">CPP</td>
                <td align="left" rowspan="1" colspan="1">462</td>
                <td align="left" rowspan="1" colspan="1">459</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">AFP</td>
                <td align="left" rowspan="1" colspan="1">2,324</td>
                <td align="left" rowspan="1" colspan="1">1,352</td>
                <td align="left" rowspan="1" colspan="1">DPPIP</td>
                <td align="left" rowspan="1" colspan="1">313</td>
                <td align="left" rowspan="1" colspan="1">313</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">AHIVP</td>
                <td align="left" rowspan="1" colspan="1">109</td>
                <td align="left" rowspan="1" colspan="1">101</td>
                <td align="left" rowspan="1" colspan="1">QSP</td>
                <td align="left" rowspan="1" colspan="1">220</td>
                <td align="left" rowspan="1" colspan="1">220</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">AHP</td>
                <td align="left" rowspan="1" colspan="1">948</td>
                <td align="left" rowspan="1" colspan="1">917</td>
                <td align="left" rowspan="1" colspan="1">SBP</td>
                <td align="left" rowspan="1" colspan="1">104</td>
                <td align="left" rowspan="1" colspan="1">104</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">AIP</td>
                <td align="left" rowspan="1" colspan="1">2,049</td>
                <td align="left" rowspan="1" colspan="1">2,049</td>
                <td align="left" rowspan="1" colspan="1">THP</td>
                <td align="left" rowspan="1" colspan="1">651</td>
                <td align="left" rowspan="1" colspan="1">651</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">AMRSAP</td>
                <td align="left" rowspan="1" colspan="1">173</td>
                <td align="left" rowspan="1" colspan="1">168</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Total</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>11,142</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>9,841</bold>
                </td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec id="sec004">
      <title>2.2 PrMFTP framework</title>
      <p>The framework of PrMFTP is shown in <xref rid="pcbi.1010511.g001" ref-type="fig">Fig 1</xref>, which consists of five layers: input layer, embedding layer, DNN layer, MHSA layer, and classification layer. The details of these layers are described as follows:</p>
      <fig position="float" id="pcbi.1010511.g001">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010511.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>The framework of PrMFTP.</title>
          <p>First, peptide sequences are encoded as an input vector using numbers, and converted into a fixed-size matrix through the embedding layer. Second, DNN layer, a combination of multi-scale CNN and BiLSTM architectures, is used to capture the sequence features. Third, multi-head self-attention mechanism (MSHA) is used to make the model attend the more important and discriminating sequence features for prediction of multi-functional therapeutic peptides. Finally, the resulting feature matrix is fed into a classification layer and applied to score the different therapeutic peptides to achieve the predicted result.</p>
        </caption>
        <graphic xlink:href="pcbi.1010511.g001" position="float"/>
      </fig>
    </sec>
    <sec id="sec005">
      <title>Input layer</title>
      <p>This layer encoded peptide sequence into a digital vector. The peptide sequences consisted of 20 standard amino acids {A, C, D, E, F, G, H, I, M, N, P, Q, R, S, T, V, W, Y}, and these amino acids were encoded into nature numbers {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20}, respectively. In our benchmark dataset, the length of the peptide sequences varied from 5 bp (the minimum length) to 50 bp (the maximum length), but the model could only process peptide sequences with a fixed dimension. Therefore, if the length of a peptide sequence is less than 50 bp, the pad ones were set to 0.</p>
    </sec>
    <sec id="sec006">
      <title>Embedding layer</title>
      <p>Through the embedding layer, the sequence vector obtained from the input layer was transformed into a dense continuous feature vector. The embedding layer algorithm encapsulated as much information in the peptide sequence text as possible into the vector space [<xref rid="pcbi.1010511.ref040" ref-type="bibr">40</xref>]. Finally, the peptide sequence was represented by the embedding matrix, which was used as the input matrix to DNN layer.</p>
    </sec>
    <sec id="sec007">
      <title>DNN layer</title>
      <p>The DNN layer consisted of a multi-scale convolutional neural network (CNN) and bi-directional long short-term memory (BiLSTM). Firstly, the multi-scale convolutional layer was used to extract the semantic features of the sequence. To obtain more comprehensive features, the convolution windows with sizes 2, 3 and 8 were used to extract the peptide features of different sequence lengths. Then, with the convolution feature matrix, the maximum pooling operation was used to reduce the number of features and prevent over-fitting. Secondly, feature matrix extracted from CNN was used as the input matrix to BiLSTM. We used BiLSTM to extract the hidden information in sequences, and it can also achieve long-dependent sequence information. The core of BiLSTM was to use memory cells to remember long-term historical information that could be impressed with memory cells and managed with a door mechanism. The door structure was used to limit the amount of information. BiLSTM effectively captured the relationship between the properties of the sequence in the forward and backward directions to obtain global information from the sequences [<xref rid="pcbi.1010511.ref041" ref-type="bibr">41</xref>]. Finally, sequence feature matrix extracted from BiLSTM was used as the input matrix to MHSA layer.</p>
    </sec>
    <sec id="sec008">
      <title>MHSA layer</title>
      <p>MHSA was proposed to focus attention on different parts of the peptide sequence. Therefore, in our model architecture, MHSA layer further optimized the sequence features filtered by DNN layer to capture evolutionary features. MHSA was composed of multiple self-attention (SA) mechanisms, which were used to represent the context of learning sequences. The mathematical description of SA is as follows:
<disp-formula id="pcbi.1010511.e001"><alternatives><graphic xlink:href="pcbi.1010511.e001.jpg" id="pcbi.1010511.e001g" position="anchor"/><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:msup><mml:mrow><mml:mo>*</mml:mo><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mo>*</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:msup><mml:mrow><mml:mo>*</mml:mo><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives><label>(1)</label></disp-formula>
<disp-formula id="pcbi.1010511.e002"><alternatives><graphic xlink:href="pcbi.1010511.e002.jpg" id="pcbi.1010511.e002g" position="anchor"/><mml:math id="M2" display="block" overflow="scroll"><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mrow><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>Q</mml:mi><mml:mo>*</mml:mo><mml:msup><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msqrt><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mi>V</mml:mi></mml:math></alternatives><label>(2)</label></disp-formula>
where <inline-formula id="pcbi.1010511.e003"><alternatives><graphic xlink:href="pcbi.1010511.e003.jpg" id="pcbi.1010511.e003g" position="anchor"/><mml:math id="M3" display="inline" overflow="scroll"><mml:mi>F</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> is the output matrix of DNN layer, and <inline-formula id="pcbi.1010511.e004"><alternatives><graphic xlink:href="pcbi.1010511.e004.jpg" id="pcbi.1010511.e004g" position="anchor"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> are the query, key and value matrix, respectively. These matrixes are obtained by <italic toggle="yes">F</italic> through a linear transformation with <inline-formula id="pcbi.1010511.e005"><alternatives><graphic xlink:href="pcbi.1010511.e005.jpg" id="pcbi.1010511.e005g" position="anchor"/><mml:math id="M5" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>, here <italic toggle="yes">d</italic><sub><italic toggle="yes">m</italic></sub> is twice the dimensionality of the BiLSTM hidden layer, <italic toggle="yes">d</italic><sub><italic toggle="yes">k</italic></sub> is the dimension of the query, key or value vector and <italic toggle="yes">L</italic> is the length of an input sequence.</p>
      <p>Based on the SA mechanism, the linear matrix was changed from one set (<italic toggle="yes">W</italic><sup><italic toggle="yes">Q</italic></sup>, <italic toggle="yes">W</italic><sup><italic toggle="yes">K</italic></sup>, <italic toggle="yes">W</italic><sup><italic toggle="yes">V</italic></sup>) to multiple sets {<inline-formula id="pcbi.1010511.e006"><alternatives><graphic xlink:href="pcbi.1010511.e006.jpg" id="pcbi.1010511.e006g" position="anchor"/><mml:math id="M6" display="inline" overflow="scroll"><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, …, <inline-formula id="pcbi.1010511.e007"><alternatives><graphic xlink:href="pcbi.1010511.e007.jpg" id="pcbi.1010511.e007g" position="anchor"/><mml:math id="M7" display="inline" overflow="scroll"><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>}. Different randomly initialized linear matrices (<italic toggle="yes">W</italic><sup><italic toggle="yes">Q</italic></sup>, <italic toggle="yes">W</italic><sup><italic toggle="yes">K</italic></sup>, <italic toggle="yes">W</italic><sup><italic toggle="yes">V</italic></sup>) can map input vectors to different subspaces, allowing the model to understand input information from different spatial dimensions. Therefore, the mathematical description of MHSA is as follows:
<disp-formula id="pcbi.1010511.e008"><alternatives><graphic xlink:href="pcbi.1010511.e008.jpg" id="pcbi.1010511.e008g" position="anchor"/><mml:math id="M8" display="block" overflow="scroll"><mml:msub><mml:mrow><mml:mi>H</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>Q</mml:mi><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>V</mml:mi><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:math></alternatives><label>(3)</label></disp-formula>
<disp-formula id="pcbi.1010511.e009"><alternatives><graphic xlink:href="pcbi.1010511.e009.jpg" id="pcbi.1010511.e009g" position="anchor"/><mml:math id="M9" display="block" overflow="scroll"><mml:mi>M</mml:mi><mml:mi>H</mml:mi><mml:mi>S</mml:mi><mml:mi>A</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>Q</mml:mi><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:mi>V</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi></mml:mrow></mml:msup><mml:mo>*</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives><label>(4)</label></disp-formula>
where <inline-formula id="pcbi.1010511.e010"><alternatives><graphic xlink:href="pcbi.1010511.e010.jpg" id="pcbi.1010511.e010g" position="anchor"/><mml:math id="M10" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>Q</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> are the query, key and value matrixes of the <italic toggle="yes">i</italic>-th head, respectively, <italic toggle="yes">h</italic> is the size of heads and <inline-formula id="pcbi.1010511.e011"><alternatives><graphic xlink:href="pcbi.1010511.e011.jpg" id="pcbi.1010511.e011g" position="anchor"/><mml:math id="M11" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>h</mml:mi><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> is a linear transformation matrix to map the output of MHSA to the space of the same dimension.</p>
    </sec>
    <sec id="sec009">
      <title>Classification layer</title>
      <p>We used the full connection layer as the classification layer. The vector from the fully connected layer was used as the input of the output layer. In the multi-label problem, the probability of each node was independent with each other, and binary cross-entropy was used as the loss function. Taking sigmoid as the activation function, the score of each node between 0 and 1 was obtained. Finally, we used the threshold of 0.5 to get the prediction label of each category.</p>
    </sec>
    <sec id="sec010">
      <title>2.3 Class weights</title>
      <p>In this work, the multi-label dataset is imbalanced, in which some therapeutic peptides are very frequent (for example, the number of therapeutic peptide in the largest class (ABP) is 2,154), while others are quite rare (for example, the number in the smallest one (AEP) is 58). Therefore, we proposed a class weight optimization method to add class weights to different labels, with the prupose of overcoming the imbalanced problem. We named this novel calculation method as CW, and its mathematical description is as follows:
<disp-formula id="pcbi.1010511.e012"><alternatives><graphic xlink:href="pcbi.1010511.e012.jpg" id="pcbi.1010511.e012g" position="anchor"/><mml:math id="M12" display="block" overflow="scroll"><mml:mi mathvariant="normal">C</mml:mi><mml:mi mathvariant="normal">W</mml:mi><mml:mo>:</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>φ</mml:mi><mml:mo>*</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="italic">log</mml:mi></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msup></mml:math></alternatives><label>(5)</label></disp-formula>
where <italic toggle="yes">W</italic><sub><italic toggle="yes">i</italic></sub> is the weight of the <italic toggle="yes">i</italic>-th class, <italic toggle="yes">N</italic> is the total number of instances in the training set, <italic toggle="yes">n</italic><sub><italic toggle="yes">i</italic></sub> is the number of instances that are associated with the <italic toggle="yes">i</italic>-th class, <italic toggle="yes">φ</italic> is a hyperparameter whose purpose is to increase the loss value of the model by doubling the label weight of each category, and θ is a constant, and its constraints are as shown in Formula (<xref rid="pcbi.1010511.e013" ref-type="disp-formula">6</xref>):
<disp-formula id="pcbi.1010511.e013"><alternatives><graphic xlink:href="pcbi.1010511.e013.jpg" id="pcbi.1010511.e013g" position="anchor"/><mml:math id="M13" display="block" overflow="scroll"><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>θ</mml:mi><mml:mo>≤</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="italic">ln</mml:mi></mml:mrow><mml:mspace width="0.25em"/><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="italic">ln</mml:mi></mml:mrow><mml:mspace width="0.25em"/><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="italic">ln</mml:mi></mml:mrow><mml:mspace width="0.25em"/><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="italic">log</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mspace width="0.25em"/><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:math></alternatives><label>(6)</label></disp-formula>
where <italic toggle="yes">X</italic> is obtained by dividing <italic toggle="yes">N</italic> by the minimum value of <italic toggle="yes">n</italic><sub><italic toggle="yes">i</italic></sub>, and <italic toggle="yes">Y</italic> is obtained by <italic toggle="yes">N</italic> by maximum value of <italic toggle="yes">n</italic><sub><italic toggle="yes">i</italic></sub>.</p>
    </sec>
    <sec id="sec011">
      <title>2.4 Performance metrics</title>
      <p>As illustrated in the previous works on multi-label classifications [<xref rid="pcbi.1010511.ref042" ref-type="bibr">42</xref>–<xref rid="pcbi.1010511.ref044" ref-type="bibr">44</xref>], several evaluation indexes have been proposed to evaluate the model performance. In this work, the performance of our proposed multi-label models is estimated by Precision, Coverage, Accuracy, Absolute true, and Absolute false. The mathematical description of these measurements is as follows:
<disp-formula id="pcbi.1010511.e014"><alternatives><graphic xlink:href="pcbi.1010511.e014.jpg" id="pcbi.1010511.e014g" position="anchor"/><mml:math id="M14" display="block" overflow="scroll"><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">Precision</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mfrac><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">⋂</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">Coverage</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mfrac><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">⋂</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">Accuracy</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mfrac><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">⋂</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">⋃</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>Absolute</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">true</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">Absolute</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">false</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mfrac><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">⋃</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow><mml:mo>‖</mml:mo><mml:mo>−</mml:mo><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">⋂</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives></disp-formula>
where <italic toggle="yes">N</italic> is the total number of multi-functional therapeutic peptide sequences in the datasets, <italic toggle="yes">M</italic> represents the number of labels, that is the function types of therapeutic peptides ∩/∪ denotes the intersect/union in the set theory, ‖∙‖ indicates the operation of calculating the number of elements, <italic toggle="yes">L</italic><sub><italic toggle="yes">i</italic></sub> represents the subset of the <italic toggle="yes">i</italic>-th sample with real labels, and <inline-formula id="pcbi.1010511.e015"><alternatives><graphic xlink:href="pcbi.1010511.e015.jpg" id="pcbi.1010511.e015g" position="anchor"/><mml:math id="M15" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> represents the subset of the <italic toggle="yes">i</italic>-th sample with labels predicted and
<disp-formula id="pcbi.1010511.e016"><alternatives><graphic xlink:href="pcbi.1010511.e016.jpg" id="pcbi.1010511.e016g" position="anchor"/><mml:math id="M16" display="block" overflow="scroll"><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.25em"/><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives></disp-formula>
statistical significance of differences between methods is quantified with the t-test.</p>
    </sec>
    <sec id="sec012">
      <title>2.5 Implementation details</title>
      <p>Our prediction model was implemented using Tensorflow 1.12.0 and Keras 2.2.4. In the computer with an Intel(R) Xeon(R) <email>CPU@2.20GHz</email> and NVIDIA Titan XP GPU, it took about 2 hours to train the PrMFTP model, and PrMFTP took about 600 seconds for multi-functional therapeutic peptides prediction on test set. It is generally known that the performance of the DL model was affected by some hyperparameters, such as learning rate, number of hidden layers, and dropout regularization [<xref rid="pcbi.1010511.ref045" ref-type="bibr">45</xref>]. These hyperparameters were optimized by grid search on the training set with 5-fold cross-validation to achieve an optimal model as shown in <xref rid="pcbi.1010511.s003" ref-type="supplementary-material">S1 Table</xref>. In the DNN layer, CNN was constructed using the Conv1D function in Keras. To extract the features of peptide sequences with different lengths, three convolutional kernel sizes ks ∈ {2, 3, 8} were selected. Then, we trained our model with Adam optimizer, batch size = 64 and epochs = 60. To eliminate the effects induced by the random initialization of the DL framework, we repeated the training of all models ten times, and the average scores were obtained as the final predicted results for a test sample.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec013">
    <title>3. Results and discussion</title>
    <sec id="sec014">
      <title>3.1 Comparison of multi-label models using classical ML and DL methods</title>
      <p>To achieve a high-effective model for multi-label therapeutic peptides prediction, we compared the performance of these models based on different classical ML methods (such as BR [<xref rid="pcbi.1010511.ref028" ref-type="bibr">28</xref>], CLR [<xref rid="pcbi.1010511.ref029" ref-type="bibr">29</xref>], random k-labelsets multi-label classification (RAKEL) [<xref rid="pcbi.1010511.ref042" ref-type="bibr">42</xref>] and RBRL [<xref rid="pcbi.1010511.ref031" ref-type="bibr">31</xref>]) and DL models (such as CNN, BiLSTM, CNN+BiLSTM, CNN+BiLSTM+SA). To ensure the fairness of model comparison, during the training processes for other ML and DL models, we employed two strategies: (1) the peptide sequences were uniformly encoded into digital vectors with a fixed dimension and served as input vectors for all models, and (2) we applied hyperparameter optimization for other ML and DL methods using a grid search method on the training with five-fold cross-validation. The classification performance of these models on the training set is presented in <xref rid="pcbi.1010511.g002" ref-type="fig">Fig 2</xref> and <xref rid="pcbi.1010511.s004" ref-type="supplementary-material">S2 Table</xref>. As the more important metrics for multi-label classification evaluation, Accuracy and Absolute true were used to select the more perfect model. <xref rid="pcbi.1010511.g002" ref-type="fig">Fig 2</xref> shows the average value of Accuracy and Absolute true on the training set, and we can see that CNN+BiLSTM+MHSA model has the best performance compared with other models. <xref rid="pcbi.1010511.s004" ref-type="supplementary-material">S2 Table</xref> shows that our model (CNN+BiLSTM+MHSA) is significantly on the training set with 5-fold cross-validation. CNN and BiLSTM in the DNN layer are used for local and global feature extraction, meanwhile, MHSA is used for further feature filtering. In addition, the performance of models based on DL is generally higher than that of models using classical ML. DL model automatically extracts the implicit feature information of peptide sequence to improve the performance of the model.</p>
      <fig position="float" id="pcbi.1010511.g002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010511.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Accuracy and Absolute true of multi-label therapeutic peptides prediction models using different classical ML and DL algorithms on the training set with 5-fold cross-validation.</title>
        </caption>
        <graphic xlink:href="pcbi.1010511.g002" position="float"/>
      </fig>
      <p>The performance of these models on the test set is shown in <xref rid="pcbi.1010511.t002" ref-type="table">Table 2</xref>, which is similar with that on the training set. Compared with models based on CNN, BiLSTM and CNN+BiLSTM, our CNN+BiLSTM+MHSA model has 4.8% higher for Accuracy and 5.2% higher for Absolute true on the test set. Our model used the MHSA to optimize the feature matrix extracted from DNN layer. Compared with SA, the Accuracy and Absolute true of the model are improved by 3.8% and 3.7%, respectively. Therefore, we applied CNN+BiLSTM+MHSA model for multi-functional therapeutic peptides prediction.</p>
      <table-wrap position="float" id="pcbi.1010511.t002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010511.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>The performance of multi-label therapeutic peptides prediction models on the test set.</title>
          <p>The highest value is highlighted in bold.</p>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1010511.t002" id="pcbi.1010511.t002g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Model</th>
                <th align="left" rowspan="1" colspan="1">Precision ↑</th>
                <th align="left" rowspan="1" colspan="1">Coverage ↑</th>
                <th align="left" rowspan="1" colspan="1">Accuracy ↑</th>
                <th align="left" rowspan="1" colspan="1">Absolute true ↑</th>
                <th align="left" rowspan="1" colspan="1">Absolute false ↓</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">BR</td>
                <td align="left" rowspan="1" colspan="1">0.427</td>
                <td align="left" rowspan="1" colspan="1">0.437</td>
                <td align="left" rowspan="1" colspan="1">0.394</td>
                <td align="left" rowspan="1" colspan="1">0.325</td>
                <td align="left" rowspan="1" colspan="1">0.050</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">CLR</td>
                <td align="left" rowspan="1" colspan="1">0.418</td>
                <td align="left" rowspan="1" colspan="1">0.428</td>
                <td align="left" rowspan="1" colspan="1">0.387</td>
                <td align="left" rowspan="1" colspan="1">0.320</td>
                <td align="left" rowspan="1" colspan="1">0.047</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">RAKEL</td>
                <td align="left" rowspan="1" colspan="1">0.349</td>
                <td align="left" rowspan="1" colspan="1">0.317</td>
                <td align="left" rowspan="1" colspan="1">0.307</td>
                <td align="left" rowspan="1" colspan="1">0.265</td>
                <td align="left" rowspan="1" colspan="1">0.052</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">RBRL</td>
                <td align="left" rowspan="1" colspan="1">0.513</td>
                <td align="left" rowspan="1" colspan="1">0.507</td>
                <td align="left" rowspan="1" colspan="1">0.478</td>
                <td align="left" rowspan="1" colspan="1">0.426</td>
                <td align="left" rowspan="1" colspan="1">0.057</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">CNN</td>
                <td align="left" rowspan="1" colspan="1">0.456</td>
                <td align="left" rowspan="1" colspan="1">0.410</td>
                <td align="left" rowspan="1" colspan="1">0.406</td>
                <td align="left" rowspan="1" colspan="1">0.366</td>
                <td align="left" rowspan="1" colspan="1">0.042</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">BiLSTM</td>
                <td align="left" rowspan="1" colspan="1">0.572</td>
                <td align="left" rowspan="1" colspan="1">0.532</td>
                <td align="left" rowspan="1" colspan="1">0.522</td>
                <td align="left" rowspan="1" colspan="1">0.472</td>
                <td align="left" rowspan="1" colspan="1">0.037</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">CNN+BiLSTM</td>
                <td align="left" rowspan="1" colspan="1">0.563</td>
                <td align="left" rowspan="1" colspan="1">0.509</td>
                <td align="left" rowspan="1" colspan="1">0.505</td>
                <td align="left" rowspan="1" colspan="1">0.458</td>
                <td align="left" rowspan="1" colspan="1">0.037</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">CNN+BiLSTM+SA</td>
                <td align="left" rowspan="1" colspan="1">0.589</td>
                <td align="left" rowspan="1" colspan="1">0.535</td>
                <td align="left" rowspan="1" colspan="1">0.532</td>
                <td align="left" rowspan="1" colspan="1">0.487</td>
                <td align="left" rowspan="1" colspan="1">0.036</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">CNN+BiLSTM+MHSA (our model)</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.626</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.574</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.570</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.524</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.034</bold>
                </td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec id="sec015">
      <title>3.2 Comparison with classical algorithms for solving the problem of imbalanced data classification</title>
      <p>Considering the high imbalanced level in the benchmark dataset, the undersampling method is easy to cause the loss of label information, especially the peptides with multiple labels. The oversampling method increases the size of peptide data with a small numbers, but it may affect other labels and lead to overfitting [<xref rid="pcbi.1010511.ref046" ref-type="bibr">46</xref>]. As a cost-sensitive approach, class weight optimization has been used to handle the imbalanced problem in the multi-label dataset [<xref rid="pcbi.1010511.ref047" ref-type="bibr">47</xref>]. In the previous studies, two methods [<xref rid="pcbi.1010511.ref048" ref-type="bibr">48</xref>] [<xref rid="pcbi.1010511.ref046" ref-type="bibr">46</xref>] have been proposed and applied to improve the multi-label classification performance (here we called these methods as CW1 and CW2, respectively). Considering the successes of CW1 and CW2, we employed these two class weight optimization methods in this study. In addition, we proposed CW as the third method. To estimate the improvement based on these three methods, we compared the values of Accuracy and Absolute true among the base model with different class weight optimization methods (CW1, CW2, and CW) on the same test subsets. We randomly extracted 80% of the test set results and repeated them five times to obtain five test subsets. The average values of Accuracy and Absolute true on the test set is shown in <xref rid="pcbi.1010511.g003" ref-type="fig">Fig 3</xref>, and the other metrics of the predicted results on the test set are in <xref rid="pcbi.1010511.s005" ref-type="supplementary-material">S3 Table</xref>. The results indicate that the model base+CW is superior to the other base models (base, base+CW1, base+CW2), and achieves the highest performance improvement.</p>
      <fig position="float" id="pcbi.1010511.g003">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010511.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>The performance comparison of the base (CNN+BiLSTM+MHSA) model with different algorithms for solving the problem of imbalanced data classification on the test set.</title>
          <p>A. Accuracy; B. Absolute true. Base+CW (our model) is significantly better at P-value &lt; 0.001 (t-test).</p>
        </caption>
        <graphic xlink:href="pcbi.1010511.g003" position="float"/>
      </fig>
      <p>The performance of these models is associated with class weight values, so we investigated the distribution of the class weight values of CW1, CW2 and CW methods for each label of therapeutic peptides. The class weights calculated by different methods are shown in <xref rid="pcbi.1010511.s002" ref-type="supplementary-material">S2 Fig</xref>. Comparing with the CW1 and CW2 methods, the CW method makes the value range of class weights and the difference among these class weights in relatively reasonable regions. Moreover, we can find the optimal depth learning parameters in the process of model training by increasing the weight of each class. Compared with CW2 and CW, CW1 set a higher weight for the classes with the smaller numbers. It will result in the decline of the overall performance of the model. By comparing the base+CW2 and base+CW models with the base model, it can be seen that the method of adding class weight can deal with the imbalance of multi-label data, and improve the performance. Finally, the base model combined with CW, named PrMFTP, was used for multi-functional therapeutic peptides prediction.</p>
      <p>To further verify the superiority of CW method, MLSMOTE [<xref rid="pcbi.1010511.ref049" ref-type="bibr">49</xref>], a variation of SMOTE for multi-label sets, has been used to compare with our CW method. The results are shown in <xref rid="pcbi.1010511.s005" ref-type="supplementary-material">S3 Table</xref>, and it is found that CW method achieves better performance(Precision = 0.699, Coverage = 0.669, Accuracy = 0.651, Absolute true = 0.593 and Absolute false = 0.031)than MLSMOTE (Precision = 0.638, Coverage = 0.606, Accuracy = 0.591, Absolute true = 0.536 and Absolute false = 0.033) on the test set. As an oversampling method, MLSMOTE can increase the data size of minority labels, but may affect other labels and lead to overfitting. As a cost-sensitive method, CW considers higher costs for the misclassification of minority classes to handle the multi-label imbalanced data and improve the model performance.</p>
    </sec>
    <sec id="sec016">
      <title>3.3 Performance comparison of PrMFTP with the existing methods</title>
      <p>At present, there are few methods to predict the MFTP, including TP-MV [<xref rid="pcbi.1010511.ref050" ref-type="bibr">50</xref>], MLBP. Although TP-MV is a therapeutic peptides prediction, PrMFTP cannot compare with this method. It is because that TP-MV used binary relevance to transform the multi-label task to more binary problems for specific functional peptides prediction. Our PrMFTP applied algorithm adaptation to construct a general model effectively and could be used for any functional peptide identification. Given abovementioned reason, we compared PrMFTP with MLBP, not TP-MV.</p>
      <p>MLBP based on multi-label DL method, MLBP was used to identify the multi-functional peptides of bioactive peptides, which can simultaneously predict multiple functional peptides including ACP, ADP, AHP, AIP, and AMP [<xref rid="pcbi.1010511.ref004" ref-type="bibr">4</xref>]. To further evaluate the performance of PrMFTP, we compared PrMFTP with MLBP. To ensure the fairness of the comparison, we retrained the model MLBP on our training set and compared the performance on the same test subsets. We randomly extracted 80% of the test set results and repeated them five times to obtain five test subsets. The average value of Precision, Coverage, Accuracy, Absolute true, and Absolute false for the five test subsets are shown in <xref rid="pcbi.1010511.g004" ref-type="fig">Fig 4</xref>. The result indicates that PrMFTP is superior to MLBP on all evaluation metrics. For example, Accuracy and Absolute true of PrMFTP were increased by 16.0% and 14.8%, respectively. It was noteworthy that MHSA in the PrMFTP model could further filter and optimize the features, and PrMFTP solved the problem of data imbalance through the optimization of class weight to improve the prediction performance of the model. To sum up, PrMFTP has a comparatively excellent performance.</p>
      <fig position="float" id="pcbi.1010511.g004">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010511.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>Performance comparison of MLBP and PrMFTP.</title>
          <p>A. Precision, Coverage, Accuracy and Absolute true; B. Absolute false. **** mean that PrMFTP is significantly better at P-value &lt; 0.0001 (t-test).</p>
        </caption>
        <graphic xlink:href="pcbi.1010511.g004" position="float"/>
      </fig>
    </sec>
    <sec id="sec017">
      <title>3.4 Ablation study</title>
      <p>According to the comparison of PrMFTP and MLBP (<xref rid="pcbi.1010511.g004" ref-type="fig">Fig 4</xref>), we discovered the importance of MHSA and class weight optimization on performance improvement. To further investigate the importance of multi-scale CNN, BiLSTM, MHSA, and CW in PrMFTP, we illustrated the role of these components through ablation experiments and compared the following variants of PrMFTP:</p>
      <list list-type="bullet">
        <list-item>
          <p>w/o CNN is a variant that does not use multi-scale CNN.</p>
        </list-item>
        <list-item>
          <p>w/o BiLSTM is a variant that does not use BiLSTM.</p>
        </list-item>
        <list-item>
          <p>w/o MHSA is a variant that does not use MHSA.</p>
        </list-item>
        <list-item>
          <p>w/o CW is a variant that does not use CW.</p>
        </list-item>
      </list>
      <p><xref rid="pcbi.1010511.t003" ref-type="table">Table 3</xref> shows the performance of PrMFTP and their variants on the performance on the same test subsets. We randomly extracted 80% of the test set results and repeated them five times to obtain five test subsets. As seen, the removal of any module in PrMFTP would induce the performance decreases. This result illustrates that each module is crucial to PrMFTP’s performance. On the test set, the performance of the w/o BiLSTM model decreased most drastically, and the Accuracy and Absolute true decreased by 9.4% and 8.7%, respectively, followed by the w/o CNN model (the Accuracy and Absolute true decreased by 7.5% and 7.4%, respectively), the w/o CW model (the Accuracy and Absolute true decreased by 8.0% and 6.9%, respectively), and the w/o MHSA model (the Accuracy and Absolute true decreased by 3.0% and 3.5%, respectively). Comparing the results of the w/o CW, w/o BiLSTM, and PrMFTP models, the features extracted by the DL layer are conducive to improving the prediction performance of the model. Comparing the results of w/o CW and PrMFTP models, adding class weights is beneficial to improve the performance of the model. Removing MHSA leads to the performance degradation of the model, which shows that MHSA can optimize the extracted features and improve the performance of the model.</p>
      <table-wrap position="float" id="pcbi.1010511.t003">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1010511.t003</object-id>
        <label>Table 3</label>
        <caption>
          <title>The performance of PrMFTP and their variants on the test set.</title>
          <p>The highest value is highlighted in bold. w/o is abbreviation of without. The mean ± standard deviation on 5-fold cross-validation is shown for models. *, **, *** and **** mean that PrMFTP is significantly better at P-value &lt; 0.05, P-value &lt; 0.01, P-value &lt; 0.001 and P-value &lt; 0.0001 (t-test), respectively.</p>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1010511.t003" id="pcbi.1010511.t003g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Model</th>
                <th align="left" rowspan="1" colspan="1">Precision ↑</th>
                <th align="left" rowspan="1" colspan="1">Coverage ↑</th>
                <th align="left" rowspan="1" colspan="1">Accuracy ↑</th>
                <th align="left" rowspan="1" colspan="1">Absolute true ↑</th>
                <th align="left" rowspan="1" colspan="1">Absolute false ↓</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">PrMFTP</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.699±0.004</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.669±0.004</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.651±0.004</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.593±0.004</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.031±0.001</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">w/o CNN</td>
                <td align="left" rowspan="1" colspan="1">0.618±0.006****</td>
                <td align="left" rowspan="1" colspan="1">0.598±0.006****</td>
                <td align="left" rowspan="1" colspan="1">0.576±0.006****</td>
                <td align="left" rowspan="1" colspan="1">0.519±0.006****</td>
                <td align="left" rowspan="1" colspan="1">0.033±0.001***</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">w/o BiLSTM</td>
                <td align="left" rowspan="1" colspan="1">0.605±0.005****</td>
                <td align="left" rowspan="1" colspan="1">0.573±0.005****</td>
                <td align="left" rowspan="1" colspan="1">0.557±0.004****</td>
                <td align="left" rowspan="1" colspan="1">0.504±0.004****</td>
                <td align="left" rowspan="1" colspan="1">0.034±0.001****</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">w/o MHSA</td>
                <td align="left" rowspan="1" colspan="1">0.660±0.002****</td>
                <td align="left" rowspan="1" colspan="1">0.651±0.002****</td>
                <td align="left" rowspan="1" colspan="1">0.621±0.003****</td>
                <td align="left" rowspan="1" colspan="1">0.558±0.004****</td>
                <td align="left" rowspan="1" colspan="1">0.032±0.001*</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">w/o CW</td>
                <td align="left" rowspan="1" colspan="1">0.629±0.004****</td>
                <td align="left" rowspan="1" colspan="1">0.574±0.005****</td>
                <td align="left" rowspan="1" colspan="1">0.571±0.005****</td>
                <td align="left" rowspan="1" colspan="1">0.524±0.007****</td>
                <td align="left" rowspan="1" colspan="1">0.035±0.001****</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec id="sec018">
      <title>3.5 The PrMFTP web server</title>
      <p>To facilitate the pre-screening of therapeutic peptides by researchers, we established a user-friendly web server for the PrMFTP model (<ext-link xlink:href="http://bioinfo.ahu.edu.cn/" ext-link-type="uri">http://bioinfo.ahu.edu.cn/</ext-link> PrMFTP). In this web server, the user can input the FASTA formatted peptide sequences into the main box or upload a FASTA file containing peptide sequences. Then, the user could achieve the prediction results with the mailbox or on the webserver. After that, the user clicks the submit button and start the prediction of these unknown peptides. It needs only a few minutes for the predicted results.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec019">
    <title>Conclusion</title>
    <p>In this study, to address the multi-functional prediction of therapeutic peptides, we propose a new prediction model based on MHSA and class weight optimization, called PrMFTP. Compared with the existing multi-label methods, PrMFTP achieves the highest prediction performance. The pivotal part of PrMFTP model includes the global and local information extraction of the sequence through multi-scale CNN and BiLSTM, and then the optimization of sequence features through MHSA. In addition, PrMFTP model effectively solves the problem of data imbalance by adding class weight and optimizing the value of class weight to a certain extent. In the future development of MFTP prediction, we will consider how to further solve the imbalance of data sets and improve the prediction performance of the model.</p>
  </sec>
  <sec id="sec020" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pcbi.1010511.s001" position="float" content-type="local-data">
      <label>S1 Fig</label>
      <caption>
        <title>Number distribution of therapeutic peptides.</title>
        <p>The upset plot shows the detailed number of therapeutic peptides in each group. In the upset plot, the ordinate represents the number of peptides, while the abscissa represents the components of each group. The pie charts exhibit the label distribution of the therapeutic peptides.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010511.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010511.s002" position="float" content-type="local-data">
      <label>S2 Fig</label>
      <caption>
        <title>Class weights calculated by different methods.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1010511.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010511.s003" position="float" content-type="local-data">
      <label>S1 Table</label>
      <caption>
        <title>Parameter details of PrMFTP model.</title>
        <p>(DOCX)</p>
      </caption>
      <media xlink:href="pcbi.1010511.s003.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010511.s004" position="float" content-type="local-data">
      <label>S2 Table</label>
      <caption>
        <title>The performance of different multi-label models for therapeutic peptides prediction on the training set with 5-fold cross-validation.</title>
        <p>The highest value is highlighted in bold. *, **, *** and **** mean that CNN+BiLSTM+MHSA (our model) is significantly better at P-value &lt; 0.05, P-value &lt; 0.01, P-value &lt; 0.001 and P-value &lt; 0.0001 (t-test), respectively.</p>
        <p>(DOCX)</p>
      </caption>
      <media xlink:href="pcbi.1010511.s004.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1010511.s005" position="float" content-type="local-data">
      <label>S3 Table</label>
      <caption>
        <title>The performance of the base (CNN+BiLSTM+MHSA) model with different calculation class weight methods and MLSMOTE on the test set.</title>
        <p>The highest value is highlighted in bold. On all performance metrics, Base+CW (our model) is significantly better compared with the other methods. The mean ± standard deviation on 5-fold cross-validation is shown for models. *, **, *** and **** mean that CNN+BiLSTM+MHSA (our model) is significantly better at P-value &lt; 0.05, P-value &lt; 0.01, P-value &lt; 0.001 and P-value &lt; 0.0001 (t-test), respectively.</p>
        <p>(DOCX)</p>
      </caption>
      <media xlink:href="pcbi.1010511.s005.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1010511.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Markus</surname><given-names>Muttenthaler</given-names></name>, <name><surname>King</surname><given-names>Glenn F</given-names></name>, <name><surname>Adams</surname><given-names>David J</given-names></name>, <name><surname>Alewood</surname><given-names>Paul F</given-names></name>. <article-title>Trends in peptide drug discovery</article-title>. <source>Nature Reviews Drug Discovery</source>. <year>2021</year>; <volume>20</volume>:<fpage>309</fpage>–<lpage>25</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41573-020-00135-8</pub-id><?supplied-pmid 33536635?><pub-id pub-id-type="pmid">33536635</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Lei</surname><given-names>Wang</given-names></name>, <name><surname>Nanxi</surname><given-names>Wang</given-names></name>, <name><surname>Wenping</surname><given-names>Zhang</given-names></name>, <name><surname>Xurui</surname><given-names>Cheng</given-names></name>, <name><surname>Zhibin</surname><given-names>Yan</given-names></name>, <name><surname>Gang</surname><given-names>Shao</given-names></name>, <etal>et al</etal>. <article-title>Therapeutic peptides: current applications and future directions</article-title>. <source>Signal Transduction and Targeted Therapy</source>. <year>2022</year>; <volume>7</volume>:<fpage>1</fpage>–<lpage>27</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41392-022-00904-4</pub-id><?supplied-pmid 35165272?><pub-id pub-id-type="pmid">34980881</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Haggag Yusuf</surname><given-names>A</given-names></name>, <name><surname>Donia Ahmed</surname><given-names>A</given-names></name>, <name><surname>Osman Mohamed</surname><given-names>A</given-names></name>, <name><surname>El-Gizawy Sanaa</surname><given-names>A</given-names></name>. <article-title>Peptides as drug candidates: limitations and recent development perspectives</article-title>. <source>Biomedical Journal of Scientific &amp; Technical Research</source>. <year>2018</year>; <volume>1</volume>:<fpage>3</fpage>. <pub-id pub-id-type="doi">10.26717/bjstr.2018.08.001694</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Wending</surname><given-names>Tang</given-names></name>, <name><surname>Ruyu</surname><given-names>Dai</given-names></name>, <name><surname>Wenhui</surname><given-names>Yan</given-names></name>, <name><surname>Wei</surname><given-names>Zhang</given-names></name>, <name><surname>Yannan</surname><given-names>Bin</given-names></name>, <name><surname>Enhua</surname><given-names>Xia</given-names></name>, <etal>et al</etal>. <article-title>Identifying multi-functional bioactive peptide functions using multi-label deep learning</article-title>. <source>Briefings in Bioinformatics</source>. <year>2022</year>; 23:bbab414. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/bbab414</pub-id><?supplied-pmid 34651655?><pub-id pub-id-type="pmid">34651655</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Deling</surname><given-names>Xu</given-names></name>, <name><surname>Yanyan</surname><given-names>Wu</given-names></name>, <name><surname>Zhixing</surname><given-names>Cheng</given-names></name>, <name><surname>Jing</surname><given-names>Yang</given-names></name>, <name><surname>Yanrui</surname><given-names>Ding</given-names></name>. <article-title>ACHP: a web server for predicting anti-cancer peptide and anti-hypertensive peptide</article-title>. <source>International Journal of Peptide Research and Therapeutics</source>. <year>2021</year>; <volume>27</volume>:<fpage>1933</fpage>–<lpage>44</lpage>. <pub-id pub-id-type="doi">10.1007/s10989-021-10222-y</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Jinhao</surname><given-names>Zhang</given-names></name>, <name><surname>Zehua</surname><given-names>Zhang</given-names></name>, <name><surname>Lianrong</surname><given-names>Pu</given-names></name>, <name><surname>Jijun</surname><given-names>Tang</given-names></name>, <name><surname>Fei</surname><given-names>Guo</given-names></name>. <article-title>AIEpred: an ensemble predictive model of classifier chain to identify anti-inflammatory peptides</article-title>. <source>IEEE/ACM Transactions on Computational Biology and Bioinformatics</source>. <year>2021</year>; <volume>18</volume>:<fpage>1831</fpage>–<lpage>40</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TCBB.2020.2968419</pub-id><?supplied-pmid 31985437?><pub-id pub-id-type="pmid">31985437</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Ruyu</surname><given-names>Dai</given-names></name>, <name><surname>Wei</surname><given-names>Zhang</given-names></name>, <name><surname>Wending</surname><given-names>Tang</given-names></name>, <name><surname>Evelien</surname><given-names>Wynendaele</given-names></name>, <name><surname>Qizhi</surname><given-names>Zhu</given-names></name>, <name><surname>Yannan</surname><given-names>Bin</given-names></name>, <etal>et al</etal>. <article-title>BBPpred: sequence-based prediction of blood-brain barrier peptides with feature representation learning and logistic regression</article-title>. <source>Journal of Chemical Information and Modeling</source>. <year>2021</year>; <volume>61</volume>:<fpage>525</fpage>–<lpage>34</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1021/acs.jcim.0c01115</pub-id><?supplied-pmid 33426873?><pub-id pub-id-type="pmid">33426873</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Fallah Atanaki Fereshteh</surname><given-names>Behrouzi Saman</given-names></name>, <name><surname>Shohreh</surname><given-names>Ariaeenejad</given-names></name>, <name><surname>Amin</surname><given-names>Boroomand</given-names></name>, <name><surname>Kaveh</surname><given-names>Kavousi</given-names></name>. <article-title>BIPEP: sequence-based prediction of biofilm inhibitory peptides using a combination of NMR and physicochemical descriptors</article-title>. <source>ACS Omega</source>. <year>2020</year>; <volume>5</volume>:<fpage>7290</fpage>–<lpage>7</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1021/acsomega.9b04119</pub-id><?supplied-pmid 32280870?><pub-id pub-id-type="pmid">32280870</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Yuxuan</surname><given-names>Pang</given-names></name>, <name><surname>Zhuo</surname><given-names>Wang</given-names></name>, <name><surname>Jhong Jhih-Hua</surname><given-names>Lee Tzong-Yi</given-names></name>. <article-title>Identifying anti-coronavirus peptides by incorporating different negative datasets and imbalanced learning strategies</article-title>. <source>Briefings in Bioinformatics</source>. <year>2021</year>; <volume>22</volume>:<fpage>1085</fpage>–<lpage>95</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/bbaa423</pub-id><?supplied-pmid 33497434?><pub-id pub-id-type="pmid">33497434</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Muhammad</surname><given-names>Arif</given-names></name>, <name><surname>Saeed</surname><given-names>Ahmad</given-names></name>, <name><surname>Farman</surname><given-names>Ali</given-names></name>, <name><surname>Ge</surname><given-names>Fang</given-names></name>, <name><surname>Min</surname><given-names>Li</given-names></name>, <name><surname>Dongjun</surname><given-names>Yu</given-names></name>. <article-title>TargetCPP: accurate prediction of cell-penetrating peptides from optimized multi-scale features using gradient boost decision tree</article-title>. <source>Journal of Computer-Aided Molecular Design</source>. <year>2020</year>; <volume>34</volume>:<fpage>841</fpage>–<lpage>56</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10822-020-00307-z</pub-id><?supplied-pmid 32180124?><pub-id pub-id-type="pmid">32180124</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Watshara</surname><given-names>Shoombuatong</given-names></name>, <name><surname>Nalini</surname><given-names>Schaduangrat</given-names></name>, <name><surname>Reny</surname><given-names>Pratiwi</given-names></name>, <name><surname>Chanin</surname><given-names>Nantasenamat</given-names></name>. <article-title>THPep: a machine learning-based approach for predicting tumor homing peptides</article-title>. <source>Computational Biology and Chemistry</source>. <year>2019</year>; <volume>80</volume>:<fpage>441</fpage>–<lpage>51</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.compbiolchem.2019.05.008</pub-id><?supplied-pmid 31151025?><pub-id pub-id-type="pmid">31151025</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Piyush</surname><given-names>Agrawal</given-names></name>, <name><surname>Dhruv</surname><given-names>Bhagat</given-names></name>, <name><surname>Manish</surname><given-names>Mahalwal</given-names></name>, <name><surname>Neelam</surname><given-names>Sharma</given-names></name>, <name><surname>Raghava</surname><given-names>Gajendra PS</given-names></name>. <article-title>AntiCP 2.0: an updated model for predicting anticancer peptides</article-title>. <source>Briefings in Bioinformatics</source>. <year>2021</year>; 22:bbaa153. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/bbaa153</pub-id><?supplied-pmid 32770192?><pub-id pub-id-type="pmid">32770192</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>Zhang</given-names></name>, <name><surname>Enhua</surname><given-names>Xia</given-names></name>, <name><surname>Ruyu</surname><given-names>Dai</given-names></name>, <name><surname>Wending</surname><given-names>Tang</given-names></name>, <name><surname>Yannan</surname><given-names>Bin</given-names></name>, <name><surname>Junfeng</surname><given-names>Xia</given-names></name>. <article-title>PredAPP: predicting anti-parasitic peptides with undersampling and ensemble approaches</article-title>. <source>Interdisciplinary Sciences: Computational Life Sciences</source>. <year>2021</year>:<fpage>1</fpage>–<lpage>11</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s12539-021-00484-x</pub-id><?supplied-pmid 34608613?><pub-id pub-id-type="pmid">34608613</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Ke</surname><given-names>Yan</given-names></name>, <name><surname>Hongwu</surname><given-names>Lv</given-names></name>, <name><surname>Yichen</surname><given-names>Guo</given-names></name>, <name><surname>Yongyong</surname><given-names>Chen</given-names></name>, <name><surname>Hao</surname><given-names>Wu</given-names></name>, <name><surname>Bin</surname><given-names>Liu</given-names></name>. <article-title>TPpred-ATMV: therapeutic peptide prediction by adaptive multi-view tensor learning model</article-title>. <source>Bioinformatics</source>. <year>2022</year>; <volume>38</volume>:<fpage>2712</fpage>–<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btac200</pub-id><?supplied-pmid 35561206?><pub-id pub-id-type="pmid">35561206</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Li Hong-Liang</surname><given-names>Pang Yi-He</given-names></name>, <name><surname>Bin</surname><given-names>Liu</given-names></name>. <article-title>BioSeq-BLM: a platform for analyzing DNA, RNA and protein sequences based on biological language models</article-title>. <source>Nucleic Acids Research</source>. <year>2021</year>; <volume>49</volume>:<fpage>e129</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkab829</pub-id><?supplied-pmid 34581805?><pub-id pub-id-type="pmid">34581805</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Youngmahn</surname><given-names>Han</given-names></name>, <name><surname>Dongsup</surname><given-names>Kim</given-names></name>. <article-title>Deep convolutional neural networks for pan-specific peptide-MHC class I binding prediction</article-title>. <source>BMC Bioinformatics</source>. <year>2017</year>; <volume>18</volume>:<fpage>1</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12859-017-1997-x</pub-id><?supplied-pmid 29281985?><pub-id pub-id-type="pmid">28049414</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Matt</surname><given-names>Spencer</given-names></name>, <name><surname>Jesse</surname><given-names>Eickholt</given-names></name>, <name><surname>Jianlin</surname><given-names>Cheng</given-names></name>. <article-title>A deep learning network approach to ab initio protein secondary structure prediction</article-title>. <source>IEEE/ACM Transactions on Computational Biology and Bioinformatics</source>. <year>2014</year>; <volume>12</volume>:<fpage>103</fpage>–<lpage>12</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TCBB.2014.2343960</pub-id><?supplied-pmid 25750595?><pub-id pub-id-type="pmid">25750595</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Sønderby</surname><given-names>Kaae Søren</given-names></name>, <name><surname>Sønderby Casper Kaae</surname><given-names>Nielsen Henrik</given-names></name>, <name><surname>Ole</surname><given-names>Winther</given-names></name>, editors. <article-title>Convolutional LSTM networks for subcellular localization of proteins</article-title>. <source>International Conference on Algorithms for Computational Biology</source>; <year>2015</year>. <pub-id pub-id-type="doi">10.1007/978-3-319-21233-3_6</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Chu</surname><given-names>Y</given-names></name>, <name><surname>Kaushik</surname><given-names>A</given-names></name>. C, Wang X, Wang W, Zhang Y, Shan X, <etal>et al</etal>. <article-title>DTI-CDF: a cascade deep forest model towards the prediction of drug-target interactions based on hybrid features</article-title>. <source>Briefings in Bioinformatics</source>. <year>2021</year>; <volume>22</volume>:<fpage>451</fpage>–<lpage>62</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/bbz152</pub-id><?supplied-pmid 31885041?><pub-id pub-id-type="pmid">31885041</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Deng</surname><given-names>Y</given-names></name>, <name><surname>Xu</surname><given-names>X</given-names></name>, <name><surname>Qiu</surname><given-names>Y</given-names></name>, <name><surname>Xia</surname><given-names>J</given-names></name>, <name><surname>Zhang</surname><given-names>W</given-names></name>, <name><surname>Liu</surname><given-names>S</given-names></name>. <article-title>A multimodal deep learning framework for predicting drug-drug interaction events</article-title>. <source>Bioinformatics</source>. <year>2020</year>; <volume>36</volume>:<fpage>4316</fpage>–<lpage>22</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btaa501</pub-id><?supplied-pmid 32407508?><pub-id pub-id-type="pmid">32407508</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>F</given-names></name>, <name><surname>Yue</surname><given-names>X</given-names></name>, <name><surname>Xiong</surname><given-names>Z</given-names></name>, <name><surname>Yu</surname><given-names>Z</given-names></name>, <name><surname>Liu</surname><given-names>S</given-names></name>, <name><surname>Zhang</surname><given-names>W</given-names></name>. <article-title>Tensor decomposition with relational constraints for predicting multiple types of microRNA-disease associations</article-title>. <source>Briefings in Bioinformatics</source>. <year>2021</year>; 22:bbaa140. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/bbaa140</pub-id><?supplied-pmid 32725161?><pub-id pub-id-type="pmid">32725161</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Lin Tzu-Tang</surname><given-names>Yang Li-Yen</given-names></name>, <name><surname>Lu I-Hsuan</surname><given-names>Cheng Wen-Chih</given-names></name>, <name><surname>Hsu Zhe-Ren</surname><given-names>Chen Shu-Hwa</given-names></name>, <etal>et al</etal>. <article-title>AI4AMP: an antimicrobial peptide predictor using physicochemical property-based encoding method and deep Learning</article-title>. <source>Msystems</source>. <year>2021</year>; <volume>6</volume>:<fpage>e00299</fpage>–<lpage>21</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1128/mSystems.00299-21</pub-id><?supplied-pmid 34783578?><pub-id pub-id-type="pmid">34783578</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Ritesh</surname><given-names>Sharma</given-names></name>, <name><surname>Sameer</surname><given-names>Shrivastava</given-names></name>, <name><surname>Kumar Singh Sanjay</surname><given-names>Kumar Abhinav</given-names></name>, <name><surname>Sonal</surname><given-names>Saxena</given-names></name>, <article-title>Kumar Singh Raj. Deep-ABPpred: identifying antibacterial peptides in protein sequences using bidirectional LSTM with word2vec</article-title>. <source>Briefings in Bioinformatics</source>. <year>2021</year>; 22:bbab065. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/bbab065</pub-id><?supplied-pmid 33784381?><pub-id pub-id-type="pmid">33784381</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>Chun</surname><given-names>Fang</given-names></name>, <name><surname>Yoshitaka</surname><given-names>Moriwaki</given-names></name>, <name><surname>Caihong</surname><given-names>Li</given-names></name>, <name><surname>Kentaro</surname><given-names>Shimizu</given-names></name>. <article-title>Prediction of antifungal peptides by deep learning with character embedding</article-title>. <source>IPSJ Transactions on Bioinformatics</source>. <year>2019</year>; <volume>12</volume>:<fpage>21</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.2197/ipsjtbio.12.21</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Jiawei</surname><given-names>Li</given-names></name>, <name><surname>Yuqian</surname><given-names>Pu</given-names></name>, <name><surname>Jijun</surname><given-names>Tang</given-names></name>, <name><surname>Quan</surname><given-names>Zou</given-names></name>, <name><surname>Fei</surname><given-names>Guo</given-names></name>. <article-title>DeepAVP: a dual-channel deep neural network for identifying variable-length antiviral peptides</article-title>. <source>IEEE Journal of Biomedical and Health Informatics</source>. <year>2020</year>; <volume>24</volume>:<fpage>3012</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/JBHI.2020.2977091</pub-id><?supplied-pmid 32142462?><pub-id pub-id-type="pmid">32142462</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Shumin</surname><given-names>Li</given-names></name>, <name><surname>Junjie</surname><given-names>Chen</given-names></name>, <name><surname>Bin</surname><given-names>Liu</given-names></name>. <article-title>Protein remote homology detection based on bidirectional long short-term memory</article-title>. <source>BMC Bioinformatics</source>. <year>2017</year>; <volume>18</volume><comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12859-017-1842-2</pub-id><?supplied-pmid 29017445?><pub-id pub-id-type="pmid">29017445</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Minling</surname><given-names>Zhang</given-names></name>, <name><surname>Zhihua</surname><given-names>Zhou</given-names></name>. <article-title>A review on multi-label learning algorithms</article-title>. <source>IEEE Transactions on Knowledge and Data Engineering</source>. <year>2013</year>; <volume>26</volume>:<fpage>1819</fpage>–<lpage>37</lpage>. <pub-id pub-id-type="doi">10.1109/tkde.2013.39</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Boutell Matthew</surname><given-names>R</given-names></name>, <name><surname>Luo</surname><given-names>Jiebo</given-names></name>, <name><surname>Shen</surname><given-names>Xipeng</given-names></name>, <name><surname>Brown</surname><given-names>Christopher M</given-names></name>. <article-title>Learning multi-label scene classification</article-title>. <source>Pattern Recognition</source>. <year>2004</year>; <volume>37</volume>:<fpage>1757</fpage>–<lpage>71</lpage>. <pub-id pub-id-type="doi">10.1016/j.patcog.2004.03.009</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Johannes</surname><given-names>Fürnkranz</given-names></name>, <name><surname>Eyke</surname><given-names>Hüllermeier</given-names></name>, <name><surname>Loza Mencía Eneldo</surname><given-names>Brinker Klaus</given-names></name>. <article-title>Multilabel classification via calibrated label ranking</article-title>. <source>Machine Learning</source>. <year>2008</year>; <volume>73</volume>:<fpage>133</fpage>–<lpage>53</lpage>. <pub-id pub-id-type="doi">10.1007/s10994-008-5064-8</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Grigorios</surname><given-names>Tsoumakas</given-names></name>, <name><surname>Ioannis</surname><given-names>Vlahavas</given-names></name>. <article-title>Random k-labelsets: an ensemble method for multilabel classification</article-title>. <source>European Conference on Machine Learning</source>. <year>2007</year>:<fpage>406</fpage>–<lpage>17</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-540-74958-5_38</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Wu</surname><given-names>Guoqiang</given-names></name>, <name><surname>Zheng</surname><given-names>Ruobing</given-names></name>, <name><surname>Tian</surname><given-names>Yingjie</given-names></name>, <name><surname>Liu</surname><given-names>Dalian</given-names></name>. <article-title>Joint ranking SVM and binary relevance with robust low-rank learning for multi-label classification</article-title>. <source>Neural Networks</source>. <year>2020</year>; <volume>122</volume>:<fpage>24</fpage>–<lpage>39</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neunet.2019.10.002</pub-id><?supplied-pmid 31675625?><pub-id pub-id-type="pmid">31675625</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Zhouhan</surname><given-names>Lin</given-names></name>., <name><surname>Feng</surname><given-names>Minwei</given-names></name>., <name><surname>Santos Cicero</surname><given-names>Nogueira dos</given-names></name>., <name><surname>Yu</surname></name>., <name><surname>Xiang</surname><given-names>Bing</given-names></name>., <name><surname>Zhou</surname><given-names>Bowen</given-names></name>., <etal>et al</etal>. <article-title>A structured self-attentive sentence embedding</article-title>. <source>ArXiv Preprint ArXiv:170303130</source>. <year>2017</year>; <pub-id pub-id-type="doi">10.48550/arXiv.1703.03130</pub-id>. Focus to learn more</mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang Yu</surname><given-names>P</given-names></name>, <name><surname>Zou</surname><given-names>Quan</given-names></name>. <article-title>PPTPP: a novel therapeutic peptide prediction method using physicochemical property encoding and adaptive feature representation learning</article-title>. <source>Bioinformatics</source>. <year>2020</year>; <volume>36</volume>:<fpage>3982</fpage>–<lpage>7</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btaa275</pub-id><?supplied-pmid 32348463?><pub-id pub-id-type="pmid">32348463</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Xuan</surname><given-names>Xiao</given-names></name>, <name><surname>Yutao</surname><given-names>Shao</given-names></name>, <name><surname>Xiang</surname><given-names>Cheng</given-names></name>, <name><surname>Biljana</surname><given-names>Stamatovic</given-names></name>. <article-title>iAMP-CA2L: a new CNN-BiLSTM-SVM classifier based on cellular automata image for identifying antimicrobial peptides and their functional types</article-title>. <source>Briefings in Bioinformatics</source>. <year>2021</year>; <volume>22</volume>:<fpage>bbab209</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bib/bbab209</pub-id><?supplied-pmid 34086856?><pub-id pub-id-type="pmid">34086856</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Susanta</surname><given-names>Roy</given-names></name>, <name><surname>Robindra</surname><given-names>Teron</given-names></name>. <article-title>BioDADPep: a bioinformatics database for anti diabetic peptides</article-title>. <source>Bioinformation</source>. <year>2019</year>; <volume>15</volume>:<fpage>780</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.6026/97320630015780</pub-id><?supplied-pmid 31902976?><pub-id pub-id-type="pmid">31902976</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Mst</surname><given-names>Khatun</given-names></name>, Md Hasan, <name><surname>Watshara</surname><given-names>Shoombuatong</given-names></name>, <name><surname>Hiroyuki</surname><given-names>Kurata</given-names></name>. <article-title>ProIn-Fuse: improved and robust prediction of proinflammatory peptides by fusing of multiple feature representations</article-title>. <source>Journal of Computer-Aided Molecular Design</source>. <year>2020</year>; <volume>34</volume>:<fpage>1229</fpage>–<lpage>36</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10822-020-00343-9</pub-id><?supplied-pmid 32964284?><pub-id pub-id-type="pmid">32964284</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Pankhuri</surname><given-names>Jain</given-names></name>, <name><surname>Tiwari Anoop Kumar</surname><given-names>Som Tanmoy</given-names></name>. <article-title>Enhanced prediction of anti-tubercular peptides from sequence information using divergence measure-based intuitionistic fuzzy-rough feature selection</article-title>. <source>Soft Computing</source>. <year>2020</year>; <volume>25</volume>:<fpage>3065</fpage>–<lpage>86</lpage>. <pub-id pub-id-type="doi">10.1007/s00500-020-05363-z</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref038">
      <label>38</label>
      <mixed-citation publication-type="journal"><name><surname>Phasit</surname><given-names>Charoenkwan</given-names></name>, <name><surname>Sakawrat</surname><given-names>Kanthawong</given-names></name>, <name><surname>Chanin</surname><given-names>Nantasenamat</given-names></name>, <name><surname>Hasan</surname><given-names>Md Mehedi Shoombuatong Watshara</given-names></name>. <article-title>IDPPIV-SCM: a sequence-based predictor for identifying and analyzing dipeptidyl peptidase IV (DPP-IV) inhibitory peptides using a scoring card method</article-title>. <source>Journal of Proteome Research</source>. <year>2020</year>; <volume>19</volume>:<fpage>4125</fpage>–<lpage>36</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1021/acs.jproteome.0c00590</pub-id><?supplied-pmid 32897718?><pub-id pub-id-type="pmid">32897718</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Hyun</surname><given-names>Kim</given-names></name>, <name><surname>Jang Ju Hye</surname><given-names>Kim Sun Chang</given-names></name>, <article-title>Cho Ju Hyun. De novo generation of short antimicrobial peptides with enhanced stability and cell specificity</article-title>. <source>Journal of Antimicrobial Chemotherapy</source>. <year>2014</year>; <volume>69</volume>:<fpage>121</fpage>–<lpage>32</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/jac/dkt322</pub-id><?supplied-pmid 23946320?><pub-id pub-id-type="pmid">23946320</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref040">
      <label>40</label>
      <mixed-citation publication-type="book"><name><surname>Eugen</surname><given-names>Vušak</given-names></name>, <name><surname>Vjeko</surname><given-names>Kužina</given-names></name>, <name><surname>Alan</surname><given-names>Jović</given-names></name>, editors. <part-title>A survey of word embedding algorithms for textual data information extraction</part-title>. <source>2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)</source>: <publisher-name>IEEE</publisher-name>. <pub-id pub-id-type="doi">10.23919/mipro52101.2021.9597076</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Aslan Muhammet Fatih</surname><given-names>Unlersen Muhammed Fahri</given-names></name>, <name><surname>Kadir</surname><given-names>Sabanci</given-names></name>, <name><surname>Akif</surname><given-names>Durdu</given-names></name>. <article-title>CNN-based transfer learning-BiLSTM network: a novel approach for COVID-19 infection detection</article-title>. <source>Applied Soft Computing</source>. <year>2021</year>; <volume>98</volume>:<fpage>106912</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.asoc.2020.106912</pub-id><?supplied-pmid 33230395?><pub-id pub-id-type="pmid">33230395</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref042">
      <label>42</label>
      <mixed-citation publication-type="journal"><name><surname>Jianpeng</surname><given-names>Zhou</given-names></name>, <name><surname>Lei</surname><given-names>Chen</given-names></name>, <name><surname>Zihan</surname><given-names>Guo</given-names></name>. <article-title>iATC-NRAKEL: an efficient multi-label classifier for recognizing anatomical therapeutic chemical classes of drugs</article-title>. <source>Bioinformatics</source>. <year>2020</year>; <volume>36</volume>:<fpage>1391</fpage>–<lpage>6</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz757</pub-id><?supplied-pmid 31593226?><pub-id pub-id-type="pmid">31593226</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Sadaf</surname><given-names>Gull</given-names></name>, <name><surname>Nauman</surname><given-names>Shamim</given-names></name>, <name><surname>Fayyaz</surname><given-names>Minhas</given-names></name>. <article-title>AMAP: hierarchical multi-label prediction of biologically active and antimicrobial peptides</article-title>. <source>Computers in Biology and Medicine</source>. <year>2019</year>; <volume>107</volume>:<fpage>172</fpage>–<lpage>81</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.compbiomed.2019.02.018</pub-id><?supplied-pmid 30831306?><pub-id pub-id-type="pmid">30831306</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref044">
      <label>44</label>
      <mixed-citation publication-type="journal"><name><surname>Xuan</surname><given-names>Xiao</given-names></name>, <name><surname>Pu</surname><given-names>Wang</given-names></name>, <name><surname>Weizhong</surname><given-names>Lin</given-names></name>, <name><surname>Jianhua</surname><given-names>Jia</given-names></name>, <name><surname>Kuochen</surname><given-names>Chou</given-names></name>. <article-title>iAMP-2L: a two-level multi-label classifier for identifying antimicrobial peptides and their functional types</article-title>. <source>Analytical Biochemistry</source>. <year>2013</year>; <volume>436</volume>:<fpage>168</fpage>–<lpage>77</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ab.2013.01.019</pub-id><?supplied-pmid 23395824?><pub-id pub-id-type="pmid">23395824</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref045">
      <label>45</label>
      <mixed-citation publication-type="journal"><name><surname>Alexios</surname><given-names>Koutsoukas</given-names></name>, <name><surname>Monaghan Keith J</surname><given-names>Li Xiaoli</given-names></name>, <name><surname>Jun</surname><given-names>Huan</given-names></name>. <article-title>Deep-learning: investigating deep neural networks hyper-parameters and comparison of performance to shallow methods for modeling bioactivity data</article-title>. <source>Journal of Cheminformatics</source>. <year>2017</year>; <volume>9</volume>:<fpage>1</fpage>–<lpage>13</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s13321-017-0226-y</pub-id><?supplied-pmid 29086090?><pub-id pub-id-type="pmid">28316652</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref046">
      <label>46</label>
      <mixed-citation publication-type="journal"><name><surname>Konstantin</surname><given-names>Sozykin</given-names></name>, <name><surname>Stanislav</surname><given-names>Protasov</given-names></name>, <name><surname>Adil</surname><given-names>Khan</given-names></name>, <name><surname>Rasheed</surname><given-names>Hussain</given-names></name>, <name><surname>Jooyoung</surname><given-names>Lee</given-names></name>. <article-title>Multi-label class-imbalanced action recognition in hockey videos via 3D convolutional neural networks</article-title>. <source>2018 19th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)</source>. <volume>2018</volume>:<fpage>146</fpage>–<lpage>51</lpage>. <pub-id pub-id-type="doi">10.1109/snpd.2018.8441034</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref047">
      <label>47</label>
      <mixed-citation publication-type="journal"><name><surname>Tarekegn</surname><given-names>Adane Nega</given-names></name>, <name><surname>Mario</surname><given-names>Giacobini</given-names></name>, <name><surname>Michalak</surname><given-names>Krzysztof</given-names></name>. <article-title>A review of methods for imbalanced multi-label classification</article-title>. <source>Pattern Recognition</source>. <year>2021</year>; <volume>118</volume>:<fpage>107965</fpage>. <pub-id pub-id-type="doi">10.1016/j.patcog.2021.107965</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref048">
      <label>48</label>
      <mixed-citation publication-type="journal"><name><surname>Duolin</surname><given-names>Wang</given-names></name>, <name><surname>Zhaoyue</surname><given-names>Zhang</given-names></name>, <name><surname>Yuexu</surname><given-names>Jiang</given-names></name>, <name><surname>Ziting</surname><given-names>Mao</given-names></name>, <name><surname>Dong</surname><given-names>Wang</given-names></name>, <name><surname>Hao</surname><given-names>Lin</given-names></name>, <etal>et al</etal>. <article-title>DM3Loc: multi-label mRNA subcellular localization prediction and analysis based on multi-head self-attention mechanism</article-title>. <source>Nucleic Acids Research</source>. <year>2021</year>; <volume>49</volume>:<fpage>e46</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkab016</pub-id><?supplied-pmid 33503258?><pub-id pub-id-type="pmid">33503258</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref049">
      <label>49</label>
      <mixed-citation publication-type="journal"><name><surname>Francisco</surname><given-names>Charte</given-names></name>, <name><surname>Rivera</surname><given-names>Antonio J</given-names></name>, <name><surname>del Jesus María</surname><given-names>J</given-names></name>, <name><surname>Herrera</surname><given-names>Francisco</given-names></name>. <article-title>MLSMOTE: Approaching imbalanced multilabel learning through synthetic instance generation</article-title>. <source>Knowledge-Based Systems</source>. <year>2015</year>; <volume>89</volume>:<fpage>385</fpage>–<lpage>97</lpage>. <pub-id pub-id-type="doi">10.1016/j.knosys.2015.07.019</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1010511.ref050">
      <label>50</label>
      <mixed-citation publication-type="journal"><name><surname>Ke</surname><given-names>Yan</given-names></name>, <name><surname>Hongwu</surname><given-names>Lv</given-names></name>, <name><surname>Jie</surname><given-names>Wen</given-names></name>, <name><surname>Yichen</surname><given-names>Guo</given-names></name>, <name><surname>Bin</surname><given-names>Liu</given-names></name>. <article-title>TP-MV: Therapeutic Peptides Prediction by Multi-view Learning</article-title>. <source>Current Bioinformatics</source>. <year>2022</year>; <volume>17</volume>:<fpage>174</fpage>–<lpage>83</lpage>. <pub-id pub-id-type="doi">10.2174/1574893617666211220153429</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
