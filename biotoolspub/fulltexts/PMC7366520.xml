<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Plant Sci</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Plant Sci</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Plant Sci.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Plant Science</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1664-462X</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7366520</article-id>
    <article-id pub-id-type="doi">10.3389/fpls.2020.01015</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Plant Science</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>The XyloTron: Flexible, Open-Source, Image-Based Macroscopic Field Identification of Wood Products</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Ravindran</surname>
          <given-names>Prabu</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="author-notes" rid="fn001">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/977451"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Thompson</surname>
          <given-names>Blaise J.</given-names>
        </name>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="https://loop.frontiersin.org/people/1001595"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Soares</surname>
          <given-names>Richard K.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wiedenhoeft</surname>
          <given-names>Alex C.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff5">
          <sup>5</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>Center for Wood Anatomy Research, USDA Forest Products Laboratory</institution>, <addr-line>Madison, WI</addr-line>, <country>United States</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Department of Botany, University of Wisconsin</institution>, <addr-line>Madison, WI</addr-line>, <country>United States</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Department of Chemistry, University of Wisconsin</institution>, <addr-line>Madison, WI</addr-line>, <country>United States</country></aff>
    <aff id="aff4"><sup>4</sup><institution>Department of Forestry and Natural Resources, Purdue University</institution>, <addr-line>West Lafayette, IN</addr-line>, <country>United States</country></aff>
    <aff id="aff5"><sup>5</sup><institution>Departamento de Ciências Biolôgicas (Botânica), Universidade Estadual Paulista</institution>, <addr-line>Botucatu</addr-line>, <country>Brazil</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Matti Mõttus, VTT Technical Research Centre of Finland Ltd, Finland</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Silvana Nisgoski, Federal University of Paraná, Brazil; Gerald Koch, Thuenen-Institute of Wood Research, Germany</p>
      </fn>
      <corresp id="fn001">*Correspondence: Prabu Ravindran, <email xlink:href="mailto:pravindran@wisc.edu" xlink:type="simple">pravindran@wisc.edu</email></corresp>
      <fn fn-type="other" id="fn002">
        <p>This article was submitted to Technical Advances in Plant Science, a section of the journal Frontiers in Plant Science</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>10</day>
      <month>7</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>11</volume>
    <elocation-id>1015</elocation-id>
    <history>
      <date date-type="received">
        <day>14</day>
        <month>5</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>22</day>
        <month>6</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2020 Ravindran, Thompson, Soares and Wiedenhoeft</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Ravindran, Thompson, Soares and Wiedenhoeft</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Forests, estimated to contain two thirds of the world’s biodiversity, face existential threats due to illegal logging and land conversion. Efforts to combat illegal logging and to support sustainable value chains are hampered by a critical lack of affordable and scalable technologies for field-level inspection of wood and wood products. To meet this need we present the XyloTron, a complete, self-contained, multi-illumination, field-deployable, open-source platform for field imaging and identification of forest products at the macroscopic scale. The XyloTron platform integrates an imaging system built with off-the-shelf components, flexible illumination options with visible and UV light sources, software for camera control, and deep learning models for identification. We demonstrate the capabilities of the XyloTron platform with example applications for automatic wood and charcoal identification using visible light and human-mediated wood identification based on ultra-violet illumination and discuss applications in field imaging, metrology, and material characterization of other substrates.</p>
    </abstract>
    <kwd-group>
      <kwd>wood identification</kwd>
      <kwd>charcoal identification</kwd>
      <kwd>convolutional neural networks</kwd>
      <kwd>deep learning</kwd>
      <kwd>sustainability</kwd>
      <kwd>forest products</kwd>
      <kwd>computer vision</kwd>
    </kwd-group>
    <counts>
      <fig-count count="6"/>
      <table-count count="0"/>
      <equation-count count="0"/>
      <ref-count count="34"/>
      <page-count count="8"/>
      <word-count count="2856"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>Introduction</title>
    <p>In 2018, global trade in forest products represented a value chain of more than 550 billion USD<xref ref-type="fn" rid="fn1"><sup>1</sup></xref> and was at the highest volume since record-keeping began in 1947 (<xref rid="B8" ref-type="bibr">Food and Agriculture Organization, 2018</xref>). This value chain includes logs, timbers, dressed lumber, veneers, finished products, comminuted wood products, pulp and pulp-derived products, wood fuel, and charcoal, among others. Illegal logging accounts for 15–30% of the global timber supply chain (<xref rid="B21" ref-type="bibr">Nellemann, 2012</xref>), resulting in lost revenue for source countries, governmental corruption, and unregulated degradation of forest lands. Of the illegal trade in timber, it is estimated that 80% is controlled by transnational criminal enterprises (<xref rid="B21" ref-type="bibr">Nellemann, 2012</xref>), making illegal logging the fourth most lucrative form of transnational crime after counterfeiting, drug trafficking, and human trafficking, and the most profitable form of transnational natural resource crime (<xref rid="B18" ref-type="bibr">May, 2017</xref>).</p>
    <p>In part as a result of the global scale of illegal logging and its ties to transnational organized crime, industrial compliance with and governmental enforcement of laws and regulations governing trade in wood and wood-derived products have remained an international priority. These include the Convention on the International Trade in Endangered Species (CITES, 27 U.S.T. § 1087), the Lacey Act (18 U.S.C. § 42–43; 16 U.S.C. § 3371–3378), the European Union Timber Regulation (EUTR, No. 995/2010), Australia’s Illegal Logging Protection Act (2012), and Illegal Logging Protection Regulation (2014). There is also growing interest in “greening” the charcoal value chain (<xref rid="B30" ref-type="bibr">van Dam, 2017</xref>), which directly impacts the energy needs and livelihoods of one-third of the world’s population (<xref rid="B7" ref-type="bibr">Food and Agriculture Organization, 2019</xref>). Research and technology development in support of law enforcement and industrial compliance have emphasized predominantly laboratory-based approaches [as reviewed in (<xref rid="B5" ref-type="bibr">Dormontt et al., 2015</xref>; <xref rid="B14" ref-type="bibr">International Consortium on Combating Wildlife Crime, 2016</xref>; <xref rid="B27" ref-type="bibr">Schmitz et al., 2019</xref>)], but the first (and in some jurisdictions the only) step in the enforcement of provisions against illegal logging is identification or screening of products in the field, at ports, border crossings, or other points of control.</p>
    <p>The current state-of-the-art for routine field screening of wood across the world is an entirely human enterprise using naked eye and hand lens observation of wood anatomical features (<xref rid="B19" ref-type="bibr">Miller et al., 2002</xref>; <xref rid="B17" ref-type="bibr">Koch et al., 2011</xref>; <xref rid="B33" ref-type="bibr">Wiedenhoeft, 2011</xref>; <xref rid="B34" ref-type="bibr">Yin et al., 2016</xref>;<xref ref-type="fn" rid="fn2"><sup>2</sup></xref>
<xref rid="B25" ref-type="bibr">Ruffinatto and Crivellaro, 2019</xref>). Field screening of wood is severely limited by the dearth of human expertise in forensic wood analysis (<xref rid="B32" ref-type="bibr">Wiedenhoeft et al., 2019</xref>), and there is even less field expertise for charcoal. Affordable and scalable technologies that can either dramatically extend or obviate the need for human expertise clearly have value in solving the global field-screening limitation and effective evidence-based policy development for compliance or enforcement will require context-dependent modifications to the adopted technology.</p>
    <p>To move away from dependence on, or to complement, human expertise, various authors have advocated for computer vision based approaches to wood and charcoal identification. Several proof-of-concept systems have been reported, relying either on laboratory-acquired images (<xref rid="B15" ref-type="bibr">Khalid et al., 2008</xref>; <xref rid="B31" ref-type="bibr">Wang et al., 2013</xref>; <xref rid="B6" ref-type="bibr">Filho et al., 2014</xref>; <xref rid="B20" ref-type="bibr">Muniz et al., 2016</xref>; <xref rid="B3" ref-type="bibr">Barmpoutis et al., 2018</xref>; <xref rid="B1" ref-type="bibr">Andrade et al., 2019</xref>), or field-acquired cell phone images (<xref rid="B29" ref-type="bibr">Tang et al., 2018</xref>) that are relatively variable in terms of chromatic control, total magnification, spherical aberration, and other data-quality factors reviewed in <xref rid="B11" ref-type="bibr">Hermanson and Wiedenhoeft (2011)</xref>, with two notable forays into controlling these factors for field imaging (<xref rid="B12" ref-type="bibr">Hermanson et al., 2019</xref>; <xref rid="B2" ref-type="bibr">Andrade et al., 2020</xref>). Computer vision based wood (<xref rid="B23" ref-type="bibr">Ravindran et al., 2018</xref>) and charcoal identification is appealing because it is affordable (<xref rid="B22" ref-type="bibr">Ravindran and Wiedenhoeft, 2020</xref>) and therefore scalable, operates on an accepted source of variability in wood, its anatomy, and for wood has demonstrated potential for real-world field deployment (<xref rid="B24" ref-type="bibr">Ravindran et al., 2019</xref>). Realization of practical, context-specific, field deployment strategies requires a high quality computer vision platform that is affordable, flexible, and open source.</p>
    <p>Here we present the XyloTron, the world’s first complete, open-source, do-it-yourself platform for imaging, identification, and metrology of materials exhibiting useful macroscopic variability, such as wood and charcoal (<xref ref-type="fig" rid="f1"><bold>Figure 1</bold></xref>). The XyloTron provides controlled visible light and UV illumination capability, continuously-adjustable illumination positioning, and software to control the device, capture images, and deploy trained classification models for field screening. Compared to laboratory-based methods the XyloTron exists at an affordable and scalable price point—less than 1,500 USD per unit—such that it can be deployed in the developing world (<xref rid="B24" ref-type="bibr">Ravindran et al., 2019</xref>), in research institutions with modest budgets, and even in classrooms. We demonstrate the capabilities of the XyloTron for two applications, namely wood identification and charcoal identification—to the best of our knowledge the first time a unified field deployable system has been used for both applications. In order to foster an ecosystem around the technology we open-source the hardware design and software applications along with the trained models at <uri xlink:type="simple" xlink:href="https://github.com/fpl-xylotron">https://github.com/fpl-xylotron</uri> so the platform can be adapted to meet specific contextual needs as it is adopted.</p>
    <fig id="f1" position="float">
      <label>Figure 1</label>
      <caption>
        <p>Two forest products and XyloTron macroscopic images of each, using visible light and UV light illumination. Left: 2 × 4s representing solid wood products, and visible light and UV fluorescence images of black locust (<italic>Robinia pseudoacacia</italic>) wood. Right: Lump charcoal with a visible light illuminated image of oak charcoal.</p>
      </caption>
      <graphic xlink:href="fpls-11-01015-g001"/>
    </fig>
  </sec>
  <sec sec-type="materials|methods" id="s2">
    <title>Materials and Methods</title>
    <sec id="s2_1">
      <title>XyloTron Platform</title>
      <p>A full bill of materials, 3D design files, electrical schematics, relevant dimensioned design drawings, and a step-by-step illustrated assembly manual for building and calibrating a XyloTron system are provided in <xref ref-type="supplementary-material" rid="SM1"><bold>Supplements S1</bold></xref> and <xref ref-type="supplementary-material" rid="SM2"><bold>S2</bold></xref>. Each XyloTron requires a suitable laptop or desktop for image data collection and identification model deployment. Minimum hardware requirements and software necessary for data collection and field implementation are overviewed in <xref ref-type="supplementary-material" rid="SM3"><bold>Supplement S3</bold></xref> and are available at <uri xlink:type="simple" xlink:href="https://github.com/fpl-xylotron">https://github.com/fpl-xylotron</uri>.</p>
      <p>The XyloTron has two distinct positions for its illumination array and a range of intermediate positions. When in the wood position the illumination array is as close to the specimen as possible, and when in the charcoal position, it is as distant from the specimen as possible, in this way maximizing the visibility of anatomical features for each material. The XyloTron images a fixed tissue area of 6.35 × 6.35 mm over a 2,048 × 2,048 pixel image.</p>
    </sec>
    <sec id="s2_2">
      <title>Reference Materials and Image Data Sets</title>
      <sec id="s2_2_1">
        <title>Wood</title>
        <p>The wood specimens in the xylarium of the USDA Forest Products Laboratory routinely serve as reference material for forensic wood identification in investigations ranging from illegal logging to arson and murder. 470 wood specimens from 31 species were selected for imaging based on the wood anatomy, surface fluorescence, and geographic origin. The transverse surfaces of the selected specimens were dry sanded to 1,500 grit then imaged using visible light with the illumination array of the XyloTron in the wood position, resulting in a dataset comprised of 3,126 non-overlapping images. In many contexts (including ours) wood identification at the species level is not possible (<xref rid="B9" ref-type="bibr">Gasson, 2011</xref>) and/or not required. This was leveraged to group the selected species into 12 classes for identification at a practical taxonomic granularity and to address the data scarcity problem prevalent in machine learning based wood identification.</p>
      </sec>
      <sec id="s2_2_2">
        <title>Charcoal</title>
        <p>Commercial lump charcoal specimens, submitted by the Forest Stewardship Council for forensic identification as part of a product claim verification study, were used as reference material to collect the charcoal image data set. The charcoal specimens from six genera were identified/verified by authors Soares and Wiedenhoeft using traditional methods; the selected six genera represented 74% of the European FSC-certified lump charcoal submitted. With the XyloTron illumination array in the charcoal position, 1,312 non-overlapping images of the transverse surfaces polished to 1,000 grit of 150 charcoal specimens were obtained using visible light illumination. The image dimensions and optical resolution were the same as those for the wood image data set.</p>
      </sec>
    </sec>
    <sec id="s2_3">
      <title>Machine Learning for Wood and Charcoal Identification</title>
      <p>Separate models [using an ImageNet (<xref rid="B26" ref-type="bibr">Russakovsky et al., 2015</xref>) pre-trained (<xref rid="B10" ref-type="bibr">He et al., 2015</xref>) backbone with custom classifier heads (see <xref ref-type="fig" rid="f2"><bold>Figure 2</bold></xref>)] for wood and charcoal identification were trained using a two-stage transfer learning strategy (<xref rid="B13" ref-type="bibr">Howard and Gugger, 2020</xref>). In the first stage, the backbone was used as a feature extractor (<italic>i.e.</italic>, weights frozen) and the weights of the custom head were learned, while the weights of the entire network were fine-tuned during the second stage. Both stages employed the Adam optimizer (<xref rid="B16" ref-type="bibr">Kingma and Ba, 2015</xref>) with simultaneous cosine annealing of the learning rate and momentum (<xref rid="B28" ref-type="bibr">Smith, 2018</xref>). Random image patches of size (in pixels) 2,048 × 768 were down sampled to 512 × 192 and input to the models in minibatches of size 16 with a data augmentation strategy that included horizontal/vertical flips, small rotations and cutout (<xref rid="B4" ref-type="bibr">Devries and Taylor, 2017</xref>). The model performance for specimen classification was evaluated using five-fold cross validation with the predicted class for a test set specimen being the majority of the class predictions for the specimen’s images. It is critical to note (as detailed in <xref ref-type="supplementary-material" rid="SM4"><bold>S4</bold></xref>) that any given specimen contributed images only to a single fold. Further details about the species selected, their grouping into classes for wood identification, classifier architecture, training methodology, and hyperparameter settings can be found in <xref ref-type="supplementary-material" rid="SM4"><bold>Supplement S4</bold></xref>.</p>
      <fig id="f2" position="float">
        <label>Figure 2</label>
        <caption>
          <p>Schematic of the machine learning architecture implemented for wood and charcoal models.</p>
        </caption>
        <graphic xlink:href="fpls-11-01015-g002"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <title>Results</title>
    <sec id="s3_1">
      <title>Wood Imaging Performance With Visible and UV Light</title>
      <p><italic>Morus rubra</italic> and <italic>Robinia pseudoacacia</italic> are two species confusable at the macroscopic scale using only visible light and traditional wood anatomy (<xref ref-type="fig" rid="f3"><bold>Figures 3A, B</bold></xref>) but with markedly different surface fluorescence properties (<xref ref-type="fig" rid="f3"><bold>Figures 3C–F</bold></xref>). The visible light images of the two woods clearly depict the underlying anatomical structure. <italic>Morus</italic> does not exhibit surface fluorescence, so when imaged with UV illumination shows no (<xref ref-type="fig" rid="f3"><bold>Figure 3C</bold></xref>) or comparatively little (<xref ref-type="fig" rid="f3"><bold>Figure 3D</bold></xref>) anatomical detail. <italic>Robinia</italic>, by contrast, exhibits bright yellow-green surface fluorescence thus the images taken with UV illumination clearly show the anatomy (<xref ref-type="fig" rid="f3"><bold>Figures 3E, F</bold></xref>). This demonstrates the capability of the XyloTron system to image wood using visible light and to record surface fluorescence in wood substrates for identification and screening.</p>
      <fig id="f3" position="float">
        <label>Figure 3</label>
        <caption>
          <p>Visible light <bold>(A, B)</bold> and UV illumination <bold>(C–F)</bold> XyloTron images of <italic>Morus rubra</italic>
<bold>(A, C, D)</bold> and <italic>Robinia pseudoacacia</italic>
<bold>(B, E, F)</bold> with the illumination array in the wood position. <bold>(C</bold>–<bold>F)</bold> are the same tissue as above, with different camera gain and exposure times - C (0dB gain, 133 ms exposure), D (24dB gain, 133 ms exposure), E (0dB gain, 13 ms exposure), F (24dB gain, 29 ms exposure.)</p>
        </caption>
        <graphic xlink:href="fpls-11-01015-g003"/>
      </fig>
    </sec>
    <sec id="s3_2">
      <title>Charcoal Imaging Performance With Visible Light</title>
      <p>The adjustable illumination array position of the XyloTron enables high-quality imaging of both wood and charcoal substrates. The position of the illumination array for the charcoal position was determined to provide the best visualization of wood anatomical details necessary for robust charcoal identification (<xref ref-type="fig" rid="f4"><bold>Figure 4</bold></xref>). The fine wood anatomical detail of the charcoal is better revealed when the illumination array is more distant from the specimen (<xref ref-type="fig" rid="f4"><bold>Figure 4C</bold></xref>).</p>
      <fig id="f4" position="float">
        <label>Figure 4</label>
        <caption>
          <p>XyloTron images of <italic>Quercus</italic> wood <bold>(A)</bold> and charcoal <bold>(B)</bold> imaged with the illumination array in the wood position, and <italic>Quercus</italic> charcoal imaged with the illumination array in the charcoal position <bold>(C)</bold>. Fine anatomical details such as banded apotracheal parenchyma in the latewood are visible in <bold>(A</bold>, <bold>C)</bold>, but not in <bold>(B)</bold>.</p>
        </caption>
        <graphic xlink:href="fpls-11-01015-g004"/>
      </fig>
    </sec>
    <sec id="s3_3">
      <title>Wood and Charcoal Identification Models</title>
      <p>The specimen prediction confusion matrix for the trained 12 class wood identification using the XyloTron is shown in <xref ref-type="fig" rid="f5"><bold>Figure 5</bold></xref> (left) with a specimen classification accuracy of 97.7%. Most of the incorrect predictions could be overcome by a human user engaging the UV illumination function and making a determination of the presence of UV fluorescence (<italic>e.g.</italic> confusions between <italic>Albizia</italic>, which is fluorescent, and <italic>Inga</italic>, which is not, likewise between <italic>Robinia</italic> and <italic>Morus</italic>, between <italic>Hymenaea</italic> and <italic>Detarium</italic>, and between <italic>Ulmus rubra</italic> and <italic>Ulmus americana</italic>).</p>
      <fig id="f5" position="float">
        <label>Figure 5</label>
        <caption>
          <p>Confusion matrices for wood (left) and charcoal (right). The misclassifications in the 12 class wood model (left) mostly occur between classes with similar wood anatomy when illuminated with visible light, and all but four could be ameliorated by engaging the UV illumination capability of the XyloTron and having the human user evaluate fluorescence. The misclassifications in the 6-class charcoal identification model (right) are limited to <italic>Acer</italic> and <italic>Betula</italic>, the charcoal of which have similar anatomical features on their transverse surface.</p>
        </caption>
        <graphic xlink:href="fpls-11-01015-g005"/>
      </fig>
      <p>The confusion matrix for the proof-of-concept 6-class charcoal identification model using visible light illumination and the illumination array in the charcoal position is shown in <xref ref-type="fig" rid="f5"><bold>Figure 5</bold></xref> (right). The overall accuracy of the model is 98.7%, with misclassifications limited to confusion between <italic>Acer</italic> and <italic>Betula</italic> which are macroscopically similar.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>Discussion</title>
    <p>The wood identification model performance vastly exceeds the performance of trained field personnel and indeed approaches or exceeds expected field performance of forensic wood anatomy experts. If human XyloTron users of this model would employ UV illumination, performance would be further enhanced. In <xref ref-type="fig" rid="f5"><bold>Figure 5</bold></xref> (left), misclassification of only four specimens are not solved by such a human-hybrid approach employing UV illumination: <italic>Swietenia-Detarium</italic>, <italic>Dialium-Ulmus americana</italic>, <italic>Nauclea-Tectona grandis</italic>, and <italic>Tectona grandis-Morus</italic>. In other words, the effective accuracy of a human-hybrid version of our model incorporating UV illumination increases from 97.7 to 99.1%. Field accuracy at this level distinctly exceeds even the best-performing experts in the United States when performance was evaluated at the genus level (<xref rid="B32" ref-type="bibr">Wiedenhoeft et al., 2019</xref>).</p>
    <p>To the best of our knowledge, there is no program anywhere in the world to train field personnel to inspect or identify charcoal despite the fact that globally the charcoal sector generates income for more than 40 million people and caters to the energy needs of more than one-third of the world’s population, predominantly in the developing world (<xref rid="B7" ref-type="bibr">Food and Agriculture Organization, 2019</xref>). In the absence of an existing field identification program for charcoal we cannot directly compare our model accuracy to field inspectors. By providing a highly accurate (98.7%), field-deployable, proof-of-concept model for six classes of lump charcoal that only confuses anatomically similar charcoals, we deliver the ability to inspect and verify materials that heretofore could only be assessed reliably in the laboratory or a limited group of expert wood anatomists. Ongoing work<xref ref-type="fn" rid="fn3"><sup>3</sup></xref> in our laboratory is addressing the breadth of charcoal taxa currently identifiable with the XyloTron, which is expected to more adequately sample the charcoals that represent the remaining 26% of the FSC-certified lump charcoal in the EU market.</p>
    <p>While our prior and current work with the XyloTron platform has emphasized solid wood and charcoal, we are also developing applications for wood veneers, various types of synthetic products, and field metrology. As demonstrated, the XyloTron is well-suited to capture macroscopic images of any suitable substrate with interesting macroscopic variation (<xref ref-type="fig" rid="f6"><bold>Figure 6</bold></xref>), and we invite researchers in a range of disciplines to adapt and enhance the platform for their applications by adding additional functionalities (e.g. multi-flash imaging, multi-color illumination, and alternative machine vision models).</p>
    <fig id="f6" position="float">
      <label>Figure 6</label>
      <caption>
        <p>Natural and human-made materials and XyloTron macroscopic images of each, using visible light illumination with the illumination array in the wood position. In addition to wood, biological materials such as the gills on a mushroom, the rachis and barbs of a feather, and the trichomes of a leaf can be rapidly imaged to reveal macroscopic characteristics. Similarly, macroscopic features of synthetic materials, such as textiles, can be imaged for identification and characterization.</p>
      </caption>
      <graphic xlink:href="fpls-11-01015-g006"/>
    </fig>
  </sec>
  <sec sec-type="conclusions" id="s5">
    <title>Conclusions</title>
    <p>By providing a field-deployable system able to image and identify solid wood and charcoal, we take a step toward providing law enforcement and industrial compliance officers with the tools needed to verify wood and charcoal supply chains. Further, the open-source XyloTron platform can be readily adopted for other materials with macroscopic variability, or adapted and modified for new use-cases.</p>
  </sec>
  <sec id="s6">
    <title>Code Availability</title>
    <p>The software apps for image dataset collection and trained model deployment along with the weights of the trained model will be made available at <uri xlink:type="simple" xlink:href="https://github.com/fpl-xylotron">https://github.com/fpl-xylotron</uri>. The code for model training will be available from the corresponding author on reasonable request.</p>
  </sec>
  <sec sec-type="data-availability" id="s7">
    <title>Data Availability Statement</title>
    <p>The raw data supporting the conclusions of this article will be made available by the authors on reasonable request.</p>
  </sec>
  <sec id="s8">
    <title>Author Contributions</title>
    <p>PR developed the machine learning analyses. AW and BT adapted/designed/developed the XyloTron movable lighting array, PCBs, and electronics. AW and RS conducted forensic analysis of charcoal and established the scope of the identification models. PR and AW conducted data analysis, synthesis, and wrote the paper.</p>
  </sec>
  <sec sec-type="funding-information" id="s9">
    <title>Funding</title>
    <p>This work was supported in part by a grant from the US Department of State <italic>via</italic> Interagency Agreement number 19318814Y0010 to AW and in part by research funding from the Forest Stewardship Council to AW. PR was partially supported by the Wisconsin Idea Baldwin Grant.</p>
  </sec>
  <sec id="s10">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>A critical thank you to Cathy Karr-Colque and Luke Thompson at the US Dept. of State and to Forest Service International Programs, esp. Elizabeth Lebow, Cynthia Mackie, Alex Moad, Shelley Gardner, and Val Mezainis. Sincere gratitude to the Center for Wood Anatomy Research where the XyloTron was developed and to the FPL facilities staff, esp. Dave Eustice, Dick Jordan, Joe Balczewski, Dave Juntunen, Steve Mauch, and Will Kinney. The assistance of Sarah Friedrich on the figures is gratefully acknowledged. Dr. Patricia Vega provided helpful feedback and suggestions to improve the clarity of the manuscript, and insightful suggestions from Dr. David Schwartz are gratefully acknowledged.</p>
  </ack>
  <fn-group>
    <fn id="fn1">
      <label>1</label>
      <p>
        <uri xlink:type="simple" xlink:href="http://www.fao.org/faostat/en/#data/FO">http://www.fao.org/faostat/en/#data/FO</uri>
      </p>
    </fn>
    <fn id="fn2">
      <label>2</label>
      <p>
        <uri xlink:type="simple" xlink:href="http://www.florestal.gov.br/servicos/85-laboratorio-de-produtos-florestais-lpf/367-madeiras-comerciais-do-brasil-chave-interativa-de-identificacao-baseada-em-caracteres-gerais-e-macroscopicos">http://www.florestal.gov.br/servicos/85-laboratorio-de-produtos-florestais-lpf/367-madeiras-comerciais-do-brasil-chave-interativa-de-identificacao-baseada-em-caracteres-gerais-e-macroscopicos</uri>
      </p>
    </fn>
    <fn id="fn3">
      <label>3</label>
      <p>See also: <uri xlink:type="simple" xlink:href="https://fsc.org/en/newsfeed/fsc-conducts-investigations-on-charcoal-producers">https://fsc.org/en/newsfeed/fsc-conducts-investigations-on-charcoal-producers</uri>.</p>
    </fn>
  </fn-group>
  <sec sec-type="supplementary-material" id="s11">
    <title>Supplementary Material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fpls.2020.01015/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fpls.2020.01015/full#supplementary-material</ext-link></p>
    <supplementary-material content-type="local-data" id="SM1">
      <media xlink:href="DataSheet_1.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="SM2">
      <media xlink:href="DataSheet_2.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="SM3">
      <media xlink:href="DataSheet_3.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="SM4">
      <media xlink:href="DataSheet_4.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="SM5">
      <media xlink:href="DataSheet_5.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="SM6">
      <media xlink:href="DataSheet_6.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrade</surname><given-names>B.</given-names></name><name><surname>Vital</surname><given-names>B.</given-names></name><name><surname>Carneiro</surname><given-names>A.</given-names></name><name><surname>Basso</surname><given-names>V.</given-names></name><name><surname>Pinto</surname><given-names>F.</given-names></name></person-group> (<year>2019</year>). <article-title>Potential of texture analysis for charcoal classification</article-title>. <source>Floresta e Ambiente</source>
<volume>26</volume>, <fpage>e20171241</fpage>.  <pub-id pub-id-type="doi">10.1590/2179-8087.124117</pub-id>
</mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Andrade</surname><given-names>B.</given-names></name><name><surname>Basso</surname><given-names>V.</given-names></name><name><surname>Latorraca</surname><given-names>J.</given-names></name></person-group> (<year>2020</year>). <article-title>Machine vision for field-level wood identification</article-title>. <source>IAWA J.</source>, <fpage>1</fpage>–<lpage>18</lpage>.  <pub-id pub-id-type="doi">10.1163/22941932-bja10001</pub-id>
</mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barmpoutis</surname><given-names>P.</given-names></name><name><surname>Dimitropoulos</surname><given-names>K.</given-names></name><name><surname>Barboutis</surname><given-names>I. J.</given-names></name><name><surname>Nikos</surname><given-names>G.</given-names></name><name><surname>Lefakis</surname><given-names>P.</given-names></name></person-group> (<year>2018</year>). <article-title>Wood species recognition through multidimensional texture analysis</article-title>. <source>Comput. Electron. Agric.</source>
<volume>144</volume>, <fpage>241</fpage>–<lpage>248</lpage>.  <pub-id pub-id-type="doi">10.1016/j.compag.2017.12.011</pub-id>
</mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Devries</surname><given-names>T.</given-names></name><name><surname>Taylor</surname><given-names>G. W.</given-names></name></person-group> (<year>2017</year>). <article-title>Improved regularization of convolutional neural networks with cutout</article-title>. <source>CoRR.</source> ArXiv:1708.04552.
</mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dormontt</surname><given-names>E. E.</given-names></name><name><surname>Boner</surname><given-names>M.</given-names></name><name><surname>Braun</surname><given-names>B.</given-names></name><name><surname>Breulmann</surname><given-names>G.</given-names></name><name><surname>Degen</surname><given-names>B.</given-names></name><name><surname>Espinoza</surname><given-names>E.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>Forensic timber identification: It’s time to integrate disciplines to combat illegal logging</article-title>. <source>Biol. Conserv.</source>
<volume>191</volume>, <fpage>790</fpage>–<lpage> 798</lpage>.  <pub-id pub-id-type="doi">10.1016/j.biocon.2015.06.038</pub-id>
</mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Filho</surname><given-names>P. L.</given-names></name><name><surname>Oliveira</surname><given-names>L. S.</given-names></name><name><surname>Nisgoski</surname><given-names>S.</given-names></name><name><surname>Britto</surname><given-names>A. S.</given-names></name></person-group> (<year>2014</year>). <article-title>Forest species recognition using macroscopic images</article-title>. <source>Mach. Vision Appl.</source>
<volume>25</volume>, <fpage>1019</fpage>–<lpage>1031</lpage>.  <pub-id pub-id-type="doi">10.1007/s00138-014-0592-7</pub-id>
</mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><collab>Food and Agriculture Organization</collab></person-group> (<year>2019</year>). <source>FAO Yearbook of Forest Products 2017</source> (<publisher-name>Food and Agricultural Organization (FAO)</publisher-name>). <uri xlink:type="simple" xlink:href="http://www.fao.org/3/ca5703m/ca5703m.pdf">http://www.fao.org/3/ca5703m/ca5703m.pdf</uri> (Accessed <date-in-citation>2020-06-08</date-in-citation>).
</mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><collab>Food and Agriculture Organization</collab></person-group> (<year>2018</year>). <source>Global Forest Products: Facts and Figures</source> (<publisher-name>Food and Agricultural Organization (FAO)</publisher-name>). <uri xlink:type="simple" xlink:href="http://www.fao.org/3/ca7415en/ca7415en.pdf">http://www.fao.org/3/ca7415en/ca7415en.pdf</uri> (Accessed <date-in-citation>2020-06-08</date-in-citation>).
</mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gasson</surname><given-names>P.</given-names></name></person-group> (<year>2011</year>). <article-title>How precise can wood identification be? wood anatomy’s role in support of the legal timber trade, especially CITES</article-title>. <source>IAWA J.</source>
<volume>32</volume>, <fpage>137</fpage>–<lpage>154</lpage>.  <pub-id pub-id-type="doi">10.1163/22941932-90000049</pub-id>
</mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>He</surname><given-names>K.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Ren</surname><given-names>S.</given-names></name><name><surname>Sun</surname><given-names>J.</given-names></name></person-group> (<year>2015</year>).<article-title>Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification</article-title>, in: <conf-name>Proceedings of the 2015 IEEE International Conference on Computer Vision. ICCV</conf-name>, Vol. <volume>15</volume> pp. <fpage>1026</fpage>–<lpage>1034</lpage>.  <pub-id pub-id-type="doi">10.1109/ICCV.2015.123</pub-id>
</mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hermanson</surname><given-names>J.</given-names></name><name><surname>Wiedenhoeft</surname><given-names>A.</given-names></name></person-group> (<year>2011</year>). <article-title>A brief review of machine vision in the context of automated wood identification systems</article-title>. <source>IAWA J.</source>
<volume>32</volume>, <fpage>233</fpage>–<lpage>250</lpage>.  <pub-id pub-id-type="doi">10.1163/22941932-90000054</pub-id>
</mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hermanson</surname><given-names>J. C.</given-names></name><name><surname>Dostal</surname><given-names>D.</given-names></name><name><surname>Destree</surname><given-names>J. C.</given-names></name><name><surname>Wiedenhoeft</surname><given-names>A. C.</given-names></name></person-group> (<year>2019</year>). <source>The XyloScope – a field deployable macroscopic digital imaging device for wood</source>, Research Note, FPL-RN-0367. (<publisher-loc>Madison WI, USA</publisher-loc>: <publisher-name>Forest Products Laboratory</publisher-name>). <uri xlink:type="simple" xlink:href="https://www.fpl.fs.fed.us/documnts/fplrn/fpl_rn367.pdf">https://www.fpl.fs.fed.us/documnts/fplrn/fpl_rn367.pdf</uri> (Accessed <date-in-citation>2020-06-08</date-in-citation>).
</mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>J.</given-names></name><name><surname>Gugger</surname><given-names>S.</given-names></name></person-group> (<year>2020</year>). <article-title>Fastai: A layered API for deep learning</article-title>. <source>Information</source>
<volume>11</volume>, <fpage>108</fpage>.  <pub-id pub-id-type="doi">10.3390/info11020108</pub-id>
</mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><collab>International Consortium on Combating Wildlife Crime</collab></person-group> (<year>2016</year>). <source>Best Practice Guide for Forensic Timber Identification</source> (<publisher-name>United Nations Office on Drugs and Crime</publisher-name>). <uri xlink:type="simple" xlink:href="https://www.unodc.org/documents/Wildlife/Guide_Timber.pdf">https://www.unodc.org/documents/Wildlife/Guide_Timber.pdf</uri> (Accessed <date-in-citation>2020-06-08</date-in-citation>).
</mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khalid</surname><given-names>M.</given-names></name><name><surname>Lew</surname><given-names>E.</given-names></name><name><surname>Lee</surname><given-names>Y.</given-names></name><name><surname>Yusof</surname><given-names>R.</given-names></name><name><surname>Nadaraj</surname><given-names>M.</given-names></name></person-group> (<year>2008</year>). <article-title>Design of an intelligent wood species recognition system</article-title>. <source>Int. J. Simulat Syst. Sci. Technol.</source>
<volume>9</volume>, <fpage>9</fpage>–<lpage>19</lpage>.
</mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>D.</given-names></name><name><surname>Ba</surname><given-names>J.</given-names></name></person-group> (<year>2015</year>).<article-title>Adam: A method for stochastic optimization</article-title>, in: <conf-name>Proceedings of 2015 International Conference on Learning Representations</conf-name>.
</mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koch</surname><given-names>G.</given-names></name><name><surname>Richter</surname><given-names>H.-G.</given-names></name><name><surname>Schmitt</surname><given-names>U.</given-names></name></person-group> (<year>2011</year>). <article-title>Design and application of CITESwoodID computer-aided identification and description of CITES-protected timbers</article-title>. <source>IAWA J.</source>
<volume>32</volume>, <fpage>213</fpage>–<lpage>220</lpage>.  <pub-id pub-id-type="doi">10.1163/22941932-90000052</pub-id>
</mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>May</surname><given-names>C.</given-names></name></person-group> (<year>2017</year>). <source>Transnational Crime and the developing world</source> (<publisher-name>Global Financial Integrity</publisher-name>). <uri xlink:type="simple" xlink:href="https://gfintegrity.org/report/transnational-crime-and-the-developing-world/">https://gfintegrity.org/report/transnational-crime-and-the-developing-world/</uri> (Accessed <date-in-citation>2020-06-08</date-in-citation>).
</mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>R.</given-names></name><name><surname>Wiedenhoeft</surname><given-names>A.</given-names></name><name><surname>Ribeyron</surname><given-names>M.-J.</given-names></name></person-group> (<year>2002</year>). <source>CITES Identification Guide - Tropical Woods: Guide to the Identification of Tropical Woods Controlled Under the Convention on International Trade in Endangered Species of Wild Fauna and Flora</source> (<publisher-loc>Ottawa</publisher-loc>: <publisher-name>Environment Canada</publisher-name>).
</mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muniz</surname><given-names>G.</given-names></name><name><surname>Carneiro</surname><given-names>M.</given-names></name><name><surname>Batista</surname><given-names>F.</given-names></name><name><surname>Schardosin</surname><given-names>F.</given-names></name><name><surname>Nisgoski</surname><given-names>S.</given-names></name></person-group> (<year>2016</year>). <article-title>Wood and charcoal identification of five species from the miscellaneous group known in Brazil as “Angelim” by near-IR and wood anatomy</article-title>. <source>Maderas Ciencia y Tecnol.</source>
<volume>18</volume>, <fpage>505</fpage>–<lpage>522</lpage>.  <pub-id pub-id-type="doi">10.4067/S0718-221X2016005000045</pub-id>
</mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nellemann</surname><given-names>C.</given-names></name></person-group> (<year>2012</year>). “<article-title>Green Carbon, Black Trade: A Rapid Response Assessment on Illegal Logging, Tax Fraud and Laundering in the World’s Tropical Forests</article-title>,” in <source>A Rapid Response Assessment</source> (<publisher-name>United Nations Environment Programme, GRID-Arendal</publisher-name>). <uri xlink:type="simple" xlink:href="http://www.grida.no/publications/126">www.grida.no/publications/126</uri> (Accessed <date-in-citation>2020-06-08</date-in-citation>).
</mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ravindran</surname><given-names>P.</given-names></name><name><surname>Wiedenhoeft</surname><given-names>A. C.</given-names></name></person-group> (<year>2020</year>). <article-title>Comparison of two forensic wood identification technologies for ten Meliaceae woods: computer vision vs. mass spectrometry</article-title>. <source>Wood Sci. Technol.</source>  <pub-id pub-id-type="doi">10.1007/s00226-020-01178-1</pub-id>
</mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ravindran</surname><given-names>P.</given-names></name><name><surname>da Costa</surname><given-names>A. M.</given-names></name><name><surname>Soares</surname><given-names>R.</given-names></name><name><surname>Wiedenhoeft</surname><given-names>A. C.</given-names></name></person-group> (<year>2018</year>). <article-title>Classification of CITES-listed and other neotropical Meliaceae wood images using convolutional neural networks</article-title>. <source>Plant Methods</source>
<volume>14</volume>, <fpage>25</fpage>.  <pub-id pub-id-type="doi">10.1186/s13007-018-0292-9</pub-id>
<pub-id pub-id-type="pmid">29588649</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ravindran</surname><given-names>P.</given-names></name><name><surname>Ebanyenle</surname><given-names>E.</given-names></name><name><surname>Ebeheakey</surname><given-names>A. A.</given-names></name><name><surname>Abban</surname><given-names>K. B.</given-names></name><name><surname>Lambog</surname><given-names>O.</given-names></name><name><surname>Soares</surname><given-names>R.</given-names></name><etal/></person-group> (<year>2019</year>). “<article-title>Image based identification of Ghanaian timbers using the XyloTron: Opportunities, risks and challenges</article-title>,” in <source>NeurIPS 2019 Workshop on Machine Learning for the Developing World.</source> ArXiv:1912.00296.
</mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ruffinatto</surname><given-names>F.</given-names></name><name><surname>Crivellaro</surname><given-names>A.</given-names></name></person-group> (<year>2019</year>). <source>Atlas of Macroscopic Wood Identification, With a Special Focus on Timbers Used in Europe and CITES-listed Species</source> (<publisher-loc>Cham, Switzerland</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>), <fpage>439</fpage>.  <pub-id pub-id-type="doi">10.1007/978-3-030-23566-6</pub-id>
</mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russakovsky</surname><given-names>O.</given-names></name><name><surname>Deng</surname><given-names>J.</given-names></name><name><surname>Su</surname><given-names>H.</given-names></name><name><surname>Krause</surname><given-names>J.</given-names></name><name><surname>Satheesh</surname><given-names>S.</given-names></name><name><surname>Ma</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>ImageNet large scale visual recognition challenge</article-title>. <source>Int. J. Comput. Vision</source>
<volume>115</volume>, <fpage>211</fpage>–<lpage>252</lpage>.  <pub-id pub-id-type="doi">10.1007/s11263-015-0816-y</pub-id>
</mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schmitz</surname><given-names>N.</given-names></name><name><surname>Beeckman</surname><given-names>H.</given-names></name><name><surname>Cabezas</surname><given-names>J. A.</given-names></name><name><surname>Cervera</surname><given-names>M.</given-names></name><name><surname>Espinoza</surname><given-names>E.</given-names></name><name><surname>Fernandez-Golfin</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2019</year>). <source>The Timber Tracking Tool Infogram. Overview of wood identification methods' capacity</source> (<publisher-loc>Hamburg, Germany</publisher-loc>: <publisher-name>Thunen Institute</publisher-name>).  <pub-id pub-id-type="doi">10.13140/RG.2.2.27920.25603</pub-id>
</mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>L.</given-names></name></person-group> (<year>2018</year>). <article-title>A disciplined approach to neural network hyper-parameters: Part 1 – learning rate, batch size, momentum, and weight decay</article-title>. <source>CoRR.</source> ArXiv:1803.09820.
</mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>X. J.</given-names></name><name><surname>Tay</surname><given-names>Y. H.</given-names></name><name><surname>Siam</surname><given-names>N. A.</given-names></name><name><surname>Lim</surname><given-names>S. C.</given-names></name></person-group> (<year>2018</year>).<article-title> MyWood-ID: Automated macroscopic wood identification system using smartphone and macro-lens</article-title>, in: <conf-name>Proceedings of the 2018 International Conference on Computational Intelligence and Intelligent Systems</conf-name>, pp. <fpage>37</fpage>–<lpage>43</lpage>, Commercial version: <uri xlink:type="simple" xlink:href="https://www.xylorix.com/">https://www.xylorix.com/</uri>.  <pub-id pub-id-type="doi">10.1145/3293475.3293493</pub-id>
</mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>van Dam</surname><given-names>J.</given-names></name></person-group> (<year>2017</year>). <source>The charcoal transition: greening the charcoal value chain to mitigate climate change and improve local livelihoods</source> (<publisher-loc>Rome</publisher-loc>: <publisher-name>Food and Agriculture Organization of the United Nations</publisher-name>). <uri xlink:type="simple" xlink:href="http://www.fao.org/3/a-i6935e.pdf">http://www.fao.org/3/a-i6935e.pdf</uri> (Accessed <date-in-citation>2020-06-08</date-in-citation>).
</mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>H.</given-names></name><name><surname>Zhang</surname><given-names>G.</given-names></name><name><surname>Qi</surname><given-names>H.</given-names></name></person-group> (<year>2013</year>). <article-title>Wood recognition using image texture features</article-title>. <source>PloS One</source>
<volume>8</volume>, <fpage>1</fpage>–<lpage>12</lpage>.  <pub-id pub-id-type="doi">10.1371/journal.pone.0076101</pub-id>
</mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiedenhoeft</surname><given-names>A. C.</given-names></name><name><surname>Simeone</surname><given-names>J.</given-names></name><name><surname>Smith</surname><given-names>A.</given-names></name><name><surname>Parker-Forney</surname><given-names>M.</given-names></name><name><surname>Soares</surname><given-names>R.</given-names></name><name><surname>Fishman</surname><given-names>A.</given-names></name></person-group> (<year>2019</year>). <article-title>Fraud and misrepresentation in retail forest products exceeds u.s. forensic wood science capacity</article-title>. <source>PloS One</source>
<volume>14</volume>, <fpage>1</fpage>–<lpage>13</lpage>.  <pub-id pub-id-type="doi">10.1371/journal.pone.0219917</pub-id>
</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wiedenhoeft</surname><given-names>A. C.</given-names></name></person-group> (<year>2011</year>). <source>Identification of Central American Woods. Publication</source> (<publisher-loc>Madison, WI</publisher-loc>: <publisher-name>Forest Products Society</publisher-name>), <page-range>7215–7211</page-range>.
</mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>Y.</given-names></name><name><surname>Jiang</surname><given-names>X.</given-names></name><name><surname>Yuan</surname><given-names>L.</given-names></name></person-group> (<year>2016</year>). <source>Identification manual of endangered and precious timber species common in trades</source> (<publisher-loc>Biological Division, Beijing</publisher-loc>: <publisher-name>Science Press</publisher-name>).
</mixed-citation>
    </ref>
  </ref-list>
</back>
