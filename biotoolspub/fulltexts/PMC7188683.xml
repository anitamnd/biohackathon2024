<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Sci Rep</journal-id>
    <journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id>
    <journal-title-group>
      <journal-title>Scientific Reports</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2045-2322</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7188683</article-id>
    <article-id pub-id-type="publisher-id">63259</article-id>
    <article-id pub-id-type="doi">10.1038/s41598-020-63259-2</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>AFP-LSE: Antifreeze Proteins Prediction Using Latent Space Encoding of Composition of k-Spaced Amino Acid Pairs</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Usman</surname>
          <given-names>Muhammad</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Khan</surname>
          <given-names>Shujaat</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Lee</surname>
          <given-names>Jeong-A</given-names>
        </name>
        <address>
          <email>jalee@chosun.ac.kr</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0000 9475 8840</institution-id><institution-id institution-id-type="GRID">grid.254187.d</institution-id><institution>Department of Computer Engineering, Chosun University, </institution></institution-wrap>Gwangju, 61452 Republic of Korea </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2292 0500</institution-id><institution-id institution-id-type="GRID">grid.37172.30</institution-id><institution>Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology (KAIST), </institution></institution-wrap>Daejeon, 34141 Republic of Korea </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>28</day>
      <month>4</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>28</day>
      <month>4</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>10</volume>
    <elocation-id>7197</elocation-id>
    <history>
      <date date-type="received">
        <day>8</day>
        <month>1</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>26</day>
        <month>3</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Species living in extremely cold environments resist the freezing conditions through antifreeze proteins (AFPs). Apart from being essential proteins for various organisms living in sub-zero temperatures, AFPs have numerous applications in different industries. They possess very small resemblance to each other and cannot be easily identified using simple search algorithms such as BLAST and PSI-BLAST. Diverse AFPs found in fishes (Type I, II, III, IV and antifreeze glycoproteins (AFGPs)), are sub-types and show low sequence and structural similarity, making their accurate prediction challenging. Although several machine-learning methods have been proposed for the classification of AFPs, prediction methods that have greater reliability are required. In this paper, we propose a novel machine-learning-based approach for the prediction of AFP sequences using latent space learning through a deep auto-encoder method. For latent space pruning, we use the output of the auto-encoder with a deep neural network classifier to learn the non-linear mapping of the protein sequence descriptor and class label. The proposed method outperformed the existing methods, yielding excellent results in comparison. A comprehensive ablation study is performed, and the proposed method is evaluated in terms of widely used performance measures. In particular, the proposed method demonstrated a high Matthews correlation coefficient of 0.52, F-score of 0.49, and Youden’s index of 0.81 on an independent test dataset, thereby outperforming the existing methods for AFP prediction.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Computational biology and bioinformatics</kwd>
      <kwd>Machine learning</kwd>
      <kwd>Computer science</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2020</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par2">In Antarctic fish, a survival mechanism that prevented them from freezing in seawater at sub-zero temperatures was observed, which led to the discovery of antifreeze proteins (AFP)<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. AFPs have been identified as a crucial substance for resisting a freezing environment in various species including plants, bacteria, fungi, insects, and animals<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. Ice exists in different geometric shapes due to the varying arrangements of oxygen atoms; therefore, the structural and sequential arrangements of AFPs largely vary to accommodate this heterogeneity of ice molecules<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. Ice also exhibits the property of recrystallization, by which small ice crystals bind to the water molecules, thus becoming a large ice lattice, causing severe damage to the cell membrane, which, in some cases, may be lethal<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>. AFPs are commonly categorized into glycoproteins (AFGPs) and non-glycoproteins (AFPs)<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>. They protect the organisms using two mechanisms: (i) thermal hysteresis (TH), by which the freezing point of water is depressed to a few degrees by the adsorption-inhibition effect without altering the melting point<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>; (ii) ice crystal inhibition, by which the AFP sites bind to the surfaces of ice and inhibit their growth to become a larger ice lattice, developing either small harmless ice crystals or forming a needle-shaped lattice, thus diminishing the recrystallization property of ice<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>.</p>
    <p id="Par3">AFPs are indispensable in organisms such as fish<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, fungi<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>, bacteria<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>, plants<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>, and insects<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. Furthermore, they are essential in various medical applications (for example, cryopreservation and cryosurgery)<sup><xref ref-type="bibr" rid="CR12">12</xref></sup> and food industry<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>. The ice-binding mechanism of proteins is not fully understood<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. Reliable prediction of AFPs may play a fundamental role in identifying the underlying ice-binding mechanism. Accurate prediction would lead to the understanding of protein-ice interaction, which in turn would enable the design of macro-molecular antifreeze proteins with enhanced efficiency<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. Studies indicate that AFPs show minute or, in most cases, no similarity in structures, sequences, and ice-binding sites within closely related species<sup><xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR17">17</xref></sup>. For instance the sub-types of AFPs found in fishes namely Type I, II, III, IV and AFGP<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, have no significant similarities in structures and sequences; rather, they demonstrate some homology to different protein families from which they are assumed to have evolved<sup><xref ref-type="bibr" rid="CR18">18</xref>,<xref ref-type="bibr" rid="CR19">19</xref></sup>. This inconsistency makes their in-silico identification using conventional search tools such as BLAST<sup><xref ref-type="bibr" rid="CR20">20</xref></sup> and PSI-BLAST<sup><xref ref-type="bibr" rid="CR21">21</xref></sup> unfavorable and increases the complexity of the development of a reliable prediction model due to the lack of common features.</p>
    <p id="Par4">Researchers have proposed several computational strategies such as machine learning to achieve superior results for this diversified classification problem. Kandaswamy <italic>et al</italic>. proposed a framework named AFP-Pred, which is considered to be a pioneering work in this direction, to utilize machine learning<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. In this method, a feature vector containing 119 attributes was obtained by encoding each sequence, from which dominant features were selected using the ReliefF approach to train the random forest (RF) classifier. Yu <italic>et al</italic>. proposed a web-based predictor named iAFP<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>, which utilized n-peptide composition to obtain the feature set. Superior features were selected using the genetic algorithm, and the resultant features were employed to train a support vector machine (SVM). Xiaowei <italic>et al</italic>. used position-specific scoring matrix (PSSM) profiles with an SVM classifier to develop a web-based AFP predictor called AFP_PSSM<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. Mondal <italic>et al</italic>. used the sequence order information from Chou’s pseudo amino acid composition (PseAAC) with an SVM to develop an algorithm for AFP prediction (AFP-PseAAC)<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>. Yang <italic>et al</italic>. developed an ensemble-based learning method named AFP-Ensemble<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>, in which the RF classifier was trained for predicting AFPs. As they performed the evaluation on a non-standard dataset, their results are not discussed in this study. Xiao <italic>et al</italic>. developed a predictor named iAFP-Ense<sup><xref ref-type="bibr" rid="CR27">27</xref></sup> by incorporating evolutionary information into PseAAC using RF classifiers; however, the classifier was not evaluated on an independent test dataset. Khan <italic>et al</italic>. performed segmentation of protein sequences to divide them into two groups for amino acid composition (AAC) and di-peptide composition analyses<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. The dominating features were selected using information gain and ranker methods, and classification was performed using the RF classifier. A web-based predictor for AFPs called CryoProtect<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> is proposed using the RF classifier. The predictor used AAC and di-peptide composition as features for the classifier. The classification of AFP from other protein families is an example of a class imbalance problem. A widely adopted technique to deal with the unbalanced dataset is resampling<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>. Simple resampling techniques involve over-sampling, in which records from the minority class are randomly duplicated, and under-sampling, which executes a random removal of some records from the majority class. However, over-sampling has been reported to pose the problem of overfitting<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> and under-sampling leads to the loss of information<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. To overcome these limitations Nath <italic>et al</italic>. adopted <italic>K</italic>-means clustering with ensemble prediction algorithms to predict AFPs<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>.</p>
    <p id="Par5">The aforementioned methods have shown a reasonable improvement in prediction performance. However, there is a need for an improved method to obtain the desired results. In particular, to the best of our knowledge, none of the methods discussed above have achieved a balanced accuracy value of 90% or above on the standard dataset.</p>
    <p id="Par6">In this work, we utilize the composition of <italic>k</italic>-spaced amino acid pairs (CKSAAP) for the numerical representation of the amino acid sequence, which has been successfully adopted by several researchers to address various prediction problems<sup><xref ref-type="bibr" rid="CR33">33</xref>–<xref ref-type="bibr" rid="CR35">35</xref></sup>. A part of this work was presented in<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>, where we explored the discrimination power of <italic>k</italic> = 0 to 13-spaced amino acid pairs. More specifically, we observed that a gap of <italic>k</italic> = 8 provides the best classification performance.</p>
    <p id="Par7">In recent times, deep learning has been used in various bio-informatics applications<sup><xref ref-type="bibr" rid="CR37">37</xref>,<xref ref-type="bibr" rid="CR38">38</xref></sup>. It has also been very successfully employed for classification problems<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>. The novelty of our work is that, for the first time, a deep-learning-based technique has been proposed for the classification of AFP sequences. As the dataset is significantly small in size and, with <italic>k</italic> = 8, the number of descriptors of the CKSAAP scheme is 3600, the training of the model becomes an ill-posed problem.</p>
    <p id="Par8">In this paper, we propose a novel machine-learning-based approach using the concept of latent space learning through a task-specific deep auto-encoder. An auto-encoder, generally used for feature compression<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>, is now utilized to perform composite functions, i.e., to extract significant features from the encoding scheme and to perform the prediction task. The auto-encoder is modified to learn minimally redundant and maximally relevant latent space features, and hence, the feature length is drastically reduced. Exploiting only these important attributes, the classifier achieves superior performance.</p>
    <p id="Par9">A thorough ablation study is performed on the model to obtain the optimal values of the hyperparameters and latent space size. The best model produces superior results on the evaluation parameters including the Matthews correlation coefficient (MCC), Youden’s index, balanced accuracy and F1 score. The workflow of the proposed method and the ablation studies performed are shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, and its details are discussed in later sections.<fig id="Fig1"><label>Figure 1</label><caption><p>(<bold>a</bold>) Workflow of the proposed algorithm. The features are extracted using CKSAAP encoding scheme by keeping the gap value <italic>k</italic> = 8. (<bold>b</bold>) Workflow of the ablation studies. To perform the ablation studies, the dataset is divided into training and test sets, where training dataset is composed of 1:1, 1:2 and 1:3 AFP:Non-AFP ratios i.e., 300:300, 300:600 and 300:900 AFPs:Non-AFPs respectively and remaining samples were used for test dataset. For each case 9 different models of latent variable size (<italic>LV</italic> = 1, 2, 3, 4, 5, 10, 15, 20 and 25) were designed.</p></caption><graphic xlink:href="41598_2020_63259_Fig1_HTML" id="d29e465"/></fig></p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>Evaluation parameters</title>
      <p id="Par10">AFP prediction is considered a classification problem. Accordingly, we use standard threshold-dependent parameters including sensitivity, specificity, accuracy, MCC, balanced accuracy, Youden’s index and F1 score to evaluate the performance of the proposed classifier. These parameters can be evaluated using the following equations:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sensitivity=\frac{TP}{TP+FN}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41598_2020_63259_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Specificity=\frac{TN}{TN+FP}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41598_2020_63259_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Accuracy=\frac{TP+TN}{TP+TN+FP+FN}$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41598_2020_63259_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MCC=\frac{TPTN-FPFN}{\sqrt{(TP+FP)(TN+FN)(TP+FN)(TN+FP)}}$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mi>M</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41598_2020_63259_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Balanced\,Accuracy=\frac{Sensitivity+Specificity}{2}$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mi>B</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mspace width=".25em"/><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:math><graphic xlink:href="41598_2020_63259_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Youden{\prime} s\,Index=Sensitivity+Specificity-1$$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mi>Y</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mo>′</mml:mo><mml:mi>s</mml:mi><mml:mspace width=".5em"/><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:math><graphic xlink:href="41598_2020_63259_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F1\,Score=2\ast \frac{{Precision}\ast {Recall}}{{Precision}+{Recall}}$$\end{document}</tex-math><mml:math id="M14" display="block"><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mspace width=".5em"/><mml:mi>S</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>∗</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo>∗</mml:mo><mml:mi mathvariant="italic">Recall</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">Recall</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41598_2020_63259_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Precision}=\frac{TP}{TP+FP}$$\end{document}</tex-math><mml:math id="M16" display="block"><mml:mi mathvariant="italic">Precision</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="41598_2020_63259_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>Here TP, FP, TN, and FN represent true positive (correctly classified AFP), false positive (incorrect classification of non-AFP as AFP), true negative (correctly classified non-AFP), and false negative (incorrect classification of AFP as non-AFP), respectively. Thus, sensitivity indicates the fraction of AFPs correctly classified as AFPs and specificity indicates the fraction of non-AFPs correctly classified as non-AFP. Accuracy indicates the ratio of the total number of correctly classified samples to the total number of samples. As the test dataset is highly imbalanced, the parameters that assess the predictor’s quality considering the imbalanced distribution of the test data must be emphasized. For example, MCC considers the TP, TN, FP, and FN values and is regarded as a balanced measure, even if the test dataset is imbalanced. The range of MCC lies between −1 → 1, with −1 indicating the worst binary classification and 1 indicating the best binary classification. Furthermore, balanced accuracy, which is defined as an average of the recall obtained on each class, is usually used when the test dataset is imbalanced. Youden’s index is a class-specific measure, and the F-score represents the harmonic mean of precision and recall/sensitivity.</p>
    </sec>
    <sec id="Sec4">
      <title>Dataset</title>
      <p id="Par11">The benchmark dataset<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> is obtained to assess the performance of our approach. The dataset was constructed by initially obtaining 221 AFPs from the Pfam database as seed. A stringent threshold, (<italic>E</italic> = 0.001), was chosen during the PSI-BLAST to remove any redundancy from the data. A manual check was performed to remove any non-AFPs, and finally, the CD-HIT program was used to reduce the sequence identity to 40%. The total number of proteins in the positive dataset is 481. The negative dataset has 9493 non-AFPs, which do not have overlap with the AFPs. These positive and negative datasets were divided into two subsets for training and testing.</p>
      <p id="Par12">For a fair comparison, the subsets are maintained to be quantitatively equal to the subsets used in the previous approaches i.e., 300 AFPs and 300 non-AFPs in the training subset, and 181 AFPs and 9193 non-AFPs in the test subset. The selection of proteins from the dataset was randomized to ensure generalization. Some methods have utilized an imbalanced training dataset to investigate the influence of the number of non-AFPs on the prediction performance<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>. Therefore, to determine the effect of data distribution, we performed an ablation study with 600, 900, and 1200 negative training samples during training while maintaining a constant number of positive samples i.e., 300.</p>
    </sec>
    <sec id="Sec5">
      <title>Features extraction</title>
      <sec id="Sec6">
        <title>Composition of k-spaced amino acid pairs</title>
        <p id="Par13">Several machine-learning approaches have been utilized to perform the prediction task for AFPs<sup><xref ref-type="bibr" rid="CR28">28</xref>,<xref ref-type="bibr" rid="CR42">42</xref></sup>. The fundamental task in developing a computation-based classification model is the translation of protein sequences to interpretative encoded numerical features. Therefore, the conversion of sequence into the numerical vector is indispensable. Various encoding schemes that employ numerous protein features have been developed to extract diverse information from the protein sequences. As it was believed that an individual feature extraction strategy may only represent a partial target’s knowledge<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>, in numerous studies, multiple feature extraction methods are combined to enhance the classification performance<sup><xref ref-type="bibr" rid="CR23">23</xref>,<xref ref-type="bibr" rid="CR24">24</xref>,<xref ref-type="bibr" rid="CR26">26</xref>,<xref ref-type="bibr" rid="CR27">27</xref></sup>. However, it has been observed in recent studies that a viable feature extraction method e.g., CKSAAP can equally contribute toward satisfactory prediction performances<sup><xref ref-type="bibr" rid="CR43">43</xref>–<xref ref-type="bibr" rid="CR45">45</xref></sup>. Thus, we utilized CKSAAP encoding scheme in the AFP-CKSAAP method<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>.</p>
        <p id="Par14">This encoding method has emphasized the significance of amino acid pairs and has been utilized in various classification methods<sup><xref ref-type="bibr" rid="CR34">34</xref>,<xref ref-type="bibr" rid="CR35">35</xref>,<xref ref-type="bibr" rid="CR46">46</xref></sup>. The feature vector is obtained by calculating the frequency of amino acid pairs separated by <italic>k</italic> (<italic>j</italic> = 0, 1, 2, … <italic>k</italic>) number of residues. The representation is based on the frequency of <italic>k</italic>-spaced amino acid pairs in a local sequence window. If <italic>k</italic> = 2, <italic>k</italic>-spaced pairs for <italic>j</italic> = 0, 1, and 2 are considered. For each value of <italic>j</italic>, the corresponding feature vectors <italic>F</italic><sub><italic>j</italic></sub> i.e., <italic>F</italic><sub>0</sub>, <italic>F</italic><sub>1</sub> and <italic>F</italic><sub>2</sub> as shown in Eqs. (<xref rid="Equ9" ref-type="">9</xref>), (<xref rid="Equ10" ref-type="">10</xref>), and (<xref rid="Equ11" ref-type="">11</xref>), respectively, are evaluated, each having a length of 400. The final feature vector <italic>F</italic> is computed by concatenating the individual feature vectors as shown in Eq. (<xref rid="Equ12" ref-type="">12</xref>). The value of each descriptor is calculated by dividing the number of occurrences of that amino acid pair by the total number of <italic>j</italic>-spaced residue pairs (<italic>N</italic><sub>0</sub>, <italic>N</italic><sub>1</sub> … <italic>N</italic><sub><italic>j</italic></sub>) in the protein. For <italic>j</italic>, <italic>N</italic><sub><italic>j</italic></sub> = <italic>L</italic> − (<italic>j</italic> + 1), where <italic>L</italic> is the length of the protein sequence. In Fig. <xref rid="Fig2" ref-type="fig">2</xref>, only a few windows have been highlighted for the purpose of illustration. However, in practice, all the amino acid pairs are covered in overlapping windows with the respective gap values.<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{0}={\left(\frac{{F}_{AA}}{{N}_{0}},\frac{{F}_{AC}}{{N}_{0}},\frac{{F}_{AD}}{{N}_{0}},\ldots ,\frac{{F}_{YY}}{{N}_{0}}\right)}_{400}$$\end{document}</tex-math><mml:math id="M18" display="block"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mrow><mml:mn>400</mml:mn></mml:mrow></mml:msub></mml:math><graphic xlink:href="41598_2020_63259_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{1}={\left(\frac{{F}_{AxA}}{{N}_{1}},\frac{{F}_{AxC}}{{N}_{1}},\frac{{F}_{AxD}}{{N}_{1}},\ldots ,\frac{{F}_{YxY}}{{N}_{1}}\right)}_{400}$$\end{document}</tex-math><mml:math id="M20" display="block"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>x</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>x</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>x</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>x</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mrow><mml:mn>400</mml:mn></mml:mrow></mml:msub></mml:math><graphic xlink:href="41598_2020_63259_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{2}={\left(\frac{{F}_{AxxA}}{{N}_{2}},\frac{{F}_{AxxC}}{{N}_{2}},\frac{{F}_{AxxD}}{{N}_{2}},\ldots ,\frac{{F}_{YxxY}}{{N}_{2}}\right)}_{400}$$\end{document}</tex-math><mml:math id="M22" display="block"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>x</mml:mi><mml:mi>x</mml:mi><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>x</mml:mi><mml:mi>x</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>x</mml:mi><mml:mi>x</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>…</mml:mi><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>Y</mml:mi><mml:mi>x</mml:mi><mml:mi>x</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mrow><mml:mn>400</mml:mn></mml:mrow></mml:msub></mml:math><graphic xlink:href="41598_2020_63259_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F={F}_{0}+\,+{F}_{1}+\,+\ldots +\,+{F}_{j}+\,+\ldots +\,+{F}_{k},\,F\in {{\mathbb{R}}}^{400\ast (k+1)}$$\end{document}</tex-math><mml:math id="M24" display="block"><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mspace width="-.25em"/><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mspace width="-.25em"/><mml:mo>+</mml:mo><mml:mi>…</mml:mi><mml:mo>+</mml:mo><mml:mspace width="-.25em"/><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mspace width="-.25em"/><mml:mo>+</mml:mo><mml:mi>…</mml:mi><mml:mo>+</mml:mo><mml:mspace width="-.25em"/><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width=".25em"/><mml:mi>F</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mn>400</mml:mn><mml:mo>∗</mml:mo><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math><graphic xlink:href="41598_2020_63259_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula><fig id="Fig2"><label>Figure 2</label><caption><p>Illustration of CKSAAP descriptor calculation for <italic>k</italic> = 2.</p></caption><graphic xlink:href="41598_2020_63259_Fig2_HTML" id="d29e1643"/></fig></p>
        <p id="Par15">It is evident from Eq. (<xref rid="Equ12" ref-type="">12</xref>) and Fig. <xref rid="Fig2" ref-type="fig">2</xref>, that the CKSAAP encoding scheme utilizes the the trivial information from the preceding features including AAC, DPC, and TPC, which have been proven to play a vital role in AFP prediction in earlier studies<sup><xref ref-type="bibr" rid="CR22">22</xref>,<xref ref-type="bibr" rid="CR28">28</xref>,<xref ref-type="bibr" rid="CR29">29</xref></sup>.</p>
      </sec>
      <sec id="Sec7">
        <title>Incremental feature selection</title>
        <p id="Par16">Selection of key representative parameters is important for improving the prediction performance of a classifier. AFP-CKSAAP has been thoroughly evaluated to determine the optimal value of <italic>k</italic> by manually performing the sequential forward selection method to determine the best-suited feature. The best performance of the classifier was obtained by maintaining the gap value <italic>k</italic> = 8<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. It is also evident from the references that an attribute vector obtained from a very large value of <italic>k</italic> will include redundant features and may not contribute toward prediction<sup><xref ref-type="bibr" rid="CR33">33</xref>,<xref ref-type="bibr" rid="CR47">47</xref></sup>. Owing to the significance of maintaining this value of <italic>k</italic>, in this study, we perform all the performance analyses by maintaining the constant gap value of <italic>k</italic> = 8.</p>
        <p id="Par17">From Eq. (<xref rid="Equ12" ref-type="">12</xref>), it can be inferred that the gap value <italic>k</italic> = 8 in CKSAAP retrieves a feature vector of length 3600. In AFP-CKSAAP, we utilized all the features for classification using a deep neural network that produced satisfactory results, outperforming the previously proposed methods by a fair margin. However, by training the algorithm with fewer training samples having large feature dimensions, there exists a possibility that the AFP-CKSAAP algorithm may lose its generalization for new samples. Therefore, in this study, we intend to achieve satisfactory prediction using a reduced number of features. This could be done by dimension reduction using existing methods such as principle component analysis<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>, Gini index<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>, and mutual information<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>. However, recently, an auto-encoder has also been effectively used for dimension reduction<sup><xref ref-type="bibr" rid="CR51">51</xref>,<xref ref-type="bibr" rid="CR52">52</xref></sup>. An auto-encoder, which is an unsupervised algorithm, has emerged as a successful neural network framework that learns to represent the input data in much fewer dimensions and regenerates an output approximately similar to the input that has been fed to it. The principal function of this algorithm is its ability to reconstruct the input using substantially fewer features by constraining the latent space. The properties of the latent space in the auto-encoder make it a favorable candidate for feature compression in this study. The details of the architecture of the auto-encoder and its utilization in this study are discussed later sections.</p>
      </sec>
    </sec>
    <sec id="Sec8">
      <title>Latent space learning for AFP classification</title>
      <p id="Par18">In this study, we design a novel auto-encoder-based classification model for the prediction of AFP proteins. The proposed model is a combination of auto-encoder and classifier. By simultaneously training the auto-encoder and classifier, we successfully learned a noise-free latent space representation, which is composed of variables that have learned the least redundant and most relevant attributes of the input data. The architecture of the proposed model is shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>.<fig id="Fig3"><label>Figure 3</label><caption><p>Architecture of the proposed model for AFP classification. The encoder is composed of an input layer and four hidden layers and embeds the observation to the latent space. The output layer of the encoder is the latent space, connected to the last hidden layer of the the encoder, and serves as the input for the decoder and classifier.The decoder is the complement of the encoder and decodes the representation to the original space. The classifier is a fully connected four-layered multilayer perceptron and is tuned to perform prediction task.</p></caption><graphic xlink:href="41598_2020_63259_Fig3_HTML" id="d29e1738"/></fig></p>
      <sec id="Sec9">
        <title>Network specifications</title>
        <sec id="Sec10">
          <title>Auto-encoder</title>
          <p id="Par19">An auto-encoder is an unsupervised learning algorithm that aims to learn to reproduce the input using fewer dimensions. We propose to use a multilayer auto-encoder architecture that has been regularized to be sparse to generate compressed latent space. By imposing a sparsity penalty during training, the model learns the most informative and discriminative features for AFP classification  from the input data as a byproduct<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>. The architecture is composed of three sections: (i) an encoder with some hidden layers, (ii) a latent space, which represents the encoded input in reduced dimensions by ignoring the noise in the input<sup><xref ref-type="bibr" rid="CR53">53</xref></sup>, and (iii) a decoder that regenerates the input from the latent space variables. The number of hidden layers and the number of neurons in each layer of the encoder and decoder are varied to obtain reasonable performance. In this study, the encoder and decoder are composed of five layers, including four hidden layers. The number of neurons in the input layer of the encoder is equal to the length of the attribute vector, the number of neurons in the first hidden layer is 50, the numbers of neurons in the second and third hidden layers of the encoder are 25 each, and the fourth hidden layer has 10 neurons. The number of neurons in the latent space is systematically altered to obtain the best performance. The best performance was achieved when four neurons in the space were selected. The decoder is a complement of the encoder, this symmetry ensures the smooth encoding and decoding procedure<sup><xref ref-type="bibr" rid="CR54">54</xref></sup>. Therefore, the number of neurons in the first hidden layer of the decoder is equal to that in the last layer of the encoder and so on i.e., the numbers of neurons in the first, second, third and fourth hidden layers of the decoder are 10, 25, 25, and 50 respectively. Finally, the number of neurons in the output layer of the decoder is equal to the length of attribute vector.</p>
          <p id="Par20">The latent space, represents the learned representative features, and is the middle layer of the auto-encoder. It is shared between the encoder and decoder, serving as the final layer for the encoder and the input layer for the decoder. In the proposed model, the latent space has been regularized to be sensitive to the unique statistical features of the input by adding a regularization term in the loss function.</p>
          <p id="Par21">Therefore, the model retrieves the information by using the most discriminative features only, essentially serving the classification task. Thus, the classifier is trained on the dominant features, and the decoder is trained to regenerate the input from the latent variables.</p>
        </sec>
        <sec id="Sec11">
          <title>Classifier</title>
          <p id="Par22">The classifier is designed to process the latent space variables generated by the auto-encoder module. For the classification, a similar approach as in AFP-CKSAAP<sup><xref ref-type="bibr" rid="CR36">36</xref></sup> i.e., multilayer perceptron (MLP), is implemented. The architecture of the classifier, as shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, is composed of three hidden layers and an output layer. The final layer of the encoder, which is the latent space, serves as an input layer for the classifier. Therefore, the input layer of the classifier has 4 neurons, each hidden layer has 10 neurons, and the number of neurons in the output layer is equivalent to the number of classes.</p>
        </sec>
      </sec>
      <sec id="Sec12">
        <title>Training method</title>
        <p id="Par23">The model consisting of two modules, the auto-encoder module and the classifier module as shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>, is trained using Python on Keras (Tensorflow) for 1000 epochs with a variant of the gradient descent algorithm called Rmsprop<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>. Each layer of the auto-encoder module uses a rectified linear unit (ReLU) as an activation function to avoid a vanishing gradient. Furthermore, a dropout layer with 30% is used after each layer for better generalization and to avoid overfitting. For the classification module, ReLU has been used as an activation function for all the layers, except the output layer where the softmax function is used to generate class prediction probabilities.</p>
        <p id="Par24">The proposed model generates two types of outputs: (i) a decoded feature vector, and (ii) a class label of input protein. For the auto-encoder and classifier modules, we used different loss functions to minimize their respective error values. To train the auto-encoder, we use a mean squared error (MSE) loss function, whereas the classifier module is optimized by minimizing the binary cross entropy between the true class and predicted class labels. The MSE is calculated between the input and decoded feature vectors of the auto-encoder. The results of MSE values for all the auto-encoder models are presented in Table <xref rid="Tab1" ref-type="table">1</xref>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Performance of the proposed method evaluated on widely used metrics for different data distributions and variations in the latent space size.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>No. of latent variables:</th><th>LV1</th><th>LV2</th><th>LV3</th><th>LV4</th><th>LV5</th><th>LV10</th><th>LV15</th><th>LV20</th><th>LV25</th></tr><tr><th>Training samples ratios:</th><th colspan="9">1:1 AFP:NON-AFP</th></tr></thead><tbody><tr><td><italic>Sensitivity (%)</italic></td><td>84.83 ± 3.95</td><td>79.72 ± 7.22</td><td>82.59 ± 6.39</td><td>82.18 ± 5.21</td><td>85.58 ± 5.40</td><td>82.59 ± 4.68</td><td>82.03 ± 5.50</td><td>81.13 ± 8.94</td><td>80.49 ± 6.94</td></tr><tr><td><italic>Specificity (%)</italic></td><td>91.52 ± 3.04</td><td>90.82 ± 4.39</td><td>89.95 ± 2.66</td><td>92.86 ± 4.01</td><td>88.95 ± 3.75</td><td>90.73 ± 3.25</td><td>93.06 ± 2.26</td><td>91.97 ± 3.99</td><td>91.51 ± 2.94</td></tr><tr><td><italic>Balanced Accuracy (%)</italic></td><td>88.17 ± 1.19</td><td>85.27 ± 2.63</td><td>86.27 ± 2.30</td><td>87.52 ± 1.40</td><td>87.26 ± 1.79</td><td>86.66 ± 2.01</td><td>87.54 ± 1.90</td><td>86.55 ± 2.78</td><td>86.00 ± 2.40</td></tr><tr><td><italic>Youden’s Index</italic></td><td>0.76 ± 0.02</td><td>0.70 ± 0.05</td><td>0.72 ± 0.04</td><td>0.75 ± 0.02</td><td>0.74 ± 0.03</td><td>0.73 ± 0.04</td><td>0.75 ± 0.03</td><td>0.73 ± 0.05</td><td>0.72 ± 0.04</td></tr><tr><td><italic>MCC</italic></td><td>0.46 ± 0.05</td><td>0.33 ± 0.04</td><td>0.32 ± 0.03</td><td>0.48 ± 0.07</td><td>0.32 ± 0.04</td><td>0.34 ± 0.06</td><td>0.48 ± 0.04</td><td>0.46 ± 0.06</td><td>0.34 ± 0.04</td></tr><tr><td><italic>F1-Score</italic></td><td>0.42 ± 0.07</td><td>0.26 ± 0.05</td><td>0.25 ± 0.04</td><td>0.46 ± 0.09</td><td>0.24 ± 0.05</td><td>0.27 ± 0.07</td><td>0.45 ± 0.05</td><td>0.43 ± 0.08</td><td>0.28 ± 0.06</td></tr><tr><td><italic>MSE (dB)</italic></td><td>−14.69 ± 3.34</td><td>−15.90 ± 4.08</td><td>−16.57 ± 5.30</td><td>−18.45 ± 6.40</td><td>−17.08 ± 7.45</td><td>−18.31 ± 7.72</td><td>−16.27 ± 2.26</td><td>−17.86 ± 4.92</td><td>−15.96 ± 4.42</td></tr><tr><td><bold>Training samples ratios:</bold></td><td colspan="9"><bold>1:2 AFP:NON-AFP</bold></td></tr><tr><td><italic>Sensitivity (%)</italic></td><td>79.77 ± 7.69</td><td>75.74 ± 4.81</td><td>76.79 ± 7.06</td><td>83.42 ± 5.50</td><td>77.23 ± 7.50</td><td>77.73 ± 5.77</td><td>79.22 ± 8.14</td><td>82.04 ± 8.10</td><td>76.96 ± 8.10</td></tr><tr><td><italic>Specificity (%)</italic></td><td>93.16 ± 2.80</td><td>94.84 ± 1.33</td><td>94.08 ± 2.59</td><td>90.02 ± 4.38</td><td>93.23 ± 4.88</td><td>94.56 ± 2.40</td><td>93.29 ± 2.89</td><td>92.88 ± 2.50</td><td>94.21 ± 2.24</td></tr><tr><td><italic>Balanced Accuracy (%)</italic></td><td>86.47 ± 2.69</td><td>85.29 ± 2.11</td><td>85.43 ± 2.58</td><td>86.72 ± 1.25</td><td>85.23 ± 1.80</td><td>86.15 ± 1.72</td><td>86.26 ± 2.94</td><td>87.46 ± 1.42</td><td>85.58 ± 3.08</td></tr><tr><td><italic>Youden’s Index</italic></td><td>0.72 ± 0.05</td><td>0.70 ± 0.04</td><td>0.70 ± 0.05</td><td>0.73 ± 0.02</td><td>0.70 ± 0.03</td><td>0.72 ± 0.03</td><td>0.72 ± 0.05</td><td>0.74 ± 0.02</td><td>0.71 ± 0.06</td></tr><tr><td><italic>MCC</italic></td><td>0.38 ± 0.05</td><td>0.40 ± 0.03</td><td>0.40 ± 0.05</td><td>0.33 ± 0.05</td><td>0.39 ± 0.07</td><td>0.42 ± 0.06</td><td>0.38 ± 0.05</td><td>0.38 ± 0.05</td><td>0.40 ± 0.05</td></tr><tr><td><italic>F1-Score</italic></td><td>0.32 ± 0.08</td><td>0.36 ± 0.04</td><td>0.35 ± 0.07</td><td>0.26 ± 0.07</td><td>0.35 ± 0.10</td><td>0.37 ± 0.09</td><td>0.33 ± 0.07</td><td>0.32 ± 0.06</td><td>0.35 ± 0.07</td></tr><tr><td><italic>MSE (dB)</italic></td><td>−16.71 ± 6.38</td><td>−17.28 ± 4.30</td><td>−14.28 ± 2.38</td><td>−18.63 ± 4.54</td><td>−16.00 ± 3.05</td><td>−18.43 ± 4.99</td><td>−14.48 ± 2.46</td><td>−18.24 ± 2.79</td><td>−16.76 ± 4.72</td></tr><tr><td><bold>Training samples ratios:</bold></td><td colspan="9"><bold>1:3 AFP:NON-AFP</bold></td></tr><tr><td><italic>Sensitivity (%)</italic></td><td>71.27 ± 2.60</td><td>80.11 ± 6.09</td><td>76.46 ± 6.15</td><td>75.74 ± 10.78</td><td>76.40 ± 5.13</td><td>76.68 ± 4.60</td><td>82.70 ± 4.97</td><td>76.62 ± 5.26</td><td>77.01 ± 7.26</td></tr><tr><td><italic>Specificity (%)</italic></td><td>94.77 ± 3.01</td><td>94.38 ± 2.84</td><td>96.21 ± 1.80</td><td>95.41 ± 2.23</td><td>95.19 ± 1.53</td><td>95.57 ± 1.67</td><td>93.28 ± 2.87</td><td>95.47 ± 1.90</td><td>95.84 ± 2.00</td></tr><tr><td><italic>Balanced Accuracy (%)</italic></td><td>83.02 ± 11.92</td><td>87.24 ± 1.94</td><td>86.33 ± 2.23</td><td>85.57 ± 4.63</td><td>86.30 ± 1.89</td><td>86.13 ± 1.75</td><td>87.99 ± 1.21</td><td>86.05 ± 1.79</td><td>86.42 ± 2.87</td></tr><tr><td><italic>Youden’s Index</italic></td><td>0.66 ± 0.23</td><td>0.74 ± 0.03</td><td>0.72 ± 0.04</td><td>0.71 ± 0.09</td><td>0.72 ± 0.03</td><td>0.72 ± 0.03</td><td>0.75 ± 0.02</td><td>0.72 ± 0.03</td><td>0.72 ± 0.05</td></tr><tr><td><italic>MCC</italic></td><td>0.37 ± 0.13</td><td>0.43 ± 0.07</td><td>0.48 ± 0.06</td><td>0.44 ± 0.05</td><td>0.47 ± 0.05</td><td>0.44 ± 0.06</td><td>0.40 ± 0.04</td><td>0.44 ± 0.06</td><td>0.46 ± 0.05</td></tr><tr><td><italic>F1-Score</italic></td><td>0.33 ± 0.13</td><td>0.38 ± 0.09</td><td>0.44 ± 0.08</td><td>0.40 ± 0.07</td><td>0.44 ± 0.07</td><td>0.41 ± 0.08</td><td>0.34 ± 0.06</td><td>0.40 ± 0.08</td><td>0.43 ± 0.07</td></tr><tr><td><italic>MSE (dB)</italic></td><td>−18.82 ± 7.91</td><td>−17.16 ± 3.86</td><td>−15.86 ± 2.51</td><td>−16.18 ± 3.82</td><td>−16.68 ± 1.85</td><td>−15.44 ± 2.21</td><td>−17.89 ± 4.84</td><td>−16.27 ± 3.60</td><td>−17.32 ± 2.87</td></tr></tbody></table></table-wrap></p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec13" sec-type="results">
    <title>Results</title>
    <p id="Par25">Herein, we present the results of the experiments performed for the evaluation of the model. The training dataset is randomly divided into two subsets, i.e., training and validation, with the ratio of 90:10, i.e., out of 600 samples, 540 samples were used for training and 60 samples for validation. We used early stopping with the patience of 50 epochs to avoid overfitting, and we stopped the training if the model stopped improving. The metric in the early stopping was validation loss, and the training was stopped at approximately 700 epochs. The best model was obtained by performing the ablation study, the details of which are discussed later in the text.</p>
    <sec id="Sec14">
      <title>Ablation study</title>
      <p id="Par26">In this work, we perform an ablation study to obtain a simple overall architecture. This is motivated by the fact that the latent space is sparsely populated. This sparse space eliminates redundancies to achieve the degree of compression factor that can be reached. To this end, a benchmark architecture is evaluated with various modifications in the design, and the performance of each model is observed. One must choose an optimal number of neurons in the latent space so that the feature vector is significantly reduced, and the decoder must be able to regenerate the input using these features. Furthermore, the latent space serves as the input layer of the classifier network, which makes it crucial. Considering the significance of the latent variables, in this study, we evaluated the models with varying number of latent space variables. Additionally, we intended to observe the behavior of the model with respect to the data distribution in the train dataset. The existing studies, with some exceptions, have been conducted on the balanced training dataset of the benchmark data. For a fair comparison, we used a similar configuration of the train and test datasets. However, to evaluate the robustness of the proposed method, we also train it using an unbalanced dataset.</p>
    </sec>
    <sec id="Sec15">
      <title>Effect of latent variables</title>
      <p id="Par27">In the first ablation study, we observe the effect of varying the number of variables in the latent space by maintaining a constant balanced data distribution for training. Since the latent space is sparsely populated, it satisfies the limitation on the compression factor. Therefore, we start the evaluation by maintaining the latent space variable of length 25. The latent space variables (LV) are then systematically reduced and evaluated by reducing 5 neurons. Subsequently, after evaluating the performance of the model for LV 5 neurons, the latent space variables were further reduced one by one. For each configuration, 20 simulation runs are performed, and the values of the statistical parameters such as MCC, Youden’s index, balanced accuracy, F1 score, and MSE are observed. The mean values of Youden’s index and the MSE for the reconstruction error have been depicted in Figs. <xref rid="Fig4" ref-type="fig">4</xref> and <xref rid="Fig5" ref-type="fig">5</xref>, respectively.<fig id="Fig4"><label>Figure 4</label><caption><p>Effect on the Youden’s index values by varying number of variables in the latent space.</p></caption><graphic xlink:href="41598_2020_63259_Fig4_HTML" id="d29e2572"/></fig><fig id="Fig5"><label>Figure 5</label><caption><p>MSE values depicting reconstruction error for various auto-encoder models.</p></caption><graphic xlink:href="41598_2020_63259_Fig5_HTML" id="d29e2581"/></fig></p>
    </sec>
    <sec id="Sec16">
      <title>Effect of data distribution</title>
      <p id="Par28">Another ablation study was performed to observe the sensitivity of the model for training the data distribution. To this end, AFPs and non-AFPs were fused in three distinct subsets having AFP and non-AFP ratios of 1:1, 1:2, and 1:3. Additionally, the effect of the latent space variables on the data distribution was considered; therefore, the training was performed on incremental latent space variables. Yang <italic>et al</italic>. studied the effect of an imbalanced training dataset and it has been reported that their classifier does not comprehend the imbalanced data and classifies most of the samples to the majority class<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>, the results therefore are not appreciable. However, the proposed classifier (AFP-LSE) has the tendency to learn further motif information when the number of training samples is increased. Appreciable values of performance metrics in Table <xref rid="Tab1" ref-type="table">1</xref>, suggests that the performance of the classifier can be improved by utilizing the supplementary information from the negative class. As there is a limitation in the availability of AFP datasets, previous studies have been conducted on a small balanced dataset. Therefore, for a comparison, we report the results of the performance of the classifier trained by using similar configurations.</p>
      <sec id="Sec17">
        <title>Performance evaluation and comparison with contemporary methods</title>
        <p id="Par29">After an analysis of the results obtained from the ablation study performed to determine the optimal parameters and the size of the latent space, the best model is selected as the classifier for AFP and is named as AFP-LSE. The model is trained with CKSAAP encoded samples with <italic>k</italic> = 8, with the number of latent space variables <italic>LV</italic> = 4 and with 1:1 ratio of training and test datasets. The model is evaluated on an independent test dataset, and its results on the statistical parameters are better than those obtained by the previously reported methods. This study evaluates the performance of the classifier on the parameters reflecting the true efficacy of the classifier by considering the imbalanced condition of the training and testing datasets. Therefore, we emphasize the parameters MCC, balanced accuracy, and Youden’s index due to their insensitivity toward imbalance in classes. The best model showed the MCC value of 0.52, balanced accuracy of more than 90%, and Youden’s index value of 0.81. The performance of AFP-LSE is compared with those of the existing methods as shown in Table <xref rid="Tab2" ref-type="table">2</xref>. Based on the prediction results, AFP-LSE achieved superior performance on all the statistical measures. Particularly, improvements of approximately 2% and 5% in the balanced accuracy and Youden’s index, respectively, were observed when compared with the corresponding values for the best classifier in the literature i.e., CryoProtect<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>. Similarly, the best values of the MCC and F-score were demonstrated by AFP_PSSM<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>, whereas the proposed classifier shows improvements of approximately 52% and 68%, respectively, for the aforementioned parameters.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Comparison of best performing AFP-LSE model with contemporary approaches on an external validation set containing 181 AFPs and 9193 Non-AFPs and trained with a balanced dataset comprising 300 AFPs and 300 Non-AFPs.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Methods</th><th>Classifier</th><th>Sensitivity</th><th>Specificity</th><th>Acc</th><th>Youden’s Ind</th><th>Bal Acc</th><th>MCC</th><th>F-Score</th></tr></thead><tbody><tr><td>iAFP<sup><xref ref-type="bibr" rid="CR23">23</xref></sup></td><td>SVM</td><td>13.2%</td><td>97.0%</td><td>95.3%</td><td>0.10</td><td>55.1%</td><td>0.08</td><td>0.10</td></tr><tr><td>AFP-Pred<sup><xref ref-type="bibr" rid="CR22">22</xref></sup></td><td>RF</td><td>84.6%</td><td>82.3%</td><td>83.3%</td><td>0.63</td><td>83.4%</td><td>0.23</td><td>0.15</td></tr><tr><td>AFP_PSSM<sup><xref ref-type="bibr" rid="CR24">24</xref></sup></td><td>SVM</td><td>75.8%</td><td>93.2%</td><td>93.0%</td><td>0.69</td><td>84.5%</td><td>0.34</td><td>0.29</td></tr><tr><td>AFP-PseAAC<sup><xref ref-type="bibr" rid="CR25">25</xref></sup></td><td>SVM</td><td>86.1%</td><td>84.7%</td><td>84.7%</td><td>0.70</td><td>85.4%</td><td>0.26</td><td>0.17</td></tr><tr><td>RAFP-Pred<sup><xref ref-type="bibr" rid="CR28">28</xref></sup></td><td>RF</td><td>84.0%</td><td>91.0%</td><td>90.9%</td><td>0.75</td><td>87.5%</td><td>0.33</td><td>0.26</td></tr><tr><td>CryoProtect<sup><xref ref-type="bibr" rid="CR29">29</xref></sup></td><td>RF</td><td>87.2%</td><td>88.3%</td><td>88.2%</td><td>0.76</td><td>87.7%</td><td>0.30</td><td>0.22</td></tr><tr><td>AFP-CKSAAP<sup><xref ref-type="bibr" rid="CR36">36</xref></sup></td><td>DNN</td><td>94.0%</td><td>87.0%</td><td>88.0%</td><td>0.81</td><td>90.5%</td><td>0.32</td><td>0.22</td></tr><tr><td><bold>Proposed</bold></td><td>AE + DNN</td><td>86.7%</td><td>93.9%</td><td>93.7%</td><td>0.81</td><td>90.3%</td><td>0.52</td><td>0.49</td></tr></tbody></table></table-wrap></p>
      </sec>
      <sec id="Sec18">
        <title>Prediction of novel AFP candidates</title>
        <p id="Par30">Considering the extreme rarity of AFPs within entire organism proteomes, herein, we perform the screening of novel AFP candidate proteins. An independent dataset containing 10 candidate AFPs was obtained from the INTERPRO<sup><xref ref-type="bibr" rid="CR56">56</xref></sup> database. The sequences in this independent test dataset were not present in the positive or negative datasets of AFP-LSE. The prediction results of AFP-LSE were compared with those of PSI-BLAST search from UNIPROT<sup><xref ref-type="bibr" rid="CR57">57</xref></sup> and SWISSPROT<sup><xref ref-type="bibr" rid="CR58">58</xref></sup> databases on <italic>E</italic> = 0.1. The AFP-LSE predicted 9 proteins as AFPs and only 1 protein is predicted as non-AFP. Interestingly, the same protein is also classified as non-AFP by PSI-BLAST. Compared with AFP-LSE, PSI-BLAST retrieved only 4 out 10 candidate sequences as AFPs as shown in Table <xref rid="Tab3" ref-type="table">3</xref>. The NCBI database annotated 4 out of 10 sequences as hypothetical or unnamed proteins; further three of them were characterized as Type I antifreeze, or AFP-like domain-containing proteins, whereas the annotations of the remaining three are shown in Table <xref rid="Tab3" ref-type="table">3</xref>. The performance of AFP-LSE suggests that it can be effectively utilized for the annotation of hypothetical proteins.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Prediction results for 10 candidate antifreeze proteins obtained from INTERPRO<sup><xref ref-type="bibr" rid="CR56">56</xref></sup> database.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>GI Number</th><th>UniProtKB ACC</th><th>AFP-LSE</th><th>PSI-BLAST</th><th>NCBI Definition</th></tr></thead><tbody><tr><td>26325086</td><td>Q14DU1</td><td>Non-AFP</td><td>Non-AFP</td><td>Kelch-like 11 (Drosophila)</td></tr><tr><td>74221639</td><td>Q3V0I3</td><td>AFP</td><td>AFP</td><td>Uncharacterized protein</td></tr><tr><td>12843602</td><td>Q9D7P2</td><td>AFP</td><td>Non-AFP</td><td>Uncharacterized protein</td></tr><tr><td>30249105</td><td>Q82VH2</td><td>AFP</td><td>AFP</td><td>Type I antifreeze protein</td></tr><tr><td>45435722</td><td>Q66D88</td><td>AFP</td><td>Non-AFP</td><td>Hypothetical protein</td></tr><tr><td>281341260</td><td>D2H0G8</td><td>AFP</td><td>AFP</td><td>AFP-like domain-containing protein</td></tr><tr><td>2315605</td><td>O16596</td><td>AFP</td><td>Non-AFP</td><td>Cell division coordinator CpoB</td></tr><tr><td>260817607</td><td>C3YJ26</td><td>AFP</td><td>AFP</td><td>AFP-like domain-containing protein</td></tr><tr><td>26388908</td><td>Q8BMV6</td><td>AFP</td><td>Non-AFP</td><td>RIKEN cDNA E130116L18 gene</td></tr><tr><td>26348120</td><td>Q8C1R8</td><td>AFP</td><td>Non-AFP</td><td>Uncharacterized protein</td></tr></tbody></table></table-wrap></p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec19" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par31">Due to the lack of availability of AFP samples, the nature of the available dataset is skewed, therefore, the classification of AFPs from non-AFPs poses a class imbalance problem which is challenging for machine-learning algorithms<sup><xref ref-type="bibr" rid="CR59">59</xref></sup>. In addition to this class imbalance, there is an issue of rare cases of sub-types in AFP, as in “AFP” class, where only fewer sub-types are in abundance, which leads to intra-class imbalance and introduces outlier artifacts in designing a reliable classifier. In contrast, in typical classification problems e.g., in the case of lysine acetylation sites prediction in proteins, or the identification of protein-protein binding sites, there is an availability of a substantially large number of positive and negative samples in datasets, hence, they do not suffer from the problem of class imbalance or intra-class variation<sup><xref ref-type="bibr" rid="CR33">33</xref>,<xref ref-type="bibr" rid="CR60">60</xref>,<xref ref-type="bibr" rid="CR61">61</xref></sup>. Another challenge faced in the classification of AFPs is the variation in the sequences of AFPs, which subsequently produces features with low inter-class and high intra-class variance. These inevitable phenomena are the consequences of the similarity exhibited by AFPs with different protein families from which they are assumed to be evolved<sup><xref ref-type="bibr" rid="CR18">18</xref>,<xref ref-type="bibr" rid="CR19">19</xref></sup> and because different AFPs present low sequence similarity among each other. Principal component analysis (PCA) projection of CKSAAP features, which is discussed later in the text, establishes explicit evidence in Fig. <xref rid="Fig6" ref-type="fig">6(a,b)</xref>, that both AFPs and non-AFPs appear in an overlapping fashion, suggesting that the development of the AFP classifier using linear methods is an arduous task.<fig id="Fig6"><label>Figure 6</label><caption><p>Comparison of proposed auto-encoder-based latent space encoding (AE-LSE) with principal component analysis (PCA) method for 2D projection.</p></caption><graphic xlink:href="41598_2020_63259_Fig6_HTML" id="d29e3172"/></fig></p>
    <p id="Par32">For an insightful understanding of CKSAAP representation-based classification of AFPs using the given dataset, we present a comparison of the PCA and AFP-LSE methods. For visual assessments, the data were projected on two dimensions utilizing the top two eigenvectors in the case of PCA and two latent spaces in the case of AFP-LSE. As shown in Fig. <xref rid="Fig6" ref-type="fig">6(c)</xref>, the proposed non-linear auto-encoder-based latent space encoding (AE-LSE) presents superior learning capabilities and maps the AFPs and non-AFPs in separate regions in contrast to the linear unsupervised sub-space learning method of PCA depicted in Fig. <xref rid="Fig6" ref-type="fig">6(a)</xref>, which fails to do so, revealing that both classes are inseparable in a linear sense.</p>
    <p id="Par33">The same eigenvectors and the latent space from PCA and AE-LSE respectively, obtained from training are then utilized to project the test data. Differences in the mapping capabilities of AFPs can be observed for both the PCA and AE-LSE methods in Fig. <xref rid="Fig6" ref-type="fig">6(b,d)</xref> respectively. It can be observed in the bottom right of the Fig. <xref rid="Fig6" ref-type="fig">6(d)</xref> that the AE-LSE method forms clusters of AFP samples. Nevertheless, there is some overlapping of non-AFPs, the overall separability of the data projected through the AE-LSE method is better than that of the data linearly projected by the PCA, indicating that the discovery of unknown groups using PCA is strenuous. This helps in understanding the working principle of the proposed method and the motivation for the development of non-linear auto-encoder-based learning of latent space.</p>
    <p id="Par34">The proposed method can contribute toward the design of a superior mapping function resulting in a reduction of dimensions while retaining the information that separates the AFP from the non-AFP samples. Recently, many researchers have shown interest in auto-encoder-based models<sup><xref ref-type="bibr" rid="CR62">62</xref></sup>. However, to the best of our knowledge, no auto-encoder-based classifier has been proposed for the classification of protein sequences. The proposed model can be used for the prediction of other types of proteins as well, for instance, bioluminance proteins (BLPs)<sup><xref ref-type="bibr" rid="CR63">63</xref></sup> and extra cellular matrix proteins (ECM)<sup><xref ref-type="bibr" rid="CR64">64</xref></sup> etc. In particular, it can be utilized for the dimensionality reduction in highly non-linear classification problems where number attributes are higher than the training samples. To avoid overfitting, we used regularization techniques such as dropout and batch-normalization in this study. For future studies we would recommend utilizing transfer learning approach where the AFP-LSE model is first trained with a closely related classification task and later fine-tuned for AFP dataset. However, transfer learning and other training strategies are beyond the scope of this study. The Python implementation of the proposed algorithm has been made public, and interested user can utilize the algorithm for their problem of interest. The algorithm is available at (<ext-link ext-link-type="uri" xlink:href="https://github.com/Shujaat123/AFP-LSE">https://github.com/Shujaat123/AFP-LSE</ext-link>). In the near future, we would like to explore auto-encoder-based classifiers further for other bio-informatics problems.</p>
  </sec>
  <sec id="Sec20" sec-type="conclusion">
    <title>Conclusion</title>
    <p id="Par35">The prediction of AFPs due to the unavailability of a substantial dataset and the inherent diversity in the sequence and structures is a challenging classification problem that has been addressed by various researchers. In the proposed prediction method, each protein sequence was encoded using CKSAAP with <italic>k</italic> = 8. The results of our previous study showed that these features can significantly contribute to the classification performance. For classification, we proposed a novel machine-learning-based method for the AFP prediction. The method uses an auto-encoder for feature compression, and these reduced features are used to train the neural-network-based classifier. A comparison of the proposed non-linear mapping method with the linear projection approach of PCA demonstrated superior classification capabilities of the proposed method. A comprehensive ablation study was performed for a better understanding of the effect of latent space variables as well as the impact of training data distribution, and widely used biostatistics nomenclatures were evaluated. The method yields excellent classification results on the benchmark dataset, outperforming the existing methods, particularly yielding an MCC value of 0.52 with a Youden’s index of 0.81.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>This study was supported by research fund from Chosun University, 2019. We also thank anonymous reviewer for insightful comments, Prof Imran Naseem (imran.naseem@uwa.edu.au) and Seongyong Park (sypark0215@kaist.ac.kr) for useful suggestions.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>M.U. and S.K. designed the research, M.U. conducted the experiments and wrote the manuscript, S.K. conceived the experiments and performed analysis, J.L. analyzed the results. All authors discussed the results and reviewed the manuscript.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par36">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>DeVries</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Wohlschlag</surname>
            <given-names>DE</given-names>
          </name>
        </person-group>
        <article-title>Freezing resistance in some antarctic fishes</article-title>
        <source>Science</source>
        <year>1969</year>
        <volume>163</volume>
        <fpage>1073</fpage>
        <lpage>1075</lpage>
        <pub-id pub-id-type="doi">10.1126/science.163.3871.1073</pub-id>
        <?supplied-pmid 5764871?>
        <pub-id pub-id-type="pmid">5764871</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Crevel</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Fedyk</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Spurgeon</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Antifreeze proteins: characteristics, occurrence and human exposure</article-title>
        <source>Food and Chemical Toxicology</source>
        <year>2002</year>
        <volume>40</volume>
        <fpage>899</fpage>
        <lpage>903</lpage>
        <pub-id pub-id-type="doi">10.1016/S0278-6915(02)00042-X</pub-id>
        <?supplied-pmid 12065210?>
        <pub-id pub-id-type="pmid">12065210</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Davies</surname>
            <given-names>PL</given-names>
          </name>
          <name>
            <surname>Baardsnes</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kuiper</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Walker</surname>
            <given-names>VK</given-names>
          </name>
        </person-group>
        <article-title>Structure and function of antifreeze proteins</article-title>
        <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>
        <year>2002</year>
        <volume>357</volume>
        <fpage>927</fpage>
        <lpage>935</lpage>
        <pub-id pub-id-type="doi">10.1098/rstb.2002.1081</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kuramochi</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Expression of ice-binding proteins in caenorhabditis elegans improves the survival rate upon cold shock and during freezing</article-title>
        <source>Scientific reports</source>
        <year>2019</year>
        <volume>9</volume>
        <fpage>6246</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-019-42650-8</pub-id>
        <?supplied-pmid 31092839?>
        <pub-id pub-id-type="pmid">31092839</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Davies</surname>
            <given-names>PL</given-names>
          </name>
          <name>
            <surname>Hew</surname>
            <given-names>CL</given-names>
          </name>
        </person-group>
        <article-title>Biochemistry of fish antifreeze proteins</article-title>
        <source>The FASEB Journal</source>
        <year>1990</year>
        <volume>4</volume>
        <fpage>2460</fpage>
        <lpage>2468</lpage>
        <pub-id pub-id-type="doi">10.1096/fasebj.4.8.2185972</pub-id>
        <?supplied-pmid 2185972?>
        <pub-id pub-id-type="pmid">2185972</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Masud</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Joardder</surname>
            <given-names>MU</given-names>
          </name>
          <name>
            <surname>Karim</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Effect of hysteresis phenomena of cellular plant-based food materials on convection drying kinetics</article-title>
        <source>Drying Technology</source>
        <year>2019</year>
        <volume>37</volume>
        <fpage>1313</fpage>
        <lpage>1320</lpage>
        <pub-id pub-id-type="doi">10.1080/07373937.2018.1498508</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yamazaki</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Nishimiya</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Tsuda</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Togashi</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Munehara</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Freeze tolerance in sculpins (pisces; cottoidea) inhabiting north pacific and arctic oceans: Antifreeze activity and gene sequences of the antifreeze protein</article-title>
        <source>Biomolecules</source>
        <year>2019</year>
        <volume>9</volume>
        <fpage>139</fpage>
        <pub-id pub-id-type="doi">10.3390/biom9040139</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <mixed-citation publication-type="other">de Menezes, G. C. A., Porto, B. A., Simões, J. C., Rosa, C. A. &amp;Rosa, L. H. Fungi in snow and glacial ice of antarctica. In <italic>Fungi of Antarctica</italic>, 127–146 (Springer, 2019).</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Arai</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Fukami</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hoshino</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Kondo</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Tsuda</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Ice-binding proteins from the fungus antarctomyces psychrotrophicus possibly originate from two different bacteria through horizontal gene transfer</article-title>
        <source>The FEBS journal</source>
        <year>2019</year>
        <volume>286</volume>
        <fpage>946</fpage>
        <lpage>962</lpage>
        <pub-id pub-id-type="doi">10.1111/febs.14725</pub-id>
        <?supplied-pmid 30548092?>
        <pub-id pub-id-type="pmid">30548092</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pe</surname>
            <given-names>PPW</given-names>
          </name>
          <name>
            <surname>Naing</surname>
            <given-names>AH</given-names>
          </name>
          <name>
            <surname>Chung</surname>
            <given-names>MY</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>KI</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>CK</given-names>
          </name>
        </person-group>
        <article-title>The role of antifreeze proteins in the regulation of genes involved in the response of hosta capitata to cold</article-title>
        <source>3 Biotech</source>
        <year>2019</year>
        <volume>9</volume>
        <fpage>335</fpage>
        <pub-id pub-id-type="doi">10.1007/s13205-019-1859-5</pub-id>
        <?supplied-pmid 31475087?>
        <pub-id pub-id-type="pmid">31475087</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vu</surname>
            <given-names>HM</given-names>
          </name>
          <name>
            <surname>Pennoyer</surname>
            <given-names>JE</given-names>
          </name>
          <name>
            <surname>Ruiz</surname>
            <given-names>KR</given-names>
          </name>
          <name>
            <surname>Portmann</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Duman</surname>
            <given-names>JG</given-names>
          </name>
        </person-group>
        <article-title>Beetle, dendroides canadensis, antifreeze proteins increased high temperature survivorship in transgenic fruit flies, drosophila melanogaster</article-title>
        <source>Journal of insect physiology</source>
        <year>2019</year>
        <volume>112</volume>
        <fpage>68</fpage>
        <lpage>72</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jinsphys.2018.12.004</pub-id>
        <?supplied-pmid 30562493?>
        <pub-id pub-id-type="pmid">30562493</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Naing</surname>
            <given-names>AH</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>CK</given-names>
          </name>
        </person-group>
        <article-title>A brief review of applications of antifreeze proteins in cryopreservation and metabolic genetic engineering</article-title>
        <source>3 Biotech</source>
        <year>2019</year>
        <volume>9</volume>
        <fpage>329</fpage>
        <pub-id pub-id-type="doi">10.1007/s13205-019-1861-y</pub-id>
        <?supplied-pmid 31448185?>
        <pub-id pub-id-type="pmid">31448185</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">Gong, S. <italic>et al</italic>. Evaluation of the antifreeze effects and its related mechanism of sericin peptides on the frozen dough of steamed potato bread. <italic>Journal of Food Processing and Preservation</italic> e14053 (2019).</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meister</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Molecular structure of a hyperactive antifreeze protein adsorbed to ice</article-title>
        <source>The Journal of chemical physics</source>
        <year>2019</year>
        <volume>150</volume>
        <fpage>131101</fpage>
        <pub-id pub-id-type="doi">10.1063/1.5090589</pub-id>
        <?supplied-pmid 30954062?>
        <pub-id pub-id-type="pmid">30954062</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>HJ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Marine antifreeze proteins: structure, function, and application to cryopreservation as a potential cryoprotectant</article-title>
        <source>Marine drugs</source>
        <year>2017</year>
        <volume>15</volume>
        <fpage>27</fpage>
        <pub-id pub-id-type="doi">10.3390/md15020027</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jia</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Davies</surname>
            <given-names>PL</given-names>
          </name>
        </person-group>
        <article-title>Antifreeze proteins: an unusual receptor–ligand interaction</article-title>
        <source>Trends in biochemical sciences</source>
        <year>2002</year>
        <volume>27</volume>
        <fpage>101</fpage>
        <lpage>106</lpage>
        <pub-id pub-id-type="doi">10.1016/S0968-0004(01)02028-X</pub-id>
        <?supplied-pmid 11852248?>
        <pub-id pub-id-type="pmid">11852248</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Graham</surname>
            <given-names>LA</given-names>
          </name>
          <name>
            <surname>Marshall</surname>
            <given-names>CB</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>F-H</given-names>
          </name>
          <name>
            <surname>Campbell</surname>
            <given-names>RL</given-names>
          </name>
          <name>
            <surname>Davies</surname>
            <given-names>PL</given-names>
          </name>
        </person-group>
        <article-title>Hyperactive antifreeze protein from fish contains multiple ice-binding sites</article-title>
        <source>Biochemistry</source>
        <year>2008</year>
        <volume>47</volume>
        <fpage>2051</fpage>
        <lpage>2063</lpage>
        <pub-id pub-id-type="doi">10.1021/bi7020316</pub-id>
        <?supplied-pmid 18225917?>
        <pub-id pub-id-type="pmid">18225917</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fletcher</surname>
            <given-names>GL</given-names>
          </name>
          <name>
            <surname>Hew</surname>
            <given-names>CL</given-names>
          </name>
          <name>
            <surname>Davies</surname>
            <given-names>PL</given-names>
          </name>
        </person-group>
        <article-title>Antifreeze proteins of teleost fishes</article-title>
        <source>Annual review of physiology</source>
        <year>2001</year>
        <volume>63</volume>
        <fpage>359</fpage>
        <lpage>390</lpage>
        <pub-id pub-id-type="doi">10.1146/annurev.physiol.63.1.359</pub-id>
        <?supplied-pmid 11181960?>
        <pub-id pub-id-type="pmid">11181960</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nath</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Subbiah</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>The role of pertinently diversified and balanced training as well as testing data sets in achieving the true performance of classifiers in predicting the antifreeze proteins</article-title>
        <source>Neurocomputing</source>
        <year>2018</year>
        <volume>272</volume>
        <fpage>294</fpage>
        <lpage>305</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neucom.2017.07.004</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Altschul</surname>
            <given-names>SF</given-names>
          </name>
          <name>
            <surname>Gish</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Myers</surname>
            <given-names>EW</given-names>
          </name>
          <name>
            <surname>Lipman</surname>
            <given-names>DJ</given-names>
          </name>
        </person-group>
        <article-title>Basic local alignment search tool</article-title>
        <source>Journal of molecular biology</source>
        <year>1990</year>
        <volume>215</volume>
        <fpage>403</fpage>
        <lpage>410</lpage>
        <pub-id pub-id-type="doi">10.1016/S0022-2836(05)80360-2</pub-id>
        <?supplied-pmid 2231712?>
        <pub-id pub-id-type="pmid">2231712</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Altschul</surname>
            <given-names>SF</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Gapped blast and psi-blast: a new generation of protein database search programs</article-title>
        <source>Nucleic acids research</source>
        <year>1997</year>
        <volume>25</volume>
        <fpage>3389</fpage>
        <lpage>3402</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/25.17.3389</pub-id>
        <?supplied-pmid 9254694?>
        <pub-id pub-id-type="pmid">9254694</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kandaswamy</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>AFP-Pred: A random forest approach for predicting antifreeze proteins from sequence-derived</article-title>
        <source>Journal of Theoretical Biology</source>
        <year>2011</year>
        <volume>270</volume>
        <fpage>56</fpage>
        <lpage>62</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2010.10.037</pub-id>
        <?supplied-pmid 21056045?>
        <pub-id pub-id-type="pmid">21056045</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>C-S</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>C-H</given-names>
          </name>
        </person-group>
        <article-title>Identification of antifreeze proteins and their functional residues by support vector machine and genetic algorithms based on n-peptide compositions</article-title>
        <source>PloS one</source>
        <year>2011</year>
        <volume>6</volume>
        <fpage>e20445</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0020445</pub-id>
        <?supplied-pmid 21655262?>
        <pub-id pub-id-type="pmid">21655262</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiaowei</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhiqiang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Minghao</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Using support vector machine and evolutionary profiles to predict antifreeze protein sequences</article-title>
        <source>International Journal of Molecular Science</source>
        <year>2012</year>
        <volume>13</volume>
        <fpage>2196</fpage>
        <lpage>2207</lpage>
        <pub-id pub-id-type="doi">10.3390/ijms13022196</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mondal</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Pai</surname>
            <given-names>PP</given-names>
          </name>
        </person-group>
        <article-title>Chou’s pseudo amino acid composition improves sequence-based antifreeze protein prediction</article-title>
        <source>Journal of theoretical biology</source>
        <year>2014</year>
        <volume>356</volume>
        <fpage>30</fpage>
        <lpage>35</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2014.04.006</pub-id>
        <?supplied-pmid 24732262?>
        <pub-id pub-id-type="pmid">24732262</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>An effective antifreeze protein predictor with ensemble classifiers and comprehensive sequence descriptors</article-title>
        <source>International journal of molecular sciences</source>
        <year>2015</year>
        <volume>16</volume>
        <fpage>21191</fpage>
        <lpage>21214</lpage>
        <pub-id pub-id-type="doi">10.3390/ijms160921191</pub-id>
        <?supplied-pmid 26370959?>
        <pub-id pub-id-type="pmid">26370959</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Hui</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>iafp-ense: an ensemble classifier for identifying antifreeze protein by incorporating grey model and pssm into pseaac</article-title>
        <source>The Journal of membrane biology</source>
        <year>2016</year>
        <volume>249</volume>
        <fpage>845</fpage>
        <lpage>854</lpage>
        <pub-id pub-id-type="doi">10.1007/s00232-016-9935-9</pub-id>
        <?supplied-pmid 27812737?>
        <pub-id pub-id-type="pmid">27812737</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Khan</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Naseem</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Togneri</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Bennamoun</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Rafp-pred: Robust prediction of antifreeze proteins using localized analysis of n-peptide compositions</article-title>
        <source>IEEE/ACM Transactions on Computational Biology and Bioinformatics</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>244</fpage>
        <lpage>250</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2016.2617337</pub-id>
        <?supplied-pmid 28113406?>
        <pub-id pub-id-type="pmid">28113406</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Pratiwi, R. <italic>et al</italic>. Cryoprotect: a web server for classifying antifreeze proteins from nonantifreeze proteins. <italic>Journal of Chemistry</italic><bold>2017</bold> (2017).</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Tyagi, S. &amp; Mittal, S. Sampling approaches for imbalanced data classification problem in machine learning. In <italic>Proceedings of ICRIC 2019</italic>, 209–221 (Springer, 2020).</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Krawczyk, B., Koziarski, M. &amp; Wozniak, M. Radial-based oversampling for multiclass imbalanced data classification. <italic>IEEE transactions on neural networks and learning systems</italic> (2019).</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vuttipittayamongkol</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Elyan</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Neighbourhood-based undersampling approach for handling imbalanced and overlapped data</article-title>
        <source>Information Sciences</source>
        <year>2020</year>
        <volume>509</volume>
        <fpage>47</fpage>
        <lpage>70</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ins.2019.08.062</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>A deep learning method to more accurately recall known lysine acetylation sites</article-title>
        <source>BMC bioinformatics</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>49</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-019-2632-9</pub-id>
        <?supplied-pmid 30674277?>
        <pub-id pub-id-type="pmid">30674277</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Deepubi: a deep learning framework for prediction of ubiquitination sites in proteins</article-title>
        <source>BMC bioinformatics</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>86</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-019-2677-9</pub-id>
        <?supplied-pmid 30777029?>
        <pub-id pub-id-type="pmid">30777029</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Chen, D., Tian, X., Zhou, B. &amp; Gao, J. Profold: Protein fold classification with additional structural features and a novel ensemble classifier. <italic>BioMed research international</italic><bold>2016</bold> (2016).</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Usman, M. &amp; Lee, J. A. Afp-cksaap: Prediction of antifreeze proteins using composition of k-spaced amino acid pairs with deep neural network. In <italic>2019 IEEE 19th International Conference on Bioinformatics and Bioengineering (BIBE)</italic>, 38–43 (IEEE, 2019).</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Tang, B., Pan, Z., Yin, K. &amp; Khateeb, A. Recent advances of deep learning in bioinformatics and computational biology. <italic>Frontiers in Genetics</italic><bold>10</bold> (2019).</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Li, F. <italic>et al</italic>. Deepcleave: a deep learning predictor for caspase and matrix metalloprotease substrates and cleavage sites. <italic>Bioinformatics</italic><bold>10</bold> (2019).</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Khan</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Islam</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Jan</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Din</surname>
            <given-names>IU</given-names>
          </name>
          <name>
            <surname>Rodrigues</surname>
            <given-names>JJC</given-names>
          </name>
        </person-group>
        <article-title>A novel deep learning based framework for the detection and classification of breast cancer using transfer learning</article-title>
        <source>Pattern Recognition Letters</source>
        <year>2019</year>
        <volume>125</volume>
        <fpage>1</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patrec.2019.03.022</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ng</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Sparse autoencoder</article-title>
        <source>CS294A Lecture notes</source>
        <year>2011</year>
        <volume>72</volume>
        <fpage>1</fpage>
        <lpage>19</lpage>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Du</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>PseAAC-Builder: A cross-platform stand-alone program for generating various special Chou’s pseudo-amino acid compositions</article-title>
        <source>Analytical biochemistry</source>
        <year>2012</year>
        <volume>425</volume>
        <fpage>117</fpage>
        <lpage>119</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ab.2012.03.015</pub-id>
        <?supplied-pmid 22459120?>
        <pub-id pub-id-type="pmid">22459120</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kozuch</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Stillinger</surname>
            <given-names>FH</given-names>
          </name>
          <name>
            <surname>Debenedetti</surname>
            <given-names>PG</given-names>
          </name>
        </person-group>
        <article-title>Combined molecular dynamics and neural network method for predicting protein antifreeze activity</article-title>
        <source>Proceedings of the National Academy of Sciences</source>
        <year>2018</year>
        <volume>115</volume>
        <fpage>13252</fpage>
        <lpage>13257</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1814945115</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ju</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>S-Y</given-names>
          </name>
        </person-group>
        <article-title>Prediction of citrullination sites by incorporating k-spaced amino acid pairs into chou’s general pseudo amino acid composition</article-title>
        <source>Gene</source>
        <year>2018</year>
        <volume>664</volume>
        <fpage>78</fpage>
        <lpage>83</lpage>
        <pub-id pub-id-type="doi">10.1016/j.gene.2018.04.055</pub-id>
        <?supplied-pmid 29694908?>
        <pub-id pub-id-type="pmid">29694908</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <mixed-citation publication-type="other">Ju, Z. &amp; Wang, S.-Y. Prediction of lysine formylation sites using the composition of k-spaced amino acid pairs via chou’s 5-steps rule and general pseudo components. <italic>Genomics</italic> (2019).</mixed-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>Prediction of protein ubiquitination sites in arabidopsis thaliana</article-title>
        <source>Current Bioinformatics</source>
        <year>2019</year>
        <volume>14</volume>
        <fpage>614</fpage>
        <lpage>620</lpage>
        <pub-id pub-id-type="doi">10.2174/1574893614666190311141647</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Prediction of ubiquitination sites by using the composition of k-spaced amino acid pairs</article-title>
        <source>PloS one</source>
        <year>2011</year>
        <volume>6</volume>
        <fpage>e22930</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0022930</pub-id>
        <?supplied-pmid 21829559?>
        <pub-id pub-id-type="pmid">21829559</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Q-Y</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Du</surname>
            <given-names>P-F</given-names>
          </name>
        </person-group>
        <article-title>Predicting protein lysine phosphoglycerylation sites by hybridizing many sequence based features</article-title>
        <source>Molecular BioSystems</source>
        <year>2017</year>
        <volume>13</volume>
        <fpage>874</fpage>
        <lpage>882</lpage>
        <pub-id pub-id-type="doi">10.1039/C6MB00875E</pub-id>
        <?supplied-pmid 28396891?>
        <pub-id pub-id-type="pmid">28396891</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ringnér</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>What is principal component analysis?</article-title>
        <source>Nature biotechnology</source>
        <year>2008</year>
        <volume>26</volume>
        <fpage>303</fpage>
        <pub-id pub-id-type="doi">10.1038/nbt0308-303</pub-id>
        <?supplied-pmid 18327243?>
        <pub-id pub-id-type="pmid">18327243</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yitzhaki</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>On an extension of the gini inequality index</article-title>
        <source>International economic review</source>
        <year>1983</year>
        <volume>24</volume>
        <fpage>617</fpage>
        <lpage>628</lpage>
        <pub-id pub-id-type="doi">10.2307/2648789</pub-id>
      </element-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Naseem</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Togneri</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Bennamoun</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Ecmsrc: A sparse learning approach for the prediction of extracellular matrix proteins</article-title>
        <source>Current Bioinformatics</source>
        <year>2017</year>
        <volume>12</volume>
        <fpage>361</fpage>
        <lpage>368</lpage>
        <pub-id pub-id-type="doi">10.2174/1574893611666151215213508</pub-id>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gogna</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Majumdar</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Discriminative autoencoder for feature extraction: Application to character recognition</article-title>
        <source>Neural Processing Letters</source>
        <year>2019</year>
        <volume>49</volume>
        <fpage>1723</fpage>
        <lpage>1735</lpage>
        <pub-id pub-id-type="doi">10.1007/s11063-018-9894-5</pub-id>
      </element-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>L</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Unsupervised eeg feature extraction based on echo state network</article-title>
        <source>Information Sciences</source>
        <year>2019</year>
        <volume>475</volume>
        <fpage>1</fpage>
        <lpage>17</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ins.2018.09.057</pub-id>
      </element-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <mixed-citation publication-type="other">Bhowick, D., Gupta, D. K., Maiti, S. &amp; Shankar, U. Stacked autoencoders based machine learning for noise reduction and signal reconstruction in geophysical data. <italic>arXiv preprint arXiv:1907.03278</italic> (2019).</mixed-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yoon</surname>
            <given-names>YH</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Huh</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>JC</given-names>
          </name>
        </person-group>
        <article-title>Efficient b-mode ultrasound image reconstruction from sub-sampled rf data using deep learning</article-title>
        <source>IEEE transactions on medical imaging</source>
        <year>2018</year>
        <volume>38</volume>
        <fpage>325</fpage>
        <lpage>336</lpage>
        <pub-id pub-id-type="doi">10.1109/TMI.2018.2864821</pub-id>
        <?supplied-pmid 30106712?>
        <pub-id pub-id-type="pmid">30106712</pub-id>
      </element-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tieleman</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude</article-title>
        <source>COURSERA: Neural networks for machine learning</source>
        <year>2012</year>
        <volume>4</volume>
        <fpage>26</fpage>
        <lpage>31</lpage>
      </element-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hunter</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Interpro: the integrative protein signature database</article-title>
        <source>Nucleic acids research</source>
        <year>2009</year>
        <volume>37</volume>
        <fpage>D211</fpage>
        <lpage>D215</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkn785</pub-id>
        <?supplied-pmid 18940856?>
        <pub-id pub-id-type="pmid">18940856</pub-id>
      </element-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Consortium</surname>
            <given-names>TU</given-names>
          </name>
        </person-group>
        <article-title>UniProt: a worldwide hub of protein knowledge</article-title>
        <source>Nucleic Acids Research</source>
        <year>2018</year>
        <volume>47</volume>
        <fpage>D506</fpage>
        <lpage>D515</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gky1049</pub-id>
      </element-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boeckmann</surname>
            <given-names>B</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The swiss-prot protein knowledgebase and its supplement trembl in 2003</article-title>
        <source>Nucleic acids research</source>
        <year>2003</year>
        <volume>31</volume>
        <fpage>365</fpage>
        <lpage>370</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkg095</pub-id>
        <?supplied-pmid 12520024?>
        <pub-id pub-id-type="pmid">12520024</pub-id>
      </element-citation>
    </ref>
    <ref id="CR59">
      <label>59.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Johnson</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Khoshgoftaar</surname>
            <given-names>TM</given-names>
          </name>
        </person-group>
        <article-title>Survey on deep learning with class imbalance</article-title>
        <source>Journal of Big Data</source>
        <year>2019</year>
        <volume>6</volume>
        <fpage>27</fpage>
        <pub-id pub-id-type="doi">10.1186/s40537-019-0192-5</pub-id>
      </element-citation>
    </ref>
    <ref id="CR60">
      <label>60.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fernandez-Recio</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Totrov</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Skorodumov</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Abagyan</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Optimal docking area: a new method for predicting protein–protein interaction sites</article-title>
        <source>PROTEINS: Structure, Function, and bioinformatics</source>
        <year>2005</year>
        <volume>58</volume>
        <fpage>134</fpage>
        <lpage>143</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.20285</pub-id>
      </element-citation>
    </ref>
    <ref id="CR61">
      <label>61.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jia</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <article-title>Identification of protein-protein binding sites by incorporating the physicochemical properties and stationary wavelet transforms into pseudo amino acid composition</article-title>
        <source>Journal of Biomolecular Structure and Dynamics</source>
        <year>2016</year>
        <volume>34</volume>
        <fpage>1946</fpage>
        <lpage>1961</lpage>
        <pub-id pub-id-type="doi">10.1080/07391102.2015.1095116</pub-id>
        <?supplied-pmid 26375780?>
        <pub-id pub-id-type="pmid">26375780</pub-id>
      </element-citation>
    </ref>
    <ref id="CR62">
      <label>62.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Eraslan</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Simon</surname>
            <given-names>LM</given-names>
          </name>
          <name>
            <surname>Mircea</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Mueller</surname>
            <given-names>NS</given-names>
          </name>
          <name>
            <surname>Theis</surname>
            <given-names>FJ</given-names>
          </name>
        </person-group>
        <article-title>Single-cell rna-seq denoising using a deep count autoencoder</article-title>
        <source>Nature communications</source>
        <year>2019</year>
        <volume>10</volume>
        <fpage>1</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="doi">10.1038/s41467-018-07931-2</pub-id>
      </element-citation>
    </ref>
    <ref id="CR63">
      <label>63.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Strack</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Building up bioluminescence</article-title>
        <source>Nature methods</source>
        <year>2019</year>
        <volume>16</volume>
        <fpage>20</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-018-0274-x</pub-id>
        <?supplied-pmid 30573844?>
        <pub-id pub-id-type="pmid">30573844</pub-id>
      </element-citation>
    </ref>
    <ref id="CR64">
      <label>64.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Garcia-Garcera</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Rocha</surname>
            <given-names>EP</given-names>
          </name>
        </person-group>
        <article-title>Community diversity and habitat structure shape the repertoire of extracellular proteins in bacteria</article-title>
        <source>Nature Communications</source>
        <year>2020</year>
        <volume>11</volume>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="doi">10.1038/s41467-020-14572-x</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
