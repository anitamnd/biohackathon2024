<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLoS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8982879</article-id>
    <article-id pub-id-type="pmid">35324898</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1009986</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-21-01590</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Molecular Biology</subject>
          <subj-group>
            <subject>Macromolecular Structure Analysis</subject>
            <subj-group>
              <subject>Protein Structure</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Protein Structure</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Molecular Biology</subject>
          <subj-group>
            <subject>Macromolecular Structure Analysis</subject>
            <subj-group>
              <subject>Protein Structure</subject>
              <subj-group>
                <subject>Protein Structure Comparison</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Protein Structure</subject>
              <subj-group>
                <subject>Protein Structure Comparison</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Database and Informatics Methods</subject>
          <subj-group>
            <subject>Biological Databases</subject>
            <subj-group>
              <subject>Protein Structure Databases</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Molecular Biology</subject>
          <subj-group>
            <subject>Macromolecular Structure Analysis</subject>
            <subj-group>
              <subject>Protein Structure</subject>
              <subj-group>
                <subject>Protein Structure Databases</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Protein Structure</subject>
              <subj-group>
                <subject>Protein Structure Databases</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Molecular Biology</subject>
          <subj-group>
            <subject>Macromolecular Structure Analysis</subject>
            <subj-group>
              <subject>Protein Structure</subject>
              <subj-group>
                <subject>Protein Structure Prediction</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Protein Structure</subject>
              <subj-group>
                <subject>Protein Structure Prediction</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Neural Networks</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Neural Networks</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Molecular Biology</subject>
          <subj-group>
            <subject>Macromolecular Structure Analysis</subject>
            <subj-group>
              <subject>Protein Structure</subject>
              <subj-group>
                <subject>Protein Structure Networks</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Protein Structure</subject>
              <subj-group>
                <subject>Protein Structure Networks</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Database and Informatics Methods</subject>
          <subj-group>
            <subject>Bioinformatics</subject>
            <subj-group>
              <subject>Sequence Analysis</subject>
              <subj-group>
                <subject>Sequence Alignment</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Structural Engineering</subject>
          <subj-group>
            <subject>Built Structures</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Fast protein structure comparison through effective representation learning with contrastive graph neural networks</article-title>
      <alt-title alt-title-type="running-head">Fast protein structure comparison through effective representation learning</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4910-1430</contrib-id>
        <name>
          <surname>Xia</surname>
          <given-names>Chunqiu</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Feng</surname>
          <given-names>Shi-Hao</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xia</surname>
          <given-names>Ying</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5010-464X</contrib-id>
        <name>
          <surname>Pan</surname>
          <given-names>Xiaoyong</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="cor001" ref-type="corresp">*</xref>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4029-3325</contrib-id>
        <name>
          <surname>Shen</surname>
          <given-names>Hong-Bin</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="cor001" ref-type="corresp">*</xref>
        <xref rid="aff001" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <addr-line>Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, and Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai, China</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Punta</surname>
          <given-names>Marco</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>San Raffaele Hospital: IRCCS Ospedale San Raffaele, ITALY</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>2008xypan@sjtu.edu.cn</email> (XP); <email>hbshen@sjtu.edu.cn</email> (HS)</corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>24</day>
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <volume>18</volume>
    <issue>3</issue>
    <elocation-id>e1009986</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>8</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>3</day>
        <month>3</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 Xia et al</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Xia et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1009986.pdf"/>
    <abstract>
      <p>Protein structure alignment algorithms are often time-consuming, resulting in challenges for large-scale protein structure similarity-based retrieval. There is an urgent need for more efficient structure comparison approaches as the number of protein structures increases rapidly. In this paper, we propose an effective graph-based protein structure representation learning method, GraSR, for fast and accurate structure comparison. In GraSR, a graph is constructed based on the intra-residue distance derived from the tertiary structure. Then, deep graph neural networks (GNNs) with a short-cut connection learn graph representations of the tertiary structures under a contrastive learning framework. To further improve GraSR, a novel dynamic training data partition strategy and length-scaling cosine distance are introduced. We objectively evaluate our method GraSR on SCOPe v2.07 and a new released independent test set from PDB database with a designed comprehensive performance metric. Compared with other state-of-the-art methods, GraSR achieves about 7%-10% improvement on two benchmark datasets. GraSR is also much faster than alignment-based methods. We dig into the model and observe that the superiority of GraSR is mainly brought by the learned discriminative residue-level and global descriptors. The web-server and source code of GraSR are freely available at <ext-link xlink:href="http://www.csbio.sjtu.edu.cn/bioinf/GraSR/" ext-link-type="uri">www.csbio.sjtu.edu.cn/bioinf/GraSR/</ext-link> for academic use.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>The size and shape of protein structures vary considerably. Accurate protein structure comparison usually relies on structure alignment algorithms. However, superimposing two protein structures is relatively time-consuming, which makes it inappropriate for large-scale protein structure retrieval. Alignment-free algorithms are proposed for efficient protein structure comparison over the last few decades. These algorithms first transform the coordinates of atoms in two proteins to fixed-length vectors. Then, the comparison can be done by measuring the distance or similarity between two vectors, which is much faster than alignment. In this study, we propose a novel protein structure representation method for efficient structure comparison. Compared with other state-of-the-art alignment-free methods, our method achieves better performance on both ranking and multi-class classification tasks due to the powerful representation ability of deep graph neural networks. We dig into the model and observe that the superiority of our method is mainly brought by the learned discriminative residue-level and global descriptors.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>61725302</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4029-3325</contrib-id>
          <name>
            <surname>Shen</surname>
            <given-names>Hong-Bin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>62073219</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4029-3325</contrib-id>
          <name>
            <surname>Shen</surname>
            <given-names>Hong-Bin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award003">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100003399</institution-id>
            <institution>Science and Technology Commission of Shanghai Municipality</institution>
          </institution-wrap>
        </funding-source>
        <award-id>20S11902100</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5010-464X</contrib-id>
          <name>
            <surname>Pan</surname>
            <given-names>Xiaoyong</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>H.S. was supported by National Natural Science Foundation of China (No. 61725302, 62073219). X.P. was supported by Science and Technology Commission of Shanghai Municipality (20S11902100). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="7"/>
      <table-count count="4"/>
      <page-count count="21"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>PLOS Publication Stage</meta-name>
        <meta-value>vor-update-to-uncorrected-proof</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>Publication Update</meta-name>
        <meta-value>2022-04-05</meta-value>
      </custom-meta>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>The data and source code can be found at <ext-link xlink:href="https://github.com/chunqiux/GraSR" ext-link-type="uri">https://github.com/chunqiux/GraSR</ext-link>. In addition, we also archive it on Zenodo (<ext-link xlink:href="https://doi.org/10.5281/zenodo.5338957" ext-link-type="uri">https://doi.org/10.5281/zenodo.5338957</ext-link>).</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>The data and source code can be found at <ext-link xlink:href="https://github.com/chunqiux/GraSR" ext-link-type="uri">https://github.com/chunqiux/GraSR</ext-link>. In addition, we also archive it on Zenodo (<ext-link xlink:href="https://doi.org/10.5281/zenodo.5338957" ext-link-type="uri">https://doi.org/10.5281/zenodo.5338957</ext-link>).</p>
  </notes>
</front>
<body>
  <disp-quote>
    <p>This is a <italic toggle="yes">PLOS Computational Biology</italic> Software paper.</p>
  </disp-quote>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Protein structure comparison aims to measure the structural similarity between two different proteins. It is a core infrastructure for structural biology and provides support for protein structure prediction [<xref rid="pcbi.1009986.ref001" ref-type="bibr">1</xref>], protein-protein docking [<xref rid="pcbi.1009986.ref002" ref-type="bibr">2</xref>], structure-based protein function prediction [<xref rid="pcbi.1009986.ref003" ref-type="bibr">3</xref>], etc. Considering the number of experimentally solved protein structures is increasing rapidly in the Protein Data Bank (PDB) and the accuracy of protein structure prediction has improved dramatically in recent years, e.g. AlphaFold2 approach [<xref rid="pcbi.1009986.ref004" ref-type="bibr">4</xref>], it is highly desired to develop fast and accurate protein tertiary structure comparison methods which could benefit structural homology discovery and other downstream structure-based analysis [<xref rid="pcbi.1009986.ref005" ref-type="bibr">5</xref>].</p>
    <p>Protein structure comparison methods can be generally divided into two types: alignment-based methods [<xref rid="pcbi.1009986.ref006" ref-type="bibr">6</xref>–<xref rid="pcbi.1009986.ref013" ref-type="bibr">13</xref>] and alignment-free methods [<xref rid="pcbi.1009986.ref014" ref-type="bibr">14</xref>–<xref rid="pcbi.1009986.ref016" ref-type="bibr">16</xref>]. The former finds the optimal structural superposition of two protein structures. Then, scoring functions, such as RMSD (root-mean-squared deviation) [<xref rid="pcbi.1009986.ref017" ref-type="bibr">17</xref>], are used to measure the Euclidean distance between each pair of corresponding residues in the two proteins. The latter usually first transforms the Cartesian coordinates of all backbone atoms of a protein structure to a vector. Then, the structural comparison is performed by calculating the distance or correlation coefficient between the two corresponding vectors.</p>
    <p>For alignment-based methods, the most challenging task is how to superimpose the atomic coordinates of two protein structures, which has been proven an NP-hard problem [<xref rid="pcbi.1009986.ref018" ref-type="bibr">18</xref>]. To accelerate the alignment process, existing methods [<xref rid="pcbi.1009986.ref006" ref-type="bibr">6</xref>–<xref rid="pcbi.1009986.ref010" ref-type="bibr">10</xref>] generally apply heuristic algorithms. For example, heuristics are used in combinatorial extension (CE) for similarity evaluation and path extension [<xref rid="pcbi.1009986.ref006" ref-type="bibr">6</xref>]; Monte Carlo optimization is used in DALI for the assembly of alignments [<xref rid="pcbi.1009986.ref007" ref-type="bibr">7</xref>]; heuristic iteration combined with Needleman-Wunsch dynamic programming is used in STRUCTAL, SAL and TM-align to optimize the superposition [<xref rid="pcbi.1009986.ref008" ref-type="bibr">8</xref>–<xref rid="pcbi.1009986.ref010" ref-type="bibr">10</xref>,<xref rid="pcbi.1009986.ref019" ref-type="bibr">19</xref>].</p>
    <p>Generally, existing alignment-based methods are time-consuming. When searching against a large-scale protein structure database, alignment-based methods would be infeasible. For instance, for <italic toggle="yes">m</italic> query structures and a database containing <italic toggle="yes">n</italic> structures, the time complexity of similar structure retrieval will be O(<italic toggle="yes">mn</italic>) if the database is not specifically designed. For example, the 2.07 version of Structural Classification of Proteins-extended (SCOPe) database contains 87,224 PDB entries and 276,231 domains [<xref rid="pcbi.1009986.ref020" ref-type="bibr">20</xref>,<xref rid="pcbi.1009986.ref021" ref-type="bibr">21</xref>]. TM-align, one of the popular alignment-based methods, takes about 0.5 sec for one structural alignment on a 1.26 GHz PIII processor [<xref rid="pcbi.1009986.ref010" ref-type="bibr">10</xref>]. In total, it will take about 138,115 secs (more than 38 hours) for a single query to retrieve all similar domains. In addition, recent protein structure prediction tools can predict protein structures from sequences with a remarkable accuracy. It is expected that these prediction algorithms will soon be applied to the protein sequences with unknown structures. For example, over 8 million protein sequences are currently deposited in the NR database, which would result in millions of predicted protein structures in a near future. If searching such a big number of predicted protein structures against the PDB database, the time cost of alignment-based 3D structure comparison (e.g. TM-align) will be unaffordable. Thus, it is an urgent task to develop more efficient protein structure comparison methods for large-scale protein structure homology retrieval due to the explosion of protein 3D structure data.</p>
    <p>Compared with the alignment-based methods, alignment-free methods follow a different paradigm that represents a protein structure using a vector. This vector is named <italic toggle="yes">descriptor</italic> in this study by following the practice in other machine learning tasks [<xref rid="pcbi.1009986.ref022" ref-type="bibr">22</xref>,<xref rid="pcbi.1009986.ref023" ref-type="bibr">23</xref>]. In general, descriptors need to satisfy two requirements:1) the length should be fixed and independent of the size of proteins; 2) they should be invariant to rotation and translation of proteins.</p>
    <p>Generally, the alignment-free methods can be divided into three groups according to their ways of obtaining the descriptors. The first group is the geometry-based method, which extracts predefined geometric features from protein structures. For example, the scaled Gauss metric (SGM) is proposed based on knot theory [<xref rid="pcbi.1009986.ref014" ref-type="bibr">14</xref>]. It treats the protein backbone as a space curve and extracts Gaussian invariants from the curve. The second group is the frequency-based method. It first splits the whole protein structure into many short consecutive segments and then classifies each segment into one predefined type. For example, the secondary structure element footprint (SSEF) method [<xref rid="pcbi.1009986.ref015" ref-type="bibr">15</xref>] uses the frequencies of the combination of secondary structures as descriptors. Fragbag constructs a fragment template library and each segment in the backbone is associated with the most similar template in the library [<xref rid="pcbi.1009986.ref016" ref-type="bibr">16</xref>]. Frequencies of each fragment will be counted to form the descriptors. Both groups of alignment-free methods rely on hand-crafted geometric features.</p>
    <p>The third group is the learning-based method. Learning-based methods try to work around the sequence segmentation and feature engineering by learning structural representation automatically using deep neural networks. DeepFold is such a method, which extracts descriptors from intra-residue distance matrices under a Siamese framework with a convolutional neural network (CNN) encoder [<xref rid="pcbi.1009986.ref024" ref-type="bibr">24</xref>]. DeepFold model has suggested that deep learning techniques are able to extract more discriminative descriptors than the former two hand-designed alignment-free methods. However, DeepFold has a large number of parameters, which would decrease its efficiency. In addition, CNNs also could face challenges of effectively capturing the spatial relationships among residues in protein structures [<xref rid="pcbi.1009986.ref025" ref-type="bibr">25</xref>]. Alternatively, graph neural networks (GNNs) can be designed to handle the spatial graph data derived from protein structures with impressive performance [<xref rid="pcbi.1009986.ref026" ref-type="bibr">26</xref>].</p>
    <p>In this paper, we propose a novel <underline>Gra</underline>ph-based protein <underline>S</underline>tructure <underline>R</underline>epresentation (GraSR) method with deep GNNs. GraSR first represents the protein structures using graphs based on the intra-residue distance. Then, a contrastive learning framework is used to optimize the encoder, where TM-score derived from TM-align is used as the reference benchmark [<xref rid="pcbi.1009986.ref027" ref-type="bibr">27</xref>]. The encoder in GraSR consists of the long short-term memory neural network (LSTM) and GNN instead of the CNN [<xref rid="pcbi.1009986.ref028" ref-type="bibr">28</xref>,<xref rid="pcbi.1009986.ref029" ref-type="bibr">29</xref>]. Compared with CNN, GNN and LSTM have much fewer parameters, speeding up the training and inference procedure. In addition, GNN can learn global and local geometric features of residues better. Moreover, a new training data partition strategy and a length-based normalization technique are designed to further improve the performance. Several state-of-the-art methods and GraSR are evaluated on SCOPe v2.07 and an independent test set constructed from the newly released PDB. The results show that GraSR retrieves more similar protein structures and the extracted descriptors are more discriminative for fold recognition.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>Materials and methods</title>
    <p>In this section, we first introduce the benchmark datasets for evaluating GraSR. Then, we give the details about graph construction from protein structures and the proposed GNN encoder, which is trained under the framework of contrastive learning with two novel training strategies. Finally, experimental settings for ranking and multi-class classification tasks are given in detail.</p>
    <sec id="sec003">
      <title>Benchmark datasets</title>
      <p>In this study, we use SCOPe v2.07 (March 2018) as the benchmark set. The 40% identity filtered subset of SCOPe v2.07 is used to train and validate our model GraSR. This dataset contains 14,323 domains and 1,058 domains are removed during the data collection process (cf. Text A in <xref rid="pcbi.1009986.s001" ref-type="supplementary-material">S1 File</xref>). Thus, 13,265 domains are finally used for cross-validation. Each domain can be classified into one of the seven classes [<xref rid="pcbi.1009986.ref020" ref-type="bibr">20</xref>] including: a) All alpha proteins (2286 domains), b) All beta proteins (2757 domains), c) Alpha and beta proteins (a/b) (4148 domains), d) Alpha and beta proteins (a+b) (3378 domains), e) Multi-domain proteins (alpha and beta) (279 domains), f) Membrane and cell surface proteins and peptides (213 domains), and g) Small proteins (204 domains).</p>
      <p>In addition to SCOPe v2.07, we have also constructed an independent test set by using protein structures from PDB, the release date of which is from Oct 1<sup>st</sup> 2017 to Oct 1<sup>st</sup> 2019 (i.e., the date after the publication of DeepFold). If a certain PDB file contains multiple chains, it will be split into multiple files, each of which contains only one chain. Then, CD-HIT is used to remove the redundant sequences [<xref rid="pcbi.1009986.ref030" ref-type="bibr">30</xref>]. The sequence identity of the independent set itself and its sequence identity to SCOPe v2.07 are both below 40% after filtering. At last, 51 protein chains are removed due to the same technical issues as SCOPe. The final independent test set (named ind_PDB) contains 1,914 protein structures.</p>
    </sec>
    <sec id="sec004">
      <title>Graph construction and raw node feature extraction</title>
      <p>The graph of a protein structure <inline-formula id="pcbi.1009986.e001"><alternatives><graphic xlink:href="pcbi.1009986.e001.jpg" id="pcbi.1009986.e001g" position="anchor"/><mml:math id="M1" display="inline" overflow="scroll"><mml:mi mathvariant="script">G</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> is constructed based on the Cartesian coordinates of <italic toggle="yes">C</italic><sub><italic toggle="yes">α</italic></sub> atoms, where <italic toggle="yes">V</italic> is the set of nodes, <italic toggle="yes">E</italic> is the set of edges. In this study, each <italic toggle="yes">C</italic><sub><italic toggle="yes">α</italic></sub> atom is considered as a node and edges are defined between any two <italic toggle="yes">C</italic><sub><italic toggle="yes">α</italic></sub> atoms, which means <inline-formula id="pcbi.1009986.e002"><alternatives><graphic xlink:href="pcbi.1009986.e002.jpg" id="pcbi.1009986.e002g" position="anchor"/><mml:math id="M2" display="inline" overflow="scroll"><mml:mi mathvariant="script">G</mml:mi></mml:math></alternatives></inline-formula> is a complete graph. The intra-residue distance matrix is denoted as <inline-formula id="pcbi.1009986.e003"><alternatives><graphic xlink:href="pcbi.1009986.e003.jpg" id="pcbi.1009986.e003g" position="anchor"/><mml:math id="M3" display="inline" overflow="scroll"><mml:mi mathvariant="bold-script">D</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">N</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>, and <italic toggle="yes">N</italic><sub><italic toggle="yes">r</italic></sub> is the number of residues in the given protein. Then, the adjacency matrix <inline-formula id="pcbi.1009986.e004"><alternatives><graphic xlink:href="pcbi.1009986.e004.jpg" id="pcbi.1009986.e004g" position="anchor"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mi mathvariant="bold-script">A</mml:mi></mml:math></alternatives></inline-formula> is derived from <inline-formula id="pcbi.1009986.e005"><alternatives><graphic xlink:href="pcbi.1009986.e005.jpg" id="pcbi.1009986.e005g" position="anchor"/><mml:math id="M5" display="inline" overflow="scroll"><mml:mi mathvariant="bold-script">D</mml:mi></mml:math></alternatives></inline-formula> as following:
<disp-formula id="pcbi.1009986.e006"><alternatives><graphic xlink:href="pcbi.1009986.e006.jpg" id="pcbi.1009986.e006g" position="anchor"/><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-script">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>ω</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-script">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(1)</label></disp-formula>
where <italic toggle="yes">ω</italic> and <italic toggle="yes">ϵ</italic> are two hyperparameters for normalization and <inline-formula id="pcbi.1009986.e007"><alternatives><graphic xlink:href="pcbi.1009986.e007.jpg" id="pcbi.1009986.e007g" position="anchor"/><mml:math id="M7" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-script">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is the Euclidean distance between the <italic toggle="yes">i</italic><sup><italic toggle="yes">th</italic></sup>
<italic toggle="yes">C</italic><sub><italic toggle="yes">α</italic></sub> atom and the <italic toggle="yes">j</italic><sup><italic toggle="yes">th</italic></sup>
<italic toggle="yes">C</italic><sub><italic toggle="yes">α</italic></sub> atom. <italic toggle="yes">ϵ</italic> can also help avoid numerical error when <inline-formula id="pcbi.1009986.e008"><alternatives><graphic xlink:href="pcbi.1009986.e008.jpg" id="pcbi.1009986.e008g" position="anchor"/><mml:math id="M8" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold-script">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mi mathvariant="normal">Å</mml:mi><mml:mo>.</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi mathvariant="bold-script">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is normalized to (0, 2] by setting <italic toggle="yes">ω</italic> = 4 and <italic toggle="yes">ϵ</italic> = 2.</p>
      <p>As shown in <xref rid="pcbi.1009986.g001" ref-type="fig">Fig 1B</xref>, two types of raw node features are extracted, and they are invariant to rotation and translation. One is distance-based features, which is derived from the distance between the target residue and some specific points in the three-dimensional space. The coordinate of one of these points is calculated as following:
<disp-formula id="pcbi.1009986.e009"><alternatives><graphic xlink:href="pcbi.1009986.e009.jpg" id="pcbi.1009986.e009g" position="anchor"/><mml:math id="M9" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="bold">v</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>:</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder></mml:mstyle><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives><label>(2)</label></disp-formula>
where <inline-formula id="pcbi.1009986.e010"><alternatives><graphic xlink:href="pcbi.1009986.e010.jpg" id="pcbi.1009986.e010g" position="anchor"/><mml:math id="M10" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>:</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> and <bold>v</bold><sub><italic toggle="yes">i</italic></sub> denotes the Cartesian coordinate of <italic toggle="yes">i</italic><sup><italic toggle="yes">th</italic></sup> residue in the protein sequence. These points are named reference points in this study. The coordinates of all reference points and the raw node features of the target residue can be derived as Algorithm 1. The length of the distance-based raw node feature vector <bold>x</bold><sub><italic toggle="yes">v</italic></sub> is 2<sup><italic toggle="yes">M</italic></sup>−1, where <italic toggle="yes">M</italic> is a hyperparameter controlling the number of reference points. A proof that the distance-based feature is invariant to rotation and translation can be found in Text D of <xref rid="pcbi.1009986.s001" ref-type="supplementary-material">S1 File</xref></p>
      <fig position="float" id="pcbi.1009986.g001">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009986.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <p>(A) The complete graph <inline-formula id="pcbi.1009986.e011"><alternatives><graphic xlink:href="pcbi.1009986.e011" id="pcbi.1009986.e011g" position="anchor"/><mml:math id="M11" display="inline" overflow="scroll"><mml:mi mathvariant="script">G</mml:mi></mml:math></alternatives></inline-formula> is constructed based on protein tertiary structure, where the adjacency matrix is derived from the intra-residue distance matrix. (B) Raw node features consist of distance-based feature <bold>x</bold><sub><italic toggle="yes">v</italic></sub> and angle-based feature <italic toggle="yes">x</italic><sub><italic toggle="yes">a</italic></sub>.</p>
        </caption>
        <graphic xlink:href="pcbi.1009986.g001" position="float"/>
      </fig>
      <p specific-use="line"><bold>Algorithm 1</bold>. Distance-based raw node feature extraction from the protein structure graph.</p>
      <p specific-use="line"><bold>Input</bold> The set of nodes: <inline-formula id="pcbi.1009986.e012"><alternatives><graphic xlink:href="pcbi.1009986.e012.jpg" id="pcbi.1009986.e012g" position="anchor"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:math></alternatives></inline-formula></p>
      <p specific-use="line">        The number of reference points: 2<sup><italic toggle="yes">M</italic></sup>−1(<italic toggle="yes">M</italic>∈ℕ)</p>
      <p specific-use="line">        The coordinate of the target residue: <bold>v</bold><sub><italic toggle="yes">tgt</italic></sub>∈<italic toggle="yes">V</italic></p>
      <p specific-use="line"><bold>Output</bold> The distance-based raw node feature vector of a target residue: <bold>x</bold><sub><italic toggle="yes">v</italic></sub></p>
      <p specific-use="line"><bold>Step</bold> t = 0</p>
      <p specific-use="line">        # Reference points are divided into <italic toggle="yes">M</italic> groups. The <italic toggle="yes">m</italic><sup><italic toggle="yes">th</italic></sup> group consists of 2<sup><italic toggle="yes">m</italic></sup> points.</p>
      <p specific-use="line">        for <italic toggle="yes">m</italic> in {0,1,…,<italic toggle="yes">M</italic>−1}:</p>
      <p specific-use="line">            # Calculate the <italic toggle="yes">g</italic><sup><italic toggle="yes">th</italic></sup> reference point in the <italic toggle="yes">m</italic><sup><italic toggle="yes">th</italic></sup> group.</p>
      <p specific-use="line">            for <italic toggle="yes">g</italic> in {1,2,3,…,2<sup><italic toggle="yes">m</italic></sup>}:</p>
      <p specific-use="line">                # The subset <inline-formula id="pcbi.1009986.e013"><alternatives><graphic xlink:href="pcbi.1009986.e013.jpg" id="pcbi.1009986.e013g" position="anchor"/><mml:math id="M13" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mo>⌊</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>⌋</mml:mo><mml:mo>:</mml:mo><mml:mo>⌈</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>⌉</mml:mo></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> refers to a continuous fragment in a protein.</p>
      <p specific-use="line">            <inline-formula id="pcbi.1009986.e014"><alternatives><graphic xlink:href="pcbi.1009986.e014.jpg" id="pcbi.1009986.e014g" position="anchor"/><mml:math id="M14" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi mathvariant="bold">v</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mo>⌊</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>⌋</mml:mo><mml:mo>:</mml:mo><mml:mo>⌈</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>⌉</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></p>
      <p specific-use="line">                t++</p>
      <p specific-use="line">        <inline-formula id="pcbi.1009986.e015"><alternatives><graphic xlink:href="pcbi.1009986.e015.jpg" id="pcbi.1009986.e015g" position="anchor"/><mml:math id="M15" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>g</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0,1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula></p>
      <p>The other is angle-based features, which are derived from the angles formed by the <italic toggle="yes">C</italic><sub><italic toggle="yes">α</italic></sub> atoms of three consecutive residues in the structure and can be calculated as following:
<disp-formula id="pcbi.1009986.e016"><alternatives><graphic xlink:href="pcbi.1009986.e016.jpg" id="pcbi.1009986.e016g" position="anchor"/><mml:math id="M16" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>‖</mml:mo><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>(3)</label></disp-formula>
where <italic toggle="yes">x</italic><sub><italic toggle="yes">a</italic></sub> denotes the angle-based raw feature of the <italic toggle="yes">i</italic><sup><italic toggle="yes">th</italic></sup> residue in the protein sequence. When <italic toggle="yes">i</italic> = 1 or <italic toggle="yes">N</italic><sub><italic toggle="yes">r</italic></sub>, <italic toggle="yes">x</italic><sub><italic toggle="yes">a</italic></sub> = 0. The final raw node features with a length of <italic toggle="yes">d</italic> = 2<sup><italic toggle="yes">M</italic></sup> concatenate the distance-based and angle-based features.</p>
    </sec>
    <sec id="sec005">
      <title>GNN-based encoder</title>
      <p>The graph convolutional neural network (GCN) is motivated by the spectral graph theory and is proposed for learning on graph-structured data [<xref rid="pcbi.1009986.ref028" ref-type="bibr">28</xref>,<xref rid="pcbi.1009986.ref031" ref-type="bibr">31</xref>]. To date, many graph neural networks (GNNs) are proposed to extend the GCN, such as the message passing neural network (MPNN) and GraphSage [<xref rid="pcbi.1009986.ref032" ref-type="bibr">32</xref>,<xref rid="pcbi.1009986.ref033" ref-type="bibr">33</xref>]. Most of GNNs are designed to update the node embeddings by aggregating the information from their neighboring nodes.</p>
      <p>In this study, a graph convolutional layer is designed to learn the geometric features of each residue and its neighborhood in the three-dimensional space as following:
<disp-formula id="pcbi.1009986.e017"><alternatives><graphic xlink:href="pcbi.1009986.e017.jpg" id="pcbi.1009986.e017g" position="anchor"/><mml:math id="M17" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">σ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-script">A</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives><label>(4)</label></disp-formula>
where <inline-formula id="pcbi.1009986.e018"><alternatives><graphic xlink:href="pcbi.1009986.e018.jpg" id="pcbi.1009986.e018g" position="anchor"/><mml:math id="M18" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> is the node feature matrix of the <italic toggle="yes">l</italic><sup><italic toggle="yes">th</italic></sup> layer, <bold>W</bold><sup><italic toggle="yes">l</italic></sup>∈ℝ<sup><italic toggle="yes">d</italic>×<italic toggle="yes">d</italic></sup> is the learnable weight matrix of the <italic toggle="yes">l</italic><sup><italic toggle="yes">th</italic></sup> layer, <inline-formula id="pcbi.1009986.e019"><alternatives><graphic xlink:href="pcbi.1009986.e019.jpg" id="pcbi.1009986.e019g" position="anchor"/><mml:math id="M19" display="inline" overflow="scroll"><mml:mi mathvariant="bold-script">A</mml:mi></mml:math></alternatives></inline-formula> is the adjacency matrix, and σ(∙) is a nonlinear activation function.</p>
      <p><xref rid="pcbi.1009986.e017" ref-type="disp-formula">Eq 4</xref> can also be written as:
<disp-formula id="pcbi.1009986.e020"><alternatives><graphic xlink:href="pcbi.1009986.e020.jpg" id="pcbi.1009986.e020g" position="anchor"/><mml:math id="M20" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">σ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>∙</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives><label>(5)</label></disp-formula>
where <inline-formula id="pcbi.1009986.e021"><alternatives><graphic xlink:href="pcbi.1009986.e021.jpg" id="pcbi.1009986.e021g" position="anchor"/><mml:math id="M21" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is the node embeddings of the <italic toggle="yes">j</italic><sup><italic toggle="yes">th</italic></sup> node in the graph (i.e., the <italic toggle="yes">j</italic><sup><italic toggle="yes">th</italic></sup> row of <bold>X</bold><sup><italic toggle="yes">l</italic></sup>) and <italic toggle="yes">a</italic><sub><italic toggle="yes">jk</italic></sub> is the element of <inline-formula id="pcbi.1009986.e022"><alternatives><graphic xlink:href="pcbi.1009986.e022.jpg" id="pcbi.1009986.e022g" position="anchor"/><mml:math id="M22" display="inline" overflow="scroll"><mml:mi mathvariant="bold-script">A</mml:mi></mml:math></alternatives></inline-formula>.</p>
      <p>It is obvious that the central node feature is affected more by the nodes close to it instead of distant ones according to the <xref rid="pcbi.1009986.e020" ref-type="disp-formula">Eq 5</xref>. The adjacency matrix plays the role of a weight matrix. Here we do not normalize the adjacency matrix since self-loop and normalization are already applied to the adjacency matrix during graph construction.</p>
      <p>Multiple graph convolutional layers are stacked to learn high-level geometric features in our model. To overcome the gradient-vanishing and over-smoothing problem, residual blocks are built by adding identity shortcuts [<xref rid="pcbi.1009986.ref034" ref-type="bibr">34</xref>]. Each residual block contains two graph convolutional layers and can be defined as following:
<disp-formula id="pcbi.1009986.e023"><alternatives><graphic xlink:href="pcbi.1009986.e023.jpg" id="pcbi.1009986.e023g" position="anchor"/><mml:math id="M23" display="block" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="normal">σ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-script">A</mml:mi><mml:msup><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives><label>(6)</label></disp-formula>
where <bold>W</bold><sub><italic toggle="yes">s</italic></sub> is used to match the dimension when the sizes of <bold>X</bold><sup><italic toggle="yes">l</italic>+1</sup> and <bold>X</bold><sup><italic toggle="yes">l</italic></sup> are different.</p>
      <p>The primary structure of a protein consists of a sequence of amino acids (nodes). However, GCN cannot capture the order of nodes because aggregator is invariant to permutation. Thus, before applying graph convolution, a bidirectional long short-term memory (BiLSTM) network is used to extract low-level features from sequential context [<xref rid="pcbi.1009986.ref035" ref-type="bibr">35</xref>]. BiLSTM consists of two LSTMs. Each of them takes the same protein sequence as the input but from different directions. The hidden state at each time step of these two LSTMs is concatenated as the initial node embeddings for the following graph convolutional layers.</p>
      <p>As shown in <xref rid="pcbi.1009986.g002" ref-type="fig">Fig 2</xref>, the GNN-based encoder consists of three modules: the first module is used to extract sequential context, which consists of two multi-layer perceptrons (MLPs) and a BiLSTM network; the second module consists of multiple graph convolutional layers; in the last module, a global max pooling layer is used to summarize the final graph embeddings.</p>
      <fig position="float" id="pcbi.1009986.g002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009986.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Architecture of GNN-based encoder.</title>
          <p>The BiLSTM module extracts low-level node features from the primary structures of proteins. The graph convolution module extracts high-level node features based on the adjacency matrices <inline-formula id="pcbi.1009986.e024"><alternatives><graphic xlink:href="pcbi.1009986.e024" id="pcbi.1009986.e024g" position="anchor"/><mml:math id="M24" display="inline" overflow="scroll"><mml:mi mathvariant="bold-script">A</mml:mi></mml:math></alternatives></inline-formula>. The readout module transforms node features to the descriptors by a global max pooling layer. The residual blocks (ResBlock) used in the graph convolutional module consists of two graph convolutional (GC) layers.</p>
        </caption>
        <graphic xlink:href="pcbi.1009986.g002" position="float"/>
      </fig>
    </sec>
    <sec id="sec006">
      <title>The contrastive learning framework</title>
      <p>A contrastive learning framework usually consists of multiple neural networks sharing the same architecture and parameters. These neural networks serve as encoders and each of them transforms a sample to the corresponding descriptor. The loss function is dependent on the distance between these descriptors. If samples are similar, the distance should be minimized; otherwise, the distance should be maximized.</p>
      <p>In GraSR, Momentum Contrast (MoCo) is used as a contrastive learning framework, which was originally proposed for unsupervised visual representation learning [<xref rid="pcbi.1009986.ref036" ref-type="bibr">36</xref>]. We apply it to protein structure representation by substituting its CNN encoders with our GNN encoders. As shown in <xref rid="pcbi.1009986.g003" ref-type="fig">Fig 3</xref>, MoCo consists of two GNN-based encoders <inline-formula id="pcbi.1009986.e025"><alternatives><graphic xlink:href="pcbi.1009986.e025.jpg" id="pcbi.1009986.e025g" position="anchor"/><mml:math id="M25" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1009986.e026"><alternatives><graphic xlink:href="pcbi.1009986.e026.jpg" id="pcbi.1009986.e026g" position="anchor"/><mml:math id="M26" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, which share the same architecture. However, these two encoders have different parameter sets of <italic toggle="yes">θ</italic><sub><italic toggle="yes">q</italic></sub> and <italic toggle="yes">θ</italic><sub><italic toggle="yes">k</italic></sub>. The parameter set <italic toggle="yes">θ</italic><sub><italic toggle="yes">q</italic></sub> is updated by back-propagation. The parameter set <italic toggle="yes">θ</italic><sub><italic toggle="yes">k</italic></sub> is updated by <italic toggle="yes">θ</italic><sub><italic toggle="yes">q</italic></sub> as following:
<disp-formula id="pcbi.1009986.e027"><alternatives><graphic xlink:href="pcbi.1009986.e027.jpg" id="pcbi.1009986.e027g" position="anchor"/><mml:math id="M27" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:mi>m</mml:mi><mml:mo>∙</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>∙</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives><label>(7)</label></disp-formula>
where <italic toggle="yes">m</italic>∈(0, 1] is a momentum coefficient.</p>
      <fig position="float" id="pcbi.1009986.g003">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009986.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>The contrastive learning framework for protein structure representation learning.</title>
          <p>At each iteration, raw features <bold>X</bold><sub><italic toggle="yes">q</italic></sub> and <bold>X</bold><sub><italic toggle="yes">k</italic></sub> are extracted from the query protein structure and the key protein structure, respectively. Then, descriptors <bold>y</bold><sub><italic toggle="yes">q</italic></sub> and <bold>y</bold><sub><italic toggle="yes">k</italic></sub> are encoded by GNN encoder <inline-formula id="pcbi.1009986.e028"><alternatives><graphic xlink:href="pcbi.1009986.e028" id="pcbi.1009986.e028g" position="anchor"/><mml:math id="M28" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1009986.e029"><alternatives><graphic xlink:href="pcbi.1009986.e029" id="pcbi.1009986.e029g" position="anchor"/><mml:math id="M29" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, respectively. The value of loss function guides the optimization of the parameters <italic toggle="yes">θ</italic><sub><italic toggle="yes">q</italic></sub> of <inline-formula id="pcbi.1009986.e030"><alternatives><graphic xlink:href="pcbi.1009986.e030" id="pcbi.1009986.e030g" position="anchor"/><mml:math id="M30" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> while the parameters <italic toggle="yes">θ</italic><sub><italic toggle="yes">k</italic></sub> are updated based on <italic toggle="yes">θ</italic><sub><italic toggle="yes">q</italic></sub>. At the end of the current iteration, <bold>y</bold><sub><italic toggle="yes">k</italic></sub> will enqueue as a negative sample for the next iteration.</p>
        </caption>
        <graphic xlink:href="pcbi.1009986.g003" position="float"/>
      </fig>
      <p>The input of two encoders are raw node features <inline-formula id="pcbi.1009986.e031"><alternatives><graphic xlink:href="pcbi.1009986.e031.jpg" id="pcbi.1009986.e031g" position="anchor"/><mml:math id="M31" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1009986.e032"><alternatives><graphic xlink:href="pcbi.1009986.e032.jpg" id="pcbi.1009986.e032g" position="anchor"/><mml:math id="M32" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> extracted from the query protein structure and the key protein (i.e., the protein in the database) structure, respectively. <italic toggle="yes">l</italic><sub><italic toggle="yes">q</italic></sub> is the number of residues in the query protein, <italic toggle="yes">l</italic><sub><italic toggle="yes">k</italic></sub> is the number of residues in the key protein, and <italic toggle="yes">d</italic> is the dimension of raw features. When constructing the training data, we guarantee that the key protein structure is the structural neighbor (i.e., similar structure) of the query protein in the current mini-batch and thus it can be seen as a positive sample. Moreover, the chosen query protein must be dissimilar to previous <italic toggle="yes">n</italic> key proteins. The outputs of MoCo are two descriptors <bold>y</bold><sub><italic toggle="yes">q</italic></sub>∈ℝ<sup><italic toggle="yes">L</italic></sup> and <bold>y</bold><sub><italic toggle="yes">k</italic></sub>∈ℝ<sup><italic toggle="yes">L</italic></sup>, where <italic toggle="yes">L</italic> is the length of the descriptors. At the end of each iteration, <bold>y</bold><sub><italic toggle="yes">k</italic></sub> is pushed into a randomly initialized queue of length <italic toggle="yes">n</italic> during training. All descriptors in the queue can be used as the negative samples (i.e., dissimilar structures) in the next iteration due to the specific data construction. If the queue is full, the earliest samples dequeue.</p>
      <p>The loss function called InfoNCE [<xref rid="pcbi.1009986.ref037" ref-type="bibr">37</xref>] is used to optimize the encoder <inline-formula id="pcbi.1009986.e033"><alternatives><graphic xlink:href="pcbi.1009986.e033.jpg" id="pcbi.1009986.e033g" position="anchor"/><mml:math id="M33" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> as following:
<disp-formula id="pcbi.1009986.e034"><alternatives><graphic xlink:href="pcbi.1009986.e034.jpg" id="pcbi.1009986.e034g" position="anchor"/><mml:math id="M34" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">L</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>∙</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>∙</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives><label>(8)</label></disp-formula>
where τ is a temperature hyperparameter, <italic toggle="yes">n</italic> is the length of the queue, and <bold>y</bold><sub><italic toggle="yes">i</italic></sub> is the descriptor of <italic toggle="yes">i</italic><sup><italic toggle="yes">th</italic></sup> negative sample in the queue. Dot-product is used to measure the cosine similarity between <bold>y</bold><sub><italic toggle="yes">q</italic></sub> and other descriptors because <bold>y</bold><sub><italic toggle="yes">q</italic></sub>, <bold>y</bold><sub><italic toggle="yes">k</italic></sub> and <bold>y</bold><sub><italic toggle="yes">i</italic></sub> are normalized to 1.</p>
    </sec>
    <sec id="sec007">
      <title>Length-scaling cosine distance</title>
      <p>In the training stage, cosine similarity is used to measure the similarity between two descriptors. Cosine similarity is symmetric, which means cos(<bold>y</bold><sub><italic toggle="yes">a</italic></sub>, <bold>y</bold><sub><italic toggle="yes">b</italic></sub>) = cos(<bold>y</bold><sub><italic toggle="yes">b</italic></sub>, <bold>y</bold><sub><italic toggle="yes">a</italic></sub>). However, TM-score is dependent on the length of protein sequences and thus asymmetric according to its definition [<xref rid="pcbi.1009986.ref027" ref-type="bibr">27</xref>]. Length-scaling cosine distance is proposed to bridge the gap between cosine similarity and TM-score. Cosine distance is defined as <inline-formula id="pcbi.1009986.e035"><alternatives><graphic xlink:href="pcbi.1009986.e035.jpg" id="pcbi.1009986.e035g" position="anchor"/><mml:math id="M35" display="inline" overflow="scroll"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>‖</mml:mo><mml:mo>‖</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>‖</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. It can be rewritten as <inline-formula id="pcbi.1009986.e036"><alternatives><graphic xlink:href="pcbi.1009986.e036.jpg" id="pcbi.1009986.e036g" position="anchor"/><mml:math id="M36" display="inline" overflow="scroll"><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> if ‖<bold>y</bold><sub><italic toggle="yes">a</italic></sub>‖ = ‖<bold>y</bold><sub><italic toggle="yes">b</italic></sub>‖ = 1. Thus, we define the length-scaling cosine distance as following:
<disp-formula id="pcbi.1009986.e037"><alternatives><graphic xlink:href="pcbi.1009986.e037.jpg" id="pcbi.1009986.e037g" position="anchor"/><mml:math id="M37" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">max</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mn>0,2</mml:mn></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></alternatives><label>(9)</label></disp-formula>
where <italic toggle="yes">l</italic><sub><italic toggle="yes">a</italic></sub>, <italic toggle="yes">l</italic><sub><italic toggle="yes">b</italic></sub>, and <italic toggle="yes">l</italic><sub><italic toggle="yes">max</italic></sub> denote the length of query sequence A, key sequence B and the longest sequence in the database. When <italic toggle="yes">l</italic><sub><italic toggle="yes">b</italic></sub>&lt;<italic toggle="yes">l</italic><sub><italic toggle="yes">a</italic></sub>, it is equivalent to standard cosine distance; otherwise, the distance between <bold>y</bold><sub><italic toggle="yes">a</italic></sub> and <bold>y</bold><sub><italic toggle="yes">b</italic></sub> will be decreased. d(<bold>y</bold><sub><italic toggle="yes">a</italic></sub>, <bold>y</bold><sub><italic toggle="yes">b</italic></sub>)&gt;d(<bold>y</bold><sub><italic toggle="yes">b</italic></sub>, <bold>y</bold><sub><italic toggle="yes">a</italic></sub>) if <italic toggle="yes">l</italic><sub><italic toggle="yes">a</italic></sub>&lt;<italic toggle="yes">l</italic><sub><italic toggle="yes">b</italic></sub>, which is more consistent with TM-score.</p>
      <p>Length-scaling cosine distance is only used in the testing stage for ranking. In the training stage, cosine similarity is still applied to model optimization.</p>
    </sec>
    <sec id="sec008">
      <title>Dynamic training data partition</title>
      <p>In the previous learning-based method DeepFold, it uses the following data partition strategy: for each sample pair (<bold>X</bold><sub><italic toggle="yes">a</italic></sub>, <bold>X</bold><sub><italic toggle="yes">b</italic></sub>), if its TM-score is higher than <italic toggle="yes">ρ</italic>∙TM<sub><italic toggle="yes">max</italic></sub>(X<sub><italic toggle="yes">a</italic></sub>), <bold>X</bold><sub><italic toggle="yes">b</italic></sub> is seen as a positive sample to <bold>X</bold><sub><italic toggle="yes">a</italic></sub>, where TM<sub><italic toggle="yes">max</italic></sub>(X<sub><italic toggle="yes">a</italic></sub>) is the maximal TM-score between <bold>X</bold><sub><italic toggle="yes">a</italic></sub> and other protein structures in the target database [<xref rid="pcbi.1009986.ref024" ref-type="bibr">24</xref>]. <italic toggle="yes">ρ</italic>∈(0,1) is a hyperparameter and is set to 0.9. The above strategy for training data partition used in DeepFold is the same as that used for test data partition. It means that the model only needs to learn TM(<bold>X</bold><sub><italic toggle="yes">q</italic></sub>, <bold>X</bold><sub>P</sub>)&gt;TM(<bold>X</bold><sub><italic toggle="yes">q</italic></sub>, <bold>X</bold><sub>N</sub>), where <bold>X</bold><sub>P</sub> is any positive sample to <bold>X</bold><sub><italic toggle="yes">q</italic></sub> and <bold>X</bold><sub>N</sub> is any negative sample to <bold>X</bold><sub><italic toggle="yes">q</italic></sub>. The relationship between any positive pairs and the relationship between any negative pairs remain unknown to the model.</p>
      <p>To resolve the above issue, we design a dynamic training data partition strategy. At first, for each query structure, all structures in the database are sorted according to their TM-score. Then, the Top <italic toggle="yes">K</italic> percent (e.g., 30%) structures are used to construct a subset, which is denoted as <inline-formula id="pcbi.1009986.e038"><alternatives><graphic xlink:href="pcbi.1009986.e038.jpg" id="pcbi.1009986.e038g" position="anchor"/><mml:math id="M38" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">S</mml:mi></mml:math></alternatives></inline-formula>. At each iteration, a structure is randomly sampled from<inline-formula id="pcbi.1009986.e039"><alternatives><graphic xlink:href="pcbi.1009986.e039.jpg" id="pcbi.1009986.e039g" position="anchor"/><mml:math id="M39" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">S</mml:mi></mml:math></alternatives></inline-formula> as a positive sample <bold>X</bold><sub>S</sub>. Any structures in the database (no matter whether it is in <inline-formula id="pcbi.1009986.e040"><alternatives><graphic xlink:href="pcbi.1009986.e040.jpg" id="pcbi.1009986.e040g" position="anchor"/><mml:math id="M40" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">S</mml:mi></mml:math></alternatives></inline-formula>) with TM-score less than TM(<bold>X</bold><sub><italic toggle="yes">q</italic></sub>, <bold>X</bold><sub>S</sub>) are seen as negative samples. If the neural network is trained for infinite iterations, each structure in <inline-formula id="pcbi.1009986.e041"><alternatives><graphic xlink:href="pcbi.1009986.e041.jpg" id="pcbi.1009986.e041g" position="anchor"/><mml:math id="M41" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">S</mml:mi></mml:math></alternatives></inline-formula> will be sampled at least once. Therefore, the relationship among all samples in the <inline-formula id="pcbi.1009986.e042"><alternatives><graphic xlink:href="pcbi.1009986.e042.jpg" id="pcbi.1009986.e042g" position="anchor"/><mml:math id="M42" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">S</mml:mi></mml:math></alternatives></inline-formula> can be learned by the neural network using the dynamic training data partition strategy.</p>
    </sec>
  </sec>
  <sec id="sec009">
    <title>Experimental settings</title>
    <sec id="sec010">
      <title>Evaluation protocols</title>
      <p>The 5-fold cross-validation is conducted to train and validate GraSR on SCOPe v2.07. Other methods for comparison are tested by running their standalone software. To comprehensively evaluate the performance, each method is evaluated for a ranking task and a classification task.</p>
      <p>In the ranking task, all methods are also evaluated on the independent test set ind_PDB. For each query, each method ranks all structures in the database in descending/ascending order according to the similarities/distance. The ranking result is compared against the result of TM-align.</p>
      <p>To make a fair comparison, similar settings with the latest method, DeepFold, are used [<xref rid="pcbi.1009986.ref024" ref-type="bibr">24</xref>]. For each query structure in test set, the structures with TM-score no less than 0.9*TM-score_max (the highest TM-score in the training set) are considered as structural neighbors, namely positive samples.</p>
      <p>Similar to DeepFold and Fragbag, we calculate the area under Receiver operating characteristics (AUROC) curves and the area under precision-recall curves (AUPRC) as performance metrics. However, AUROC would overestimate the performance when data is severely imbalanced [<xref rid="pcbi.1009986.ref038" ref-type="bibr">38</xref>]. Considering that protein structures generally have very few structural neighbors, ROC may not be a reliable metric here. Thus, we are more focused on AUPRC when comparing different methods.</p>
      <p>In addition, Top-K accuracy could also not be comprehensive. For example, two algorithms find one and two structural neighbors in Top-10, respectively. The latter performs better. However, both are considered as hits according to the definition of Top-K accuracy. To avoid the problem, we propose a new metric named Top-K hit ratio based on Top-K accuracy as following:
<disp-formula id="pcbi.1009986.e043"><alternatives><graphic xlink:href="pcbi.1009986.e043.jpg" id="pcbi.1009986.e043g" position="anchor"/><mml:math id="M43" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>K</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>b</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives><label>(10)</label></disp-formula>
where <inline-formula id="pcbi.1009986.e044"><alternatives><graphic xlink:href="pcbi.1009986.e044.jpg" id="pcbi.1009986.e044g" position="anchor"/><mml:math id="M44" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> denotes the number of structural neighbors found by the algorithm for the <italic toggle="yes">i</italic><sup><italic toggle="yes">th</italic></sup> query, <inline-formula id="pcbi.1009986.e045"><alternatives><graphic xlink:href="pcbi.1009986.e045.jpg" id="pcbi.1009986.e045g" position="anchor"/><mml:math id="M45" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>b</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> denotes the total number of structural neighbors for the <italic toggle="yes">i</italic><sup><italic toggle="yes">th</italic></sup> query, and <italic toggle="yes">N</italic><sub><italic toggle="yes">q</italic></sub> denotes the number of queries. This metric can be seen as an extension to Top-K accuracy. When <italic toggle="yes">K</italic> = 1, Top-K hit ratio is equivalent to Top-K accuracy.</p>
      <p>In summary, AUROC, AUPRC, Top-1 hit ratio, Top-5 hit ratio, and Top-10 hit ratio are selected to evaluate all methods in the ranking task. AUROC/AUPRC is calculated for each query, and the average of AUROC/AUPRC is used to evaluate the overall performance on the whole dataset.</p>
      <p>Each domain in SCOPe v2.07 belongs to a specific class. In the classification task, all methods are used to generate descriptors from domains. Then, logistic regression (LR) classifiers are trained and used to predict the class of descriptors using 10-fold cross-validation. Considering it is a multi-class classification problem, average F1-score and accuracy are used as the evaluation metrics instead of ROC or PRC.</p>
      <p>In addition, statistical hypothesis tests are further conducted to verify whether the performance difference between GraSR and compared methods is significant by following the protocol used in [<xref rid="pcbi.1009986.ref039" ref-type="bibr">39</xref>]. Half of the proteins in the validation or test set will be sampled randomly. The predictive performance of all methods will be evaluated on this subset. The procedure will be repeated 10 times and then GraSR will be compared with other methods on the 10 pairs of results. Paired t-test or Wilcoxon signed-rank test will be applied, which depends on whether the measurement follows a Gaussian distribution.</p>
    </sec>
    <sec id="sec011">
      <title>Parameter setting details</title>
      <p>The hyperparameter <italic toggle="yes">M</italic> is set to 5, which means the number of reference points is 31. Following the practice in the original paper [<xref rid="pcbi.1009986.ref036" ref-type="bibr">36</xref>], in the MoCo framework, the momentum <italic toggle="yes">m</italic> is set to 0.999 and the temperature τ is set to 0.07. The length of the queue of negative samples is set to 1024. When applying the dynamic training strategy, Top-30% structures are used to construct the subset <inline-formula id="pcbi.1009986.e046"><alternatives><graphic xlink:href="pcbi.1009986.e046.jpg" id="pcbi.1009986.e046g" position="anchor"/><mml:math id="M46" display="inline" overflow="scroll"><mml:mi mathvariant="double-struck">S</mml:mi></mml:math></alternatives></inline-formula>. The length of the raw node feature vector <italic toggle="yes">d</italic> is set to 32. Stochastic gradient descent (SGD) is used to optimize the neural networks and the momentum of SGD is set to 0.9. The size of mini-batch is set to 64. Initial learning rate is set to 0.1 and divided by 10 when AUPRC plateaus. Each model during cross-validation is trained for up to 2.4×10<sup>5</sup> iterations. Shuffled batch normalization (BN) is used after each layer [<xref rid="pcbi.1009986.ref040" ref-type="bibr">40</xref>]. Rectified linear unit (ReLU) and dropout is used in the Res Block after the first GC layer [<xref rid="pcbi.1009986.ref041" ref-type="bibr">41</xref>,<xref rid="pcbi.1009986.ref042" ref-type="bibr">42</xref>]. Leaky ReLU is used in the other layers [<xref rid="pcbi.1009986.ref043" ref-type="bibr">43</xref>]. The whole GraSR model is trained on two TITAN Xp Graphics Cards, and the training procedure took several days.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="sec012">
    <title>Results</title>
    <p>In this section, we first perform ablation studies to evaluate the effectiveness of two proposed training strategies and GNN-based encoder in GraSR. Then, we compare GraSR with baseline methods for ranking and multi-classification task on two benchmarked datasets. Finally, we also evaluate the computational efficiency of GraSR and baseline methods.</p>
    <sec id="sec013">
      <title>Ablation studies</title>
      <p>In this section, we evaluate the effectiveness of the length-scaling cosine distance, the dynamic training data partition strategy, the raw node features, the BiLSTM layer and the GNN-based encoder, which are designed for GraSR. All experiments are performed on the SCOPe v2.07 and ind_PDB. Six variants of GraSR are used to compare:</p>
      <list list-type="alpha-lower">
        <list-item>
          <p>w/o LS: length-scaling cosine distance used in GraSR is substituted with standard cosine distance.</p>
        </list-item>
        <list-item>
          <p>w/o DP: dynamic training data partition strategy is not used.</p>
        </list-item>
        <list-item>
          <p>w/o RNN: remove the BiLSTM layer from the encoder.</p>
        </list-item>
        <list-item>
          <p>GraSR-dist: Only the distance-based raw node feature is used.</p>
        </list-item>
        <list-item>
          <p>GraSR-angle: only the angle-based raw node feature is used.</p>
        </list-item>
        <list-item>
          <p>GraSR-CNN: the GNN-based encoder used in GraSR is substituted with a CNN-based encoder. The architecture of the CNN is similar to the one used in DeepFold [<xref rid="pcbi.1009986.ref024" ref-type="bibr">24</xref>] (cf. Text B in <xref rid="pcbi.1009986.s001" ref-type="supplementary-material">S1 File</xref>).</p>
        </list-item>
      </list>
      <p>The results in <xref rid="pcbi.1009986.t001" ref-type="table">Table 1</xref> show that the performance degrades in general if any component of GraSR is removed or substituted of these variants in our local tests. Avg. AUPRC, Top-1 hit ratio, Top-5 hit ratio and Top-10 hit ratio of GraSR increase 10.01%/6.86%, 10.34%/7.63%, 9.86%/7.11% and 8.74%/5.85% respectively when compared with GraSR-CNN. These results demonstrate that our proposed GNN-based encoder is more suitable for protein structure representation than the common CNN. The BiLSTM layer is also indispensable because the variant achieves the worst performance when it is removed. In addition, the dynamic training data partition strategy obtains ~1–2% increase on the four metrics, respectively. It proves that even if no change is made to the main algorithm architecture, refining the data labelling is able to improve its performance. The improvement brought by length-scaling cosine distance is also significant except the Top-10 hit ratio on the ind_PDB. The result of GraSR-dist and GraSR-angle shows that distance-based node features are more important while angle-based node features can help improve the Avg. AUROC. The overall results show that all introduced components contribute to the superior performance of GraSR.</p>
      <table-wrap position="float" id="pcbi.1009986.t001">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009986.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>Ablation studies of length-scaling cosine distance, the dynamic training data partition strategy and the GNN-based encoder on SCOPe v2.07 and ind_PDB.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1009986.t001" id="pcbi.1009986.t001g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Dataset</th>
                <th align="left" rowspan="1" colspan="1">Method</th>
                <th align="left" rowspan="1" colspan="1">Avg. AUROC<xref rid="t001fn004" ref-type="table-fn"><sup>†</sup></xref></th>
                <th align="left" rowspan="1" colspan="1">Avg. AUPRC<xref rid="t001fn004" ref-type="table-fn"><sup>†</sup></xref></th>
                <th align="left" rowspan="1" colspan="1">Top-1<xref rid="t001fn004" ref-type="table-fn"><sup>†</sup></xref></th>
                <th align="left" rowspan="1" colspan="1">Top-5<xref rid="t001fn004" ref-type="table-fn"><sup>†</sup></xref></th>
                <th align="left" rowspan="1" colspan="1">Top-10<xref rid="t001fn004" ref-type="table-fn"><sup>†</sup></xref></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="7" colspan="1">SCOPe v2.07</td>
                <td align="left" rowspan="1" colspan="1">w/o LS</td>
                <td align="left" rowspan="1" colspan="1">0.9752<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.6521<xref rid="t001fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.7188<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.7063<xref rid="t001fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.7370<xref rid="t001fn001" ref-type="table-fn">*</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">w/o DP</td>
                <td align="left" rowspan="1" colspan="1">0.9743<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.6426<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.7038<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.7007<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.7275<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">w/o RNN</td>
                <td align="left" rowspan="1" colspan="1">0.9603<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.5005<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.5630<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.5541<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.5954<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraSR-dist</td>
                <td align="left" rowspan="1" colspan="1">0.9816<xref rid="t001fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.6587</td>
                <td align="left" rowspan="1" colspan="1">0.7260</td>
                <td align="left" rowspan="1" colspan="1">0.7104</td>
                <td align="left" rowspan="1" colspan="1">0.7406</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraSR-angle</td>
                <td align="left" rowspan="1" colspan="1">0.9803<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.6073<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.6674<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.6650<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.7042<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraSR-CNN</td>
                <td align="left" rowspan="1" colspan="1">0.9781<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.5594<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.6248<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.6115<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.6526<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraSR</td>
                <td align="left" rowspan="1" colspan="1">0.9823</td>
                <td align="left" rowspan="1" colspan="1">0.6595</td>
                <td align="left" rowspan="1" colspan="1">0.7282</td>
                <td align="left" rowspan="1" colspan="1">0.7101</td>
                <td align="left" rowspan="1" colspan="1">0.7400</td>
              </tr>
              <tr>
                <td align="left" rowspan="7" colspan="1">ind_PDB</td>
                <td align="left" rowspan="1" colspan="1">w/o LS</td>
                <td align="left" rowspan="1" colspan="1">0.9436<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.3919<xref rid="t001fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.4383<xref rid="t001fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.4388<xref rid="t001fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.4698</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">w/o DP</td>
                <td align="left" rowspan="1" colspan="1">0.9382<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.3881<xref rid="t001fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.4333<xref rid="t001fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.4370<xref rid="t001fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.4665</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">w/o RNN</td>
                <td align="left" rowspan="1" colspan="1">0.8999<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.2640<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.3052<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.3019<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
                <td align="left" rowspan="1" colspan="1">0.3224<xref rid="t001fn003" ref-type="table-fn">***</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraSR-dist</td>
                <td align="left" rowspan="1" colspan="1">0.9539</td>
                <td align="left" rowspan="1" colspan="1">0.4016</td>
                <td align="left" rowspan="1" colspan="1">0.4483</td>
                <td align="left" rowspan="1" colspan="1">0.4462</td>
                <td align="left" rowspan="1" colspan="1">0.4818</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraSR-angle</td>
                <td align="left" rowspan="1" colspan="1">0.9615<xref rid="t001fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.3670<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.4085<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.4098<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.4391<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraSR-CNN</td>
                <td align="left" rowspan="1" colspan="1">0.9623<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.3372<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.3795<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.3777<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.4179<xref rid="t001fn002" ref-type="table-fn">**</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraSR</td>
                <td align="left" rowspan="1" colspan="1">0.9528</td>
                <td align="left" rowspan="1" colspan="1">0.4058</td>
                <td align="left" rowspan="1" colspan="1">0.4558</td>
                <td align="left" rowspan="1" colspan="1">0.4488</td>
                <td align="left" rowspan="1" colspan="1">0.4764</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t001fn001">
            <p>*<italic toggle="yes">p</italic>-value of t-test is &lt; 0.05</p>
          </fn>
          <fn id="t001fn002">
            <p>**<italic toggle="yes">p</italic>-value of t-test is &lt; 10<sup>−4</sup></p>
          </fn>
          <fn id="t001fn003">
            <p>***<italic toggle="yes">p</italic>-value of t-test is &lt; 10<sup>−9</sup>.</p>
          </fn>
          <fn id="t001fn004">
            <p><sup>†</sup>Avg. AUROC, Avg. AUPRC and Top-K hit ratio are in [0, 1], the bigger the better.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="sec014">
      <title>Comparing GraSR with the state-of-the-art alignment-free methods</title>
      <p>GraSR is compared with three state-of-the-art structure representation methods: SGM, SSEF and DeepFold [<xref rid="pcbi.1009986.ref014" ref-type="bibr">14</xref>,<xref rid="pcbi.1009986.ref015" ref-type="bibr">15</xref>,<xref rid="pcbi.1009986.ref024" ref-type="bibr">24</xref>]. All methods are evaluated for the ranking task and classification task on two benchmark datasets. Moreover, the computational efficiency of structure representation methods is also benchmarked.</p>
    </sec>
    <sec id="sec015">
      <title>GraSR is superior to baseline methods on the ranking task</title>
      <p>The results summarized in the <xref rid="pcbi.1009986.t002" ref-type="table">Table 2</xref> show that GraSR significantly outperforms other baseline methods. Another deep-learning-based method DeepFold achieves the second best performance. Compared with DeepFold, GraSR achieves about 10%/7% improvement on SCOPe v2.07/ind_PDB. The results indicate that the architecture of our proposed GNN is superior to CNN of DeepFold on this task. In addition, it can be observed that two deep-learning-based methods perform better than other methods based on hand-crafted descriptors. This observation demonstrates that the descriptors automatically learned from large-scale data reserve more structural information. DeepFold, SGM and GraSR perform better on SCOPe v2.07 than on ind_PDB. The reason is that these methods are trained or designed based on SCOPe or CATH, each entry of which represents a single domain. However, on the ind_PDB, each structure may contain multiple domains. Even so, GraSR still yields an AUPRC of over 0.4, which is higher than that of other baseline methods.</p>
      <table-wrap position="float" id="pcbi.1009986.t002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009986.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Ranking performance of GraSR and other baseline methods.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1009986.t002" id="pcbi.1009986.t002g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Dataset</th>
                <th align="left" rowspan="1" colspan="1">Method</th>
                <th align="left" rowspan="1" colspan="1">Avg. AUROC<xref rid="t002fn003" ref-type="table-fn"><sup>†</sup></xref></th>
                <th align="left" rowspan="1" colspan="1">Avg. AUPRC<xref rid="t002fn003" ref-type="table-fn"><sup>†</sup></xref></th>
                <th align="left" rowspan="1" colspan="1">Top-1<xref rid="t002fn003" ref-type="table-fn"><sup>†</sup></xref></th>
                <th align="left" rowspan="1" colspan="1">Top-5<xref rid="t002fn003" ref-type="table-fn"><sup>†</sup></xref></th>
                <th align="left" rowspan="1" colspan="1">Top-10<xref rid="t002fn003" ref-type="table-fn"><sup>†</sup></xref></th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="4" colspan="1">SCOPe v2.07</td>
                <td align="left" rowspan="1" colspan="1">SGM</td>
                <td align="left" rowspan="1" colspan="1">0.9224<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.4537<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.556<xref rid="t002fn002" ref-type="table-fn">2**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.5312<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.5553<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">SSEF</td>
                <td align="left" rowspan="1" colspan="1">0.8423<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.0381<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.0838<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.0580<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.0610<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">DeepFold</td>
                <td align="left" rowspan="1" colspan="1">0.9574<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.4971<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.6035<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.5659<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.5927<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraSR</td>
                <td align="left" rowspan="1" colspan="1">0.9823</td>
                <td align="left" rowspan="1" colspan="1">0.6595</td>
                <td align="left" rowspan="1" colspan="1">0.7282</td>
                <td align="left" rowspan="1" colspan="1">0.7101</td>
                <td align="left" rowspan="1" colspan="1">0.7400</td>
              </tr>
              <tr>
                <td align="left" rowspan="4" colspan="1">ind_PDB</td>
                <td align="left" rowspan="1" colspan="1">SGM</td>
                <td align="left" rowspan="1" colspan="1">0.8167<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.2231<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.2745<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.2681<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.2850<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">SSEF</td>
                <td align="left" rowspan="1" colspan="1">0.8281<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.0433<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.0474<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.0400<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.0460<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">DeepFold</td>
                <td align="left" rowspan="1" colspan="1">0.9339<xref rid="t002fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.3144<xref rid="t002fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.3819<xref rid="t002fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.3662<xref rid="t002fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.3916<xref rid="t002fn001" ref-type="table-fn">*</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraSR</td>
                <td align="left" rowspan="1" colspan="1">0.9528</td>
                <td align="left" rowspan="1" colspan="1">0.4058</td>
                <td align="left" rowspan="1" colspan="1">0.4558</td>
                <td align="left" rowspan="1" colspan="1">0.4488</td>
                <td align="left" rowspan="1" colspan="1">0.4764</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t002fn001">
            <p>*<italic toggle="yes">p</italic>-value of t-test is &lt; 10<sup>−4</sup></p>
          </fn>
          <fn id="t002fn002">
            <p>**<italic toggle="yes">p</italic>-value of t-test is &lt; 10<sup>−9</sup>.</p>
          </fn>
          <fn id="t002fn003">
            <p><sup>†</sup>Avg. AUROC, Avg. AUPRC and Top-K hit ratio are in [0, 1], the bigger the better.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Considering that DeepFold is also trained using the labels derived from TM-score, we further compare GraSR with it. We sample 5,000 structure pairs randomly from SCOPe v2.07 and ind_PDB, respectively. The correlation between the distance derived from the representations learned by GraSR/DeepFold and TM-score of these structure pairs are shown in <xref rid="pcbi.1009986.g004" ref-type="fig">Fig 4</xref>. The Pearson correlation coefficient (PCC) of both methods are smaller than zero, and the negative correlation between the distance and TM-score is expected. The |PCC| (absolute value of PCC) of GraSR is 10.1%/12.1% higher than that of DeepFold on SCOPe v2.07/ind_PDB. The results demonstrate that the similarity between two descriptors derived from GraSR is more correlated to the TM-score, which is derived from an alignment-based method TM-align. The PCC of both methods are not very high because they focus on the structure pairs with relatively high TM-score. If we remove the structure pairs with TM-score smaller than 0.5, the |PCC| of GraSR will increase to 0.600/0.556 on SCOPe v2.07/ind_PDB. The high correlation to TM-score elucidates the effectiveness of GraSR.</p>
      <fig position="float" id="pcbi.1009986.g004">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009986.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>Correlation between distance derived from the representations learned by GraSR/DeepFold and TM-score on (A) SCOPe v2.07 and (B) ind_PDB.</title>
          <p>The Pearson correlation coefficient (PCC) is calculated for quantitative assessment.</p>
        </caption>
        <graphic xlink:href="pcbi.1009986.g004" position="float"/>
      </fig>
    </sec>
    <sec id="sec016">
      <title>GraSR outperforms baseline methods on the classification task</title>
      <p>GraSR and other structure representation methods are further evaluated by predicting the classes of proteins in SCOPe v2.07. There are totally 7 classes in the 40% identity filtered subset of SCOPe v2.07 [<xref rid="pcbi.1009986.ref020" ref-type="bibr">20</xref>]. We first use GraSR and other baseline methods to learn the structure representations, which are then fed into a multi-class LR for fold recognition.</p>
      <p>The results are summarized in the <xref rid="pcbi.1009986.t003" ref-type="table">Table 3</xref>. It can be observed that the results of the classification task are consistent with those of the ranking task. GraSR achieves the highest average F1-score and accuracy, followed by CNN-based DeepFold. Compared with DeepFold, GraSR further increases the average F1-score/accuracy by 5.1%/3.7%. The improvement is significant according to the <italic toggle="yes">p</italic>-value of t-test. Considering that LR is a linear classifier, the improvement is mainly owing to the learned discriminative descriptors. In addition, GraSR yields higher F1-scores on all seven classes than those of DeepFold (cf. <xref rid="pcbi.1009986.g005" ref-type="fig">Fig 5</xref>).</p>
      <fig position="float" id="pcbi.1009986.g005">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009986.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <title>The F1-score of each class in SCOPe of GraSR and other baseline methods.</title>
          <p>a: All alpha proteins; b: All beta proteins; c: Alpha and beta proteins (a/b); d: Alpha and beta proteins (a+b); e: Multi-domain proteins (alpha and beta); f: Membrane and cell surface proteins and peptides; g: Small proteins.</p>
        </caption>
        <graphic xlink:href="pcbi.1009986.g005" position="float"/>
      </fig>
      <table-wrap position="float" id="pcbi.1009986.t003">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009986.t003</object-id>
        <label>Table 3</label>
        <caption>
          <title>Multi-class classification performance of GraSR and other methods.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1009986.t003" id="pcbi.1009986.t003g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Method</th>
                <th align="left" rowspan="1" colspan="1">Avg. F1-score</th>
                <th align="left" rowspan="1" colspan="1">Accuracy</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">SGM</td>
                <td align="left" rowspan="1" colspan="1">0.6289<xref rid="t003fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.8354<xref rid="t003fn002" ref-type="table-fn">**</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">SSEF</td>
                <td align="left" rowspan="1" colspan="1">0.4920<xref rid="t003fn002" ref-type="table-fn">**</xref></td>
                <td align="left" rowspan="1" colspan="1">0.7470<xref rid="t003fn002" ref-type="table-fn">**</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">DeepFold</td>
                <td align="left" rowspan="1" colspan="1">0.7615<xref rid="t003fn001" ref-type="table-fn">*</xref></td>
                <td align="left" rowspan="1" colspan="1">0.8887<xref rid="t003fn002" ref-type="table-fn">**</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraSR</td>
                <td align="left" rowspan="1" colspan="1">0.8124</td>
                <td align="left" rowspan="1" colspan="1">0.9258</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t003fn001">
            <p>*<italic toggle="yes">p</italic>-value of t-test is &lt; 10<sup>−4</sup></p>
          </fn>
          <fn id="t003fn002">
            <p>**<italic toggle="yes">p</italic>-value of t-test is &lt; 10<sup>−9</sup>.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>As shown in <xref rid="pcbi.1009986.g005" ref-type="fig">Fig 5</xref>, the performance of SGM, DeepFold and our method is comparable on the all alpha proteins, all beta proteins, alpha and beta proteins (a/b) and alpha and beta proteins (a+b). However, two deep learning-based methods, GraSR and DeepFold, perform better than two hand-crafted descriptors, SGM and SSEF, for multi-domain proteins, membrane and cell surface proteins and peptides, and small proteins. We notice that the three classes contain relatively fewer domains. A potential reason is that deep learning methods can capture more complicated and detailed structural patterns that have not been fully explored.</p>
    </sec>
    <sec id="sec017">
      <title>GraSR is computationally efficient</title>
      <p>To evaluate the computational efficiency, we test the abovementioned alignment-free methods and one of the latest method, Geometricus [<xref rid="pcbi.1009986.ref044" ref-type="bibr">44</xref>], as following:</p>
      <list list-type="order">
        <list-item>
          <p>Record the time <italic toggle="yes">t</italic><sub><italic toggle="yes">q</italic></sub> for generating the descriptors of all query structures.</p>
        </list-item>
        <list-item>
          <p>Record the time <italic toggle="yes">t</italic><sub><italic toggle="yes">k</italic></sub> for generating the descriptors of all key structures (i.e., the structures in the database).</p>
        </list-item>
        <list-item>
          <p>Record the sum of time <italic toggle="yes">t</italic><sub><italic toggle="yes">d</italic></sub> for calculating the distance between each query structure and key structure.</p>
        </list-item>
      </list>
      <p>All 1,914 protein structures in the dataset ind_PDB are treated as the query structures and key structures simultaneously. Therefore, the pairwise distance is calculated 1,914×1,914 = 3,663,396 times. The total time for structure retrieval can be calculated as <italic toggle="yes">T</italic><sub><italic toggle="yes">total</italic></sub> = <italic toggle="yes">t</italic><sub><italic toggle="yes">q</italic></sub>+<italic toggle="yes">t</italic><sub><italic toggle="yes">k</italic></sub>+<italic toggle="yes">t</italic><sub><italic toggle="yes">d</italic></sub>. It can be simplified to <italic toggle="yes">T</italic><sub><italic toggle="yes">total</italic></sub> = 2<italic toggle="yes">t</italic><sub><italic toggle="yes">q</italic></sub>+<italic toggle="yes">t</italic><sub><italic toggle="yes">d</italic></sub> since query structures and key structures are the same. In fact, the structures in databases are known, and the descriptors of them can be precomputed. Thus, the total time with precomputation is shown and denoted as <inline-formula id="pcbi.1009986.e047"><alternatives><graphic xlink:href="pcbi.1009986.e047.jpg" id="pcbi.1009986.e047g" position="anchor"/><mml:math id="M47" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>.</p>
      <p>Only one logical core of Intel Xeon CPU E5-2630 v4 is used to run the programs of these methods. The results are summarized in the <xref rid="pcbi.1009986.t004" ref-type="table">Table 4</xref>. Geometricus is the fastest among all alignment-free methods. Two deep learning methods are relatively slower due to a large number of parameters in the model. However, the time consumption is still acceptable and GraSR (<inline-formula id="pcbi.1009986.e048"><alternatives><graphic xlink:href="pcbi.1009986.e048.jpg" id="pcbi.1009986.e048g" position="anchor"/><mml:math id="M48" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1.75</mml:mn><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:math></alternatives></inline-formula>) is much faster than DeepFold (<inline-formula id="pcbi.1009986.e049"><alternatives><graphic xlink:href="pcbi.1009986.e049.jpg" id="pcbi.1009986.e049g" position="anchor"/><mml:math id="M49" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>4.69</mml:mn><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:math></alternatives></inline-formula>) due to less parameters in GNN-based encoders of GraSR. Moreover, GraSR yields much better performance on ranking and classification task than SGM. Considering that deep learning methods can be accelerated easily by GPU, the gap between them can be reduced. In addition, the time consumption of alignment-based TM-align is also shown for comparison. There is a large gap between TM-align and alignment-free methods since finding the optimal superposition is time-consuming. The results demonstrate that alignment-free methods are still the fastest ways for protein structure retrieval from a large structure database. Our results suggest that GraSR is a promising choice when making the tradeoff between the accuracy and running time.</p>
      <table-wrap position="float" id="pcbi.1009986.t004">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009986.t004</object-id>
        <label>Table 4</label>
        <caption>
          <title>Time cost of GraSR and other methods for protein structure retrieval from ind_PDB.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="pcbi.1009986.t004" id="pcbi.1009986.t004g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Method</th>
                <th align="left" rowspan="1" colspan="1"><italic toggle="yes">T</italic><sub><italic toggle="yes">total</italic></sub><xref rid="t004fn001" ref-type="table-fn"><sup>a</sup></xref> (sec)</th>
                <th align="left" rowspan="1" colspan="1"><italic toggle="yes">T</italic><sub><italic toggle="yes">avg</italic></sub><xref rid="t004fn002" ref-type="table-fn"><sup>b</sup></xref> (sec)</th>
                <th align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1009986.e050"><alternatives><graphic xlink:href="pcbi.1009986.e050" id="pcbi.1009986.e050g" position="anchor"/><mml:math id="M50" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula><xref rid="t004fn003" ref-type="table-fn"><sup>c</sup></xref> (sec)</th>
                <th align="left" rowspan="1" colspan="1"><inline-formula id="pcbi.1009986.e051"><alternatives><graphic xlink:href="pcbi.1009986.e051" id="pcbi.1009986.e051g" position="anchor"/><mml:math id="M51" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">T</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mi mathvariant="bold-italic">v</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula><xref rid="t004fn004" ref-type="table-fn"><sup>d</sup></xref> (sec)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">SGM</td>
                <td align="left" rowspan="1" colspan="1">950.87</td>
                <td align="left" rowspan="1" colspan="1">0.50</td>
                <td align="left" rowspan="1" colspan="1">512.84</td>
                <td align="left" rowspan="1" colspan="1">0.27</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">SSEF</td>
                <td align="left" rowspan="1" colspan="1">2222.77</td>
                <td align="left" rowspan="1" colspan="1">1.16</td>
                <td align="left" rowspan="1" colspan="1">1313.01</td>
                <td align="left" rowspan="1" colspan="1">0.69</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">DeepFold</td>
                <td align="left" rowspan="1" colspan="1">17753.80</td>
                <td align="left" rowspan="1" colspan="1">9.28</td>
                <td align="left" rowspan="1" colspan="1">8980.56</td>
                <td align="left" rowspan="1" colspan="1">4.69</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Geometricus<xref rid="t004fn005" ref-type="table-fn"><sup>e</sup></xref></td>
                <td align="left" rowspan="1" colspan="1">447.55</td>
                <td align="left" rowspan="1" colspan="1">0.23</td>
                <td align="left" colspan="2" rowspan="1"/>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GraSR</td>
                <td align="left" rowspan="1" colspan="1">6534.55</td>
                <td align="left" rowspan="1" colspan="1">3.41</td>
                <td align="left" rowspan="1" colspan="1">3355.81</td>
                <td align="left" rowspan="1" colspan="1">1.75</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">TM-align</td>
                <td align="left" rowspan="1" colspan="1">673833.95</td>
                <td align="left" rowspan="1" colspan="1">352.06</td>
                <td align="left" colspan="2" rowspan="1"/>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t004fn001">
            <p><sup>a</sup>Total time for protein structure retrieval from ind_PDB without precomputation.</p>
          </fn>
          <fn id="t004fn002">
            <p><sup>b</sup><italic toggle="yes">T</italic><sub><italic toggle="yes">avg</italic></sub> = <italic toggle="yes">T</italic><sub><italic toggle="yes">total</italic></sub>/1914.</p>
          </fn>
          <fn id="t004fn003">
            <p><sup>c</sup>Total time for protein structure retrieval from ind_PDB with precomputation.</p>
          </fn>
          <fn id="t004fn004">
            <p>
              <sup>d</sup>
              <inline-formula id="pcbi.1009986.e052">
                <alternatives>
                  <graphic xlink:href="pcbi.1009986.e052" id="pcbi.1009986.e052g" position="anchor"/>
                  <mml:math id="M52" display="inline" overflow="scroll">
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>T</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>a</mml:mi>
                        <mml:mi>v</mml:mi>
                        <mml:mi>g</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>′</mml:mo>
                      </mml:mrow>
                    </mml:msubsup>
                    <mml:mo>=</mml:mo>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>T</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>t</mml:mi>
                        <mml:mi>o</mml:mi>
                        <mml:mi>t</mml:mi>
                        <mml:mi>a</mml:mi>
                        <mml:mi>l</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>′</mml:mo>
                      </mml:mrow>
                    </mml:msubsup>
                    <mml:mo>/</mml:mo>
                    <mml:mn>1914</mml:mn>
                  </mml:math>
                </alternatives>
              </inline-formula>
            </p>
          </fn>
          <fn id="t004fn005">
            <p><sup>e</sup>The length of the descriptors generated by Geometricus is dependent on the query structures. Thus, the descriptors of the structures in the database cannot be precomputed.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec018">
    <title>Discussions</title>
    <sec id="sec019">
      <title>GraSR learns discriminative structure representations</title>
      <p>To demonstrate whether the learned descriptors are discriminative, the descriptors generated by SGM, SSEF, DeepFold, and GraSR are visualized using t-distributed stochastic neighbor embedding (t-SNE) in <xref rid="pcbi.1009986.g006" ref-type="fig">Fig 6</xref> [<xref rid="pcbi.1009986.ref045" ref-type="bibr">45</xref>]. The perplexity of t-SNE is set to 300. We have tried different perplexity (cf. Figs A-C in <xref rid="pcbi.1009986.s001" ref-type="supplementary-material">S1 File</xref>), but the results are quite similar. The seven classes can be further divided into four major classes (i.e., all alpha proteins, all beta proteins, alpha and beta proteins (a/b), and alpha and beta proteins (a+b)) and three minor classes (i.e., multi-domain proteins, membrane and cell surface proteins and peptides, and small proteins). All methods do not perform well on three minor classes. The potential reason is that the classification standard of SCOPe is not fully related to the structural similarity. Geometrically similar but differently classified proteins are not uncommon, and they are known as the cross fold similarities [<xref rid="pcbi.1009986.ref009" ref-type="bibr">9</xref>,<xref rid="pcbi.1009986.ref016" ref-type="bibr">16</xref>,<xref rid="pcbi.1009986.ref046" ref-type="bibr">46</xref>]. For example, a protein belonging to multi-domain proteins may contain a domain belonging to all alpha proteins and a domain belonging to all beta proteins. Descriptors of four major classes derived from GraSR, SGM and DeepFold are well separated as shown in the <xref rid="pcbi.1009986.g006" ref-type="fig">Fig 6</xref>, and the results can explain for their good performance. There is much overlap among different classes based on the descriptors of SSEF, which can explain for its unsatisfactory performance on both ranking and classification tasks.</p>
      <fig position="float" id="pcbi.1009986.g006">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009986.g006</object-id>
        <label>Fig 6</label>
        <caption>
          <title>Visualization of descriptors learned from GraSR and other methods by t-SNE.</title>
          <p>a: All alpha proteins; b: All beta proteins; c: Alpha and beta proteins (a/b); d: Alpha and beta proteins (a+b); e: Multi-domain proteins (alpha and beta); f: Membrane and cell surface proteins and peptides; g: Small proteins.</p>
        </caption>
        <graphic xlink:href="pcbi.1009986.g006" position="float"/>
      </fig>
      <p>An interesting observation is that descriptors of GraSR tend to form many small clusters instead of less but larger clusters like other methods. A potential reason is that structures of the same class can be further divided into different folds / superfamilies and structures of different folds / superfamilies may share low structural similarities.</p>
    </sec>
    <sec id="sec020">
      <title>GraSR learns hidden information related to alignment implicitly</title>
      <p>Due to our GNN-based encoders, the final descriptors of GraSR are derived by aggregating all node embeddings in the readout layer. Thus, we can extract these node embeddings as residue-level descriptors. The descriptor of each residue represents the local geometric features in its spatial neighborhood. We superimpose two protein structures based on their residue-level descriptors.</p>
      <p>Given two protein structures, the cosine similarity matrix <inline-formula id="pcbi.1009986.e053"><alternatives><graphic xlink:href="pcbi.1009986.e053.jpg" id="pcbi.1009986.e053g" position="anchor"/><mml:math id="M53" display="inline" overflow="scroll"><mml:mi mathvariant="normal">C</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1,1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> is calculated between each residue pairs, where <italic toggle="yes">L</italic><sub>1</sub> and <italic toggle="yes">L</italic><sub>2</sub> are the number of residues in the respective structures and <italic toggle="yes">c</italic><sub><italic toggle="yes">ij</italic></sub> denotes the cosine similarity between the <italic toggle="yes">i</italic><sup>th</sup> residue in one structure and the <italic toggle="yes">j</italic><sup>th</sup> residue in the other one. Then, Needlman-Wunsch dynamic programming algorithm is used to align two protein sequences [<xref rid="pcbi.1009986.ref019" ref-type="bibr">19</xref>]. The cosine similarity matrix serves as the scoring matrix. The penalty for opening and extending a gap is 0 and 0.1, respectively. Kabsch algorithm is used to find the optimal rotation and translation for two structures after determining the residue correspondence [<xref rid="pcbi.1009986.ref047" ref-type="bibr">47</xref>]. Other more complicated and effective alignment algorithms are not applied here since we only want to know whether GraSR could find an acceptable residue correspondence instead of obtaining the best superposition.</p>
      <p>Two proteins in <xref rid="pcbi.1009986.g007" ref-type="fig">Fig 7A</xref> belong to the same SCOPe family: FAD/NAD-linked reductases, N-terminal and central domains (SCOPe-sccs: c.3.1.5). The RMSD of their superposition is only 2.12Å. Proteins in <xref rid="pcbi.1009986.g007" ref-type="fig">Fig 7B</xref> belong to the same superfamily: Bacterial luciferase-like (SCOPe-sccs: c.1.16), but are in different families. Thus, the RMSD of them is relatively larger. The alignment has also been done to many other structures and their structural neighbors in the SCOPe and similar phenomena are also observed. Some exceptions do exist when the number of residues in two aligned proteins are varied. However, the overall results show that equivalent residues in two similar protein structures can be found based on the residue-level descriptors derived from GraSR. It should be noticed that GraSR only knows whether a protein structure pair is more similar than other ones and no alignment information is used in the training stage. Thus, the GNNs used in GraSR learn accurate node embeddings, which help determine the residue correspondence and benefit the global descriptors of the protein structures.</p>
      <fig position="float" id="pcbi.1009986.g007">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1009986.g007</object-id>
        <label>Fig 7</label>
        <caption>
          <title>Protein structure superposition derived from the residue-level descriptors of GraSR.</title>
          <p>(A) SCOPe-sid: d1v59a2 (red) and d1h6va2 (blue) (B) SCOPe-sid: d5dqpa_ (red) and d1ezwa_ (blue).</p>
        </caption>
        <graphic xlink:href="pcbi.1009986.g007" position="float"/>
      </fig>
    </sec>
    <sec id="sec021">
      <title>Future directions</title>
      <p>Although GraSR and other alignment-free methods can provide fast and accurate structure retrieval, there still exists space for further improvement. Structure alignment is not needed by alignment-free methods, which accelerates the comparison process; on the other hand, it is difficult for alignment-free methods to obtain the superposition information of the protein structures, which will be useful for understanding the structural similarity at the atomic level. The accuracy of alignment-free methods is inferior to alignment-based methods in some cases. The potential reason is also the lack of structure alignment. Combining these two approaches would be promising than using them alone. Faster alignment-free methods can be used to retrieve a small subset of roughly similar structures and then accurate but slower alignment-based methods are used to pick the most similar structures from the subset at atomic level. In addition, with further development of deep learning theory, it is possible and also necessary to extract more accurate superposition information from neural networks according to our observation in the section 4.2.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec022">
    <title>Conclusions</title>
    <p>Comparing the similarity of two protein 3D structure accurately in a fast manner is highly desired with the explosion of protein structure data. This will help us know more about the protein fold type space. In this study, we propose an effective protein structure representation learning method GraSR for this task, which is constructed under an effective contrastive learning framework. The encoders are redesigned and two novel strategies are proposed to further improve the performance. The encoders integrate a biLSTM and multiple graph convolutional layers to extract high-level features from both the primary structure and tertiary structure. The length-scaling cosine distance is designed to bridge the gap between the standard cosine distance and TM-score, and the dynamic training data partition strategy helps the encoder to learn more fine-grained relationship between protein structures. In addition, we propose a more comprehensive evaluation measurement named Top-K hit ratio, which can be seen as an extension to the Top-K accuracy. All protein structure representation methods are evaluated on the SCOPe v2.07 and the independent test set built from PDB. Compared with the existing methods, the result demonstrates that GraSR learns more discriminative protein structural descriptors and achieves higher performance on the ranking task and multi-class classification task. In addition to the global structure representation, GraSR can implicitly learn residue-level representations, which can be used to describe the local geometric features. We expect that the structural descriptors learned by GraSR could be useful for downstream tasks, such as structure-based protein function prediction and protein-ligand binding affinity prediction.</p>
  </sec>
  <sec id="sec023" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pcbi.1009986.s001" position="float" content-type="local-data">
      <label>S1 File</label>
      <caption>
        <title>Supplemental control experiments, analyses and figures.</title>
        <p><bold>Text A:</bold> Rules for data filtering. <bold>Text B:</bold> The Architecture of the CNN-based encoder. <bold>Text C:</bold> Selection of K in dynamic training data partition. <bold>Text D:</bold> The distance-based feature is invariant to rotation and translation. <bold>Text E:</bold> Visualization by t-SNE at different perplexity. <bold>Table A:</bold> Performance of GraphFold when selecting different K in the dynamic training data partition on SCOPe v2.07. <bold>Fig A:</bold> Visualization of descriptors learned from GraSR and other methods by t-SNE (perplexity = 30). <bold>Fig B:</bold> Visualization of descriptors learned from GraSR and other methods by t-SNE (perplexity = 100). <bold>Fig C:</bold> Visualization of descriptors learned from GraSR and other methods by t-SNE (perplexity = 500).</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1009986.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1009986.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Kryshtafovych</surname><given-names>A</given-names></name>, <name><surname>Schwede</surname><given-names>T</given-names></name>, <name><surname>Topf</surname><given-names>M</given-names></name>, <name><surname>Fidelis</surname><given-names>K</given-names></name>, <name><surname>Moult</surname><given-names>J</given-names></name>. <article-title>Critical assessment of methods of protein structure prediction (CASP)-Round XIII</article-title>. <source>Proteins</source>. <year>2019</year>;<volume>87</volume>(<issue>12</issue>):<fpage>1011</fpage>–<lpage>20</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/prot.25823</pub-id><?supplied-pmid 31589781?><pub-id pub-id-type="pmid">31589781</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Lensink</surname><given-names>MF</given-names></name>, <name><surname>Velankar</surname><given-names>S</given-names></name>, <name><surname>Baek</surname><given-names>M</given-names></name>, <name><surname>Heo</surname><given-names>L</given-names></name>, <name><surname>Seok</surname><given-names>C</given-names></name>, <name><surname>Wodak</surname><given-names>SJ</given-names></name>. <article-title>The challenge of modeling protein assemblies: the CASP12-</article-title><source>CAPRI experiment. Proteins</source>. <year>2018</year>;<volume>86</volume><issue>Suppl 1</issue>:<fpage>257</fpage>–<lpage>73</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/prot.25419</pub-id><?supplied-pmid 29127686?><pub-id pub-id-type="pmid">29127686</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Gherardini</surname><given-names>PF</given-names></name>, <name><surname>Helmer-Citterich</surname><given-names>M</given-names></name>. <article-title>Structure-based function prediction: approaches and applications</article-title>. <source>Brief Funct Genomic Proteomic</source>. <year>2008</year>;<volume>7</volume>(<issue>4</issue>):<fpage>291</fpage>–<lpage>302</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bfgp/eln030</pub-id><?supplied-pmid 18599513?><pub-id pub-id-type="pmid">18599513</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Senior</surname><given-names>AW</given-names></name>, <name><surname>Evans</surname><given-names>R</given-names></name>, <name><surname>Jumper</surname><given-names>J</given-names></name>, <name><surname>Kirkpatrick</surname><given-names>J</given-names></name>, <name><surname>Sifre</surname><given-names>L</given-names></name>, <name><surname>Green</surname><given-names>T</given-names></name>, <etal>et al</etal>. <article-title>Improved protein structure prediction using potentials from deep learning</article-title>. <source>Nat</source>. <year>2020</year>;<volume>577</volume>(<issue>7792</issue>):<fpage>706</fpage>–<lpage>10</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41586-019-1923-7</pub-id><?supplied-pmid 31942072?><pub-id pub-id-type="pmid">31942072</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Lapatto</surname><given-names>R</given-names></name>, <name><surname>Blundell</surname><given-names>T</given-names></name>, <name><surname>Hemmings</surname><given-names>A</given-names></name>, <name><surname>Overington</surname><given-names>J</given-names></name>, <name><surname>Wilderspin</surname><given-names>A</given-names></name>, <name><surname>Wood</surname><given-names>S</given-names></name>, <etal>et al</etal>. <article-title>X-ray analysis of HIV-1 proteinase at 2.7 A resolution confirms structural homology among retroviral enzymes</article-title>. <source>Nature</source>. <year>1989</year>;<volume>342</volume>(<issue>6247</issue>):<fpage>299</fpage>–<lpage>302</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/342299a0</pub-id><?supplied-pmid 2682266?><pub-id pub-id-type="pmid">2682266</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Shindyalov</surname><given-names>IN</given-names></name>, <name><surname>Bourne</surname><given-names>PE</given-names></name>. <article-title>Protein structure alignment by incremental combinatorial extension (CE) of the optimal path</article-title>. <source>Protein Eng</source>. <year>1998</year>;<volume>11</volume>(<issue>9</issue>):<fpage>739</fpage>–<lpage>47</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/protein/11.9.739</pub-id><?supplied-pmid 9796821?><pub-id pub-id-type="pmid">9796821</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Holm</surname><given-names>L</given-names></name>, <name><surname>Sander</surname><given-names>C</given-names></name>. <article-title>Protein-Structure Comparison by Alignment of Distance Matrices</article-title>. <source>J Mol Biol</source>. <year>1993</year>;<volume>233</volume>(<issue>1</issue>):<fpage>123</fpage>–<lpage>38</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1006/jmbi.1993.1489</pub-id><?supplied-pmid 8377180?><pub-id pub-id-type="pmid">8377180</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Levitt</surname><given-names>M</given-names></name>, <name><surname>Gerstein</surname><given-names>M</given-names></name>. <article-title>A unified statistical framework for sequence comparison and structure comparison</article-title>. <source>P Natl Acad Sci USA</source>. <year>1998</year>;<volume>95</volume>(<issue>11</issue>):<fpage>5913</fpage>–<lpage>20</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.95.11.5913</pub-id><?supplied-pmid 9600892?><pub-id pub-id-type="pmid">9600892</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Kihara</surname><given-names>D</given-names></name>, <name><surname>Skolnick</surname><given-names>J</given-names></name>. <article-title>The PDB is a covering set of small protein structures</article-title>. <source>J Mol Biol</source>. <year>2003</year>;<volume>334</volume>(<issue>4</issue>):<fpage>793</fpage>–<lpage>802</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jmb.2003.10.027</pub-id><?supplied-pmid 14636603?><pub-id pub-id-type="pmid">14636603</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Skolnick</surname><given-names>J</given-names></name>. <article-title>TM-align: a protein structure alignment algorithm based on the TM-score</article-title>. <source>Nucleic Acids Res</source>. <year>2005</year>;<volume>33</volume>(<issue>7</issue>):<fpage>2302</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gki524</pub-id><?supplied-pmid 15849316?><pub-id pub-id-type="pmid">15849316</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Daniluk</surname><given-names>P</given-names></name>, <name><surname>Oleniecki</surname><given-names>T</given-names></name>, <name><surname>Lesyng</surname><given-names>B</given-names></name>. <article-title>DAMA-a method for computing multiple alignments of protein structures using local structure descriptors</article-title>. <source>Bioinformatics</source>. <year>2021</year>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btab571</pub-id><?supplied-pmid 34396393?><pub-id pub-id-type="pmid">34396393</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Akdel</surname><given-names>M</given-names></name>, <name><surname>Durairaj</surname><given-names>J</given-names></name>, <name><surname>de Ridder</surname><given-names>D</given-names></name>, <name><surname>van Dijk</surname><given-names>ADJ</given-names></name>. <article-title>Caretta—A multiple protein structure alignment and feature extraction suite</article-title>. <source>Computational and structural biotechnology journal</source>. <year>2020</year>;<volume>18</volume>:<fpage>981</fpage>–<lpage>92</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.csbj.2020.03.011</pub-id><?supplied-pmid 32368333?><pub-id pub-id-type="pmid">32368333</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Shegay</surname><given-names>MV</given-names></name>, <name><surname>Suplatov</surname><given-names>DA</given-names></name>, <name><surname>Popova</surname><given-names>NN</given-names></name>, <name><surname>Svedas</surname><given-names>VK</given-names></name>, <name><surname>Voevodin</surname><given-names>VV</given-names></name>. <article-title>parMATT: parallel multiple alignment of protein 3D-structures with translations and twists for distributed-memory systems</article-title>. <source>Bioinformatics</source>. <year>2019</year>;<volume>35</volume>(<issue>21</issue>):<fpage>4456</fpage>–<lpage>8</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btz224</pub-id><?supplied-pmid 30918940?><pub-id pub-id-type="pmid">30918940</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Rogen</surname><given-names>P</given-names></name>, <name><surname>Fain</surname><given-names>B</given-names></name>. <article-title>Automatic classification of protein structure by using Gauss integrals</article-title>. <source>P Natl Acad Sci USA</source>. <year>2003</year>;<volume>100</volume>(<issue>1</issue>):<fpage>119</fpage>–<lpage>24</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.2636460100</pub-id><?supplied-pmid 12506205?><pub-id pub-id-type="pmid">12506205</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Zotenko</surname><given-names>E</given-names></name>, <name><surname>O’Leary</surname><given-names>DP</given-names></name>, <name><surname>Przytycka</surname><given-names>TM</given-names></name>. <article-title>Secondary structure spatial conformation footprint: a novel method for fast protein structure comparison and classification</article-title>. <source>Bmc Struct Biol</source>. <year>2006</year>;<volume>6</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>12</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/1472-6807-6-12</pub-id><?supplied-pmid 16762072?><pub-id pub-id-type="pmid">16396680</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Budowski-Tal</surname><given-names>I</given-names></name>, <name><surname>Nov</surname><given-names>Y</given-names></name>, <name><surname>Kolodny</surname><given-names>R</given-names></name>. <article-title>FragBag, an accurate representation of protein structure, retrieves structural neighbors from the entire PDB quickly and accurately</article-title>. <source>P Natl Acad Sci USA.</source><year>2010</year>;<volume>107</volume>(<issue>8</issue>):<fpage>3481</fpage>–<lpage>6</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1073/pnas.0914097107</pub-id><?supplied-pmid 20133727?><pub-id pub-id-type="pmid">20133727</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Petitjean</surname><given-names>M.</given-names></name><article-title>On the root mean square quantitative chirality and quantitative symmetry measures</article-title>. <source>J Math Phys</source>. <year>1999</year>;<volume>40</volume>(<issue>9</issue>):<fpage>4587</fpage>–<lpage>95</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Lathrop</surname><given-names>RH</given-names></name>. <article-title>The Protein Threading Problem with Sequence Amino-Acid Interaction Preferences Is NP-Complete</article-title>. <source>Protein Eng</source>. <year>1994</year>;<volume>7</volume>(<issue>9</issue>):<fpage>1059</fpage>–<lpage>68</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/protein/7.9.1059</pub-id><?supplied-pmid 7831276?><pub-id pub-id-type="pmid">7831276</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Needleman</surname><given-names>SB</given-names></name>, <name><surname>Wunsch</surname><given-names>CD</given-names></name>. <article-title>A general method applicable to the search for similarities in the amino acid sequence of two proteins</article-title>. <source>J Mol Biol</source>. <year>1970</year>;<volume>48</volume>(<issue>3</issue>):<fpage>443</fpage>–<lpage>53</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/0022-2836(70)90057-4</pub-id><?supplied-pmid 5420325?><pub-id pub-id-type="pmid">5420325</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Fox</surname><given-names>NK</given-names></name>, <name><surname>Brenner</surname><given-names>SE</given-names></name>, <name><surname>Chandonia</surname><given-names>JM</given-names></name>. <article-title>SCOPe: Structural Classification of Proteins-extended, integrating SCOP and ASTRAL data and classification of new structures</article-title>. <source>Nucleic Acids Res</source>. <year>2014</year>;<volume>42</volume>(<issue>D1</issue>):<fpage>D304</fpage>–<lpage>D9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkt1240</pub-id><?supplied-pmid 24304899?><pub-id pub-id-type="pmid">24304899</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Berman</surname><given-names>HM</given-names></name>, <name><surname>Westbrook</surname><given-names>J</given-names></name>, <name><surname>Feng</surname><given-names>Z</given-names></name>, <name><surname>Gilliland</surname><given-names>G</given-names></name>, <name><surname>Bhat</surname><given-names>TN</given-names></name>, <name><surname>Weissig</surname><given-names>H</given-names></name>, <etal>et al</etal>. <article-title>The Protein Data Bank</article-title>. <source>Nucleic Acids Res</source>. <year>2000</year>;<volume>28</volume>(<issue>1</issue>):<fpage>235</fpage>–<lpage>42</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/28.1.235</pub-id><?supplied-pmid 10592235?><pub-id pub-id-type="pmid">10592235</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>K</given-names></name>, <name><surname>Lu</surname><given-names>JW</given-names></name>, <name><surname>Chen</surname><given-names>CS</given-names></name>, <name><surname>Zhou</surname><given-names>J</given-names></name>, <name><surname>Sun</surname><given-names>MT</given-names></name>. <article-title>Unsupervised Deep Learning of Compact Binary Descriptors</article-title>. <source>Ieee T Pattern Anal</source>. <year>2019</year>;<volume>41</volume>(<issue>6</issue>):<fpage>1501</fpage>–<lpage>14</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Randic</surname><given-names>M.</given-names></name><article-title>Novel Molecular Descriptor for Structure-Property Studies</article-title>. <source>Chem Phys Lett</source>. <year>1993</year>;<volume>211</volume>(<issue>4–5</issue>):<fpage>478</fpage>–<lpage>83</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>Y</given-names></name>, <name><surname>Ye</surname><given-names>Q</given-names></name>, <name><surname>Wang</surname><given-names>LW</given-names></name>, <name><surname>Peng</surname><given-names>J</given-names></name>. <article-title>Learning structural motif representations for efficient protein structure search</article-title>. <source>Bioinformatics</source>. <year>2018</year>;<volume>34</volume>(<issue>17</issue>):<fpage>773</fpage>–<lpage>80</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/bty585</pub-id><?supplied-pmid 30423083?><pub-id pub-id-type="pmid">30423083</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Xia</surname><given-names>Y</given-names></name>, <name><surname>Xia</surname><given-names>CQ</given-names></name>, <name><surname>Pan</surname><given-names>X</given-names></name>, <name><surname>Shen</surname><given-names>HB</given-names></name>. <article-title>GraphBind: protein structural context embedded rules learned by hierarchical graph neural networks for recognizing nucleic-acid-binding residues</article-title>. <source>Nucleic acids research</source>. <year>2021</year>;<volume>49</volume>(<issue>9</issue>):<fpage>e51</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/nar/gkab044</pub-id><?supplied-pmid 33577689?><pub-id pub-id-type="pmid">33577689</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Gainza</surname><given-names>P</given-names></name>, <name><surname>Sverrisson</surname><given-names>F</given-names></name>, <name><surname>Monti</surname><given-names>F</given-names></name>, <name><surname>Rodola</surname><given-names>E</given-names></name>, <name><surname>Boscaini</surname><given-names>D</given-names></name>, <name><surname>Bronstein</surname><given-names>MM</given-names></name>, <etal>et al</etal>. <article-title>Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning.</article-title><source>Nat Methods</source>. <year>2020</year>;<volume>17</volume>(<issue>2</issue>):<fpage>184</fpage>–<lpage>92</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41592-019-0666-6</pub-id><?supplied-pmid 31819266?><pub-id pub-id-type="pmid">31819266</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Skolnick</surname><given-names>J</given-names></name>. <article-title>Scoring function for automated assessment of protein structure template quality</article-title>. <source>Proteins-Structure Function and Bioinformatics</source>. <year>2004</year>;<volume>57</volume>(<issue>4</issue>):<fpage>702</fpage>–<lpage>10</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1002/prot.20264</pub-id><?supplied-pmid 15476259?><pub-id pub-id-type="pmid">15476259</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Kipf</surname><given-names>Thomas N</given-names></name>, <name><surname>Welling</surname><given-names>M</given-names></name>. <article-title>Semi-supervised classification with graph convolutional networks.</article-title><source>International Conference on Learning Representations</source><year>2017</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Hochreiter</surname><given-names>S</given-names></name>, <name><surname>Schmidhuber</surname><given-names>J</given-names></name>. <article-title>Long short-term memory</article-title>. <source>Neural Comput</source>. <year>1997</year>;<volume>9</volume>(<issue>8</issue>):<fpage>1735</fpage>–<lpage>80</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id><?supplied-pmid 9377276?><pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>WZ</given-names></name>, <name><surname>Godzik</surname><given-names>A</given-names></name>. <article-title>Cd-hit: a fast program for clustering and comparing large sets of protein or nucleotide sequences</article-title>. <source>Bioinformatics</source>. <year>2006</year>;<volume>22</volume>(<issue>13</issue>):<fpage>1658</fpage>–<lpage>9</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btl158</pub-id><?supplied-pmid 16731699?><pub-id pub-id-type="pmid">16731699</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Hammond</surname><given-names>DK</given-names></name>, <name><surname>Vandergheynst</surname><given-names>P</given-names></name>, <name><surname>Gribonval</surname><given-names>R</given-names></name>. <article-title>Wavelets on graphs via spectral graph theory.</article-title><source>Appl Comput Harmon A</source>. <year>2011</year>;<volume>30</volume>(<issue>2</issue>):<fpage>129</fpage>–<lpage>50</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Gilmer</surname><given-names>Justin</given-names></name>, <name><surname>Schoenholz</surname><given-names>Samuel S.</given-names></name>, <name><surname>Riley</surname><given-names>Patrick F.</given-names></name>, <name><surname>Vinyals</surname><given-names>Oriol</given-names></name>, <name><surname>Dahl</surname><given-names>GE</given-names></name>. <article-title>Neural Message Passing for Quantum Chemistry</article-title>. <source>International Conference on Machine Learning</source><year>2017</year>. p. <fpage>1263</fpage>–<lpage>72</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Hamilton</surname><given-names>William L.</given-names></name>, <name><surname>Ying</surname><given-names>Rex</given-names></name>, <name><surname>Leskovec</surname><given-names>J</given-names></name>. <article-title>Inductive Representation Learning on Large Graphs</article-title>. <source>Conference on Neural Information Processing Systems</source><year>2017</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>He</surname><given-names>KM</given-names></name>, <name><surname>Zhang</surname><given-names>XY</given-names></name>, <name><surname>Ren</surname><given-names>SQ</given-names></name>, <name><surname>Sun</surname><given-names>J</given-names></name>. <article-title>Deep Residual Learning for Image Recognition</article-title>. <source>IEEE Conference on Computer Vision and Pattern Recognition</source>. <year>2016</year>:<fpage>770</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Graves</surname><given-names>A</given-names></name>, <name><surname>Schmidhuber</surname><given-names>J</given-names></name>. <article-title>Framewise phoneme classification with bidirectional LSTM and other neural network architectures</article-title>. <source>Neural Networks.</source><year>2005</year>;<volume>18</volume>(<issue>5–6</issue>):<fpage>602</fpage>–<lpage>10</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.neunet.2005.06.042</pub-id><?supplied-pmid 16112549?><pub-id pub-id-type="pmid">16112549</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref036">
      <label>36</label>
      <mixed-citation publication-type="book"><name><surname>He</surname><given-names>Kaiming</given-names></name>, <name><surname>Fan</surname><given-names>Haoqi</given-names></name>, <name><surname>Wu</surname><given-names>Yuxin</given-names></name>, <name><surname>Xie</surname><given-names>Saining</given-names></name>, <name><surname>Girshick</surname><given-names>R</given-names></name>, editors. <part-title>Momentum contrast for unsupervised visual representation learning</part-title>. <publisher-name>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</publisher-name>; <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>van den Oord</surname><given-names>Aaron</given-names></name>, <name><surname>Li</surname><given-names>Yazhe</given-names></name>, <name><surname>Vinyals</surname><given-names>aO</given-names></name>. <article-title>Representation learning with contrastive predictive coding</article-title><year>2018</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref038">
      <label>38</label>
      <mixed-citation publication-type="book"><name><surname>Davis</surname><given-names>J</given-names></name>, <name><surname>G</surname><given-names>M</given-names></name>. <source>The relationship between Precision-Recall and ROC curves</source>. <publisher-name>International Conference on Machine Learning</publisher-name><year>2006</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Meng</surname><given-names>FC</given-names></name>, <name><surname>Kurgan</surname><given-names>L</given-names></name>. <article-title>DFLpred: High-throughput prediction of disordered flexible linker regions in protein sequences</article-title>. <source>Bioinformatics</source>. <year>2016</year>;<volume>32</volume>(<issue>12</issue>):<fpage>341</fpage>–<lpage>50</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btw280</pub-id><?supplied-pmid 27307636?><pub-id pub-id-type="pmid">27307636</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref040">
      <label>40</label>
      <mixed-citation publication-type="book"><name><surname>Ioffe</surname><given-names>S</given-names></name>, <name><surname>Szegedy</surname><given-names>C</given-names></name>. <part-title>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.</part-title> In: <name><surname>Francis</surname><given-names>B</given-names></name>, <name><surname>David</surname><given-names>B</given-names></name>, editors. <source>Proceedings of the 32nd International Conference on Machine Learning; Proceedings of Machine Learning Research</source>: <publisher-name>PMLR</publisher-name>; <year>2015</year>. p. <fpage>448</fpage>–<lpage>56</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Hinton</surname><given-names>GE</given-names></name>, <name><surname>Srivastava</surname><given-names>N</given-names></name>, <name><surname>Krizhevsky</surname><given-names>A</given-names></name>, <name><surname>Sutskever</surname><given-names>I</given-names></name>, <name><surname>Salakhutdinov</surname><given-names>R</given-names></name>. <article-title>Improving neural networks by preventing co-adaptation of feature detectors</article-title>. <source>ArXiv</source>. <year>2012</year>;abs/1207.0580.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref042">
      <label>42</label>
      <mixed-citation publication-type="book"><name><surname>Nair</surname><given-names>Vinod</given-names></name>, <name><surname>Hinton</surname><given-names>GE</given-names></name>. <part-title>Rectified Linear Units Improve Restricted Boltzmann Machines</part-title>. <publisher-name>International Conference on Machine Learning</publisher-name><year>2010</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref043">
      <label>43</label>
      <mixed-citation publication-type="book"><name><surname>Maas</surname><given-names>Andrew L.</given-names></name>, <name><surname>Hannun</surname><given-names>Awni Y.</given-names></name>, <name><surname>Ng</surname><given-names>AY</given-names></name>. <part-title>Rectifier Nonlinearities Improve Neural Network Acoustic Models</part-title>. <publisher-name>International Conference on Machine Learning</publisher-name><year>2013</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref044">
      <label>44</label>
      <mixed-citation publication-type="journal"><name><surname>Durairaj</surname><given-names>J</given-names></name>, <name><surname>Akdel</surname><given-names>M</given-names></name>, <name><surname>de Ridder</surname><given-names>D</given-names></name>, <name><surname>van Dijk</surname><given-names>ADJ</given-names></name>. <article-title>Geometricus represents protein structures as shape-mers derived from moment invariants</article-title>. <source>Bioinformatics</source>. <year>2020</year>;<volume>36</volume>(<issue>Suppl_2</issue>):<fpage>i718</fpage>–<lpage>i25</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btaa839</pub-id><?supplied-pmid 33381814?><pub-id pub-id-type="pmid">33381814</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref045">
      <label>45</label>
      <mixed-citation publication-type="journal"><name><surname>van der Maaten</surname><given-names>L</given-names></name>, <name><surname>Hinton</surname><given-names>G</given-names></name>. <article-title>Visualizing Data using t-SNE</article-title>. <source>J Mach Learn Res</source>. <year>2008</year>;<volume>9</volume>:<fpage>2579</fpage>–<lpage>605</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref046">
      <label>46</label>
      <mixed-citation publication-type="journal"><name><surname>Kolodny</surname><given-names>R</given-names></name>, <name><surname>Koehl</surname><given-names>P</given-names></name>, <name><surname>Levitt</surname><given-names>M</given-names></name>. <article-title>Comprehensive evaluation of protein structure alignment methods: Scoring by geometric measures</article-title>. <source>J Mol Biol</source>. <year>2005</year>;<volume>346</volume>(<issue>4</issue>):<fpage>1173</fpage>–<lpage>88</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.jmb.2004.12.032</pub-id><?supplied-pmid 15701525?><pub-id pub-id-type="pmid">15701525</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1009986.ref047">
      <label>47</label>
      <mixed-citation publication-type="journal"><name><surname>Kabsch</surname><given-names>W.</given-names></name><article-title>A discussion of the solution for the best rotation to relate two sets of vectors</article-title>. <source>Acta Crystallographica Section A</source>. <year>1978</year>;<volume>34</volume>(<issue>5</issue>):<fpage>827</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
