<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10918628</article-id>
    <article-id pub-id-type="pmid">38366935</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btae092</article-id>
    <article-id pub-id-type="publisher-id">btae092</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Note</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>EvoAug-TF: extending evolution-inspired data augmentations for genomic deep learning to TensorFlow</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0009-0001-2925-1909</contrib-id>
        <name>
          <surname>Yu</surname>
          <given-names>Yiyang</given-names>
        </name>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization" degree-contribution="supporting">Conceptualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation" degree-contribution="equal">Data curation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="lead">Formal analysis</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="lead">Investigation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology" degree-contribution="lead">Methodology</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software" degree-contribution="lead">Software</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation" degree-contribution="equal">Validation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization" degree-contribution="equal">Visualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="lead">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="supporting">Writing - review &amp; editing</role>
        <aff><institution>Simons Center for Quantitative Biology, Cold Spring Harbor Laboratory</institution>, Cold Spring Harbor, NY 11724, <country country="US">United States</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Muthukumar</surname>
          <given-names>Shivani</given-names>
        </name>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="supporting">Formal analysis</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="supporting">Writing - review &amp; editing</role>
        <aff><institution>Commack High School</institution>, Commack, NY 11725, <country country="US">United States</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-8722-0038</contrib-id>
        <name>
          <surname>Koo</surname>
          <given-names>Peter K</given-names>
        </name>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization" degree-contribution="lead">Conceptualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation" degree-contribution="equal">Data curation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="supporting">Formal analysis</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition" degree-contribution="lead">Funding acquisition</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="supporting">Investigation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology" degree-contribution="supporting">Methodology</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration" degree-contribution="lead">Project administration</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources" degree-contribution="lead">Resources</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software" degree-contribution="supporting">Software</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision" degree-contribution="lead">Supervision</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation" degree-contribution="supporting">Validation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization" degree-contribution="supporting">Visualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="supporting">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="lead">Writing - review &amp; editing</role>
        <aff><institution>Simons Center for Quantitative Biology, Cold Spring Harbor Laboratory</institution>, Cold Spring Harbor, NY 11724, <country country="US">United States</country></aff>
        <xref rid="btae092-cor1" ref-type="corresp"/>
        <!--koo@cshl.edu-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btae092-cor1">Corresponding author. Simons Center for Quantitative Biology, Cold Spring Harbor Laboratory, 1 Bungtown Rd, Cold Spring Harbor, NY 11724, United States. E-mail: <email>koo@cshl.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2024-02-16">
      <day>16</day>
      <month>2</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>16</day>
      <month>2</month>
      <year>2024</year>
    </pub-date>
    <volume>40</volume>
    <issue>3</issue>
    <elocation-id>btae092</elocation-id>
    <history>
      <date date-type="received">
        <day>15</day>
        <month>7</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>01</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="editorial-decision">
        <day>09</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="corrected-typeset">
        <day>06</day>
        <month>3</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2024</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btae092.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Summary</title>
        <p>Deep neural networks (DNNs) have been widely applied to predict the molecular functions of the non-coding genome. DNNs are data hungry and thus require many training examples to fit data well. However, functional genomics experiments typically generate limited amounts of data, constrained by the activity levels of the molecular function under study inside the cell. Recently, EvoAug was introduced to train a genomic DNN with evolution-inspired augmentations. EvoAug-trained DNNs have demonstrated improved generalization and interpretability with attribution analysis. However, EvoAug only supports PyTorch-based models, which limits its applications to a broad class of genomic DNNs based in TensorFlow. Here, we extend EvoAug’s functionality to TensorFlow in a new package, we call EvoAug-TF. Through a systematic benchmark, we find that EvoAug-TF yields comparable performance with the original EvoAug package.</p>
      </sec>
      <sec id="s2">
        <title>Availability and implementation</title>
        <p>EvoAug-TF is freely available for users and is distributed under an open-source MIT license. Researchers can access the open-source code on GitHub (<ext-link xlink:href="https://github.com/p-koo/evoaug-tf" ext-link-type="uri">https://github.com/p-koo/evoaug-tf</ext-link>). The pre-compiled package is provided via PyPI (<ext-link xlink:href="https://pypi.org/project/evoaug-tf" ext-link-type="uri">https://pypi.org/project/evoaug-tf</ext-link>) with in-depth documentation on ReadTheDocs (<ext-link xlink:href="https://evoaug-tf.readthedocs.io" ext-link-type="uri">https://evoaug-tf.readthedocs.io</ext-link>). The scripts for reproducing the results are available at (<ext-link xlink:href="https://github.com/p-koo/evoaug-tf_analysis" ext-link-type="uri">https://github.com/p-koo/evoaug-tf_analysis</ext-link>).</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of General Medical Sciences</institution>
            <institution-id institution-id-type="DOI">10.13039/100000057</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R01GM149921</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Human Genome Research Institute of the National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01HG012131</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>US National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>S10OD028632-01</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="4"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Deep neural networks (DNNs) have emerged as a promising tool for supervised learning of regulatory genomics data, taking DNA sequences as input and predicting the readouts of functional genomics experiments (<xref rid="btae092-B7" ref-type="bibr">Eraslan <italic toggle="yes">et al.</italic> 2019</xref>, <xref rid="btae092-B10" ref-type="bibr">Koo and Ploenzke 2020</xref>). Due to their overparameterization, DNNs are data hungry, requiring large amounts of data to learn discriminative features that ensure good generalization (<xref rid="btae092-B23" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2021</xref>). However, most functional genomics experiments only observe a limited number of molecular interactions within the context of a cell. For instance, the number of binding sites available for a transcription factor can be limited to the finite number of accessible DNA within a given cell type. Hence, dataset size is a major limiting factor when analyzing functional genomics data with DNNs.</p>
    <p>Data augmentation is a widely practiced strategy in machine learning to provide additional training samples. In practice, random transformations that maintain the same training labels are imposed on the input data, leveraging the natural symmetries in the data. For example, in natural images, the objects can undergo affine transformations, flips, color perturbations, and blurs, which do not alter the object’s label. In genomics, the available transformations that can maintain the same training labels are limited to reverse complements and small random shifts (<xref rid="btae092-B3" ref-type="bibr">Avsec <italic toggle="yes">et al.</italic> 2021a</xref>, <xref rid="btae092-B22" ref-type="bibr">Toneyan <italic toggle="yes">et al.</italic> 2022</xref>).</p>
    <p>To expand the available augmentations, EvoAug (Lee <italic toggle="yes">et al.</italic> 2023) was recently introduced to provide evolution-inspired data augmentations, including translocations, insertions, deletions, inversions, and mutations. In nature, genetic variation is sampled by evolution to increase phenotypic diversity. Thus, genetic mutations can alter the function of the sequence and, hence, change its label. Nevertheless, EvoAug asserts that the transformed sequences retain the same training label as the wild-type sequence, which can be considered as imposing a prior. For instance, small random translocations impose a prior that the activity of motifs is invariant to shifts. Moreover, insertions and deletions impose a prior that the distance between motifs is insignificant. Considered as a prior, evolution-inspired augmentations can introduce a bias in the DNN that may break the underlying rules of <italic toggle="yes">cis</italic>-regulatory grammars in the data. Thus, EvoAug employs a second stage of training that finetunes the DNN on the original, unaltered data, ensuring functional integrity toward the observed biology. This two-stage training curriculum has proven beneficial for genomic DNNs using synthetic data augmentations (Lee <italic toggle="yes">et al.</italic> 2023) and natural data augmentations (<xref rid="btae092-B6" ref-type="bibr">Duncan <italic toggle="yes">et al.</italic> 2023</xref>), as well as for protein-based DNNs (<xref rid="btae092-B15" ref-type="bibr">Lu <italic toggle="yes">et al.</italic> 2020</xref>, <xref rid="btae092-B14" ref-type="bibr">2022</xref>).</p>
    <p>However, the availability of EvoAug has been limited to a PyTorch (<xref rid="btae092-B19" ref-type="bibr">Paszke <italic toggle="yes">et al.</italic> 2019</xref>) implementation, posing a barrier for researchers working in TensorFlow (<xref rid="btae092-B1" ref-type="bibr">Abadi <italic toggle="yes">et al.</italic> 2016</xref>). To address this demand, we present <monospace>EvoAug-TF</monospace>, a TensorFlow implementation that builds upon the same principles as EvoAug. Below, we describe EvoAug-TF, highlighting its adaptations and unique features that are specific to the TensorFlow framework. Additionally, we present experimental results showcasing the effectiveness of EvoAug-TF in improving the generalization capabilities of genomic DNNs.</p>
  </sec>
  <sec>
    <title>2 Methodology and implementation</title>
    <p>EvoAug-TF adapts the functionality of the PyTorch-based EvoAug framework in TensorFlow (<xref rid="btae092-F1" ref-type="fig">Fig. 1a</xref>), including the augmentation techniques (e.g. random transversion, insertion, translocation, deletion, mutation, and noise). EvoAug-TF employs the same two-stage training curriculum, where stochastic augmentations are applied online to each mini-batch during training, followed by a finetuning step on the original, unperturbed data. Since EvoAug-TF imposes transformations on the input data while maintaining the same labels as the wild-type sequence, in its current form, EvoAug-TF only supports DNNs that output scalars in single-task or multi-task settings. In contrast, profile-based DNNs (<xref rid="btae092-B9" ref-type="bibr">Kelley <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae092-B4" ref-type="bibr">Avsec <italic toggle="yes">et al.</italic> 2021b</xref>, <xref rid="btae092-B22" ref-type="bibr">Toneyan <italic toggle="yes">et al.</italic> 2022</xref>) may require transformations to the corresponding labels, which is currently not supported in EvoAug-TF.</p>
    <fig position="float" id="btae092-F1">
      <label>Figure 1.</label>
      <caption>
        <p>Performance comparison between EvoAug and standard training. (a) Flowchart illustrating EvoAug-TF’s two-stage training curriculum. (b) Schematic demonstrating the difference between sequence mode and batch mode, where each column represents a mini-batch of sequences and different colors represent different data augmentations. (c, d) Performance comparison between EvoAug (PyTorch-based) and EvoAug-TF (TensorFlow-based) with DeepSTARR models trained with individual or combinations of augmentations (i.e. insertion + translocation + deletion; all augmentations) and finetuned on original STARR-seq data for two promoters: developmental (c) and housekeeping (d). (e) Comparison of the training time per epoch between EvoAug (PyTorch) and EvoAug-TF (TensorFlow). (c–e) Each scatter plot includes the data from five trials with random initialization. (f) Box-plots comparing the performance (area under the receiver operating characteristic curve) of a convolutional neural network trained with standard training, EvoAug-TF augmentations, and with finetuning on various Chip-seq peak classification tasks. (g) Performance comparison of DeepSTARR models with various training methods fit to training sets with varying levels of down-sampling. EvoAug-TF augmentations employed insertion + translocation + deletion in batch mode. The shaded region represents the SD of the mean across five models with different random initializations. (h) Box-plot comparison of the consistency of patterns within Saliency Maps, as measured by the <italic toggle="yes">k</italic>-attr-mean, for DeepSTARR models with standard training or EvoAug-TF augmentations (All). (i) Box-plot comparison of the attribution variation score, calculated according to the root-mean-squared attribution scores, for attribution maps generated by different methods (i.e. Saliency Maps, Integrated Gradients, and DeepSHAP) using a DeepSTARR model trained with standard training or EvoAug-TF augmentations (All). (h, i) Mann–Whitney <italic toggle="yes">U</italic>-test with <italic toggle="yes">P</italic>-values &lt;.001 (***) and .01 (**). Boxes represent five identical models with different random initializations.</p>
      </caption>
      <graphic xlink:href="btae092f1" position="float"/>
    </fig>
    <p>Several adaptations were made to EvoAug-TF compared to the PyTorch implementation, incorporating key design choices specific to the TensorFlow version. To ensure compatibility with TensorFlow’s graph mode and optimize training speed, <monospace>tf</monospace>. <monospace>Tensors</monospace> are used as substitutes for NumPy arrays, which were utilized in the PyTorch implementation. Additionally, EvoAug-TF employs <monospace>tf.while_loop</monospace> to achieve the same effects as the for loops used in the PyTorch implementation. The implementation of EvoAug-TF relies on TensorFlow 2 and its relevant libraries and dependencies; it has been tested thoroughly on versions 2.7 and 2.15.</p>
    <p>A key difference between EvoAug-TF and EvoAug lies in the approach to applying augmentations to the mini-batch during training. In the PyTorch implementation, the number of augmentations and the augmentation type are randomly chosen for each sequence. In the TensorFlow implementation, the same number of augmentations and augmentation types are employed for each sequence. However, the selected augmentation type(s) are sampled in a stochastic manner to impose a unique perturbation to each sequence in the mini-batch, similar to EvoAug. This design choice was made to simplify the process of imposing augmentations, while still sampling a high degree of genetic variation. Moreover, for some augmentations—such as translocation, insertion, deletion, and transversion (i.e. reverse-complement)—we offer an additional option to perform the same perturbation across all of the sequences within the mini-batch (<xref rid="btae092-F1" ref-type="fig">Fig. 1b</xref>), which we term batch mode. This feature provides a faster way to deploy augmentations, improving computational efficiency at the expense of sampling diversity.</p>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <p>To benchmark the performance of EvoAug-TF, we utilized the data and deep-learning model from the DeepSTARR study (<xref rid="btae092-B5" ref-type="bibr">de Almeida <italic toggle="yes">et al.</italic> 2022</xref>). The prediction task is set up to take as input 249-nt sequences and predict enhancer activity [measured via STARR-seq (<xref rid="btae092-B2" ref-type="bibr">Arnold <italic toggle="yes">et al.</italic> 2013</xref>)] for developmental and housekeeping transcriptional promoters in <italic toggle="yes">Drosophila melanogaster</italic> S2 cells as a multi-task regression. We systematically trained the DeepSTARR model with different EvoAug-TF augmentations individually and in combinations and compared their performance with the original EvoAug, using the same hyperparameters as in the original study (Lee <italic toggle="yes">et al.</italic> 2023). To ensure the robustness of the results, we conducted five trials for each set of augmentations with different random initializations.</p>
    <p>We found that models trained with EvoAug-TF augmentations achieved comparable performance to the original EvoAug-trained models with the same augmentation settings (<xref rid="btae092-F1" ref-type="fig">Fig. 1c and d</xref>). Notably, EvoAug-TF consistently yielded improved performance compared to the original EvoAug after Stage 1 (i.e. before finetuning) with the exception of random noise augmentation. However, the original EvoAug yielded slightly better performance than EvoAug-TF upon finetuning. In most cases, models trained with data augmentations led to improved performance compared to standard training.</p>
    <p>In terms of computational costs, we found that running EvoAug-TF exhibited similar training times per epoch as EvoAug (<xref rid="btae092-F1" ref-type="fig">Fig. 1e</xref>). Thus, EvoAug-TF’s approach of applying the same numbers and types of augmentations to each sequence maintains a comparable computational cost as EvoAug’s approach of applying different numbers and types of augmentations to each sequence. Notably, both approaches are effective in improving model performance.</p>
    <p>To further demonstrate the breadth of the EvoAug-TF package, we explored the use of batch mode augmentations. First, we trained convolutional neural networks on ChIP-seq peak classification from the original EvoAug study using batch mode augmentations (i.e. insertion, deletion, and translocation only). As expected, models trained with EvoAug-TF augmentations in batch mode consistently led to improved performance (<xref rid="btae092-F1" ref-type="fig">Fig. 1f</xref>). We also explored the effectiveness of EvoAug-TF in the low data regime with the same batch mode augmentations. Strikingly, a DeepSTARR model trained with EvoAug-TF on only 25% of the training data yields better performance than the same DeepSTARR model trained on the whole dataset with standard training (<xref rid="btae092-F1" ref-type="fig">Fig. 1g</xref>). Thus, EvoAug-TF can greatly improve data efficiency when training genomic deep-learning models, and batch mode is an effective way to improve performance over standard training.</p>
    <p>In the original study, EvoAug-trained models were found to improve motif representations in attribution maps. To explore whether EvoAug-TF trained models also improve the interpretability of attribution maps, we generated Saliency Maps (<xref rid="btae092-B20" ref-type="bibr">Simonyan <italic toggle="yes">et al.</italic> 2013</xref>) for 500 sequences with the highest observed enhancer activity for the developmental promoter and a different set of 500 sequences for the housekeeping promoter in the DeepSTARR dataset. We then quantified the consistency of salient patterns across a population of attribution maps using the Kullback–Liebler Divergence (KLD) between the distribution of locally embedded attribution scores versus an uninformative prior, which is termed <italic toggle="yes">k</italic>-attr-mean metric (<xref rid="btae092-B17" ref-type="bibr">Majdandzic <italic toggle="yes">et al.</italic> 2022</xref>). A higher KLD suggests that the attribution scores reflect similar recurring patterns across the 500 attribution maps. Indeed, EvoAug-TF-trained DeepSTARR yielded significantly higher KLD scores than standard training (<xref rid="btae092-F1" ref-type="fig">Fig. 1h</xref>).</p>
    <p>Attribution methods are sensitive to local function properties and thus can yield spurious attribution scores for reasons that are not biological (<xref rid="btae092-B17" ref-type="bibr">Majdandzic <italic toggle="yes">et al.</italic> 2022</xref>). Similar to the robustness test for model predictions introduced in <xref rid="btae092-B22" ref-type="bibr">Toneyan <italic toggle="yes">et al.</italic> (2022)</xref>, we developed a translational robustness test to quantitatively assess the robustness of attribution scores to small shifts in the input sequence. The assumption is that when no significant attribution scores are present near the ends of the sequence, small shifts to the sequence should not affect the importance of binding sites. Hence, the attribution scores for the binding sites should also shift with the translations while maintaining the same importance levels. In the translational robustness test, the input sequence was randomly translated by up to 30 nt in either direction with <monospace>np.roll</monospace>, the [corrected (<xref rid="btae092-B18" ref-type="bibr">Majdandzic <italic toggle="yes">et al.</italic> 2023</xref>)] attribution scores were calculated for the translated sequence, and then the inverse translation was imposed on the attribution maps to align with the wild-type attribution map. This process was repeated 20 times for each sequence, which resulted in 20 translated attribution maps realigned to the input sequence. Next, a variation score was calculated using the root-mean-squared error to summarize the total variation across the aligned attribution maps with a scalar value. As expected, DeepSTARR trained with EvoAug-TF yields a significantly lower variability score compared to standard training for Saliency Maps (<xref rid="btae092-B20" ref-type="bibr">Simonyan <italic toggle="yes">et al.</italic> 2013</xref>), Integrated Gradients (<xref rid="btae092-B21" ref-type="bibr">Sundararajan <italic toggle="yes">et al.</italic> 2017</xref>), and DeepSHAP (<xref rid="btae092-B16" ref-type="bibr">Lundberg and Lee 2017)</xref> (<xref rid="btae092-F1" ref-type="fig">Fig. 1i</xref>). Thus, EvoAug-TF training has the benefit of resulting in more robust attribution maps for various attribution methods.</p>
    <p>Each augmentation has corresponding hyperparameters that can be tuned to optimize performance gains. Previously, EvoAug identified hyperparameters through a simple grid search, focusing on one augmentation at a time. The EvoAug-TF package provides examples that show how to integrate EvoAug-TF with comprehensive hyperparameter searches, such as population-based training (<xref rid="btae092-B8" ref-type="bibr">Jaderberg <italic toggle="yes">et al.</italic> 2017</xref>) and the asynchronous hyperband algorithm (<xref rid="btae092-B12" ref-type="bibr">Li <italic toggle="yes">et al.</italic> 2018</xref>) provided by Ray Tune (<xref rid="btae092-B13" ref-type="bibr">Liaw <italic toggle="yes">et al.</italic> 2018</xref>). These should offer an alternative strategy to help navigate the combinatoric search space of discovering optimal hyperparameters when deploying multiple augmentations.</p>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>EvoAug-TF is a TensorFlow implementation of EvoAug (a PyTorch package) that provides the ability to train genomic DNNs with evolution-inspired data augmentations. Our results demonstrate the effectiveness of EvoAug-TF to improve generalization and model interpretability with attribution methods. We found that models incorporating EvoAug-TF augmentations achieved comparable or improved performance with similar computational efficiency as the original EvoAug models in PyTorch. Similar to EvoAug, EvoAug-TF is extensible—it can easily accommodate new types of custom augmentations within its data augmentation framework. While the current implementation only supports model outputs as scalars in single- or multi-task settings, we plan to extend these capabilities for multivariate predictions in the future to provide data augmentations for quantitative models that output profiles of read coverages (<xref rid="btae092-B9" ref-type="bibr">Kelley <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae092-B4" ref-type="bibr">Avsec <italic toggle="yes">et al.</italic> 2021b</xref>, <xref rid="btae092-B22" ref-type="bibr">Toneyan <italic toggle="yes">et al.</italic> 2022</xref>). Overall, EvoAug-TF offers a new tool for TensorFlow users in the genomics research community to improve data efficiency in training genomic deep-learning models, leading to improved generalization and interpretability with attribution analysis.</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors would like to thank Ziqi (Amber) Tang and Chandana Rajesh for support in setting up Ray Tune, Jakub Kaczmarzyk for support in setting up ReadTheDocs documentation, and Anirban Sarkar and Alessandro Crnjar for support on the translational robustness test for attribution maps.</p>
  </ack>
  <sec>
    <title>Author contributions</title>
    <p>Y.Y. and P.K. conceived the experiments, Y.Y. developed EvoAug-TF, conducted the experiments, and analyzed the results. S.M. developed the attribution translational robustness test and performed the experiments that used the test. Y.Y., S.M., and P.K. wrote and reviewed the manuscript.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported in part by the National Institute Of General Medical Sciences of the National Institutes of Health [award number R01GM149921]; and the National Human Genome Research Institute of the National Institutes of Health [award number R01HG012131]. This work was performed with assistance from the US National Institutes of Health [grant number S10OD028632-01].</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btae092-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Abadi</surname><given-names>M</given-names></string-name>, <string-name><surname>Agarwal</surname><given-names>A</given-names></string-name>, <string-name><surname>Barham</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal><italic toggle="yes">TensorFlow: Large-scale Machine Learning on Heterogeneous Systems</italic>. In: <italic toggle="yes">Proceedings of the 12th USENIX conference on Operating Systems Design and Implementation, Savannah, GA, USA</italic>, <year>2016</year>, <fpage>265</fpage>–<lpage>283</lpage>.</mixed-citation>
    </ref>
    <ref id="btae092-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Arnold</surname><given-names>CD</given-names></string-name>, <string-name><surname>Gerlach</surname><given-names>D</given-names></string-name>, <string-name><surname>Stelzer</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>Genome-wide quantitative enhancer activity maps identified STARR-seq</article-title>. <source>Science</source><year>2013</year>;<volume>339</volume>:<fpage>1074</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">23328393</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Avsec</surname><given-names>Ž</given-names></string-name>, <string-name><surname>Agarwal</surname><given-names>V</given-names></string-name>, <string-name><surname>Visentin</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>Effective gene expression prediction from sequence by integrating long-range interactions</article-title>. <source>Nat Methods</source><year>2021a</year>;<volume>18</volume>:<fpage>1196</fpage>–<lpage>203</lpage>.<pub-id pub-id-type="pmid">34608324</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Avsec</surname><given-names>Ž</given-names></string-name>, <string-name><surname>Weilert</surname><given-names>M</given-names></string-name>, <string-name><surname>Shrikumar</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Base-resolution models of transcription-factor binding reveal soft motif syntax</article-title>. <source>Nat Genet</source><year>2021b</year>;<volume>53</volume>:<fpage>354</fpage>–<lpage>66</lpage>.<pub-id pub-id-type="pmid">33603233</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Almeida</surname><given-names>BP</given-names></string-name>, <string-name><surname>Reiter</surname><given-names>F</given-names></string-name>, <string-name><surname>Pagani</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>DeepSTARR predicts enhancer activity from DNA sequence and enables the de novo design of synthetic enhancers</article-title>. <source>Nat Genet</source><year>2022</year>;<volume>54</volume>:<fpage>613</fpage>–<lpage>24</lpage>.<pub-id pub-id-type="pmid">35551305</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B6">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Duncan</surname><given-names>AG</given-names></string-name>, <string-name><surname>Mitchell</surname><given-names>JA</given-names></string-name>, <string-name><surname>Moses</surname><given-names>AM.</given-names></string-name></person-group> Improving the performance of supervised deep learning for regulatory genomics using phylogenetic augmentation. bioRxiv, <year>2023</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eraslan</surname><given-names>G</given-names></string-name>, <string-name><surname>Avsec</surname><given-names>Ž</given-names></string-name>, <string-name><surname>Gagneur</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Deep learning: new computational modelling techniques for genomics</article-title>. <source>Nat Rev Genet</source><year>2019</year>;<volume>20</volume>:<fpage>389</fpage>–<lpage>403</lpage>.<pub-id pub-id-type="pmid">30971806</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jaderberg</surname><given-names>M</given-names></string-name>, <string-name><surname>Dalibard</surname><given-names>V</given-names></string-name>, <string-name><surname>Osindero</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal> Population based training of neural networks. arXiv, arXiv:1711.09846, <year>2017</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kelley</surname><given-names>DR</given-names></string-name>, <string-name><surname>Reshef</surname><given-names>YA</given-names></string-name>, <string-name><surname>Bileschi</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>Sequential regulatory activity prediction across chromosomes with convolutional neural networks</article-title>. <source>Genome Res</source><year>2018</year>;<volume>28</volume>:<fpage>739</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">29588361</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Koo</surname><given-names>PK</given-names></string-name>, <string-name><surname>Ploenzke</surname><given-names>M.</given-names></string-name></person-group><article-title>Deep learning for inferring transcription factor binding sites</article-title>. <source>Curr Opin Syst Biol</source><year>2020</year>;<volume>19</volume>:<fpage>16</fpage>–<lpage>23</lpage>.<pub-id pub-id-type="pmid">32905524</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>NK</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Toneyan</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>EvoAug: improving generalization and interpretability of genomic deep neural networks with evolution-inspired data augmentations</article-title>. <source>Genome Biol</source><year>2023</year>;<volume>24</volume>:<fpage>105</fpage>.<pub-id pub-id-type="pmid">37143118</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>L</given-names></string-name>, <string-name><surname>Jamieson</surname><given-names>K</given-names></string-name>, <string-name><surname>Rostamizadeh</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal> Massively parallel hyperparameter tuning. arXiv, arXiv:1810.05934, <year>2018</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Liaw</surname><given-names>R</given-names></string-name>, <string-name><surname>Liang</surname><given-names>E</given-names></string-name>, <string-name><surname>Nishihara</surname><given-names>R</given-names></string-name></person-group><etal>et al</etal> Tune: a research platform for distributed model selection and training. arXiv, arXiv:1807.05118, <year>2018</year>. preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lu</surname><given-names>AX</given-names></string-name>, <string-name><surname>Lu</surname><given-names>AX</given-names></string-name>, <string-name><surname>Pritišanac</surname><given-names>I</given-names></string-name></person-group><etal>et al</etal><article-title>Discovering molecular features of intrinsically disordered regions by using evolution for contrastive learning</article-title>. <source>PLoS Comput Biol</source><year>2022</year>;<volume>18</volume>:<fpage>e1010238</fpage>.<pub-id pub-id-type="pmid">35767567</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lu</surname><given-names>AX</given-names></string-name>, <string-name><surname>Lu</surname><given-names>AX</given-names></string-name>, <string-name><surname>Moses</surname><given-names>A.</given-names></string-name></person-group> Evolution is all you need: phylogenetic augmentation for contrastive learning. arXiv, arXiv:2012.13475, <year>2020</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lundberg</surname><given-names>SM</given-names></string-name>, <string-name><surname>Lee</surname><given-names>S-I.</given-names></string-name></person-group> A unified approach to interpreting model predictions. In: <italic toggle="yes">Proceedings of the 31st International Conference on Neural Information Processing Systems, Long Beach, CA, USA</italic>, Vol. <volume>30</volume>. <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="btae092-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Majdandzic</surname><given-names>A</given-names></string-name>, <string-name><surname>Rajesh</surname><given-names>C</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal> Selecting deep neural networks that yield consistent attribution-based interpretations for genomics. <italic toggle="yes">Proc Mach Learn Res</italic><year>2022</year>;<volume>200</volume>:<fpage>131</fpage>–<lpage>49</lpage>.</mixed-citation>
    </ref>
    <ref id="btae092-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Majdandzic</surname><given-names>A</given-names></string-name>, <string-name><surname>Rajesh</surname><given-names>C</given-names></string-name>, <string-name><surname>Koo</surname><given-names>PK.</given-names></string-name></person-group><article-title>Correcting gradient-based interpretations of deep neural networks for genomics</article-title>. <source>Genome Biol</source><year>2023</year>;<volume>24</volume>:<fpage>109</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">37161475</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Paszke</surname><given-names>A</given-names></string-name>, <string-name><surname>Gross</surname><given-names>S</given-names></string-name>, <string-name><surname>Massa</surname><given-names>F</given-names></string-name></person-group><etal>et al</etal> Pytorch: an imperative style, high-performance deep learning library. In: <italic toggle="yes">Proceedings of the 33rd International Conference on Neural Information Processing Systems, Vancouver, BC, Canada</italic>, Vol. 721. <year>2019</year>, <fpage>8024</fpage>–<lpage>35</lpage>.</mixed-citation>
    </ref>
    <ref id="btae092-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Simonyan</surname><given-names>K</given-names></string-name>, <string-name><surname>Vedaldi</surname><given-names>A</given-names></string-name>, <string-name><surname>Zisserman</surname><given-names>A.</given-names></string-name></person-group> Deep inside convolutional networks: visualising image classification models and saliency maps. arXiv, arXiv:1312.6034, <year>2013</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B21">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Sundararajan</surname><given-names>M</given-names></string-name>, <string-name><surname>Taly</surname><given-names>A</given-names></string-name>, <string-name><surname>Yan</surname><given-names>Q.</given-names></string-name></person-group> Axiomatic attribution for deep networks. In: <italic toggle="yes">Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia</italic>. <fpage>3319</fpage>–<lpage>28</lpage>. <publisher-name>PMLR</publisher-name>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="btae092-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Toneyan</surname><given-names>S</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Koo</surname><given-names>PK.</given-names></string-name></person-group><article-title>Evaluating deep learning for predicting epigenomic profiles</article-title>. <source>Nat Mach Intell</source><year>2022</year>;<volume>4</volume>:<fpage>1088</fpage>–<lpage>100</lpage>.<pub-id pub-id-type="pmid">37324054</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>C</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>S</given-names></string-name>, <string-name><surname>Hardt</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>Understanding deep learning (still) requires rethinking generalization</article-title>. <source>Commun ACM</source><year>2021</year>;<volume>64</volume>:<fpage>107</fpage>–<lpage>15</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10918628</article-id>
    <article-id pub-id-type="pmid">38366935</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btae092</article-id>
    <article-id pub-id-type="publisher-id">btae092</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Note</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>EvoAug-TF: extending evolution-inspired data augmentations for genomic deep learning to TensorFlow</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0009-0001-2925-1909</contrib-id>
        <name>
          <surname>Yu</surname>
          <given-names>Yiyang</given-names>
        </name>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization" degree-contribution="supporting">Conceptualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation" degree-contribution="equal">Data curation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="lead">Formal analysis</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="lead">Investigation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology" degree-contribution="lead">Methodology</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software" degree-contribution="lead">Software</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation" degree-contribution="equal">Validation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization" degree-contribution="equal">Visualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="lead">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="supporting">Writing - review &amp; editing</role>
        <aff><institution>Simons Center for Quantitative Biology, Cold Spring Harbor Laboratory</institution>, Cold Spring Harbor, NY 11724, <country country="US">United States</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Muthukumar</surname>
          <given-names>Shivani</given-names>
        </name>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="supporting">Formal analysis</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="supporting">Writing - review &amp; editing</role>
        <aff><institution>Commack High School</institution>, Commack, NY 11725, <country country="US">United States</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-8722-0038</contrib-id>
        <name>
          <surname>Koo</surname>
          <given-names>Peter K</given-names>
        </name>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization" degree-contribution="lead">Conceptualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation" degree-contribution="equal">Data curation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="supporting">Formal analysis</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition" degree-contribution="lead">Funding acquisition</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="supporting">Investigation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology" degree-contribution="supporting">Methodology</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration" degree-contribution="lead">Project administration</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources" degree-contribution="lead">Resources</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software" degree-contribution="supporting">Software</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision" degree-contribution="lead">Supervision</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation" degree-contribution="supporting">Validation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization" degree-contribution="supporting">Visualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="supporting">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="lead">Writing - review &amp; editing</role>
        <aff><institution>Simons Center for Quantitative Biology, Cold Spring Harbor Laboratory</institution>, Cold Spring Harbor, NY 11724, <country country="US">United States</country></aff>
        <xref rid="btae092-cor1" ref-type="corresp"/>
        <!--koo@cshl.edu-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btae092-cor1">Corresponding author. Simons Center for Quantitative Biology, Cold Spring Harbor Laboratory, 1 Bungtown Rd, Cold Spring Harbor, NY 11724, United States. E-mail: <email>koo@cshl.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2024-02-16">
      <day>16</day>
      <month>2</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>16</day>
      <month>2</month>
      <year>2024</year>
    </pub-date>
    <volume>40</volume>
    <issue>3</issue>
    <elocation-id>btae092</elocation-id>
    <history>
      <date date-type="received">
        <day>15</day>
        <month>7</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>01</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="editorial-decision">
        <day>09</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="corrected-typeset">
        <day>06</day>
        <month>3</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2024</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btae092.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Summary</title>
        <p>Deep neural networks (DNNs) have been widely applied to predict the molecular functions of the non-coding genome. DNNs are data hungry and thus require many training examples to fit data well. However, functional genomics experiments typically generate limited amounts of data, constrained by the activity levels of the molecular function under study inside the cell. Recently, EvoAug was introduced to train a genomic DNN with evolution-inspired augmentations. EvoAug-trained DNNs have demonstrated improved generalization and interpretability with attribution analysis. However, EvoAug only supports PyTorch-based models, which limits its applications to a broad class of genomic DNNs based in TensorFlow. Here, we extend EvoAug’s functionality to TensorFlow in a new package, we call EvoAug-TF. Through a systematic benchmark, we find that EvoAug-TF yields comparable performance with the original EvoAug package.</p>
      </sec>
      <sec id="s2">
        <title>Availability and implementation</title>
        <p>EvoAug-TF is freely available for users and is distributed under an open-source MIT license. Researchers can access the open-source code on GitHub (<ext-link xlink:href="https://github.com/p-koo/evoaug-tf" ext-link-type="uri">https://github.com/p-koo/evoaug-tf</ext-link>). The pre-compiled package is provided via PyPI (<ext-link xlink:href="https://pypi.org/project/evoaug-tf" ext-link-type="uri">https://pypi.org/project/evoaug-tf</ext-link>) with in-depth documentation on ReadTheDocs (<ext-link xlink:href="https://evoaug-tf.readthedocs.io" ext-link-type="uri">https://evoaug-tf.readthedocs.io</ext-link>). The scripts for reproducing the results are available at (<ext-link xlink:href="https://github.com/p-koo/evoaug-tf_analysis" ext-link-type="uri">https://github.com/p-koo/evoaug-tf_analysis</ext-link>).</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of General Medical Sciences</institution>
            <institution-id institution-id-type="DOI">10.13039/100000057</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R01GM149921</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Human Genome Research Institute of the National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01HG012131</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>US National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>S10OD028632-01</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="4"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Deep neural networks (DNNs) have emerged as a promising tool for supervised learning of regulatory genomics data, taking DNA sequences as input and predicting the readouts of functional genomics experiments (<xref rid="btae092-B7" ref-type="bibr">Eraslan <italic toggle="yes">et al.</italic> 2019</xref>, <xref rid="btae092-B10" ref-type="bibr">Koo and Ploenzke 2020</xref>). Due to their overparameterization, DNNs are data hungry, requiring large amounts of data to learn discriminative features that ensure good generalization (<xref rid="btae092-B23" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2021</xref>). However, most functional genomics experiments only observe a limited number of molecular interactions within the context of a cell. For instance, the number of binding sites available for a transcription factor can be limited to the finite number of accessible DNA within a given cell type. Hence, dataset size is a major limiting factor when analyzing functional genomics data with DNNs.</p>
    <p>Data augmentation is a widely practiced strategy in machine learning to provide additional training samples. In practice, random transformations that maintain the same training labels are imposed on the input data, leveraging the natural symmetries in the data. For example, in natural images, the objects can undergo affine transformations, flips, color perturbations, and blurs, which do not alter the object’s label. In genomics, the available transformations that can maintain the same training labels are limited to reverse complements and small random shifts (<xref rid="btae092-B3" ref-type="bibr">Avsec <italic toggle="yes">et al.</italic> 2021a</xref>, <xref rid="btae092-B22" ref-type="bibr">Toneyan <italic toggle="yes">et al.</italic> 2022</xref>).</p>
    <p>To expand the available augmentations, EvoAug (Lee <italic toggle="yes">et al.</italic> 2023) was recently introduced to provide evolution-inspired data augmentations, including translocations, insertions, deletions, inversions, and mutations. In nature, genetic variation is sampled by evolution to increase phenotypic diversity. Thus, genetic mutations can alter the function of the sequence and, hence, change its label. Nevertheless, EvoAug asserts that the transformed sequences retain the same training label as the wild-type sequence, which can be considered as imposing a prior. For instance, small random translocations impose a prior that the activity of motifs is invariant to shifts. Moreover, insertions and deletions impose a prior that the distance between motifs is insignificant. Considered as a prior, evolution-inspired augmentations can introduce a bias in the DNN that may break the underlying rules of <italic toggle="yes">cis</italic>-regulatory grammars in the data. Thus, EvoAug employs a second stage of training that finetunes the DNN on the original, unaltered data, ensuring functional integrity toward the observed biology. This two-stage training curriculum has proven beneficial for genomic DNNs using synthetic data augmentations (Lee <italic toggle="yes">et al.</italic> 2023) and natural data augmentations (<xref rid="btae092-B6" ref-type="bibr">Duncan <italic toggle="yes">et al.</italic> 2023</xref>), as well as for protein-based DNNs (<xref rid="btae092-B15" ref-type="bibr">Lu <italic toggle="yes">et al.</italic> 2020</xref>, <xref rid="btae092-B14" ref-type="bibr">2022</xref>).</p>
    <p>However, the availability of EvoAug has been limited to a PyTorch (<xref rid="btae092-B19" ref-type="bibr">Paszke <italic toggle="yes">et al.</italic> 2019</xref>) implementation, posing a barrier for researchers working in TensorFlow (<xref rid="btae092-B1" ref-type="bibr">Abadi <italic toggle="yes">et al.</italic> 2016</xref>). To address this demand, we present <monospace>EvoAug-TF</monospace>, a TensorFlow implementation that builds upon the same principles as EvoAug. Below, we describe EvoAug-TF, highlighting its adaptations and unique features that are specific to the TensorFlow framework. Additionally, we present experimental results showcasing the effectiveness of EvoAug-TF in improving the generalization capabilities of genomic DNNs.</p>
  </sec>
  <sec>
    <title>2 Methodology and implementation</title>
    <p>EvoAug-TF adapts the functionality of the PyTorch-based EvoAug framework in TensorFlow (<xref rid="btae092-F1" ref-type="fig">Fig. 1a</xref>), including the augmentation techniques (e.g. random transversion, insertion, translocation, deletion, mutation, and noise). EvoAug-TF employs the same two-stage training curriculum, where stochastic augmentations are applied online to each mini-batch during training, followed by a finetuning step on the original, unperturbed data. Since EvoAug-TF imposes transformations on the input data while maintaining the same labels as the wild-type sequence, in its current form, EvoAug-TF only supports DNNs that output scalars in single-task or multi-task settings. In contrast, profile-based DNNs (<xref rid="btae092-B9" ref-type="bibr">Kelley <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae092-B4" ref-type="bibr">Avsec <italic toggle="yes">et al.</italic> 2021b</xref>, <xref rid="btae092-B22" ref-type="bibr">Toneyan <italic toggle="yes">et al.</italic> 2022</xref>) may require transformations to the corresponding labels, which is currently not supported in EvoAug-TF.</p>
    <fig position="float" id="btae092-F1">
      <label>Figure 1.</label>
      <caption>
        <p>Performance comparison between EvoAug and standard training. (a) Flowchart illustrating EvoAug-TF’s two-stage training curriculum. (b) Schematic demonstrating the difference between sequence mode and batch mode, where each column represents a mini-batch of sequences and different colors represent different data augmentations. (c, d) Performance comparison between EvoAug (PyTorch-based) and EvoAug-TF (TensorFlow-based) with DeepSTARR models trained with individual or combinations of augmentations (i.e. insertion + translocation + deletion; all augmentations) and finetuned on original STARR-seq data for two promoters: developmental (c) and housekeeping (d). (e) Comparison of the training time per epoch between EvoAug (PyTorch) and EvoAug-TF (TensorFlow). (c–e) Each scatter plot includes the data from five trials with random initialization. (f) Box-plots comparing the performance (area under the receiver operating characteristic curve) of a convolutional neural network trained with standard training, EvoAug-TF augmentations, and with finetuning on various Chip-seq peak classification tasks. (g) Performance comparison of DeepSTARR models with various training methods fit to training sets with varying levels of down-sampling. EvoAug-TF augmentations employed insertion + translocation + deletion in batch mode. The shaded region represents the SD of the mean across five models with different random initializations. (h) Box-plot comparison of the consistency of patterns within Saliency Maps, as measured by the <italic toggle="yes">k</italic>-attr-mean, for DeepSTARR models with standard training or EvoAug-TF augmentations (All). (i) Box-plot comparison of the attribution variation score, calculated according to the root-mean-squared attribution scores, for attribution maps generated by different methods (i.e. Saliency Maps, Integrated Gradients, and DeepSHAP) using a DeepSTARR model trained with standard training or EvoAug-TF augmentations (All). (h, i) Mann–Whitney <italic toggle="yes">U</italic>-test with <italic toggle="yes">P</italic>-values &lt;.001 (***) and .01 (**). Boxes represent five identical models with different random initializations.</p>
      </caption>
      <graphic xlink:href="btae092f1" position="float"/>
    </fig>
    <p>Several adaptations were made to EvoAug-TF compared to the PyTorch implementation, incorporating key design choices specific to the TensorFlow version. To ensure compatibility with TensorFlow’s graph mode and optimize training speed, <monospace>tf</monospace>. <monospace>Tensors</monospace> are used as substitutes for NumPy arrays, which were utilized in the PyTorch implementation. Additionally, EvoAug-TF employs <monospace>tf.while_loop</monospace> to achieve the same effects as the for loops used in the PyTorch implementation. The implementation of EvoAug-TF relies on TensorFlow 2 and its relevant libraries and dependencies; it has been tested thoroughly on versions 2.7 and 2.15.</p>
    <p>A key difference between EvoAug-TF and EvoAug lies in the approach to applying augmentations to the mini-batch during training. In the PyTorch implementation, the number of augmentations and the augmentation type are randomly chosen for each sequence. In the TensorFlow implementation, the same number of augmentations and augmentation types are employed for each sequence. However, the selected augmentation type(s) are sampled in a stochastic manner to impose a unique perturbation to each sequence in the mini-batch, similar to EvoAug. This design choice was made to simplify the process of imposing augmentations, while still sampling a high degree of genetic variation. Moreover, for some augmentations—such as translocation, insertion, deletion, and transversion (i.e. reverse-complement)—we offer an additional option to perform the same perturbation across all of the sequences within the mini-batch (<xref rid="btae092-F1" ref-type="fig">Fig. 1b</xref>), which we term batch mode. This feature provides a faster way to deploy augmentations, improving computational efficiency at the expense of sampling diversity.</p>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <p>To benchmark the performance of EvoAug-TF, we utilized the data and deep-learning model from the DeepSTARR study (<xref rid="btae092-B5" ref-type="bibr">de Almeida <italic toggle="yes">et al.</italic> 2022</xref>). The prediction task is set up to take as input 249-nt sequences and predict enhancer activity [measured via STARR-seq (<xref rid="btae092-B2" ref-type="bibr">Arnold <italic toggle="yes">et al.</italic> 2013</xref>)] for developmental and housekeeping transcriptional promoters in <italic toggle="yes">Drosophila melanogaster</italic> S2 cells as a multi-task regression. We systematically trained the DeepSTARR model with different EvoAug-TF augmentations individually and in combinations and compared their performance with the original EvoAug, using the same hyperparameters as in the original study (Lee <italic toggle="yes">et al.</italic> 2023). To ensure the robustness of the results, we conducted five trials for each set of augmentations with different random initializations.</p>
    <p>We found that models trained with EvoAug-TF augmentations achieved comparable performance to the original EvoAug-trained models with the same augmentation settings (<xref rid="btae092-F1" ref-type="fig">Fig. 1c and d</xref>). Notably, EvoAug-TF consistently yielded improved performance compared to the original EvoAug after Stage 1 (i.e. before finetuning) with the exception of random noise augmentation. However, the original EvoAug yielded slightly better performance than EvoAug-TF upon finetuning. In most cases, models trained with data augmentations led to improved performance compared to standard training.</p>
    <p>In terms of computational costs, we found that running EvoAug-TF exhibited similar training times per epoch as EvoAug (<xref rid="btae092-F1" ref-type="fig">Fig. 1e</xref>). Thus, EvoAug-TF’s approach of applying the same numbers and types of augmentations to each sequence maintains a comparable computational cost as EvoAug’s approach of applying different numbers and types of augmentations to each sequence. Notably, both approaches are effective in improving model performance.</p>
    <p>To further demonstrate the breadth of the EvoAug-TF package, we explored the use of batch mode augmentations. First, we trained convolutional neural networks on ChIP-seq peak classification from the original EvoAug study using batch mode augmentations (i.e. insertion, deletion, and translocation only). As expected, models trained with EvoAug-TF augmentations in batch mode consistently led to improved performance (<xref rid="btae092-F1" ref-type="fig">Fig. 1f</xref>). We also explored the effectiveness of EvoAug-TF in the low data regime with the same batch mode augmentations. Strikingly, a DeepSTARR model trained with EvoAug-TF on only 25% of the training data yields better performance than the same DeepSTARR model trained on the whole dataset with standard training (<xref rid="btae092-F1" ref-type="fig">Fig. 1g</xref>). Thus, EvoAug-TF can greatly improve data efficiency when training genomic deep-learning models, and batch mode is an effective way to improve performance over standard training.</p>
    <p>In the original study, EvoAug-trained models were found to improve motif representations in attribution maps. To explore whether EvoAug-TF trained models also improve the interpretability of attribution maps, we generated Saliency Maps (<xref rid="btae092-B20" ref-type="bibr">Simonyan <italic toggle="yes">et al.</italic> 2013</xref>) for 500 sequences with the highest observed enhancer activity for the developmental promoter and a different set of 500 sequences for the housekeeping promoter in the DeepSTARR dataset. We then quantified the consistency of salient patterns across a population of attribution maps using the Kullback–Liebler Divergence (KLD) between the distribution of locally embedded attribution scores versus an uninformative prior, which is termed <italic toggle="yes">k</italic>-attr-mean metric (<xref rid="btae092-B17" ref-type="bibr">Majdandzic <italic toggle="yes">et al.</italic> 2022</xref>). A higher KLD suggests that the attribution scores reflect similar recurring patterns across the 500 attribution maps. Indeed, EvoAug-TF-trained DeepSTARR yielded significantly higher KLD scores than standard training (<xref rid="btae092-F1" ref-type="fig">Fig. 1h</xref>).</p>
    <p>Attribution methods are sensitive to local function properties and thus can yield spurious attribution scores for reasons that are not biological (<xref rid="btae092-B17" ref-type="bibr">Majdandzic <italic toggle="yes">et al.</italic> 2022</xref>). Similar to the robustness test for model predictions introduced in <xref rid="btae092-B22" ref-type="bibr">Toneyan <italic toggle="yes">et al.</italic> (2022)</xref>, we developed a translational robustness test to quantitatively assess the robustness of attribution scores to small shifts in the input sequence. The assumption is that when no significant attribution scores are present near the ends of the sequence, small shifts to the sequence should not affect the importance of binding sites. Hence, the attribution scores for the binding sites should also shift with the translations while maintaining the same importance levels. In the translational robustness test, the input sequence was randomly translated by up to 30 nt in either direction with <monospace>np.roll</monospace>, the [corrected (<xref rid="btae092-B18" ref-type="bibr">Majdandzic <italic toggle="yes">et al.</italic> 2023</xref>)] attribution scores were calculated for the translated sequence, and then the inverse translation was imposed on the attribution maps to align with the wild-type attribution map. This process was repeated 20 times for each sequence, which resulted in 20 translated attribution maps realigned to the input sequence. Next, a variation score was calculated using the root-mean-squared error to summarize the total variation across the aligned attribution maps with a scalar value. As expected, DeepSTARR trained with EvoAug-TF yields a significantly lower variability score compared to standard training for Saliency Maps (<xref rid="btae092-B20" ref-type="bibr">Simonyan <italic toggle="yes">et al.</italic> 2013</xref>), Integrated Gradients (<xref rid="btae092-B21" ref-type="bibr">Sundararajan <italic toggle="yes">et al.</italic> 2017</xref>), and DeepSHAP (<xref rid="btae092-B16" ref-type="bibr">Lundberg and Lee 2017)</xref> (<xref rid="btae092-F1" ref-type="fig">Fig. 1i</xref>). Thus, EvoAug-TF training has the benefit of resulting in more robust attribution maps for various attribution methods.</p>
    <p>Each augmentation has corresponding hyperparameters that can be tuned to optimize performance gains. Previously, EvoAug identified hyperparameters through a simple grid search, focusing on one augmentation at a time. The EvoAug-TF package provides examples that show how to integrate EvoAug-TF with comprehensive hyperparameter searches, such as population-based training (<xref rid="btae092-B8" ref-type="bibr">Jaderberg <italic toggle="yes">et al.</italic> 2017</xref>) and the asynchronous hyperband algorithm (<xref rid="btae092-B12" ref-type="bibr">Li <italic toggle="yes">et al.</italic> 2018</xref>) provided by Ray Tune (<xref rid="btae092-B13" ref-type="bibr">Liaw <italic toggle="yes">et al.</italic> 2018</xref>). These should offer an alternative strategy to help navigate the combinatoric search space of discovering optimal hyperparameters when deploying multiple augmentations.</p>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>EvoAug-TF is a TensorFlow implementation of EvoAug (a PyTorch package) that provides the ability to train genomic DNNs with evolution-inspired data augmentations. Our results demonstrate the effectiveness of EvoAug-TF to improve generalization and model interpretability with attribution methods. We found that models incorporating EvoAug-TF augmentations achieved comparable or improved performance with similar computational efficiency as the original EvoAug models in PyTorch. Similar to EvoAug, EvoAug-TF is extensible—it can easily accommodate new types of custom augmentations within its data augmentation framework. While the current implementation only supports model outputs as scalars in single- or multi-task settings, we plan to extend these capabilities for multivariate predictions in the future to provide data augmentations for quantitative models that output profiles of read coverages (<xref rid="btae092-B9" ref-type="bibr">Kelley <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae092-B4" ref-type="bibr">Avsec <italic toggle="yes">et al.</italic> 2021b</xref>, <xref rid="btae092-B22" ref-type="bibr">Toneyan <italic toggle="yes">et al.</italic> 2022</xref>). Overall, EvoAug-TF offers a new tool for TensorFlow users in the genomics research community to improve data efficiency in training genomic deep-learning models, leading to improved generalization and interpretability with attribution analysis.</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors would like to thank Ziqi (Amber) Tang and Chandana Rajesh for support in setting up Ray Tune, Jakub Kaczmarzyk for support in setting up ReadTheDocs documentation, and Anirban Sarkar and Alessandro Crnjar for support on the translational robustness test for attribution maps.</p>
  </ack>
  <sec>
    <title>Author contributions</title>
    <p>Y.Y. and P.K. conceived the experiments, Y.Y. developed EvoAug-TF, conducted the experiments, and analyzed the results. S.M. developed the attribution translational robustness test and performed the experiments that used the test. Y.Y., S.M., and P.K. wrote and reviewed the manuscript.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported in part by the National Institute Of General Medical Sciences of the National Institutes of Health [award number R01GM149921]; and the National Human Genome Research Institute of the National Institutes of Health [award number R01HG012131]. This work was performed with assistance from the US National Institutes of Health [grant number S10OD028632-01].</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btae092-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Abadi</surname><given-names>M</given-names></string-name>, <string-name><surname>Agarwal</surname><given-names>A</given-names></string-name>, <string-name><surname>Barham</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal><italic toggle="yes">TensorFlow: Large-scale Machine Learning on Heterogeneous Systems</italic>. In: <italic toggle="yes">Proceedings of the 12th USENIX conference on Operating Systems Design and Implementation, Savannah, GA, USA</italic>, <year>2016</year>, <fpage>265</fpage>–<lpage>283</lpage>.</mixed-citation>
    </ref>
    <ref id="btae092-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Arnold</surname><given-names>CD</given-names></string-name>, <string-name><surname>Gerlach</surname><given-names>D</given-names></string-name>, <string-name><surname>Stelzer</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>Genome-wide quantitative enhancer activity maps identified STARR-seq</article-title>. <source>Science</source><year>2013</year>;<volume>339</volume>:<fpage>1074</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">23328393</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Avsec</surname><given-names>Ž</given-names></string-name>, <string-name><surname>Agarwal</surname><given-names>V</given-names></string-name>, <string-name><surname>Visentin</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>Effective gene expression prediction from sequence by integrating long-range interactions</article-title>. <source>Nat Methods</source><year>2021a</year>;<volume>18</volume>:<fpage>1196</fpage>–<lpage>203</lpage>.<pub-id pub-id-type="pmid">34608324</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Avsec</surname><given-names>Ž</given-names></string-name>, <string-name><surname>Weilert</surname><given-names>M</given-names></string-name>, <string-name><surname>Shrikumar</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Base-resolution models of transcription-factor binding reveal soft motif syntax</article-title>. <source>Nat Genet</source><year>2021b</year>;<volume>53</volume>:<fpage>354</fpage>–<lpage>66</lpage>.<pub-id pub-id-type="pmid">33603233</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Almeida</surname><given-names>BP</given-names></string-name>, <string-name><surname>Reiter</surname><given-names>F</given-names></string-name>, <string-name><surname>Pagani</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>DeepSTARR predicts enhancer activity from DNA sequence and enables the de novo design of synthetic enhancers</article-title>. <source>Nat Genet</source><year>2022</year>;<volume>54</volume>:<fpage>613</fpage>–<lpage>24</lpage>.<pub-id pub-id-type="pmid">35551305</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B6">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Duncan</surname><given-names>AG</given-names></string-name>, <string-name><surname>Mitchell</surname><given-names>JA</given-names></string-name>, <string-name><surname>Moses</surname><given-names>AM.</given-names></string-name></person-group> Improving the performance of supervised deep learning for regulatory genomics using phylogenetic augmentation. bioRxiv, <year>2023</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eraslan</surname><given-names>G</given-names></string-name>, <string-name><surname>Avsec</surname><given-names>Ž</given-names></string-name>, <string-name><surname>Gagneur</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Deep learning: new computational modelling techniques for genomics</article-title>. <source>Nat Rev Genet</source><year>2019</year>;<volume>20</volume>:<fpage>389</fpage>–<lpage>403</lpage>.<pub-id pub-id-type="pmid">30971806</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jaderberg</surname><given-names>M</given-names></string-name>, <string-name><surname>Dalibard</surname><given-names>V</given-names></string-name>, <string-name><surname>Osindero</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal> Population based training of neural networks. arXiv, arXiv:1711.09846, <year>2017</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kelley</surname><given-names>DR</given-names></string-name>, <string-name><surname>Reshef</surname><given-names>YA</given-names></string-name>, <string-name><surname>Bileschi</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>Sequential regulatory activity prediction across chromosomes with convolutional neural networks</article-title>. <source>Genome Res</source><year>2018</year>;<volume>28</volume>:<fpage>739</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">29588361</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Koo</surname><given-names>PK</given-names></string-name>, <string-name><surname>Ploenzke</surname><given-names>M.</given-names></string-name></person-group><article-title>Deep learning for inferring transcription factor binding sites</article-title>. <source>Curr Opin Syst Biol</source><year>2020</year>;<volume>19</volume>:<fpage>16</fpage>–<lpage>23</lpage>.<pub-id pub-id-type="pmid">32905524</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>NK</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Toneyan</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>EvoAug: improving generalization and interpretability of genomic deep neural networks with evolution-inspired data augmentations</article-title>. <source>Genome Biol</source><year>2023</year>;<volume>24</volume>:<fpage>105</fpage>.<pub-id pub-id-type="pmid">37143118</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>L</given-names></string-name>, <string-name><surname>Jamieson</surname><given-names>K</given-names></string-name>, <string-name><surname>Rostamizadeh</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal> Massively parallel hyperparameter tuning. arXiv, arXiv:1810.05934, <year>2018</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Liaw</surname><given-names>R</given-names></string-name>, <string-name><surname>Liang</surname><given-names>E</given-names></string-name>, <string-name><surname>Nishihara</surname><given-names>R</given-names></string-name></person-group><etal>et al</etal> Tune: a research platform for distributed model selection and training. arXiv, arXiv:1807.05118, <year>2018</year>. preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lu</surname><given-names>AX</given-names></string-name>, <string-name><surname>Lu</surname><given-names>AX</given-names></string-name>, <string-name><surname>Pritišanac</surname><given-names>I</given-names></string-name></person-group><etal>et al</etal><article-title>Discovering molecular features of intrinsically disordered regions by using evolution for contrastive learning</article-title>. <source>PLoS Comput Biol</source><year>2022</year>;<volume>18</volume>:<fpage>e1010238</fpage>.<pub-id pub-id-type="pmid">35767567</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lu</surname><given-names>AX</given-names></string-name>, <string-name><surname>Lu</surname><given-names>AX</given-names></string-name>, <string-name><surname>Moses</surname><given-names>A.</given-names></string-name></person-group> Evolution is all you need: phylogenetic augmentation for contrastive learning. arXiv, arXiv:2012.13475, <year>2020</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lundberg</surname><given-names>SM</given-names></string-name>, <string-name><surname>Lee</surname><given-names>S-I.</given-names></string-name></person-group> A unified approach to interpreting model predictions. In: <italic toggle="yes">Proceedings of the 31st International Conference on Neural Information Processing Systems, Long Beach, CA, USA</italic>, Vol. <volume>30</volume>. <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="btae092-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Majdandzic</surname><given-names>A</given-names></string-name>, <string-name><surname>Rajesh</surname><given-names>C</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal> Selecting deep neural networks that yield consistent attribution-based interpretations for genomics. <italic toggle="yes">Proc Mach Learn Res</italic><year>2022</year>;<volume>200</volume>:<fpage>131</fpage>–<lpage>49</lpage>.</mixed-citation>
    </ref>
    <ref id="btae092-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Majdandzic</surname><given-names>A</given-names></string-name>, <string-name><surname>Rajesh</surname><given-names>C</given-names></string-name>, <string-name><surname>Koo</surname><given-names>PK.</given-names></string-name></person-group><article-title>Correcting gradient-based interpretations of deep neural networks for genomics</article-title>. <source>Genome Biol</source><year>2023</year>;<volume>24</volume>:<fpage>109</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">37161475</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Paszke</surname><given-names>A</given-names></string-name>, <string-name><surname>Gross</surname><given-names>S</given-names></string-name>, <string-name><surname>Massa</surname><given-names>F</given-names></string-name></person-group><etal>et al</etal> Pytorch: an imperative style, high-performance deep learning library. In: <italic toggle="yes">Proceedings of the 33rd International Conference on Neural Information Processing Systems, Vancouver, BC, Canada</italic>, Vol. 721. <year>2019</year>, <fpage>8024</fpage>–<lpage>35</lpage>.</mixed-citation>
    </ref>
    <ref id="btae092-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Simonyan</surname><given-names>K</given-names></string-name>, <string-name><surname>Vedaldi</surname><given-names>A</given-names></string-name>, <string-name><surname>Zisserman</surname><given-names>A.</given-names></string-name></person-group> Deep inside convolutional networks: visualising image classification models and saliency maps. arXiv, arXiv:1312.6034, <year>2013</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B21">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Sundararajan</surname><given-names>M</given-names></string-name>, <string-name><surname>Taly</surname><given-names>A</given-names></string-name>, <string-name><surname>Yan</surname><given-names>Q.</given-names></string-name></person-group> Axiomatic attribution for deep networks. In: <italic toggle="yes">Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia</italic>. <fpage>3319</fpage>–<lpage>28</lpage>. <publisher-name>PMLR</publisher-name>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="btae092-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Toneyan</surname><given-names>S</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Koo</surname><given-names>PK.</given-names></string-name></person-group><article-title>Evaluating deep learning for predicting epigenomic profiles</article-title>. <source>Nat Mach Intell</source><year>2022</year>;<volume>4</volume>:<fpage>1088</fpage>–<lpage>100</lpage>.<pub-id pub-id-type="pmid">37324054</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>C</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>S</given-names></string-name>, <string-name><surname>Hardt</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>Understanding deep learning (still) requires rethinking generalization</article-title>. <source>Commun ACM</source><year>2021</year>;<volume>64</volume>:<fpage>107</fpage>–<lpage>15</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10918628</article-id>
    <article-id pub-id-type="pmid">38366935</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btae092</article-id>
    <article-id pub-id-type="publisher-id">btae092</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Note</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>EvoAug-TF: extending evolution-inspired data augmentations for genomic deep learning to TensorFlow</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0009-0001-2925-1909</contrib-id>
        <name>
          <surname>Yu</surname>
          <given-names>Yiyang</given-names>
        </name>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization" degree-contribution="supporting">Conceptualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation" degree-contribution="equal">Data curation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="lead">Formal analysis</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="lead">Investigation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology" degree-contribution="lead">Methodology</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software" degree-contribution="lead">Software</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation" degree-contribution="equal">Validation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization" degree-contribution="equal">Visualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="lead">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="supporting">Writing - review &amp; editing</role>
        <aff><institution>Simons Center for Quantitative Biology, Cold Spring Harbor Laboratory</institution>, Cold Spring Harbor, NY 11724, <country country="US">United States</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Muthukumar</surname>
          <given-names>Shivani</given-names>
        </name>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="supporting">Formal analysis</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="supporting">Writing - review &amp; editing</role>
        <aff><institution>Commack High School</institution>, Commack, NY 11725, <country country="US">United States</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-8722-0038</contrib-id>
        <name>
          <surname>Koo</surname>
          <given-names>Peter K</given-names>
        </name>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization" degree-contribution="lead">Conceptualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="https://credit.niso.org/contributor-roles/data-curation" degree-contribution="equal">Data curation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="supporting">Formal analysis</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition" degree-contribution="lead">Funding acquisition</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="supporting">Investigation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology" degree-contribution="supporting">Methodology</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Project administration" vocab-term-identifier="https://credit.niso.org/contributor-roles/project-administration" degree-contribution="lead">Project administration</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Resources" vocab-term-identifier="https://credit.niso.org/contributor-roles/resources" degree-contribution="lead">Resources</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Software" vocab-term-identifier="https://credit.niso.org/contributor-roles/software" degree-contribution="supporting">Software</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision" degree-contribution="lead">Supervision</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation" degree-contribution="supporting">Validation</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization" degree-contribution="supporting">Visualization</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="supporting">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="lead">Writing - review &amp; editing</role>
        <aff><institution>Simons Center for Quantitative Biology, Cold Spring Harbor Laboratory</institution>, Cold Spring Harbor, NY 11724, <country country="US">United States</country></aff>
        <xref rid="btae092-cor1" ref-type="corresp"/>
        <!--koo@cshl.edu-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btae092-cor1">Corresponding author. Simons Center for Quantitative Biology, Cold Spring Harbor Laboratory, 1 Bungtown Rd, Cold Spring Harbor, NY 11724, United States. E-mail: <email>koo@cshl.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2024-02-16">
      <day>16</day>
      <month>2</month>
      <year>2024</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>16</day>
      <month>2</month>
      <year>2024</year>
    </pub-date>
    <volume>40</volume>
    <issue>3</issue>
    <elocation-id>btae092</elocation-id>
    <history>
      <date date-type="received">
        <day>15</day>
        <month>7</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>01</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="editorial-decision">
        <day>09</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>2</month>
        <year>2024</year>
      </date>
      <date date-type="corrected-typeset">
        <day>06</day>
        <month>3</month>
        <year>2024</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2024. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2024</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btae092.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Summary</title>
        <p>Deep neural networks (DNNs) have been widely applied to predict the molecular functions of the non-coding genome. DNNs are data hungry and thus require many training examples to fit data well. However, functional genomics experiments typically generate limited amounts of data, constrained by the activity levels of the molecular function under study inside the cell. Recently, EvoAug was introduced to train a genomic DNN with evolution-inspired augmentations. EvoAug-trained DNNs have demonstrated improved generalization and interpretability with attribution analysis. However, EvoAug only supports PyTorch-based models, which limits its applications to a broad class of genomic DNNs based in TensorFlow. Here, we extend EvoAug’s functionality to TensorFlow in a new package, we call EvoAug-TF. Through a systematic benchmark, we find that EvoAug-TF yields comparable performance with the original EvoAug package.</p>
      </sec>
      <sec id="s2">
        <title>Availability and implementation</title>
        <p>EvoAug-TF is freely available for users and is distributed under an open-source MIT license. Researchers can access the open-source code on GitHub (<ext-link xlink:href="https://github.com/p-koo/evoaug-tf" ext-link-type="uri">https://github.com/p-koo/evoaug-tf</ext-link>). The pre-compiled package is provided via PyPI (<ext-link xlink:href="https://pypi.org/project/evoaug-tf" ext-link-type="uri">https://pypi.org/project/evoaug-tf</ext-link>) with in-depth documentation on ReadTheDocs (<ext-link xlink:href="https://evoaug-tf.readthedocs.io" ext-link-type="uri">https://evoaug-tf.readthedocs.io</ext-link>). The scripts for reproducing the results are available at (<ext-link xlink:href="https://github.com/p-koo/evoaug-tf_analysis" ext-link-type="uri">https://github.com/p-koo/evoaug-tf_analysis</ext-link>).</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of General Medical Sciences</institution>
            <institution-id institution-id-type="DOI">10.13039/100000057</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R01GM149921</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Human Genome Research Institute of the National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01HG012131</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>US National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>S10OD028632-01</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="4"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Deep neural networks (DNNs) have emerged as a promising tool for supervised learning of regulatory genomics data, taking DNA sequences as input and predicting the readouts of functional genomics experiments (<xref rid="btae092-B7" ref-type="bibr">Eraslan <italic toggle="yes">et al.</italic> 2019</xref>, <xref rid="btae092-B10" ref-type="bibr">Koo and Ploenzke 2020</xref>). Due to their overparameterization, DNNs are data hungry, requiring large amounts of data to learn discriminative features that ensure good generalization (<xref rid="btae092-B23" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2021</xref>). However, most functional genomics experiments only observe a limited number of molecular interactions within the context of a cell. For instance, the number of binding sites available for a transcription factor can be limited to the finite number of accessible DNA within a given cell type. Hence, dataset size is a major limiting factor when analyzing functional genomics data with DNNs.</p>
    <p>Data augmentation is a widely practiced strategy in machine learning to provide additional training samples. In practice, random transformations that maintain the same training labels are imposed on the input data, leveraging the natural symmetries in the data. For example, in natural images, the objects can undergo affine transformations, flips, color perturbations, and blurs, which do not alter the object’s label. In genomics, the available transformations that can maintain the same training labels are limited to reverse complements and small random shifts (<xref rid="btae092-B3" ref-type="bibr">Avsec <italic toggle="yes">et al.</italic> 2021a</xref>, <xref rid="btae092-B22" ref-type="bibr">Toneyan <italic toggle="yes">et al.</italic> 2022</xref>).</p>
    <p>To expand the available augmentations, EvoAug (Lee <italic toggle="yes">et al.</italic> 2023) was recently introduced to provide evolution-inspired data augmentations, including translocations, insertions, deletions, inversions, and mutations. In nature, genetic variation is sampled by evolution to increase phenotypic diversity. Thus, genetic mutations can alter the function of the sequence and, hence, change its label. Nevertheless, EvoAug asserts that the transformed sequences retain the same training label as the wild-type sequence, which can be considered as imposing a prior. For instance, small random translocations impose a prior that the activity of motifs is invariant to shifts. Moreover, insertions and deletions impose a prior that the distance between motifs is insignificant. Considered as a prior, evolution-inspired augmentations can introduce a bias in the DNN that may break the underlying rules of <italic toggle="yes">cis</italic>-regulatory grammars in the data. Thus, EvoAug employs a second stage of training that finetunes the DNN on the original, unaltered data, ensuring functional integrity toward the observed biology. This two-stage training curriculum has proven beneficial for genomic DNNs using synthetic data augmentations (Lee <italic toggle="yes">et al.</italic> 2023) and natural data augmentations (<xref rid="btae092-B6" ref-type="bibr">Duncan <italic toggle="yes">et al.</italic> 2023</xref>), as well as for protein-based DNNs (<xref rid="btae092-B15" ref-type="bibr">Lu <italic toggle="yes">et al.</italic> 2020</xref>, <xref rid="btae092-B14" ref-type="bibr">2022</xref>).</p>
    <p>However, the availability of EvoAug has been limited to a PyTorch (<xref rid="btae092-B19" ref-type="bibr">Paszke <italic toggle="yes">et al.</italic> 2019</xref>) implementation, posing a barrier for researchers working in TensorFlow (<xref rid="btae092-B1" ref-type="bibr">Abadi <italic toggle="yes">et al.</italic> 2016</xref>). To address this demand, we present <monospace>EvoAug-TF</monospace>, a TensorFlow implementation that builds upon the same principles as EvoAug. Below, we describe EvoAug-TF, highlighting its adaptations and unique features that are specific to the TensorFlow framework. Additionally, we present experimental results showcasing the effectiveness of EvoAug-TF in improving the generalization capabilities of genomic DNNs.</p>
  </sec>
  <sec>
    <title>2 Methodology and implementation</title>
    <p>EvoAug-TF adapts the functionality of the PyTorch-based EvoAug framework in TensorFlow (<xref rid="btae092-F1" ref-type="fig">Fig. 1a</xref>), including the augmentation techniques (e.g. random transversion, insertion, translocation, deletion, mutation, and noise). EvoAug-TF employs the same two-stage training curriculum, where stochastic augmentations are applied online to each mini-batch during training, followed by a finetuning step on the original, unperturbed data. Since EvoAug-TF imposes transformations on the input data while maintaining the same labels as the wild-type sequence, in its current form, EvoAug-TF only supports DNNs that output scalars in single-task or multi-task settings. In contrast, profile-based DNNs (<xref rid="btae092-B9" ref-type="bibr">Kelley <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae092-B4" ref-type="bibr">Avsec <italic toggle="yes">et al.</italic> 2021b</xref>, <xref rid="btae092-B22" ref-type="bibr">Toneyan <italic toggle="yes">et al.</italic> 2022</xref>) may require transformations to the corresponding labels, which is currently not supported in EvoAug-TF.</p>
    <fig position="float" id="btae092-F1">
      <label>Figure 1.</label>
      <caption>
        <p>Performance comparison between EvoAug and standard training. (a) Flowchart illustrating EvoAug-TF’s two-stage training curriculum. (b) Schematic demonstrating the difference between sequence mode and batch mode, where each column represents a mini-batch of sequences and different colors represent different data augmentations. (c, d) Performance comparison between EvoAug (PyTorch-based) and EvoAug-TF (TensorFlow-based) with DeepSTARR models trained with individual or combinations of augmentations (i.e. insertion + translocation + deletion; all augmentations) and finetuned on original STARR-seq data for two promoters: developmental (c) and housekeeping (d). (e) Comparison of the training time per epoch between EvoAug (PyTorch) and EvoAug-TF (TensorFlow). (c–e) Each scatter plot includes the data from five trials with random initialization. (f) Box-plots comparing the performance (area under the receiver operating characteristic curve) of a convolutional neural network trained with standard training, EvoAug-TF augmentations, and with finetuning on various Chip-seq peak classification tasks. (g) Performance comparison of DeepSTARR models with various training methods fit to training sets with varying levels of down-sampling. EvoAug-TF augmentations employed insertion + translocation + deletion in batch mode. The shaded region represents the SD of the mean across five models with different random initializations. (h) Box-plot comparison of the consistency of patterns within Saliency Maps, as measured by the <italic toggle="yes">k</italic>-attr-mean, for DeepSTARR models with standard training or EvoAug-TF augmentations (All). (i) Box-plot comparison of the attribution variation score, calculated according to the root-mean-squared attribution scores, for attribution maps generated by different methods (i.e. Saliency Maps, Integrated Gradients, and DeepSHAP) using a DeepSTARR model trained with standard training or EvoAug-TF augmentations (All). (h, i) Mann–Whitney <italic toggle="yes">U</italic>-test with <italic toggle="yes">P</italic>-values &lt;.001 (***) and .01 (**). Boxes represent five identical models with different random initializations.</p>
      </caption>
      <graphic xlink:href="btae092f1" position="float"/>
    </fig>
    <p>Several adaptations were made to EvoAug-TF compared to the PyTorch implementation, incorporating key design choices specific to the TensorFlow version. To ensure compatibility with TensorFlow’s graph mode and optimize training speed, <monospace>tf</monospace>. <monospace>Tensors</monospace> are used as substitutes for NumPy arrays, which were utilized in the PyTorch implementation. Additionally, EvoAug-TF employs <monospace>tf.while_loop</monospace> to achieve the same effects as the for loops used in the PyTorch implementation. The implementation of EvoAug-TF relies on TensorFlow 2 and its relevant libraries and dependencies; it has been tested thoroughly on versions 2.7 and 2.15.</p>
    <p>A key difference between EvoAug-TF and EvoAug lies in the approach to applying augmentations to the mini-batch during training. In the PyTorch implementation, the number of augmentations and the augmentation type are randomly chosen for each sequence. In the TensorFlow implementation, the same number of augmentations and augmentation types are employed for each sequence. However, the selected augmentation type(s) are sampled in a stochastic manner to impose a unique perturbation to each sequence in the mini-batch, similar to EvoAug. This design choice was made to simplify the process of imposing augmentations, while still sampling a high degree of genetic variation. Moreover, for some augmentations—such as translocation, insertion, deletion, and transversion (i.e. reverse-complement)—we offer an additional option to perform the same perturbation across all of the sequences within the mini-batch (<xref rid="btae092-F1" ref-type="fig">Fig. 1b</xref>), which we term batch mode. This feature provides a faster way to deploy augmentations, improving computational efficiency at the expense of sampling diversity.</p>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <p>To benchmark the performance of EvoAug-TF, we utilized the data and deep-learning model from the DeepSTARR study (<xref rid="btae092-B5" ref-type="bibr">de Almeida <italic toggle="yes">et al.</italic> 2022</xref>). The prediction task is set up to take as input 249-nt sequences and predict enhancer activity [measured via STARR-seq (<xref rid="btae092-B2" ref-type="bibr">Arnold <italic toggle="yes">et al.</italic> 2013</xref>)] for developmental and housekeeping transcriptional promoters in <italic toggle="yes">Drosophila melanogaster</italic> S2 cells as a multi-task regression. We systematically trained the DeepSTARR model with different EvoAug-TF augmentations individually and in combinations and compared their performance with the original EvoAug, using the same hyperparameters as in the original study (Lee <italic toggle="yes">et al.</italic> 2023). To ensure the robustness of the results, we conducted five trials for each set of augmentations with different random initializations.</p>
    <p>We found that models trained with EvoAug-TF augmentations achieved comparable performance to the original EvoAug-trained models with the same augmentation settings (<xref rid="btae092-F1" ref-type="fig">Fig. 1c and d</xref>). Notably, EvoAug-TF consistently yielded improved performance compared to the original EvoAug after Stage 1 (i.e. before finetuning) with the exception of random noise augmentation. However, the original EvoAug yielded slightly better performance than EvoAug-TF upon finetuning. In most cases, models trained with data augmentations led to improved performance compared to standard training.</p>
    <p>In terms of computational costs, we found that running EvoAug-TF exhibited similar training times per epoch as EvoAug (<xref rid="btae092-F1" ref-type="fig">Fig. 1e</xref>). Thus, EvoAug-TF’s approach of applying the same numbers and types of augmentations to each sequence maintains a comparable computational cost as EvoAug’s approach of applying different numbers and types of augmentations to each sequence. Notably, both approaches are effective in improving model performance.</p>
    <p>To further demonstrate the breadth of the EvoAug-TF package, we explored the use of batch mode augmentations. First, we trained convolutional neural networks on ChIP-seq peak classification from the original EvoAug study using batch mode augmentations (i.e. insertion, deletion, and translocation only). As expected, models trained with EvoAug-TF augmentations in batch mode consistently led to improved performance (<xref rid="btae092-F1" ref-type="fig">Fig. 1f</xref>). We also explored the effectiveness of EvoAug-TF in the low data regime with the same batch mode augmentations. Strikingly, a DeepSTARR model trained with EvoAug-TF on only 25% of the training data yields better performance than the same DeepSTARR model trained on the whole dataset with standard training (<xref rid="btae092-F1" ref-type="fig">Fig. 1g</xref>). Thus, EvoAug-TF can greatly improve data efficiency when training genomic deep-learning models, and batch mode is an effective way to improve performance over standard training.</p>
    <p>In the original study, EvoAug-trained models were found to improve motif representations in attribution maps. To explore whether EvoAug-TF trained models also improve the interpretability of attribution maps, we generated Saliency Maps (<xref rid="btae092-B20" ref-type="bibr">Simonyan <italic toggle="yes">et al.</italic> 2013</xref>) for 500 sequences with the highest observed enhancer activity for the developmental promoter and a different set of 500 sequences for the housekeeping promoter in the DeepSTARR dataset. We then quantified the consistency of salient patterns across a population of attribution maps using the Kullback–Liebler Divergence (KLD) between the distribution of locally embedded attribution scores versus an uninformative prior, which is termed <italic toggle="yes">k</italic>-attr-mean metric (<xref rid="btae092-B17" ref-type="bibr">Majdandzic <italic toggle="yes">et al.</italic> 2022</xref>). A higher KLD suggests that the attribution scores reflect similar recurring patterns across the 500 attribution maps. Indeed, EvoAug-TF-trained DeepSTARR yielded significantly higher KLD scores than standard training (<xref rid="btae092-F1" ref-type="fig">Fig. 1h</xref>).</p>
    <p>Attribution methods are sensitive to local function properties and thus can yield spurious attribution scores for reasons that are not biological (<xref rid="btae092-B17" ref-type="bibr">Majdandzic <italic toggle="yes">et al.</italic> 2022</xref>). Similar to the robustness test for model predictions introduced in <xref rid="btae092-B22" ref-type="bibr">Toneyan <italic toggle="yes">et al.</italic> (2022)</xref>, we developed a translational robustness test to quantitatively assess the robustness of attribution scores to small shifts in the input sequence. The assumption is that when no significant attribution scores are present near the ends of the sequence, small shifts to the sequence should not affect the importance of binding sites. Hence, the attribution scores for the binding sites should also shift with the translations while maintaining the same importance levels. In the translational robustness test, the input sequence was randomly translated by up to 30 nt in either direction with <monospace>np.roll</monospace>, the [corrected (<xref rid="btae092-B18" ref-type="bibr">Majdandzic <italic toggle="yes">et al.</italic> 2023</xref>)] attribution scores were calculated for the translated sequence, and then the inverse translation was imposed on the attribution maps to align with the wild-type attribution map. This process was repeated 20 times for each sequence, which resulted in 20 translated attribution maps realigned to the input sequence. Next, a variation score was calculated using the root-mean-squared error to summarize the total variation across the aligned attribution maps with a scalar value. As expected, DeepSTARR trained with EvoAug-TF yields a significantly lower variability score compared to standard training for Saliency Maps (<xref rid="btae092-B20" ref-type="bibr">Simonyan <italic toggle="yes">et al.</italic> 2013</xref>), Integrated Gradients (<xref rid="btae092-B21" ref-type="bibr">Sundararajan <italic toggle="yes">et al.</italic> 2017</xref>), and DeepSHAP (<xref rid="btae092-B16" ref-type="bibr">Lundberg and Lee 2017)</xref> (<xref rid="btae092-F1" ref-type="fig">Fig. 1i</xref>). Thus, EvoAug-TF training has the benefit of resulting in more robust attribution maps for various attribution methods.</p>
    <p>Each augmentation has corresponding hyperparameters that can be tuned to optimize performance gains. Previously, EvoAug identified hyperparameters through a simple grid search, focusing on one augmentation at a time. The EvoAug-TF package provides examples that show how to integrate EvoAug-TF with comprehensive hyperparameter searches, such as population-based training (<xref rid="btae092-B8" ref-type="bibr">Jaderberg <italic toggle="yes">et al.</italic> 2017</xref>) and the asynchronous hyperband algorithm (<xref rid="btae092-B12" ref-type="bibr">Li <italic toggle="yes">et al.</italic> 2018</xref>) provided by Ray Tune (<xref rid="btae092-B13" ref-type="bibr">Liaw <italic toggle="yes">et al.</italic> 2018</xref>). These should offer an alternative strategy to help navigate the combinatoric search space of discovering optimal hyperparameters when deploying multiple augmentations.</p>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>EvoAug-TF is a TensorFlow implementation of EvoAug (a PyTorch package) that provides the ability to train genomic DNNs with evolution-inspired data augmentations. Our results demonstrate the effectiveness of EvoAug-TF to improve generalization and model interpretability with attribution methods. We found that models incorporating EvoAug-TF augmentations achieved comparable or improved performance with similar computational efficiency as the original EvoAug models in PyTorch. Similar to EvoAug, EvoAug-TF is extensible—it can easily accommodate new types of custom augmentations within its data augmentation framework. While the current implementation only supports model outputs as scalars in single- or multi-task settings, we plan to extend these capabilities for multivariate predictions in the future to provide data augmentations for quantitative models that output profiles of read coverages (<xref rid="btae092-B9" ref-type="bibr">Kelley <italic toggle="yes">et al.</italic> 2018</xref>, <xref rid="btae092-B4" ref-type="bibr">Avsec <italic toggle="yes">et al.</italic> 2021b</xref>, <xref rid="btae092-B22" ref-type="bibr">Toneyan <italic toggle="yes">et al.</italic> 2022</xref>). Overall, EvoAug-TF offers a new tool for TensorFlow users in the genomics research community to improve data efficiency in training genomic deep-learning models, leading to improved generalization and interpretability with attribution analysis.</p>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors would like to thank Ziqi (Amber) Tang and Chandana Rajesh for support in setting up Ray Tune, Jakub Kaczmarzyk for support in setting up ReadTheDocs documentation, and Anirban Sarkar and Alessandro Crnjar for support on the translational robustness test for attribution maps.</p>
  </ack>
  <sec>
    <title>Author contributions</title>
    <p>Y.Y. and P.K. conceived the experiments, Y.Y. developed EvoAug-TF, conducted the experiments, and analyzed the results. S.M. developed the attribution translational robustness test and performed the experiments that used the test. Y.Y., S.M., and P.K. wrote and reviewed the manuscript.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Conflict of interest</title>
    <p>None declared.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported in part by the National Institute Of General Medical Sciences of the National Institutes of Health [award number R01GM149921]; and the National Human Genome Research Institute of the National Institutes of Health [award number R01HG012131]. This work was performed with assistance from the US National Institutes of Health [grant number S10OD028632-01].</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btae092-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Abadi</surname><given-names>M</given-names></string-name>, <string-name><surname>Agarwal</surname><given-names>A</given-names></string-name>, <string-name><surname>Barham</surname><given-names>P</given-names></string-name></person-group><etal>et al</etal><italic toggle="yes">TensorFlow: Large-scale Machine Learning on Heterogeneous Systems</italic>. In: <italic toggle="yes">Proceedings of the 12th USENIX conference on Operating Systems Design and Implementation, Savannah, GA, USA</italic>, <year>2016</year>, <fpage>265</fpage>–<lpage>283</lpage>.</mixed-citation>
    </ref>
    <ref id="btae092-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Arnold</surname><given-names>CD</given-names></string-name>, <string-name><surname>Gerlach</surname><given-names>D</given-names></string-name>, <string-name><surname>Stelzer</surname><given-names>C</given-names></string-name></person-group><etal>et al</etal><article-title>Genome-wide quantitative enhancer activity maps identified STARR-seq</article-title>. <source>Science</source><year>2013</year>;<volume>339</volume>:<fpage>1074</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">23328393</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Avsec</surname><given-names>Ž</given-names></string-name>, <string-name><surname>Agarwal</surname><given-names>V</given-names></string-name>, <string-name><surname>Visentin</surname><given-names>D</given-names></string-name></person-group><etal>et al</etal><article-title>Effective gene expression prediction from sequence by integrating long-range interactions</article-title>. <source>Nat Methods</source><year>2021a</year>;<volume>18</volume>:<fpage>1196</fpage>–<lpage>203</lpage>.<pub-id pub-id-type="pmid">34608324</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Avsec</surname><given-names>Ž</given-names></string-name>, <string-name><surname>Weilert</surname><given-names>M</given-names></string-name>, <string-name><surname>Shrikumar</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal><article-title>Base-resolution models of transcription-factor binding reveal soft motif syntax</article-title>. <source>Nat Genet</source><year>2021b</year>;<volume>53</volume>:<fpage>354</fpage>–<lpage>66</lpage>.<pub-id pub-id-type="pmid">33603233</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Almeida</surname><given-names>BP</given-names></string-name>, <string-name><surname>Reiter</surname><given-names>F</given-names></string-name>, <string-name><surname>Pagani</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>DeepSTARR predicts enhancer activity from DNA sequence and enables the de novo design of synthetic enhancers</article-title>. <source>Nat Genet</source><year>2022</year>;<volume>54</volume>:<fpage>613</fpage>–<lpage>24</lpage>.<pub-id pub-id-type="pmid">35551305</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B6">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Duncan</surname><given-names>AG</given-names></string-name>, <string-name><surname>Mitchell</surname><given-names>JA</given-names></string-name>, <string-name><surname>Moses</surname><given-names>AM.</given-names></string-name></person-group> Improving the performance of supervised deep learning for regulatory genomics using phylogenetic augmentation. bioRxiv, <year>2023</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eraslan</surname><given-names>G</given-names></string-name>, <string-name><surname>Avsec</surname><given-names>Ž</given-names></string-name>, <string-name><surname>Gagneur</surname><given-names>J</given-names></string-name></person-group><etal>et al</etal><article-title>Deep learning: new computational modelling techniques for genomics</article-title>. <source>Nat Rev Genet</source><year>2019</year>;<volume>20</volume>:<fpage>389</fpage>–<lpage>403</lpage>.<pub-id pub-id-type="pmid">30971806</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Jaderberg</surname><given-names>M</given-names></string-name>, <string-name><surname>Dalibard</surname><given-names>V</given-names></string-name>, <string-name><surname>Osindero</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal> Population based training of neural networks. arXiv, arXiv:1711.09846, <year>2017</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kelley</surname><given-names>DR</given-names></string-name>, <string-name><surname>Reshef</surname><given-names>YA</given-names></string-name>, <string-name><surname>Bileschi</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>Sequential regulatory activity prediction across chromosomes with convolutional neural networks</article-title>. <source>Genome Res</source><year>2018</year>;<volume>28</volume>:<fpage>739</fpage>–<lpage>50</lpage>.<pub-id pub-id-type="pmid">29588361</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Koo</surname><given-names>PK</given-names></string-name>, <string-name><surname>Ploenzke</surname><given-names>M.</given-names></string-name></person-group><article-title>Deep learning for inferring transcription factor binding sites</article-title>. <source>Curr Opin Syst Biol</source><year>2020</year>;<volume>19</volume>:<fpage>16</fpage>–<lpage>23</lpage>.<pub-id pub-id-type="pmid">32905524</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname><given-names>NK</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Toneyan</surname><given-names>S</given-names></string-name></person-group><etal>et al</etal><article-title>EvoAug: improving generalization and interpretability of genomic deep neural networks with evolution-inspired data augmentations</article-title>. <source>Genome Biol</source><year>2023</year>;<volume>24</volume>:<fpage>105</fpage>.<pub-id pub-id-type="pmid">37143118</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>L</given-names></string-name>, <string-name><surname>Jamieson</surname><given-names>K</given-names></string-name>, <string-name><surname>Rostamizadeh</surname><given-names>A</given-names></string-name></person-group><etal>et al</etal> Massively parallel hyperparameter tuning. arXiv, arXiv:1810.05934, <year>2018</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B13">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Liaw</surname><given-names>R</given-names></string-name>, <string-name><surname>Liang</surname><given-names>E</given-names></string-name>, <string-name><surname>Nishihara</surname><given-names>R</given-names></string-name></person-group><etal>et al</etal> Tune: a research platform for distributed model selection and training. arXiv, arXiv:1807.05118, <year>2018</year>. preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lu</surname><given-names>AX</given-names></string-name>, <string-name><surname>Lu</surname><given-names>AX</given-names></string-name>, <string-name><surname>Pritišanac</surname><given-names>I</given-names></string-name></person-group><etal>et al</etal><article-title>Discovering molecular features of intrinsically disordered regions by using evolution for contrastive learning</article-title>. <source>PLoS Comput Biol</source><year>2022</year>;<volume>18</volume>:<fpage>e1010238</fpage>.<pub-id pub-id-type="pmid">35767567</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B15">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lu</surname><given-names>AX</given-names></string-name>, <string-name><surname>Lu</surname><given-names>AX</given-names></string-name>, <string-name><surname>Moses</surname><given-names>A.</given-names></string-name></person-group> Evolution is all you need: phylogenetic augmentation for contrastive learning. arXiv, arXiv:2012.13475, <year>2020</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lundberg</surname><given-names>SM</given-names></string-name>, <string-name><surname>Lee</surname><given-names>S-I.</given-names></string-name></person-group> A unified approach to interpreting model predictions. In: <italic toggle="yes">Proceedings of the 31st International Conference on Neural Information Processing Systems, Long Beach, CA, USA</italic>, Vol. <volume>30</volume>. <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="btae092-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Majdandzic</surname><given-names>A</given-names></string-name>, <string-name><surname>Rajesh</surname><given-names>C</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Z</given-names></string-name></person-group><etal>et al</etal> Selecting deep neural networks that yield consistent attribution-based interpretations for genomics. <italic toggle="yes">Proc Mach Learn Res</italic><year>2022</year>;<volume>200</volume>:<fpage>131</fpage>–<lpage>49</lpage>.</mixed-citation>
    </ref>
    <ref id="btae092-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Majdandzic</surname><given-names>A</given-names></string-name>, <string-name><surname>Rajesh</surname><given-names>C</given-names></string-name>, <string-name><surname>Koo</surname><given-names>PK.</given-names></string-name></person-group><article-title>Correcting gradient-based interpretations of deep neural networks for genomics</article-title>. <source>Genome Biol</source><year>2023</year>;<volume>24</volume>:<fpage>109</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">37161475</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Paszke</surname><given-names>A</given-names></string-name>, <string-name><surname>Gross</surname><given-names>S</given-names></string-name>, <string-name><surname>Massa</surname><given-names>F</given-names></string-name></person-group><etal>et al</etal> Pytorch: an imperative style, high-performance deep learning library. In: <italic toggle="yes">Proceedings of the 33rd International Conference on Neural Information Processing Systems, Vancouver, BC, Canada</italic>, Vol. 721. <year>2019</year>, <fpage>8024</fpage>–<lpage>35</lpage>.</mixed-citation>
    </ref>
    <ref id="btae092-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Simonyan</surname><given-names>K</given-names></string-name>, <string-name><surname>Vedaldi</surname><given-names>A</given-names></string-name>, <string-name><surname>Zisserman</surname><given-names>A.</given-names></string-name></person-group> Deep inside convolutional networks: visualising image classification models and saliency maps. arXiv, arXiv:1312.6034, <year>2013</year>, preprint: not peer reviewed.</mixed-citation>
    </ref>
    <ref id="btae092-B21">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Sundararajan</surname><given-names>M</given-names></string-name>, <string-name><surname>Taly</surname><given-names>A</given-names></string-name>, <string-name><surname>Yan</surname><given-names>Q.</given-names></string-name></person-group> Axiomatic attribution for deep networks. In: <italic toggle="yes">Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia</italic>. <fpage>3319</fpage>–<lpage>28</lpage>. <publisher-name>PMLR</publisher-name>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="btae092-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Toneyan</surname><given-names>S</given-names></string-name>, <string-name><surname>Tang</surname><given-names>Z</given-names></string-name>, <string-name><surname>Koo</surname><given-names>PK.</given-names></string-name></person-group><article-title>Evaluating deep learning for predicting epigenomic profiles</article-title>. <source>Nat Mach Intell</source><year>2022</year>;<volume>4</volume>:<fpage>1088</fpage>–<lpage>100</lpage>.<pub-id pub-id-type="pmid">37324054</pub-id></mixed-citation>
    </ref>
    <ref id="btae092-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>C</given-names></string-name>, <string-name><surname>Bengio</surname><given-names>S</given-names></string-name>, <string-name><surname>Hardt</surname><given-names>M</given-names></string-name></person-group><etal>et al</etal><article-title>Understanding deep learning (still) requires rethinking generalization</article-title>. <source>Commun ACM</source><year>2021</year>;<volume>64</volume>:<fpage>107</fpage>–<lpage>15</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
