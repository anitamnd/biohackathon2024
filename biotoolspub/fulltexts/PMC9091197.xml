<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Genet</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Genet</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Genet.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Genetics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1664-8021</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9091197</article-id>
    <article-id pub-id-type="publisher-id">799349</article-id>
    <article-id pub-id-type="doi">10.3389/fgene.2022.799349</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Genetics</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>HerbKG: Constructing a Herbal-Molecular Medicine Knowledge Graph Using a Two-Stage Framework Based on Deep Transfer Learning</article-title>
      <alt-title alt-title-type="left-running-head">Zhu et al.</alt-title>
      <alt-title alt-title-type="right-running-head">A Herbal-Molecular Medicine Knowledge Graph</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Zhu</surname>
          <given-names>Xian</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1472600/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gu</surname>
          <given-names>Yueming</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Xiao</surname>
          <given-names>Zhifeng</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">*</xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1472087/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>School of Information Management</institution>, <institution>Nanjing University</institution>, <addr-line>Nanjing</addr-line>, <country>China</country></aff>
    <aff id="aff2"><sup>2</sup><institution>School of Health Economics and Management</institution>, <institution>Nanjing University of Chinese Medicine</institution>, <addr-line>Nanjing</addr-line>, <country>China</country></aff>
    <aff id="aff3"><sup>3</sup><institution>School of Computing and Information Systems</institution>, <institution>Faculty of Engineering and Information Technology</institution>, <institution>University of Melbourne</institution>, <addr-line>Parkville</addr-line>, <addr-line>VIC</addr-line>, <country>Australia</country></aff>
    <aff id="aff4"><sup>4</sup><institution>School of Engineering</institution>, <institution>Penn State Erie</institution>, <institution>The Behrend College</institution>, <addr-line>Erie</addr-line>, <addr-line>PA</addr-line>, <country>United States</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p><bold>Edited by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/1326351/overview" ext-link-type="uri">Gregory Fonseca</ext-link>, McGill University, Canada</p>
      </fn>
      <fn fn-type="edited-by">
        <p><bold>Reviewed by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/778584/overview" ext-link-type="uri">Pu-Feng Du</ext-link>, Tianjin University, China</p>
        <p><ext-link xlink:href="https://loop.frontiersin.org/people/853876/overview" ext-link-type="uri">Jun Ding</ext-link>, McGill University Health Centre, Canada</p>
      </fn>
      <corresp id="c001">*Correspondence: Zhifeng Xiao, <email>zux2@psu.edu</email>
</corresp>
      <fn fn-type="other">
        <p>This article was submitted to Computational Genomics, a section of the journal Frontiers in Genetics</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>27</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>13</volume>
    <elocation-id>799349</elocation-id>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>10</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>05</day>
        <month>4</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2022 Zhu, Gu and Xiao.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Zhu, Gu and Xiao</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Recent advances have witnessed a growth of herbalism studies adopting a modern scientific approach in molecular medicine, offering valuable domain knowledge that can potentially boost the development of herbalism with evidence-supported efficacy and safety. However, these domain-specific scientific findings have not been systematically organized, affecting the efficiency of knowledge discovery and usage. Existing knowledge graphs in herbalism mainly focus on diagnosis and treatment with an absence of knowledge connection with molecular medicine. To fill this gap, we present HerbKG, a knowledge graph that bridges herbal and molecular medicine. The core bio-entities of HerbKG include herbs, chemicals extracted from the herbs, genes that are affected by the chemicals, and diseases treated by herbs due to the functions of genes. We have developed a learning framework to automate the process of HerbKG construction. The resulting HerbKG, after analyzing over 500K PubMed abstracts, is populated with 53K relations, providing extensive herbal-molecular domain knowledge in support of downstream applications. The code and an interactive tool are available at <ext-link xlink:href="https://github.com/FeiYee/HerbKG" ext-link-type="uri">https://github.com/FeiYee/HerbKG</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>biobert</kwd>
      <kwd>knowledge graph</kwd>
      <kwd>herb</kwd>
      <kwd>chemical</kwd>
      <kwd>disease</kwd>
      <kwd>gene</kwd>
      <kwd>BERT</kwd>
      <kwd>ontology</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>1 Introduction</title>
    <p>A knowledge graph (KG) serves as a useful tool to represent real-world semantic phenomena in an organized way (<xref rid="B40" ref-type="bibr">Wang et al., 2017</xref>). Specifically, a KG consists of a collection of three tuples, each of which follows a format of [head, tail, relation]. The head and tail specify an entity pair, and the relation defines how the two entities are semantically related. Both entities and relations can have domain-specific properties. A broad spectrum of large-scale KGs encoding generic knowledge, such as YAGO3 (<xref rid="B25" ref-type="bibr">Mahdisoltani et al., 2014</xref>), Freebase (<xref rid="B7" ref-type="bibr">Bollacker et al., 2008</xref>), DBpedia (<xref rid="B2" ref-type="bibr">Auer et al., 2007</xref>), and BabelNet (<xref rid="B28" ref-type="bibr">Navigli and Ponzetto, 2012</xref>), have been developed and have created massive value that benefits a variety of downstream applications, such as knowledge visualization (<xref rid="B18" ref-type="bibr">Kerdjoudj and Curé, 2015</xref>) and reasoning (<xref rid="B11" ref-type="bibr">Chen et al., 2020</xref>), information retrieval (<xref rid="B51" ref-type="bibr">Wise et al., 2020</xref>), and question answering (<xref rid="B31" ref-type="bibr">Saha et al., 2018</xref>). Furthermore, domain-specific KGs have also gained extensive interests (<xref rid="B14" ref-type="bibr">Ernst et al., 2014</xref>) by domain experts who desire to have efficient access to high-quality domain knowledge. For instance, a biomedical KG allows researchers and medical practitioners to mine and discover complex interactions between millions of bio-entities (e.g., chemicals, genes, and diseases), facilitating academic knowledge query and clinical decision making (<xref rid="B37" ref-type="bibr">Su et al., 2021</xref>; <xref rid="B53" ref-type="bibr">Zheng et al., 2021</xref>). Adding such domain knowledge into existing healthcare applications can greatly improve the quality and efficiency of current medical operations and IT systems.</p>
    <p>As a sub-field of medicine, herbal medicine, also referred to as herbalism, is the study of pharmacognosy and the use of medicinal plants, forming the basis of traditional medicine that has been existing and evolving for over five thousand years across multiple continents and countries, including Africa, Americas, ancient Egypt, Greece, China, and India (<xref rid="B50" ref-type="bibr">Wikipedia contributors, 2004c</xref>). In the modern era, herbalism has received criticism and skepticism due to the lack of strong evidence of efficacy and safety found in high-quality scientific publications. Currently, herbalism is still the primary health care in many underdeveloped regions and is widely used to treat chronic diseases, such as diabetes (<xref rid="B13" ref-type="bibr">Egede et al., 2002</xref>), cancer (<xref rid="B10" ref-type="bibr">Burstein et al., 1999</xref>), end-stage kidney disease (<xref rid="B30" ref-type="bibr">Roozbeh et al., 2013</xref>), and asthma (<xref rid="B38" ref-type="bibr">Szelenyi and Brune, 2002</xref>). In the past decades, more and more researchers have taken a modern scientific approach to investigating the biological function of herbs and herbal contents, validating the interconnection between herbs, extracted chemicals, diseases, and genes (<xref rid="B3" ref-type="bibr">Babu et al., 2007</xref>; <xref rid="B9" ref-type="bibr">Brackman et al., 2008</xref>). These studies bridge modern molecular medicine and traditional herbalism, which provides more evidence to support the medicinal usage of herbs, opening a promising direction to boost the development of herbalism in the 21st century. In addition, these studies provide valuable domain knowledge in herbalism that should be restructured for building a herb KG.</p>
    <p>Existing efforts of herb KG construction mainly focus on the diagnosis and treatment side of herbalism. Wang et al. (<xref rid="B41" ref-type="bibr">Wang et al., 2019</xref>) propose a Knowledge Graph Embedding Enhanced Topic Model (KGETM) for traditional Chinese medicine (TCM). The used KG in the study considers relations between symptoms, syndromes, treatments, and herbs to support a herb recommendation application. Zheng et al. (<xref rid="B54" ref-type="bibr">Zheng et al., 2020</xref>) have developed a TCM KG that stores herbs, therapies, prescriptions, diseases, syndromes, symptoms, and the relations between them. Another group (<xref rid="B35" ref-type="bibr">Somé et al., 2019</xref>) has developed the West African Herbal-based Traditional Medicine KG consisting of 143 identified West African medicinal plants and 108 recipes to treat 110 diseases and symptoms. Similar herb KGs that aim to facilitate prescription can be found in literature (<xref rid="B24" ref-type="bibr">Liu et al., 2018</xref>; <xref rid="B26" ref-type="bibr">Miao et al., 2018</xref>; <xref rid="B15" ref-type="bibr">Gong et al., 2021</xref>). On the other hand, prior efforts have also investigated generic biomedical KGs. Zheng et al. (<xref rid="B53" ref-type="bibr">Zheng et al., 2021</xref>) propose PharmKG, which consists of 500,000 relations between genes, drugs, and diseases. Another study by Su et al. (<xref rid="B37" ref-type="bibr">Su et al., 2021</xref>) proposes the Cornell Biomedical Knowledge Hub (CBKH) that takes into account genes, drugs, diseases, anatomies, molecules, and symptoms, resulting in a KG with 2,231,297 entities of six types and 48, 678, 651 relations of eight types. To our best knowledge, there is no existing KG in the literature to model herbs, the contained chemicals, and their interactions with genes and diseases from the viewpoint of molecular medicine. Thus, our study aims to fill this gap.</p>
    <p>The contributions of this study are summarized as follows:<list list-type="simple"><list-item><p>• We propose a Herb ontology named HerbOnt composed of four entity types and five relation types to encode the interplay between herbs, chemicals, genes, and diseases.</p></list-item><list-item><p>• We develop a learning framework to automate the construction of HerbKG. We leverage an existing named entity recognition (NER) model and design a BERT-based model for relation extraction (RE) to annotate raw PubMed abstracts that are screened to match the subject of herbalism.</p></list-item><list-item><p>• To validate the RE model, we create a herb RE dataset with 3,526 human-annotated relations. BERT and two of its variants, SciBERT and BioBERT are evaluated on the herb RE dataset. In addition, two performance boosters, including a fine-tuning strategy and a substitution-based generative augmentation module, have been utilized for performance improvement. Our ablation studies show that the two boosters can bring consistent gains in the F1 score due to the additional domain knowledge injected into the models. The best model, the fine-tuned BioBERT that is further trained on the augmented dataset, can achieve an F1 score of 95.9%. The self-created herb RE dataset, with the evaluated models, can serve as a credible benchmark for future research.</p></list-item><list-item><p>• The proposed system has analyzed a total of 516,393 PubMed abstracts and identified 4,130 herbs, 6,331 chemicals, 2,187 diseases, and 2,641 genes, with 53,754 distinct relations, providing valuable domain knowledge in herbalism from the molecular perspective. In addition, the constructed HerbKG can support multiple downstream tasks like evidence-based graph queries and drug re-positioning. We have made the code publicly available at <ext-link xlink:href="https://github.com/FeiYee/HerbKG" ext-link-type="uri">https://github.com/FeiYee/HerbKG</ext-link>, where an interactive tool and a system tutorial are also provided.</p></list-item></list>
</p>
    <p>The rest of this paper is structured as follows. <xref rid="s2" ref-type="sec">Section 2</xref> provides the technical details of the proposed framework for HerbKG construction. <xref rid="s3" ref-type="sec">Section 3</xref> presents the experimental results and a discussion about several downstream tasks. <xref rid="s4" ref-type="sec">Section 4</xref> offers a summary of this study with limitations and future plans.</p>
  </sec>
  <sec id="s2">
    <title>2 Materials and Methods</title>
    <sec id="s2-1">
      <title>2.1 The Herb Ontology</title>
      <p>In information sciences, an ontology shows the properties of a subject area and how they are related, by defining a set of categories and concepts that represent the subject (<xref rid="B17" ref-type="bibr">Guarino et al., 2009</xref>). To unify the terminology throughout the article, we use entity types to refer to categories and entities to refer to concepts that are instantiated from entity types. An ontology serves as a template for constructing a KG since only relations defined in the ontology can be added into the KG. As shown in <xref rid="F1" ref-type="fig">Figure 1</xref>, HerbOnt consists of four entity types, including Herb, Chemical, Disease, and Gene, with five coarse-grained relation types, including HerbHasCompoundChemical (HHC), HerbTreatsDisease (HTD), ChemicalActsOnDisease (CAD), ChemicalAssociatesGene (CAG), and GeneInfluencesDisease (GID). A description of the entity types is as follows.<list list-type="simple"><list-item><p>• Herbs in this study can be a part or produced from parts of a plant (either fresh or dried), including the leafy green or flowering parts, seeds, bark, roots and fruits. Examples include “abrus precatorius”, “ginkgo biloba”, “salvia officinalis”, and “cinnamomum cassia”.</p></list-item><list-item><p>• Chemicals refer to chemical compounds that can be used as medicine. In our study, we mainly focus on the chemicals extracted from herbs. Examples include “essential amino acids”, “isoflavanquinones”, “diphenhydramine”, and “abruquinone A”.</p></list-item><list-item><p>• A Disease refers to a particular abnormal condition that negatively affects the structure or function of all or part of an organism, and that is not due to any immediate external injury (<xref rid="B48" ref-type="bibr">Wikipedia contributors, 2004a</xref>). Examples include “anemia”, “otoconia”, “hypoosmotic swelling”, and “gastric ulcer”.</p></list-item><list-item><p>• A Gene refers to a basic unit of heredity and a sequence of nucleotides in DNA or RNA that encodes the synthesis of a gene product, either RNA or protein (<xref rid="B49" ref-type="bibr">Wikipedia contributors, 2004b</xref>). Examples include “caspase-3″, “AP-1″, “Bax”, and “cytochrome c”.</p></list-item></list>
</p>
      <fig position="float" id="F1">
        <label>FIGURE 1</label>
        <caption>
          <p>The proposed Herb ontology consists of four entity types and five relations. The four entity types are Herb, Chemical, Disease, and Gene; the five relation types are HerbHasCompoundChemical (HHC), HerbTreatsDisease (HTD), ChemicalActsOnDisease (CAD), ChemicalAssociatesGene (CAG), and GeneInfluencesDisease (GID).</p>
        </caption>
        <graphic xlink:href="fgene-13-799349-g001" position="float"/>
      </fig>
      <p>We also provide a description of the relation types below:<list list-type="simple"><list-item><p>• An HHC describes a containment relation between a herb and a chemical, which is extracted from the herb. A herb may contain one or more chemicals that can be used for medical purposes. For example, cassia barks contains cinnamaldehyde.</p></list-item><list-item><p>• An HTD indicates that a herb has positive effect on the treatment of a disease.</p></list-item><list-item><p>• A CAD refers to a relation between a chemical and a disease. The effect of the chemical on the disease can be either positive or negative. CAD allows us to understand which chemical extracted from the herb causes what effect on the disease.</p></list-item><list-item><p>• A CAG describes an association between a chemical and a gene. For example, a study (<xref rid="B23" ref-type="bibr">Li et al., 2016</xref>) shows that cinnamaldehyde (a chemical) can inhibit the PI3K/Akt (a gene) signaling pathway, inducing apoptosis and affecting the biological behavior of human colorectal cancer cells.</p></list-item><list-item><p>• A GID indicates a connection between a gene and a disease. For example, a study (<xref rid="B20" ref-type="bibr">Lee et al., 2007</xref>) shows that AP-1 (a gene) inactivation can inhibit SW620 colon cancer (a disease) cell growth.</p></list-item></list>
</p>
    </sec>
    <sec id="s2-2">
      <title>2.2 HerbKG Learning Tasks</title>
      <p>Two learning tasks, including NER and RE, are involved in the construction of HerbKG. We provide a formal definition for each task as follows.</p>
      <sec id="s2-2-1">
        <title>2.2.1 NER Task</title>
        <p>The goal of NER is to locate entity mentions in an input text and classify them into a set of pre-defined categories. Formally, let <italic>s</italic> = [<italic>t</italic>
<sub>1</sub>, <italic>t</italic>
<sub>2</sub>, <italic>…</italic> , <italic>t</italic>
<sub><italic>n</italic></sub>] denote a sentence <italic>s</italic> with <italic>n</italic> tokens. Taking <italic>s</italic> as an input, an NER model outputs a list of tuples <inline-formula id="inf1"><mml:math id="m1" overflow="scroll"><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>&gt;</mml:mo></mml:math></inline-formula>, each of which is an entity mention in <italic>s</italic>. Here, <italic>I</italic>
<sub><italic>s</italic></sub> and <italic>I</italic>
<sub><italic>e</italic></sub> specify the indices of the starting and ending tokens of an entity mention. Thus, both <italic>I</italic>
<sub><italic>s</italic></sub> and <italic>I</italic>
<sub><italic>e</italic></sub> are in [1, <italic>n</italic>], and <italic>I</italic>
<sub><italic>s</italic></sub> ≤ <italic>I</italic>
<sub><italic>e</italic></sub>. Also, <italic>k</italic> belongs to a category set. In our study, <italic>k</italic> ∈ {<italic>“Herb”</italic>, <italic>“Chemical”</italic>, <italic>“Disease”</italic>, <italic>“Gene”</italic>}.</p>
      </sec>
      <sec id="s2-2-2">
        <title>2.2.2 RE Task</title>
        <p>For the RE task, we choose to develop a medium-sized dataset, because there is no existing one that has the same ontology definition as HerbOnt. We formulate the learning problem as follows. Let <inline-formula id="inf2"><mml:math id="m2" overflow="scroll"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> be the self-developed herb RE dataset with <italic>m</italic> examples. Each input <italic>x</italic>
<sub><italic>i</italic></sub> contains the title and content of an abstract and a pair of entities. The label <italic>y</italic>
<sub><italic>i</italic></sub> specifies the relation type of the entity pair in <italic>x</italic>
<sub><italic>i</italic></sub>. The task is to train a model to predict the relation type given <italic>x</italic>
<sub><italic>i</italic></sub> as an input. It is noted that the problem belongs to document-level RE, where the head and tail entity mentions could span across multiple sentences in the abstract. Also, in the context of HerbKG, we have <italic>y</italic>
<sub><italic>i</italic></sub> ∈ {<italic>“HHC”</italic>, <italic>“HTD”</italic>, <italic>“CAD”</italic>, <italic>“CAG”</italic>, <italic>“GID”</italic>, <italic>“Neg</italic>.<italic>“</italic>}, in which the first five are positive relation types defined in HerbOnt, and “Neg.” represent the negative examples indicating a non-relation. Since not every entity pair of an abstract are related, it is essential to introduce negative examples into the dataset so that the model can be trained to make a distinction.</p>
      </sec>
    </sec>
    <sec id="s2-3">
      <title>2.3 System Overview</title>
      <p><xref rid="F2" ref-type="fig">Figure 2</xref> shows a two-stage learning framework of building HerbKG. Since only a small fraction of PubMed articles are relevant to the subject of HerbKG, we develop a screening procedure to identify the matching abstracts. Specifically, only an abstract that contains a mention of either a herb or a chemical in a pre-defined domain vocabulary is considered as a match. In practice, it is straightforward to list the herbs and their contained chemicals for medicinal usage. This work is manually done by one of the authors with domain knowledge in herbal medicine. Each selected abstract is then passed through the PubTator Central (PTC) NER model (<xref rid="B43" ref-type="bibr">Wei et al., 2019</xref>), followed by a custom BERT-based RE model to produce a list of identified relation triplets, which are used for the HerbKG construction. In addition, two boosting strategies have been utilized for performance improvement, including fine-tuning BERT on domain resources and a generative data augmentation method. The former aims to inject domain knowledge into the BERT model, while the latter can generate synthetic samples to enhance the training set. The constructed HerbKG can support multiple downstream applications, such as descriptive analysis, evidence-based graph query, similarity analysis, and drug repurposing.</p>
      <fig position="float" id="F2">
        <label>FIGURE 2</label>
        <caption>
          <p>A two-stage learning framework for building HerbKG. Stage I is the NER task, which is done by the PTC NER model. Stage II is the RE task, which extracts relation triplets used to build the HerbKG. In addition, two boosting strategies have been utilized for performance improvement, including fine-tuning BERT on domain resources and a generative data augmentation method. The former aims to inject domain knowledge into the BERT model, while the latter can generate synthetic samples to enhance the training set. The constructed HerbKG can support multiple downstream applications, such as descriptive analysis, evidence-based graph query, similarity analysis, and drug repurposing.</p>
        </caption>
        <graphic xlink:href="fgene-13-799349-g002" position="float"/>
      </fig>
    </sec>
    <sec id="s2-4">
      <title>2.4 The PTC NER Model</title>
      <p>Numerous methods have been developed to solve NER. In this study, we adopt an existing model (<xref rid="B43" ref-type="bibr">Wei et al., 2019</xref>), referred to as PTC, proposed by Wei et al., who have provided an implementation hosted online at <ext-link xlink:href="https://www.ncbi.nlm.nih.gov/research/pubtator/" ext-link-type="uri">https://www.ncbi.nlm.nih.gov/research/pubtator/</ext-link>. PTC can identify and annotate six types of entities, including Gene, Disease, Chemical, Mutation, Species, and Cellline. At a high level, PTC works by feeding an article into a tagging module, which integrates a series of entity taggers including GNormPlus (<xref rid="B44" ref-type="bibr">Wei et al., 2015a</xref>), AB3P (<xref rid="B34" ref-type="bibr">Sohn et al., 2008</xref>), SimConcept (<xref rid="B46" ref-type="bibr">Wei et al., 2015b</xref>), tmVar 2.0 (<xref rid="B47" ref-type="bibr">Wei et al., 2018</xref>), SR4GN (<xref rid="B45" ref-type="bibr">Wei et al., 2012</xref>), TaggerOne (<xref rid="B19" ref-type="bibr">Leaman and Lu, 2016</xref>), and Cellosaurus (<xref rid="B4" ref-type="bibr">Bairoch, 2018</xref>). The tagging module also addresses several issues in bio-entity annotation, including abbreviation resolution, detection of composite/variant mentions, and entity normalization. The initial annotations are further processed by a concept disambiguation module to ensure that mentions referring to the same entity receive the same identifier. <xref rid="F3" ref-type="fig">Figure 3</xref> is a screenshot of bio-concept annotation using the PTC web interface for an article with PMID 12860272.</p>
      <fig position="float" id="F3">
        <label>FIGURE 3</label>
        <caption>
          <p>Bio-concept annotation through the PTC web interface for an article with PMID 12860272.</p>
        </caption>
        <graphic xlink:href="fgene-13-799349-g003" position="float"/>
      </fig>
      <p>To adapt PTC to suit our needs, we disable the detection of mutations and celllines that are not defined in HerbOnt. Also, a detected species is annotated as a herb if it matches any entity in the pre-defined domain vocabulary. The top three sections in <xref rid="T1" ref-type="table">Table 1</xref> display an annotated sample by PTC. These intermediate samples are further annotated by an RE model, which is discussed in the next subsection.</p>
      <table-wrap position="float" id="T1">
        <label>TABLE 1</label>
        <caption>
          <p>A sample with annotation in the herb RE dataset.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1">Title</th>
              <th align="center" rowspan="1" colspan="1">9848396 Cinnamaldehyde Inhibits Lymphocyte Proliferation and Modulates T-Cell Differentiation</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">Abstract</td>
              <td align="left" rowspan="1" colspan="1">9848396 Two kinds of cinnamaldehyde derivative, 2′-hydroxycinnamaldehyde (HCA) and 2′-benzoxy-cinnamaldehyde (BCA), were studied for their immunomodulatory effects. These compounds were screened as anticancer drug candidates from stem bark of Cinnamomum cassia for their inhibitory effect on farnesyl protein transferase activity. Ras activation, which is accompanied with its farnesylation, has been known to be important in immune cell activation as well as in carcinogenesis. Treatment of these cinnamaldehydes to mouse splenocyte cultures induced suppression of lymphoproliferation following both Con A and LPS stimulation in a dose-dependent manner…</td>
            </tr>
            <tr>
              <td rowspan="5" align="left" colspan="1">Entity Mentions</td>
              <td align="left" rowspan="1" colspan="1">9848396 0 14 Cinnamaldehyde Chemical C012843</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">9848396 127 151 2′-hydroxycinnamaldehyde Chemical C117567</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">9848396 162 187 2′-benzoxy-cinnamaldehyde Chemical C117567</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">9848396 322 339 Cinnamomum cassia Herb 119,260</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">…</td>
            </tr>
            <tr>
              <td rowspan="4" align="left" colspan="1">Relations</td>
              <td align="left" rowspan="1" colspan="1">9848396 HHC 119260 D013390</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">9848396 HHC 119260 C117567</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">9848396 CAD D013390 C565232</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">9848396 CAD C117567 C565232</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="s2-5">
      <title>2.5 A BERT-Based RE Model</title>
      <p>As defined in <xref rid="s2-2-2" ref-type="sec">Section 2.2.2</xref>, the RE task in this study is a multi-class classification problem aiming to predict the relation type, given an abstract and a pair of annotated entities. Since there is no existing dataset, we have developed a dataset and trained a BERT-based model for the herb RE task.</p>
      <sec id="s2-5-1">
        <title>2.5.1 Herb RE Dataset Development</title>
        <p><xref rid="F4" ref-type="fig">Figure 4</xref> describes the dataset development process. First, we gather a collection of seed keywords of herb varieties that are commonly used in herbal medicine. We then use a self-developed crawler to search the PubMed dataset for the seed herb keywords. The search is only applied to the PubMed abstracts rather than the full texts, because an abstract contains the essential findings of a study; in most cases, the entities and their relations are clearly stated in an abstract, providing sufficient information that can be extracted to build our knowledge graph. The crawler is able to scrape a collection of relevant abstracts guided by the seed keywords. Next, the collected abstracts are fed into the PTC through its restful API at <ext-link xlink:href="https://www.ncbi.nlm.nih.gov/research/pubtator/api.html" ext-link-type="uri">https://www.ncbi.nlm.nih.gov/research/pubtator/api.html</ext-link> (accessed on 7 July 2021). We display a complete sample with full annotation in <xref rid="T1" ref-type="table">Table 1</xref>, in which the first three rows, including Title, Abstract, and Entity Mentions, are generated by the PubTator API; the last row, Relations, is completed by a human annotator, who is a Ph.D. student in molecular biology with sufficient domain knowledge for the annotation task.</p>
        <fig position="float" id="F4">
          <label>FIGURE 4</label>
          <caption>
            <p>The development process of the Herb RE dataset. A crawler is adopted to search for a pre-defined set of herb keywords in the PubMed dataset, returning a collection of matching abstracts that are firstly annotated by the PTC for NER and then annotated by a human annotator for RE. Thereafter the positive examples can be directly extracted, and the negative examples can be obtained through negative sampling. The positive and negative samples are aggregated to form the final herb RE dataset. Blue boxes in the figure represent various types of data being processed along the pipeline, and green rounded boxes represent operations/functions applied on the data.</p>
          </caption>
          <graphic xlink:href="fgene-13-799349-g004" position="float"/>
        </fig>
        <p>Each annotated abstract follows the PubTator format, as shown in <xref rid="T1" ref-type="table">Table 1</xref>, which divides a sample into four sections, each starting with the PubMed article ID of the abstract. The Title and Abstract sections that are directly extracted from the PubMed database. Each entity mention is a six-tuple with a specified sequence of PubMed ID, entity start position, end position, entity text, entity type, and entity ID. Similarly, each relation in the Relations section is a four-tuple sequence including the PubMed ID, the relation type, the head entity ID, and the tail entity ID.</p>
        <p>Since we adopt BERT-based models for RE, the input can be split into two sentences, denoted by A and B. For our RE task, sentence A is a concatenation of the title and the abstract, and sentence B contains the head and tail entities, separated by a space. For each relation type, we need both positive and negative training examples. Also, each example in the dataset is a three-tuple, namely, sentence A, sentence B, and relation type that are separated by a tab. To simplify training, we group all negative examples together to create a new RE category, i.e., “Neg.“. Therefore, the RE type for each example is one of the elements in {<italic>“HHC”</italic>, <italic>“HTD”</italic>, <italic>“CAD”</italic>, <italic>“CAG”</italic>, <italic>“GID”</italic>, <italic>“Neg</italic>.<italic>”</italic>}, leading to a six-class classification problem. <xref rid="T2" ref-type="table">Table 2</xref> shows five instances in the herb RE dataset.</p>
        <table-wrap position="float" id="T2">
          <label>TABLE 2</label>
          <caption>
            <p>Instances in the herb RE dataset.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th align="left" rowspan="1" colspan="1">RE Type</th>
                <th align="center" rowspan="1" colspan="1">Sentence A</th>
                <th align="center" rowspan="1" colspan="1">Head Entity</th>
                <th align="center" rowspan="1" colspan="1">Tail Entity</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1">HHC</td>
                <td align="left" rowspan="1" colspan="1">These results showed that cassia barks contained high contents of cinnamaldehyde …</td>
                <td align="left" rowspan="1" colspan="1">cassia bark</td>
                <td align="left" rowspan="1" colspan="1">cinnamaldehyde</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">HTD</td>
                <td align="left" rowspan="1" colspan="1">…The extract of cinnamon bark contains potentially valuable antiamyloidogenic agents for the prevention and treatment of AD …</td>
                <td align="left" rowspan="1" colspan="1">cinnamon</td>
                <td align="left" rowspan="1" colspan="1">AD</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">CAD</td>
                <td align="left" rowspan="1" colspan="1">…The present experiment showed that cinnamaldehyde dose-dependently depresses the proliferation of three types of NSCLC cells and induces cell apoptosis <italic>in vitro</italic> and <italic>in vivo</italic>…</td>
                <td align="left" rowspan="1" colspan="1">cinnamaldehyde</td>
                <td align="left" rowspan="1" colspan="1">NSCLC</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">CAG</td>
                <td align="left" rowspan="1" colspan="1">…Cinnamaldehyde affects the biological behavior of human colorectal cancer cells and induces apoptosis via inhibition of the PI3K/Akt signaling pathway…</td>
                <td align="left" rowspan="1" colspan="1">Cinnamaldehyde</td>
                <td align="left" rowspan="1" colspan="1">PI3K/Akt</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GID</td>
                <td align="left" rowspan="1" colspan="1">…2-hydroxycinnamaldehyde inhibits SW620 colon cancer cell growth through AP-1 inactivation…</td>
                <td align="left" rowspan="1" colspan="1">AP-1</td>
                <td align="left" rowspan="1" colspan="1">colon cancer</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p><xref rid="T3" ref-type="table">Table 3</xref> shows the stats of the herb RE dataset that contains a total of manually annotated 3,526 examples, split in the ratio of 3:1 to obtain the training and test sets. It is observed that the six classes are highly imbalanced. HHC and Neg. combined account for nearly 70% of all relations, while CAG and GID only take 1.3 and 3.1%, respectively. Thus, a performance metric (see <xref rid="s3-1-1" ref-type="sec">Section 3.1.1</xref>) should be carefully chosen to properly deal with the class imbalance issue.</p>
        <table-wrap position="float" id="T3">
          <label>TABLE 3</label>
          <caption>
            <p>Stats for the herb RE dataset.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th align="center" rowspan="1" colspan="1">HHC</th>
                <th align="center" rowspan="1" colspan="1">HTD</th>
                <th align="center" rowspan="1" colspan="1">CAD</th>
                <th align="center" rowspan="1" colspan="1">CAG</th>
                <th align="center" rowspan="1" colspan="1">GID</th>
                <th align="center" rowspan="1" colspan="1">Neg</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1">Training</td>
                <td align="center" rowspan="1" colspan="1">884</td>
                <td align="char" char="." rowspan="1" colspan="1">472</td>
                <td align="char" char="." rowspan="1" colspan="1">176</td>
                <td align="char" char="." rowspan="1" colspan="1">29</td>
                <td align="char" char="." rowspan="1" colspan="1">81</td>
                <td align="center" rowspan="1" colspan="1">1,010</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Test</td>
                <td align="center" rowspan="1" colspan="1">346</td>
                <td align="char" char="." rowspan="1" colspan="1">201</td>
                <td align="char" char="." rowspan="1" colspan="1">68</td>
                <td align="char" char="." rowspan="1" colspan="1">16</td>
                <td align="char" char="." rowspan="1" colspan="1">29</td>
                <td align="center" rowspan="1" colspan="1">224</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Total</td>
                <td align="center" rowspan="1" colspan="1">1,230</td>
                <td align="char" char="." rowspan="1" colspan="1">673</td>
                <td align="char" char="." rowspan="1" colspan="1">244</td>
                <td align="char" char="." rowspan="1" colspan="1">45</td>
                <td align="char" char="." rowspan="1" colspan="1">110</td>
                <td align="center" rowspan="1" colspan="1">1,234</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">%</td>
                <td align="center" rowspan="1" colspan="1">34.8</td>
                <td align="char" char="." rowspan="1" colspan="1">19.1</td>
                <td align="char" char="." rowspan="1" colspan="1">6.9</td>
                <td align="char" char="." rowspan="1" colspan="1">1.3</td>
                <td align="char" char="." rowspan="1" colspan="1">3.1</td>
                <td align="center" rowspan="1" colspan="1">34.8</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec id="s2-5-2">
        <title>2.5.2 BERT-Based Neural Architecture for RE</title>
        <p>BERT (<xref rid="B12" ref-type="bibr">Devlin et al., 2018</xref>) is a transformer-based NLP model created and published in 2018 by Devlin et al. at Google. The original BERT model has two versions: Bert<sub><italic>base</italic></sub> and Bert<sub><italic>large</italic></sub>. The former consists of a stack of 12 transformer encoders with 12 self-attention headers, and the latter includes 24 encoders with 16 self-attention headers. Each transformer encoder consists of a self-attention layer with multiple heads and a feed-forward layer. A self-attention head projects a sequence of input tokens into a latent space to capture the semantic dependency between the tokens. The output of the self-attention layer is normalized, aggregated, and passed through a feed-forward layer to produce a vector, namely, the hidden state, which is the output of the transformer encoder. The paths the tokens take to flow through the encoder can be partially executed in parallel, which allows the training and inference of the neural network to be accelerated. In this study, we adopt Bert<sub><italic>base</italic></sub>, which is pre-trained on BooksCorpus (<xref rid="B29" ref-type="bibr">Pechenick et al., 2015</xref>) (800M words) and on English Wikipedia (2,500M words). BERT adopts two unique pre-training techniques, i.e., masked-language modeling (MLM) and next sentence prediction (NSP), both of which are self-supervised. MLM works by randomly masking a fraction of tokens in the input sentence and training the model to predict the missing ones, while NSP trains BERT to predict the follow-up sentence given an input sentence. Both MLM and NSP aim to help BERT better understand the style of unstructured human language by optimizing the loss function of self-training and adjusting the model parameters. BERT has achieved the state-of-the-art (SOTA) performance in a variety of NLP tasks (<xref rid="B12" ref-type="bibr">Devlin et al., 2018</xref>) and yielded a spectrum of variants (<xref rid="B5" ref-type="bibr">Beltagy et al., 2019</xref>; <xref rid="B32" ref-type="bibr">Sanh et al., 2019</xref>; <xref rid="B21" ref-type="bibr">Lee et al., 2020</xref>).</p>
        <p><xref rid="F5" ref-type="fig">Figure 5</xref> describes the neural architecture of the BERT-based model for the herb RE task. Each input instance contains two strings, including sentences A and B, separated by a [sep] token. Sentence A is a concatenation of the title and abstract of a PubMed article, and sentence B contains an entity pair linked by a space character. The input passes through a stack of embedding layers for token, sentence, and positional embedding, transforming the original text to numeric vectors, which are further fed into a series of transformer encoders (<xref rid="B39" ref-type="bibr">Vaswani et al., 2017</xref>), where the neural parameters are updated via its unique self-attention mechanism. Lastly, the output of the <italic>N</italic>th transformer layer passes through a dense and classification (also softmax) layer to generate the prediction result, which is a six-dimensional normalized vector that encodes the confidence scores for each relation type. During training, the predicted and ground truth values are fed into a cross entropy loss function to calculate the loss for back-propagation.</p>
        <fig position="float" id="F5">
          <label>FIGURE 5</label>
          <caption>
            <p>Neural architecture of BERT-based RE model. The input consists of sentence <bold>(A,B)</bold>, in which A is a concatenation of the title and the abstract content, and <bold>(B)</bold> includes the head and tail entity mentions. <bold>(A)</bold> (sep) token is placed at the end of each sentence as a separator. The input is processed through token, sentence, and positional embedding layers and then fed into a sequence of transformer encoder layers. Lastly, the output of the <italic>N</italic>th transformer passes a dense and a classification (softmax) layer to generate the prediction result.</p>
          </caption>
          <graphic xlink:href="fgene-13-799349-g005" position="float"/>
        </fig>
        <p>We investigated BERT and two BERT variants, namely, BioBERT and SciBERT, to develop the benchmark models for the herb RE task.<list list-type="simple"><list-item><p>• BioBERT (<xref rid="B21" ref-type="bibr">Lee et al., 2020</xref>) is a BERT variant pre-trained on PubMed articles for adapting the biomedical domain. BioBERT has been pre-trained on a large biomedical corpus with over a million PubMed articles, leading to superior performance in a variety of biomedical NLP tasks, compared to BERT and other pre-training models (<xref rid="B21" ref-type="bibr">Lee et al., 2020</xref>).</p></list-item><list-item><p>• SciBERT (<xref rid="B5" ref-type="bibr">Beltagy et al., 2019</xref>) is another BERT varient pre-trained on a corpus consisting of 1.14M full text scientific papers with 3.1B tokens collected from semanticscholar. org. As shown in (<xref rid="B5" ref-type="bibr">Beltagy et al., 2019</xref>), SciBERT has achieved SOTA performance in numerous NLP tasks in the scientific domain.</p></list-item></list>
</p>
      </sec>
    </sec>
    <sec id="s2-6">
      <title>2.6 Performance Boosters</title>
      <p>A big challenge faced by the RE task is the lack of training resources due to the high annotation cost that has to involve a human expert. Therefore, the RE model cannot absorb sufficient domain knowledge to always make the correct prediction. Two strategies, including fine-tuning and data augmentation, have been adopted to enhance the model’s learning capability in the context of herbal-molecular medicine.</p>
      <sec id="s2-6-1">
        <title>2.6.1 Fine-Tuning on Domain Resources</title>
        <p>BERT, SciBERT, and BioBERT have been sufficiently pre-trained on different types of domain resources, namely, on general English texts, general scientific articles, and biomedical articles, respectively. Due to the disparity of domains, BERT and its two variants have learned different knowledge, which could lead to misclassification when applied to the domain of herbal-molecular medicine. Therefore, we conduct fine-tuning for all three models on the 516K PubMed abstracts to inject more domain knowledge into the models. The tuned models are then further trained to tackle the downstream RE task.</p>
      </sec>
      <sec id="s2-6-2">
        <title>2.6.2 Substitution-Based Generative Augmentation</title>
        <p>We employ a GPT-2-based generative model to generate synthetic samples to enhance the quantity and diversity of the training data. <xref rid="F6" ref-type="fig">Figure 6</xref> depicts the data augmentation mechanism, which includes the following steps.<list list-type="simple"><list-item><p>• Corpus preparation. GPT-2 is a pre-trained generative model that can produce generic English sentences. To satisfy our requirements, GPT-2 needs to be fine-tuned on a corpus relevant to our RE task. Thus, the first is to prepare a corpus with textual resources that 1) are in the domain of herbal-molecular medicine and 2) present the entities and relations pre-defined in the herb ontology. Intuitively, we extract such sentences from the annotated dataset described in <xref rid="s2-5-1" ref-type="sec">Section 2.5.1</xref> based on one condition, namely, the sentence must contain at least a pair of entities that present one of the pre-defined relation categories. For example, the sentence “Cinnamaldehyde induces apoptosis via inhibition of the PI3K/Akt signaling pathway.” presents a CAG relation, is an ideal candidate to be added to the corpus. Since there are five relation types, five corpora are needed.</p></list-item><list-item><p>• Substitution I. For each sentence in each corpus, we apply a transformation by substituting each entity mention in the sentence with a type token. For example, the sentence in the above item becomes “[Chemical] induces apoptosis via inhibition of the [Gene] signaling pathway.” after the substitution. This step allows GPT-2 to focus on the semantic relations between generic entity types rather than particular entity mentions.</p></list-item><list-item><p>• Fine-tuning GPT-2. After substitution I, we send each corpus to fine-tune a GPT-2 model. The tuned GPT-2 model can generate sentences that are both semantically and syntactically similar to the ones in the input corpus. For instance, a generated sentence may look like “[Chemical] reduced myocardial infarction area and attenuated [Gene] production.”</p></list-item><list-item><p>• Substitution II. The generated samples are passed through another substitution block, which samples a pair of entities with known relations from an entity database (i.e., entity DB in the Figure) to replace the type token, namely, the placeholder, yielding the final augmented sample with the correct entity and relation annotation. The generated sentence from the previous item can become “Flavonoids reduced myocardial infarction area and attenuated TNF-alpha production.” which encodes a CAG relation between the entities in bold. The output of this module can be used to train the BERT-like models for the RE task.</p></list-item></list>
</p>
        <fig position="float" id="F6">
          <label>FIGURE 6</label>
          <caption>
            <p>Substitution-based generative model for data augmentation. Blue boxes refer to text samples, green rounded boxes are procedures, and orange rounded boxes are models.</p>
          </caption>
          <graphic xlink:href="fgene-13-799349-g006" position="float"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec id="s3">
    <title>3 Experiments and Results</title>
    <p>All experiments were implemented using Python 3.6.7 and PyTorch 1.7.1 and conducted on a Windows 10 workstation with an i7-10875h CPU and a Tesla V100 16G GPU. We chose BERT base, which has 12 layers of encoders with a hidden size of 768, 12 attention heads, and 110M trainable parameters. As such, we choose the BERT base version for both SciBERT and BioBERT to conduct a comparable experiment.</p>
    <sec id="s3-1">
      <title>3.1 RE Task Evaluation</title>
      <p>We focus on the evaluation of the RE module for two reasons: 1) we adopted an existing NER model whose performance has been extensively evaluated in the original paper (<xref rid="B43" ref-type="bibr">Wei et al., 2019</xref>); 2) the outputs of the RE model are directly added into the HerbKG, which determines the quality of the KG.</p>
      <sec id="s3-1-1">
        <title>3.1.1 RE Performance Metric</title>
        <p>Given a highly imbalanced RE dataset, accuracy is not an adequate metric since the model is encouraged to classify examples into the major classes and can still achieve a decent accuracy. A better metric to deal with class imbalance is the F1 score, which is defined as the harmonic mean of precision (Pre) and recall (Rec). Also, Pre and Rec are useful metrics since they are two inverse indicators of false alarms and missed instances, respectively. With the given true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN), the definitions of Pre, Rec, and F1 are given in <xref rid="e1" ref-type="disp-formula">Eqs. 1</xref>–<xref rid="e3" ref-type="disp-formula">3</xref>. In addition, we choose the precision-recall area under the curve (PR AUC) as another important performance indicator, which is usually calculated by the average precision (AP) metric given in <xref rid="e4" ref-type="disp-formula">Eq 4</xref>, where precision <italic>P</italic> is expressed as a function of recall <italic>R</italic>, and AP is the average value of precision over the interval from <italic>R</italic> = 0 to <italic>R</italic> = 1. In other words, AP summarizes the PR curve as the weighted mean of precisions at each threshold, with the increase in recall from the previous threshold used as the weight, namely, <italic>R</italic>
<sub><italic>n</italic></sub> − <italic>R</italic>
<sub><italic>n</italic>−1</sub> in <xref rid="e4" ref-type="disp-formula">Eq 4</xref>.<disp-formula id="e1"><mml:math id="m3" overflow="scroll"><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mn>100</mml:mn><mml:mi>%</mml:mi></mml:math><label>(1)</label></disp-formula>
<disp-formula id="e2"><mml:math id="m4" overflow="scroll"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mn>100</mml:mn><mml:mi>%</mml:mi></mml:math><label>(2)</label></disp-formula>
<disp-formula id="e3"><mml:math id="m5" overflow="scroll"><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mn>100</mml:mn><mml:mi>%</mml:mi></mml:math><label>(3)</label></disp-formula>
<disp-formula id="e4"><mml:math id="m6" overflow="scroll"><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mi>P</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi>r</mml:mi><mml:mo>≈</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munder><mml:mfenced open="(" close=")"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math><label>(4)</label></disp-formula>
</p>
      </sec>
      <sec id="s3-1-2">
        <title>3.1.2 Hyperparameter Tuning</title>
        <p>Since the three benchmark RE models adopt the same neural architecture, it is convenient to tune the models with the same set of hyperparameters in the same predefined ranges, which are given in <xref rid="T4" ref-type="table">Table 4</xref>. We tuned four hyperparameters, including epoch, learning rate, loss function, and optimizer, which are commonly used in prior efforts (<xref rid="B22" ref-type="bibr">Lee and Hsiang, 2019</xref>; <xref rid="B27" ref-type="bibr">Mosbach et al., 2020</xref>). For the number of epochs, we chose the odd numbers less than ten. Since the models have been extensively pre-trained, fine-tuning them for a downstream task would be fast (<xref rid="B55" ref-type="bibr">Zhu et al., 2021</xref>). For the learning rate, we chose four values including 0.0001, 0.0003, 0.001, 0.003, and 0.01. In practice, a large learning rate may bring difficulty in model convergence due to overshooting, and a small learning rate may lead to slow convergence (<xref rid="B16" ref-type="bibr">Goodfellow et al., 2016</xref>). For the loss function, we examined two options, including the standard cross entropy (CE), and the weighted CE. Since the class labels are imbalanced, using a weighted CE allows the algorithm to trade off recall and precision by up- or down-weighting the cost of a positive error relative to a negative error. Lastly, for the optimizer, we explored three options, including stochastic gradient descent (SGD), Adam, and SGD with Momentum. During training, SGD is computationally fast due to its frequent updates to the parameters; the Adam optimizer improves SGD by combining the AdaGrad and RMSProp algorithms to handle sparse gradients; adding momentum to SGD allows the optimization algorithm to accumulate the gradient used by the previous steps to calculate a better direction for the next step. A grid search is conducted based on the given ranges of hyperparameters to determine the optimal setting. <xref rid="T5" ref-type="table">Table 5</xref> shows the best hyperparameters for each model obtained from the grid search using F1 as the selection criterion. It is observed that all three models demonstrate an F1 of over 92%. The best model, BioBERT, presents an F1 of 94.37%. A detailed breakdown of the results is discussed in the next subsection.</p>
        <table-wrap position="float" id="T4">
          <label>TABLE 4</label>
          <caption>
            <p>Hyperparameter tuning range.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th align="left" rowspan="1" colspan="1">Hyperparameter</th>
                <th align="center" rowspan="1" colspan="1">Tuned Range</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1">Epoch</td>
                <td align="left" rowspan="1" colspan="1">[1, 3, 5, 7, 9]</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">LR</td>
                <td align="left" rowspan="1" colspan="1">[0.0001, 0.0003, 0.001, 0.003, 0.01]</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Loss</td>
                <td align="left" rowspan="1" colspan="1">[cross entropy, weighted cross entropy]</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Optimizer</td>
                <td align="left" rowspan="1" colspan="1">[SGD, Adam, Momentum]</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T5">
          <label>TABLE 5</label>
          <caption>
            <p>Optimal hyperparameter setting.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th align="left" rowspan="1" colspan="1">Hyperparameter</th>
                <th align="center" rowspan="1" colspan="1">BERT</th>
                <th align="center" rowspan="1" colspan="1">SciBERT</th>
                <th align="center" rowspan="1" colspan="1">BioBERT</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1">Epoch</td>
                <td align="center" rowspan="1" colspan="1">5</td>
                <td align="center" rowspan="1" colspan="1">3</td>
                <td align="center" rowspan="1" colspan="1">3</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">LR</td>
                <td align="center" rowspan="1" colspan="1">0.001</td>
                <td align="center" rowspan="1" colspan="1">0.001</td>
                <td align="center" rowspan="1" colspan="1">0.0003</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Loss</td>
                <td align="center" rowspan="1" colspan="1">CE</td>
                <td align="center" rowspan="1" colspan="1">CE</td>
                <td align="center" rowspan="1" colspan="1">CE</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Optimizer</td>
                <td align="center" rowspan="1" colspan="1">Adam</td>
                <td align="center" rowspan="1" colspan="1">Adam</td>
                <td align="center" rowspan="1" colspan="1">Adam</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">F1</td>
                <td align="center" rowspan="1" colspan="1">0.9265</td>
                <td align="center" rowspan="1" colspan="1">0.9344</td>
                <td align="center" rowspan="1" colspan="1">
                  <bold>0.9473</bold>
                </td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn>
              <p>The highest F1 score is marked in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec id="s3-1-3">
        <title>3.1.3 RE Performance Comparison</title>
        <p>We report a performance comparison on the RE task for BERT, SciBERT, and BioBERT using their base models in <xref rid="T6" ref-type="table">Tables 6–</xref>
<xref rid="T8" ref-type="table">8</xref> respectively. Each table is divided into two sections. The upper section is a confusion matrix that provides the exact RE classification results on the test set of the herb RE dataset, and the lower section presents the results in multiple metrics including TP, FP, FN, TN, Pre, Rec, and F1, which reflects the model performance from various aspects. We break down the result interpretation as follows.<list list-type="simple"><list-item><p>• The overall ranking of the three models is BioBERT, SciBERT, and BERT, with an F1 of 94.7, 93.4, and 92.6%, respectively. This result is reasonable, since the three versions are pre-trained on corpora of different domains. BERT, SciBERT, and BioBERT are pre-trained on general English articles, scientific articles, and biomedical (i.e., PubMed) articles, presenting a narrower but more focused domain. It is clear that BioBERT has obtained extensive biomedical domain knowledge that well fits the herb RE task, leading to superior performance.</p></list-item><list-item><p>• The three minor relation types, namely, CAG, CAD, and GID, present worse performance due to insufficient training instances. Taking CAG as an example, there are only 16 instances in the test set. The BERT model throws two false alarms (the actual relations are HHC and HTD) and misclassifies three CAG instances into HHC (two cases) and CAD (one case), resulting in 13 instances correctly predicted. SciBERT fixes one error prediction (CAG misclassified as HHC) made by BERT. On the other hand, BioBERT eliminates all three false alarms, leading to a gain of 5.8% in F1, compared to BERT. Similar observations can be made for other relation types. In other words, BioBERT results in consistent performance gain across the individual relation types, demonstrating its superiority in the herb RE task.</p></list-item></list>
</p>
        <table-wrap position="float" id="T6">
          <label>TABLE 6</label>
          <caption>
            <p>BERT performance.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th align="center" rowspan="1" colspan="1">CAG</th>
                <th align="center" rowspan="1" colspan="1">HHC</th>
                <th align="center" rowspan="1" colspan="1">HTD</th>
                <th align="center" rowspan="1" colspan="1">CAD</th>
                <th align="center" rowspan="1" colspan="1">GID</th>
                <th align="center" rowspan="1" colspan="1">Neg</th>
                <th align="center" rowspan="1" colspan="1">Total</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1">CAG</td>
                <td align="char" char="." rowspan="1" colspan="1">13</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">16</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">HHC</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">338</td>
                <td align="char" char="." rowspan="1" colspan="1">6</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">346</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">HTD</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">5</td>
                <td align="char" char="." rowspan="1" colspan="1">191</td>
                <td align="char" char="." rowspan="1" colspan="1">3</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">201</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">CAD</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">64</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">68</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GID</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">4</td>
                <td align="char" char="." rowspan="1" colspan="1">25</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">29</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Neg</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">220</td>
                <td align="char" char="." rowspan="1" colspan="1">224</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">TP</td>
                <td align="char" char="." rowspan="1" colspan="1">13</td>
                <td align="char" char="." rowspan="1" colspan="1">338</td>
                <td align="char" char="." rowspan="1" colspan="1">191</td>
                <td align="char" char="." rowspan="1" colspan="1">64</td>
                <td align="char" char="." rowspan="1" colspan="1">25</td>
                <td align="char" char="." rowspan="1" colspan="1">220</td>
                <td align="char" char="." rowspan="1" colspan="1">851</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">FP</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">10</td>
                <td align="char" char="." rowspan="1" colspan="1">9</td>
                <td align="char" char="." rowspan="1" colspan="1">9</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">33</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">FN</td>
                <td align="char" char="." rowspan="1" colspan="1">3</td>
                <td align="char" char="." rowspan="1" colspan="1">8</td>
                <td align="char" char="." rowspan="1" colspan="1">10</td>
                <td align="char" char="." rowspan="1" colspan="1">4</td>
                <td align="char" char="." rowspan="1" colspan="1">4</td>
                <td align="char" char="." rowspan="1" colspan="1">4</td>
                <td align="char" char="." rowspan="1" colspan="1">33</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">TN</td>
                <td align="char" char="." rowspan="1" colspan="1">838</td>
                <td align="char" char="." rowspan="1" colspan="1">513</td>
                <td align="char" char="." rowspan="1" colspan="1">660</td>
                <td align="char" char="." rowspan="1" colspan="1">787</td>
                <td align="char" char="." rowspan="1" colspan="1">826</td>
                <td align="char" char="." rowspan="1" colspan="1">631</td>
                <td align="char" char="." rowspan="1" colspan="1">4,255</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Pre</td>
                <td align="char" char="." rowspan="1" colspan="1">86.7%</td>
                <td align="char" char="." rowspan="1" colspan="1">97.1%</td>
                <td align="char" char="." rowspan="1" colspan="1">95.5%</td>
                <td align="char" char="." rowspan="1" colspan="1">87.7%</td>
                <td align="char" char="." rowspan="1" colspan="1">92.6%</td>
                <td align="char" char="." rowspan="1" colspan="1">99.5%</td>
                <td align="char" char="." rowspan="1" colspan="1">93.2%</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Rec</td>
                <td align="char" char="." rowspan="1" colspan="1">81.3%</td>
                <td align="char" char="." rowspan="1" colspan="1">97.7%</td>
                <td align="char" char="." rowspan="1" colspan="1">95.0%</td>
                <td align="char" char="." rowspan="1" colspan="1">94.1%</td>
                <td align="char" char="." rowspan="1" colspan="1">86.2%</td>
                <td align="char" char="." rowspan="1" colspan="1">98.2%</td>
                <td align="char" char="." rowspan="1" colspan="1">92.1%</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">F1</td>
                <td align="char" char="." rowspan="1" colspan="1">83.9%</td>
                <td align="char" char="." rowspan="1" colspan="1">97.4%</td>
                <td align="char" char="." rowspan="1" colspan="1">95.3%</td>
                <td align="char" char="." rowspan="1" colspan="1">90.8%</td>
                <td align="char" char="." rowspan="1" colspan="1">89.3%</td>
                <td align="char" char="." rowspan="1" colspan="1">98.9%</td>
                <td align="char" char="." rowspan="1" colspan="1">92.6%</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T7">
          <label>TABLE 7</label>
          <caption>
            <p>SciBERT performance.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th align="center" rowspan="1" colspan="1">CAG</th>
                <th align="center" rowspan="1" colspan="1">HHC</th>
                <th align="center" rowspan="1" colspan="1">HTD</th>
                <th align="center" rowspan="1" colspan="1">CAD</th>
                <th align="center" rowspan="1" colspan="1">GID</th>
                <th align="center" rowspan="1" colspan="1">Neg</th>
                <th align="center" rowspan="1" colspan="1">Total</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1">CAG</td>
                <td align="char" char="." rowspan="1" colspan="1">14</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">16</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">HHC</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">338</td>
                <td align="char" char="." rowspan="1" colspan="1">5</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">346</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">HTD</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">5</td>
                <td align="char" char="." rowspan="1" colspan="1">191</td>
                <td align="char" char="." rowspan="1" colspan="1">3</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">201</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">CAD</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">66</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">68</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GID</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">4</td>
                <td align="char" char="." rowspan="1" colspan="1">25</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">29</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Neg</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">220</td>
                <td align="char" char="." rowspan="1" colspan="1">224</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">TP</td>
                <td align="char" char="." rowspan="1" colspan="1">14</td>
                <td align="char" char="." rowspan="1" colspan="1">338</td>
                <td align="char" char="." rowspan="1" colspan="1">191</td>
                <td align="char" char="." rowspan="1" colspan="1">66</td>
                <td align="char" char="." rowspan="1" colspan="1">25</td>
                <td align="char" char="." rowspan="1" colspan="1">220</td>
                <td align="char" char="." rowspan="1" colspan="1">854</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">FP</td>
                <td align="char" char="." rowspan="1" colspan="1">3</td>
                <td align="char" char="." rowspan="1" colspan="1">8</td>
                <td align="char" char="." rowspan="1" colspan="1">8</td>
                <td align="char" char="." rowspan="1" colspan="1">9</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">30</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">FN</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">8</td>
                <td align="char" char="." rowspan="1" colspan="1">10</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">4</td>
                <td align="char" char="." rowspan="1" colspan="1">4</td>
                <td align="char" char="." rowspan="1" colspan="1">30</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">TN</td>
                <td align="char" char="." rowspan="1" colspan="1">840</td>
                <td align="char" char="." rowspan="1" colspan="1">516</td>
                <td align="char" char="." rowspan="1" colspan="1">663</td>
                <td align="char" char="." rowspan="1" colspan="1">788</td>
                <td align="char" char="." rowspan="1" colspan="1">829</td>
                <td align="char" char="." rowspan="1" colspan="1">634</td>
                <td align="char" char="." rowspan="1" colspan="1">4,270</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Pre</td>
                <td align="char" char="." rowspan="1" colspan="1">82.4%</td>
                <td align="char" char="." rowspan="1" colspan="1">97.7%</td>
                <td align="char" char="." rowspan="1" colspan="1">96.0%</td>
                <td align="char" char="." rowspan="1" colspan="1">88.0%</td>
                <td align="char" char="." rowspan="1" colspan="1">96.2%</td>
                <td align="char" char="." rowspan="1" colspan="1">99.5%</td>
                <td align="char" char="." rowspan="1" colspan="1">93.3%</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Rec</td>
                <td align="char" char="." rowspan="1" colspan="1">87.5%</td>
                <td align="char" char="." rowspan="1" colspan="1">97.7%</td>
                <td align="char" char="." rowspan="1" colspan="1">95.0%</td>
                <td align="char" char="." rowspan="1" colspan="1">97.1%</td>
                <td align="char" char="." rowspan="1" colspan="1">86.2%</td>
                <td align="char" char="." rowspan="1" colspan="1">98.2%</td>
                <td align="char" char="." rowspan="1" colspan="1">93.6%</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">F1</td>
                <td align="char" char="." rowspan="1" colspan="1">84.8%</td>
                <td align="char" char="." rowspan="1" colspan="1">97.7%</td>
                <td align="char" char="." rowspan="1" colspan="1">95.5%</td>
                <td align="char" char="." rowspan="1" colspan="1">92.3%</td>
                <td align="char" char="." rowspan="1" colspan="1">90.9%</td>
                <td align="char" char="." rowspan="1" colspan="1">98.9%</td>
                <td align="char" char="." rowspan="1" colspan="1">93.4%</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <table-wrap position="float" id="T8">
          <label>TABLE 8</label>
          <caption>
            <p>BioBERT performance.</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th align="left" rowspan="1" colspan="1"/>
                <th align="center" rowspan="1" colspan="1">CAG</th>
                <th align="center" rowspan="1" colspan="1">HHC</th>
                <th align="center" rowspan="1" colspan="1">HTD</th>
                <th align="center" rowspan="1" colspan="1">CAD</th>
                <th align="center" rowspan="1" colspan="1">GID</th>
                <th align="center" rowspan="1" colspan="1">Neg</th>
                <th align="center" rowspan="1" colspan="1">Total</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1">CAG</td>
                <td align="char" char="." rowspan="1" colspan="1">13</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">16</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">HHC</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">341</td>
                <td align="char" char="." rowspan="1" colspan="1">5</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">346</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">HTD</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">5</td>
                <td align="char" char="." rowspan="1" colspan="1">192</td>
                <td align="char" char="." rowspan="1" colspan="1">3</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">201</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">CAD</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">66</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">68</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">GID</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">4</td>
                <td align="char" char="." rowspan="1" colspan="1">25</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">29</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Neg</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">221</td>
                <td align="char" char="." rowspan="1" colspan="1">224</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">TP</td>
                <td align="char" char="." rowspan="1" colspan="1">13</td>
                <td align="char" char="." rowspan="1" colspan="1">341</td>
                <td align="char" char="." rowspan="1" colspan="1">192</td>
                <td align="char" char="." rowspan="1" colspan="1">66</td>
                <td align="char" char="." rowspan="1" colspan="1">25</td>
                <td align="char" char="." rowspan="1" colspan="1">221</td>
                <td align="char" char="." rowspan="1" colspan="1">858</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">FP</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">9</td>
                <td align="char" char="." rowspan="1" colspan="1">8</td>
                <td align="char" char="." rowspan="1" colspan="1">8</td>
                <td align="char" char="." rowspan="1" colspan="1">0</td>
                <td align="char" char="." rowspan="1" colspan="1">1</td>
                <td align="char" char="." rowspan="1" colspan="1">26</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">FN</td>
                <td align="char" char="." rowspan="1" colspan="1">3</td>
                <td align="char" char="." rowspan="1" colspan="1">5</td>
                <td align="char" char="." rowspan="1" colspan="1">9</td>
                <td align="char" char="." rowspan="1" colspan="1">2</td>
                <td align="char" char="." rowspan="1" colspan="1">4</td>
                <td align="char" char="." rowspan="1" colspan="1">3</td>
                <td align="char" char="." rowspan="1" colspan="1">26</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">TN</td>
                <td align="char" char="." rowspan="1" colspan="1">845</td>
                <td align="char" char="." rowspan="1" colspan="1">517</td>
                <td align="char" char="." rowspan="1" colspan="1">666</td>
                <td align="char" char="." rowspan="1" colspan="1">792</td>
                <td align="char" char="." rowspan="1" colspan="1">833</td>
                <td align="char" char="." rowspan="1" colspan="1">637</td>
                <td align="char" char="." rowspan="1" colspan="1">4,290</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Pre</td>
                <td align="char" char="." rowspan="1" colspan="1">100.0%</td>
                <td align="char" char="." rowspan="1" colspan="1">97.4%</td>
                <td align="char" char="." rowspan="1" colspan="1">96.0%</td>
                <td align="char" char="." rowspan="1" colspan="1">89.2%</td>
                <td align="char" char="." rowspan="1" colspan="1">100.0%</td>
                <td align="char" char="." rowspan="1" colspan="1">99.5%</td>
                <td align="char" char="." rowspan="1" colspan="1">97.0%</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">Rec</td>
                <td align="char" char="." rowspan="1" colspan="1">81.3%</td>
                <td align="char" char="." rowspan="1" colspan="1">98.6%</td>
                <td align="char" char="." rowspan="1" colspan="1">95.5%</td>
                <td align="char" char="." rowspan="1" colspan="1">97.1%</td>
                <td align="char" char="." rowspan="1" colspan="1">86.2%</td>
                <td align="char" char="." rowspan="1" colspan="1">98.7%</td>
                <td align="char" char="." rowspan="1" colspan="1">92.9%</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">F1</td>
                <td align="char" char="." rowspan="1" colspan="1">89.7%</td>
                <td align="char" char="." rowspan="1" colspan="1">98.0%</td>
                <td align="char" char="." rowspan="1" colspan="1">95.8%</td>
                <td align="char" char="." rowspan="1" colspan="1">93.0%</td>
                <td align="char" char="." rowspan="1" colspan="1">92.6%</td>
                <td align="char" char="." rowspan="1" colspan="1">99.1%</td>
                <td align="char" char="." rowspan="1" colspan="1">94.7%</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>The results presented in <xref rid="T6" ref-type="table">Tables 6–</xref>
<xref rid="T8" ref-type="table">8</xref> are from the base models of BERT, SciBERT, and BioBERT without any boosting strategy applied. <xref rid="F7" ref-type="fig">Figures 7</xref>, <xref rid="F8" ref-type="fig">8</xref> show the performance scores in F1 and AP for the three models. Specifically, for each model, we incrementally apply the two boosters, namely, fine-tuning and data augmentation, yielding six models. Our observations on the results are as follows.<list list-type="simple"><list-item><p>• Both fine-tuning and data augmentation have demonstrated consistent performance gains for all three models, validating the effectiveness of the boosting strategies in the given context. The best model, namely, the fine-tuned BioBERT further trained on the augmented dataset, presents an F1 score of 95.9%.</p></list-item><list-item><p>• Fine-tuning has boosted the F1 by 1.1, 0.8, and 0.7%, for BERT, SciBERT, and BioBERT, respectively. It is observed that the gain reduces as the model moves from BERT to BioBERT, which can be explained from the perspective of the domain resources used for pre-training. BERT was pre-trained on generic English texts, which is distant from the domain of herbal-molecular medicine in this study. On the other hand, BioBERT has already been trained on PubMed articles, which are highly relevant to the domain for our task. Whereas SciBERT is somewhere in the middle. Therefore, fine-tuning BERT led to the most performance gain since more domain knowledge can be injected and transferred to the downstream task. In contrast, BioBERT does not benefit too much from the fine-tuning, because most syntactic and semantic patterns (i.e., domain knowledge) have been seen and learned during pre-training.</p></list-item><list-item><p>• Adding data augmentation on top of the three tuned models also brings consistent improvements, yielding a gain of 0.6, 0.9, and 0.5%, for BERT, SciBERT, and BioBERT, respectively. The gain is minor due to the strategy taken to generate the synthetic samples. As described in <xref rid="s2-6-2" ref-type="sec">Section 2.6.2</xref>, a sentence is selected to fine-tune GPT-2 only if it contains two entity types with a known relation. As a result, the chosen sentences are generally short and only present intra-sentence relations. However, most of the hard cases are samples with inter-sentence relations. In other words, two entities may span multiple sentences to present a relation. Fortunately, these hard cases are rare in the abstracts of scientific papers. In fact, most authors tend to use concise and clear sentences to present scientific findings, which is good news for our RE task.</p></list-item><list-item><p>• Similar observations can be obtained from <xref rid="F8" ref-type="fig">Figure 8</xref> regarding the effects of fine-tuning and data augmentation on AP. The addition of fine-tuning brings up the AP by 0.6, 1.5, and 1.5% for the three base models, and the addition of data augmentation leads to a gain of 1.7, 0.6, and 0.7% for the three fine-tuned models. The gains have been consistent across for both metrics with all three models, validating the efficacy of the two boosters.</p></list-item></list>
</p>
        <fig position="float" id="F7">
          <label>FIGURE 7</label>
          <caption>
            <p>Performance comparison of BERT, SciBERT, and BioBERT in F1 score under three training settings: base model, with fine tuning (F. T.), and with F. T. and data augmentation (D. A.).</p>
          </caption>
          <graphic xlink:href="fgene-13-799349-g007" position="float"/>
        </fig>
        <fig position="float" id="F8">
          <label>FIGURE 8</label>
          <caption>
            <p>Performance comparison of BERT, SciBERT, and BioBERT in AP under three training settings: base model, with fine tuning (F. T.), and with F. T. and data augmentation (D. A.).</p>
          </caption>
          <graphic xlink:href="fgene-13-799349-g008" position="float"/>
        </fig>
      </sec>
      <sec id="s3-1-4">
        <title>3.1.4 Token Importance Evaluation</title>
        <p>In this section, we discuss how BioBERT is trained to learn the relations using several qualitative results to gain a deeper understanding on the impacts of individual tokens on the determination of a relation. The process is as follows. For each instance in the test set, only sentences that contain both head and tail entities are kept and saved in a list. Let <italic>s</italic> = [<italic>t</italic>
<sub>1</sub>, <italic>t</italic>
<sub>2</sub>, <italic>…</italic> , <italic>t</italic>
<sub><italic>n</italic></sub>] denote an extracted sentence with <italic>n</italic> tokens <italic>t</italic>
<sub>1</sub>, <italic>…</italic> , <italic>t</italic>
<sub><italic>n</italic></sub>. Our goal is to calculate a score that measures the impact of each individual token on the relation of an entity pair. Specifically, we first pass <italic>s</italic> through the fine-tuned BioBERT model to obtain a score denoted by <italic>c</italic>
<sub>*</sub>, which represents the probability that <italic>s</italic> is classified into the correct relation type. Thereafter a loop is employed to iterate through <italic>s</italic> token by token. For the <italic>i</italic>th iteration, token <italic>t</italic>
<sub><italic>i</italic></sub> is replaced by a meaningless token <italic>t</italic>′, and the modified sentence is passed through the same BioBERT model once again to obtain another score denoted by <italic>c</italic>
<sub><italic>i</italic></sub>. The score difference, denoted by <italic>d</italic>
<sub><italic>i</italic></sub> = <italic>c</italic>
<sub>*</sub> − <italic>c</italic>
<sub><italic>i</italic></sub>, reflects the importance of token <italic>t</italic>
<sub><italic>i</italic></sub>. In other words, the larger the <italic>d</italic>
<sub><italic>i</italic></sub>, the more greatly the confidence score drops, thus, the more important <italic>t</italic>
<sub><italic>i</italic></sub> is. <xref rid="F9" ref-type="fig">Figure 9</xref> shows an example where <italic>d</italic>
<sub><italic>i</italic></sub> is obtained for each token <italic>i</italic>. The sentence is extracted from an instance in the test set and expresses a HHC relation between “cassia bark” and “cinnamaldehyde”. It is observed that tokens that receive high importance scores fall into two categories: 1) tokens such as “cassia”, “barks”, and “cinnamaldehyde” are parts of the entities that are obviously important; 2) tokens such as “contained” and “contents” are the keywords that semantically determine the relation type. For the latter case, it is noted that BioBERT can effectively learn and quantify the impacts of tokens in a given instance, demonstrating its superior capability of semantic reasoning.</p>
        <fig position="float" id="F9">
          <label>FIGURE 9</label>
          <caption>
            <p>An examination of token importance in the determination of a relation type. The example shows in the figure is correctly classified by the BioBERT-based RE model, which outputs a triplet (“cassia bark”, “cinnamaldehyde”, “HHC”) as an entry in the HerbKG.</p>
          </caption>
          <graphic xlink:href="fgene-13-799349-g009" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec id="s3-2">
      <title>3.2 The Constructed HerbKG</title>
      <p>The proposed system analyzed a total of 516,393 PubMed abstracts and identified 4,130 herbs, 6,331 chemicals, 2,187 diseases, and 2,641 genes, with 53,754 distinct relations, including 19,872 HHC, 13,627 HTD, 9,984 CAD, 3,353 CAG, and 6,918 GID relations. A subgraph of HerbKG (stored using the Neo4j graph database (<xref rid="B42" ref-type="bibr">Webber, 2012</xref>)) is shown in <xref rid="F10" ref-type="fig">Figure 10</xref>, which consists of one herb entity, three chemical, eleven gene, and three disease entities. Also, the subgraph includes three HHC, eleven CAG, six GID, and three CAD relations. It is noted that only three abstracts were processed through the proposed learning pipeline to generate this subgraph.</p>
      <fig position="float" id="F10">
        <label>FIGURE 10</label>
        <caption>
          <p>The extracted graph for herb “Sophora flavescens” is a subgraph of HerbKG, in which Herb, Chemical, Gene, and Disease entities are marked in red, tan, green, and pink, repsectively.</p>
        </caption>
        <graphic xlink:href="fgene-13-799349-g010" position="float"/>
      </fig>
    </sec>
    <sec id="s3-3">
      <title>3.3 Downstream Applications</title>
      <p>This subsection covers four categories of downstream applications with several case studies to demonstrate the potential of HerbKG to provide data-driven and evidence-based knowledge support in pharmacology.</p>
      <sec id="s3-3-1">
        <title>3.3.1 Descriptive Analysis</title>
        <p>An advantage of a KG is that data, as stored in entities and relations, can be easily visualized and presented to end users. Thus, knowledge visualization has been a basic feature for KG-based applications (<xref rid="B52" ref-type="bibr">Yu et al., 2017</xref>; <xref rid="B24" ref-type="bibr">Liu et al., 2018</xref>; <xref rid="B51" ref-type="bibr">Wise et al., 2020</xref>; <xref rid="B54" ref-type="bibr">Zheng et al., 2020</xref>). In addition, descriptive analysis, which helps describe, show or summarize data points, is desired in a dashboard interface that allows a user to quickly grasp a big picture of data. Statistical results can be customized, presented, and visualized (<xref rid="B37" ref-type="bibr">Su et al., 2021</xref>; <xref rid="B53" ref-type="bibr">Zheng et al., 2021</xref>). The core mission of HerbKG is to investigate the molecular mechanism of herbal medicine. Therefore, it is crucial to understand the physiological behavior of herbs in the treatment of diseases by regulating gene expression/function. At a high level, the HerbKG can provide the top-ranked herbs with the most related genes (<xref rid="F11" ref-type="fig">Figure 11A</xref>, the genes regulated by the most herb extracts (<xref rid="F11" ref-type="fig">Figure 11B</xref>, the herbs that can treat the most diseases (<xref rid="F11" ref-type="fig">Figure 11C</xref>), and the most treated diseases by herbs (<xref rid="F11" ref-type="fig">Figure 11D</xref>). It is observed that five herbs, including Methyl Salicylatum, Allium sativum, Andrographis Paniculata, Panax Ginseng, and Rhizoma Curcumae, appear in both list (a) and (c), indicating that the extracted chemicals from these herbs have been extensively experimented to validate their effects on the diseases at the molecular level. Also, it is found that three heat shock proteins, namely HSP70, HSP90, and GRP78, are among the top-ten genes in list (b). Heat-related proteins have shown significance in clinical trials, especially in cancer treatment. Other top-ranked genes include MCL-1 (related to Myeloid Leukemia), ACE2 (related to human coronavirus), SOD2 (related to idiopathic cardiomyopathy, premature aging, sporadic motor neuron disease, and cancer), and so on. In addition, the top-ranked diseases in list (d) include several deadliest diseases, such as various types of cancer, diabetes, Alzheimer’s disease, and lower respiratory infections (e.g., MERS). Meanwhile, herbs are used to treat a wide range of common diseases, such as cold, obesity, hypertension, cough, and diarrhea. In all, these statistical results can be displayed in a dashboard to help users gain a high-level understanding of the commonly studied herbs and their related genes and diseases.</p>
        <fig position="float" id="F11">
          <label>FIGURE 11</label>
          <caption>
            <p>Examples of descriptive analysis are shown. The HerbKG can provide the top-ranked herbs with the most related genes <bold>(A)</bold>, the genes regulated by the most herb extracts <bold>(B)</bold>, the herbs that can treat the most diseases <bold>(C)</bold>, and the most treated diseases by herbs <bold>(D)</bold>.</p>
          </caption>
          <graphic xlink:href="fgene-13-799349-g011" position="float"/>
        </fig>
      </sec>
      <sec id="s3-3-2">
        <title>3.3.2 Evidence-Based Graph Queries</title>
        <p>KGs that are built from scientific articles are supported by the research findings in the source articles. Since users of such KGs could be researchers, doctors, or clinical practitioners, providing an evidence for each query that points to the original source is a huge advantage. With this feature, users can be more convinced by the information found in the KG and can be easily re-directly to the first-hand resource (<xref rid="B26" ref-type="bibr">Miao et al., 2018</xref>; <xref rid="B53" ref-type="bibr">Zheng et al., 2021</xref>). In this study, each extracted relation in HerbKG is based on a sentence in an abstract. The sentence where both entities appear becomes the evidence supporting the relation. For example, <xref rid="T9" ref-type="table">Table 9</xref> shows a collection of relations learned from an abstract (PMID27882228), which is a study that investigated Oxymatrine (OMT), a component of Sophora flavescens, and its potential treatment for neurodegenerative diseases via the regulation of a set of genes. The test was done using our best model and achieved a satisfactory result, except that the CAG relation between OMT and myeloid differentiation factor (MYD)88 (last row of the table) was not detected due to the fact that the PubTator-based NER model failed to classify it as a gene in the first place. Each sentence that contains a detected relation was marked as a piece of evidence, and the relation is reinforced if it is supported by multiple evidence from different articles, meaning that the relation has been validated by more than one study and becomes more convinced. With this setup, a wide range of graph queries can be made. Since HerbKG is stored in a Neo4j graph database, a question should be first translated into a query statement in Cypher and sent to the Neo4j database engine; then a resulting subgraph is returned. For example, if our query were “find the top three most studied chemicals of Sophora flavescens and their related entities,” the result would be the entire graph in <xref rid="F10" ref-type="fig">Figure 10</xref>.</p>
        <table-wrap position="float" id="T9">
          <label>TABLE 9</label>
          <caption>
            <p>Case study: herbal-molecular knowledge extracted from an abstract (PMID27882228).</p>
          </caption>
          <table frame="hsides" rules="groups">
            <thead valign="top">
              <tr>
                <th align="left" rowspan="1" colspan="1">Entity [Type]</th>
                <th align="center" rowspan="1" colspan="1">Entity [Type]</th>
                <th align="center" rowspan="1" colspan="1">Relation</th>
                <th align="center" rowspan="1" colspan="1">Evidence</th>
              </tr>
            </thead>
            <tbody valign="top">
              <tr>
                <td align="left" rowspan="1" colspan="1">Sophora flavescens [Herb]</td>
                <td align="left" rowspan="1" colspan="1">Oxymatrine (OMT) [Chemical]</td>
                <td align="left" rowspan="1" colspan="1">HHC</td>
                <td align="left" rowspan="1" colspan="1">Oxymatrine (OMT) is an alkaloid extracted from Sophora flavescens...</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">OMT [Chemical]</td>
                <td align="left" rowspan="1" colspan="1">HSP60 [Gene]</td>
                <td align="left" rowspan="1" colspan="1">CAG</td>
                <td align="left" rowspan="1" colspan="1">Western blot analysis and ELISA showed that OMT decreased the expression and release of HSP60 by LPS-activated BV2 cells</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">OMT [Chemical]</td>
                <td align="left" rowspan="1" colspan="1">neurodegenerative diseases [Disease]</td>
                <td align="left" rowspan="1" colspan="1">CAD</td>
                <td align="left" rowspan="1" colspan="1">OMT may therefore offer substantial therapeutic potential for treating neurodegenerative diseases ...</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">OMT [Chemical]</td>
                <td align="left" rowspan="1" colspan="1">TLR-4 [Gene]</td>
                <td align="left" rowspan="1" colspan="1">CAG</td>
                <td align="left" rowspan="1" colspan="1">Flow cytometric analysis demonstrated that LPS treatment induced apoptosis of BV2 cells, which was inhibited by OMT in parallel with inhibition of LPS-induced expression of TLR-4</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">OMT [Chemical]</td>
                <td align="left" rowspan="1" colspan="1">caspase-3 [Gene], inducible nitric oxide synthase [Gene], tumor necrosis factor-<italic>α</italic> [Gene], interleukin (IL)-1<italic>β</italic> [Gene], IL-6 [Gene]</td>
                <td align="left" rowspan="1" colspan="1">CAG</td>
                <td align="left" rowspan="1" colspan="1">OMT was shown to suppress the levels of myeloid differentiation factor (MYD)88, nuclear factor (NF)-<italic>κ</italic>B, caspase-3, inducible nitric oxide synthase, tumor necrosis factor-<italic>α</italic>, interleukin (IL)-1<italic>β</italic> and IL-6</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
      <sec id="s3-3-3">
        <title>3.3.3 Similarity Analysis</title>
        <p>Similarity analysis in a KG is useful analytical method that measures the entity-entity or relation-relation similarity. Wang et al. utilize the Pearson correlation (<xref rid="B6" ref-type="bibr">Benesty et al., 2009</xref>) to represent the semantic similarity of herbs (<xref rid="B41" ref-type="bibr">Wang et al., 2019</xref>). Recent graph neural network (GNN) models facilitate this analysis by encoding a collection of relevant features into a node/relation embedding, which can be directly used for similarity calculation (<xref rid="B33" ref-type="bibr">Shen et al., 2019</xref>; <xref rid="B51" ref-type="bibr">Wise et al., 2020</xref>; <xref rid="B53" ref-type="bibr">Zheng et al., 2021</xref>). For example, Fokoue et al. adopt a GNN to compute drug similarity, which is used as a feature to predict drug-drug interaction. A unique value provided by HerbKG is the interplay between a herb-extracted chemical and a gene, which affects a disease. To quantify the similarity between two herbs in their biological functions, we focus on two aspects, namely, the shared set of genes they regulate and the shared set of diseases they may treat. Let <inline-formula id="inf3"><mml:math id="m7" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula id="inf4"><mml:math id="m8" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:math></inline-formula> denote the set of genes herb extract <italic>i</italic> can regulate and the set of diseases <italic>i</italic> may treat, respectively. The similarity between two herb extracts <italic>i</italic> and <italic>j</italic> is given as follows.<disp-formula id="equ1"><mml:math id="m9" overflow="scroll"><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mfenced open="(" close=")"><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋂</mml:mo><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munderover></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋃</mml:mo><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munderover></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋂</mml:mo><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munderover></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋃</mml:mo><mml:munderover accentunder="false" accent="false"><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:munderover></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:math></disp-formula>
</p>
        <p>Intuitively, the more related genes and diseases two chemicals share, the more similar they are. With this idea, we performed similarity analysis for “Nelumbo nucifera”, and found the top-five most similar herbs as follows: Acanthopanax senticosus (0.56), Scutellaria barbata (0.41), Litchi chinensis (0.39), Myristica fragrans (0.31), Kaempferia galanga (0.28), where the values in the brackets indicate the similarity scores. Understanding the bio-function similarity between herbs is an important first step for drug repositioning, discussed in the following subsection.</p>
      </sec>
      <sec id="s3-3-4">
        <title>3.3.4 Drug Repurposing</title>
        <p>Drug repurposing (or repositioning) aims to discover an existing drug’s new medical indications outside of the scope of its original usage (<xref rid="B56" ref-type="bibr">Zhu et al., 2020</xref>). KG-based drug repurposing aims to discover potential drug-target or drug-disease relations that do not currently exist in the KG (<xref rid="B8" ref-type="bibr">Boudin, 2020</xref>). Existing efforts have leveraged KGs to identify drugs for the treatment of Covid-19 (<xref rid="B1" ref-type="bibr">Al-Saleem et al., 2021</xref>) and rare diseases (<xref rid="B36" ref-type="bibr">Sosa et al., 2019</xref>). It is also noted that a drug-disease relation may be either direct or indirect, investigated in (<xref rid="B56" ref-type="bibr">Zhu et al., 2020</xref>), where different types of path between a drug and a disease are considered. On HerbKG, drug repositioning can be transformed to a link prediction problem that predicts a potential association between a chemical and a disease, which are not previously connected. We could use the following steps. First, a disease, say, the Parkinson’s disease is selected. Second, we locate the Parkinson’s disease in HerbKG as well as the its related herbs, chemicals, and genes. Third, the identified genes serve as starting point to find the associated chemicals that are not directly connected to the disease in HerbKG. These chemicals may be considered as drug candidates. However, if no such chemicals can be found, a signature matching process can be employed by comparing the biological profile (including information about structure, genetic and disease association, adverse effect, and graph properties, etc.) of a drug with that of another drug that is known to be used for treating the disease. In fact, matching is an operation that measures the similarity between chemicals, which can be done <italic>via</italic> machine learning. Specifically, such a learning model takes as input a chemical’s biological profile and the disease name and predicts a score that indicates the likelihood that the chemical can treat the disease. The current version of HerbKG has only encoded the knowledge of genetic and disease association, whereas more profile information for chemicals is needed to build an accurate model. In addition to the chemical-disease association, a more effective approach is to predict the chemical-gene interaction, given that most diseases are known to be caused by specific genes with aberrant expression patterns. Therefore, the top-ranked chemical-gene pairs can be generated by the predictive model and used for further validation to support the new usage of a drug.</p>
      </sec>
    </sec>
  </sec>
  <sec id="s4">
    <title>4 Discussion</title>
    <p>Recent advances have witnessed the prosperity of KGs, which can effectively represent knowledge in the physical world. Each KG is a semantic network that stores a collection of triplets, each of which encodes the relation between a pair of entities. KGs can support a wide range of applications, such as knowledge reasoning, information retrieval, question answering, and visualization. Also, domain specific KGs have received numerous interests from domain professionals and practitioners. A typical example is a biomedical KG, which allows doctors and researchers to mine and discover interplay between bio-entities, potentially accelerating the efficiency and improving the accuracy of current clinical practice.</p>
    <p>Traditional medicine that uses herbs for health care has been existing for over five thousand years. However, herbalism has been criticized for its insufficiently verified efficacy and safety in modern medicine research. Current herbal KGs mainly focus on the diagnosis and treatment side of herbalism that explore relations between herbs, symptoms, and treatments, rather than investigate it from the view point of molecular medicine. In the past decades, more researchers adopt modern approaches in molecular medicine to study how herbs and their extracted contents affect the biological functions of human body. Our investigation shows that this type of researches have not been extensively utilized in the KG community, opening a promising research direction.</p>
    <p>Our study aims to construct a KG to bridge herbal and molecular medicine. We propose HerbKG with four entities, namely, herbs, chemicals that are extracted from the herbs, diseases that can be treated by herb contents, and genes that are affected by the chemicals. Six relation types are defined to model the interplay between the entities. We develop a systematic framework to automate the construction of HerbKG by extracting relational triplets from PubMed abstracts. The proposed framework adopts an existing NER (i.e., PTC) model and a custom BERT-based RE model. The RE model is validated on a self-created herb RE dataset and demonstrates superior performance. The resulting HerbKG, after analyzing over 516K abstracts, is populated with 53,754 relations, offering valuable domain knowledge in herbalism from the molecular perspective.</p>
    <p>A key challenge for supervised learning in a domain-specific task is the lack of abundant training resource. This challenge is addressed with two unsupervised strategies in our work. The first strategy, fine-tuning on domain resources, is to encourage the BERT model to learn more domain knowledge. The second strategy, substitution-based generative augmentation, aims to generate synthetic training samples based on the existing expert-annotated ones. The mixing of supervised and unsupervised learning paradigms brings new opportunities to tackle the problem of KG construction.</p>
    <p>This study has the following limitations that will be addressed in future work. First, the RE task can be made more fine-grained. For example, the role of a chemical played in regulating a gene’s activity or function can be divided into several subclasses such as inhibitor, activator, antagonist, and agonist, etc. Fine-grained relations can enhance the knowledge granularity encoded by HerbKG and better support the downstream applications. Another direction is to explore existing data resources. After all, several well-known benchmarks that model either drug-drug, chemical-protein, or chemical-disease relations have been studied and can be utilized in model training. Lastly, more advanced downstream applications in drug discovery can be developed. Opportunities are twofold. One idea is to adopt a GNN model to better encode a wider spectrum of data properties, such as multi-omics, molecular structural, and graph properties, for entities and relations in HerbKG and facilitate the link prediction tasks like drug repurposing and target inference. Also, predicting the effect of drug combination could be a significant task that comes with a unique advantage in herbal medicine since drug compound has been a typical way of prescription in traditional herblism. As such, abundant training data can be gathered to train learning models.</p>
  </sec>
</body>
<back>
  <sec sec-type="data-availability" id="s5">
    <title>Data Availability Statement</title>
    <p>The datasets presented in this study can be found in online repositories. The names of the repository/repositories and accession number(s) can be found below: <ext-link xlink:href="https://github.com/FeiYee/HerbKG" ext-link-type="uri">https://github.com/FeiYee/HerbKG</ext-link>.</p>
  </sec>
  <sec id="s6">
    <title>Author Contributions</title>
    <p>Conceptualization and methodology, XZ, YG, and ZX; software, validation, and original draft preparation, XZ and YG; review and editing, XZ and ZX. All authors have read and agreed to the published version of the manuscript.</p>
  </sec>
  <sec sec-type="COI-statement" id="s7">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s8">
    <title>Publisher’s Note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Al-Saleem</surname><given-names>J.</given-names></name><name><surname>Granet</surname><given-names>R.</given-names></name><name><surname>Ramakrishnan</surname><given-names>S.</given-names></name><name><surname>Ciancetta</surname><given-names>N. A.</given-names></name><name><surname>Saveson</surname><given-names>C.</given-names></name><name><surname>Gessner</surname><given-names>C.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Knowledge Graph-Based Approaches to Drug Repurposing for Covid-19</article-title>. <source>J. Chem. Inf. Model.</source>
<volume>61</volume>, <fpage>4058</fpage>–<lpage>4067</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jcim.1c00642</pub-id>
<pub-id pub-id-type="pmid">34297570</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Auer</surname><given-names>S.</given-names></name><name><surname>Bizer</surname><given-names>C.</given-names></name><name><surname>Kobilarov</surname><given-names>G.</given-names></name><name><surname>Lehmann</surname><given-names>J.</given-names></name><name><surname>Cyganiak</surname><given-names>R.</given-names></name><name><surname>Ives</surname><given-names>Z.</given-names></name></person-group> (<year>2007</year>). “<article-title>Dbpedia: A Nucleus for a Web of Open Data</article-title>,” in <source>The Semantic Web</source> (<publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>722</fpage>–<lpage>735</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-540-76298-0_52</pub-id>
</mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Babu</surname><given-names>P. S.</given-names></name><name><surname>Prabuseenivasan</surname><given-names>S.</given-names></name><name><surname>Ignacimuthu</surname><given-names>S.</given-names></name></person-group> (<year>2007</year>). <article-title>Cinnamaldehyde-A Potential Antidiabetic Agent</article-title>. <source>Phytomedicine</source>
<volume>14</volume>, <fpage>15</fpage>–<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1016/j.phymed.2006.11.005</pub-id>
<pub-id pub-id-type="pmid">17140783</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bairoch</surname><given-names>A.</given-names></name></person-group> (<year>2018</year>). <article-title>The Cellosaurus, a Cell-Line Knowledge Resource</article-title>. <source>J. Biomol. Tech.</source>
<volume>29</volume>, <fpage>25</fpage>–<lpage>38</lpage>. <pub-id pub-id-type="doi">10.7171/jbt.18-2902-002</pub-id>
<pub-id pub-id-type="pmid">29805321</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beltagy</surname><given-names>I.</given-names></name><name><surname>Lo</surname><given-names>K.</given-names></name><name><surname>Cohan</surname><given-names>A.</given-names></name></person-group> (<year>2019</year>). <article-title>Scibert: A Pretrained Language Model for Scientific Text</article-title>. <comment>arXiv preprint arXiv:1903.10676</comment>. </mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Benesty</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>J.</given-names></name><name><surname>Huang</surname><given-names>Y.</given-names></name><name><surname>Cohen</surname><given-names>I.</given-names></name></person-group> (<year>2009</year>). “<article-title>Pearson Correlation Coefficient</article-title>,” in <source>Noise Reduction in Speech Processing</source> (<publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>1</fpage>–<lpage>4</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-642-00296-0_5</pub-id>
</mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bollacker</surname><given-names>K.</given-names></name><name><surname>Evans</surname><given-names>C.</given-names></name><name><surname>Paritosh</surname><given-names>P.</given-names></name><name><surname>Sturge</surname><given-names>T.</given-names></name><name><surname>Taylor</surname><given-names>J.</given-names></name></person-group> (<year>2008</year>). “<article-title>Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge</article-title>,” in <conf-name>Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data</conf-name>, <conf-loc>Vancouver, Canada</conf-loc>, <conf-date>June 9–12, 2008</conf-date>, <fpage>1247</fpage>–<lpage>1250</lpage>. </mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Boudin</surname><given-names>M.</given-names></name></person-group> (<year>2020</year>). “<article-title>Computational Approaches for Drug Repositioning: Towards a Holistic Perspective Based on Knowledge Graphs</article-title>,” in <conf-name>Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</conf-name>, <conf-date>October 2020</conf-date>, <fpage>3225</fpage>–<lpage>3228</lpage>. </mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brackman</surname><given-names>G.</given-names></name><name><surname>Defoirdt</surname><given-names>T.</given-names></name><name><surname>Miyamoto</surname><given-names>C.</given-names></name><name><surname>Bossier</surname><given-names>P.</given-names></name><name><surname>Van Calenbergh</surname><given-names>S.</given-names></name><name><surname>Nelis</surname><given-names>H.</given-names></name><etal/></person-group> (<year>2008</year>). <article-title>Cinnamaldehyde and Cinnamaldehyde Derivatives Reduce Virulence in Vibrio Spp. By Decreasing the Dna-Binding Activity of the Quorum Sensing Response Regulator Luxr</article-title>. <source>BMC Microbiol.</source>
<volume>8</volume>, <fpage>1</fpage>–<lpage>14</lpage>. <pub-id pub-id-type="doi">10.1186/1471-2180-8-149</pub-id>
<pub-id pub-id-type="pmid">18173832</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burstein</surname><given-names>H. J.</given-names></name><name><surname>Gelber</surname><given-names>S.</given-names></name><name><surname>Guadagnoli</surname><given-names>E.</given-names></name><name><surname>Weeks</surname><given-names>J. C.</given-names></name></person-group> (<year>1999</year>). <article-title>Use of Alternative Medicine by Women with Early-Stage Breast Cancer</article-title>. <source>N. Engl. J. Med.</source>
<volume>340</volume>, <fpage>1733</fpage>–<lpage>1739</lpage>. <pub-id pub-id-type="doi">10.1056/nejm199906033402206</pub-id>
<pub-id pub-id-type="pmid">10352166</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X.</given-names></name><name><surname>Jia</surname><given-names>S.</given-names></name><name><surname>Xiang</surname><given-names>Y.</given-names></name></person-group> (<year>2020</year>). <article-title>A Review: Knowledge Reasoning Over Knowledge Graph</article-title>. <source>Expert Syst. Appl.</source>
<volume>141</volume>, <fpage>112948</fpage>. <pub-id pub-id-type="doi">10.1016/j.eswa.2019.112948</pub-id>
</mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Devlin</surname><given-names>J.</given-names></name><name><surname>Chang</surname><given-names>M.-W.</given-names></name><name><surname>Lee</surname><given-names>K.</given-names></name><name><surname>Toutanova</surname><given-names>K.</given-names></name></person-group> (<year>2018</year>). <article-title>Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding</article-title>. <comment>arXiv preprint arXiv:1810.04805</comment>. </mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Egede</surname><given-names>L. E.</given-names></name><name><surname>Ye</surname><given-names>X.</given-names></name><name><surname>Zheng</surname><given-names>D.</given-names></name><name><surname>Silverstein</surname><given-names>M. D.</given-names></name></person-group> (<year>2002</year>). <article-title>The Prevalence and Pattern of Complementary and Alternative Medicine Use in Individuals with Diabetes</article-title>. <source>Diabetes Care</source>
<volume>25</volume>, <fpage>324</fpage>–<lpage>329</lpage>. <pub-id pub-id-type="doi">10.2337/diacare.25.2.324</pub-id>
<pub-id pub-id-type="pmid">11815504</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ernst</surname><given-names>P.</given-names></name><name><surname>Meng</surname><given-names>C.</given-names></name><name><surname>Siu</surname><given-names>A.</given-names></name><name><surname>Weikum</surname><given-names>G.</given-names></name></person-group> (<year>2014</year>). “<article-title>Knowlife: a Knowledge Graph for Health and Life Sciences</article-title>,” in <conf-name>2014 IEEE 30th International Conference on Data Engineering</conf-name>, <conf-loc>Chicago, IL</conf-loc>, <conf-date>March 31–April 4, 2014</conf-date> (<publisher-name>IEEE</publisher-name>), <fpage>1254</fpage>–<lpage>1257</lpage>. <pub-id pub-id-type="doi">10.1109/icde.2014.6816754</pub-id>
</mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Gong</surname><given-names>Z.</given-names></name><name><surname>Zhang</surname><given-names>N.</given-names></name><name><surname>He</surname><given-names>J.</given-names></name></person-group> (<year>2021</year>). “<article-title>Kgrn: Knowledge Graph Relational Path Network for Target Prediction of Tcm Prescriptions</article-title>,” in <conf-name>International Conference on Intelligent Computing</conf-name>, <conf-loc>Xi’an, China</conf-loc>, <conf-date>August 7–11, 2021</conf-date> (<publisher-name>Springer</publisher-name>), <fpage>148</fpage>–<lpage>161</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-84532-2_14</pub-id>
</mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Goodfellow</surname><given-names>I.</given-names></name><name><surname>Bengio</surname><given-names>Y.</given-names></name><name><surname>Courville</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>). <source>Deep Learning</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT press</publisher-name>. </mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Guarino</surname><given-names>N.</given-names></name><name><surname>Oberle</surname><given-names>D.</given-names></name><name><surname>Staab</surname><given-names>S.</given-names></name></person-group> (<year>2009</year>). “<article-title>What Is an Ontology?</article-title>,” in <source>Handbook on Ontologies</source>. Editors <person-group person-group-type="editor"><name><surname>Staab</surname><given-names>S.</given-names></name><name><surname>Studer</surname><given-names>R.</given-names></name></person-group> (<publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>1</fpage>–<lpage>17</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-540-92673-3_0</pub-id>
</mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kerdjoudj</surname><given-names>F.</given-names></name><name><surname>Curé</surname><given-names>O.</given-names></name></person-group> (<year>2015</year>). <article-title>Rdf Knowledge Graph Visualization from a Knowledge Extraction System</article-title>. <comment>arXiv preprint arXiv:1510.00244</comment>. </mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leaman</surname><given-names>R.</given-names></name><name><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2016</year>). <article-title>Taggerone: Joint Named Entity Recognition and Normalization with Semi-markov Models</article-title>. <source>Bioinformatics</source>
<volume>32</volume>, <fpage>2839</fpage>–<lpage>2846</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btw343</pub-id>
<pub-id pub-id-type="pmid">27283952</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>C. W.</given-names></name><name><surname>Lee</surname><given-names>S. H.</given-names></name><name><surname>Lee</surname><given-names>J. W.</given-names></name><name><surname>Ban</surname><given-names>J. O.</given-names></name><name><surname>Lee</surname><given-names>S. Y.</given-names></name><name><surname>Yoo</surname><given-names>H. S.</given-names></name><etal/></person-group> (<year>2007</year>). <article-title>2-hydroxycinnamaldehyde Inhibits Sw620 colon Cancer Cell Growth through Ap-1 Inactivation</article-title>. <source>J. Pharmacol. Sci.</source>
<volume>104</volume>, <fpage>19</fpage>–<lpage>28</lpage>. <pub-id pub-id-type="doi">10.1254/jphs.fp0061204</pub-id>
<pub-id pub-id-type="pmid">17510524</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>J.</given-names></name><name><surname>Yoon</surname><given-names>W.</given-names></name><name><surname>Kim</surname><given-names>S.</given-names></name><name><surname>Kim</surname><given-names>D.</given-names></name><name><surname>Kim</surname><given-names>S.</given-names></name><name><surname>So</surname><given-names>C. H.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>Biobert: A Pre-Trained Biomedical Language Representation Model for Biomedical Text Mining</article-title>. <source>Bioinformatics</source>
<volume>36</volume>, <fpage>1234</fpage>–<lpage>1240</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btz682</pub-id>
<pub-id pub-id-type="pmid">31501885</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>J.-S.</given-names></name><name><surname>Hsiang</surname><given-names>J.</given-names></name></person-group> (<year>2019</year>). <article-title>Patentbert: Patent Classification with fine-tuning a Pre-trained Bert Model</article-title>. <comment>arXiv preprint arXiv:1906.02124</comment>. </mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Teng</surname><given-names>Y.</given-names></name><name><surname>Liu</surname><given-names>S.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name><name><surname>Chen</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Cinnamaldehyde Affects the Biological Behavior of Human Colorectal Cancer Cells and Induces Apoptosis via Inhibition of the Pi3k/akt Signaling Pathway</article-title>. <source>Oncol. Rep.</source>
<volume>35</volume>, <fpage>1501</fpage>–<lpage>1510</lpage>. <pub-id pub-id-type="doi">10.3892/or.2015.4493</pub-id>
<pub-id pub-id-type="pmid">26677144</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Z.</given-names></name><name><surname>Peng</surname><given-names>E.</given-names></name><name><surname>Yan</surname><given-names>S.</given-names></name><name><surname>Li</surname><given-names>G.</given-names></name><name><surname>Hao</surname><given-names>T.</given-names></name></person-group> (<year>2018</year>). “<article-title>T-Know: A Knowledge Graph-Based Question Answering and Infor-Mation Retrieval System for Traditional Chinese Medicine</article-title>,” in <conf-name>Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations</conf-name>, <conf-loc>Chongqing, China</conf-loc>, <conf-date>Oct 12–14, 2018</conf-date> (<publisher-loc>Santa Fe, New Mexico</publisher-loc>: <publisher-name>Association for Computational Linguistics</publisher-name>), <fpage>15</fpage>–<lpage>19</lpage>. </mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mahdisoltani</surname><given-names>F.</given-names></name><name><surname>Biega</surname><given-names>J.</given-names></name><name><surname>Suchanek</surname><given-names>F.</given-names></name></person-group> (<year>2014</year>). “<article-title>Yago3: A Knowledge Base from Multilingual Wikipedias</article-title>,” in <conf-name>7th Biennial Conference on Innovative Data Systems Research (CIDR Conference)</conf-name>, <conf-loc>Asilomar, CA</conf-loc>, <conf-date>January 4 – 7, 2014</conf-date>. </mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Miao</surname><given-names>F.</given-names></name><name><surname>Liu</surname><given-names>H.</given-names></name><name><surname>Huang</surname><given-names>Y.</given-names></name><name><surname>Liu</surname><given-names>C.</given-names></name><name><surname>Wu</surname><given-names>X.</given-names></name></person-group> (<year>2018</year>). “<article-title>Construction of Semantic-Based Traditional Chinese Medicine Prescription Knowledge Graph</article-title>,” in <conf-name>2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)</conf-name>, <conf-loc>Chongqing, China</conf-loc>, <conf-date>October 12 – 14, 2018</conf-date>, <fpage>1194</fpage>–<lpage>1198</lpage>. <pub-id pub-id-type="doi">10.1109/iaeac.2018.8577236</pub-id>
</mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mosbach</surname><given-names>M.</given-names></name><name><surname>Andriushchenko</surname><given-names>M.</given-names></name><name><surname>Klakow</surname><given-names>D.</given-names></name></person-group> (<year>2020</year>). <article-title>On the Stability of fine-tuning Bert: Misconceptions, Explanations, and strong Baselines</article-title>. <comment>arXiv preprint arXiv:2006.04884</comment>. </mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Navigli</surname><given-names>R.</given-names></name><name><surname>Ponzetto</surname><given-names>S. P.</given-names></name></person-group> (<year>2012</year>). <article-title>Babelnet: The Automatic Construction, Evaluation and Application of a Wide-Coverage Multilingual Semantic Network</article-title>. <source>Artif. Intelligence</source>
<volume>193</volume>, <fpage>217</fpage>–<lpage>250</lpage>. <pub-id pub-id-type="doi">10.1016/j.artint.2012.07.001</pub-id>
</mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pechenick</surname><given-names>E. A.</given-names></name><name><surname>Danforth</surname><given-names>C. M.</given-names></name><name><surname>Dodds</surname><given-names>P. S.</given-names></name></person-group> (<year>2015</year>). <article-title>Characterizing the Google Books Corpus: Strong Limits to Inferences of Socio-Cultural and Linguistic Evolution</article-title>. <source>PloS One</source>
<volume>10</volume>, <fpage>e0137041</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0137041</pub-id>
<pub-id pub-id-type="pmid">26445406</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roozbeh</surname><given-names>J.</given-names></name><name><surname>Hashempur</surname><given-names>M. H.</given-names></name><name><surname>Heydari</surname><given-names>M.</given-names></name></person-group> (<year>2013</year>). <article-title>Use of Herbal Remedies Among Patients Undergoing Hemodialysis</article-title>. <source>Iran J. Kidney Dis.</source>
<volume>7</volume>, <fpage>492</fpage>–<lpage>495</lpage>. <pub-id pub-id-type="pmid">24241097</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Saha</surname><given-names>A.</given-names></name><name><surname>Pahuja</surname><given-names>V.</given-names></name><name><surname>Khapra</surname><given-names>M. M.</given-names></name><name><surname>Sankaranarayanan</surname><given-names>K.</given-names></name><name><surname>Chandar</surname><given-names>S.</given-names></name></person-group> (<year>2018</year>). “<article-title>Complex Sequential Question Answering: Towards Learning to converse over Linked Question Answer Pairs with a Knowledge Graph</article-title>,” in <conf-name>Thirty-Second AAAI Conference on Artificial Intelligence</conf-name>, <conf-loc>New Orleans, Louisiana</conf-loc>, <conf-date>February 2 - 7, 2018</conf-date>. </mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanh</surname><given-names>V.</given-names></name><name><surname>Debut</surname><given-names>L.</given-names></name><name><surname>Chaumond</surname><given-names>J.</given-names></name><name><surname>Wolf</surname><given-names>T.</given-names></name></person-group> (<year>2019</year>). <article-title>Distilbert, a Distilled Version of Bert: Smaller, Faster, Cheaper and Lighter</article-title>. <comment>arXiv preprint arXiv:1910.01108</comment>. </mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>Y.</given-names></name><name><surname>Yuan</surname><given-names>K.</given-names></name><name><surname>Dai</surname><given-names>J.</given-names></name><name><surname>Tang</surname><given-names>B.</given-names></name><name><surname>Yang</surname><given-names>M.</given-names></name><name><surname>Lei</surname><given-names>K.</given-names></name></person-group> (<year>2019</year>). <article-title>Kgdds: A System for Drug-Drug Similarity Measure in Therapeutic Substitution Based on Knowledge Graph Curation</article-title>. <source>J. Med. Syst.</source>
<volume>43</volume>, <fpage>1</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1007/s10916-019-1182-z</pub-id>
</mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sohn</surname><given-names>S.</given-names></name><name><surname>Comeau</surname><given-names>D. C.</given-names></name><name><surname>Kim</surname><given-names>W.</given-names></name><name><surname>Wilbur</surname><given-names>W. J.</given-names></name></person-group> (<year>2008</year>). <article-title>Abbreviation Definition Identification Based on Automatic Precision Estimates</article-title>. <source>BMC bioinformatics</source>
<volume>9</volume>, <fpage>402</fpage>. <pub-id pub-id-type="doi">10.1186/1471-2105-9-402</pub-id>
<pub-id pub-id-type="pmid">18817555</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Somé</surname><given-names>B. M. J.</given-names></name><name><surname>Bordea</surname><given-names>G.</given-names></name><name><surname>Thiessard</surname><given-names>F.</given-names></name><name><surname>Diallo</surname><given-names>G.</given-names></name></person-group> (<year>2019</year>). “<article-title>Enabling West African Herbal-Based Traditional Medicine Digitizing: the Watrimed Knowledge Graph</article-title>,” in <source>MEDINFO 2019: Health and Wellbeing e-Networks for All</source> (<publisher-loc>Amsterdam, Netherlands</publisher-loc>: <publisher-name>IOS Press</publisher-name>), <fpage>1548</fpage>–<lpage>1549</lpage>. </mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sosa</surname><given-names>D. N.</given-names></name><name><surname>Derry</surname><given-names>A.</given-names></name><name><surname>Guo</surname><given-names>M.</given-names></name><name><surname>Wei</surname><given-names>E.</given-names></name><name><surname>Brinton</surname><given-names>C.</given-names></name><name><surname>Altman</surname><given-names>R. B.</given-names></name></person-group> (<year>2019</year>). <article-title>A Literature-Based Knowledge Graph Embedding Method for Identifying Drug Repurposing Opportunities in Rare Diseases</article-title>. <source>Pac. Symp. Biocomput</source>
<volume>25</volume>, <fpage>463</fpage>–<lpage>474</lpage>. <pub-id pub-id-type="doi">10.1142/9789811215636_0041</pub-id>
</mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Su</surname><given-names>C.</given-names></name><name><surname>Hou</surname><given-names>Y.</given-names></name><name><surname>Guo</surname><given-names>W.</given-names></name><name><surname>Chaudhry</surname><given-names>F.</given-names></name><name><surname>Ghahramani</surname><given-names>G.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Cbkh: The cornell Biomedical Knowledge Hub</article-title>. <comment>medRxiv</comment>. <pub-id pub-id-type="doi">10.1101/2021.03.12.21253461</pub-id>
</mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szelenyi</surname><given-names>I.</given-names></name><name><surname>Brune</surname><given-names>K.</given-names></name></person-group> (<year>2002</year>). <article-title>Herbal Remedies for Asthma Treatment: Between Myth and Reality</article-title>. <source>Drugs Today</source>
<volume>38</volume>, <fpage>265</fpage>. <pub-id pub-id-type="doi">10.1358/dot.2002.38.4.668337</pub-id>
</mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vaswani</surname><given-names>A.</given-names></name><name><surname>Shazeer</surname><given-names>N.</given-names></name><name><surname>Parmar</surname><given-names>N.</given-names></name><name><surname>Uszkoreit</surname><given-names>J.</given-names></name><name><surname>Jones</surname><given-names>L.</given-names></name><name><surname>Gomez</surname><given-names>A. N.</given-names></name><etal/></person-group> (<year>2017</year>). “<article-title>Attention Is All You Need</article-title>,” in <source>Advances in Neural Information Processing Systems</source> (<publisher-name>Curran Associates Inc</publisher-name>), <fpage>5998</fpage>–<lpage>6008</lpage>. </mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q.</given-names></name><name><surname>Mao</surname><given-names>Z.</given-names></name><name><surname>Wang</surname><given-names>B.</given-names></name><name><surname>Guo</surname><given-names>L.</given-names></name></person-group> (<year>2017</year>). <article-title>Knowledge Graph Embedding: A Survey of Approaches and Applications</article-title>. <source>IEEE Trans. Knowl. Data Eng.</source>
<volume>29</volume>, <fpage>2724</fpage>–<lpage>2743</lpage>. <pub-id pub-id-type="doi">10.1109/tkde.2017.2754499</pub-id>
</mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Chen</surname><given-names>J.</given-names></name></person-group> (<year>2019</year>). “<article-title>A Knowledge Graph Enhanced Topic Modeling Approach for Herb Recommendation</article-title>,” in <conf-name>International Conference on Database Systems for Advanced Applications</conf-name>, <conf-loc>Chiang Mai, Thailand</conf-loc>, <conf-date>April 2019</conf-date> (<publisher-name>Springer</publisher-name>), <fpage>709</fpage>–<lpage>724</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-18576-3_42</pub-id>
</mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Webber</surname><given-names>J.</given-names></name></person-group> (<year>2012</year>). “<article-title>A Programmatic Introduction to Neo4j</article-title>,” in <conf-name>Proceedings of the 3rd annual conference on Systems, programming, and applications: software for humanity</conf-name>, <conf-loc>Tucson, AZ</conf-loc>, <conf-date>October 12 - 15, 2012</conf-date>, <fpage>217</fpage>–<lpage>218</lpage>. <pub-id pub-id-type="doi">10.1145/2384716.2384777</pub-id>
</mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>C.-H.</given-names></name><name><surname>Allot</surname><given-names>A.</given-names></name><name><surname>Leaman</surname><given-names>R.</given-names></name><name><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2019</year>). <article-title>Pubtator Central: Automated Concept Annotation for Biomedical Full Text Articles</article-title>. <source>Nucleic Acids Res.</source>
<volume>47</volume>, <fpage>W587</fpage>–<lpage>W593</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkz389</pub-id>
<pub-id pub-id-type="pmid">31114887</pub-id></mixed-citation>
    </ref>
    <ref id="B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>C.-H.</given-names></name><name><surname>Kao</surname><given-names>H.-Y.</given-names></name><name><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2015a</year>). <article-title>Gnormplus: An Integrative Approach for Tagging Genes, Gene Families, and Protein Domains</article-title>. <source>BioMed Res. Int.</source>
<volume>2015</volume>, <fpage>918710</fpage>. <pub-id pub-id-type="doi">10.1155/2015/918710</pub-id>
<pub-id pub-id-type="pmid">26380306</pub-id></mixed-citation>
    </ref>
    <ref id="B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>C.-H.</given-names></name><name><surname>Kao</surname><given-names>H.-Y.</given-names></name><name><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2012</year>). <article-title>Sr4gn: A Species Recognition Software Tool for Gene Normalization</article-title>. <source>PloS one</source>
<volume>7</volume>, <fpage>e38460</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0038460</pub-id>
<pub-id pub-id-type="pmid">22679507</pub-id></mixed-citation>
    </ref>
    <ref id="B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>C.-H.</given-names></name><name><surname>Leaman</surname><given-names>R.</given-names></name><name><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2015b</year>). <article-title>Simconcept: A Hybrid Approach for Simplifying Composite Named Entities in Biomedical Text</article-title>. <source>IEEE J. Biomed. Health Inform.</source>
<volume>19</volume>, <fpage>1385</fpage>–<lpage>1391</lpage>. <pub-id pub-id-type="doi">10.1109/jbhi.2015.2422651</pub-id>
<pub-id pub-id-type="pmid">25879978</pub-id></mixed-citation>
    </ref>
    <ref id="B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>C.-H.</given-names></name><name><surname>Phan</surname><given-names>L.</given-names></name><name><surname>Feltz</surname><given-names>J.</given-names></name><name><surname>Maiti</surname><given-names>R.</given-names></name><name><surname>Hefferon</surname><given-names>T.</given-names></name><name><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2018</year>). <article-title>Tmvar 2.0: Integrating Genomic Variant Information from Literature with Dbsnp and Clinvar for Precision Medicine</article-title>. <source>Bioinformatics</source>
<volume>34</volume>, <fpage>80</fpage>–<lpage>87</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btx541</pub-id>
<pub-id pub-id-type="pmid">28968638</pub-id></mixed-citation>
    </ref>
    <ref id="B48">
      <mixed-citation publication-type="book"><comment>[Dataset]</comment><collab>Wikipedia contributors</collab> (<year>2004a</year>). <source>Disease — Wikipedia, the Free Encyclopedia</source>. <publisher-name>Wikimedia Foundation</publisher-name>. <comment>[Online; accessed 22-July-2021]</comment>. </mixed-citation>
    </ref>
    <ref id="B49">
      <mixed-citation publication-type="book"><comment>[Dataset]</comment><collab>Wikipedia contributors</collab> (<year>2004b</year>). <source>Gene — Wikipedia, the Free Encyclopedia</source>. <publisher-name>Wikimedia Foundation</publisher-name>. <comment>[Online; accessed 22-July-2021]</comment>. </mixed-citation>
    </ref>
    <ref id="B50">
      <mixed-citation publication-type="book"><comment>[Dataset]</comment><collab>Wikipedia contributors</collab> (<year>2004c</year>). <source>Herbal Medicine — Wikipedia, the Free Encyclopedia</source>. <publisher-name>Wikimedia Foundation</publisher-name>. <comment>[Online; accessed 22-July-2021]</comment>. </mixed-citation>
    </ref>
    <ref id="B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wise</surname><given-names>C.</given-names></name><name><surname>Ioannidis</surname><given-names>V. N.</given-names></name><name><surname>Calvo</surname><given-names>M. R.</given-names></name><name><surname>Song</surname><given-names>X.</given-names></name><name><surname>Price</surname><given-names>G.</given-names></name><name><surname>Kulkarni</surname><given-names>N.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>Covid-19 Knowledge Graph: Accelerating Information Retrieval and Discovery for Scientific Literature</article-title>. <comment>arXiv preprint arXiv:2007.12731</comment>. </mixed-citation>
    </ref>
    <ref id="B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>T.</given-names></name><name><surname>Li</surname><given-names>J.</given-names></name><name><surname>Yu</surname><given-names>Q.</given-names></name><name><surname>Tian</surname><given-names>Y.</given-names></name><name><surname>Shun</surname><given-names>X.</given-names></name><name><surname>Xu</surname><given-names>L.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Knowledge Graph for Tcm Health Preservation: Design, Construction, and Applications</article-title>. <source>Artif. Intelligence Med.</source>
<volume>77</volume>, <fpage>48</fpage>–<lpage>52</lpage>. <pub-id pub-id-type="doi">10.1016/j.artmed.2017.04.001</pub-id>
</mixed-citation>
    </ref>
    <ref id="B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>S.</given-names></name><name><surname>Rao</surname><given-names>J.</given-names></name><name><surname>Song</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Xiao</surname><given-names>X.</given-names></name><name><surname>Fang</surname><given-names>E. F.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Pharmkg: A Dedicated Knowledge Graph Benchmark for Bomedical Data Mining</article-title>. <source>Brief Bioinform</source>
<volume>22</volume>, <fpage>bbaa344</fpage>. <pub-id pub-id-type="doi">10.1093/bib/bbaa344</pub-id>
<pub-id pub-id-type="pmid">33341877</pub-id></mixed-citation>
    </ref>
    <ref id="B54">
      <mixed-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>Z.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Wen</surname><given-names>C.</given-names></name></person-group> (<year>2020</year>). “<article-title>Tcmkg: A Deep Learning Based Traditional Chinese Medicine Knowledge Graph Platform</article-title>,” in <conf-name>2020 IEEE International Conference on Knowledge Graph (ICKG)</conf-name>, <conf-loc>Nanjing, China</conf-loc>, <conf-date>August 9–11, 2020</conf-date> (<publisher-name>IEEE</publisher-name>), <fpage>560</fpage>–<lpage>564</lpage>. <pub-id pub-id-type="doi">10.1109/icbk50248.2020.00084</pub-id>
</mixed-citation>
    </ref>
    <ref id="B55">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>X.</given-names></name><name><surname>Zhang</surname><given-names>L.</given-names></name><name><surname>Du</surname><given-names>J.</given-names></name><name><surname>Xiao</surname><given-names>Z.</given-names></name></person-group> (<year>2021</year>). <article-title>Full-Abstract Biomedical Relation Extraction with Keyword-Attentive Domain Knowledge Infusion</article-title>. <source>Appl. Sci.</source>
<volume>11</volume>, <fpage>7318</fpage>. <pub-id pub-id-type="doi">10.3390/app11167318</pub-id>
</mixed-citation>
    </ref>
    <ref id="B56">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>Y.</given-names></name><name><surname>Che</surname><given-names>C.</given-names></name><name><surname>Jin</surname><given-names>B.</given-names></name><name><surname>Zhang</surname><given-names>N.</given-names></name><name><surname>Su</surname><given-names>C.</given-names></name><name><surname>Wang</surname><given-names>F.</given-names></name></person-group> (<year>2020</year>). <article-title>Knowledge-Driven Drug Repurposing Using a Comprehensive Drug Knowledge Graph</article-title>. <source>Health Inform. J</source>
<volume>26</volume>, <fpage>2737</fpage>–<lpage>2750</lpage>. <pub-id pub-id-type="doi">10.1177/1460458220937101</pub-id>
</mixed-citation>
    </ref>
  </ref-list>
</back>
