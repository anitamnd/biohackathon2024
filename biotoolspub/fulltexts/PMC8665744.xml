<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8665744</article-id>
    <article-id pub-id-type="pmid">34320631</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btab551</article-id>
    <article-id pub-id-type="publisher-id">btab551</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Sequence Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>PhosIDN: an integrated deep neural network for improving protein phosphorylation site prediction by combining sequence and protein–protein interaction information</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-8406-3129</contrib-id>
        <name>
          <surname>Yang</surname>
          <given-names>Hangyuan</given-names>
        </name>
        <aff><institution>School of Information Science and Technology, University of Science and Technology of China</institution>, Hefei AH230027, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Wang</surname>
          <given-names>Minghui</given-names>
        </name>
        <xref rid="btab551-cor1" ref-type="corresp"/>
        <aff><institution>School of Information Science and Technology, University of Science and Technology of China</institution>, Hefei AH230027, <country country="CN">China</country></aff>
        <aff><institution>Centers for Biomedical Engineering, University of Science and Technology of China</institution>, Hefei AH230027, <country country="CN">China</country></aff>
        <!--mhwang@ustc.edu.cn-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Xia</given-names>
        </name>
        <aff><institution>School of Information Science and Technology, University of Science and Technology of China</institution>, Hefei AH230027, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-4531-3970</contrib-id>
        <name>
          <surname>Zhao</surname>
          <given-names>Xing-Ming</given-names>
        </name>
        <aff><institution>Institute of Science and Technology for Brain-Inspired Intelligence, Fudan University</institution>, Shanghai 200433, <country country="CN">China</country></aff>
        <aff><institution>MOE Key Laboratory of Computational Neuroscience and Brain-Inspired Intelligence and Frontiers Center for Brain Science</institution>, Shanghai 200433, <country country="CN">China</country></aff>
        <aff><institution>Research Institute of Intelligent Complex Systems, Fudan University</institution>, Shanghai 200433, <country country="CN">China</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Ao</given-names>
        </name>
        <aff><institution>School of Information Science and Technology, University of Science and Technology of China</institution>, Hefei AH230027, <country country="CN">China</country></aff>
        <aff><institution>Centers for Biomedical Engineering, University of Science and Technology of China</institution>, Hefei AH230027, <country country="CN">China</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Cowen</surname>
          <given-names>Lenore</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btab551-cor1">To whom correspondence should be addressed. <email>mhwang@ustc.edu.cn</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>15</day>
      <month>12</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-07-28">
      <day>28</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>28</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <volume>37</volume>
    <issue>24</issue>
    <fpage>4668</fpage>
    <lpage>4676</lpage>
    <history>
      <date date-type="received">
        <day>23</day>
        <month>11</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>22</day>
        <month>6</month>
        <year>2021</year>
      </date>
      <date date-type="editorial-decision">
        <day>23</day>
        <month>7</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>27</day>
        <month>7</month>
        <year>2021</year>
      </date>
      <date date-type="corrected-typeset">
        <day>19</day>
        <month>8</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">https://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btab551.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Phosphorylation is one of the most studied post-translational modifications, which plays a pivotal role in various cellular processes. Recently, deep learning methods have achieved great success in prediction of phosphorylation sites, but most of them are based on convolutional neural network that may not capture enough information about long-range dependencies between residues in a protein sequence. In addition, existing deep learning methods only make use of sequence information for predicting phosphorylation sites, and it is highly desirable to develop a deep learning architecture that can combine heterogeneous sequence and protein–protein interaction (PPI) information for more accurate phosphorylation site prediction. </p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We present a novel integrated deep neural network named PhosIDN, for phosphorylation site prediction by extracting and combining sequence and PPI information. In PhosIDN, a sequence feature encoding sub-network is proposed to capture not only local patterns but also long-range dependencies from protein sequences. Meanwhile, useful PPI features are also extracted in PhosIDN by a PPI feature encoding sub-network adopting a multi-layer deep neural network. Moreover, to effectively combine sequence and PPI information, a heterogeneous feature combination sub-network is introduced to fully exploit the complex associations between sequence and PPI features, and their combined features are used for final prediction. Comprehensive experiment results demonstrate that the proposed PhosIDN significantly improves the prediction performance of phosphorylation sites and compares favorably with existing general and kinase-specific phosphorylation site prediction methods.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>PhosIDN is freely available at <ext-link xlink:href="https://github.com/ustchangyuanyang/PhosIDN" ext-link-type="uri">https://github.com/ustchangyuanyang/PhosIDN</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Natural Science Foundation of China</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001809</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>61871361</award-id>
        <award-id>61471331</award-id>
        <award-id>61971393</award-id>
        <award-id>61571414</award-id>
        <award-id>61932008</award-id>
        <award-id>61772368</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Key R&amp;D Program of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2020YFA0712403</award-id>
        <award-id>2018YFC0910500</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Shanghai Science and Technology Innovation Fund</institution>
          </institution-wrap>
        </funding-source>
        <award-id>19511101404</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Shanghai Municipal Science and Technology Major Project</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2018SHZDZX01</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Post-translational modifications (PTMs) are vital mechanisms to enable proper and specific protein functions by proteolytic cleavage or addition of a modifying group covalently to amino acids (<xref rid="btab551-B28" ref-type="bibr">Mann and Jensen, 2003</xref>). Among the over 200 different types of PTMs that have been identified (<xref rid="btab551-B10" ref-type="bibr">Duan and Walther, 2015</xref>), one of the most studied is phosphorylation on serine (S), threonine (T) and tyrosine (Y), which plays a pivotal role in various cellular processes such as signal transduction, DNA repair, cell cycle control and metabolism (<xref rid="btab551-B26" ref-type="bibr">Ma <italic toggle="yes">et al.</italic>, 2005</xref>; <xref rid="btab551-B40" ref-type="bibr">Wood <italic toggle="yes">et al.</italic>, 2009</xref>). There are evidences showing that over one-third of proteins can be phosphorylated and abnormal phosphorylation is related to many human diseases (<xref rid="btab551-B5" ref-type="bibr">Cohen, 2002</xref>).</p>
    <p>Due to the importance of phosphorylation in understanding disease mechanisms and guiding drug design, many experimental methods are introduced for identification of phosphorylation sites, such as low throughput 32P-labeling (<xref rid="btab551-B1" ref-type="bibr">Aponte <italic toggle="yes">et al.</italic>, 2009</xref>) and high throughput mass spectrometry (<xref rid="btab551-B2" ref-type="bibr">Beausoleil <italic toggle="yes">et al.</italic>, 2006</xref>). However, these experimental identification methods are labor-intensive and time-consuming (<xref rid="btab551-B39" ref-type="bibr">Wen <italic toggle="yes">et al.</italic>, 2016</xref>). Therefore, it is very important to develop computational approaches with advantages of low cost and fast speed. For that reason, a large number of computational prediction methods have been proposed for identification of phosphorylation sites, and most of them are based on machine learning technique. For example, <xref rid="btab551-B43" ref-type="bibr">Xue <italic toggle="yes">et al.</italic> (2008)</xref> use a Markov cluster algorithm to develop a kinase-specific phosphorylation site prediction approach, Group-based Prediction System (GPS), in which the amino acid substitution matrix is used as the input features. <xref rid="btab551-B13" ref-type="bibr">Gao <italic toggle="yes">et al.</italic> (2010)</xref> propose an approach called Musite, which uses Support Vector Machine with amino acid frequencies as well as protein disorder scores and local protein sequences similarities. <xref rid="btab551-B20" ref-type="bibr">Li <italic toggle="yes">et al.</italic> (2018)</xref> design a logistic regression-based approach, Quokka, which adopts a variety of sequence scoring functions to predict kinase-specific phosphorylation sites.</p>
    <p>Recently, as an emerging machine learning technique, deep learning has brought a significant breakthrough in protein phosphorylation site prediction (<xref rid="btab551-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btab551-B41" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2020</xref>). For example, Wang <italic toggle="yes">et al.</italic> present Musitedeep (<xref rid="btab551-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2017</xref>), the first deep learning phosphorylation site prediction method, which takes protein sequences as inputs and uses a multi-layer convolutional neural network (CNN) architecture with attention mechanism. Subsequently, Wang <italic toggle="yes">et al.</italic> design CapsNet (<xref rid="btab551-B36" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2019</xref>) that has a two-layer CNN followed by one convolutional capsule layer and one fully connected layer for further sequence feature extraction. In addition, we explore CNN architectures for phosphorylation site prediction and propose DeepPhos (<xref rid="btab551-B24" ref-type="bibr">Luo <italic toggle="yes">et al.</italic>, 2019</xref>), which uses densely connected CNN (DCCNN) blocks with different filter sizes and windows to learn multiple representations of sequences. The test results show that these carefully designed CNN architectures are superior to traditional phosphorylation site prediction methods.</p>
    <p>Although aforementioned deep learning methods have achieved promising prediction performance, there are still some issues to address. First, despite of its powerful capability of learning local sequence patterns, it has been reported that CNN may not capture enough information about long-range dependencies between residues in a protein sequence (<xref rid="btab551-B15" ref-type="bibr">Hanson <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btab551-B34" ref-type="bibr">Uddin <italic toggle="yes">et al.</italic>, 2020</xref>), which however is beneficial for phosphorylation site prediction since protein phosphorylation can be affected by long-range regions far away from phosphorylation sites (<xref rid="btab551-B16" ref-type="bibr">Jung <italic toggle="yes">et al.</italic>, 2010</xref>; <xref rid="btab551-B21" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2010</xref>). As a result, it is crucial to design more sophisticated deep learning architectures that can capture not only local patterns but also long-range dependencies from protein sequences. Second, existing deep learning architectures for phosphorylation site prediction only make use of sequence information. Indeed, it has been shown that sequence information is often insufficient to reproduce the substrate specificities of protein kinases (<xref rid="btab551-B22" ref-type="bibr">Linding <italic toggle="yes">et al.</italic>, 2007</xref>; <xref rid="btab551-B31" ref-type="bibr">Song <italic toggle="yes">et al.</italic>, 2012</xref>). On the other hand, protein–protein interactions (PPIs) can provide contextual information about additional effects in protein phosphorylation (e.g. colocalization via anchoring proteins and scaffolds) (<xref rid="btab551-B22" ref-type="bibr">Linding <italic toggle="yes">et al.</italic>, 2007</xref>; <xref rid="btab551-B31" ref-type="bibr">Song <italic toggle="yes">et al.</italic>, 2012</xref>), and have been proved to be complementary to sequence information with successful applications in existing phosphorylation prediction studies (<xref rid="btab551-B12" ref-type="bibr">Fan <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btab551-B21" ref-type="bibr">Li <italic toggle="yes">et al.</italic>, 2010</xref>; <xref rid="btab551-B22" ref-type="bibr">Linding <italic toggle="yes">et al.</italic>, 2007</xref>; <xref rid="btab551-B31" ref-type="bibr">Song <italic toggle="yes">et al.</italic>, 2012</xref>; <xref rid="btab551-B32" ref-type="bibr">2017</xref>). Therefore, it is highly desirable to develop a deep learning architecture that can combine heterogeneous sequence and PPI information for phosphorylation site prediction.</p>
    <p>In this work, we present a novel deep neural network, PhosIDN, to accurately predict protein phosphorylation sites by efficiently extracting and combining sequence and PPI information. As an integrated deep learning architecture, PhosIDN consists of three closely connected sub-networks including a sequence feature encoding sub-network (SFENet), a PPI feature encoding sub-network (IFENet) and a heterogeneous feature combination sub-network (HFCNet). SFENet incorporates DCCNN block with a self-attention module to capture not only local patterns but also long-range dependencies from protein sequences. Meanwhile, IFENet adopts a multi-layer deep neural network (DNN) to extract PPI features that are useful for predicting protein phosphorylation sites. Moreover, to effectively combine heterogeneous sequence and PPI information, HFCNet leverages a bilinear feature module to fully exploit the complex associations between sequence and PPI features, and then extracts their combined features by a multi-layer DNN. Comprehensive experiments are conducted to investigate the performance of our approach, and the evaluation results demonstrate that the proposed PhosIDN significantly improves the prediction performance of phosphorylation sites and outperforms existing general and kinase-specific phosphorylation site prediction methods.</p>
  </sec>
  <sec>
    <title>2 Methods and materials</title>
    <sec>
      <title>2.1 Benchmark dataset</title>
      <p>In this study, we adopt a large-scale dataset (<xref rid="btab551-B24" ref-type="bibr">Luo <italic toggle="yes">et al.</italic>, 2019</xref>) designed for training and evaluating deep learning models, which includes more than 160 000 experimentally verified general and kinase-specific phosphorylation sites on human proteins filtered by similarity threshold of 40% to decrease the sequence redundancy of phosphorylation proteins. Furthermore, we use the same performance evaluation strategy as in previous study (<xref rid="btab551-B24" ref-type="bibr">Luo <italic toggle="yes">et al.</italic>, 2019</xref>), which randomly selects a proportion of the dataset (∼10% for general sites and ∼20% for kinase-specific sites) as independent test data and takes the rest as training and validation data. Specifically, when predicting general phosphorylation sites, we follow previous study (<xref rid="btab551-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2017</xref>) to train two deep learning models using S/T and Y sites, respectively, and then evaluate the performance of PhosIDN and compare with other prediction methods on the independent test data that contains more than 17 000 phosphorylation sites (14 360 S/T sites and 2673 Y sites) (<xref rid="btab551-B24" ref-type="bibr">Luo <italic toggle="yes">et al.</italic>, 2019</xref>). When predicting kinase-specific phosphorylation sites, we train one specific prediction model for each kinase group, family, subfamily and individual kinase. The details of the number and residue type of sites in the independent test data for kinase-specific phosphorylation site prediction are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>.</p>
    </sec>
    <sec>
      <title>2.2 Data representation</title>
      <sec>
        <label>2.2.1</label>
        <title>Sequence data</title>
        <p>Given a protein sequence, we intercept a protein fragment containing a central potential phosphorylation site, and code it by one-hot encoding scheme that is widely adopted in phosphorylation site prediction (<xref rid="btab551-B24" ref-type="bibr">Luo <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab551-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2017</xref>). In this way, each protein fragment is encoded to a <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi>L</mml:mi><mml:mo>×</mml:mo><mml:mn>21</mml:mn></mml:mrow></mml:math></inline-formula> two-dimension matrix, here <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mi>L</mml:mi></mml:math></inline-formula> indicates the window size of the protein fragment and 21 is the size of the amino acid symbol dictionary (<xref rid="btab551-B17" ref-type="bibr">Khurana <italic toggle="yes">et al.</italic>, 2018</xref>).</p>
      </sec>
      <sec>
        <label>2.2.2</label>
        <title>PPI data</title>
        <p>In addition to protein sequences, we use PPIs from the STRING database (<xref rid="btab551-B6" ref-type="bibr">Damian <italic toggle="yes">et al.</italic>, 2011</xref>). To ensure the reliability of data, we filter PPIs by confidence score of 900 and then obtain 162 927 pairs of PPIs between 13 770 human proteins. After that, by using a graph embedding strategy (<xref rid="btab551-B37" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2016</xref>), we generate PPI embedding of size 128 for each protein. Finally, we map these proteins to UniProt identifiers using the identifier mapping provided by STRING and assign the corresponding PPI embedding to each phosphorylation protein by name matching. For phosphorylation proteins with missing PPI embeddings, we assign vectors of zeros by following previous study (<xref rid="btab551-B19" ref-type="bibr">Kulmanov <italic toggle="yes">et al.</italic>, 2018</xref>).</p>
      </sec>
    </sec>
    <sec>
      <title>2.3 Architecture of PhosIDN</title>
      <p>The proposed deep learning architecture of PhosIDN is shown in <xref rid="btab551-F1" ref-type="fig">Figure 1</xref>, which consists of two feature encoding sub-networks (i.e. SFENet and IFENet) and one heterogeneous feature combination sub-network, i.e. HFCNet. Specifically, SFENet and IFENet are designed to separately extract useful sequence and PPI features for predicting protein phosphorylation sites, and HFCNet is introduced to combine the outputs of SFENet and IFENet and finally generate the prediction results of phosphorylation sites. We describe each sub-network one-by-one as follows.</p>
      <fig position="float" id="btab551-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>The integrated deep learning architecture of PhosIDN</p>
        </caption>
        <graphic xlink:href="btab551f1" position="float"/>
      </fig>
      <sec>
        <label>2.3.1</label>
        <title>SFENet</title>
        <p>In SFENet, a DCCNN block is used to capture local sequence patterns, in which multiple convolutional layers are connected to each other simultaneously to enhance the flow of phosphorylation information (<xref rid="btab551-B24" ref-type="bibr">Luo <italic toggle="yes">et al.</italic>, 2019</xref>). However, the convolutional layers in DCCNN block may not obtain enough information about long-range dependencies between residues in a protein sequence (<xref rid="btab551-B34" ref-type="bibr">Uddin <italic toggle="yes">et al.</italic>, 2020</xref>). To address this issue, we further incorporate DCCNN block with an efficient self-attention module so that SFENet can capture not only local patterns but also long-range dependencies from protein sequences. More details of this sub-network are described as follows.</p>
        <p>For an input protein sequence, each convolutional layer in DCCNN block performs one-dimension convolutional computation along the sequence length (<xref rid="btab551-B17" ref-type="bibr">Khurana <italic toggle="yes">et al.</italic>, 2018</xref>) and the corresponding representations are then concatenated to generate the intermediate sequence features. More importantly, inspired by the self-attention mechanism (<xref rid="btab551-B35" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic>, 2017</xref>) we introduce a self-attention module to further capture the long-range dependencies between residues in a protein sequence. Specifically, the proposed self-attention module receives input from two aspects: (i<bold>)</bold> the intermediate sequence features extracted by previous DCCNN block, <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, and (ii<bold>)</bold> positional encodings, <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mi>D</mml:mi></mml:math></inline-formula> refers to the total number of convolutional filters in DCCNN block and is set to 152 in this study. Here, positional encodings are added to inject information about the absolute or relative position of residues and can be defined as follows (<xref rid="btab551-B35" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic>, 2017</xref>):
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>sin</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10000</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>d</mml:mi><mml:mo>/</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>d</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mtext>cos</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10000</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>d</mml:mi><mml:mo>/</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi>d</mml:mi></mml:math></inline-formula> is the dimension. That is, each dimension of <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> corresponds to a sinusoid. Then the intermediate sequence features is concatenated with positional encodings to obtain <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> as the input of the self-attention module:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> represents the <italic toggle="yes">i</italic>th column vector. After that, the self-attention module transforms the input into three vectors as follows:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> represent query, key and value vector, respectively, <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> refer to the parameter matrices with the size of <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mn>2</mml:mn><mml:mi>D</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is set to 128 in this study.</p>
        <p>To obtain output features of the self-attention module, each column vector is calculated as a weighted sum of all value vectors and the weight for each value vector is computed by the correlation of the query vector with corresponding key vector. Accordingly, for the output features <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>H</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, the <italic toggle="yes">j</italic>th column vector <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> can be computed in the follow steps. Firstly, the correlation <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> of the query vector <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> with key vector <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is calculated as:
<disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msubsup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msubsup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> refers to the matrix multiplication between these two vectors, resulting in their correlation in a specific space, and <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:msqrt><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> represents the scaling factor, ensuring that the computing results for correlation does not get excessively large. Secondly, the weight for each value vector is obtained by softmax function and can be calculated as follows:
<disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover><mml:mrow><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></disp-formula></p>
        <p>Thirdly, the <italic toggle="yes">j</italic>th column vector of the output features is obtained by summing the product of each value vector and its weight, which is computed as:
<disp-formula id="E7"><label>(7)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>L</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></disp-formula></p>
        <p>In this way, the output features are generated and then reshaped to a one-dimensional tensor via flatten layer. After that, a fully connected layer is adopted to obtain the final sequence features <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>S</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, here <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mi>n</mml:mi></mml:math></inline-formula> refers to the number of neurons in the fully connected layer and is set to 32 in this study.</p>
      </sec>
      <sec>
        <label>2.3.2</label>
        <title>IFENet</title>
        <p>To extract PPI features that are useful for phosphorylation site prediction, we design IFENet as a multi-layer DNN with fully connected layers using PPI embedding <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mi>E</mml:mi></mml:math></inline-formula> as input, which can be formulated as follows:
<disp-formula id="E8"><label>(8)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo>α</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mi>E</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>α</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>M</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> represents the output produced by the <italic toggle="yes">i</italic>th fully connected layer in IFENet, <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> refer to parameter matrices and bias item, respectively, <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula> represents ReLU activation function that can realize the non-linear transformation, <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mi>M</mml:mi></mml:math></inline-formula> refers to the number of fully connected layers and here is set to 3. The output produced by the last fully connected layer is used as final PPI features <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>I</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mi>m</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mi>m</mml:mi></mml:math></inline-formula> is the number of neurons in the last fully connected layer and is equal to <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mi>n</mml:mi></mml:math></inline-formula> in this study.</p>
      </sec>
      <sec>
        <label>2.3.3</label>
        <title>HFCNet</title>
        <p>After sequence and PPI features are extracted from aforementioned two sub-networks, respectively, they are further combined by the proposed HFCNet for final phosphorylation site prediction. Instead of concatenating features directly, HFCNet utilizes a bilinear feature module to capture the complex associations between heterogeneous sequence and PPI features, and the output is then fed into a multi-layer DNN to obtain the combined features. The detailed process is described as follows.</p>
        <p>For input sequence features <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and PPI features <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>I</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, bilinear feature module can be formulated as (<xref rid="btab551-B14" ref-type="bibr">Gao <italic toggle="yes">et al.</italic>, 2016</xref>):
<disp-formula id="E9"><label>(9)</label><mml:math id="M9" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>S</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>I</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> represents the bilinear features and is reshaped to a one-dimensional tensor via flatten layer. After that, by concatenating with sequence and PPI features, it is fed into a multi-layer DNN with three fully connected layers to obtain the combined features <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mi>u</mml:mi></mml:math></inline-formula> is the number of neurons in the last fully connected layer of the multi-layer DNN. Finally, the prediction scores of phosphorylation and non-phosphorylation can be calculated as follows:
<disp-formula id="E10"><label>(10)</label><mml:math id="M10" display="block" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi>ℝ</mml:mi></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>×</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> represents the weight matrix of softmax function.</p>
      </sec>
    </sec>
    <sec>
      <title>2.4 Training</title>
      <p>To minimize the training error, the binary cross-entropy is utilized as loss function in this study:
<disp-formula id="E11"><label>(11)</label><mml:math id="M11" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>C</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup><mml:mi>ln</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>ln</mml:mi></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mi>N</mml:mi></mml:math></inline-formula> represents the number of samples in training data, <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> refers to the <italic toggle="yes">j</italic>th input protein sequence and <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> represents its corresponding class label. In addition, to avoid model overfitting during training process, dropout layers are used in convolutional and fully connected layers of PhosIDN. We choose Adam optimizer (<xref rid="btab551-B18" ref-type="bibr">Kingma and Ba, 2014</xref>) that is a widely used stochastic gradient descent algorithm. Meanwhile, mini batch strategy is adopted in this study, which divides training data into several small parts by optimizer.</p>
      <p>PhosIDN can be applied to predict both general and kinase-specific phosphorylation sites. When predicting general phosphorylation sites, we use all available S/T and Y phosphorylation sites to complete the training of our deep learning models. When predicting kinase-specific phosphorylation sites, we follow previous studies (<xref rid="btab551-B24" ref-type="bibr">Luo <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab551-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2017</xref>) to adopt a transfer learning strategy to address the small-sample problem. Specifically, we first train a base model on phosphorylation data without kinase annotation and then transfer all the neural layers, the learned parameter matrices and the bias items of the base model to kinase-specific models. Then we fine-tune the final model using kinase-specific phosphorylation site training data to relieve the overfitting problem.</p>
    </sec>
    <sec>
      <title>2.5 Performance assessment</title>
      <p>In order to assess the prediction performance of PhosIDN, we follow previous studies (<xref rid="btab551-B24" ref-type="bibr">Luo <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btab551-B32" ref-type="bibr">Song <italic toggle="yes">et al.</italic>, 2017</xref>) to use several commonly measurements for performance evaluation, including area under the ROC curve (AUC), sensitivity (Sn), specificity (Sp), precision (Pre), Accuracy (Acc), F1 scores (F1) and Matthew’s correlation coefficient (MCC). The calculations of these measurements are:
<disp-formula id="E12"><label>(12)</label><mml:math id="M12" display="block" overflow="scroll"><mml:mrow><mml:mi>Sn</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E13"><label>(13)</label><mml:math id="M13" display="block" overflow="scroll"><mml:mrow><mml:mi>Sp</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E14"><label>(14)</label><mml:math id="M14" display="block" overflow="scroll"><mml:mrow><mml:mi>Pre</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E15"><label>(15)</label><mml:math id="M15" display="block" overflow="scroll"><mml:mrow><mml:mi>Acc</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E16"><label>(16)</label><mml:math id="M16" display="block" overflow="scroll"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi>Pre</mml:mi><mml:mo>×</mml:mo><mml:mi>Sn</mml:mi></mml:mrow><mml:mrow><mml:mi>Pre</mml:mi><mml:mo>+</mml:mo><mml:mi>Sn</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E17"><label>(17)</label><mml:math id="M17" display="block" overflow="scroll"><mml:mrow><mml:mi>MCC</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where TP, TN, FP and FN refer to true positives, true negatives, false positives and false negatives, respectively.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Evaluating the performance of PhosIDN</title>
      <sec>
        <label>3.1.1</label>
        <title>Performance evaluation with sequence information</title>
        <p>To evaluate the ability of the proposed method in capturing long-range dependencies between residues, we first compare PhosIDN using only protein sequence as input (here referred to as PhosIDNSeq) with DCCNN on independent test data of general phosphorylation sites. We follow previous study (<xref rid="btab551-B16" ref-type="bibr">Jung <italic toggle="yes">et al.</italic>, 2010</xref>) to select several different window sizes for our experiments and the ROC curves on S/T and Y sites are plotted in <xref rid="btab551-F2" ref-type="fig">Figure 2</xref>. It is observed that the performance of DCCNN cannot benefit from the increase of the window size, indicating that CNN is good at learning local sequence patterns but may not take full advantage of larger window sizes. For example, on S/T sites DCCNN is able to obtain AUC value of 79.8% with window size of 33, while when the window size is increased to 71 the AUC value of DCCNN slightly drops to 79.2%, and the decrease in AUC value is associated with a <italic toggle="yes">P</italic> value of 0.0002935 calculated by using the roc_test function in pROC package (<xref rid="btab551-B30" ref-type="bibr">Robin <italic toggle="yes">et al.</italic>, 2011</xref>). On the contrary, PhosIDNSeq obtains consistent performance improvements with the increase of the window size. Take S/T site as an example, compared with window size of 15, the AUC value of PhosIDNSeq is improved by 3.8% (<italic toggle="yes">P</italic> value = 2.9735E-96) and 5.0% (<italic toggle="yes">P</italic> value = 8.1592E-154) when the window size is increased to 33 and 71, respectively. Meanwhile, we find that PhosIDNSeq obtains comparable or higher AUC values than DCCNN for each window size and shows significant advantage with the largest window size of 71. For example, on S/T sites the AUC value is enhanced from 79.2% (DCCNN) to 81.1% (PhosIDNSeq) with a <italic toggle="yes">P</italic> value of 1.7987E-40. Similarly, on Y sites the AUC value is enhanced from 70.4% (DCCNN) to 72.6% (PhosIDNSeq) with a <italic toggle="yes">P</italic> value of 7.8998E-8. Taken together, these results suggest that PhosIDNSeq can capture not only local patterns but also long-range dependencies from protein sequences. Accordingly, we select the window size as 71 for PhosIDNSeq in the subsequent experiments.</p>
        <fig position="float" id="btab551-F2">
          <label>Fig. 2.</label>
          <caption>
            <p>ROC curves of PhosIDNSeq for different window sizes on S/T and Y sites</p>
          </caption>
          <graphic xlink:href="btab551f2" position="float"/>
        </fig>
        <p>Besides, we compare PhosIDNSeq with DCCNN for predicting kinase-specific phosphorylation sites, and the AUC values based on independent test data are displayed in <xref rid="btab551-T1" ref-type="table">Table 1</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S2</xref>. For prediction of some kinases on S/T sites such as family CDK and subfamily ERK1, DCCNN shows good prediction performance with high AUC values (94.1% on family CDK and 94.2% on subfamily ERK1), which validate the importance of local sequence patterns in predicting kinase-specific phosphorylation sites. In comparison, as a more sophisticated deep learning architecture, PhosIDNSeq further improve the prediction performance for these kinases and the corresponding AUC values on family CDK and subfamily ERK1 reach 97.0% and 97.6%, respectively. At the same time, PhosIDNSeq also consistently outperforms DCCNN for kinase-specific prediction on Y sites. For example, compared with DCCNN on group TK and kinase SRC, PhosIDNSeq manages to obtain AUC values of 83.6% and 85.4% with an improvement of 3.2% (<italic toggle="yes">P</italic> value = 0.01383) and 2.8% (<italic toggle="yes">P</italic> value = 0.04638), respectively. These results show that in addition to general phosphorylation site prediction, PhosIDNSeq can also successfully boost the performance of kinase-specific phosphorylation site prediction with powerful capability of capturing long-range dependencies between residues.</p>
        <table-wrap position="float" id="btab551-T1">
          <label>Table 1.</label>
          <caption>
            <p>AUC values (%) of PhosIDN with sequence information for kinase-specific phosphorylation site prediction</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Kinase</th>
                <th rowspan="1" colspan="1">DCCNN</th>
                <th rowspan="1" colspan="1">PhosIDNSeq</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td colspan="3" rowspan="1">Group</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> AGC</td>
                <td rowspan="1" colspan="1">87.0</td>
                <td rowspan="1" colspan="1">
                  <bold>89.1</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> Atypical</td>
                <td rowspan="1" colspan="1">82.3</td>
                <td rowspan="1" colspan="1">
                  <bold>84.2</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> CAMK</td>
                <td rowspan="1" colspan="1">89.4</td>
                <td rowspan="1" colspan="1">
                  <bold>91.6</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> CMGC</td>
                <td rowspan="1" colspan="1">89.8</td>
                <td rowspan="1" colspan="1">
                  <bold>92.6</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> TK</td>
                <td rowspan="1" colspan="1">80.4</td>
                <td rowspan="1" colspan="1">
                  <bold>83.6</bold>
                </td>
              </tr>
              <tr>
                <td colspan="3" rowspan="1">Family</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> CDK</td>
                <td rowspan="1" colspan="1">94.1</td>
                <td rowspan="1" colspan="1">
                  <bold>97.0</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> CK2</td>
                <td rowspan="1" colspan="1">92.4</td>
                <td rowspan="1" colspan="1">
                  <bold>95.4</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> MAPK</td>
                <td rowspan="1" colspan="1">94.5</td>
                <td rowspan="1" colspan="1">
                  <bold>95.4</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> PKC</td>
                <td rowspan="1" colspan="1">83.7</td>
                <td rowspan="1" colspan="1">
                  <bold>86.4</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> Src</td>
                <td rowspan="1" colspan="1">81.2</td>
                <td rowspan="1" colspan="1">
                  <bold>83.6</bold>
                </td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <p><italic toggle="yes">Note</italic>: Best performance values are highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <label>3.1.2</label>
        <title>Performance evaluation with both sequence and PPI information</title>
        <p>To assess the performance of our proposed method in extracting and combining sequence and PPI information, by using independent test data of kinase-specific phosphorylation sites we compare PhosIDN with three other versions of the proposed method: (i<bold>)</bold> baseline: in this case, we directly concatenate PPI embedding and the output of SFENet and combine them via one fully connected layer, (ii<bold>)</bold> IFENet*: in this case, we directly concatenate the outputs of SFENet and IFENet and use one fully connected layer to combine them and (iii<bold>)</bold> HFCNet*: in this case, we utilize HFCNet to combine PPI embedding and the output of SFENet. To rigorously evaluate the contribution of PPI information, the phosphorylated proteins in the independent test data are excluded from PPIs during the training of PhosIDN. As shown in <xref rid="btab551-T2" ref-type="table">Table 2</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S3</xref>, all the methods using both protein sequence and PPI embedding as inputs produce higher performance than PhosIDNSeq, which corroborate previous studies that find PPI information contributes to the performance of kinase-specific phosphorylation site prediction. Furthermore, it can be clearly seen that IFENet* consistently performs better than baseline method, which suggests the ability of IFENet in extracting useful PPI features. For example, the AUC values of IFENet* are 87.8% and 91.7% on group Atypical and kinase SRC, respectively, which have 3.1% and 3.9% improvement over baseline method, respectively. Meanwhile, it is observed that HFCNet* also obtains higher AUC values than baseline method. For example, the AUC values achieved by HFCNet* reach 94.3% and 97.5% on group CMGC and subfamily CDK2, respectively, which are 1.3% and 1.1% better than those obtained by baseline method, respectively. These results demonstrate the strength of HFCNet in heterogeneous feature combination for kinase-specific phosphorylation site prediction. Finally, by integrating IFENet and HFCNet, PhosIDN achieves the best performance across all kinase-specific test data with remarkable improvements on AUC value. For example, on subfamily PKCa PhosIDN obtains the best AUC value of 92.1%, with an improvement of 2.7% (<italic toggle="yes">P</italic> value = 0.0007384), 2.0% (<italic toggle="yes">P</italic> value = 0.002713) and 2.2% (<italic toggle="yes">P</italic> value = 0.001736) over baseline method, IFENet* and HFCNet*, respectively.</p>
        <table-wrap position="float" id="btab551-T2">
          <label>Table 2.</label>
          <caption>
            <p>AUC values (%) of PhosIDN with both sequence and PPI information for kinase-specific phosphorylation site prediction</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Kinase</th>
                <th rowspan="1" colspan="1">Baseline</th>
                <th rowspan="1" colspan="1">IFENet*</th>
                <th rowspan="1" colspan="1">HFCNet*</th>
                <th rowspan="1" colspan="1">PhosIDN</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td colspan="5" rowspan="1">Group</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> AGC</td>
                <td rowspan="1" colspan="1">89.7</td>
                <td rowspan="1" colspan="1">91.5</td>
                <td rowspan="1" colspan="1">90.9</td>
                <td rowspan="1" colspan="1">
                  <bold>93.2</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> Atypical</td>
                <td rowspan="1" colspan="1">84.7</td>
                <td rowspan="1" colspan="1">87.8</td>
                <td rowspan="1" colspan="1">87.1</td>
                <td rowspan="1" colspan="1">
                  <bold>88.7</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> CAMK</td>
                <td rowspan="1" colspan="1">92.0</td>
                <td rowspan="1" colspan="1">94.2</td>
                <td rowspan="1" colspan="1">93.9</td>
                <td rowspan="1" colspan="1">
                  <bold>94.9</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> CMGC</td>
                <td rowspan="1" colspan="1">93.0</td>
                <td rowspan="1" colspan="1">93.7</td>
                <td rowspan="1" colspan="1">94.3</td>
                <td rowspan="1" colspan="1">
                  <bold>95.0</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> TK</td>
                <td rowspan="1" colspan="1">88.5</td>
                <td rowspan="1" colspan="1">91.0</td>
                <td rowspan="1" colspan="1">89.5</td>
                <td rowspan="1" colspan="1">
                  <bold>92.2</bold>
                </td>
              </tr>
              <tr>
                <td colspan="5" rowspan="1">Family</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> CDK</td>
                <td rowspan="1" colspan="1">97.0</td>
                <td rowspan="1" colspan="1">97.6</td>
                <td rowspan="1" colspan="1">97.4</td>
                <td rowspan="1" colspan="1">
                  <bold>98.2</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> CK2</td>
                <td rowspan="1" colspan="1">95.5</td>
                <td rowspan="1" colspan="1">96.0</td>
                <td rowspan="1" colspan="1">95.5</td>
                <td rowspan="1" colspan="1">
                  <bold>97.0</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> MAPK</td>
                <td rowspan="1" colspan="1">96.1</td>
                <td rowspan="1" colspan="1">96.6</td>
                <td rowspan="1" colspan="1">96.7</td>
                <td rowspan="1" colspan="1">
                  <bold>97.4</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> PKC</td>
                <td rowspan="1" colspan="1">88.7</td>
                <td rowspan="1" colspan="1">90.6</td>
                <td rowspan="1" colspan="1">89.1</td>
                <td rowspan="1" colspan="1">
                  <bold>91.6</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"> Src</td>
                <td rowspan="1" colspan="1">86.9</td>
                <td rowspan="1" colspan="1">88.8</td>
                <td rowspan="1" colspan="1">89.0</td>
                <td rowspan="1" colspan="1">
                  <bold>90.3</bold>
                </td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn2">
              <p>Baseline, direct concatenation of PPI embedding and the output of SFENet followed by one fully connected layer; IFENet*, direct concatenation of the outputs of SFENet and IFENet followed by one fully connected layer; HFCNet*, combination of PPI embedding and the output of SFENet via HFCNet; PhosIDN, our proposed integrated deep neural network. Best performance values are highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>In addition to AUC value, Sp, Sn, Pre, Acc, MCC and F1 are also used in this study to verify the effectiveness of the proposed method. By following previous study (<xref rid="btab551-B23" ref-type="bibr">Liu <italic toggle="yes">et al.</italic>, 2018</xref>), we compute other measurements when the Sp threshold is set at medium stringency level (90%) and high stringency level (95%), and display the values of these measurements in <xref rid="btab551-T3" ref-type="table">Table 3</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref>. It can be seen that both IFENet* and HFCNet* consistently achieve higher performance than baseline method. For example, on group Atypical at high stringency level, the Sn, Acc, MCC, Pre and F1 of IFENet* are 45.8%, 70.3%, 46.7%, 90.0% and 60.7%, respectively, while baseline method only obtains 28.0%, 61.4%, 30.8%, 84.6% and 42.0%, respectively. Also, the results clearly demonstrate the superior performance of PhosIDN. Take family PKC as an example, at medium stringency level PhosIDN has 12.6%, 7.2% and 12.4% improvement for F1 compared with baseline method, IFENet* and HFCNet*, respectively. In conclusion, PhosIDN can effectively extract and combine sequence and PPI information and significantly improve the performance of kinase-specific phosphorylation site prediction.</p>
        <table-wrap position="float" id="btab551-T3">
          <label>Table 3.</label>
          <caption>
            <p>The values (%) of Sn, Acc, MCC, Pre and F1 of PhosIDN for kinase-specific phosphorylation site prediction at medium and high stringency levels</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="2" colspan="1">Kinase</th>
                <th rowspan="2" colspan="1">Method</th>
                <th colspan="5" align="center" rowspan="1">Sp = 90%<hr/></th>
                <th colspan="5" align="center" rowspan="1">Sp = 95%<hr/></th>
              </tr>
              <tr>
                <th align="center" rowspan="1" colspan="1">Sn</th>
                <th align="center" rowspan="1" colspan="1">Acc</th>
                <th align="center" rowspan="1" colspan="1">Mcc</th>
                <th align="center" rowspan="1" colspan="1">Pre</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
                <th align="center" rowspan="1" colspan="1">Sn</th>
                <th align="center" rowspan="1" colspan="1">Acc</th>
                <th align="center" rowspan="1" colspan="1">Mcc</th>
                <th align="center" rowspan="1" colspan="1">Pre</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="4" colspan="1">Group AGC</td>
                <td rowspan="1" colspan="1">Baseline</td>
                <td rowspan="1" colspan="1">68.1</td>
                <td rowspan="1" colspan="1">78.6</td>
                <td rowspan="1" colspan="1">59.2</td>
                <td rowspan="1" colspan="1">88.3</td>
                <td rowspan="1" colspan="1">76.9</td>
                <td rowspan="1" colspan="1">58.4</td>
                <td rowspan="1" colspan="1">75.7</td>
                <td rowspan="1" colspan="1">56.6</td>
                <td rowspan="1" colspan="1">92.7</td>
                <td rowspan="1" colspan="1">71.6</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">IFENet*</td>
                <td rowspan="1" colspan="1">75.6</td>
                <td rowspan="1" colspan="1">82.5</td>
                <td rowspan="1" colspan="1">66.0</td>
                <td rowspan="1" colspan="1">89.4</td>
                <td rowspan="1" colspan="1">81.9</td>
                <td rowspan="1" colspan="1">65.0</td>
                <td rowspan="1" colspan="1">79.2</td>
                <td rowspan="1" colspan="1">62.2</td>
                <td rowspan="1" colspan="1">93.4</td>
                <td rowspan="1" colspan="1">76.7</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">HFCNet*</td>
                <td rowspan="1" colspan="1">72.2</td>
                <td rowspan="1" colspan="1">80.7</td>
                <td rowspan="1" colspan="1">62.9</td>
                <td rowspan="1" colspan="1">88.9</td>
                <td rowspan="1" colspan="1">79.7</td>
                <td rowspan="1" colspan="1">59.7</td>
                <td rowspan="1" colspan="1">77.9</td>
                <td rowspan="1" colspan="1">57.6</td>
                <td rowspan="1" colspan="1">92.9</td>
                <td rowspan="1" colspan="1">72.7</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PhosIDN</td>
                <td rowspan="1" colspan="1">
                  <bold>81.0</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>85.3</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>71.1</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>90.0</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>85.3</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>67.6</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>80.6</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>64.4</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>93.6</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>78.5</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="4" colspan="1">Group Atypical</td>
                <td rowspan="1" colspan="1">Baseline</td>
                <td rowspan="1" colspan="1">54.2</td>
                <td rowspan="1" colspan="1">72.0</td>
                <td rowspan="1" colspan="1">47.2</td>
                <td rowspan="1" colspan="1">84.2</td>
                <td rowspan="1" colspan="1">66.0</td>
                <td rowspan="1" colspan="1">28.0</td>
                <td rowspan="1" colspan="1">61.4</td>
                <td rowspan="1" colspan="1">30.8</td>
                <td rowspan="1" colspan="1">84.6</td>
                <td rowspan="1" colspan="1">42.0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">IFENet*</td>
                <td rowspan="1" colspan="1">57.6</td>
                <td rowspan="1" colspan="1">73.7</td>
                <td rowspan="1" colspan="1">50.1</td>
                <td rowspan="1" colspan="1">85.0</td>
                <td rowspan="1" colspan="1">68.7</td>
                <td rowspan="1" colspan="1">45.8</td>
                <td rowspan="1" colspan="1">70.3</td>
                <td rowspan="1" colspan="1">46.7</td>
                <td rowspan="1" colspan="1">90.0</td>
                <td rowspan="1" colspan="1">60.7</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">HFCNet*</td>
                <td rowspan="1" colspan="1">54.2</td>
                <td rowspan="1" colspan="1">72.0</td>
                <td rowspan="1" colspan="1">47.2</td>
                <td rowspan="1" colspan="1">84.2</td>
                <td rowspan="1" colspan="1">66.0</td>
                <td rowspan="1" colspan="1">40.7</td>
                <td rowspan="1" colspan="1">67.8</td>
                <td rowspan="1" colspan="1">42.4</td>
                <td rowspan="1" colspan="1">88.9</td>
                <td rowspan="1" colspan="1">55.8</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PhosIDN</td>
                <td rowspan="1" colspan="1">
                  <bold>65.3</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>77.5</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>56.8</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>86.5</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>74.4</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>50.8</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>72.9</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>51.0</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>90.9</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>65.2</bold>
                </td>
              </tr>
              <tr>
                <td rowspan="4" colspan="1">Group CAMK</td>
                <td rowspan="1" colspan="1">Baseline</td>
                <td rowspan="1" colspan="1">71.7</td>
                <td rowspan="1" colspan="1">80.1</td>
                <td rowspan="1" colspan="1">62.1</td>
                <td rowspan="1" colspan="1">89.9</td>
                <td rowspan="1" colspan="1">79.7</td>
                <td rowspan="1" colspan="1">62.4</td>
                <td rowspan="1" colspan="1">77.2</td>
                <td rowspan="1" colspan="1">59.5</td>
                <td rowspan="1" colspan="1">93.9</td>
                <td rowspan="1" colspan="1">75.0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">IFENet*</td>
                <td rowspan="1" colspan="1">83.8</td>
                <td rowspan="1" colspan="1">86.7</td>
                <td rowspan="1" colspan="1">73.7</td>
                <td rowspan="1" colspan="1">91.2</td>
                <td rowspan="1" colspan="1">87.3</td>
                <td rowspan="1" colspan="1">68.8</td>
                <td rowspan="1" colspan="1">80.7</td>
                <td rowspan="1" colspan="1">64.9</td>
                <td rowspan="1" colspan="1">94.4</td>
                <td rowspan="1" colspan="1">79.6</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">HFCNet*</td>
                <td rowspan="1" colspan="1">78.6</td>
                <td rowspan="1" colspan="1">84.1</td>
                <td rowspan="1" colspan="1">69.1</td>
                <td rowspan="1" colspan="1">90.7</td>
                <td rowspan="1" colspan="1">83.7</td>
                <td rowspan="1" colspan="1">65.7</td>
                <td rowspan="1" colspan="1">79.8</td>
                <td rowspan="1" colspan="1">61.1</td>
                <td rowspan="1" colspan="1">94.0</td>
                <td rowspan="1" colspan="1">77.7</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">PhosIDN</td>
                <td rowspan="1" colspan="1">
                  <bold>86.9</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>86.8</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>76.8</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>91.9</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>89.3</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>70.8</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>82.1</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>66.9</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>94.6</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>81.0</bold>
                </td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn3">
              <p><italic toggle="yes">Note</italic>: Best performance values are highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>Besides the PPIs from STRING database, we also adopt the physical interactions of proteins recorded in BioGRID database (<xref rid="btab551-B29" ref-type="bibr">Oughtred <italic toggle="yes">et al.</italic>, 2021</xref>) and obtain totally 55 542 physical interactions between 10 247 human proteins. The corresponding ROC curves of different kinases are plotted in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>. The results show that by leveraging physical interactions of proteins, our proposed method also consistently achieves considerable improvements in performance, further indicating the contribution of PPI information to phosphorylation site prediction.</p>
      </sec>
    </sec>
    <sec>
      <title>3.2 Comparison with existing methods</title>
      <p>We first compare PhosIDN with several well-known methods for general phosphorylation site prediction including PPSP (<xref rid="btab551-B42" ref-type="bibr">Xue <italic toggle="yes">et al.</italic>, 2006</xref>), NetPhos3.0 (<xref rid="btab551-B3" ref-type="bibr">Blom <italic toggle="yes">et al.</italic>, 2004</xref>), Musite (<xref rid="btab551-B13" ref-type="bibr">Gao <italic toggle="yes">et al.</italic>, 2010</xref>), MusiteDeep (<xref rid="btab551-B38" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2017</xref>) and DeepPhos (<xref rid="btab551-B24" ref-type="bibr">Luo <italic toggle="yes">et al.</italic>, 2019</xref>) based on independent test data. For existing methods, we adopt the optimal window size used by each specific method that is provided as a default setting. <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S5</xref> displays the AUC values on S/T and Y sites obtained by different methods, which shows that PhosIDN achieves better performance than other methods. Take Y site as an example, the AUC value of PhosIDN is 74.0%, which is 9.9%, 17.9%, 20.0%, 7.4% and 2.4% higher than PPSP, NetPhos3.0, Musite, MusiteDeep and DeepPhos, respectively. It is of note that the performance of DeepPhos shows little change when the maximal window size increases from default value of 51–71. In addition, we also calculate the values of Sn, Pre, Acc, MCC and F1 for all investigated methods, and the results are listed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S6</xref>. We find that PhosIDN consistently outperforms other methods on all measurements. Take S/T site as an example, at high stringency level PhosIDN obtains 24.2%, 29.6%, 20.7%, 7.4% and 4.2% improvement for F1, compared with PPSP, NetPhos3.0, Musite, MusiteDeep and DeepPhos, respectively. Taken together, these results suggest that with a novel integrated deep learning architecture, PhosIDN has a very competitive performance for general phosphorylation site prediction. However, it is noteworthy that despite of the respectable performance on general phosphorylation sites, only kinase-specific methods should be able to yield good accuracy (<xref rid="btab551-B33" ref-type="bibr">Trost and Kusalik, 2011</xref>), given the fact that protein kinases have distinct substrate specificities (<xref rid="btab551-B11" ref-type="bibr">Eisenhaber and Eisenhaber, 2010</xref>).</p>
      <p>Next, we compare our approach with some existing methods for kinase-specific phosphorylation site prediction including GPS, PPSP, MusiteDeep and DeepPhos. <xref rid="btab551-T4" ref-type="table">Table 4</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S7</xref> display the AUC values of all compared methods for different kinases. It is observed that both MusiteDeep and DeepPhos outperform other traditional phosphorylation site prediction methods, which indicates that CNN-based methods are advantageous in kinase-specific phosphorylation site prediction. For example, compared with GPS and PPSP, both MusiteDeep and DeepPhos obtain more than 7.0% AUC improvement in prediction of family CK2. At the same time, PhosIDNSeq compares favorably with MusiteDeep and DeepPhos across all kinase-specific test data. Furthermore, we find that by efficiently extracting and combining sequence and PPI information, PhosIDN achieves significant improvements over other methods that use only sequence information. For example, on family PKC the AUC value obtained by PhosIDN reaches 91.6%, while those of GPS, PPSP, MusiteDeep, DeepPhos and PhosIDNSeq are 66.2%, 76.1%, 80.5%, 84.2% and 86.4%, respectively. As for kinase SRC, PhosIDN achieves 17.6%, 29.0%, 10.6% and 7.9% AUC improvement compared with GPS, PPSP, DeepPhos and PhosIDNSeq, respectively. Moreover, we compare PhosIDN with PhosphoPredict (<xref rid="btab551-B32" ref-type="bibr">Song <italic toggle="yes">et al.</italic>, 2017</xref>) that also leverages both sequence and PPI information, and find that PhosIDN shows comparable or better performance than PhosphoPredict. For example, on family CDK and MAPK, PhosIDN manages to achieve AUC values of 98.2% and 97.4% with an improvement of 1.6% and 1.9%, respectively. Finally, we list the values of Sn, Acc, MCC, Pre and F1 at high stringency level in <xref rid="btab551-T5" ref-type="table">Table 5</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S8</xref>, and PhosIDN clearly shows the best predictive performance on all measurements. Take group AGC as an example, PhosIDN obtains Sn of 67.6%, Acc of 80.6%, MCC of 64.4%, Pre of 93.6% and F1 of 78.5%, while the performance of the next-best method are Sn of 54.2%, Acc of 73.6%, MCC of 53.1%, Pre of 92.1% and F1 of 68.3%. In conclusion, the aforementioned analysis demonstrates that PhosIDN compares favorably with existing methods for predicting phosphorylation sites.</p>
      <table-wrap position="float" id="btab551-T4">
        <label>Table 4.</label>
        <caption>
          <p>AUC values (%) of different methods for kinase-specific phosphorylation site prediction</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Kinase</th>
              <th rowspan="1" colspan="1">GPS</th>
              <th rowspan="1" colspan="1">PPSP</th>
              <th rowspan="1" colspan="1">MusiteDeep</th>
              <th rowspan="1" colspan="1">DeepPhos</th>
              <th rowspan="1" colspan="1">PhosphoPredict</th>
              <th rowspan="1" colspan="1">PhosIDNSeq</th>
              <th rowspan="1" colspan="1">PhosIDN</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td colspan="8" rowspan="1">Group</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> AGC</td>
              <td rowspan="1" colspan="1">56.5</td>
              <td rowspan="1" colspan="1">78.0</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">88.4</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">89.1</td>
              <td rowspan="1" colspan="1">
                <bold>93.2</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> Atypical</td>
              <td rowspan="1" colspan="1">76.5</td>
              <td rowspan="1" colspan="1">64.4</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">83.2</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">84.2</td>
              <td rowspan="1" colspan="1">
                <bold>88.7</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> CAMK</td>
              <td rowspan="1" colspan="1">70.6</td>
              <td rowspan="1" colspan="1">71.3</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">90.9</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">91.6</td>
              <td rowspan="1" colspan="1">
                <bold>94.9</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> CMGC</td>
              <td rowspan="1" colspan="1">83.2</td>
              <td rowspan="1" colspan="1">82.1</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">91.9</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">92.6</td>
              <td rowspan="1" colspan="1">
                <bold>95.0</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> TK</td>
              <td rowspan="1" colspan="1">60.4</td>
              <td rowspan="1" colspan="1">70.6</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">82.0</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">83.6</td>
              <td rowspan="1" colspan="1">
                <bold>92.2</bold>
              </td>
            </tr>
            <tr>
              <td colspan="8" rowspan="1">Family</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> CDK</td>
              <td rowspan="1" colspan="1">90.5</td>
              <td rowspan="1" colspan="1">86.1</td>
              <td rowspan="1" colspan="1">93.0</td>
              <td rowspan="1" colspan="1">96.0</td>
              <td rowspan="1" colspan="1">96.6</td>
              <td rowspan="1" colspan="1">97.0</td>
              <td rowspan="1" colspan="1">
                <bold>98.2</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> CK2</td>
              <td rowspan="1" colspan="1">84.1</td>
              <td rowspan="1" colspan="1">84.7</td>
              <td rowspan="1" colspan="1">92.5</td>
              <td rowspan="1" colspan="1">93.7</td>
              <td rowspan="1" colspan="1">96.3</td>
              <td rowspan="1" colspan="1">95.4</td>
              <td rowspan="1" colspan="1">
                <bold>97.0</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> MAPK</td>
              <td rowspan="1" colspan="1">92.1</td>
              <td rowspan="1" colspan="1">84.4</td>
              <td rowspan="1" colspan="1">93.4</td>
              <td rowspan="1" colspan="1">95.4</td>
              <td rowspan="1" colspan="1">95.5</td>
              <td rowspan="1" colspan="1">95.4</td>
              <td rowspan="1" colspan="1">
                <bold>97.4</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> PKC</td>
              <td rowspan="1" colspan="1">66.2</td>
              <td rowspan="1" colspan="1">76.1</td>
              <td rowspan="1" colspan="1">80.5</td>
              <td rowspan="1" colspan="1">84.2</td>
              <td rowspan="1" colspan="1">90.2</td>
              <td rowspan="1" colspan="1">86.4</td>
              <td rowspan="1" colspan="1">
                <bold>91.6</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> Src</td>
              <td rowspan="1" colspan="1">70.2</td>
              <td rowspan="1" colspan="1">68.8</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">83.0</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">83.6</td>
              <td rowspan="1" colspan="1">
                <bold>90.3</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn4">
            <p><italic toggle="yes">Note</italic>: Best performance values are highlighted in bold.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap position="float" id="btab551-T5">
        <label>Table 5.</label>
        <caption>
          <p>The values (%) of Sn, Acc, MCC, Pre and F1 of different methods for kinase-specific phosphorylation site prediction at high stringency level</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Kinase</th>
              <th rowspan="1" colspan="1">Method</th>
              <th rowspan="1" colspan="1">Sn</th>
              <th rowspan="1" colspan="1">Acc</th>
              <th rowspan="1" colspan="1">MCC</th>
              <th rowspan="1" colspan="1">Pre</th>
              <th rowspan="1" colspan="1">F1</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="5" colspan="1">Group AGC</td>
              <td rowspan="1" colspan="1">GPS</td>
              <td rowspan="1" colspan="1">5.9</td>
              <td rowspan="1" colspan="1">48.3</td>
              <td rowspan="1" colspan="1">1.8</td>
              <td rowspan="1" colspan="1">56.1</td>
              <td rowspan="1" colspan="1">10.7</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PPSP</td>
              <td rowspan="1" colspan="1">32.9</td>
              <td rowspan="1" colspan="1">62.4</td>
              <td rowspan="1" colspan="1">34.9</td>
              <td rowspan="1" colspan="1">87.7</td>
              <td rowspan="1" colspan="1">47.9</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepPhos</td>
              <td rowspan="1" colspan="1">50.9</td>
              <td rowspan="1" colspan="1">71.8</td>
              <td rowspan="1" colspan="1">50.4</td>
              <td rowspan="1" colspan="1">91.7</td>
              <td rowspan="1" colspan="1">65.5</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PhosIDNSeq</td>
              <td rowspan="1" colspan="1">54.2</td>
              <td rowspan="1" colspan="1">73.6</td>
              <td rowspan="1" colspan="1">53.1</td>
              <td rowspan="1" colspan="1">92.1</td>
              <td rowspan="1" colspan="1">68.3</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PhosIDN</td>
              <td rowspan="1" colspan="1">
                <bold>67.6</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>80.6</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>64.4</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>93.6</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>78.5</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="5" colspan="1">Group Atypical</td>
              <td rowspan="1" colspan="1">GPS</td>
              <td rowspan="1" colspan="1">16.1</td>
              <td rowspan="1" colspan="1">55.5</td>
              <td rowspan="1" colspan="1">17.9</td>
              <td rowspan="1" colspan="1">76.0</td>
              <td rowspan="1" colspan="1">26.6</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PPSP</td>
              <td rowspan="1" colspan="1">15.3</td>
              <td rowspan="1" colspan="1">55.1</td>
              <td rowspan="1" colspan="1">16.8</td>
              <td rowspan="1" colspan="1">75.0</td>
              <td rowspan="1" colspan="1">25.4</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">DeepPhos</td>
              <td rowspan="1" colspan="1">36.4</td>
              <td rowspan="1" colspan="1">65.7</td>
              <td rowspan="1" colspan="1">38.7</td>
              <td rowspan="1" colspan="1">87.8</td>
              <td rowspan="1" colspan="1">51.5</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PhosIDNSeq</td>
              <td rowspan="1" colspan="1">39.8</td>
              <td rowspan="1" colspan="1">67.4</td>
              <td rowspan="1" colspan="1">41.6</td>
              <td rowspan="1" colspan="1">88.7</td>
              <td rowspan="1" colspan="1">55.0</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">PhosIDN</td>
              <td rowspan="1" colspan="1">
                <bold>50.8</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>72.9</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>51.0</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>90.9</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>65.2</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn5">
            <p><italic toggle="yes">Note</italic>: Best performance values are highlighted in bold.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>To evaluate the performance of PhosIDN on kinases with different associated sites, we categorize kinase families with more than 200 sites in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref> as well-annotated, and categorize kinase families with fewer than 100 sites in the dataset as poorly annotated. The corresponding AUC values of PhosIDN on well- and poorly annotated kinase families are displayed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S9</xref>. The experimental results suggest that in addition to well-annotated kinase families, PhosIDN can also achieve good AUC values on poorly annotated kinase families. For example, the AUC values of family Aur and CAMK2 are 96.5% and 95.1%, respectively. Moreover, we test the performance of PhosIDN on some individual kinases with fewer associated sites in kinase family Src and PKC, and the corresponding AUC values are displayed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S10</xref>. Take family Src as an example, PhosIDN manages to obtain AUC values of 90.8%, 91.2% and 90.7% on kinase HCK, FYN and LCK, respectively. The experimental results suggest that in comparison with well-annotated kinases, PhosIDN can also perform well on the kinases in the same kinase family but with fewer associated sites.</p>
    </sec>
    <sec>
      <title>3.3 Visualization of features</title>
      <p>In this section, we visualize the ability of our proposed method in feature extraction and combination by using t-SNE (<xref rid="btab551-B27" ref-type="bibr">Maaten and Hinton, 2008</xref>). For group Atypical and CAMK, original one-hot encoding features, sequence features extracted by PhosIDNSeq and combined features extracted by PhosIDN are plotted in <xref rid="btab551-F3" ref-type="fig">Figure 3</xref>. It is obvious that original one-hot encoding features of phosphorylation and non-phosphorylation sites are in mixture, while sequence features extracted by PhosIDNSeq show separate trends, which become even more evident when using combined features extracted by PhosIDN. Similar results for some other kinases can be observed in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref>. These results suggest that original protein sequence can be transformed into meaningful representation by PhosIDNSeq, and PhosIDN can generate better representation with stronger discriminant power in distinguishing phosphorylation and non-phosphorylation sites.</p>
      <fig position="float" id="btab551-F3">
        <label>Fig. 3.</label>
        <caption>
          <p>Visualization of original one-hot encoding features, sequence features extracted by PhosIDNSeq and combined features extracted by PhosIDN. The red dot represents the phosphorylation sites with kinase annotation belonging to (<bold>a</bold>) group Atypical or (<bold>b</bold>) group CAMK, the blue dot represents the non-phosphorylation sites</p>
        </caption>
        <graphic xlink:href="btab551f3" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>In this article, we propose PhosIDN, a novel integrated deep neural network, for accurately predicting phosphorylation sites. When using sequence information, PhosIDN obtains significant performance for both general and kinase-specific phosphorylation site prediction, and the performance can be further improved by effectively combining sequence and PPI information. Meanwhile, the experimental results show that PhosIDN compares favorably with existing methods. Furthermore, the visualization results also indicate its ability in extracting and combining features with strong discriminant power. The main contributions of this work are as follows: (i<bold>)</bold> we demonstrate that the self-attention mechanism is very valuable in protein phosphorylation site prediction by obtaining the information about long-range dependencies between residues, (ii<bold>)</bold> we design an efficient deep neural network SFENet by leveraging DCCNN block and self-attention module, which can take full advantage of sequence information by capturing not only local patterns but also long-range dependencies from protein sequences and (iii<bold>)</bold> by effectively utilizing SFENet, IFENet and HFCNet, the proposed integrated deep neural network shows great strength in extracting and combining heterogeneous sequence and PPI information, and achieves remarkable performance for predicting both general and kinase-specific phosphorylation sites.</p>
    <p>Although PhosIDN has enhanced the prediction performance of protein phosphorylation sites, there is still room for improvement. Firstly, some other biological information (e.g. gene ontology terms and protein secondary structure) is also helpful for predicting phosphorylation sites (<xref rid="btab551-B8" ref-type="bibr">Dou <italic toggle="yes">et al.</italic>, 2014</xref>; <xref rid="btab551-B9" ref-type="bibr">2017</xref>; <xref rid="btab551-B32" ref-type="bibr">Song <italic toggle="yes">et al.</italic>, 2017</xref>), which could be adopted in our future work. Secondly, despite the fact that deep learning method has become a promising approach for phosphorylation site prediction, the deep neural network is still a black-box that is often criticized for lacking interpretability (<xref rid="btab551-B25" ref-type="bibr">Ma <italic toggle="yes">et al.</italic>, 2018</xref>). Hence, it is very important to develop deep learning phosphorylation site prediction method with improved interpretability. Thirdly, in addition to self-attention module, other models such as recurrent neural network (<xref rid="btab551-B7" ref-type="bibr">Deznabi <italic toggle="yes">et al.</italic>, 2020</xref>) and long short-term memory (<xref rid="btab551-B4" ref-type="bibr">Chen <italic toggle="yes">et al.</italic>, 2019</xref>) have also been successfully used to capture the long-range dependencies in sequential data, which can be further explored in future study. Fourthly, kinase-specific models may tend to perform better on the kinases with more associated sites, and one possible reason is that for these kinases more data are available for training prediction models. For other kinases, it is expected that further improvement in performance can be obtained with more kinase-specific sites identified and collected in the future. Finally, PhosIDN shows powerful capability of extracting and combining sequence and PPI information, which suggests that our approach could be further improved and extended to other PTM site prediction tasks. In conclusion, we present a novel integrated deep neural network for predicting phosphorylation sites, which has the potential to be extended to more predictive tasks and provides clues for further biological research.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the National Natural Science Foundation of China [61871361, 61471331, 61971393, 61571414, 61932008, 61772368], National Key R&amp;D Program of China [2020YFA0712403, 2018YFC0910500], Shanghai Science and Technology Innovation Fund [19511101404] and Shanghai Municipal Science and Technology Major Project [2018SHZDZX01].</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared. </p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btab551_Supplementary_Data</label>
      <media xlink:href="btab551_supplementary_data.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btab551-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aponte</surname><given-names>A.M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2009</year>) <article-title>32P labeling of protein phosphorylation and metabolite association in the mitochondria matrix</article-title>. <source>Methods Enzymol</source>., <volume>457</volume>, <fpage>63</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">19426862</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Beausoleil</surname><given-names>S.A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2006</year>) <article-title>A probability-based approach for high-throughput protein phosphorylation analysis and site localization</article-title>. <source>Nat. Biotechnol</source>., <volume>24</volume>, <fpage>1285</fpage>–<lpage>1292</lpage>.<pub-id pub-id-type="pmid">16964243</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Blom</surname><given-names>N.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2004</year>) <article-title>Prediction of post-translational glycosylation and phosphorylation of proteins from the amino acid sequence</article-title>. <source>Proteomics</source>, <volume>4</volume>, <fpage>1633</fpage>–<lpage>1649</lpage>.<pub-id pub-id-type="pmid">15174133</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname><given-names>Z.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Large-scale comparative assessment of computational predictors for lysine post-translational modification sites</article-title>. <source>Brief. Bioinf</source>., <volume>20</volume>, <fpage>2267</fpage>–<lpage>2290</lpage>.</mixed-citation>
    </ref>
    <ref id="btab551-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cohen</surname><given-names>P.</given-names></string-name></person-group> (<year>2002</year>) <article-title>The origins of protein phosphorylation</article-title>. <source>Nat. Cell Biol</source>., <volume>4</volume>, <fpage>E127</fpage>–<lpage>E130</lpage>.<pub-id pub-id-type="pmid">11988757</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Damian</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) <article-title>The STRING database in 2011: functional interaction networks of proteins, globally integrated and scored</article-title>. <source>Nucleic Acids Res</source>., <volume>39</volume>, <fpage>561</fpage>–<lpage>568</lpage>.</mixed-citation>
    </ref>
    <ref id="btab551-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deznabi</surname><given-names>I.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>DeepKinZero: zero-shot learning for predicting kinase–phosphosite associations involving understudied kinases</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>3652</fpage>–<lpage>3661</lpage>.<pub-id pub-id-type="pmid">32044914</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dou</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>PhosphoSVM: prediction of phosphorylation sites by integrating various protein sequence attributes with a support vector machine</article-title>. <source>Amino Acids</source>, <volume>46</volume>, <fpage>1459</fpage>–<lpage>1469</lpage>.<pub-id pub-id-type="pmid">24623121</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B9">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Dou</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <part-title>Prediction of protein phosphorylation sites by integrating secondary structure information and other one-dimensional structural properties</part-title>. In: Zhou, Y. (ed.) <italic toggle="yes">Prediction of Protein Secondary Structure</italic>. <publisher-name>Springer</publisher-name>, <publisher-loc>Berlin</publisher-loc>, pp. <fpage>265</fpage>–<lpage>274</lpage>.</mixed-citation>
    </ref>
    <ref id="btab551-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Duan</surname><given-names>G.</given-names></string-name>, <string-name><surname>Walther</surname><given-names>D.</given-names></string-name></person-group> (<year>2015</year>) <article-title>The roles of post-translational modifications in the context of protein interaction networks</article-title>. <source>PLoS Comput. Biol</source>., <volume>11</volume>, <fpage>e1004049</fpage>.<pub-id pub-id-type="pmid">25692714</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eisenhaber</surname><given-names>B.</given-names></string-name>, <string-name><surname>Eisenhaber</surname><given-names>F.</given-names></string-name></person-group> (<year>2010</year>) <article-title>Prediction of posttranslational modification of proteins from their amino acid sequence</article-title>. <source>Methods Mol. Biol</source>., <volume>609</volume>, <fpage>365</fpage>–<lpage>384</lpage>.<pub-id pub-id-type="pmid">20221930</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fan</surname><given-names>W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) <article-title>Prediction of protein kinase-specific phosphorylation sites in hierarchical structure using functional information and random forest</article-title>. <source>Amino Acids</source>, <volume>46</volume>, <fpage>1069</fpage>–<lpage>1078</lpage>.<pub-id pub-id-type="pmid">24452754</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gao</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2010</year>) <article-title>Musite, a tool for global prediction of general and kinase-specific phosphorylation sites</article-title>. <source>Mol. Cell. Proteomics</source>, <volume>9</volume>, <fpage>2586</fpage>–<lpage>2600</lpage>.<pub-id pub-id-type="pmid">20702892</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Gao</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) Compact bilinear pooling. In: <italic toggle="yes">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Las Vegas, USA</italic>. pp. <fpage>317</fpage>–<lpage>326</lpage>.</mixed-citation>
    </ref>
    <ref id="btab551-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hanson</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Improving protein disorder prediction by deep bidirectional long short-term memory recurrent neural networks</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>685</fpage>–<lpage>692</lpage>.<pub-id pub-id-type="pmid">28011771</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jung</surname><given-names>I.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2010</year>) <article-title>PostMod: sequence based prediction of kinase-specific phosphorylation sites with indirect relationship</article-title>. <source>BMC Bioinformatics</source>, <volume>11</volume>, <fpage>S10</fpage>.</mixed-citation>
    </ref>
    <ref id="btab551-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Khurana</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>DeepSol: a deep learning framework for sequence-based protein solubility prediction</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>2605</fpage>–<lpage>2613</lpage>.<pub-id pub-id-type="pmid">29554211</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B18">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>D.P.</given-names></string-name>, <string-name><surname>Ba</surname><given-names>J.</given-names></string-name></person-group> (<year>2014</year>) Adam: a method for stochastic optimization. <italic toggle="yes">arXiv, preprint arXiv:1412.6980</italic>.</mixed-citation>
    </ref>
    <ref id="btab551-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kulmanov</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>DeepGO: predicting protein functions from sequence and interactions using a deep ontology-aware classifier</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>660</fpage>–<lpage>668</lpage>.<pub-id pub-id-type="pmid">29028931</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Quokka: a comprehensive tool for rapid and accurate prediction of kinase family-specific phosphorylation sites in the human proteome</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>4223</fpage>–<lpage>4231</lpage>.<pub-id pub-id-type="pmid">29947803</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2010</year>) <article-title>Identifying human kinase-specific protein phosphorylation sites by integrating heterogeneous information from various sources</article-title>. <source>PLoS One</source>, <volume>5</volume>, <fpage>e15411</fpage>.<pub-id pub-id-type="pmid">21085571</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Linding</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2007</year>) <article-title>Systematic discovery of in vivo phosphorylation networks</article-title>. <source>Cell</source>, <volume>129</volume>, <fpage>1415</fpage>–<lpage>1426</lpage>.<pub-id pub-id-type="pmid">17570479</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>PTM-ssMP: a web server for predicting different types of post-translational modification sites using novel site-specific modification profile</article-title>. <source>Int. J. Biol. Sci</source>., <volume>14</volume>, <fpage>946</fpage>–<lpage>956</lpage>.<pub-id pub-id-type="pmid">29989096</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luo</surname><given-names>F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>DeepPhos: prediction of protein phosphorylation sites with deep learning</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>2766</fpage>–<lpage>2773</lpage>.<pub-id pub-id-type="pmid">30601936</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ma</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) <article-title>Using deep learning to model the hierarchical structure and function of a cell</article-title>. <source>Nat. Methods</source>, <volume>15</volume>, <fpage>290</fpage>–<lpage>298</lpage>.<pub-id pub-id-type="pmid">29505029</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ma</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2005</year>) <article-title>Phosphorylation and functional inactivation of TSC2 by Erk: implications for tuberous sclerosisand cancer pathogenesis</article-title>. <source>Cell</source>, <volume>121</volume>, <fpage>179</fpage>–<lpage>193</lpage>.<pub-id pub-id-type="pmid">15851026</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maaten</surname><given-names>L.v.d.</given-names></string-name>, <string-name><surname>Hinton</surname><given-names>G.</given-names></string-name></person-group> (<year>2008</year>) <article-title>Visualizing data using t-SNE</article-title>. <source>J. Mach. Learn. Res</source>., <volume>9</volume>, <fpage>2579</fpage>–<lpage>2605</lpage>.</mixed-citation>
    </ref>
    <ref id="btab551-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mann</surname><given-names>M.</given-names></string-name>, <string-name><surname>Jensen</surname><given-names>O.N.</given-names></string-name></person-group> (<year>2003</year>) <article-title>Proteomic analysis of post-translational modifications</article-title>. <source>Nat. Biotechnol</source>., <volume>21</volume>, <fpage>255</fpage>–<lpage>261</lpage>.<pub-id pub-id-type="pmid">12610572</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oughtred</surname><given-names>R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2021</year>) <article-title>The BioGRID database: a comprehensive biomedical resource of curated protein, genetic, and chemical interactions</article-title>. <source>Protein Sci</source>., <volume>30</volume>, <fpage>187</fpage>–<lpage>200</lpage>.<pub-id pub-id-type="pmid">33070389</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Robin</surname><given-names>X.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) <article-title>pROC: an open-source package for R and S+ to analyze and compare ROC curves</article-title>. <source>BMC Bioinformatics</source>, <volume>12</volume>, <fpage>8</fpage>.<pub-id pub-id-type="pmid">21211059</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) <article-title>Systematic analysis of protein phosphorylation networks from phosphoproteomic data</article-title>. <source>Mol. Cell. Proteomics</source>, <volume>11</volume>, <fpage>1070</fpage>–<lpage>1083</lpage>.<pub-id pub-id-type="pmid">22798277</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>PhosphoPredict: a bioinformatics tool for prediction of human kinase-specific phosphorylation substrates and sites by integrating heterogeneous feature selection</article-title>. <source>Sci. Rep</source>., <volume>7</volume>, <fpage>6862</fpage>.<pub-id pub-id-type="pmid">28761071</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Trost</surname><given-names>B.</given-names></string-name>, <string-name><surname>Kusalik</surname><given-names>A.</given-names></string-name></person-group> (<year>2011</year>) <article-title>Computational prediction of eukaryotic phosphorylation sites</article-title>. <source>Bioinformatics</source>, <volume>27</volume>, <fpage>2927</fpage>–<lpage>2935</lpage>.<pub-id pub-id-type="pmid">21926126</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Uddin</surname><given-names>M.R.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) <article-title>SAINT: self-attention augmented inception-inside-inception network improves protein secondary structure prediction</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>4599</fpage>–<lpage>4608</lpage>.<pub-id pub-id-type="pmid">32437517</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vaswani</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>Attention is all you need</article-title>. <source>Adv. Neural Inf. Process. Syst</source>., <fpage>5998</fpage>–<lpage>6008</lpage>.</mixed-citation>
    </ref>
    <ref id="btab551-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Capsule network for protein post-translational modification site prediction</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>2386</fpage>–<lpage>2394</lpage>.<pub-id pub-id-type="pmid">30520972</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B37">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Structural Deep Network Embedding</article-title>. In: <italic toggle="yes">ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, San Francisco, USA</italic>.</mixed-citation>
    </ref>
    <ref id="btab551-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>MusiteDeep: a deep-learning framework for general and kinase-specific phosphorylation site prediction</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>3909</fpage>–<lpage>3916</lpage>.<pub-id pub-id-type="pmid">29036382</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wen</surname><given-names>P.-P.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <article-title>Accurate in silico prediction of species-specific methylation sites based on information gain feature optimization</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>3107</fpage>–<lpage>3115</lpage>.<pub-id pub-id-type="pmid">27354692</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wood</surname><given-names>C.D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2009</year>) <article-title>Nuclear localization of p38 MAPK in response to DNA damage</article-title>. <source>Int. J. Biol. Sci</source>., <volume>5</volume>, <fpage>428</fpage>–<lpage>437</lpage>.<pub-id pub-id-type="pmid">19564926</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B41">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2020</year>) PhosTransfer: a deep transfer learning framework for kinase-specific phosphorylation site prediction in hierarchy. In: <italic toggle="yes">Pacific-Asia Conference on Knowledge Discovery and Data Mining.</italic> pp. 384–395, Springer, Singapore, Singapore.</mixed-citation>
    </ref>
    <ref id="btab551-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xue</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2006</year>) <article-title>PPSP: prediction of PK-specific phosphorylation site with Bayesian decision theory</article-title>. <source>BMC Bioinformatics</source>, <volume>7</volume>, <fpage>163</fpage>.<pub-id pub-id-type="pmid">16549034</pub-id></mixed-citation>
    </ref>
    <ref id="btab551-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xue</surname><given-names>Y.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2008</year>) <article-title>GPS 2.0, a tool to predict kinase-specific phosphorylation sites in hierarchy</article-title>. <source>Mol. Cell. Proteomics</source>, <volume>7</volume>, <fpage>1598</fpage>–<lpage>1608</lpage>.<pub-id pub-id-type="pmid">18463090</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
