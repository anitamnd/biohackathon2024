<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8665743</article-id>
    <article-id pub-id-type="pmid">34152405</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btab462</article-id>
    <article-id pub-id-type="publisher-id">btab462</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Notes</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Bioimage Informatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>3Dscript.server: true server-side 3D animation of microscopy images using a natural language-based syntax</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-9327-2296</contrib-id>
        <name>
          <surname>Schmid</surname>
          <given-names>Benjamin</given-names>
        </name>
        <xref rid="btab462-cor1" ref-type="corresp"/>
        <aff><institution>Optical Imaging Centre Erlangen, University of Erlangen-Nuremberg</institution>, 91058 Erlangen, <country country="DE">Germany</country></aff>
        <!--benjamin.schmid@fau.de-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tripal</surname>
          <given-names>Philipp</given-names>
        </name>
        <aff><institution>Optical Imaging Centre Erlangen, University of Erlangen-Nuremberg</institution>, 91058 Erlangen, <country country="DE">Germany</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Winter</surname>
          <given-names>Zoltán</given-names>
        </name>
        <aff><institution>Optical Imaging Centre Erlangen, University of Erlangen-Nuremberg</institution>, 91058 Erlangen, <country country="DE">Germany</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-4283-2115</contrib-id>
        <name>
          <surname>Palmisano</surname>
          <given-names>Ralph</given-names>
        </name>
        <aff><institution>Optical Imaging Centre Erlangen, University of Erlangen-Nuremberg</institution>, 91058 Erlangen, <country country="DE">Germany</country></aff>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Xu</surname>
          <given-names>Jinbo</given-names>
        </name>
        <role>Associate Editor</role>
        <aff><institution>Optical Imaging Centre Erlangen, University of Erlangen-Nuremberg</institution>, 91058 Erlangen, <country country="DE">Germany</country></aff>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btab462-cor1">To whom correspondence should be addressed <email>benjamin.schmid@fau.de</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>15</day>
      <month>12</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-06-21">
      <day>21</day>
      <month>6</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>21</day>
      <month>6</month>
      <year>2021</year>
    </pub-date>
    <volume>37</volume>
    <issue>24</issue>
    <fpage>4901</fpage>
    <lpage>4902</lpage>
    <history>
      <date date-type="received">
        <day>24</day>
        <month>2</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>06</day>
        <month>5</month>
        <year>2021</year>
      </date>
      <date date-type="editorial-decision">
        <day>14</day>
        <month>6</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>17</day>
        <month>6</month>
        <year>2021</year>
      </date>
      <date date-type="corrected-typeset">
        <day>09</day>
        <month>8</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btab462.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Summary</title>
        <p>Creating 3D animations from microscopy data is computationally expensive and requires high-end hardware. We therefore developed 3Dscript.server, a 3D animation software that runs as a service on dedicated, shared workstations. Using 3Dscript as the underlying rendering engine, it offers unique features not found in existing software: rendering is performed completely server-side. The target animation is specified on the client without the rendering engine, eliminating any hardware requirements client-side. Still, defining an animation is intuitive due to 3Dscript’s natural language-based animation description. We implemented a new OMERO web app to utilize 3Dscript.server directly from the OMERO web interface; a Fiji client to use 3Dscript.server from Fiji for integration into image processing pipelines; and batch scripts to run 3Dscript.server on compute clusters for large-scale visualization projects.</p>
      </sec>
      <sec id="s2">
        <title>Availability and implementation</title>
        <p>Source code and documentation is available at <ext-link xlink:href="https://github.com/bene51/omero_3Dscript" ext-link-type="uri">https://github.com/bene51/omero_3Dscript</ext-link>, <ext-link xlink:href="https://github.com/bene51/3Dscript.server" ext-link-type="uri">https://github.com/bene51/3Dscript.server</ext-link> and <ext-link xlink:href="https://github.com/bene51/3Dscript.cluster" ext-link-type="uri">https://github.com/bene51/3Dscript.cluster</ext-link>.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Deutsche Forschungsgemeinschaft</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001659</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>261193037</award-id>
        <award-id>391371888</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="2"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <label>1.</label>
    <title>Introduction</title>
    <p>Today, there is an increasing endeavor to enable remote work wherever possible. Still, for creating 3D animations, users need physical access to a dedicated rendering computer, as the only alternative, screen-sharing, often lacks the required responsiveness. To our knowledge, no software exists that runs as a service, to which users can submit animation jobs from remote. The reason for this gap is the way existing software creates 3D animations: The user adjusts the state of the 3D scene, including orientation, color, etc., for different time points, in keyframes. The rendering engine then creates a movie by interpolating between them. Keyframes therefore constitute a necessary input for the animation service. Creating them, however, is interactive and therefore requires the rendering engine and also the corresponding hardware on the client.</p>
    <p>Recently, we have presented 3Dscript (<xref rid="btab462-B8" ref-type="bibr">Schmid <italic toggle="yes">et al.</italic>, 2019</xref>), where textual instructions, written in a natural language-based syntax (‘From frame 0 to frame 100 rotate by 70 degrees horizontally’), describe and define arbitrarily complex animations and thereby replace keyframes. 3Dscript fulfills two criteria that make it ideally suited for a rendering framework based on a client-server architecture: animations are defined as human-readable text that gives a good idea of the rendering result even without rendering engine and preview, and this text is composed without any hardware requirements (as it is text only). We used this fact to develop a framework that for the first time creates 3D animations purely server-side.</p>
    <p>Here, we introduce 3Dscript.server, which runs a 3D rendering server, implemented as an ImageJ/Fiji plugin (<xref rid="btab462-B6" ref-type="bibr">Rueden <italic toggle="yes">et al.</italic>, 2017</xref>; <xref rid="btab462-B7" ref-type="bibr">Schindelin <italic toggle="yes">et al.</italic>, 2012</xref>; <xref rid="btab462-B9" ref-type="bibr">Schneider <italic toggle="yes">et al.</italic>, 2012</xref>) with 3Dscript as the underlying framework. We present three client implementations, (i) 3Dscript.client, a Fiji client for seamless integration into image analysis pipelines. (ii) OMERO.3Dscript, a web application for the image management software OMERO (<xref rid="btab462-B1" ref-type="bibr">Allan <italic toggle="yes">et al.</italic>, 2012</xref>) and (iii) 3Dscript.cluster, to run large-scale 3D animation projects on a high-performance compute cluster (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 1</xref>).</p>
    <p>Closest related to the current work is ClearVolume (<xref rid="btab462-B5" ref-type="bibr">Royer <italic toggle="yes">et al.</italic>, 2015</xref>), for remotely observing in real-time data acquisition on a volumetric microscope; FPBioimage (<xref rid="btab462-B3" ref-type="bibr">Fantham and Kaminski, 2017</xref>), for collaborative 3D visualization of biomedical images in a web browser; and BigDataViewer (<xref rid="btab462-B4" ref-type="bibr">Pietzsch <italic toggle="yes">et al.</italic>, 2015</xref>), for visualizing arbitrarily sized datasets. In all three applications, input datasets are loaded from a server but rendered client-side.</p>
  </sec>
  <sec>
    <label>2.</label>
    <title>Results</title>
    <sec>
      <title>3Dscript.server: the server module</title>
      <p>To set up a shared server environment, 3Dscript.server is first installed on one or more capable workstations in the local network (<xref rid="sup1" ref-type="supplementary-material">Supplementary Video</xref> S1). The server runs as a Fiji plugin and offers a single-click configuration to start automatically when the operating system boots. 3Dscript.server assumes its input data to be stored centrally, so that it is not loaded from slow, possibly wireless, client connections. Instead, data are retrieved either from an image management system such as OMERO or from a shared file system, operated within a fast institutional network. Because a rendering job will typically demand all graphics processing unit (GPU) resources, received jobs are collected in a queue and processed sequentially. If the input data is loaded from OMERO, the result is uploaded as a compressed video file as an attachment to the input image. In case of a shared file system, it is uploaded to the directory containing the input data (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. 2</xref>).</p>
    </sec>
    <sec>
      <title>3Dscript.client: accessing 3Dscript.server from a Fiji client</title>
      <p>3Dscript.client runs as a Fiji plugin and can distribute rendering to several user-specified servers simultaneously. It conveniently detects all available servers in the local network (<xref rid="sup1" ref-type="supplementary-material">Supplementary Videos</xref> S2 and S3). We implemented 3Dscript.client such that it can be integrated in macros and scripts as part of comprehensive workflows.</p>
    </sec>
    <sec>
      <title>OMERO.3Dscript: accessing 3Dscript.server through OMERO.web</title>
      <p>We developed OMERO.3Dscript (<xref rid="btab462-F1" ref-type="fig">Fig. 1</xref>, <xref rid="sup1" ref-type="supplementary-material">Supplementary Video</xref> S4, <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>) as a web application for OMERO, the most popular image management solution in the field of scientific imaging to date. For users, OMERO.3Dscript minimizes the effort to create high-quality and reproducible 3D animations: It runs directly in a web browser, and users create 3D animations from within their familiar OMERO web environment. An auto-completion enabled text field supports users in composing the animation text. Once rendering is started, OMERO.3Dscript continuously requests the rendering progress from the server and updates the website accordingly. The rendered video is uploaded to OMERO as an attachment to the input dataset in addition to being displayed in the web interface. OMERO.3Dscript processes entire collections of images at once (<xref rid="sup1" ref-type="supplementary-material">Supplementary Video</xref> S5). It can run on the same machine that stores the imaging data, which avoids large input data transfer completely. There are no hardware requirements for the client, and since OMERO.3Dscript’s frontend runs in a browser, clients can even connect from mobile devices (<xref rid="sup1" ref-type="supplementary-material">Supplementary Video</xref> S6). With the animation text being written in natural English language, it may even be entered conveniently using speech recognition.</p>
      <fig position="float" id="btab462-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>Platform- and hardware-independent animations through server-side 3D rendering with 3Dscript.server. OMERO.3Dscript is implemented as an OMERO web application, accessing 3Dscript.server for the rendering. Its front end runs in a web browser on desktop and mobile devices, without hardware requirements, as rendering is performed server-side. Entire collections of images can be rendered together with identical parameters. Example data: chicken embryo nervous system imaged with a mesoSPIM lightsheet microscope (<xref rid="btab462-B10" ref-type="bibr">Voigt <italic toggle="yes">et al.</italic>, 2019</xref>), mouse paw acquired on an ultramicroscope lightsheet system, mouse small intestinal organoids recorded on a spinning disk microscope (<xref rid="btab462-B2" ref-type="bibr">Bardenbacher <italic toggle="yes">et al.</italic>, 2019</xref>)</p>
        </caption>
        <graphic xlink:href="btab462f1" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3Dscript.cluster: running 3Dscript.server on an HPC cluster</title>
      <p>To create 3D animations on a larger scale, 3Dscript.server also runs on compute clusters. Different time points of time-lapse data or different datasets of image collections are processed in parallel on distinct nodes, which reduces the processing time significantly. We developed scripts for submitting rendering tasks to the ‘Emmy’ compute cluster of the University of Erlangen-Nuremberg, which includes 10 nodes with at least one GPU required for 3Dscript. The provided batch scripts are written for the Torque job management system (Adaptive Computing Inc.) but are easily adapted to different systems.</p>
      <p>With 3Dscript.server, it is finally possible to create high-quality scientific 3D animations ‘on-the-go’, e.g. on a tablet PC while discussing a poster on a conference, instead of sitting in front of a high-end workstation.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btab462_Supplementary_Data</label>
      <media xlink:href="btab462_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We thank Anja Schulz-Kuhnt and Selma Fensel (University Clinic of Erlangen) for providing sample datasets of mouse lung and paw, and William Moore (University of Dundee) for support with the OMERO.3Dscript implementation.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - 261193037; 391371888.</p>
      <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References </title>
    <ref id="btab462-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Allan</surname><given-names>C.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) <article-title>OMERO: flexible, model-driven data management for experimental biology</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>245</fpage>–<lpage>253</lpage>.<pub-id pub-id-type="pmid">22373911</pub-id></mixed-citation>
    </ref>
    <ref id="btab462-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bardenbacher</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>Permeability analyses and three dimensional imaging of interferon gamma-induced barrier disintegration in intestinal organoids</article-title>. <source>Stem Cell Res</source>., <volume>35</volume>, <fpage>101383</fpage>.<pub-id pub-id-type="pmid">30776676</pub-id></mixed-citation>
    </ref>
    <ref id="btab462-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fantham</surname><given-names>M.</given-names></string-name>, <string-name><surname>Kaminski</surname><given-names>C.F.</given-names></string-name></person-group> (<year>2017</year>) <article-title>A new online tool for visualization of volumetric data</article-title>. <source>Nat. Photonics</source>, <volume>11</volume>, <fpage>69</fpage>.</mixed-citation>
    </ref>
    <ref id="btab462-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pietzsch</surname><given-names>T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>BigDataViewer: visualization and processing for large image data sets</article-title>. <source>Nat. Methods</source>, <volume>12</volume>, <fpage>481</fpage>–<lpage>483</lpage>.<pub-id pub-id-type="pmid">26020499</pub-id></mixed-citation>
    </ref>
    <ref id="btab462-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Royer</surname><given-names>L.A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) <article-title>ClearVolume: open-source live 3D visualization for light-sheet microscopy</article-title>. <source>Nat. Methods</source>, <volume>12</volume>, <fpage>480</fpage>–<lpage>481</lpage>.<pub-id pub-id-type="pmid">26020498</pub-id></mixed-citation>
    </ref>
    <ref id="btab462-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rueden</surname><given-names>C.T.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) <article-title>ImageJ2: imageJ for the next generation of scientific image data</article-title>. <source>BMC Bioinformatics</source>, <volume>18</volume>, <fpage>529</fpage>.<pub-id pub-id-type="pmid">29187165</pub-id></mixed-citation>
    </ref>
    <ref id="btab462-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schindelin</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) <article-title>Fiji: an open-source platform for biological-image analysis</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>676</fpage>–<lpage>682</lpage>.<pub-id pub-id-type="pmid">22743772</pub-id></mixed-citation>
    </ref>
    <ref id="btab462-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schmid</surname><given-names>B.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>3Dscript: animating 3D/4D microscopy data using a natural-language-based syntax</article-title>. <source>Nat. Methods</source>, <volume>16</volume>, <fpage>278</fpage>–<lpage>280</lpage>.<pub-id pub-id-type="pmid">30886414</pub-id></mixed-citation>
    </ref>
    <ref id="btab462-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schneider</surname><given-names>C.A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) <article-title>NIH Image to ImageJ: 25 years of image analysis</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>671</fpage>–<lpage>675</lpage>.<pub-id pub-id-type="pmid">22930834</pub-id></mixed-citation>
    </ref>
    <ref id="btab462-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Voigt</surname><given-names>F.F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2019</year>) <article-title>The mesoSPIM initiative: open-source light-sheet microscopes for imaging cleared tissue</article-title>. <source>Nat. Methods</source>, <volume>16</volume>, <fpage>1105</fpage>–<lpage>1108</lpage>.<pub-id pub-id-type="pmid">31527839</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
