<?properties open_access?>
<?subarticle report82909?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">F1000Res</journal-id>
    <journal-id journal-id-type="iso-abbrev">F1000Res</journal-id>
    <journal-id journal-id-type="pmc">F1000Research</journal-id>
    <journal-title-group>
      <journal-title>F1000Research</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2046-1402</issn>
    <publisher>
      <publisher-name>F1000 Research Limited</publisher-name>
      <publisher-loc>London, UK</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8097733</article-id>
    <article-id pub-id-type="doi">10.12688/f1000research.25447.2</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software Tool Article</subject>
      </subj-group>
      <subj-group>
        <subject>Articles</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>DEVILS: a tool for the visualization of large datasets with a high dynamic range</article-title>
      <fn-group content-type="pub-status">
        <fn>
          <p>[version 2; peer review: 2 approved]</p>
        </fn>
      </fn-group>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Guiet</surname>
          <given-names>Romain</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Formal Analysis</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Writing – Original Draft Preparation</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6715-4897</contrib-id>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Burri</surname>
          <given-names>Olivier</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Writing – Original Draft Preparation</role>
        <role content-type="http://credit.casrai.org/">Writing – Review &amp; Editing</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-7100-3749</contrib-id>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chiaruttini</surname>
          <given-names>Nicolas</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Writing – Review &amp; Editing</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-4722-6245</contrib-id>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hagens</surname>
          <given-names>Olivier</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Investigation</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-2248-6705</contrib-id>
        <xref ref-type="aff" rid="a2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Seitz</surname>
          <given-names>Arne</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <role content-type="http://credit.casrai.org/">Writing – Original Draft Preparation</role>
        <role content-type="http://credit.casrai.org/">Writing – Review &amp; Editing</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5013-1557</contrib-id>
        <xref ref-type="corresp" rid="c1">a</xref>
        <xref ref-type="aff" rid="a1">1</xref>
      </contrib>
      <aff id="a1"><label>1</label>BioImaging &amp; Optics platform (BIOP), Faculty of Life Sciences (SV), Ecole Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland</aff>
      <aff id="a2"><label>2</label>Laboratory of Neural Microcircuitry, Ecole Polytechnique Fédérale de Lausanne, Lausanne, Switzerland</aff>
    </contrib-group>
    <author-notes>
      <corresp id="c1">
        <label>a</label>
        <email xlink:href="mailto:arne.seitz@epfl.ch">arne.seitz@epfl.ch</email>
      </corresp>
      <fn fn-type="COI-statement">
        <p>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>9</volume>
    <elocation-id>1380</elocation-id>
    <history>
      <date date-type="accepted">
        <day>5</day>
        <month>5</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright: © 2021 Guiet R et al.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="f1000research-9-54174.pdf"/>
    <abstract>
      <p>The number of grey values that can be displayed on monitors and be processed by the human eye is smaller than the dynamic range of image-based sensors. This makes the visualization of such data a challenge, especially with specimens where small dim structures are equally important as large bright ones, or whenever variations in intensity, such as non-homogeneous staining efficiencies or light depth penetration, becomes an issue.</p>
      <p> While simple intensity display mappings are easily possible, these fail to provide a one-shot observation that can display objects of varying intensities. In order to facilitate the visualization-based analysis of large volumetric datasets, we developed an easy-to-use ImageJ plugin enabling the compressed display of features within several magnitudes of intensities. The Display Enhancement for Visual Inspection of Large Stacks plugin (DEVILS) homogenizes the intensities by using a combination of local and global pixel operations to allow for high and low intensities to be visible simultaneously to the human eye.</p>
      <p> The plugin is based on a single, intuitively understandable parameter, features a preview mode, and uses parallelization to process multiple image planes. As output, the plugin is capable of producing a BigDataViewer-compatible dataset for fast visualization.</p>
      <p> We demonstrate the utility of the plugin for large volumetric image data.</p>
    </abstract>
    <kwd-group kwd-group-type="author">
      <kwd>Large datasets</kwd>
      <kwd>ImageJ/Fiji</kwd>
      <kwd>Image Processing</kwd>
      <kwd>BigDataViewer</kwd>
      <kwd>Light-sheet fluorescence microscopy</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="fund-1" xlink:href="http://dx.doi.org/10.13039/501100005416">
        <funding-source>Norges Forskningsråd</funding-source>
      </award-group>
      <funding-statement>This work was supported by the Research Council of Norway (Grant No. 250259 to M.Fyhn).</funding-statement>
      <funding-statement>
        <italic>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</italic>
      </funding-statement>
    </funding-group>
  </article-meta>
  <notes notes-type="version-changes">
    <sec sec-type="version-changes">
      <label>Revised</label>
      <title>Amendments from Version 1</title>
      <p>We have submitted a new version of the manuscript in order to address the points mentioned by the reviewer1.  1. The words used throughout the text should be more consistent, for instance: “DEVILS Workflow”, “DEVILS Routine”, “DEVILS Algorithm”, “DEVILS operation” or “Slice”, “Plane”, “Z-Plane” should be unified. The manuscript was changed by using the term “DEVILS plugin” and avoiding the other ones. 2. This sentence should be rephrased: “A popular method to remove intensity values from large objects is to divide the image by its blurred version”. The sentence was rephrased. In essence this is more a revised version of the original manuscript with minor changes. However, as the code-documentation changed it is important to have this revised version with the new links/new dois.</p>
    </sec>
  </notes>
</front>
<body>
  <sec sec-type="intro">
    <title>Introduction</title>
    <p>The display of data from a light microscope is challenging as the modulation transfer function, which dictates the contrast, is size dependent. Images of small objects have intrinsically a lower contrast than larger ones. In particular, objects with a size close to the resolution limit of the imaging system are hardly contrasted, especially when imaged simultaneously with larger objects (Figure S1, see
<italic>Extended data</italic> (
<xref rid="ref-4" ref-type="bibr">Guiet
<italic>et al.</italic>, 2020a</xref>)). This intrinsic drawback is even reinforced by the fact that the labelling efficiency might not be uniform for small and large structures. Moreover, optical aberrations, in particular spherical ones, further degrade the signal in a non-linear and sample-dependent manner due to refractive index mismatches. The visual inspection of such image data is therefore challenging. This is often the case for large volumetric datasets as typically provided by light-sheet fluorescence microscopy (LSFM).</p>
    <p>In LSFM, detection and image acquisition of the images is camera based, delivering images with a bit depth of 12 bits and beyond. The resulting image stacks can therefore exhibit a dynamic range that is larger than the grey values that can be distinguished by the human visual system or that can be displayed on monitors and screens.</p>
    <p>Fiji is one of the mostly used open source software for biological image data (
<xref rid="ref-12" ref-type="bibr">Schindelin
<italic>et al.</italic>, 2012</xref>). However, it struggles with the display and rapid inspection of large volumetric datasets with a high dynamic range. We therefore propose a Fiji plugin that facilitates on-screen display of structures with intensities differing by several orders of magnitude called Display Enhancement for Visual Inspection of Large Stacks (DEVILS).</p>
    <p>DEVILS performs local tone-mapping of fluorescence microscopy images, which has been commonly applied in every day world (
<xref rid="ref-11" ref-type="bibr">Salih
<italic>et al.</italic>, 2012</xref>) and medical image processing (
<xref rid="ref-9" ref-type="bibr">Park &amp; Montag, 2007</xref>). To achieve this in fluorescence images from biological samples, DEVILS uses a combination of three image processing routines. The original image is divided by a processed copy of itself (i.e. convolved with a Gaussian kernel) followed by a nonlinear intensity modification (square root operation) and a local rolling-ball background subtraction. Together they are implemented as a Fiji plugin. To deal with the size of the datasets, in the range of hundreds of gigabytes, the plugin can work on multiple planes of a virtual stack in parallel threads.</p>
    <p>We compare the result of the operations with several well-known and established methods to adjust the display of an image and furthermore analyse the effect of the DEVILS algorithm by comparing objects varying in intensity and size, as well as the different noise and background levels in the image. Details of the operations and its implementation as a user-friendly ImageJ plugin are discussed afterwards.</p>
  </sec>
  <sec sec-type="methods">
    <title>Methods</title>
    <sec>
      <title>Microscopy</title>
      <p><bold><italic>Cleared right murine midbrain, using active clarity protocol (
<xref rid="ref-8" ref-type="bibr">Lee
<italic>et al.</italic>, 2016</xref>) (
<xref ref-type="fig" rid="f1">Figure 1</xref> and
<xref ref-type="fig" rid="f3">Figure 3</xref>).</italic></bold> Multichannel stacks were acquired as tiles with 15% overlap on a Zeiss Lightsheet Z1 using a 20×/1.0 clearing objective. Each channel was acquired sequentially for each slice using single-sided illumination and a lightsheet thickness of 5.5 μm at the center and an optic zoom of 0.75×. The channels were acquired in the following order: tdTomato, endogenous staining of dopaminergic neurons (Ex: 561 nm, Em: BP 575 – 615 nm); Alexa Fluor 488, immunostaining of TH (Ex: 488 nm, Em: BP 525 – 545 nm) and DAPI, nuclear counterstain (Ex: 405 nm, Em: 420 – 470 nm). Original acquisitions yielded voxel sizes of 0.29 μm in XY and 1.5 μm in Z. The resulting tiles were fused and downscaled to an isotropic resolution of 1.2 μm using BigStitcher (
<xref rid="ref-6" ref-type="bibr">Hörl
<italic>et al.</italic>, 2019</xref>).</p>
      <fig fig-type="figure" id="f1" orientation="portrait" position="anchor">
        <label>Figure 1. </label>
        <caption>
          <title>Comparison of different image display methods.</title>
          <p>An optical slice of a chemically cleared mouse midbrain was imaged with light-sheet fluorescence microscopy (LSFM) and different image processing operations are compared. Images are displayed using the Fire look-up table (LUT) except for A which is displayed in grey-scale. Apart from panels
<bold>A</bold>,
<bold>B</bold> and
<bold>D</bold>, the auto contrast (AC) adjustment of Fiji was set to 0.35. (
<bold>A</bold>) Unprocessed image displayed using a grey LUT with the minimum (min) and maximum (max) display settings set to the pixel histogram values (568 – 55656). Scale bar: 100 µm. (
<bold>B</bold>) Unprocessed image displayed using the Fire LUT with the same display settings as in
<bold>A</bold>. (
<bold>C</bold>) Unprocessed image displayed using AC adjustment. (
<bold>D</bold>) Unprocessed image displayed with min-max set to 568 – 3709 (3709 equals 1/15
<sup>th</sup> of the maximal intensity). (
<bold>E</bold>) Original image displayed using Gamma adjustment (=2). (
<bold>F</bold>) Original image after applying the Square Root operation. (
<bold>G</bold>) Original image after a division by a spatially filtered version of the image (Gaussian blur, =50). (
<bold>H</bold>) Original image after applying the ‘Subtract Background’ method from Fiji/ (radius = 25 px). (
<bold>I</bold>) Original image after applying the DEVILS plugin with
<italic>p</italic> = 25.</p>
        </caption>
        <graphic xlink:href="f1000research-9-54174-g0000"/>
      </fig>
      <p><bold><italic>Cleared whole mouse (Parvalbumin-Cre C57BL/6) brain using CLARITY1 protocol (
<xref ref-type="fig" rid="f5">Figures 5A and 5B</xref>).</italic></bold> Single channel stack acquisition on a mesoSPIM system (
<xref rid="ref-15" ref-type="bibr">Voigt
<italic>et al.</italic>, 2019</xref>) (Wyss Center Advanced Light-sheet Imaging Center, Geneva, Switzerland) using a 42 Olympus MVX-10 zoom macroscope with a 1× objective (Olympus MVPLAPO 1×), for a final magnification of 0.8× for
<xref ref-type="fig" rid="f5">Figure 5A</xref> and 2.0× for
<xref ref-type="fig" rid="f5">Figure 5B</xref>. Stacks were acquired in single-sided illumination. The acquired channel represents the expression of php.eB AAV (
<xref rid="ref-20" ref-type="bibr">Chan
<italic>et al.</italic>, 2017</xref>) through endogenous expression of TdTomato (Ex: 561 nm, EM: LP 561 nm, BrightLine HC, AHF). Final voxel sizes are 8.23 μm in XY and 5 μm in Z for
<xref ref-type="fig" rid="f5">Figure 5A</xref>, and 3.26 μm in XY, and 3 μm in Z for
<xref ref-type="fig" rid="f5">Figure 5B</xref>. pAAV-FLEX-tdTomato was a gift from Edward Boyden (Addgene plasmid # 28306 ;
<ext-link ext-link-type="uri" xlink:href="http://n2t.net/addgene:28306">http://n2t.net/addgene:28306</ext-link> ; RRID:Addgene_28306)</p>
      <p><bold><italic>Drosophila larva brain (
<xref ref-type="fig" rid="f5">Figure 5C</xref>).</italic></bold> The sample was dissected in PBS and suspended in a 2 mm diameter capillary with 1% agarose and imaged on a Zeiss Lightsheet Z1 using a 20×/1.0 water objective. A single channel with dual-sided illumination was acquired in GFP over a Z-stack. This acquisition was repeated over four angles (multiview acquisition) at 90° intervals. The acquired channel represents endogenous expression of nuclear GFP on a subset of motoneurons (Ex: 488 nm Em: BP 525 – 545 nm). Original acquisitions yielded voxel sizes of 0.46 μm in XY and 1.16 μm in Z. The resulting multiview acquisition was registered and fused to an isotropic voxel size of 0.46 μm using BigStitcher (
<xref rid="ref-6" ref-type="bibr">Hörl
<italic>et al.</italic>, 2019</xref>).</p>
    </sec>
    <sec>
      <title>Common display methods and comparison with DEVILS</title>
      <p>One of the benefits of LSFM is that large specimens can be imaged at subcellular resolution. However, the modulation contrast obtained with diffraction limited light microscopy scales with the size of the imaged objects. An object with a size equal to the diffraction limit of the imaging system is half as bright compared to objects with two times the size of the diffraction limit. The intensity of objects with sizes half the diffraction limit is a mere 10% compared to the larger objects mentioned earlier (
<xref rid="ref-16" ref-type="bibr">Williams &amp; Becklund, 2002</xref>). Adding variation of biomarker expression and staining efficiency to the equation makes it clear that images of specimens with both large and small objects will contain areas whose intensity differs by several orders of magnitude. Brain tissue constitutes a prominent example (see
<xref ref-type="fig" rid="f1">Figure 1</xref>). Regions with clusters of cells with high pixel intensities and rather dim individual cells typically make displaying the image even more challenging. In the following section, we will compare common display modifications and outline the DEVILS plugin.</p>
      <p>In
<xref ref-type="fig" rid="f1">Figure 1</xref> one optical plane of a chemically cleared part of a mouse brain is displayed, acquired with a LSFM. Meaningful inspection of the dataset requires use of the entire dynamic range of the camera throughout the acquisition and its processing for inspection.
<xref ref-type="fig" rid="f1">Figure 1A</xref> displays the image data using a grey-scale lookup table (LUT), using the minimum and maximum pixel value as the upper and the lower limit for the display mapping function. This procedure is not giving satisfactory results as only the bright structures in the lower right corner are visible.</p>
      <p>Better visualisation of image data is obtained with a coloured LUT as the human eye can distinguish more colours than grey scales. This standard approach exploits the 24 bits of information (RGB colour) to render a wide range of intensities of a single channel visible (
<xref rid="ref-14" ref-type="bibr">Silva
<italic>et al.</italic>, 2011</xref>).
<xref ref-type="fig" rid="f1">Figure 1B</xref> shows the application of the “Fire” LUT from Fiji, using the minimum and the maximum pixel value as the upper and the lower limit for the display mapping function. Comparison with
<xref ref-type="fig" rid="f1">Figure 1A</xref> reveals that faint structures can be better recognized in the coloured image. However, the improvement is not sufficient to display all image data.
<xref ref-type="fig" rid="f1">Figure 1C and 1D</xref> illustrate that more structures become visible when adjusting the linear display function. These linear display adjustments combined with coloured LUTs are still not sufficient to display all of the image information: structures that are not visible in the top right corner of the image in
<xref ref-type="fig" rid="f1">Figure 1B and 1C</xref> become visible in
<xref ref-type="fig" rid="f1">Figure 1D</xref> when the maximum of the display function is lowered. However, clipping artefacts are visible at the same time for the brightest structures in the middle of the image.</p>
      <p>Another well-known approach to improve visualization is the application of non-linear display functions. The most common one is gamma correction, which modifies the display exponentially using a value ɣ as the exponent of the original pixel intensity. Using ɣ &gt;1 facilitates the recognition of bright structures. Thus, it can be used to suppress a homogeneous background in the sample (e.g. out of focus light, autofluorescence or unspecific antibody staining). However, it is of note that dim structures disappear (
<xref ref-type="fig" rid="f1">Figure 1E</xref>). To help visualise dim structures, ɣ &lt;1 is better suited. For example, using ɣ = 0.5, mathematically identical to calculating the square root of the image, helps to identify faint objects in the top right part of the image (
<xref ref-type="fig" rid="f1">Figure 1F</xref>). Note that fainter objects are easier to identify than in the aforementioned images using linear display settings (
<xref ref-type="fig" rid="f1">Figure 1A – D</xref>).</p>
      <p>A suitable method to correct unwanted background intensity values is to divide the original image by a blurred version of itself. The resulting image of such an operation is shown in
<xref ref-type="fig" rid="f1">Figure 1G</xref>. The operation acts as a high-pass filter. It requires careful selection of the width of the gaussian filter and can lead to artefacts on the edge of objects, as well as an increase of the background signal and of the noise in the faintest areas of the original image. Using a so-called ‘Subtract Background’ method (aka rolling ball method) one can avoid such undesired perception effects (
<xref ref-type="fig" rid="f1">Figure 1H</xref>) but this does not help much with reducing the range between the low and high intensity values.</p>
      <p>Local contrast enhancement as implemented in the CLAHE plugin of Fiji/ImageJ turned out to be non-trivial in finding the right parameters (see Supplementary Figure S2.). Therefore, we propose here a simple workflow that homogenizes the intensities and removes background so that high and low intensities are visible simultaneously for the human eye. It requires one parameter
<italic>p</italic>, the pixel size of the object of interest. The obtained result is the image
<xref ref-type="fig" rid="f1">Figure 1I</xref> that allows the observer to visualize low and high intensity objects without further adjustments.</p>
    </sec>
    <sec>
      <title> DEVILS implementation</title>
      <p>Our current implementation of the aforementioned operations is a Fiji plugin that uses a simple image processor and parallelizes its processing on the available cores of the machine (
<xref ref-type="fig" rid="f2">Figure 2A</xref>). This enables the processing of large image stacks in a reasonable amount of time: it takes seven minutes to process a 12 GB stack on a workstation typically used for image processing. The plugin reads the selected file as a virtual stack and accesses each individual plane for processing. Only one parameter
<italic>p</italic> is needed. It shall correlate with the size of the largest object in the image, in pixels. The plugin performs a division by a Gaussian blurred version of the image (=2p), calculates the square root and subtracts the background using the rolling ball method as implemented in Fiji, with a radius equal to
<italic>p</italic>. The output images are then exported as individual tif files. A virtual stack reconstituted from the individual tif files can be opened with a ‘Open DEVILS Folder’ command. Furthermore, images can also be exported in the Hdf5 format, which allows their inspection with the BigDataViewer (
<xref rid="ref-10" ref-type="bibr">Pietzsch
<italic>et al.</italic>, 2015</xref>).</p>
      <fig fig-type="figure" id="f2" orientation="portrait" position="anchor">
        <label>Figure 2. </label>
        <caption>
          <title>Implementation of DEVILS in ImageJ/Fiji.</title>
          <p>(
<bold>A</bold>) Schematic workflow of the DEVILS ImageProcessor (IP) operation and its parallelization in order to handle large image stacks.</p>
          <p>(
<bold>B</bold>) Graphical user interface of the plugin. In the standard mode, only the image location and the parameter
<italic>p</italic> is required from the user. The advanced mode enables the user to define the output directory, define an object size per channel, minimum and maximum values for conversion (necessary with 8-bit and 16-bit output) and the output bit depth (8-, 16- or 32-bit).</p>
          <p>(
<bold>C</bold>) Graphical user interface of the preview plugin.</p>
        </caption>
        <graphic xlink:href="f1000research-9-54174-g0001"/>
      </fig>
      <p>All parameters are entered via a graphical user interface (GUI) as shown in
<xref ref-type="fig" rid="f2">Figure 2B</xref> and are recordable as a macro. The advanced parameter options allow the user to specify the output folder, change the output bit-depth of the images (8-, 16- or 32-bit) and specify the minimum and maximum ranges for conversion to an 8-bit or 16-bit image. Such a conversion decreases the size of the output data but requires careful selection of the minimum and maximum values to avoid data clipping artefacts. In the basic mode, a minimum and maximum of -100 and 10000, respectively, are set and the image bit depth is fixed at 16-bit. For rapid testing of the DEVILS operation, a preview mode is available (
<xref ref-type="fig" rid="f2">Figure 2C</xref>). It processes a single image and can be used for parameter optimization e.g. to find suitable values for the image conversion.</p>
    </sec>
    <sec>
      <title>Operation</title>
      <p>A machine with 8GB of RAM or above will be able to run DEVILS, provided it has enough RAM to contain a single XY plane of your data at any time. DEVILS requires Fiji to run, and can be installed by checking the PTBIOP update site under Help &gt; Update &gt; Manage Update Sites (
<ext-link ext-link-type="uri" xlink:href="https://imagej.net/Update_Sites">https://imagej.net/Update_Sites</ext-link>).</p>
    </sec>
    <sec>
      <title>Synthetic images</title>
      <p>To better understand the effects of the DEVILS plugin on image data, we applied it to a synthetic image containing disks with increasing intensities (5 – 250) and with increasing diameters (7 – 50 pixels) (
<xref ref-type="fig" rid="f3">Figure 3A</xref>). A background of 2 intensity units was added and the entire signal was subjected to Gaussian noise with a standard deviation of 0.5. Despite the use of the “Fire” LUT, it is impossible to observe the smallest and faintest spots in the original 8-bit image. The intensity profiles for each row of disks with varying diameter are plotted in
<xref ref-type="fig" rid="f3">Figure 3B</xref> using different colours (smaller diameter in red, larger diameter in violet). The profiles are similar with intensities increasing from left to right independent of their respective diameters. Similar results are obtained for vertical intensity profiles (
<xref ref-type="fig" rid="f3">Figure 3C</xref>). The intensity of the disks is independent of its size.</p>
      <fig fig-type="figure" id="f3" orientation="portrait" position="anchor">
        <label>Figure 3. </label>
        <caption>
          <title>Synthetic images to illustrate the effect of DEVILS.</title>
          <p>(
<bold>A</bold>) Synthetic image of disks with increasing pixel intensity values from left to right (5, 10, 20, 50, 100, 150, 250) and of increasing diameter from top to bottom (7 px, 9 px, 11 px, 15 px, 20 px, 25 px, 50 px). Display settings are set to the minimum and maximum intensity values of the image and the “Fire” LUT is used for display. (
<bold>B</bold>) Vertical line profiles over disks shown in
<bold>A</bold>. The different diameters are labelled with different colours. (
<bold>C</bold>) Horizontal line profiles over disks shown in
<bold>A</bold>. the different intensities are labelled with different colours. (
<bold>D</bold>) Image
<bold>A</bold> processed with the DEVILS plugin (
<italic>p</italic> = 25). (
<bold>E</bold>) Vertical line profiles over disks shown in
<bold>D</bold>. The different diameters are labelled with different colours. (
<bold>F</bold>) Horizontal line profiles over disks shown in
<bold>D</bold>. the different intensities are labelled with different colours.</p>
        </caption>
        <graphic xlink:href="f1000research-9-54174-g0002"/>
      </fig>
      <p>The effect of the DEVILS plugin is visible in
<xref ref-type="fig" rid="f3">Figure 3D</xref>, with the smaller and fainter spots now being visible (top left corner of the image) and the intensity of the larger and brighter spots being compressed. The line profiles in
<xref ref-type="fig" rid="f3">Figure 3E – F</xref> reveal that the DEVILS output is scaling with the size and the intensity of the input disk. It becomes obvious that larger disks and brighter disks become dimmer after DEVILS processing. The intensity amplification factor (see Figure S5,
<italic>Extended data</italic> (
<xref rid="ref-4" ref-type="bibr">Guiet
<italic>et al.</italic>, 2020a</xref>)) is larger for low intensity objects of small size. In the example shown here the ratio of input to output object intensity is around two for the dimmest and smallest object (
<italic>r</italic> = 7,
<italic>I</italic> = 5). It drops to 1.6 for the largest object with the same intensity. It drops more markedly with increasing intensity. It is around one for
<italic>I</italic> = 20 and drops to 0.25 for the smallest disk with the maximum intensity (
<italic>r</italic> = 7,
<italic>I</italic> = 250). The intensity of the largest object (
<italic>r</italic> = 50) is damped by a factor of 0.07. In summary: small, dim objects are becoming brighter, the pixel intensity of large, bright objects is reduced. The maximal amplification difference between the smallest dimmest object and the largest brightest object is 30 in the example shown. This enables the researcher to inspect these objects in one single image. However, it must be stressed that the intensity of the signal can by no means be correlated to the protein, antigen or antibody concentration after the DEVILS plugin has been applied.</p>
      <p>Furthermore, the parameter
<italic>p</italic> needs to be carefully chosen. In case it is smaller than the largest objects, artefacts in these objects can be observed. The line profile after DEVILS treatment (
<italic>p</italic> = 25) of the disks with a diameter of 50 pixels indicate that the intensity inside the disk is lower than at the edges. This effect can be avoided by increasing the parameter
<italic>p</italic> to 50 or above.</p>
    </sec>
  </sec>
  <sec>
    <title>Use cases</title>
    <sec>
      <title>Multichannel images</title>
      <p>In
<xref ref-type="fig" rid="f4">Figure 4</xref> the DEVILS plugin was used in order to facilitate the inspection of a 3D multichannel dataset. Dopaminergic neurons in the mouse midbrain expressing the fluorescent protein tdTomato were immunostained with an α-tyrosine hydroxylase (TH) antibody, visualized with an Alexa Fluor 488 secondary antibody (AF488). DAPI was used as a nuclear counterstain. The plugin was applied to each channel separately. The overlay of the raw images and the outcome of the DEVILS operation are shown in the main panels of
<xref ref-type="fig" rid="f4">Figure 4A and 4B</xref>, respectively. Several observations can be made when comparing cropped regions from raw and processed images (dashed square in
<xref ref-type="fig" rid="f4">Figure 4A – B</xref>). First, DEVILS processing reveals a lot of hidden detail; this is visible in all channels, but most marked in the AF488 channel. Second, the intensity drop of individual acquisition tiles towards their edges is reduced after DEVILS processing. Third, a final advantage can be seen in the intensity profile plots along the Z-axis of the image stack: DEVILS processing significantly flattens the bell-shaped curve of the mean intensity per plane (
<xref ref-type="fig" rid="f4">Figure 4D and 4F</xref>). This enables a more rapid inspection of the 3D-dataset as no intensity adjustments need to be made when moving between planes. In fact, the entire dataset can now be visualized with the same display settings. The utility of DEVILS is furthermore demonstrated in
<xref ref-type="fig" rid="f5">Figure 5</xref> where it was applied to datasets acquired from different species and different microscope setups.</p>
      <fig fig-type="figure" id="f4" orientation="portrait" position="anchor">
        <label>Figure 4. </label>
        <caption>
          <title>DEVILS applied to a multichannel image.</title>
          <p>A part of a cleared mouse midbrain was imaged using light-sheet fluorescence microscopy (LSFM). (
<bold>A</bold>) Raw and merged display of the three individual channels of a single optical slice. The DAPI nuclear counterstain is false coloured in azure, the α-TH staining is shown in chartreuse (AF488) and the dopaminergic neurons in bright pink (tdTomato). The image is assembled from 24 individual tile images. The dashed square indicates a region used for cropping. Crops for each of the individual channels are shown below the main panel. Scale bars: 250 µm. (
<bold>B</bold>) Image
<bold>A</bold> after DEVILS processing (
<italic>p</italic> = 25). (
<bold>C</bold>) Cropped region from
<bold>A</bold> showing the dopaminergic neurons at different Z-positions in the image stack, using the “Fire” look-up table (LUT) and auto contrast adjustment set to 0.35 on slice 280. Scale bar: 250 µm. (
<bold>D</bold>) Mean (black) and maximum (Max, grey) intensities (left and right Y-axes, resp.) of the acquisition channel as shown in panel
<bold>C</bold> per Z-plane (X-axis). (
<bold>E</bold>) Cropped region from
<bold>B</bold> showing the dopaminergic neurons at different Z-positions in the image stack, using the Fire LUT and auto contrast adjustment set to 0.35. (
<bold>F</bold>) Mean (black) and maximum (Max, grey) intensities (left and right Y-axes, resp.) of the acquisition channel as shown in panel
<bold>E</bold> per Z-plane (X-axis).</p>
        </caption>
        <graphic xlink:href="f1000research-9-54174-g0003"/>
      </fig>
      <fig fig-type="figure" id="f5" orientation="portrait" position="anchor">
        <label>Figure 5. </label>
        <caption>
          <title>Example images of DEVILS processing.</title>
          <p>(
<bold>A</bold>) Cleared mouse brain acquired with a mesoSPIM\0.8X. Comparison of raw and DEVILS processed images of a Z-color-coded projection using the “Physics” look-up table (LUT). The auto contrast was set on slice 600. Scale bar: 500 µm. (
<bold>B</bold>) Cleared mouse brain acquired with a mesoSPIM\2.0X. Comparison of raw and DEVILS processed images of a Z-color-coded projection using the “Physics” LUT. The auto contrast was set on slice 600. Scale bar: 500 µm. (
<bold>C</bold>)
<italic>Drosophila</italic> brain acquired with light-sheet fluorescence microscopy (LSFM). Comparison of raw and DEVILS processed images of a Z-color-coded projection using the Physics LUT. The auto contrast was set on slice 380. Scale bar: 50 µm.</p>
        </caption>
        <graphic xlink:href="f1000research-9-54174-g0004"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="conclusion">
    <title>Conclusion</title>
    <p>We presented the DEVILS plugin, which is capable of simultaneously displaying structures with intensities differing by several orders of magnitude. The limitations of currently available displays and visualization methods preclude viewing image data with such a dynamic range. DEVILS, implemented as a Fiji/ImageJ Plugin, homogenizes intensity differences and removes global and local background. This approach facilitates the inspection of image data with high and low intensities in a single view while at the same time allowing for the rapid inspection of volumetric 3D datasets.</p>
    <p>The plugin modifies the pixel intensities in a non-linear way and is dependent on the size of the object, its 2D environment and the intensity itself. Intensity-based interpretation of processed image data is therefore not possible. However, it is a versatile tool for the visual inspection of large volumetric datasets, such as those typically obtained from LSFM. Prompt inspection of these datasets is key when assessing the quality of the data and deciding on further acquisition, processing and analysis strategies. Until now, a rapid method to display data with intensity differences covering several orders of magnitude was missing. DEVILS is providing an easy and straightforward approach to overcome these current limitations.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <sec>
      <title>Underlying data</title>
      <p>Figshare: Data: DEVILS: a tool for the visualization of large datasets with a high dynamic range.
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.c.5197940.v2">https://doi.org/10.6084/m9.figshare.c.5197940.v2</ext-link> (
<xref rid="ref-2" ref-type="bibr">Guiet
<italic>et al.</italic>, 2020b</xref>)</p>
      <p>This project contains the following underlying data:</p>
      <list list-type="simple">
        <list-item>
          <label>- </label>
          <p>Dataset Figure Fig1, Fig3 (raw data underlying Figures 1 and 4 in czi format)</p>
        </list-item>
        <list-item>
          <label>- </label>
          <p>Dataset Figure 5a, b (raw data underlying Figure 5A and 5B in czi format)</p>
        </list-item>
        <list-item>
          <label>- </label>
          <p>Dataset Figure 5c (raw data underlying Figure 5C in czi format)</p>
        </list-item>
      </list>
    </sec>
    <sec>
      <title>Extended data</title>
      <p>Zenodo: DEVILS: a tool for the visualization of large datasets with a high dynamic range.
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.4457159">https://doi.org/10.5281/zenodo.4457159</ext-link> (
<xref rid="ref-4" ref-type="bibr">Guiet
<italic>et al.</italic>, 2020a</xref>).</p>
      <p>This project contains the following extended data:</p>
      <list list-type="simple">
        <list-item>
          <label>- </label>
          <p>Extended data.pdf (details of sample preparation and image acquisition for Figures 1, 4 and 5; supplementary figures)</p>
        </list-item>
        <list-item>
          <label>- </label>
          <p>Workflow description.pdf (workflow describing how to process the provided “.czi” file, with BigStitcher and then with DEVILS)</p>
        </list-item>
      </list>
      <p>Data are available under the terms of the
<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/legalcode">Creative Commons Attribution 4.0 International license</ext-link> (CC-BY 4.0).</p>
    </sec>
  </sec>
  <sec>
    <title>Software availability</title>
    <p>Source code available from:
<ext-link ext-link-type="uri" xlink:href="https://github.com/BIOP/ijp-DEVILS">https://github.com/BIOP/ijp-DEVILS</ext-link>
</p>
    <p>Archived source code at time of publication:
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.4457443">https://doi.org/10.5281/zenodo.4457443</ext-link> (
<xref rid="ref-5" ref-type="bibr">Guiet
<italic>et al.</italic>, 2020c</xref>).</p>
    <p>License:
<ext-link ext-link-type="uri" xlink:href="https://opensource.org/licenses/GPL-3.0">GNU General Public License version 3</ext-link>
</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgements</title>
    <p>We gratefully acknowledge the Advanced Lightsheet Imaging Center (ALICe) of the Wyss Center (Geneva, Switzerland) for image acquisition, Thierry Laroche for help with the Z1 imaging, Sverre Grødem and Marianne Fynn for brain sample preparation, Wei Jiao of the group of Prof. Brian McCabe (EPFL, Lausanne, Switzerland) for providing the
<italic>Drosophila</italic> embryos and the Faculty of Life Sciences at the EPFL for continuous support to the BioImaging &amp; Optics platform (BIOP). This publication was supported by COST Action NEUBIAS (CA15124), funded by COST (European Cooperation in Science and Technology).</p>
  </ack>
  <ref-list>
    <ref id="ref-20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>KY</given-names></name><name><surname>Jang</surname><given-names>MJ</given-names></name><name><surname>Yoo</surname><given-names>BB</given-names></name><etal/></person-group>:
<article-title>Engineered AAVs for efficient noninvasive gene delivery to the central and peripheral nervous systems.</article-title><source><italic toggle="yes">Nat Neurosci.</italic></source><year>2017</year>;<volume>20</volume>(<issue>8</issue>):<fpage>1172</fpage>–<lpage>1179</lpage>.
<pub-id pub-id-type="doi">10.1038/nn.4593</pub-id><!--<pub-id pub-id-type="pmcid">5529245</pub-id>--><?supplied-pmid 28671695?><pub-id pub-id-type="pmid">28671695</pub-id></mixed-citation>
    </ref>
    <ref id="ref-4">
      <mixed-citation publication-type="data"><person-group person-group-type="author"><name><surname>Guiet</surname><given-names>R</given-names></name><name><surname>Burri</surname><given-names>O</given-names></name><name><surname>Chiaruttini</surname><given-names>N</given-names></name><etal/></person-group>:
<article-title>DEVILS: a tool for the visualization of large datasets with a high dynamic range.</article-title><source><italic toggle="yes">Zenodo.</italic></source><year>2020a</year>.
<pub-id pub-id-type="doi">10.5281/zenodo.4058414</pub-id></mixed-citation>
    </ref>
    <ref id="ref-2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guiet</surname><given-names>R</given-names></name><name><surname>Burri</surname><given-names>O</given-names></name><name><surname>Chiaruttini</surname><given-names>N</given-names></name><etal/></person-group>:
<article-title>Data: DEVILS: a tool for the visualization of large datasets with a high dynamic range.</article-title><source><italic toggle="yes">figshare.</italic></source>Collection.<year>2020b</year>.
<pub-id pub-id-type="doi">10.6084/m9.figshare.c.5197940.v2</pub-id></mixed-citation>
    </ref>
    <ref id="ref-5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guiet</surname><given-names>R</given-names></name><name><surname>Seitz</surname><given-names>A</given-names></name><name><surname>Burri</surname><given-names>O</given-names></name><etal/></person-group>:
<article-title>BIOP/ijp-DEVILS: Release for Publication (Version v1.0.2).</article-title><source><italic toggle="yes">Zenodo.</italic></source><year>2020c</year>.
<pub-id pub-id-type="doi">10.5281/zenodo.4095054</pub-id></mixed-citation>
    </ref>
    <ref id="ref-6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hörl</surname><given-names>D</given-names></name><name><surname>Rusak</surname><given-names>FR</given-names></name><name><surname>Preusser</surname><given-names>F</given-names></name><etal/></person-group>:
<article-title>BigStitcher: reconstructing high-resolution image datasets of cleared and expanded samples.</article-title><source><italic toggle="yes">Nat Methods.</italic></source><year>2019</year>;<volume>16</volume>(<issue>9</issue>):<fpage>870</fpage>–<lpage>874</lpage>.
<pub-id pub-id-type="doi">10.1038/s41592-019-0501-0</pub-id><?supplied-pmid 31384047?><pub-id pub-id-type="pmid">31384047</pub-id></mixed-citation>
    </ref>
    <ref id="ref-8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>E</given-names></name><name><surname>Choi</surname><given-names>J</given-names></name><name><surname>Jo</surname><given-names>Y</given-names></name><etal/></person-group>:
<article-title>ACT-PRESTO: Rapid and consistent tissue clearing and labeling method for 3-dimensional (3D) imaging.</article-title><source><italic toggle="yes">Sci Rep.</italic></source><year>2016</year>;<volume>6</volume>:<fpage>18631</fpage>.
<pub-id pub-id-type="doi">10.1038/srep18631</pub-id><!--<pub-id pub-id-type="pmcid">4707495</pub-id>--><?supplied-pmid 26750588?><pub-id pub-id-type="pmid">26750588</pub-id></mixed-citation>
    </ref>
    <ref id="ref-9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>SH</given-names></name><name><surname>Montag</surname><given-names>ED</given-names></name></person-group>:
<article-title>Evaluating tone mapping algorithms for rendering non-pictorial (scientific) high-dynamic-range images.</article-title><source><italic toggle="yes">J Vis Commun Image Represent.</italic></source><year>2007</year>;<volume>18</volume>(<issue>5</issue>):<fpage>415</fpage>–<lpage>428</lpage>.
<pub-id pub-id-type="doi">10.1016/j.jvcir.2007.06.008</pub-id></mixed-citation>
    </ref>
    <ref id="ref-10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pietzsch</surname><given-names>T</given-names></name><name><surname>Saalfeld</surname><given-names>S</given-names></name><name><surname>Preibisch</surname><given-names>S</given-names></name><etal/></person-group>:
<article-title>BigDataViewer: visualization and processing for large image data sets.</article-title><source><italic toggle="yes">Nat Methods.</italic></source><year>2015</year>;<volume>12</volume>(<issue>6</issue>):<fpage>481</fpage>–<lpage>483</lpage>.
<pub-id pub-id-type="doi">10.1038/nmeth.3392</pub-id><?supplied-pmid 26020499?><pub-id pub-id-type="pmid">26020499</pub-id></mixed-citation>
    </ref>
    <ref id="ref-11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salih</surname><given-names>Y</given-names></name><name><surname>bt Md-Esa</surname><given-names>W</given-names></name><name><surname>Malik</surname><given-names>AS</given-names></name><etal/></person-group>:
<article-title>Tone mapping of HDR images: A review</article-title>. In
<italic>2012 4th International Conference on Intelligent and Advanced Systems (ICIAS2012)</italic>, (Kuala Lumpur, Malaysia: IEEE),<year>2012</year>;<fpage>368</fpage>–<lpage>373</lpage>.
<pub-id pub-id-type="doi">10.1109/ICIAS.2012.6306220</pub-id></mixed-citation>
    </ref>
    <ref id="ref-12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schindelin</surname><given-names>J</given-names></name><name><surname>Arganda-Carreras</surname><given-names>I</given-names></name><name><surname>Frise</surname><given-names>E</given-names></name><etal/></person-group>:
<article-title>Fiji: an open-source platform for biological-image analysis.</article-title><source><italic toggle="yes">Nat Methods.</italic></source><year>2012</year>;<volume>9</volume>(<issue>7</issue>):<fpage>676</fpage>–<lpage>682</lpage>.
<pub-id pub-id-type="doi">10.1038/nmeth.2019</pub-id><!--<pub-id pub-id-type="pmcid">3855844</pub-id>--><?supplied-pmid 22743772?><pub-id pub-id-type="pmid">22743772</pub-id></mixed-citation>
    </ref>
    <ref id="ref-14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silva</surname><given-names>S</given-names></name><name><surname>Santos</surname><given-names>SB</given-names></name><name><surname>Madeira</surname><given-names>J</given-names></name></person-group>:
<article-title>Using color in visualization: A survey.</article-title><source><italic toggle="yes">Comput Graph.</italic></source><year>2011</year>;<volume>35</volume>(<issue>2</issue>):<fpage>320</fpage>–<lpage>333</lpage>.
<pub-id pub-id-type="doi">10.1016/j.cag.2010.11.015</pub-id></mixed-citation>
    </ref>
    <ref id="ref-15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voigt</surname><given-names>FF</given-names></name><name><surname>Kirschenbaum</surname><given-names>D</given-names></name><name><surname>Platonova</surname><given-names>E</given-names></name><etal/></person-group>:
<article-title>The mesoSPIM initiative: open-source light-sheet microscopes for imaging cleared tissue.</article-title><source><italic toggle="yes">Nat Methods.</italic></source><year>2019</year>;<volume>16</volume>(<issue>11</issue>):<fpage>1105</fpage>–<lpage>1108</lpage>.
<pub-id pub-id-type="doi">10.1038/s41592-019-0554-0</pub-id><!--<pub-id pub-id-type="pmcid">6824906</pub-id>--><?supplied-pmid 31527839?><pub-id pub-id-type="pmid">31527839</pub-id></mixed-citation>
    </ref>
    <ref id="ref-16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>CS</given-names></name><name><surname>Becklund</surname><given-names>OA</given-names></name></person-group>:
<article-title>Introduction to the optical transfer function</article-title>. (Bellingham, Wash: SPIE Press).<year>2002</year>.
<pub-id pub-id-type="doi">10.1117/3.2265056</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article id="report82909" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.54174.r82909</article-id>
    <title-group>
      <article-title>Reviewer response for version 2</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Masud</surname>
          <given-names>Mehedi</given-names>
        </name>
        <xref ref-type="aff" rid="r82909a1">1</xref>
        <role>Referee</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6019-7245</contrib-id>
      </contrib>
      <aff id="r82909a1"><label>1</label>College of Computers and Information Technology, Taif University, Taif, Saudi Arabia</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>4</day>
      <month>5</month>
      <year>2021</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2021 Masud M</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d39e1423" ext-link-type="doi" xlink:href="10.12688/f1000research.25447.2">Version 2</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <list list-type="bullet">
        <list-item>
          <p>The motivation needs more clarification.</p>
        </list-item>
        <list-item>
          <p>The rationale of this tool is not clear, particularly in which domain this tool will be suitable? </p>
        </list-item>
        <list-item>
          <p>What dataset the paper is considered?</p>
        </list-item>
        <list-item>
          <p>Is it suitable for medical datasets or what?</p>
        </list-item>
        <list-item>
          <p>The acronyms' style should be the same. See example:</p>
          <p> light-sheet fluorescence microscopy (LSFM)</p>
          <p> Display Enhancement for Visual Inspection of Large Stacks (DEVILS).</p>
        </list-item>
      </list>
    </p>
    <p>Are the conclusions about the tool and its performance adequately supported by the findings presented in the article?</p>
    <p>Yes</p>
    <p>Is the rationale for developing the new software tool clearly explained?</p>
    <p>Partly</p>
    <p>Is the description of the software tool technically sound?</p>
    <p>Yes</p>
    <p>Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others?</p>
    <p>Yes</p>
    <p>Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool?</p>
    <p>Partly</p>
    <p>Reviewer Expertise:</p>
    <p>Deep learning for Medical diagnosis</p>
    <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
  </body>
</sub-article>
<sub-article id="report81839" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.54174.r81839</article-id>
    <title-group>
      <article-title>Reviewer response for version 2</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Tosi</surname>
          <given-names>Sebastien</given-names>
        </name>
        <xref ref-type="aff" rid="r81839a1">1</xref>
        <role>Referee</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8348-2778</contrib-id>
      </contrib>
      <aff id="r81839a1"><label>1</label>Institute for Research in Biomedicine, IRB Barcelona, Barcelona Institute of Science and Technology (BIST), Barcelona, Spain</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>29</day>
      <month>3</month>
      <year>2021</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2021 Tosi S</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d39e1528" ext-link-type="doi" xlink:href="10.12688/f1000research.25447.2">Version 2</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>Thanks to the authors for addressing my comments. The only feature I would further suggest is that the plugin maintains the channel colors and composite mode settings from the original image when applied in Preview mode. Also, it would probably help to perform some automatic contrast adjustement on all channels instead of using the defaults min/max in Basic mode.</p>
    <p>Are the conclusions about the tool and its performance adequately supported by the findings presented in the article?</p>
    <p>Partly</p>
    <p>Is the rationale for developing the new software tool clearly explained?</p>
    <p>Yes</p>
    <p>Is the description of the software tool technically sound?</p>
    <p>Yes</p>
    <p>Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others?</p>
    <p>Yes</p>
    <p>Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool?</p>
    <p>Partly</p>
    <p>Reviewer Expertise:</p>
    <p>Signal processing, image processing, computer science</p>
    <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard.</p>
  </body>
</sub-article>
<sub-article id="report75553" article-type="peer-review">
  <front-stub>
    <article-id pub-id-type="doi">10.5256/f1000research.28080.r75553</article-id>
    <title-group>
      <article-title>Reviewer response for version 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Tosi</surname>
          <given-names>Sebastien</given-names>
        </name>
        <xref ref-type="aff" rid="r75553a1">1</xref>
        <role>Referee</role>
        <contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-8348-2778</contrib-id>
      </contrib>
      <aff id="r75553a1"><label>1</label>Institute for Research in Biomedicine, IRB Barcelona, Barcelona Institute of Science and Technology (BIST), Barcelona, Spain</aff>
    </contrib-group>
    <author-notes>
      <fn fn-type="COI-statement">
        <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>17</day>
      <month>12</month>
      <year>2020</year>
    </pub-date>
    <permissions>
      <copyright-statement>Copyright: © 2020 Tosi S</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access peer review report distributed under the terms of the Creative Commons Attribution Licence, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <related-article related-article-type="peer-reviewed-article" id="d39e1612" ext-link-type="doi" xlink:href="10.12688/f1000research.25447.1">Version 1</related-article>
    <custom-meta-group>
      <custom-meta>
        <meta-name>recommendation</meta-name>
        <meta-value>approve-with-reservations</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>The authors introduce an ImageJ plugin to enhance the contrast of small, dim objects in microscopy images without saturating brighter regions. Overall the technique enables a single shot view of complex images with large dynamic range without having to constantly fiddle with the contrast adjustments. The plugin is compatible with large 3D images and it somehow complements existing techniques, but its implementation suffers from several glitches that should be addressed (see Software related issues).</p>
    <p>
      <bold><underline>Potential improvements</underline>:</bold>
    </p>
    <p> For completeness, ImageJ Enhance Local Contrast (CLAHE) with window size adjusted to the size of largest objects should be included to the comparison (Figure 1 and related text).</p>
    <p> Some ImageJ native functions (e.g. subtract background) already leverage multiple cores so it is not clear what advantage brings the thread parallelization described. A speed comparison (with and without parallelization) would help. Also, the hardware used for the test report should be precisely described (especially the number of cores of the workstation).</p>
    <p> It is not clear why the default minimum grayscale value is set to -100. If this is due to the subtract background performed, I would recommend running it with “Disable Smoothing” and setting the default minimum grayscale value to 0.</p>
    <p> It is not clear what is the advantage of opening an exported folder with “Open DEVILS folder” instead of importing the image sequence. This should be motivated.</p>
    <p> The extra parameters of the “DEVILS Preview” dialog box should ideally only appear when ticking “Use advanced parameters” and “Largest_object_size” should not appear twice as this is rather confusing.</p>
    <p> I strongly suggest to better highlight the install procedure from ImageJ update sites both in the manuscript and in GitHub.</p>
    <p>
      <bold><underline>Software related issues</underline>:</bold>
    </p>
    <p> When running “DEVILS Preview”, the images obtained are very dim and their grayscale values do not correspond to the values actually exported when applying DEVILS with the same settings. </p>
    <p> I got an error when applying the operation from DEVILS Preview: “Unrecognized command “DEVILS Preview”.</p>
    <p>
      <bold><underline>Wording</underline>:</bold>
    </p>
    <p> The words used throughout the text should be more consistent, for instance: “DEVILS Workflow”, “DEVILS Routine”, “DEVILS Algorithm”, “DEVILS operation” or “Slice”, “Plane”, “Z-Plane” should be unified.</p>
    <p> This sentence should be rephrased: “A popular method to remove intensity values from large objects is to divide the image by its blurred version”.</p>
    <p>Are the conclusions about the tool and its performance adequately supported by the findings presented in the article?</p>
    <p>Partly</p>
    <p>Is the rationale for developing the new software tool clearly explained?</p>
    <p>Yes</p>
    <p>Is the description of the software tool technically sound?</p>
    <p>Yes</p>
    <p>Are sufficient details of the code, methods and analysis (if applicable) provided to allow replication of the software development and its use by others?</p>
    <p>Yes</p>
    <p>Is sufficient information provided to allow interpretation of the expected output datasets and any results generated using the tool?</p>
    <p>Partly</p>
    <p>Reviewer Expertise:</p>
    <p>Signal processing, image processing, computer science</p>
    <p>I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard, however I have significant reservations, as outlined above.</p>
  </body>
  <sub-article id="comment6295-75553" article-type="response">
    <front-stub>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Seitz</surname>
            <given-names>Arne</given-names>
          </name>
          <aff/>
        </contrib>
      </contrib-group>
      <author-notes>
        <fn fn-type="COI-statement">
          <p><bold>Competing interests: </bold>No competing interests were disclosed.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>22</day>
        <month>1</month>
        <year>2021</year>
      </pub-date>
    </front-stub>
    <body>
      <p>Dear Sebastien,</p>
      <p> Thanks for carefully reading our manuscript and your useful comments and suggestions. We are grateful for them and convinced that they help to improve the quality of the publication as well as its understandability as well as the DEVILS plugin.</p>
      <p> Whenever possible we addressed your points either in the new version of the manuscript or the supplemental material. Please find the answers to the individual points you mentioned in the following:</p>
      <p>
        <bold>1. For completeness, ImageJ Enhance Local Contrast (CLAHE) with window size adjusted to the size of largest objects should be included to the comparison (Figure 1 and related text).</bold>
      </p>
      <p> We have added a comparison with ImageJ enhance Local Contrast (CLAHE) in the supplemental material and are referring to it in the main text.</p>
      <p> We found that this approach can give equally good results however that the parameter finetuning can be time-consuming. Therefore, we think that DEVILS has some advantages for the visualization of large volumetric datasets.</p>
      <p>
        <bold>2. Some ImageJ native functions (e.g. subtract background) already leverage multiple cores so it is not clear what advantage brings the thread parallelization described. A speed comparison (with and without parallelization) would help. Also, the hardware used for the test report should be precisely described (especially the number of cores of the workstation).</bold>
      </p>
      <p> DEVILS is written so that multiple image planes can be processed in parallel in order to speed up the workflow.</p>
      <p> We have investigated the effect of further parallelization and added the results to the supplemental material section. </p>
      <p>
        <bold>3. It is not clear why the default minimum grayscale value is set to -100. If this is due to the subtract background performed, I would recommend running it with “Disable Smoothing” and setting the default minimum grayscale value to 0.</bold>
      </p>
      <p> We have taken up the suggestion and evaluated the “Disable Smoothing” option. It modifies the resulting image, however negative values are still present as shown by the macro accessible via this
<ext-link ext-link-type="uri" xlink:href="https://gist.github.com/romainGuiet/0700295baa0097986ac418e5b596fcec">gist link</ext-link>, the macro can also be
<ext-link ext-link-type="uri" xlink:href="https://ij.imjoy.io/?run=https://gist.github.com/romainGuiet/0700295baa0097986ac418e5b596fcec">run with the gist link in ij.imjoy.io</ext-link>
</p>
      <p>
        <bold>4. It is not clear what is the advantage of opening an exported folder with “Open DEVILS folder” instead of importing the image sequence. This should be motivated.</bold>
      </p>
      <p> The advantage of the “Open DEVILS folder” is to be able to import processed images as stack or hyperstack directly without the need to specify the order (channels, time, slices). This is in particular useful for multidimensional datasets. We have updated the documentation to explain the advantages of using this folder instead of importing the images manually.</p>
      <p>
        <ext-link ext-link-type="uri" xlink:href="https://github.com/BIOP/ijp-DEVILS#opening-tiff-files--opening-devils-folder">https://github.com/BIOP/ijp-DEVILS#opening-tiff-files--opening-devils-folder</ext-link>
      </p>
      <p>
        <bold>5. The extra parameters of the “DEVILS Preview” dialog box should ideally only appear when ticking “Use advanced parameters” and “Largest_object_size” should not appear twice as this is rather confusing.</bold>
      </p>
      <p> We created two separate commands: DEVILS Preview (Basic) and DEVILS Preview (Advanced) in order to avoid appearing the parameter twice. This helps to avoid the above mentioned confusion.</p>
      <p>
        <bold>6. I strongly suggest to better highlight the install procedure from ImageJ update sites both in the manuscript and in GitHub.</bold>
      </p>
      <p> The
<ext-link ext-link-type="uri" xlink:href="https://github.com/BIOP/ijp-DEVILS#opening-devils-folder">documentation </ext-link>is now containing a paragraph about the installation procedure. (
<ext-link ext-link-type="uri" xlink:href="https://github.com/BIOP/ijp-DEVILS#installation">https://github.com/BIOP/ijp-DEVILS#installation</ext-link> ).</p>
      <p>
        <bold>7. When running “DEVILS Preview”, the images obtained are very dim and their grayscale values do not correspond to the values actually exported when applying DEVILS with the same settings. </bold>
      </p>
      <p> The preview is interactive, and the “Brightness and Contrast” menu can be used to adjust the min and max display range for each channel. This has been clarified in the documentation.</p>
      <p><ext-link ext-link-type="uri" xlink:href="https://github.com/BIOP/ijp-DEVILS#devils-preview--advanced-">https://github.com/BIOP/ijp-DEVILS#devils-preview--advanced-</ext-link>and
<ext-link ext-link-type="uri" xlink:href="https://github.com/BIOP/ijp-DEVILS#minimum-resp-maximum-for-final-conversion-step">https://github.com/BIOP/ijp-DEVILS#minimum-resp-maximum-for-final-conversion-step</ext-link> </p>
      <p>
        <bold>8. I got an error when applying the operation from DEVILS Preview: “Unrecognized command “DEVILS Preview”.</bold>
      </p>
      <p> This bug his has been fixed in the latest version available via the update site. </p>
      <p>
        <bold>9. The words used throughout the text should be more consistent, for instance: “DEVILS Workflow”, “DEVILS Routine”, “DEVILS Algorithm”, “DEVILS operation” or “Slice”, “Plane”, “Z-Plane” should be unified.</bold>
      </p>
      <p> The manuscript was changed by using the term “DEVILS plugin” and avoiding the other ones. </p>
      <p>
        <bold>10. This sentence should be rephrased: “A popular method to remove intensity values from large objects is to divide the image by its blurred version”.</bold>
      </p>
      <p> The sentence was rephrased.</p>
      <p> Thanks again for your comments and suggestions.</p>
      <p> Best regards</p>
    </body>
  </sub-article>
</sub-article>
