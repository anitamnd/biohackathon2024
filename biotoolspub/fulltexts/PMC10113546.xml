<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Neuroinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Neuroinform</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Neuroinform.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Neuroinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1662-5196</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10113546</article-id>
    <article-id pub-id-type="doi">10.3389/fninf.2023.1104508</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Neuroscience</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>QuNex—An integrative platform for reproducible neuroimaging analytics</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Ji</surname>
          <given-names>Jie Lisa</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">
          <sup>*</sup>
        </xref>
        <xref rid="fn001" ref-type="author-notes">
          <sup>†</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/1746453/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Demšar</surname>
          <given-names>Jure</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="fn001" ref-type="author-notes">
          <sup>†</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/898883/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fonteneau</surname>
          <given-names>Clara</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/922007/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tamayo</surname>
          <given-names>Zailyn</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pan</surname>
          <given-names>Lining</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kraljič</surname>
          <given-names>Aleksij</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/1665169/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Matkovič</surname>
          <given-names>Andraž</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/1674559/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Purg</surname>
          <given-names>Nina</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/1437864/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Helmer</surname>
          <given-names>Markus</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Warrington</surname>
          <given-names>Shaun</given-names>
        </name>
        <xref rid="aff5" ref-type="aff">
          <sup>5</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/2108821/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Winkler</surname>
          <given-names>Anderson</given-names>
        </name>
        <xref rid="aff6" ref-type="aff">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zerbi</surname>
          <given-names>Valerio</given-names>
        </name>
        <xref rid="aff7" ref-type="aff">
          <sup>7</sup>
        </xref>
        <xref rid="aff8" ref-type="aff">
          <sup>8</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/1822391/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Coalson</surname>
          <given-names>Timothy S.</given-names>
        </name>
        <xref rid="aff9" ref-type="aff">
          <sup>9</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Glasser</surname>
          <given-names>Matthew F.</given-names>
        </name>
        <xref rid="aff9" ref-type="aff">
          <sup>9</sup>
        </xref>
        <xref rid="aff10" ref-type="aff">
          <sup>10</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/30956/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Harms</surname>
          <given-names>Michael P.</given-names>
        </name>
        <xref rid="aff11" ref-type="aff">
          <sup>11</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/70411/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sotiropoulos</surname>
          <given-names>Stamatios N.</given-names>
        </name>
        <xref rid="aff5" ref-type="aff">
          <sup>5</sup>
        </xref>
        <xref rid="aff12" ref-type="aff">
          <sup>12</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/706440/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Murray</surname>
          <given-names>John D.</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff13" ref-type="aff">
          <sup>13</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/33283/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Anticevic</surname>
          <given-names>Alan</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="aff14" ref-type="aff">
          <sup>14</sup>
        </xref>
        <xref rid="fn002" ref-type="author-notes">
          <sup>‡</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/47692/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Repovš</surname>
          <given-names>Grega</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="fn002" ref-type="author-notes">
          <sup>‡</sup>
        </xref>
        <uri xlink:href="http://loop.frontiersin.org/people/44875/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>Department of Psychiatry, Yale University School of Medicine</institution>, <addr-line>New Haven, CT</addr-line>, <country>United States</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Manifest Technologies</institution>, <addr-line>North Haven, CT</addr-line>, <country>United States</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Faculty of Computer and Information Science, University of Ljubljana</institution>, <addr-line>Ljubljana</addr-line>, <country>Slovenia</country></aff>
    <aff id="aff4"><sup>4</sup><institution>Department of Psychology, Faculty of Arts, University of Ljubljana</institution>, <addr-line>Ljubljana</addr-line>, <country>Slovenia</country></aff>
    <aff id="aff5"><sup>5</sup><institution>Sir Peter Mansfield Imaging Centre, School of Medicine, University of Nottingham</institution>, <addr-line>Nottingham</addr-line>, <country>United Kingdom</country></aff>
    <aff id="aff6"><sup>6</sup><institution>Department of Human Genetics, The University of Texas Rio Grande Valley</institution>, <addr-line>Brownsville, TX</addr-line>, <country>United States</country></aff>
    <aff id="aff7"><sup>7</sup><institution>Centre for Biomedical Imaging (CIBM)</institution>, <addr-line>Lausanne</addr-line>, <country>Switzerland</country></aff>
    <aff id="aff8"><sup>8</sup><institution>Neuro-X Institute, School of Engineering (STI), EPFL</institution>, <addr-line>Lausanne</addr-line>, <country>Switzerland</country></aff>
    <aff id="aff9"><sup>9</sup><institution>Department of Neuroscience, Washington University in St. Louis</institution>, <addr-line>St. Louis, MO</addr-line>, <country>United States</country></aff>
    <aff id="aff10"><sup>10</sup><institution>Department of Radiology, Washington University in St. Louis</institution>, <addr-line>St. Louis, MO</addr-line>, <country>United States</country></aff>
    <aff id="aff11"><sup>11</sup><institution>Department of Psychiatry, Washington University in St. Louis</institution>, <addr-line>St. Louis, MO</addr-line>, <country>United States</country></aff>
    <aff id="aff12"><sup>12</sup><institution>Nottingham NIHR Biomedical Research Centre, Queen's Medical Centre, University of Nottingham</institution>, <addr-line>Nottingham</addr-line>, <country>United Kingdom</country></aff>
    <aff id="aff13"><sup>13</sup><institution>Department of Physics, Yale University</institution>, <addr-line>New Haven, CT</addr-line>, <country>United States</country></aff>
    <aff id="aff14"><sup>14</sup><institution>Department of Psychology, Yale University School of Medicine</institution>, <addr-line>New Haven, CT</addr-line>, <country>United States</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Matthias H. Hennig, University of Edinburgh, United Kingdom</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Bo-yong Park, Inha University, Republic of Korea; Hyunjin Park, Sungkyunkwan University, Republic of Korea</p>
      </fn>
      <corresp id="c001">*Correspondence: Jie Lisa Ji <email>jielisa.ji@yale.edu</email></corresp>
      <fn fn-type="equal" id="fn001">
        <p>†These authors have contributed equally to this work</p>
      </fn>
      <fn fn-type="equal" id="fn002">
        <p>‡These authors share senior authorship</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>05</day>
      <month>4</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>17</volume>
    <elocation-id>1104508</elocation-id>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>21</day>
        <month>2</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2023 Ji, Demšar, Fonteneau, Tamayo, Pan, Kraljič, Matkovič, Purg, Helmer, Warrington, Winkler, Zerbi, Coalson, Glasser, Harms, Sotiropoulos, Murray, Anticevic and Repovš.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Ji, Demšar, Fonteneau, Tamayo, Pan, Kraljič, Matkovič, Purg, Helmer, Warrington, Winkler, Zerbi, Coalson, Glasser, Harms, Sotiropoulos, Murray, Anticevic and Repovš</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <sec>
        <title>Introduction</title>
        <p>Neuroimaging technology has experienced explosive growth and transformed the study of neural mechanisms across health and disease. However, given the diversity of sophisticated tools for handling neuroimaging data, the field faces challenges in method integration, particularly across multiple modalities and species. Specifically, researchers often have to rely on siloed approaches which limit reproducibility, with idiosyncratic data organization and limited software interoperability.</p>
      </sec>
      <sec>
        <title>Methods</title>
        <p>To address these challenges, we have developed Quantitative Neuroimaging Environment &amp; Toolbox (QuNex), a platform for consistent end-to-end processing and analytics. QuNex provides several novel functionalities for neuroimaging analyses, including a “turnkey” command for the reproducible deployment of custom workflows, from onboarding raw data to generating analytic features.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>The platform enables interoperable integration of multi-modal, community-developed neuroimaging software through an extension framework with a software development kit (SDK) for seamless integration of community tools. Critically, it supports high-throughput, parallel processing in high-performance compute environments, either locally or in the cloud. Notably, QuNex has successfully processed over 10,000 scans across neuroimaging consortia, including multiple clinical datasets. Moreover, QuNex enables integration of human and non-human workflows <italic>via</italic> a cohesive translational platform.</p>
      </sec>
      <sec>
        <title>Discussion</title>
        <p>Collectively, this effort stands to significantly impact neuroimaging method integration across acquisition approaches, pipelines, datasets, computational environments, and species. Building on this platform will enable more rapid, scalable, and reproducible impact of neuroimaging technology across health and disease.</p>
      </sec>
    </abstract>
    <kwd-group>
      <kwd>neuroimaging</kwd>
      <kwd>data processing</kwd>
      <kwd>functional MRI</kwd>
      <kwd>diffusion MRI</kwd>
      <kwd>multi-modal analyses</kwd>
      <kwd>containerization</kwd>
      <kwd>cloud integration</kwd>
      <kwd>high-performance computing</kwd>
    </kwd-group>
    <funding-group>
      <funding-statement>Financial support for this study was provided by NIH grants DP5OD012109-01 (to AA), 1U01MH121766 (to AA), R01MH112746 (to JM), 5R01MH112189 (to AA), and 5R01MH108590 (to AA), NIAAA grant 2P50AA012870-11 (to AA), NIH grants R24MH108315, 5R24MH122820, AG052564, and MH109589, NSF NeuroNex grant 2015276 (to JM), the Brain and Behavior Research Foundation Young Investigator Award (to AA), SFARI Pilot Award (to JM and AA), the European Research Council (Consolidator Grant 101000969 to SS and SW), Wellcome Trust (Grant 217266/Z/19/Z to SS), Swiss National Science Foundation (SNSF) ECCELLENZA (PCEFP3_203005 to VZ), and the Slovenian Research Agency (ARRS) (Grant Nos. J7-8275, J7-6829, and P3-0338 to GR).</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="7"/>
      <table-count count="0"/>
      <equation-count count="0"/>
      <ref-count count="65"/>
      <page-count count="18"/>
      <word-count count="12980"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>Introduction</title>
    <p>Neuroimaging has transformed the study of the central nervous system across species, developmental stages, and health/disease states. The impact of neuroimaging research has led to the development of a diverse and growing array of tools and pipelines that address distinct aspects of data management, preprocessing, and analysis [e.g., AFNI (Cox, <xref rid="B16" ref-type="bibr">1996</xref>), FreeSurfer (Fischl, <xref rid="B25" ref-type="bibr">2012</xref>), FSL (Smith et al., <xref rid="B57" ref-type="bibr">2004</xref>), SPM (Ashburner, <xref rid="B4" ref-type="bibr">2012</xref>), HCP (Glasser et al., <xref rid="B32" ref-type="bibr">2013</xref>), fMRIPrep (Esteban et al., <xref rid="B22" ref-type="bibr">2019</xref>), QSIPrep (Cieslak et al., <xref rid="B15" ref-type="bibr">2021</xref>), PALM (Winkler et al., <xref rid="B63" ref-type="bibr">2014</xref>)]. However, the growing array of neuroimaging tools has created challenges for integration of such methods across modalities, species, and analytic choices. Furthermore, different neuroimaging techniques (e.g., functional magnetic resonance imaging/fMRI, diffusion magnetic resonance imaging/dMRI, arterial spin labeling/ASL, task-evoked versus resting-state etc.) have often spurred the creation of methodology-specific silos with limited interoperability across tools for processing and downstream analyses. This has contributed to a fragmented neuroimaging community in lieu of integrative, standardized, and reproducible workflows in the field (Botvinik-Nezer et al., <xref rid="B11" ref-type="bibr">2020</xref>).</p>
    <p>A number of coordinated efforts have attempted to standardize acquisition and processing procedures. For example, the Human Connectome Project (HCP)'s Minimal Preprocessing Pipelines (MPP) (Glasser et al., <xref rid="B32" ref-type="bibr">2013</xref>) allow quality control (QC) and distortion correction for several neuroimaging modalities through a unified framework, while considering multiple formats for preserving the geometry of different brain structures (surfaces for the cortical sheet and volumes for deep structures). Another state-of-the-art preprocessing framework, fMRIPrep (Esteban et al., <xref rid="B22" ref-type="bibr">2019</xref>), focuses on fMRI, seeking to ensure high-quality automated preprocessing and integrated QC. QSIPrep (Cieslak et al., <xref rid="B15" ref-type="bibr">2021</xref>) enables similar-in-spirit automated preprocessing for dMRI. FSL's XTRACT (Warrington et al., <xref rid="B62" ref-type="bibr">2020</xref>) allows consistent white matter bundle tracking in human and non-human primate dMRI. Several high-level environments, such as nipype (Gorgolewski et al., <xref rid="B35" ref-type="bibr">2016</xref>), micapipe (Cruces et al., <xref rid="B17" ref-type="bibr">2022</xref>), and BrainVoyager (Goebel, <xref rid="B34" ref-type="bibr">2012</xref>), have also provided frameworks for leveraging other tools to build neuroimaging pipelines, including support across multiple modalities. Such efforts have been instrumental in guiding the field toward unified and consistent handling of data and increasing accessibility for users to state-of-the-art tools. However, these solutions are mostly application- or modality-specific, and therefore are not designed to enable an integrative workflow framework that is modality- and method-agnostic. Many of these options are uni-modal preprocessing pipelines (e.g., fMRIPrep, QSIPrep) or preprocessing pipelines developed for specific consortia (HCP and UKBiobank pipelines). To date, no environment has been explicitly designed to seamlessly connect external and internally-developed multi-modal preprocessing pipelines with downstream analytic tools, and provide a comprehensive, customizable ecosystem for flexible user-driven end-to-end neuroimaging workflows.</p>
    <p>To address this need, we have developed the Quantitative Neuroimaging Environment and Toolbox (QuNex). QuNex is designed as an integrative platform for reproducible neuroimaging analytics. Specifically, it enables researchers to seamlessly execute data preparation, preprocessing, QC, feature generation, and statistics in an integrative and reproducible manner. The “turnkey” end-to-end execution capability allows entire study workflows, from data onboarding to analyses, to be customized and executed <italic>via</italic> a single command. Furthermore, the platform is optimized for high performance computing (HPC) or cloud-based environments to enable high-throughput parallel processing of large-scale neuroimaging datasets [e.g., Adolescent Brain Cognitive Development (Casey et al., <xref rid="B14" ref-type="bibr">2018</xref>) or UK Biobank (Bycroft et al., <xref rid="B13" ref-type="bibr">2018</xref>)]. In fact, QuNex has been adopted as the platform of choice for executing workflows across all Lifespan and Connectomes of Human Disease datasets by the Connectome Coordinating Facility (Elam et al., <xref rid="B21" ref-type="bibr">2021</xref>).</p>
    <p>Critically, we have explicitly developed QuNex to integrate and facilitate the use of existing software packages, while enhancing their functionality through a rich array of novel internal features. Our platform currently supports a number of popular and well-validated neuroimaging tools, with a framework for extensibility and integration of additional original packages based on user needs (see Section Discussion). Moreover, QuNex offers functionality for onboarding entire datasets, with compatibility for the BIDS (Brain Imaging Data Structure, Gorgolewski et al., <xref rid="B35" ref-type="bibr">2016</xref>) or HCP-style conventions, as well as support for NIFTI (volumetric), GIFTI (surface meshes), CIFTI (grayordinates), and DICOM file formats. Lastly, QuNex enables analysis of non-human primate (Hayashi et al., <xref rid="B37" ref-type="bibr">2021</xref>) and rodent (e.g., mouse) (Zerbi et al., <xref rid="B65" ref-type="bibr">2015</xref>) datasets in a complementary manner to human neuroimaging workflows. To the best of our knowledge, no existing framework provides comprehensive functionality to handle the diversity of neuroimaging workflows across species, modalities, pipelines, analytic workflows, datasets, and scanner manufacturers, while explicitly enabling methodological extensibility and innovation.</p>
    <p>QuNex offers an integrative solution that minimizes technical bottlenecks and access friction for executing standardized neuroimaging workflows at scale with reproducible standards. Of note, QuNex is an integrative framework for multi-modal, multi-species neuroimaging tools and workflows, rather than a choice of preprocessing or analytic pipeline; as such, QuNex provides users with multiple options and complete control over processing and analytic decisions, giving them the opportunity to pick the right tools for their job. Thus, QuNex provides a novel, integrative solution for consistent and customizable workflows in neuroimaging.</p>
    <p>In this paper, we present QuNex's capabilities through specific example use cases: (1) Turnkey execution of neuroimaging workflows and versatile selection of data for high-throughput batch processing with native scheduler support; (2) Consistent and standardized processing of datasets of various sizes, modalities, study types, and quality; (3) Multi-modal feature generation at different levels of resolution; (4) Comprehensive and flexible general linear modeling at the single-session level and integrated interoperability with third-party tools for group-level analytics; (5) Support for multi-species neuroimaging data, to link, unify, and translate between human and non-human studies. For these use cases, we sample data from over 10,000 scan sessions that QuNex has been used to process across neuroimaging consortia, including clinical datasets.</p>
  </sec>
  <sec sec-type="methods" id="s2">
    <title>Methods</title>
    <sec>
      <title> Description of the preprocessing validation datasets</title>
      <p>We tested preprocessing using QuNex on a total of 16 datasets, including both publicly-available and aggregated internal datasets. For each dataset, we prepared batch files with parameters specific to the study (or site, if the study is multi-site and acquisition parameters differed between sites). We then used QuNex commands to run all sessions through the HCP Minimal Preprocessing Pipelines (MPP) for structural (T1w images; T2w if available), functional data, and diffusion data (if available). A brief description of each dataset in <xref rid="SM1" ref-type="supplementary-material">Supplementary material</xref>. Additional details on diffusion datasets and preprocessing can also be found below.</p>
    </sec>
    <sec>
      <title> Preprocessing of validation datasets</title>
      <p>All datasets were preprocessed using QuNex with the HCP MPP (Glasser et al., <xref rid="B32" ref-type="bibr">2013</xref>) <italic>via</italic> QuNex. A summary of the HCP Pipelines is as follows: the T1w structural images were first aligned by warping them to the standard Montreal Neurological Institute-152 (MNI-152) brain template in a single step, through a combination of linear and non-linear transformations <italic>via</italic> the FMRIB Software Library (FSL) linear image registration tool (FLIRT) and non-linear image registration tool (FNIRT) (Jenkinson et al., <xref rid="B40" ref-type="bibr">2002</xref>). If a T2w was present, it was co-registered to the T1w image. If field maps were collected, these were used to perform distortion correction. Next, FreeSurfer's recon-all pipeline was used to segment brain-wide gray and white matter to produce individual cortical and subcortical anatomical segmentations (Reuter et al., <xref rid="B53" ref-type="bibr">2012</xref>). Cortical surface models were generated for pial and white matter boundaries as well as segmentation masks for each subcortical gray matter voxel. The T2w image was used to refine the surface tracing. Using the pial and white matter surface boundaries, a “cortical ribbon” was defined along with corresponding subcortical voxels, which were combined to generate the neural file in the Connectivity Informatics Technology Initiative (CIFTI) volume/surface “grayordinate” space for each individual subject (Glasser et al., <xref rid="B32" ref-type="bibr">2013</xref>). BOLD data were motion-corrected by aligning to the middle frame of every run <italic>via</italic> FLIRT in the initial NIFTI volume space. Next a brain-mask was applied to exclude signal from non-brain tissue. Next, cortical BOLD data were converted to the CIFTI gray matter matrix by sampling from the anatomically-defined gray matter cortical ribbon and subsequently aligned to the HCP atlas using surface-based nonlinear deformation (Glasser et al., <xref rid="B32" ref-type="bibr">2013</xref>). Subcortical voxels were aligned to the MNI-152 atlas using whole-brain non-linear registration and then the Freesurfer-defined subcortical segmentation was applied to isolate the CIFTI subcortex. For datasets without field maps and/or a T2w image, we used a version of the MPP adapted for compatibility with “legacy” data, featured as a standard option in the HCP Pipelines provided by the QuNex team (<ext-link xlink:href="https://github.com/Washington-University/HCPpipelines/pull/156" ext-link-type="uri">https://github.com/Washington-University/HCPpipelines/pull/156</ext-link>). The adaptations for single-band BOLD acquisition have been described in prior publications (Ji et al., <xref rid="B41" ref-type="bibr">2019a</xref>, <xref rid="B42" ref-type="bibr">2021</xref>). Briefly, adjustments include allowing the HCP MPP to be conducted without high-resolution registration using T2w images and without optional distortion correction using field maps. For validation of preprocessing <italic>via</italic> QuNex, we counted the number of sessions in each study which successfully completed the HCP MPP versus the number of sessions which errored during the pipeline.</p>
    </sec>
    <sec>
      <title> Description of the datasets used for analytics</title>
      <sec>
        <title>HCP young adults (HCP-YA) dataset</title>
        <p>To demonstrate neuroimaging analytics and feature generation in human data, we used <italic>N</italic> = 339 unrelated subjects from the HCP-YA cohort (Van Essen et al., <xref rid="B61" ref-type="bibr">2013</xref>). The functional data from these subjects underwent additional processing and removal of artifactual signal after the HCP MPP. These steps included ICA-FIX (Glasser et al., <xref rid="B32" ref-type="bibr">2013</xref>; Salimi-Khorshidi et al., <xref rid="B55" ref-type="bibr">2014</xref>) and movement scrubbing (Power et al., <xref rid="B52" ref-type="bibr">2013</xref>) as done in our prior work (Ji et al., <xref rid="B41" ref-type="bibr">2019a</xref>, <xref rid="B42" ref-type="bibr">2021</xref>). We combined the four 15-min resting-state BOLD runs in order of acquisition, after first demeaning each run individually and removing the first 100 frames to remove potential magnetization effects (Ji et al., <xref rid="B43" ref-type="bibr">2019b</xref>). Seed-based functional connectivity was computed using <monospace>qunex fc_compute_seedmaps</monospace> and calculated as the Fisher's Z-transformed Pearson's <italic>r</italic>-value between the seed region BOLD time-series and time-series in the rest of brain. Task activation maps were computed from a language processing task (Barch et al., <xref rid="B7" ref-type="bibr">2013</xref>), derived from Binder et al. (<xref rid="B10" ref-type="bibr">2011</xref>). Briefly, the task consisted of two runs, each with four blocks of three conditions: (i) Sentence presentation with detection of semantic, syntactic, and pragmatic violations; (ii) Story presentation with comprehension questions (“Story” condition); (iii) Math problems involving sets of arithmetic problems and response periods (“Math” condition). Trials were presented auditorily and participants chose one of two answers by pushing a button. Task-evoked signal for the Language task was computed by fitting a GLM to preprocessed BOLD time series data with <monospace>qunex preprocess_conc</monospace>. Two predictors were included in the model for the “Story” and “Math” blocks, respectively. Each block was ~30 s in length and the sustained activity across each block was modeled using the Boynton HRF (Boynton et al., <xref rid="B12" ref-type="bibr">1996</xref>). Results shown here are from the Story vs. Math contrast (Glasser et al., <xref rid="B30" ref-type="bibr">2016a</xref>; Ji et al., <xref rid="B43" ref-type="bibr">2019b</xref>). Across all tests, statistical significance was assessed with PALM (Winkler et al., <xref rid="B63" ref-type="bibr">2014</xref>) <italic>via</italic>
<monospace>qunex run_palm</monospace>. Briefly, threshold-free cluster enhancement was applied (Smith and Nichols, <xref rid="B58" ref-type="bibr">2009</xref>) and the data were randomly permuted 5,000 times to obtain a null distribution. All contrasts were corrected for family-wise error. Diffusion data from this dataset were first preprocessed with the HCP MPP (Glasser et al., <xref rid="B32" ref-type="bibr">2013</xref>) <italic>via</italic>
<monospace>qunex hcp_diffusion</monospace>, including susceptibility and eddy-current induced distortion and motion correction (Andersson et al., <xref rid="B2" ref-type="bibr">2003</xref>; Andersson and Sotiropoulos, <xref rid="B3" ref-type="bibr">2016</xref>) and the estimation of dMRI to MNI-152 (<italic>via</italic> the T1w space Andersson and Sotiropoulos, <xref rid="B3" ref-type="bibr">2016</xref>) registration fields. Next, fiber orientations were modeled for up to three orientations per voxel using the FSL's bedpostX crossing fibers diffusion model (Behrens et al., <xref rid="B8" ref-type="bibr">2007</xref>; Jbabdi et al., <xref rid="B39" ref-type="bibr">2012</xref>), <italic>via</italic>
<monospace>qunex dwi_bedpostx_gpu</monospace>. After registering to the standard space, whole brain probabilistic tractography was run with FSL's probtrackx <italic>via</italic>
<monospace>qunex</monospace>
<monospace>dwi_probtracx_dense_gpu</monospace>, producing a dense connectivity matrix for the full CIFTI space. Further, we estimated 42 white matter fiber bundles, and their cortical termination maps, for each subject <italic>via</italic> XTRACT (Warrington et al., <xref rid="B62" ref-type="bibr">2020</xref>). Following individual tracking, resultant tracts were group-averaged by binarizing normalized streamline path distributions at a threshold and averaging binary masks across the cohort to give the percentage of subjects for which a given tract is present at a given voxel. For all tracts except the middle cerebellar peduncle (MCP), which is not represented in CIFTI surface file formats, the cortical termination map was estimated using connectivity blueprints, as described in Mars et al. (<xref rid="B48" ref-type="bibr">2018</xref>). These maps reflect the termination points of the corresponding tract on the white-gray matter boundary surface.</p>
      </sec>
      <sec>
        <title>Non-human primate macaque datasets</title>
        <p>Neural data from two macaques (one <italic>in vivo</italic>, one <italic>ex vivo</italic>) are shown. Structural (T1w, T2w, myelin) and functional BOLD data were obtained from a session in the publicly-available PRIMatE Data Exchange (PRIME-DE) repository (Milham et al., <xref rid="B50" ref-type="bibr">2018</xref>), specifically from the University of California-Davis dataset. In this protocol, subjects were anesthesized with ketamine, dexmedetomidine, or buprenorphine prior to intubation and placement in stereotaxic frame with 1–2% isoflurane maintenance anesthesia during the scanning protocol. They underwent 13.5 min of resting-state BOLD acquisition (gradient echo voxel size: 1.4 × 1.4 × 1.4 mm; TE: 24 ms; TR: 1,600 ms; FOV = 140 mm) as well as T1w (voxel size: 0.3 × 0.3 × 0.3 mm; TE: 3.65 ms; TR: 2,500 ms; TI: 1,100 ms; flip angle: 7°), T2w (voxel size: 0.3 × 0.3 × 0.3 mm; TE: 307 ms; TR: 3,000 ms), spin-echo field maps, and diffusion on a Siemens Skyra 3T scanner with a 4-channel clamshell coil. Preprocessing steps are consistent with the HCP MPP and described in detail in Autio et al. (<xref rid="B5" ref-type="bibr">2020</xref>) and Hayashi et al. (<xref rid="B37" ref-type="bibr">2021</xref>).</p>
        <p>The high-resolution macaque diffusion data shown were obtained ex vivo and have been previously described (Mars et al., <xref rid="B48" ref-type="bibr">2018</xref>; Eichert et al., <xref rid="B20" ref-type="bibr">2020</xref>; Warrington et al., <xref rid="B62" ref-type="bibr">2020</xref>) and are available <italic>via</italic> PRIME-DE (<ext-link xlink:href="http://fcon_1000.projects.nitrc.org/indi/PRIME/oxford2.html" ext-link-type="uri">http://fcon_1000.projects.nitrc.org/indi/PRIME/oxford2.html</ext-link>). The brains were soaked in phosphate-buffered saline before scanning and placed in fomblin or fluorinert during the scan. Data were acquired at the University of Oxford on a 7T magnet with an Agilent DirectDrive console (Agilent Technologies, Santa Clara, CA, USA) using a 2D diffusion-weighted spin-echo protocol with single line readout (DW-SEMS, TE/TR: 25 ms/10 s; matrix size: 128 × 128; resolution: 0.6 × 0.6 mm; number of slices: 128; slice thickness: 0.6 mm). Diffusion data were acquired over the course of 53 h. For each subject, 16 non-diffusion-weighted (b = 0 s/mm<sup>2</sup>) and 128 diffusion-weighted (b = 4,000 s/mm<sup>2</sup>) volumes were acquired with diffusion directions distributed over the whole sphere. FA maps were registered to the standard F99 space (Van Essen, <xref rid="B60" ref-type="bibr">2002</xref>) using FNIRT. As with the human data, the macaque diffusion data were modeled using the crossing fiber model from bedpostX and used to inform tractography. Again, 42 white matter fiber bundles, and their cortical termination maps, were estimated using XTRACT.</p>
      </sec>
    </sec>
    <sec>
      <title> Functional parcellation and seed definitions</title>
      <p>Throughout this manuscript we used the Cole-Anticevic Brain-wide Network Partition (CAB-NP) (Ji et al., <xref rid="B43" ref-type="bibr">2019b</xref>), based on the HCP MMP (Glasser et al., <xref rid="B30" ref-type="bibr">2016a</xref>), to demonstrate the utility of parcellations in QuNex. These parcellations (along with atlases provided by FSL/Freesurfer) are also currently distributed with QuNex. However, users can choose to use alternative parcellations by simply providing QuNex with the relevant parcellation files. The CAB-NP was used for definitions of functional networks (e.g., the Language network) and parcels in the cortex and subcortex. Broca's Area was defined as Brodmann's Area 44, corresponding to the parcel labeled “L_44_ROI” in the HCP MMP and “Language-14_L-Ctx” in the CAB-NP (Glasser et al., <xref rid="B30" ref-type="bibr">2016a</xref>). The left Primary Somatorysensory Area (S1) region was defined as Brodmann's Area 1 and corresponds to the parcel labeled “L_1_ROI” in the HCP MMP and “Somatomotor-29_L-Ctx” in the CAB-NP (Glasser et al., <xref rid="B30" ref-type="bibr">2016a</xref>).</p>
    </sec>
    <sec>
      <title> Design and features for open science</title>
      <p>QuNex is developed in accordance to modern standards in software engineering. Adhering to these standards results in a consistently structured, well-documented, and strictly versioned platform. All QuNex code is open and well-commented which both eases and encourages community development. Furthermore, our Git repositories use the GitFlow branching model which, besides keeping our repositories neat and tidy, also helps with the process of merging community developed features into our solution. QuNex has an extensive documentation, both in the form of inline help, accessible from CLI and a Wiki page. Inline documentation offers a short description of all QuNex commands and their parameters while the Wiki documentation offers a number of tutorials and more extensive usage guides. Furthermore, users can establish a direct communication with QuNex developers through the official QuNex forum (<ext-link xlink:href="https://forum.qunex.yale.edu/" ext-link-type="uri">https://forum.qunex.yale.edu/</ext-link>), where they can get additional support and discuss or suggest possible new features or anything else QuNex related. To assure maximum possible levels of tractability and reproducibility, QuNex is versioned by using the semantic versioning process (<ext-link xlink:href="https://semver.org/" ext-link-type="uri">https://semver.org/</ext-link>). The QuNex platform is completely free and open source—QuNex source code is licensed under the GPL (GNU General Public License). Furthermore, QuNex is not only open by nature, but also by design. In other words, we did not simply open up the QuNex code base, we developed it to be as open and accessible as possible. To open up QuNex to the neuroinformatics community, we designed a specialized extensions framework. This framework supports development in multiple programming languages (e.g., Python, MATLAB, R, Bash) and was built with the sole intention to ease the integration of custom community based processing and analysis commands into the QuNex platform. Extensions developed through this extensions framework can access all the tools and utilities (e.g., the batch turnkey engine, logging, scheduling ...) residing in the core QuNex code. Once developed, QuNex Extensions are seamlessly attached to the QuNex platform and ran in the same fashion as all existing QuNex commands. Our end goal is to fold the best extensions into our core codebase and thus have a community supported, organically growing neuroimaging platform. As mentioned, to ease this process we have also prepared an SDK, which includes the guidelines and tools that should both speed up the extension development process and make extensions code more consistent with the core QuNex code. This will then allow for faster adoption of QuNex Extensions into the core codebase. See <xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 10</xref> for visualization of the QuNex Extensions framework.</p>
      <p>Since QuNex and other similar platforms depend on a number of software tools which are developed independently, assuring complete reproducibility can be a challenging task since researchers are required to track and archive all the dependencies. To alleviate this issue we publish a container along each unique QuNex version. As a result, using the container for processing and analysis allows users to achieve complete reproducibility by tracking a single number—the version of the QuNex platform used in processing and analysis. QuNex containers are not only important because they offer complete transparency and reproducibility, through them users can execute their studies on a number of different platforms and systems (e.g., HPC system, cloud services, PC, etc.). Just like the QuNex source code, QuNex containers are also completely free and open to the research community.</p>
    </sec>
    <sec>
      <title> Containerization and deployment</title>
      <p>Through containerization, QuNex is fully platform-agnostic and comes in the form of both Docker and Singularity containers. This offer several advantages to end users. First, the QuNex container includes all of the required dependencies, packages, and libraries which greatly reduces the time a user needs to setup everything and start processing. Second, the QuNex container is meticulously versioned and archived, which guarantees complete reproducibility of methods. Last but not least, containers can be run on practically every modern operating system (e.g., Windows, macOS, Linux) and can be deployed on any hardware configuration (e.g., desktop computer, laptop, cloud, high performance computing system). Users can easily execute the QuNex container <italic>via</italic> the included <monospace>qunex_container</monospace> script, which removes common technical barriers to connecting a container with the operating system. Furthermore, when running studies on an HPC system users need to manually configure the parameters of the underlying scheduling system, which can be again a tedious task for those that are not familiar with scheduling system. To alleviate this issue, the <monospace>qunex_container</monospace> script offers native support for several popular job schedulers (SLURM, PBS, LSF).</p>
    </sec>
    <sec>
      <title> QuNex commands</title>
      <p>A detailed list and a short description of all commands, along with a visualization of how commands can be chained together, can be found in the <xref rid="SM1" ref-type="supplementary-material">Supplementary material</xref>. Here, we specify a short description for each of the functional groups of QuNex commands.</p>
      <sec>
        <title>Study creation, data onboarding, and mapping</title>
        <p>This group of commands serves for setting up a QuNex study and its folder structure, importing your data into the study and preparing all the support files required for processing.</p>
      </sec>
      <sec>
        <title>HCP pipelines</title>
        <p>These commands incorporate everything required for executing the whole HCP MPP along with some additional HCP Pipelines commands. Commands support the whole HCP MPP along with some additional processing and denoising commands. Below is a very brief overview of each pipeline, for details please consult the manuscript prepared by Glasser et al. (<xref rid="B32" ref-type="bibr">2013</xref>) and the official HCP Pipelines repository (<ext-link xlink:href="https://github.com/Washington-University/HCPpipelines" ext-link-type="uri">https://github.com/Washington-University/HCPpipelines</ext-link>). See <xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 3</xref> for a visualization of HCP Pipelines implementation in QuNex.</p>
      </sec>
      <sec>
        <title>Quality control</title>
        <p>QuNex contains commands through which users can execute visual QC for a number of commonly used MRI modalities—raw NIfTI, T1w, T2w, myelin, fMRI, dMRI, eddyQC, etc.</p>
      </sec>
      <sec>
        <title>Diffusion analyses</title>
        <p>QuNex also includes functionality for processing images acquired through dMRI. These commands prepare the data for a number of common dMRI analyses including diffusion tensor imaging (DTI) and probabilistic tractography.</p>
      </sec>
      <sec>
        <title>BOLD analyses</title>
        <p>Before running task-evoked and resting-state functional connectivity analyses, BOLD data needs to be additionally preprocessed. First, all the relevant data needs to be prepared—BOLD brain masks need to be created, BOLD image statistics need to be computed and processed and nuisance signals need to be extracted. These data are then used to process the images, which might include spatial smoothing, temporal high and/or low pass filtering, assumed HRF and unassumed HRF task modeling and regression of undesired nuisance and task signal.</p>
      </sec>
      <sec>
        <title>Permutation analysis of linear models (PALM)</title>
        <p>The main purpose of this group of commands is to allow easier use of results and outputs generated by QuNex in various PALM (Winkler et al., <xref rid="B63" ref-type="bibr">2014</xref>) analyses (e.g., second-level statistical analysis and various types of statistical tests).</p>
      </sec>
      <sec>
        <title>Mice pipelines</title>
        <p>QuNex contains a set of commands for onboarding and preprocessing rodent MRI data (typically in the Bruker format). Results of the mice preprocessing pipelines can be then analyzed using the same set of commands as with human data.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <title>Results</title>
    <p>Through QuNex, researchers can use a single platform to perform onboarding, preprocessing, QC, and analyses across multiple modalities and species. We have developed an open-source environment for multi-modal neuroimaging analytics. QuNex is fully platform-agnostic and comes in the form of both Docker and Singularity containers which allows for easy deployment regardless of the underlying hardware or operating system. It has also been designed with the aim to be community-driven. To promote community participation, we have adopted modern and flexible development standards and implemented several supporting tools, including a SDK that includes helper tools for setting up a development environment and testing newly developed code, and an extensions framework through which researchers can integrate their own pipelines into the QuNex platform. These tools enable users to speed up both their development and integration of newly developed features into the core codebase. QuNex comes with an extensive documentation both in the format of inline help through the command line interface (CLI) and a dedicated Wiki page. Furthermore, users can visit our forum (<ext-link xlink:href="https://forum.qunex.yale.edu/" ext-link-type="uri">https://forum.qunex.yale.edu/</ext-link>) for anything QuNex related, from discussions to feature requests, bug reports, issues, usage assistance, and to request the integration of other tools.</p>
    <sec>
      <title> QuNex is an integrative multi-modal and multi-species neuroimaging platform</title>
      <p>Given the diversity of sophisticated tools for handling neuroimaging data, the field faces a key challenge around method integration. We addressed this challenge by building a platform for seamless integration of a wide array of neuroimaging operations, ranging from low-level onboarding of raw data to final cutting-edge surface-based analyses and visualizations. <xref rid="F1" ref-type="fig">Figure 1</xref> provides a general overview of the QuNex platform, while a summary of QuNex commands and functionalities is shown in <xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 1</xref>. QuNex supports processing of diverse data from multiple species (i.e., human, macaque, and mouse), modalities (e.g., T1w, T2w, fMRI, dMRI), and common neuorimaging data formats (e.g., DICOM, NIfTI, and vendor-specific Bruker and PAR/REC). It offers support for onboarding of BIDS-compliant or HCP-style datasets and native support for studies that combine neuroimaging with behavioral assessments. To this end, it allows for integrated analyses with behavioral data, such as task performance or symptom assessments, and provides a clear hierarchy for organizing data in a study with behavior and neural modalities (see <xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 2</xref>).</p>
      <fig position="float" id="F1">
        <label>Figure 1</label>
        <caption>
          <p>QuNex provides an integrated, versatile, and flexible neuroimaging platform. <bold>(A)</bold> QuNex supports processing of input data from multiple species, including human, macaque, and mouse. <bold>(B)</bold> Additionally, data can be onboarded from a variety of popular formats, including neuroimaging data in DICOM, PAR/REC, NIfTI formats, a full BIDS dataset, or behavioral data from task performance or symptom assessments. <bold>(C)</bold> The QuNex platform is available as a container for ease of distribution, portability, and execution. The QuNex container can be accessed <italic>via</italic> the command line and contains all the necessary packages, libraries, and dependencies needed for running processing and analytic functions. <bold>(D)</bold> QuNex is designed to be easily scalable to accommodate a variety of datasets and job sizes. From a user access point (i.e., the user's local machine), QuNex can be deployed locally, on cloud servers, or <italic>via</italic> job schedulers in supercomputer environments. <bold>(E)</bold> QuNex outputs multi-modal features at the single subject and group levels. Supported features that can be extracted from individual subjects include structural features from T1w, T2w, and dMRI (such as myelin, cortical thickness, sulcal depth, and curvature) and functional features from BOLD imaging (such as functional connectivity matrices). Additional modalities, e.g., receptor occupancy from PET (positron emission tomography), are also being developed (see Section Discussion). Features can be extracted at the dense, parcel, or network levels. <bold>(F)</bold> Importantly, QuNex also provides a comprehensive set of tools for community contribution, engagement, and support. A Software Development Kit (SDK) and GitFlow-powered DevOps framework is provided for community-developed extensions. A forum (<ext-link xlink:href="https://forum.qunex.yale.edu" ext-link-type="uri">https://forum.qunex.yale.edu</ext-link>) is available for users to engage with the QuNex developer team to ask questions, report bugs, and/or provide feedback.</p>
        </caption>
        <graphic xlink:href="fninf-17-1104508-g0001" position="float"/>
      </fig>
      <p>QuNex is capable of generating multi-modal imaging-derived features both at the single subject level and at the group level. It enables extraction of structural features from T1w and T2w data (e.g., myelin, cortical thickness, volumes, sulcal depth, and curvature), white matter microstructure and structural connectivity features from dMRI data (e.g., whole-brain “dense” connectomes, regional connectivity, white matter tract segmentation) and functional features from fMRI data (e.g., activation maps and peaks, functional connectivity matrices, or connectomes). As described below and shown in <xref rid="F4" ref-type="fig">Figure 4</xref>, features can be extracted at the dense, parcel, or network levels using surface or volume-based analysis.</p>
    </sec>
    <sec>
      <title> Turnkey engine automates processing <italic>via</italic> a single command</title>
      <p>Efficient processing of neuroimaging datasets requires streamlined workflows that can execute multiple steps, with minimal manual intervention. One of the most powerful QuNex features is its “turnkey” engine, accessible through the <monospace>run_turnkey</monospace> command. The turnkey functionality allows users to chain and execute several QuNex commands using a single command line call, enabling the generation of consistent outputs in an efficient, streamlined manner. The turnkey steps are entirely configurable and modular, such that users can customize workflows to suit their specific needs. An example of an end-to-end workflow is shown in <xref rid="F2" ref-type="fig">Figure 2A</xref>. The QuNex turnkey engine supports data onboarding of the most commonly used neuroimaging formats, state-of-the-art preprocessing pipelines (e.g., HCP MPP; Glasser et al., <xref rid="B32" ref-type="bibr">2013</xref>, see <xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 3</xref>) and denoising techniques, as well as steps for data QC. QuNex expands upon preprocessing functionalities offered by other packages by providing robust QC functionality, <italic>via</italic> visualizing key features of multi-modal data (including T1w, T2w, dMRI, and BOLD, <xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 4</xref>). This simplifies thorough validation of the quality of input data as well as the intermediate and final preprocessing outputs. Users can additionally choose to generate neuroimaging features for use in further analyses, including the parcellation of timeseries and functional connectivity.</p>
      <fig position="float" id="F2">
        <label>Figure 2</label>
        <caption>
          <p>QuNex turnkey functionality and batch engine for high-throughput processing. <bold>(A)</bold> QuNex provides a “turnkey” engine which enables fully automated deployment of entire pipelines on neuroimaging data <italic>via</italic> a single command (<monospace>qunex run_turnkey</monospace>). An example of a typical workflow with key steps supported by the turnkey engine is highlighted, along with the example command specification. QuNex supports state-of-the-art preprocessing tools from the neuroimaging community (e.g., the HCP MPP; Glasser et al., <xref rid="B32" ref-type="bibr">2013</xref>). For a detailed visual schematic of QuNex steps and commands (see <xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 1</xref>). <bold>(B)</bold> The QuNex batch specification is designed to enable flexible and comprehensive “filtering” and selection of specific data subsets to process. The filtering criteria can be specified at multiple levels, such as devices (e.g., Siemens, GE, or Philips MRI scanners), institutions (e.g., scanning sites), groups (e.g., patient vs. controls), subjects, sessions (e.g., time points in a longitudinal study), modalities (e.g., T1w, T2w, BOLD, diffusion), or scan tags (e.g., name of scan). <bold>(C)</bold> QuNex natively supports job scheduling <italic>via</italic> LSF, SLURM, or PBS schedulers and can be easily deployed in HPC systems to handle high-throughput, parallel processing of large neuroimaging datasets. The scheduling options enable precise specification of paralellization both across sessions and within session (e.g., parallel processing of BOLD images) for optimal performance and utilization of cluster resources.</p>
        </caption>
        <graphic xlink:href="fninf-17-1104508-g0002" position="float"/>
      </fig>
    </sec>
    <sec>
      <title> Filtering grammar enables flexible selection of study-specific data processing</title>
      <p>Flexible selection of sessions/scans for specific steps is an essential feature for dataset management, especially datasets from multiple sites, scanners, participant groups, or scan types. For example, the user may need to execute a command only on data from a specific scanner; or only on resting-state (vs. task-based) functional scans for all sessions in the study. QuNex enables such selection with a powerful filtering grammar in the study-level “batch files,” which are text files that are generated as part of the onboarding process.</p>
      <p>Batch files contain metadata about the imaging data and various acquisition parameters (e.g., site, device vendor, group, subject ID, session ID, acquired modalities) and serve as a record of all session-specific information in a particular study. When users create the batch file through the <monospace>create_batch</monospace> command, QuNex sifts through all sessions in the study and adds the information it needs for further processing and analyses to the batch file. This makes the batch file a key hub that stores all the relevant study metadata. One of the key advantages of this approach is that users can easily execute commands on all or only a specific subset of sessions from a study by filtering the study-level batch file. <xref rid="F2" ref-type="fig">Figure 2B</xref> visualizes the logic behind filtering data subsets from batch files and examples of the <monospace>filter</monospace> parameter in a QuNex command. Information about each scan (e.g., scanner/device, institution/scan site, group, subject ID, session ID, modality, scan tag) in the batch file is provided using a <monospace>key:value</monospace> format (e.g., <monospace>group:patient</monospace>). While some keys are required for QuNex processing steps (e.g., <monospace>session</monospace>, <monospace>subject</monospace>) and are populated automatically during the onboarding process, users can add as many additional <monospace>key:value</monospace> tags as they need. The <monospace>filter</monospace> parameter in a QuNex command will search through the batch file and select only the scans with the specified <monospace>key:value</monospace> tag. This filtering can be executed at multiple levels, from selecting all scans from a particular type of scanner to scans from only a single session. For example, the setting <monospace>filter = “device:Siemens”</monospace> will select all data for scans conducted by a Siemens scanner, whereas the setting <monospace>filter = “session:0001_1”</monospace> will select only data from the session ID 0001_1.</p>
    </sec>
    <sec>
      <title> QuNex provides native scheduler support for job management</title>
      <p>Many institutions use HPC systems or cloud-based servers for processing, necessitating job management applications such as scheduler software and custom scheduling scripts (see examples in <xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 5</xref>). This is especially important for efficient processing of large datasets which may include thousands of sessions. While QuNex is platform-agnostic, all QuNex commands, including <monospace>run_turnkey</monospace>, are compatible with commonly used scheduling systems (i.e., SLURM, PBS, and LSF) for job management in HPC systems (<xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 6</xref>). Thus, QuNex is easily scalable and equipped to handle high-throughput, parallel processing of large neuroimaging datasets. To schedule a command on a cluster, users simply provide a <monospace>scheduler</monospace> parameter to any QuNex command call and the command will be executed as a job on an HPC system, eliminating the need for specialized scripts with scheduling directives. Additionally, QuNex provides parameters for users to easily customize the parallelization of their jobs from the command line call. The <monospace>parjobs</monospace> parameter specifies the total number of jobs to run in parallel; <monospace>parsessions</monospace> specifies the number of sessions to run in parallel within any single job; and <monospace>parelements</monospace> specifies the number of elements (e.g., fMRI runs) within each session to run in parallel. Users can provide the scheduling specification for their jobs to ensure that computational resources are allocated in a specific way; otherwise, QuNex will automatically assign scheduling values for job parallelization, as described in <xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 7</xref>. <xref rid="F2" ref-type="fig">Figure 2C</xref> shows examples of how the native support for scheduling and QuNex's parallelization parameters can be leveraged to customize the way processing is distributed across jobs. For example, specifying <monospace>parjobs=1</monospace>, <monospace>parsessions=2</monospace>, and <monospace>parelements=1</monospace> will ensure that only one job is run at a time on the compute nodes, with two sessions running in parallel. Any individual elements within each session (e.g., multiple BOLD runs) will run serially, one at a time. This parallelization and scheduling functionality, in combination with the turnkey engine and batch specification, is extremely powerful at handling large-scale datasets, while providing great flexibility and user friendliness in optimization to maximally utilize computing resources. Through a single QuNex command line call, a user can onboard, process, and analyze thousands of scans on an HPC system in a parallel manner, drastically reducing the amount of time and effort for datasets of scale.</p>
    </sec>
    <sec>
      <title> Parameter specification environment enables reproducible workflows of multi-modal datasets</title>
      <p>The diversity of neuroimaging parameters can lead to challenges in replicating preprocessing choices and thus affect the reproducibility of results. QuNex supports consistent specification and documentation of parameter values by storing this information in the parameter header of batch files (see <xref rid="F3" ref-type="fig">Figure 3B</xref> for an example) while allowing users to specify the parameters appropriate for their data (e.g. echo spacing, TR) and preprocessing preferences (e.g., spatial smoothing, filtering, global signal regression). Full descriptions for all supported parameters for each QuNex function are available in the documentation (<ext-link xlink:href="http://qunex.readthedocs.io/" ext-link-type="uri">http://qunex.readthedocs.io/</ext-link>) and the in-line help. Many parameters in neuroimaging pipelines are the same across different steps or commands, or across different command executions (e.g., if data for the same study/scanner are processed sequentially). By providing these parameters and their values in the batch files, users are assured that shared parameters will use the same value across pipeline steps. Furthermore, such specification enables complete transparency and reproducibility, as processing workflows can be fully replicated by using the same batch files, and the batch files themselves can be easily shared between researchers. For convenience, an alternative way of providing parameters is through the CLI call; if a parameter is defined both in the batch file and in the CLI call, the version in the CLI call takes precedence.</p>
      <fig position="float" id="F3">
        <label>Figure 3</label>
        <caption>
          <p>Consistent processing at scale and standardized outputs through batch specification. <bold>(A)</bold> The batch specification mechanism in QuNex is designed to support data processing from single-site and multi-site datasets to produce standardized outputs. Acquisition parameters can be flexibly specified for each sequence. Here, example datasets I (single-site study) and II (multi-site study) illustrate possible use cases, with the sequences in each dataset shown in green text. Although Dataset I does not include T2w scans, and Dataset II contains data from different scanners, all these data can be consistently preprocessed in all modalities to produce standardized output neural features. <bold>(B)</bold> Parameters can be tailored for each study in the header of the batch processing file. An example is shown with parameters in green text tailored to Site B in Dataset II (similar to those used in HCP datasets; Glasser et al., <xref rid="B32" ref-type="bibr">2013</xref>). Detailed instructions and examples for setting up the batch parameter header for a user's specific study is available in the documentation. <bold>(C)</bold> QuNex has been highly successful in preprocessing data from numerous publicly available as well as private datasets, totalling over 10,000 independent scan sessions from over 50 different scanners. In some cases, advanced user options can be used to rescue sessions which failed with “out-of-the-box” default preprocessing options. These options include using custom brain masks, control points, or expert file options in Freesurfer (Fischl, <xref rid="B25" ref-type="bibr">2012</xref>; McCarthy et al., <xref rid="B49" ref-type="bibr">2015</xref>) (see <xref rid="SM1" ref-type="supplementary-material">Supplementary material</xref>). The number of successful/total sessions is reported in each bar. The number of sessions rescued with advanced options is shown in parentheses, when applicable. The total proportion of successfully preprocessed sessions from each study (including any sessions rerun with advanced options) as well as the grand total across all studies is shown above the bar plots. The majority of the sessions which failed were due to excessive motion in the structural T1w image, which can cause issues with the registration and segmentation. <bold>(D)</bold> QuNex has been successfully used to preprocess data with a wide range of parameters and from diverse datasets. <bold>(Left)</bold> QuNex has been tested on MRI data acquired with the three major scanner manufacturers (Philips, GE, and Siemens). Here <italic>N</italic><sub><italic>S</italic></sub> specifies the number of individual scan sessions that were acquired with each type of scanner. <bold>(Middle)</bold> QuNex is capable of processing images acquired both with and without simultaneous multi-slice (SMS) acquisition (also known as multi-band acquisition, i.e., Simultaneous Multi-Slice in Siemens scanners; Hyperband in GE scanners; and Multi-Band SENSE in Philips scanners; Kozak et al., <xref rid="B44" ref-type="bibr">2020</xref>). <bold>(Right)</bold> QuNex has been tested on data from clinical, pharmacology, longitudinal, and basic population-based datasets. Here, <italic>N</italic><sub><italic>D</italic></sub> specifies the number of datasets; <italic>N</italic><sub><italic>S</italic></sub> specifies the total number of individual scan sessions in those datasets.</p>
        </caption>
        <graphic xlink:href="fninf-17-1104508-g0003" position="float"/>
      </fig>
      <p>Preprocessing functions are typically executed on multiple sessions at the same time so that they can run in parallel. As mentioned above, QuNex utilizes batch files to define processing parameters, in order to facilitate batch processing of sessions. This batch file specification allows QuNex to produce standardized outputs from data across different studies while allowing for differences in acquisition parameters (e.g., in a multi-site study, where scanner manufacturers may differ across sites). <xref rid="F3" ref-type="fig">Figure 3A</xref> illustrates two example use-case datasets (Datasets I and II). The flexibility of the QuNex batch parameter specification enables all data from these different studies and scanners to be preprocessed consistently and produce consistent outputs in all modalities. <xref rid="F3" ref-type="fig">Figure 3B</xref> illustrates an example of a real-world batch parameter specification. This information is included in the header of a batch file, and is followed by the session-level information (as shown in <xref rid="F2" ref-type="fig">Figure 2B</xref>) for all sessions.</p>
      <p>We have successfully used QuNex to preprocess and analyze data from a large number of public and private neuroimaging datasets (<xref rid="F3" ref-type="fig">Figure 3C</xref>; Elam et al., <xref rid="B21" ref-type="bibr">2021</xref>), totalling more than 10,000 independent scan sessions from over 50 different scanners. <xref rid="F3" ref-type="fig">Figure 3D</xref> shows that the data differ in terms of the scanner manufacturer (Philips, GE or Siemens), acquisition technique (simultaneous multi-slice/multi-band), and the study purpose (clinical, basic, longitudinal and pharmacology studies). These datasets also span participants from different stages of development, from children to older adults. Across these diverse datasets, the percentage of successfully processed sessions is extremely high: 100% in the majority of studies and ~98.5% in total across all studies (<xref rid="F3" ref-type="fig">Figure 3C</xref>). Of note, QuNex supports the preprocessing efforts of major neuroimaging consortia and is used by the Connectome Coordination Facility to preprocess all Lifespan and Connectomes Related to Human Disease (CRHD) datasets (Elam et al., <xref rid="B21" ref-type="bibr">2021</xref>).</p>
    </sec>
    <sec>
      <title> QuNex supports extraction of multi-modal features at multiple spatial scales</title>
      <p>Feature engineering is a critical choice in neuroimaging studies and features can be computed across multiple spatial scales. Importantly, given the challenges with mapping reproducible brain-behavioral relationships (Marek et al., <xref rid="B46" ref-type="bibr">2022</xref>), selecting the right features at the appropriate scale is vital for optimizing signal-to-noise in neural data and producing reproducible results. QuNex enables feature generation and extraction at different levels of resolution (including “dense” full-resolution, parcels, or whole-brain networks) for both volume and CIFTI (combined surface and volume) representations of data, consistently across multiple modalities, for converging multi-modal neuroimaging analytics. While some parcellations are currently distributed with QuNex [such as the HCP-MMP1.0 (Glasser et al., <xref rid="B30" ref-type="bibr">2016a</xref>), CAB-NP (Ji et al., <xref rid="B43" ref-type="bibr">2019b</xref>), and atlases distributed within FSL/FreeSurfer] users are able to use whichever parcellation they wish to use by providing the relevant parcellation files [e.g., Brainnetome (Fan et al., <xref rid="B24" ref-type="bibr">2016</xref>) or Schaefer (Schaefer et al., <xref rid="B56" ref-type="bibr">2018</xref>) atlases] to the appropriate function in QuNex (e.g., <monospace>parcellate_bold</monospace>). <xref rid="F4" ref-type="fig">Figure 4</xref> shows convergent multi-modal results in a sample of <italic>N</italic> = 339 unrelated young adults. Myelin (T1w/T2w) maps reflect high myelination in sensorimotor areas such as primary visual and sensorimotor networks, and lower myelination in higher-order association networks (<xref rid="F4" ref-type="fig">Figure 4A</xref>; Glasser and Van Essen, <xref rid="B33" ref-type="bibr">2011</xref>). DMRI measures capture the white matter connectivity structure through tract termination (Warrington et al., <xref rid="B62" ref-type="bibr">2020</xref>) and maximal intensity projection (MIP) of the left arcuate fasciculus (<xref rid="F4" ref-type="fig">Figure 4B</xref>); as well as structural connectivity (Glasser et al., <xref rid="B30" ref-type="bibr">2016a</xref>). For example, seed-based structural connectivity of Broca's area (Fadiga et al., <xref rid="B23" ref-type="bibr">2009</xref>; Friederici and Gierhan, <xref rid="B29" ref-type="bibr">2013</xref>) highlights connections to canonical language areas such as Wernicke's area (Binder, <xref rid="B9" ref-type="bibr">2015</xref>), superior temporal gyrus, and sulcus (Friederici et al., <xref rid="B28" ref-type="bibr">2006</xref>; Frey et al., <xref rid="B26" ref-type="bibr">2008</xref>), and frontal language regions (Friederici, <xref rid="B27" ref-type="bibr">2011</xref>; Friederici and Gierhan, <xref rid="B29" ref-type="bibr">2013</xref>; <xref rid="F4" ref-type="fig">Figure 4C</xref>). This is consistent with the results of seed-based functional connectivity of Broca's area from resting-state fMRI data in the same individuals (<xref rid="F4" ref-type="fig">Figure 4D</xref>); and furthermore, it is aligned with the activation patterns from a language task (<xref rid="F4" ref-type="fig">Figure 4E</xref>; Barch et al., <xref rid="B7" ref-type="bibr">2013</xref>). Across modalities, QuNex supports the extraction of metrics as raw values (e.g., Pearson's r or Fisher's Z for functional connectivity; probabilistic tractography streamline counts for structural connectivity; <italic>t</italic>-values for task activation contrasts) or standardized Z-scores.</p>
      <fig position="float" id="F4">
        <label>Figure 4</label>
        <caption>
          <p>Extracting multi-modal processing features at multiple levels of resolution. Output features from multiple modalities are shown, as an example of a cross-modal analysis that may be done for a study. Here, features were computed from a cohort of <italic>N</italic> = 339 unrelated subjects from the HCP Young Adult cohort (Van Essen et al., <xref rid="B61" ref-type="bibr">2013</xref>). In addition to cross-modality support, QuNex offers feature extraction at “dense” (i.e., full-resolution), parcel-level and network-level resolutions. All features are shown below at all three resolutions. We used the Cole-Anticevic Brainwide Network Parcellation (CAB-NP) (Glasser et al., <xref rid="B30" ref-type="bibr">2016a</xref>; Ji et al., <xref rid="B43" ref-type="bibr">2019b</xref>), computed using resting-state functional connectivity from the same cohort and validated and characterized extensively in Ji et al. (<xref rid="B43" ref-type="bibr">2019b</xref>). <bold>(A)</bold> Myelin maps, estimated using the ratio of T1w/T2w images (Glasser and Van Essen, <xref rid="B33" ref-type="bibr">2011</xref>). <bold>(B)</bold> Left arcuate fasciculus computed <italic>via</italic> diffusion tractography (Warrington et al., <xref rid="B62" ref-type="bibr">2020</xref>). Surface views show the cortical tract termination (white-gray matter boundary endpoints) and volume views show the maximal intensity projection. <bold>(C)</bold> Structural connectivity of Broca's area (parcel corresponding to Brodmann's Area [BA] 44, green star) (Glasser et al., <xref rid="B30" ref-type="bibr">2016a</xref>). <bold>(D)</bold> Resting-state functional connectivity of Broca's area (green star). For parcel- and network-level maps, resting-state data were first parcelated before computing connectivity. <bold>(E)</bold> Task activation maps for the “Story vs. Math” contrast in a language processing task (Barch et al., <xref rid="B7" ref-type="bibr">2013</xref>). For parcel- and network-level maps, task fMRI data were first parcellated before model fitting. <bold>(F) (Left)</bold> Whole-brain Language network from the CAB-NP (Ji et al., <xref rid="B43" ref-type="bibr">2019b</xref>). <bold>(Right)</bold> The mean t-statistic within Language network regions from the “Story vs. Math” contrast [shown in <bold>(E)</bold>] improves when data are first parcellated at the parcel-level relative to dense-level data and shows the greatest improvement when data are first parcellated at the network-level. Error bars show the standard error. <bold>(G) (Left)</bold> T-statistics computed on the average parcel beta estimates are higher compared to the average T-statistics computed over dense estimates of the same parcel. Teal dots represent 718 parcels from the CAB-NP × 3 Language task contrasts (“Story vs. Baseline”; “Math vs. Baseline”; “Story vs. Math”). <bold>(Right)</bold> Similarly, T-statistics computed on beta estimates for the network are higher than the average of T-statistics computed across parcels within each network.</p>
        </caption>
        <graphic xlink:href="fninf-17-1104508-g0004" position="float"/>
      </fig>
      <p>Notably, features across all modalities can be extracted in a consistent, standardized format after preprocessing and post-processing within QuNex. This enables frictionless comparison of features across modalities, e.g., for multi-modal, multi-variate analyses.</p>
    </sec>
    <sec>
      <title> QuNex enables single-session modeling of time-series modalities</title>
      <p>Modeling of time-series data, such as BOLD, at the single-session level can be used for a variety of purposes, including nuisance regression and extracting task activation for individual subjects. QuNex supports denoising and modeling of time-series data at the single-session level <italic>via</italic> a general linear model (GLM) framework, executed through the <monospace>preprocess_conc</monospace> command. Here, we demonstrate this framework with functional BOLD time-series. <xref rid="F5" ref-type="fig">Figure 5A</xref> showcases a use case where resting-state BOLD data are first denoised and then used to compute seed-based functional connectivity maps of the primary somatosensory area (S1). During the denoising step, the user can specify which sources of nuisance signal to remove (e.g., motion parameters and their derivatives and BOLD signals extracted from ventricles, white matter, whole brain or any other custom defined regions, and their first derivatives). If specified, these nuisance signals are included as covariates in the GLM, which produces, for each BOLD run, residual time-series data as well as coefficient maps for all specified regressors. The denoised time-series can then be used for further analytics, e.g., by computing seed-based functional connectivity using the <monospace>fc_compute_seedmaps</monospace> command. Of note, users can also choose to instead perform denoising using the HCP's ICA-FIX pipeline (Glasser et al., <xref rid="B31" ref-type="bibr">2016b</xref>) <italic>via</italic>
<monospace>hcp_icafix</monospace>, which is also currently supported.</p>
      <fig position="float" id="F5">
        <label>Figure 5</label>
        <caption>
          <p>General Linear Model (GLM) for single-session modeling of time-series modalities and integrated interoperability with PALM for group-level analytics. <bold>(A)</bold> The QuNex GLM framework enables denoising and/or event modeling of resting-state and task BOLD images at the individual-session level in a single step. A use case is shown for resting-state BOLD data. At the single-subject level, FL FLthe user can choose to specify FL individual nuisance regressors (such as white matter and ventricular signal and motion parameters) such that they are regressed out of the BOLD timeseries with the <monospace>qunex</monospace>
<monospace>preprocess_conc</monospace> function. The regressors can be per-frame (as shown), per-trial, or even per-block. The GLM outputs a residual timeseries of “denoised” resting-state data as well as one coefficient map per nuisance regressor. The resting-state data for each subject can then be used to calculate subject-specific feature maps, such as seed-based functional connectivity maps with <monospace>qunex fc_compute_seedmaps</monospace>. <bold>(B)</bold> The GLM engine can also be used for complex modeling and analysis of task events, following a similar framework. Event modeling is specified in <monospace>qunex preprocess_conc</monospace> by providing the associated event file; the method of modeling can be either assumed (using a hemodynamic response function [HRF] of the user's choosing, e.g. Boynton) or unassumed. Here, an example from the HCP's Language task is shown. The two events, “Story” and “Math,” are convolved with the Boynton HRF to build the subject-level GLM. As with the resting-state use case shown in <bold>(A)</bold>, the GLM outputs the single-subject residual timeseries (in this case “pseudo-resting state”) as well as the coefficient maps for each regressor, here the Story and Math tasks. <bold>(C)</bold> Connectivity maps from all subjects can then be entered into a group-level GLM analysis. In this example, the linear relationship between connectivity from the primary somatosensory area (S1) seed and age across subjects is tested in a simple GLM design with one group and one explanatory variable (EV) covariate, demeaned age. QuNex supports flexible group-level GLM analyses with non-parametric tests <italic>via</italic> Permutation Analysis of Linear Models (PALM, Winkler et al., <xref rid="B63" ref-type="bibr">2014</xref>), through the <monospace>qunex run_palm</monospace> function. The specification of the GLM and individual contrasts is completely configurable and allows for flexible and specific hypothesis testing. Group-level outputs include full uncorrected statistical maps for each specified contrast as well as <italic>p</italic>-value maps that can be used for thresholding. Significance for group-level statistical maps can be assessed with the native PALM support for TFCE (Winkler et al., <xref rid="B63" ref-type="bibr">2014</xref>, shown) or cluster statistics with familywise error protection (FWEP). <bold>(D)</bold> The subject-level task coefficient maps can then be input into the <monospace>qunex run_palm</monospace> command along with the group-level design matrix and contrasts. The group-level output maps show the differences in activation between the Story and Math conditions. <bold>(E)</bold> QuNex also supports multi-variate and joint inference tests for testing hypotheses using data from multiple modalities, such as BOLD signal and dMRI. Example connectivity matrices are shown for these two modalities, with the S1 seed highlighted. Similar to the use cases shown above, maps from all subjects can be entered into a group-level analysis with a group-level design matrix and contrasts using the <monospace>qunex</monospace>
<monospace>run_palm</monospace> command. In this example, the relationship between age and S1-seeded functional connectivity and structural connectivity is assessed using a Hotelling's <italic>T</italic><sup>2</sup> test and Fisher's <italic>X</italic><sup>2</sup>. The resulting output maps show the unthresholded and thresholded (<italic>p</italic> &lt; 0.05 FWEP, 10,000 permutations) relationship between age and both neural modalities.</p>
        </caption>
        <graphic xlink:href="fninf-17-1104508-g0005" position="float"/>
      </fig>
      <p>For task data, QuNex facilitates the building of design matrices at the single session-level (<xref rid="F5" ref-type="fig">Figure 5B</xref>). The design matrices can include: (i) task regressors created by convolving a hemodynamic response function (HRF, e.g., Boynton, double Gaussian) with event timeseries (i.e., assumed modeling, as shown here for the Story and Math blocks of a language task; Barch et al., <xref rid="B7" ref-type="bibr">2013</xref>); (ii) separate regressors for each frame of the trial, i.e., unassumed modeling of task response; (iii) a combination of assumed and unassumed regressors. The events in assumed and unassumed modeling can be individually weighted, enabling estimates of trial-by-trial correlation with e.g., response reaction time, accuracy or precision. The GLM engine estimates the model and outputs both a residual time-series (“pseudo-resting state”) as well as coefficient maps for each regressor, reflecting task activation for each of the modeled events. After a model has been estimated, it is possible to compute both predicted and residual timeseries with an arbitrary combination of regressors from the estimated model (e.g., residual that retains transient task response after removal of sustained task response and nuisance regressors).</p>
    </sec>
    <sec>
      <title> QuNex supports built-in interoperability with externally-developed tools</title>
      <p>QuNex is designed to provide interoperability between community tools to remove barriers between different stages of neuroimaging research. One such feature is its compatibility with XNAT (eXtensible Neuroimaging Archive Toolkit; Marcus et al., <xref rid="B45" ref-type="bibr">2007</xref>; Herrick et al., <xref rid="B38" ref-type="bibr">2016</xref>), a widely used platform for research data transfer, archiving, and sharing (<xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 8</xref>). This enables researchers to seamlessly organize, process, and manage their imaging studies in a coherent integrated environment. QuNex also provides user-friendly interoperability with a suite of tools, including AFNI, FSL, HCP Workbench etc.</p>
      <p>Another interoperabilty feature is the execution of group-level statistical testing of neuroimaging maps, which is performed through Permutation Analysis of Linear Models (PALM) (Winkler et al., <xref rid="B63" ref-type="bibr">2014</xref>), an externally-developed tool which executes nonparametric permutation-based significance testing for neuroimaging data. QuNex provides a smooth interface for multi-level modeling <italic>via</italic> PALM. PALM itself supports volume-based NIFTI, surface-based GIFTI, and surface-volume hybrid CIFTI images, and allows for fully customizable statistical tests with a host of familywise error protection and spatial statistics options. Within QuNex, PALM is called through the <monospace>qunex run_palm</monospace> command, which provides a cohesive interface for specifying inputs, outputs, and options. The user is able to customize design matrices and contrasts according to their need and provide these along with QuNex-generated neural maps to assess for significance using permutation testing and familywise error protection.</p>
      <p><xref rid="F5" ref-type="fig">Figure 5C</xref> illustrates an example where S1-seed functional connectivity maps for <italic>N</italic> = 339 sessions are tested at the group-level to show a significant negative relationship with age in areas such as the somatomotor cortices [<italic>p</italic> &lt; 0.05, non-parametrically tested and family-wise error protected with threshold-free cluster enhancement (TFCE); Smith and Nichols, <xref rid="B58" ref-type="bibr">2009</xref>]. As with functional connectivity maps, task activation maps can be tested for significant effects in the group-level GLM with PALM (<xref rid="F5" ref-type="fig">Figure 5D</xref>). Here, a within-subject <italic>t</italic>-test of the Story &gt; Math contrast reveals significant areas of the language network, also shown in <xref rid="F4" ref-type="fig">Figures 4E</xref>, <xref rid="F4" ref-type="fig">F</xref>. QuNex additionally supports joint inference from combined multi-modal data <italic>via</italic> multivariate statistical tests (e.g., MANOVAs, MANCOVAs) and non-parametric combination tests (Winkler et al., <xref rid="B64" ref-type="bibr">2016</xref>), also executed through PALM and thus compatible with permutation testing. For example, seed-based functional connectivity and structural connectivity of area S1 from the same individuals can be entered into the same test as separate modalities. The second-level GLM shown in <xref rid="F5" ref-type="fig">Figure 5E</xref> is the same one as in <xref rid="F5" ref-type="fig">Figure 5B</xref> to test for age effects. Such joint inference tests can be used to test whether there are jointly significant differences on a set of modalities. Thus, QuNex enables streamlined workflows for multi-modal neuroimaging feature generation and integrated multi-variate statistical analyses. QuNex workflows simplify neuroimaging data management and analysis across a wide range of clinical, translational, and basic neuroimaging studies, including studies examining the relationship between neuroimaging features and gene expression or symptom presentation, or pharmacological neuroimaging studies of mechanism. <xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 9</xref> highlights a few examples of recently published studies which leveraged QuNex for preprocessing, feature generation, and analytics.</p>
      <p>QuNex also encourages future integration of open source community tools <italic>via</italic> the extensions framework, through which researchers can integrate their own tools and pipelines into the QuNex platform (<xref rid="SM1" ref-type="supplementary-material">Supplementary material</xref>). To continually engage community participation in neuroimaging tool development, QuNex provides a SDK that includes helper functions for users to set up a development and testing environment (<xref rid="SM1" ref-type="supplementary-material">Supplementary Figure 10</xref>).</p>
    </sec>
    <sec>
      <title> Cross-species support for translational neuroimaging</title>
      <p>Studies of non-human species have substantially contributed to the understanding of the central nervous system, and provided a crucial opportunity for translational science. In particular, the macaque brain is phylogenetically similar to the human brain, and comparative neuroimaging studies in macaques have served to inform and validate human neuroimaging results. It is thus imperative to develop and distribute tools for consistent processing and analytics of non-human neuroimaging data for aiding translational cross-species neuroimaging studies (de Schotten et al., <xref rid="B18" ref-type="bibr">2019</xref>; Mars et al., <xref rid="B47" ref-type="bibr">2021</xref>). To this end, QuNex supports analogous workflows for human and non-human primate neuroimaging data. <xref rid="F6" ref-type="fig">Figure 6</xref> shows parallel steps for running HCP-style preprocessing and generating multi-modal neural features in human and macaque data. Structural data outputs include FreeSurfer segmentation and labeling of cortical and subcortical areas, T1w/T2w myelin maps (<xref rid="F6" ref-type="fig">Figure 6A</xref>), and structural metrics such as cortical thickness, curvature, and subcortical volumes. Functional data outputs include BOLD signal and metrics such as functional connectivity (<xref rid="F6" ref-type="fig">Figure 6B</xref>). Diffusion metrics include measures of microstructure (e.g., fractional anisotropy maps), white matter tracts and their cortical termination maps, and whole-brain structural connectivity, as shown in <xref rid="F6" ref-type="fig">Figure 6C</xref>. Currently, QuNex supports macaque diffusion pipelines in the released container, with HCP macaque functional neuroimaging pipelines (Hayashi et al., <xref rid="B37" ref-type="bibr">2021</xref>) and mouse neuroimaging pipelines (Zerbi et al., <xref rid="B65" ref-type="bibr">2015</xref>) under development for a future release. The functional macaque images shown here are obtained from an early development version of the pipelines.</p>
      <fig position="float" id="F6">
        <label>Figure 6</label>
        <caption>
          <p>QuNex enables neuroimaging workflows across different species. <bold>(A)</bold> Structural features for exemplar macaque and human data, including surface reconstructions and segmentation from FreeSurfer. Lower panel shows output myelin (T1w/T2w) maps. <bold>(B)</bold> Functional features for exemplar macaque and human showing BOLD signal mapped to both volume and surface. Lower panels show and resting-state functional connectivity seeded from the lateral geniculate nucleus of the thalamus (green arrow). <bold>(C)</bold> Diffusion features for exemplar macaque and human data, showing whole-brain fractional anistropy, and volume and surface terminations of the left optic radiation tract. Lower panels show the structural connectivity maps seeded from the lateral geniculate nucleus of the thalamus (green arrow). Gray scale reference bars in each panel are scaled to 25 mm.</p>
        </caption>
        <graphic xlink:href="fninf-17-1104508-g0006" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>Discussion</title>
    <p>The popularity of neuroimaging research has led to the development and availability of many tools and pipelines, many of which are specific to one modality. This in turn has led to challenges in method integration, particularly across different neuroimaging sub-fields. Additionally, the wide availability of different pipeline and preprocessing/analytic choices may contribute to difficulties with producing replicable results (Botvinik-Nezer et al., <xref rid="B11" ref-type="bibr">2020</xref>). Thus, QuNex is designed to be an integrative platform with interoperability for externally-developed tools across multiple neuroimaging modalities. It leverages existing state-of-the-art neuroimaging tools and software packages, with a roadmap for continued integration of new tools and features. Additionally, QuNex provides features such as turnkey functionality, native scheduler support, flexible data filtering and selection, multi-modal integration, and cross-species support, to fully enable neuroimaging workflows.</p>
    <p>It should be noted that there are currently several tools in the neuroimaging community with multi-modality support, including (but not limited to) FSL, SPM, Freesurfer, AFNI, and PALM. These softwares all offer preprocessing and/or analytic capabilities for at least three different neural modalities, such as T1w, T2w, fMRI, arterial spin labeling (ASL), dMRI, EEG, MEG, and functional near-infrared spectroscopy (fNIRS). Rather than reinventing the wheel, QuNex builds upon the decades of research, optimization, and validation of these tools by using them as basic building blocks for fundamental steps of neuroimaging workflows, and augments their functionality and interoperability. Other high-level environments, such as HCP MPP (Glasser et al., <xref rid="B32" ref-type="bibr">2013</xref>), UK Biobank pipelines (Alfaro-Almagro et al., <xref rid="B1" ref-type="bibr">2018</xref>), fMRIPrep (Esteban et al., <xref rid="B22" ref-type="bibr">2019</xref>), QSIPrep (Cieslak et al., <xref rid="B15" ref-type="bibr">2021</xref>), micapipe (Cruces et al., <xref rid="B17" ref-type="bibr">2022</xref>), nipype (Gorgolewski et al., <xref rid="B35" ref-type="bibr">2016</xref>), BrainVoyager (Goebel, <xref rid="B34" ref-type="bibr">2012</xref>), FuNP (Park et al., <xref rid="B51" ref-type="bibr">2019</xref>), Clinica (Routier et al., <xref rid="B54" ref-type="bibr">2021</xref>), brainlife (Avesani et al., <xref rid="B6" ref-type="bibr">2019</xref>), NeuroDebian (Halchenko and Hanke, <xref rid="B36" ref-type="bibr">2012</xref>), and LONI pipelines (Dinov et al., <xref rid="B19" ref-type="bibr">2009</xref>), also leverage other neuroimaging tools as building blocks. We emphasize that QuNex is a unifying framework for integrating multi-modal, multi-species neuroimaging tools and workflows, rather than a choice of preprocessing or analytic pipeline; as such, QuNex can incorporate these options, as evidenced by the current integration of the HCP MPP and the planned integration of fMRIPrep. Furthermore, QuNex offers additional user-friendly features which expand upon the existing functionality of these tools, including flexible data filtering, turnkey functionality, support for cloud and HPC deployment, native scheduling and parallelization options, and collaborative development tools. A list of the implementations for different functionalities in QuNex, as well as comparable implementations in other neuroimaging pipelines and environments, is shown in <xref rid="F7" ref-type="fig">Figure 7</xref>.</p>
    <fig position="float" id="F7">
      <label>Figure 7</label>
      <caption>
        <p>Features included in QuNex and comparisons to other neuroimaging software. A list of tools integrated into QuNex along with supported QuNex functionalities. We also list functionalities and tools currently available in some popular neuroimaging pipelines/environments, including fMRIPrep (Esteban et al., <xref rid="B22" ref-type="bibr">2019</xref>), QSIPrep (Cieslak et al., <xref rid="B15" ref-type="bibr">2021</xref>), HCP (Glasser et al., <xref rid="B32" ref-type="bibr">2013</xref>), UK Biobank (Alfaro-Almagro et al., <xref rid="B1" ref-type="bibr">2018</xref>), nipype (Gorgolewski et al., <xref rid="B35" ref-type="bibr">2016</xref>), micapipe (Cruces et al., <xref rid="B17" ref-type="bibr">2022</xref>), FuNP (Park et al., <xref rid="B51" ref-type="bibr">2019</xref>), NeuroDebian (Halchenko and Hanke, <xref rid="B36" ref-type="bibr">2012</xref>), BrainVoyager (Goebel, <xref rid="B34" ref-type="bibr">2012</xref>), and LONI (Dinov et al., <xref rid="B19" ref-type="bibr">2009</xref>).</p>
      </caption>
      <graphic xlink:href="fninf-17-1104508-g0007" position="float"/>
    </fig>
    <p>In addition, several commercial platforms are available for neuroimaging data management and analytics [e.g., Flywheel (Tapera et al., <xref rid="B59" ref-type="bibr">2021</xref>), QMENTA, Nordic Tools, Ceretype], especially for clinical applications. While these platforms offer a wide range of neuroinformatics functionalities, they are difficult to evaluate due to their high cost of services and proprietary content. On the contrary, QuNex is free to use for non-commercial research, with transparent and collaborative code and development.</p>
    <p>The QuNex container and SDK, as well as example data and tutorials, are available at: <ext-link xlink:href="http://qunex.yale.edu" ext-link-type="uri">qunex.yale.edu</ext-link>. The online documentation can be found at: <ext-link xlink:href="http://qunex.readthedocs.io/" ext-link-type="uri">http://qunex.readthedocs.io/</ext-link> and the community forum is hosted at: <ext-link xlink:href="http://forum.qunex.yale.edu" ext-link-type="uri">forum.qunex.yale.edu</ext-link>.</p>
    <p>Neuroimaging is an actively advancing field and QuNex is committed to continual development and advancement of neuroimaging methods. Below, we list features and existing external software which are currently under development/integration, as well as those which are staged for future release. As neuroimaging techniques advance and novel tools and methods are developed and adopted, we plan to integrate them into the QuNex platform either through internal development or <italic>via</italic> the extensions framework.</p>
    <p><italic>Currently under development:</italic> Longitudinal preprocessing; mouse neuroimaging preprocessing and analytics; EEG preprocessing and analytics.</p>
    <p><italic>Staged for development:</italic> PET preprocessing and analytics; BIDS exporter; fMRIPrep.</p>
  </sec>
  <sec sec-type="data-availability" id="s5">
    <title>Data availability statement</title>
    <p>The QuNex container and SDK, as well as example data and tutorials, are available at <ext-link xlink:href="https://qunex.yale.edu" ext-link-type="uri">qunex.yale.edu</ext-link>. The original contributions presented in the study are included in the article/<xref rid="SM1" ref-type="supplementary-material">Supplementary material</xref>. Further inquiries can be directed to the corresponding author.</p>
  </sec>
  <sec sec-type="author-contributions" id="s6">
    <title>Author contributions</title>
    <p>JJ, JD, SW, SS, AA, and GR prepared the initial blockout of the manuscript. JJ and JD prepared the figures and the initial draft of the manuscript. AA and GR supervised this research. All authors helped with contributed to the development of the QuNex platform and reviewed and approved the final version of the manuscript.</p>
  </sec>
</body>
<back>
  <ack>
    <p>We would like to thank Brendan Adkinson, Charles Schleifer, Martina Starc, Anka Slana Ozimič, and Martin Bavčar for their support in testing the QuNex platform and contributing to the development of QuNex documentation.</p>
  </ack>
  <sec sec-type="COI-statement" id="conf1">
    <title>Conflict of interest</title>
    <p>JJ is an employee of Manifest Technologies and has previously worked for Neumora (formerly BlackThorn Therapeutics) and is a co-inventor on the following patent: AA, JM, and JJ: systems and methods for neuro-behavioral relationships in dimensional geometric embedding (N-BRIDGE), PCT International Application No. PCT/US2119/022110, filed March 13, 2019. AK and AM have previously consulted for Neumora (formerly BlackThorn Therapeutics). CF, JD, and ZT have previously consulted for Neumora (formerly BlackThorn Therapeutics) and consult for Manifest Technologies. MHe and LP are employees of Manifest Technologies. VZ and SS consults for Manifest Technologies. JM and AA consult for and hold equity with Neumora (formerly BlackThorn Therapeutics), Manifest Technologies, and are co-inventors on the following patents: JM, AA, and Martin, WJ: Methods and tools for detecting, diagnosing, predicting, prognosticating, or treating a neurobehavioral phenotype in a subject, U.S. Application No. 16/149,903 filed on October 2, 2018, U.S. Application for PCT International Application No. 18/054,009 filed on October 2, 2018. GR consults for and holds equity with Neumora (formerly BlackThorn Therapeutics) and Manifest Technologies. The remaining authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s8">
    <title>Publisher's note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
  <sec sec-type="supplementary-material" id="s9">
    <title>Supplementary material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link xlink:href="https://www.frontiersin.org/articles/10.3389/fninf.2023.1104508/full#supplementary-material" ext-link-type="uri">https://www.frontiersin.org/articles/10.3389/fninf.2023.1104508/full#supplementary-material</ext-link></p>
    <supplementary-material id="SM1" position="float" content-type="local-data">
      <media xlink:href="Data_Sheet_1.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alfaro-Almagro</surname><given-names>F.</given-names></name><name><surname>Jenkinson</surname><given-names>M.</given-names></name><name><surname>Bangerter</surname><given-names>N. K.</given-names></name><name><surname>Andersson</surname><given-names>J. L.</given-names></name><name><surname>Griffanti</surname><given-names>L.</given-names></name><name><surname>Douaud</surname><given-names>G.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Image processing and quality control for the first 10,000 brain imaging datasets from UK biobank</article-title>. <source>Neuroimage</source><volume>166</volume>, <fpage>400</fpage>–<lpage>424</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.10.034</pub-id><?supplied-pmid 29079522?><pub-id pub-id-type="pmid">29079522</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersson</surname><given-names>J. L.</given-names></name><name><surname>Skare</surname><given-names>S.</given-names></name><name><surname>Ashburner</surname><given-names>J.</given-names></name></person-group> (<year>2003</year>). <article-title>How to correct susceptibility distortions in spin-echo echo-planar images: application to diffusion tensor imaging</article-title>. <source>Neuroimage</source>
<volume>20</volume>, <fpage>870</fpage>–<lpage>888</lpage>. <pub-id pub-id-type="doi">10.1016/S1053-8119(03)00336-7</pub-id><?supplied-pmid 14568458?><pub-id pub-id-type="pmid">14568458</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andersson</surname><given-names>J. L.</given-names></name><name><surname>Sotiropoulos</surname><given-names>S. N.</given-names></name></person-group> (<year>2016</year>). <article-title>An integrated approach to correction for off-resonance effects and subject movement in diffusion mr imaging</article-title>. <source>Neuroimage</source>
<volume>125</volume>, <fpage>1063</fpage>–<lpage>1078</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.10.019</pub-id><?supplied-pmid 26481672?><pub-id pub-id-type="pmid">26481672</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J.</given-names></name></person-group> (<year>2012</year>). <article-title>SPM: a history</article-title>. <source>Neuroimage</source>
<volume>62</volume>, <fpage>791</fpage>–<lpage>800</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.10.025</pub-id><?supplied-pmid 22023741?><pub-id pub-id-type="pmid">22023741</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Autio</surname><given-names>J. A.</given-names></name><name><surname>Glasser</surname><given-names>M. F.</given-names></name><name><surname>Ose</surname><given-names>T.</given-names></name><name><surname>Donahue</surname><given-names>C. J.</given-names></name><name><surname>Bastiani</surname><given-names>M.</given-names></name><name><surname>Ohno</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Towards HCP-style macaque connectomes: 24-channel 3t multi-array coil, MRI sequences and preprocessing</article-title>. <source>NeuroImage</source><volume>215</volume>:<fpage>116800</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116800</pub-id><?supplied-pmid 32276072?><pub-id pub-id-type="pmid">32276072</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avesani</surname><given-names>P.</given-names></name><name><surname>McPherson</surname><given-names>B.</given-names></name><name><surname>Hayashi</surname><given-names>S.</given-names></name><name><surname>Caiafa</surname><given-names>C. F.</given-names></name><name><surname>Henschel</surname><given-names>R.</given-names></name><name><surname>Garyfallidis</surname><given-names>E.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>The open diffusion data derivatives, brain data upcycling <italic>via</italic> integrated publishing of derivatives and reproducible open cloud services</article-title>. <source>Sci. Data</source><volume>6</volume>, <fpage>1</fpage>–<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1038/s41597-019-0073-y</pub-id><?supplied-pmid 31123325?><pub-id pub-id-type="pmid">30647409</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barch</surname><given-names>D. M.</given-names></name><name><surname>Burgess</surname><given-names>G. C.</given-names></name><name><surname>Harms</surname><given-names>M. P.</given-names></name><name><surname>Petersen</surname><given-names>S. E.</given-names></name><name><surname>Schlaggar</surname><given-names>B. L.</given-names></name><name><surname>Corbetta</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>Function in the human connectome: task-fMRI and individual differences in behavior</article-title>. <source>Neuroimage</source><volume>80</volume>, <fpage>169</fpage>–<lpage>189</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.033</pub-id><?supplied-pmid 23684877?><pub-id pub-id-type="pmid">23684877</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>T. E.</given-names></name><name><surname>Berg</surname><given-names>H. J.</given-names></name><name><surname>Jbabdi</surname><given-names>S.</given-names></name><name><surname>Rushworth</surname><given-names>M. F.</given-names></name><name><surname>Woolrich</surname><given-names>M. W.</given-names></name></person-group> (<year>2007</year>). <article-title>Probabilistic diffusion tractography with multiple fibre orientations: what can we gain?</article-title>
<source>Neuroimage</source>
<volume>34</volume>, <fpage>144</fpage>–<lpage>155</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.09.018</pub-id><?supplied-pmid 17070705?><pub-id pub-id-type="pmid">17070705</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>J. R.</given-names></name></person-group> (<year>2015</year>). <article-title>The wernicke area: modern evidence and a reinterpretation</article-title>. <source>Neurology</source>
<volume>85</volume>, <fpage>2170</fpage>–<lpage>2175</lpage>. <pub-id pub-id-type="doi">10.1212/WNL.0000000000002219</pub-id><?supplied-pmid 26567270?><pub-id pub-id-type="pmid">26567270</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binder</surname><given-names>J. R.</given-names></name><name><surname>Gross</surname><given-names>W. L.</given-names></name><name><surname>Allendorfer</surname><given-names>J. B.</given-names></name><name><surname>Bonilha</surname><given-names>L.</given-names></name><name><surname>Chapin</surname><given-names>J.</given-names></name><name><surname>Edwards</surname><given-names>J. C.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Mapping anterior temporal lobe language areas with fMRI: a multicenter normative study</article-title>. <source>Neuroimage</source><volume>54</volume>, <fpage>1465</fpage>–<lpage>1475</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.09.048</pub-id><?supplied-pmid 20884358?><pub-id pub-id-type="pmid">20884358</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Botvinik-Nezer</surname><given-names>R.</given-names></name><name><surname>Holzmeister</surname><given-names>F.</given-names></name><name><surname>Camerer</surname><given-names>C. F.</given-names></name><name><surname>Dreber</surname><given-names>A.</given-names></name><name><surname>Huber</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Variability in the analysis of a single neuroimaging dataset by many teams</article-title>. <source>Nature</source><volume>582</volume>, <fpage>84</fpage>–<lpage>88</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-020-2314-9</pub-id><?supplied-pmid 33065844?><pub-id pub-id-type="pmid">32483374</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boynton</surname><given-names>G. M.</given-names></name><name><surname>Engel</surname><given-names>S. A.</given-names></name><name><surname>Glover</surname><given-names>G. H.</given-names></name><name><surname>Heeger</surname><given-names>D. J.</given-names></name></person-group> (<year>1996</year>). <article-title>Linear systems analysis of functional magnetic resonance imaging in human v1</article-title>. <source>J. Neurosci</source>. <volume>16</volume>, <fpage>4207</fpage>–<lpage>4221</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.16-13-04207.1996</pub-id><?supplied-pmid 8753882?><pub-id pub-id-type="pmid">8753882</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bycroft</surname><given-names>C.</given-names></name><name><surname>Freeman</surname><given-names>C.</given-names></name><name><surname>Petkova</surname><given-names>D.</given-names></name><name><surname>Band</surname><given-names>G.</given-names></name><name><surname>Elliott</surname><given-names>L. T.</given-names></name><name><surname>Sharp</surname><given-names>K.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>The uk biobank resource with deep phenotyping and genomic data</article-title>. <source>Nature</source><volume>562</volume>, <fpage>203</fpage>–<lpage>209</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-018-0579-z</pub-id><?supplied-pmid 30305743?><pub-id pub-id-type="pmid">30305743</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Casey</surname><given-names>B.</given-names></name><name><surname>Cannonier</surname><given-names>T.</given-names></name><name><surname>Conley</surname><given-names>M. I.</given-names></name><name><surname>Cohen</surname><given-names>A. O.</given-names></name><name><surname>Barch</surname><given-names>D. M.</given-names></name><name><surname>Heitzeg</surname><given-names>M. M.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>The adolescent brain cognitive development (ABCD) study: imaging acquisition across 21 sites</article-title>. <source>Dev. Cogn. Neurosci</source>. <volume>32</volume>, <fpage>43</fpage>–<lpage>54</lpage>. <pub-id pub-id-type="doi">10.1016/j.dcn.2018.03.001</pub-id><?supplied-pmid 29567376?><pub-id pub-id-type="pmid">29567376</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cieslak</surname><given-names>M.</given-names></name><name><surname>Cook</surname><given-names>P. A.</given-names></name><name><surname>He</surname><given-names>X.</given-names></name><name><surname>Yeh</surname><given-names>F.-C.</given-names></name><name><surname>Dhollander</surname><given-names>T.</given-names></name><name><surname>Adebimpe</surname><given-names>A.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Qsiprep: an integrative platform for preprocessing and reconstructing diffusion MRI data</article-title>. <source>Nat. Methods</source><volume>18</volume>, <fpage>775</fpage>–<lpage>778</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-021-01185-5</pub-id><?supplied-pmid 34155395?><pub-id pub-id-type="pmid">34155395</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>R. W.</given-names></name></person-group> (<year>1996</year>). <article-title>AFNI: software for analysis and visualization of functional magnetic resonance neuroimages</article-title>. <source>Comput. Biomed. Res</source>. <volume>29</volume>, <fpage>162</fpage>–<lpage>173</lpage>. <pub-id pub-id-type="doi">10.1006/cbmr.1996.0014</pub-id><?supplied-pmid 8812068?><pub-id pub-id-type="pmid">8812068</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cruces</surname><given-names>R. R.</given-names></name><name><surname>Royer</surname><given-names>J.</given-names></name><name><surname>Herholz</surname><given-names>P.</given-names></name><name><surname>Larivière</surname><given-names>S.</given-names></name><name><surname>de Wael</surname><given-names>R. V.</given-names></name><name><surname>Paquola</surname><given-names>C.</given-names></name><etal/></person-group>. (<year>2022</year>). <article-title>Micapipe: a pipeline for multimodal neuroimaging and connectome analysis</article-title>. <source>NeuroImage</source>. 263, 119612. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2022.119612</pub-id><?supplied-pmid 36070839?><pub-id pub-id-type="pmid">36070839</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Schotten</surname><given-names>M. T.</given-names></name><name><surname>Croxson</surname><given-names>P. L.</given-names></name><name><surname>Mars</surname><given-names>R. B.</given-names></name></person-group> (<year>2019</year>). <article-title>Large-scale comparative neuroimaging: where are we and what do we need?</article-title>
<source>Cortex</source>
<volume>118</volume>, <fpage>188</fpage>–<lpage>202</lpage>. <pub-id pub-id-type="doi">10.1016/j.cortex.2018.11.028</pub-id><?supplied-pmid 30661736?><pub-id pub-id-type="pmid">30661736</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dinov</surname><given-names>I.</given-names></name><name><surname>Van Horn</surname><given-names>J.</given-names></name><name><surname>Lozev</surname><given-names>K.</given-names></name><name><surname>Magsipoc</surname><given-names>R.</given-names></name><name><surname>Petrosyan</surname><given-names>P.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><etal/></person-group>. (<year>2009</year>). <article-title>Efficient, distributed and interactive neuroimaging data analysis using the loni pipeline</article-title>. <source>Front. Neuroinform</source>. <volume>3</volume>:<fpage>22</fpage>. <pub-id pub-id-type="doi">10.3389/neuro.11.022.2009</pub-id><?supplied-pmid 19649168?><pub-id pub-id-type="pmid">19649168</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichert</surname><given-names>N.</given-names></name><name><surname>Robinson</surname><given-names>E. C.</given-names></name><name><surname>Bryant</surname><given-names>K. L.</given-names></name><name><surname>Jbabdi</surname><given-names>S.</given-names></name><name><surname>Jenkinson</surname><given-names>M.</given-names></name><name><surname>Li</surname><given-names>L.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Cross-species cortical alignment identifies different types of anatomical reorganization in the primate temporal lobe</article-title>. <source>Elife</source><volume>9</volume>:<fpage>e53232</fpage>. <pub-id pub-id-type="doi">10.7554/eLife.53232</pub-id><?supplied-pmid 32202497?><pub-id pub-id-type="pmid">32202497</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elam</surname><given-names>J. S.</given-names></name><name><surname>Glasser</surname><given-names>M. F.</given-names></name><name><surname>Harms</surname><given-names>M. P.</given-names></name><name><surname>Sotiropoulos</surname><given-names>S. N.</given-names></name><name><surname>Andersson</surname><given-names>J. L.</given-names></name><name><surname>Burgess</surname><given-names>G. C.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>The human connectome project: a retrospective</article-title>. <source>NeuroImage</source><volume>2021</volume>:<fpage>118543</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118543</pub-id><?supplied-pmid 34508893?><pub-id pub-id-type="pmid">34508893</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esteban</surname><given-names>O.</given-names></name><name><surname>Markiewicz</surname><given-names>C. J.</given-names></name><name><surname>Blair</surname><given-names>R. W.</given-names></name><name><surname>Moodie</surname><given-names>C. A.</given-names></name><name><surname>Isik</surname><given-names>A. I.</given-names></name><name><surname>Erramuzpe</surname><given-names>A.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>fmriprep: a robust preprocessing pipeline for functional MRI</article-title>. <source>Nat. Methods</source><volume>16</volume>, <fpage>111</fpage>–<lpage>116</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id><?supplied-pmid 30532080?><pub-id pub-id-type="pmid">30532080</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fadiga</surname><given-names>L.</given-names></name><name><surname>Craighero</surname><given-names>L.</given-names></name><name><surname>D'Ausilio</surname><given-names>A.</given-names></name></person-group> (<year>2009</year>). <article-title>Broca's area in language, action, and music</article-title>. <source>Ann. N. Y. Acad. Sci</source>. <volume>1169</volume>, <fpage>448</fpage>–<lpage>458</lpage>. <pub-id pub-id-type="doi">10.1111/j.1749-6632.2009.04582.x</pub-id><?supplied-pmid 19673823?><pub-id pub-id-type="pmid">19673823</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fan</surname><given-names>L.</given-names></name><name><surname>Li</surname><given-names>H.</given-names></name><name><surname>Zhuo</surname><given-names>J.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>L.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>The human brainnetome atlas: a new brain atlas based on connectional architecture</article-title>. <source>Cereb. Cortex</source><volume>26</volume>, <fpage>3508</fpage>–<lpage>3526</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhw157</pub-id><?supplied-pmid 27230218?><pub-id pub-id-type="pmid">27230218</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B.</given-names></name></person-group> (<year>2012</year>). <article-title>Freesurfer</article-title>. <source>Neuroimage</source>
<volume>62</volume>, <fpage>774</fpage>–<lpage>781</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.021</pub-id><?supplied-pmid 22248573?><pub-id pub-id-type="pmid">22248573</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frey</surname><given-names>S.</given-names></name><name><surname>Campbell</surname><given-names>J. S.</given-names></name><name><surname>Pike</surname><given-names>G. B.</given-names></name><name><surname>Petrides</surname><given-names>M.</given-names></name></person-group> (<year>2008</year>). <article-title>Dissociating the human language pathways with high angular resolution diffusion fiber tractography</article-title>. <source>J. Neurosci</source>. <volume>28</volume>, <fpage>11435</fpage>–<lpage>11444</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2388-08.2008</pub-id><?supplied-pmid 18987180?><pub-id pub-id-type="pmid">18987180</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friederici</surname><given-names>A. D.</given-names></name></person-group> (<year>2011</year>). <article-title>The brain basis of language processing: from structure to function</article-title>. <source>Physiol. Rev</source>. <volume>91</volume>, <fpage>1357</fpage>–<lpage>1392</lpage>. <pub-id pub-id-type="doi">10.1152/physrev.00006.2011</pub-id><?supplied-pmid 22013214?><pub-id pub-id-type="pmid">22013214</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friederici</surname><given-names>A. D.</given-names></name><name><surname>Bahlmann</surname><given-names>J.</given-names></name><name><surname>Heim</surname><given-names>S.</given-names></name><name><surname>Schubotz</surname><given-names>R. I.</given-names></name><name><surname>Anwander</surname><given-names>A.</given-names></name></person-group> (<year>2006</year>). <article-title>The brain differentiates human and non-human grammars: functional localization and structural connectivity</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A</source>. <volume>103</volume>, <fpage>2458</fpage>–<lpage>2463</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0509389103</pub-id><?supplied-pmid 16461904?><pub-id pub-id-type="pmid">16461904</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friederici</surname><given-names>A. D.</given-names></name><name><surname>Gierhan</surname><given-names>S. M.</given-names></name></person-group> (<year>2013</year>). <article-title>The language network</article-title>. <source>Curr. Opin. Neurobiol</source>. <volume>23</volume>, <fpage>250</fpage>–<lpage>254</lpage>. <pub-id pub-id-type="doi">10.1016/j.conb.2012.10.002</pub-id><?supplied-pmid 23146876?><pub-id pub-id-type="pmid">23146876</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>M. F.</given-names></name><name><surname>Coalson</surname><given-names>T. S.</given-names></name><name><surname>Robinson</surname><given-names>E. C.</given-names></name><name><surname>Hacker</surname><given-names>C. D.</given-names></name><name><surname>Harwell</surname><given-names>J.</given-names></name><name><surname>Yacoub</surname><given-names>E.</given-names></name><etal/></person-group>. (<year>2016a</year>). <article-title>A multi-modal parcellation of human cerebral cortex</article-title>. <source>Nature</source><volume>536</volume>:<fpage>171</fpage>. <pub-id pub-id-type="doi">10.1038/nature18933</pub-id><?supplied-pmid 27437579?><pub-id pub-id-type="pmid">27437579</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>M. F.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name><name><surname>Marcus</surname><given-names>D. S.</given-names></name><name><surname>Andersson</surname><given-names>J. L.</given-names></name><name><surname>Auerbach</surname><given-names>E. J.</given-names></name><name><surname>Behrens</surname><given-names>T. E.</given-names></name><etal/></person-group>. (<year>2016b</year>). <article-title>The human connectome project's neuroimaging approach</article-title>. <source>Nat. Neurosci</source>. <volume>19</volume>, <fpage>1175</fpage>–<lpage>1187</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4361</pub-id><?supplied-pmid 27571196?><pub-id pub-id-type="pmid">27571196</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>M. F.</given-names></name><name><surname>Sotiropoulos</surname><given-names>S. N.</given-names></name><name><surname>Wilson</surname><given-names>J. A.</given-names></name><name><surname>Coalson</surname><given-names>T. S.</given-names></name><name><surname>Fischl</surname><given-names>B.</given-names></name><name><surname>Andersson</surname><given-names>J. L.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>The minimal preprocessing pipelines for the human connectome project</article-title>. <source>Neuroimage</source><volume>80</volume>, <fpage>105</fpage>–<lpage>124</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.127</pub-id><?supplied-pmid 23668970?><pub-id pub-id-type="pmid">23668970</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname><given-names>M. F.</given-names></name><name><surname>Van Essen</surname><given-names>D. C.</given-names></name></person-group> (<year>2011</year>). <article-title>Mapping human cortical areas in vivo based on myelin content as revealed by t1-and t2-weighted MRI</article-title>. <source>J. Neurosci</source>. <volume>31</volume>, <fpage>11597</fpage>–<lpage>11616</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2180-11.2011</pub-id><?supplied-pmid 21832190?><pub-id pub-id-type="pmid">21832190</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goebel</surname><given-names>R.</given-names></name></person-group> (<year>2012</year>). <article-title>Brainvoyager-past, present, future</article-title>. <source>Neuroimage</source>
<volume>62</volume>, <fpage>748</fpage>–<lpage>756</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.083</pub-id><?supplied-pmid 22289803?><pub-id pub-id-type="pmid">22289803</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>K. J.</given-names></name><name><surname>Auer</surname><given-names>T.</given-names></name><name><surname>Calhoun</surname><given-names>V. D.</given-names></name><name><surname>Craddock</surname><given-names>R. C.</given-names></name><name><surname>Das</surname><given-names>S.</given-names></name><name><surname>Duff</surname><given-names>E. P.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments</article-title>. <source>Sci. Data</source><volume>3</volume>, <fpage>1</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1038/sdata.2016.44</pub-id><?supplied-pmid 27326542?><pub-id pub-id-type="pmid">27326542</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halchenko</surname><given-names>Y. O.</given-names></name><name><surname>Hanke</surname><given-names>M.</given-names></name></person-group> (<year>2012</year>). <article-title>Open is not enough. let's take the next step: an integrated, community-driven computing platform for neuroscience</article-title>. <source>Front. Neuroinform</source>. <volume>6</volume>:<fpage>22</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2012.00022</pub-id><?supplied-pmid 23055966?><pub-id pub-id-type="pmid">23055966</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayashi</surname><given-names>T.</given-names></name><name><surname>Hou</surname><given-names>Y.</given-names></name><name><surname>Glasser</surname><given-names>M. F.</given-names></name><name><surname>Autio</surname><given-names>J. A.</given-names></name><name><surname>Knoblauch</surname><given-names>K.</given-names></name><name><surname>Inoue-Murayama</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>The nonhuman primate neuroimaging and neuroanatomy project</article-title>. <source>Neuroimage</source><volume>229</volume>:<fpage>117726</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.117726</pub-id><?supplied-pmid 33484849?><pub-id pub-id-type="pmid">33484849</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herrick</surname><given-names>R.</given-names></name><name><surname>Horton</surname><given-names>W.</given-names></name><name><surname>Olsen</surname><given-names>T.</given-names></name><name><surname>McKay</surname><given-names>M.</given-names></name><name><surname>Archie</surname><given-names>K. A.</given-names></name><name><surname>Marcus</surname><given-names>D. S.</given-names></name></person-group> (<year>2016</year>). <article-title>Xnat central: Open sourcing imaging research data</article-title>. <source>NeuroImage</source>
<volume>124</volume>, <fpage>1093</fpage>–<lpage>1096</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.06.076</pub-id><?supplied-pmid 26143202?><pub-id pub-id-type="pmid">26143202</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jbabdi</surname><given-names>S.</given-names></name><name><surname>Sotiropoulos</surname><given-names>S. N.</given-names></name><name><surname>Savio</surname><given-names>A. M.</given-names></name><name><surname>Gra na</surname><given-names>M.</given-names></name><name><surname>Behrens</surname><given-names>T. E.</given-names></name></person-group> (<year>2012</year>). <article-title>Model-based analysis of multishell diffusion MR data for tractography: how to get over fitting problems</article-title>. <source>Magn. Resonan. Med</source>. <volume>68</volume>, <fpage>1846</fpage>–<lpage>1855</lpage>. <pub-id pub-id-type="doi">10.1002/mrm.24204</pub-id><?supplied-pmid 22334356?><pub-id pub-id-type="pmid">22334356</pub-id></mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M.</given-names></name><name><surname>Bannister</surname><given-names>P.</given-names></name><name><surname>Brady</surname><given-names>M.</given-names></name><name><surname>Smith</surname><given-names>S.</given-names></name></person-group> (<year>2002</year>). <article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title>. <source>Neuroimage</source>
<volume>17</volume>, <fpage>825</fpage>–<lpage>841</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.2002.1132</pub-id><?supplied-pmid 12377157?><pub-id pub-id-type="pmid">12377157</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ji</surname><given-names>J. L.</given-names></name><name><surname>Diehl</surname><given-names>C.</given-names></name><name><surname>Schleifer</surname><given-names>C.</given-names></name><name><surname>Tamminga</surname><given-names>C. A.</given-names></name><name><surname>Keshavan</surname><given-names>M. S.</given-names></name><name><surname>Sweeney</surname><given-names>J. A.</given-names></name><etal/></person-group>. (<year>2019a</year>). <article-title>Schizophrenia exhibits bi-directional brain-wide alterations in cortico-striato-cerebellar circuits</article-title>. <source>Cereb. Cortex</source><volume>29</volume>, <fpage>4463</fpage>–<lpage>4487</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhy306</pub-id><?supplied-pmid 31157363?><pub-id pub-id-type="pmid">31157363</pub-id></mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ji</surname><given-names>J. L.</given-names></name><name><surname>Helmer</surname><given-names>M.</given-names></name><name><surname>Fonteneau</surname><given-names>C.</given-names></name><name><surname>Burt</surname><given-names>J. B.</given-names></name><name><surname>Tamayo</surname><given-names>Z.</given-names></name><name><surname>Demšar</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Mapping brain-behavior space relationships along the psychosis spectrum</article-title>. <source>Elife</source><volume>10</volume>:<fpage>e66968</fpage>. <pub-id pub-id-type="doi">10.7554/eLife.66968.sa2</pub-id><?supplied-pmid 35380951?><pub-id pub-id-type="pmid">34313219</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ji</surname><given-names>J. L.</given-names></name><name><surname>Spronk</surname><given-names>M.</given-names></name><name><surname>Kulkarni</surname><given-names>K.</given-names></name><name><surname>Repovš</surname><given-names>G.</given-names></name><name><surname>Anticevic</surname><given-names>A.</given-names></name><name><surname>Cole</surname><given-names>M. W.</given-names></name></person-group> (<year>2019b</year>). <article-title>Mapping the human brain's cortical-subcortical functional network organization</article-title>. <source>NeuroImage</source>
<volume>185</volume>, <fpage>35</fpage>–<lpage>57</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.10.006</pub-id><?supplied-pmid 30291974?><pub-id pub-id-type="pmid">30291974</pub-id></mixed-citation>
    </ref>
    <ref id="B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kozak</surname><given-names>B. M.</given-names></name><name><surname>Jaimes</surname><given-names>C.</given-names></name><name><surname>Kirsch</surname><given-names>J.</given-names></name><name><surname>Gee</surname><given-names>M. S.</given-names></name></person-group> (<year>2020</year>). <article-title>MRI techniques to decrease imaging times in children</article-title>. <source>Radiographics</source>
<volume>40</volume>, <fpage>485</fpage>–<lpage>502</lpage>. <pub-id pub-id-type="doi">10.1148/rg.2020190112</pub-id><?supplied-pmid 32031912?><pub-id pub-id-type="pmid">32031912</pub-id></mixed-citation>
    </ref>
    <ref id="B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marcus</surname><given-names>D. S.</given-names></name><name><surname>Olsen</surname><given-names>T. R.</given-names></name><name><surname>Ramaratnam</surname><given-names>M.</given-names></name><name><surname>Buckner</surname><given-names>R. L.</given-names></name></person-group> (<year>2007</year>). <article-title>The extensible neuroimaging archive toolkit</article-title>. <source>Neuroinformatics</source>
<volume>5</volume>, <fpage>11</fpage>–<lpage>33</lpage>. <pub-id pub-id-type="doi">10.1385/NI:5:1:11</pub-id><?supplied-pmid 17426351?><pub-id pub-id-type="pmid">17426351</pub-id></mixed-citation>
    </ref>
    <ref id="B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marek</surname><given-names>S.</given-names></name><name><surname>Tervo-Clemmens</surname><given-names>B.</given-names></name><name><surname>Calabro</surname><given-names>F. J.</given-names></name><name><surname>Montez</surname><given-names>D. F.</given-names></name><name><surname>Kay</surname><given-names>B. P.</given-names></name><name><surname>Hatoum</surname><given-names>A. S.</given-names></name><etal/></person-group>. (<year>2022</year>). <article-title>Reproducible brain-wide association studies require thousands of individuals</article-title>. <source>Nature</source><volume>603</volume>, <fpage>654</fpage>–<lpage>660</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-022-04492-9</pub-id><?supplied-pmid 35534626?><pub-id pub-id-type="pmid">35296861</pub-id></mixed-citation>
    </ref>
    <ref id="B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mars</surname><given-names>R. B.</given-names></name><name><surname>Jbabdi</surname><given-names>S.</given-names></name><name><surname>Rushworth</surname><given-names>M. F.</given-names></name></person-group> (<year>2021</year>). <article-title>A common space approach to comparative neuroscience</article-title>. <source>Annu. Rev. Neurosci</source>. <volume>44</volume>, <fpage>69</fpage>–<lpage>86</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-neuro-100220-025942</pub-id><?supplied-pmid 33534614?><pub-id pub-id-type="pmid">33534614</pub-id></mixed-citation>
    </ref>
    <ref id="B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mars</surname><given-names>R. B.</given-names></name><name><surname>Sotiropoulos</surname><given-names>S. N.</given-names></name><name><surname>Passingham</surname><given-names>R. E.</given-names></name><name><surname>Sallet</surname><given-names>J.</given-names></name><name><surname>Verhagen</surname><given-names>L.</given-names></name><name><surname>Khrapitchev</surname><given-names>A. A.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Whole brain comparative anatomy using connectivity blueprints</article-title>. <source>Elife</source><volume>7</volume>:<fpage>e35237</fpage>. <pub-id pub-id-type="doi">10.7554/eLife.35237</pub-id><?supplied-pmid 29749930?><pub-id pub-id-type="pmid">29749930</pub-id></mixed-citation>
    </ref>
    <ref id="B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCarthy</surname><given-names>C. S.</given-names></name><name><surname>Ramprashad</surname><given-names>A.</given-names></name><name><surname>Thompson</surname><given-names>C.</given-names></name><name><surname>Botti</surname><given-names>J.-A.</given-names></name><name><surname>Coman</surname><given-names>I. L.</given-names></name><name><surname>Kates</surname><given-names>W. R.</given-names></name></person-group> (<year>2015</year>). <article-title>A comparison of freesurfer-generated data with and without manual intervention</article-title>. <source>Front. Neurosci</source>. <volume>9</volume>:<fpage>379</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2015.00379</pub-id><?supplied-pmid 26539075?><pub-id pub-id-type="pmid">26539075</pub-id></mixed-citation>
    </ref>
    <ref id="B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milham</surname><given-names>M. P.</given-names></name><name><surname>Ai</surname><given-names>L.</given-names></name><name><surname>Koo</surname><given-names>B.</given-names></name><name><surname>Xu</surname><given-names>T.</given-names></name><name><surname>Amiez</surname><given-names>C.</given-names></name><name><surname>Balezeau</surname><given-names>F.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>An open resource for non-human primate imaging</article-title>. <source>Neuron</source><volume>100</volume>, <fpage>61</fpage>–<lpage>74</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2018.08.039</pub-id><?supplied-pmid 30269990?><pub-id pub-id-type="pmid">30269990</pub-id></mixed-citation>
    </ref>
    <ref id="B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>B.-y.</given-names></name><name><surname>Byeon</surname><given-names>K.</given-names></name><name><surname>Park</surname><given-names>H.</given-names></name></person-group> (<year>2019</year>). <article-title>Funp (fusion of neuroimaging preprocessing) pipelines: a fully automated preprocessing software for functional magnetic resonance imaging</article-title>. <source>Front. Neuroinform</source>. <volume>13</volume>:<fpage>5</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2019.00005</pub-id><?supplied-pmid 30804773?><pub-id pub-id-type="pmid">30804773</pub-id></mixed-citation>
    </ref>
    <ref id="B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>J. D.</given-names></name><name><surname>Barnes</surname><given-names>K. A.</given-names></name><name><surname>Snyder</surname><given-names>A. Z.</given-names></name><name><surname>Schlaggar</surname><given-names>B. L.</given-names></name><name><surname>Petersen</surname><given-names>S. E.</given-names></name></person-group> (<year>2013</year>). <article-title>Steps toward optimizing motion artifact removal in functional connectivity MRI; a reply to carp</article-title>. <source>Neuroimage</source>
<volume>76</volume>, <fpage>439</fpage>–<lpage>441</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.03.017</pub-id><?supplied-pmid 22440651?><pub-id pub-id-type="pmid">22440651</pub-id></mixed-citation>
    </ref>
    <ref id="B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reuter</surname><given-names>M.</given-names></name><name><surname>Schmansky</surname><given-names>N. J.</given-names></name><name><surname>Rosas</surname><given-names>H. D.</given-names></name><name><surname>Fischl</surname><given-names>B.</given-names></name></person-group> (<year>2012</year>). <article-title>Within-subject template estimation for unbiased longitudinal image analysis</article-title>. <source>Neuroimage</source>
<volume>61</volume>, <fpage>1402</fpage>–<lpage>1418</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.02.084</pub-id><?supplied-pmid 22430496?><pub-id pub-id-type="pmid">22430496</pub-id></mixed-citation>
    </ref>
    <ref id="B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Routier</surname><given-names>A.</given-names></name><name><surname>Burgos</surname><given-names>N.</given-names></name><name><surname>Díaz</surname><given-names>M.</given-names></name><name><surname>Bacci</surname><given-names>M.</given-names></name><name><surname>Bottani</surname><given-names>S.</given-names></name><name><surname>El-Rifai</surname><given-names>O.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Clinica: An open-source software platform for reproducible clinical neuroscience studies</article-title>. <source>Front. Neuroinform</source>. <volume>15</volume>:<fpage>689675</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2021.689675</pub-id><?supplied-pmid 34483871?><pub-id pub-id-type="pmid">34483871</pub-id></mixed-citation>
    </ref>
    <ref id="B55">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salimi-Khorshidi</surname><given-names>G.</given-names></name><name><surname>Douaud</surname><given-names>G.</given-names></name><name><surname>Beckmann</surname><given-names>C. F.</given-names></name><name><surname>Glasser</surname><given-names>M. F.</given-names></name><name><surname>Griffanti</surname><given-names>L.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name></person-group> (<year>2014</year>). <article-title>Automatic denoising of functional MRI data: combining independent component analysis and hierarchical fusion of classifiers</article-title>. <source>Neuroimage</source>
<volume>90</volume>, <fpage>449</fpage>–<lpage>468</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.11.046</pub-id><?supplied-pmid 24389422?><pub-id pub-id-type="pmid">24389422</pub-id></mixed-citation>
    </ref>
    <ref id="B56">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaefer</surname><given-names>A.</given-names></name><name><surname>Kong</surname><given-names>R.</given-names></name><name><surname>Gordon</surname><given-names>E. M.</given-names></name><name><surname>Laumann</surname><given-names>T. O.</given-names></name><name><surname>Zuo</surname><given-names>X.-N.</given-names></name><name><surname>Holmes</surname><given-names>A. J.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>Local-global parcellation of the human cerebral cortex from intrinsic functional connectivity MRI</article-title>. <source>Cereb. Cortex</source><volume>28</volume>, <fpage>3095</fpage>–<lpage>3114</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhx179</pub-id><?supplied-pmid 28981612?><pub-id pub-id-type="pmid">28981612</pub-id></mixed-citation>
    </ref>
    <ref id="B57">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>S. M.</given-names></name><name><surname>Jenkinson</surname><given-names>M.</given-names></name><name><surname>Woolrich</surname><given-names>M. W.</given-names></name><name><surname>Beckmann</surname><given-names>C. F.</given-names></name><name><surname>Behrens</surname><given-names>T. E.</given-names></name><name><surname>Johansen-Berg</surname><given-names>H.</given-names></name><etal/></person-group>. (<year>2004</year>). <article-title>Advances in functional and structural mr image analysis and implementation as fsl</article-title>. <source>Neuroimage</source><volume>23</volume>, <fpage>S208</fpage>–<lpage>S219</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.07.051</pub-id><?supplied-pmid 15501092?><pub-id pub-id-type="pmid">15501092</pub-id></mixed-citation>
    </ref>
    <ref id="B58">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>S. M.</given-names></name><name><surname>Nichols</surname><given-names>T. E.</given-names></name></person-group> (<year>2009</year>). <article-title>Threshold-free cluster enhancement: addressing problems of smoothing, threshold dependence and localisation in cluster inference</article-title>. <source>Neuroimage</source>
<volume>44</volume>, <fpage>83</fpage>–<lpage>98</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.03.061</pub-id><?supplied-pmid 18501637?><pub-id pub-id-type="pmid">18501637</pub-id></mixed-citation>
    </ref>
    <ref id="B59">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tapera</surname><given-names>T. M.</given-names></name><name><surname>Cieslak</surname><given-names>M.</given-names></name><name><surname>Bertolero</surname><given-names>M.</given-names></name><name><surname>Adebimpe</surname><given-names>A.</given-names></name><name><surname>Aguirre</surname><given-names>G. K.</given-names></name><name><surname>Butler</surname><given-names>E. R.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>Flywheeltools: data curation and manipulation on the flywheel platform</article-title>. <source>Front. Neuroinform</source>. <volume>15</volume>:<fpage>678403</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2021.678403</pub-id><?supplied-pmid 34239433?><pub-id pub-id-type="pmid">34239433</pub-id></mixed-citation>
    </ref>
    <ref id="B60">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>D. C.</given-names></name></person-group> (<year>2002</year>). <article-title>Windows on the brain: the emerging role of atlases and databases in neuroscience</article-title>. <source>Curr. Opin. Neurobiol</source>. <volume>12</volume>, <fpage>574</fpage>–<lpage>579</lpage>. <pub-id pub-id-type="doi">10.1016/S0959-4388(02)00361-6</pub-id><?supplied-pmid 12367638?><pub-id pub-id-type="pmid">12367638</pub-id></mixed-citation>
    </ref>
    <ref id="B61">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>D. C.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name><name><surname>Barch</surname><given-names>D. M.</given-names></name><name><surname>Behrens</surname><given-names>T. E.</given-names></name><name><surname>Yacoub</surname><given-names>E.</given-names></name><name><surname>Ugurbil</surname><given-names>K.</given-names></name><etal/></person-group>. (<year>2013</year>). <article-title>The wu-minn human connectome project: an overview</article-title>. <source>Neuroimage</source><volume>80</volume>, <fpage>62</fpage>–<lpage>79</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.041</pub-id><?supplied-pmid 23684880?><pub-id pub-id-type="pmid">23684880</pub-id></mixed-citation>
    </ref>
    <ref id="B62">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warrington</surname><given-names>S.</given-names></name><name><surname>Bryant</surname><given-names>K. L.</given-names></name><name><surname>Khrapitchev</surname><given-names>A. A.</given-names></name><name><surname>Sallet</surname><given-names>J.</given-names></name><name><surname>Charquero-Ballester</surname><given-names>M.</given-names></name><name><surname>Douaud</surname><given-names>G.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Xtract - standardised protocols for automated tractography in the human and macaque brain</article-title>. <source>NeuroImage</source><volume>217</volume>:<fpage>116923</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116923</pub-id><?supplied-pmid 32407993?><pub-id pub-id-type="pmid">32407993</pub-id></mixed-citation>
    </ref>
    <ref id="B63">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winkler</surname><given-names>A. M.</given-names></name><name><surname>Ridgway</surname><given-names>G. R.</given-names></name><name><surname>Webster</surname><given-names>M. A.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name><name><surname>Nichols</surname><given-names>T. E.</given-names></name></person-group> (<year>2014</year>). <article-title>Permutation inference for the general linear model</article-title>. <source>Neuroimage</source>
<volume>92</volume>, <fpage>381</fpage>–<lpage>397</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.01.060</pub-id><?supplied-pmid 34687243?><pub-id pub-id-type="pmid">24530839</pub-id></mixed-citation>
    </ref>
    <ref id="B64">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winkler</surname><given-names>A. M.</given-names></name><name><surname>Webster</surname><given-names>M. A.</given-names></name><name><surname>Brooks</surname><given-names>J. C.</given-names></name><name><surname>Tracey</surname><given-names>I.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name><name><surname>Nichols</surname><given-names>T. E.</given-names></name></person-group> (<year>2016</year>). <article-title>Non-parametric combination and related permutation tests for neuroimaging</article-title>. <source>Hum. Brain Mapp</source>. <volume>37</volume>, <fpage>1486</fpage>–<lpage>1511</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.23115</pub-id><?supplied-pmid 26848101?><pub-id pub-id-type="pmid">26848101</pub-id></mixed-citation>
    </ref>
    <ref id="B65">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zerbi</surname><given-names>V.</given-names></name><name><surname>Grandjean</surname><given-names>J.</given-names></name><name><surname>Rudin</surname><given-names>M.</given-names></name><name><surname>Wenderoth</surname><given-names>N.</given-names></name></person-group> (<year>2015</year>). <article-title>Mapping the mouse brain with RS-fMRI: an optimized pipeline for functional network identification</article-title>. <source>Neuroimage</source>
<volume>123</volume>, <fpage>11</fpage>–<lpage>21</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.07.090</pub-id><?supplied-pmid 26296501?><pub-id pub-id-type="pmid">26296501</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
