<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Genomics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Genomics</journal-id>
    <journal-title-group>
      <journal-title>BMC Genomics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2164</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9281153</article-id>
    <article-id pub-id-type="publisher-id">8715</article-id>
    <article-id pub-id-type="doi">10.1186/s12864-022-08715-1</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>scDLC: a deep learning framework to classify large sample single-cell RNA-seq data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Zhou</surname>
          <given-names>Yan</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Peng</surname>
          <given-names>Minjiao</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yang</surname>
          <given-names>Bin</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tong</surname>
          <given-names>Tiejun</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Baoxue</given-names>
        </name>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Tang</surname>
          <given-names>Niansheng</given-names>
        </name>
        <address>
          <email>nstang@ynu.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.263488.3</institution-id><institution-id institution-id-type="ISNI">0000 0001 0472 9649</institution-id><institution>College of Mathematics and Statistics, Institute of Statistical Sciences, Shenzhen Key Laboratory of Advanced Machine Learning and Applications, </institution><institution>Shenzhen University, </institution></institution-wrap>Shenzhen, China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.221309.b</institution-id><institution-id institution-id-type="ISNI">0000 0004 1764 5980</institution-id><institution>Department of Mathematics, </institution><institution>Hong Kong Baptist University, </institution></institution-wrap>Kowloon Tong, Hong Kong </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.411923.c</institution-id><institution-id institution-id-type="ISNI">0000 0001 1521 4747</institution-id><institution>School of Statistics, </institution><institution>Capital University of Economics and Business, </institution></institution-wrap>Beijing, China </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.440773.3</institution-id><institution-id institution-id-type="ISNI">0000 0000 9342 2456</institution-id><institution>Yunnan Key Laboratory of Statistical Modeling and Data Analysis, </institution><institution>Yunnan University, </institution></institution-wrap>Kunming, China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>12</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>12</day>
      <month>7</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>504</elocation-id>
    <history>
      <date date-type="received">
        <day>3</day>
        <month>9</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>21</day>
        <month>6</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Using single-cell RNA sequencing (scRNA-seq) data to diagnose disease is an effective technique in medical research. Several statistical methods have been developed for the classification of RNA sequencing (RNA-seq) data, including, for example, Poisson linear discriminant analysis (PLDA), negative binomial linear discriminant analysis (NBLDA), and zero-inflated Poisson logistic discriminant analysis (ZIPLDA). Nevertheless, few existing methods perform well for large sample scRNA-seq data, in particular when the distribution assumption is also violated.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">We propose a deep learning classifier (scDLC) for large sample scRNA-seq data, based on the long short-term memory recurrent neural networks (LSTMs). Our new scDLC does not require a prior knowledge on the data distribution, but instead, it takes into account the dependency of the most outstanding feature genes in the LSTMs model. LSTMs is a special recurrent neural network, which can learn long-term dependencies of a sequence.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">Simulation studies show that our new scDLC performs consistently better than the existing methods in a wide range of settings with large sample sizes. Four real scRNA-seq datasets are also analyzed, and they coincide with the simulation results that our new scDLC always performs the best. The code named “scDLC” is publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/scDLC-code/code">https://github.com/scDLC-code/code</ext-link>.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at (10.1186/s12864-022-08715-1).</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Single-cell RNA sequencing</kwd>
      <kwd>Deep learning</kwd>
      <kwd>Classifier</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>12071305, 11871390 , 11871411 and 1207010822</award-id>
        <award-id>11731011</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Natural Science Foundation of Guangdong Province of China</institution>
        </funding-source>
        <award-id>2020B1515310008</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Project of Educational Commission of Guangdong Province of China</institution>
        </funding-source>
        <award-id>2019KZDZX1007</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>the General Research Fund</institution>
        </funding-source>
        <award-id>HKBU12303918</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Initiation Grant for Faculty Niche Research Areas of Hong Kong Baptist University</institution>
        </funding-source>
        <award-id>RC-FNRA-IG/20-21/SCI/03</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p>The development of RNA sequencing (RNA-seq) has enabled unprecedented insight into the dynamics of gene expression [<xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR7">7</xref>]. In contrast to microarray data, next-generation sequencing data improve the specificity and sensitivity of gene expression and have been increasingly popular in biological and medical research, such as detecting differentially expressed genes and identifying which type of diseases a new patient belongs to with gene expression. In recent years, a single-cell RNA-sequencing (scRNA-seq), allowing sequencing to be conducted on the level of single cells, has become another standard tool in biological and medical studies [<xref ref-type="bibr" rid="CR8">8</xref>–<xref ref-type="bibr" rid="CR12">12</xref>]. The scRNA-seq data analysis not only discovers new cell types, but also reveals the deep regulatory networks [<xref ref-type="bibr" rid="CR13">13</xref>–<xref ref-type="bibr" rid="CR16">16</xref>]. Among them, cell type identification is an important task in scRNA-seq data analysis [<xref ref-type="bibr" rid="CR17">17</xref>]. In a general way, we identify cell types with unsupervised clustering within scRNA-seq data and then do the manual annotation based on a set of known marker genes [<xref ref-type="bibr" rid="CR18">18</xref>]. In practice, we rarely know the number of clusters in advance, and the annotation of clusters is also somewhat subjective [<xref ref-type="bibr" rid="CR19">19</xref>]. This may lead to bias in the analysis of the better characterised cell types. In contrast, supervised learning methods can identify the cell types more accurately and also reduce the bias associated with marker gene selection in cell type annotation.</p>
    <p>For the classification of RNA-seq data, several statistical methods have been developed [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR21">21</xref>], in particular for the bulk RNA-seq experiments. Poisson and negative binomial distributions are two most commonly used distributions to model the discrete RNA-seq data. Witten [<xref ref-type="bibr" rid="CR22">22</xref>] assumed that the RNA-seq data follow a Poisson distribution and proposed the Poisson linear discriminant analysis (PLDA). Dong et al. [<xref ref-type="bibr" rid="CR23">23</xref>] took into account the overdispersion of the RNA-seq data and proposed the negative binomial linear discriminant analysis (NBLDA). Note also that RNA-seq data may have excess zeros, especially when the sequence depth is not enough. Zhou et al. [<xref ref-type="bibr" rid="CR24">24</xref>] further proposed the zero-inflated Poisson logistic discriminant analysis (ZIPLDA) with a point mass at zero when classifying RNA-seq data.</p>
    <p>Nowadays, scRNA-seq data have been increasingly used to identify cell types and disease states for new patients. Yet to the best of our knowledge, there are still relatively few methods in the literature to classify scRNA-seq data despite the enormous potential of scRNA-seq data. Generally, low sequencing depths cause high noise levels and a large fraction of so-called “dropout” events in scRNA-seq data; and moreover, classification methods for bulk RNA-seq data may cause unacceptably large misclassification rates for scRNA-seq data. Especially for scRNA-seq data with relative large sample sizes, they may follow a more complex mixed distribution. Most existing classification methods for RNA-seq data require a certain distribution assumption, and they may fail in improving the classification accuracy for scRNA-seq data with large sample sizes. Alquicira-Hernandez et al. [<xref ref-type="bibr" rid="CR25">25</xref>] developed a novel classification method based on singular value decomposition and a support vector machine model for scRNA-seq data. Zhao et al. [<xref ref-type="bibr" rid="CR26">26</xref>] reviewed the existed classification tools for scRNA-seq data. Lin et al. [<xref ref-type="bibr" rid="CR27">27</xref>] proposed a scClassify method by using a distance weighted kNN classifier. More recently, Wang and Li [<xref ref-type="bibr" rid="CR28">28</xref>] proposed a scale-invariant deep-neural-network classifier (SINC) method which is based on deep neural-network (DNN) to classify scRNA-seq data. Their method provides a new way to dig more information for large sample size and also a novel thinking of scale invariant for next generation sequencing data. From another perspective, however, we note that the SINC method does not consider the dependency between the feature genes so that the settings may not be very realistic.</p>
    <p>In this paper, we consider a deep learning classifier (scDLC) to identify cell types for large sample scRNA-seq data, which is based on the two-layer long short-term memory recurrent neural networks (LSTMs). The deep learning classifier can learn scRNA-seq data without the need of a distribution assumption. What’s more, the scDLC method considers the dependency between the feature genes in the process of classification. LSTMs [<xref ref-type="bibr" rid="CR29">29</xref>] is a special kind of recurrent neural network which can learn long-term dependencies of a sequence. For scRNA-seq data, scDLC can automatically learn each sample of the class as a gene sequence.</p>
    <p>Our scDLC framework for identifying cell types in scRNA-seq data can be summarized as four steps. For the first fully connected layer, the gene sequences of a sample are mapped to a larger dimension. The first step aims to enlarge the information of gene sequence and make the class difference more obvious. Second, the output of the first fully connected layer is taken as the input of the two-layer long short-term memory network layer, and the weights of all gates are estimated by network calculation in each class. Third, we reduce the output dimensions to the number of classes in the second fully connected layer. Lastly, the outputs of the second fully connected layer are transformed to a probability distribution with a softmax function. In the process of training, we compare the probability of each class to the observation and estimate the optimization parameters under the cross-entropy loss function.</p>
    <p>To summarize the main advantages of the scDLC framework for classifying scRNA-seq data with large sample sizes, we note that scDLC is applicable to all scRNA-seq data no matter what the underlying distribution is. Moreover, scDLC has the capacity to capture the difference information of gene sequence from different classes, which is another key reason why it can perform the best compared to the existing competitors. In <xref rid="Sec8" ref-type="sec">Methods</xref>, we propose the framework of scDLC and further describe the estimation of parameters in details. In Simulation studies, we conduct simulation studies to evaluate the performance of the new classifier and compare it with existing methods. In Application to Real Data, we apply the proposed method to analyze four real scRNA-seq datasets to demonstrate its usefulness in practice. We then conclude the paper in Discussion with some discussion and future directions.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <p>We propose a deep learning framework (scDLC) based on the LSTMs model to classify scRNA-seq data. The details of the scDLC model have been shown in <xref rid="Sec8" ref-type="sec">Methods</xref>. To validate the performance of proposed method, we consider simulation studies and real data analysis. All the R scripts that analysed the data have been uploaded at github, which could be accessible at <ext-link ext-link-type="uri" xlink:href="https://github.com/scDLC-code/scDLC">https://github.com/scDLC-code/scDLC</ext-link>.</p>
    <sec id="Sec3">
      <title>Simulation studies</title>
      <p>In this section, we evaluate the performance of the proposed scDLC method via simulation studies. To generate scRNA-seq read count data, we apply the Splatter Bioconductor package [<xref ref-type="bibr" rid="CR30">30</xref>] that is known to be simple, reproducible and well-documented. While for comparison, we also consider seven other methods including PLDA, NBLDA, ZIPLDA, the support vector machines (SVM), scPred, scClassify and the SINC method.</p>
      <sec id="Sec4">
        <title>Simulation design</title>
        <p>In each experiment, we generate <italic>n</italic> samples for the training set and another <italic>n</italic> samples for the test set. We first consider the binary classification with <italic>K</italic>=2. Study 1 investigates the effect of different sample sizes for the binary classification. We fix the proportions of differentially expressed genes <italic>D</italic><italic>E</italic>=0.5, the probability of excess zeros <italic>p</italic><italic>z</italic><italic>e</italic><italic>r</italic><italic>o</italic>=0.2, and consider the gene number <italic>g</italic>=100, 200, 300 and 400. We then compute the misclassification rates of all methods with different sample sizes ranging from 100 to 900. In Study 2, we evaluate the performance of all methods when the proportions of differentially expressed genes are 0.2, 0.3, 0.4, 0.5, 0.6 and 0.7 with fixed sample size <italic>n</italic>=200, 300, 400 and 500. In addition, we set the probability of excess zeros <italic>p</italic><italic>z</italic><italic>e</italic><italic>r</italic><italic>o</italic>=0.2 and the gene number <italic>g</italic>=100. In Study 3, we test the performance of all methods with the different probability of excess zeros, including <italic>p</italic><italic>z</italic><italic>e</italic><italic>r</italic><italic>o</italic>= 0.1, 0.2, 0.3, 0.4, 0.5 and 0.6. For other settings, we let the gene number <italic>g</italic>=100, the sample size <italic>n</italic>=200, 300, 400 and 500, and 40% of genes be differentially expressed.</p>
        <p>For the multiple classification with <italic>K</italic>=3, we also conduct three studies to evaluate the performance of the different methods. In Study 4, we evaluate the effect of different sample sizes with three classes. All other parameters are kept the same as those in the binary classification except for the sample sizes. We set <italic>n</italic>= 300, 400, 500 and 600 for three classes in Studies 5 and 6, respectively.</p>
      </sec>
      <sec id="Sec5">
        <title>Simulation results</title>
        <p>With 1000 simulations for each experiment, we report the average misclassification rates for the binary classification in Figs. <xref rid="Fig1" ref-type="fig">1</xref>-<xref rid="Fig2" ref-type="fig">2</xref> and <xref rid="MOESM1" ref-type="media">Supplementary Fig. S1</xref>, respectively. The results for the multiple classification are presented in <xref rid="MOESM1" ref-type="media">Supplementary Figs. S2-S4</xref>. Figure <xref rid="Fig1" ref-type="fig">1</xref> shows that the misclassification rates of all the considered methods decrease as the sample size increases. It is also evident that scDLC performs much better than the other methods in all cases. Figure <xref rid="Fig2" ref-type="fig">2</xref> shows that the misclassification rates of all methods are decreased with an increasing number of differentially expressed genes, and meanwhile scDLC shows its superiority over the other methods. From <xref rid="MOESM1" ref-type="media">Supplementary</xref><xref rid="MOESM1" ref-type="media">Fig. S1</xref>, we note that an increasing probability of excess zeros will yield a higher misclassification rate and the proposed method again outperforms the other methods in all settings.
<fig id="Fig1"><label>Fig. 1</label><caption><p>The misclassification rates of all methods with different sample sizes for two classes (Study 1). Here, <italic>D</italic><italic>E</italic>=0.5 and <italic>p</italic><italic>z</italic><italic>e</italic><italic>r</italic><italic>o</italic>=0.2 for all plots. The four plots are with the gene number <italic>g</italic> = 100, 200, 300 or 400, respectively</p></caption><graphic xlink:href="12864_2022_8715_Fig1_HTML" id="MO1"/></fig><fig id="Fig2"><label>Fig. 2</label><caption><p>The misclassification rates of all methods with different DE rates for two classes (Study 2). Here, <italic>g</italic>=100 and <italic>p</italic><italic>z</italic><italic>e</italic><italic>r</italic><italic>o</italic>=0.2 for all plots. The four plots are with the sample size <italic>n</italic> = 200, 300, 400 or 500, respectively</p></caption><graphic xlink:href="12864_2022_8715_Fig2_HTML" id="MO2"/></fig></p>
        <p><xref rid="MOESM1" ref-type="media">Supplementary Figs. S2</xref> to <xref rid="MOESM1" ref-type="media">S4</xref> display the simulation results for the multiple classification with <italic>K</italic>=3. They coincide with the conclusions made for the binary comparison, and in particular, scDLC always performs the best. Moreover, we note that SINC does not perform well when the number of selected feature genes is small, and so it can only be recommended for large number of selected feature genes.</p>
      </sec>
    </sec>
    <sec id="Sec6">
      <title>Application to real data</title>
      <p>To further evaluate the performance of the different classifiers, we also analyze six scRNA-seq datasets which are from National Center for Biotechnology Information Search database (NCBI, <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/">https://www.ncbi.nlm.nih.gov/</ext-link>). The six datasets are summarized in Table <xref rid="Tab1" ref-type="table">1</xref>. The first dataset GSE99933 was released in Furlan et al. [<xref ref-type="bibr" rid="CR31">31</xref>]. It is used to demonstrate that large numbers of chromaffin cells arise from peripheral glial stem cells. This dataset has two classes, including 384 samples recombining at E12.5 and 384 samples recombining at E13.5. The second dataset GSE123454 illustrates the high information content of nuclear RNA for characterization of cellular diversity in brain tissues [<xref ref-type="bibr" rid="CR32">32</xref>]. This dataset includes 463 samples from single nuclei and 463 samples from matched single cells with measurements on 42003 genes. The third dataset GSE113069 is a testament to the diversity of subiculum pyramidal cells from the hippocampus [<xref ref-type="bibr" rid="CR33">33</xref>]. It contains three classes, each with 345, 422, 423 samples, respectively. The fourth dataset GSE84133 Baron1 was created by Baron et al. [<xref ref-type="bibr" rid="CR34">34</xref>], and was further analyzed by the deep-neural-network classifier SINC [<xref ref-type="bibr" rid="CR28">28</xref>]. Baron1 contains all major cell groups from the first human donor, excluding those with less than 20 cells. It contains nine classes, each with 110, 51, 236, 872, 214, 120, 130, 70 and 92 samples, respectively. The last two datasets are large sample datasets which contain tens of thousands of cells. Specifically, the fifth dataset GSE107585 was used to reveal potential cellular targets of kidney disease [<xref ref-type="bibr" rid="CR35">35</xref>]. It came from healthy mouse kidneys, containing total 43745 cells for all fifteen classes, each with 26482, 8544, 1729, 1581, 1308, 1001, 870, 643, 549, 313, 235, 228, 110, 78 and 74 samples, respectively. The sixth dataset PBMC can be downloaded from the Single Cell Portal with accession numbers SCP424 in <ext-link ext-link-type="uri" xlink:href="https://singlecell.broadinstitute.org/single_cell/study/SCP424/single-cell-comparison-pbmc-data">https://singlecell.broadinstitute.org/single_cell/study/SCP424/single-cell-comparison-pbmc-data</ext-link> [<xref ref-type="bibr" rid="CR36">36</xref>]. The dataset was from human organism that contains 31021 cells for all thirteen classes, each with 7805, 6437, 4391, 3529, 2881, 2197, 1466, 908, 620, 372, 203, 149, 52, and 11 samples, respectively.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Details of the four scRNA-seq datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Datasets</th><th align="left">Sample size</th><th align="left">No. of classes</th><th align="left">No. of genes</th></tr></thead><tbody><tr><td align="left">GSE99933</td><td align="left">768</td><td align="left">2</td><td align="left">23420</td></tr><tr><td align="left">GSE123454</td><td align="left">926</td><td align="left">2</td><td align="left">42003</td></tr><tr><td align="left">GSE113069</td><td align="left">1190</td><td align="left">3</td><td align="left">23218</td></tr><tr><td align="left">GSE84133(Baron1)</td><td align="left">1895</td><td align="left">9</td><td align="left">20126</td></tr><tr><td align="left">GSE107585</td><td align="left">43745</td><td align="left">15</td><td align="left">16272</td></tr><tr><td align="left">PBMC</td><td align="left">31021</td><td align="left">13</td><td align="left">29669</td></tr></tbody></table></table-wrap></p>
      <p>We assess the performance of our proposed scDLC method with seven baseline methods, including three traditional classifiers based on the Bayesian, scPred, scClassify, SVM and SINC methods. We apply the AUC score, which is the area surrounded by the coordinate axis under the ROC curve [<xref ref-type="bibr" rid="CR37">37</xref>], to measure the performance of the classifiers. We randomly draw 40 to 450 of the samples to build the training set, and regard the rest as the test set. In real data, the majority of genes are not differentially expressed and they are irrelevant for class distinction. For example, we observe in Fig. <xref rid="Fig2" ref-type="fig">2</xref> that the large rate of feature genes for class distinction will improve the accuracy of the classifiers. Thus to improve the rate of feature genes, we follow Zhou et al. [<xref ref-type="bibr" rid="CR24">24</xref>] to select the top <italic>p</italic> feature genes from the training set using the BW method. Specifically for the <italic>j</italic>th gene, the BW value is defined as the ratio of the sum of squares between groups (BSS) to that within groups (WSS) as follows: 
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$  \text{BW}(j) =\frac{\sum^{K}_{k=1}\sum^{n_{k}}_{i=1}({\bar{\boldsymbol{x}}}_{k.j}-{\bar{\boldsymbol{x}}}_{..j})^{2}}{\sum^{K}_{k=1}\sum^{n_{k}}_{i=1}({\boldsymbol{x}}_{kij}-{\bar{\boldsymbol{x}}}_{..j})^{2}},  $$ \end{document}</tex-math><mml:math id="M2"><mml:mtext>BW</mml:mtext><mml:mo>(</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k.j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>..j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">kij</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>..j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12864_2022_8715_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <inline-formula id="IEq1"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}${\bar {\boldsymbol {x}}}_{..j}$\end{document}</tex-math><mml:math id="M4"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>..j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12864_2022_8715_Article_IEq1.gif"/></alternatives></inline-formula><inline-formula id="IEq2"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$={1\over K}\sum _{k=1}^{K} {1\over n_{k}}\sum _{i=1}^{n_{k}} x_{kij}$\end{document}</tex-math><mml:math id="M6"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">kij</mml:mtext></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12864_2022_8715_Article_IEq2.gif"/></alternatives></inline-formula> is the averaged expression values across all samples, <inline-formula id="IEq3"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}${\bar {\boldsymbol {x}}}_{k.j}$\end{document}</tex-math><mml:math id="M8"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k.j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12864_2022_8715_Article_IEq3.gif"/></alternatives></inline-formula><inline-formula id="IEq4"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$={1\over n_{k}}\sum _{i=1}^{n_{k}} x_{kij}$\end{document}</tex-math><mml:math id="M10"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">kij</mml:mtext></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12864_2022_8715_Article_IEq4.gif"/></alternatives></inline-formula> is the averaged expression value across samples belonging to class <italic>k</italic>, and <italic>K</italic> is the number of classes. Moreover, without loss of generality, we retain the top <italic>p</italic>=100 feature genes from each simulation as the inputs of the first layer of scDLC. We further repeat all the experiments 100 times and calculate the average AUC scores. We also present their respective boxplots in Fig. <xref rid="Fig3" ref-type="fig">3</xref> with the AUC scores. From the boxplots, it is evident that our proposed scDLC outperforms the baseline methods for all four datasets.
<fig id="Fig3"><label>Fig. 3</label><caption><p>The classification experiment is repeated 100 times for four real datasets, and the AUC score results obtained are plotted as the boxplot</p></caption><graphic xlink:href="12864_2022_8715_Fig3_HTML" id="MO3"/></fig></p>
      <p>Next, we compare the performance of all classifiers with different sizes of training samples. Figure <xref rid="Fig4" ref-type="fig">4</xref> shows the AUC scores of the eight methods with different sizes of training samples for the first four real datasets with small sample size. The number of feature genes is fixed at 100 and the training sample size varies from 40 to 450. From Fig. <xref rid="Fig4" ref-type="fig">4</xref>, although the AUC scores of the proposed method are not outstanding when the training sample size is smaller than 50, it is still the best classifier on the whole. In particular, when the training sample size is larger than 100, our scDLC is consistently better than all other methods. As shown in Figs. <xref rid="Fig3" ref-type="fig">3</xref> and <xref rid="Fig4" ref-type="fig">4</xref>, ScPred is comparable to scDLC for GSE99933 and GSE123454 datasets and they are both better than the other methods, which contain only two cell types. Figure <xref rid="Fig5" ref-type="fig">5</xref> shows the AUC scores of the eight methods with different sizes of training samples for the last two real datasets with large sample. The number of feature genes is fixed at 100 and the training sample size varies from 1200 to 12000. From Fig. <xref rid="Fig5" ref-type="fig">5</xref>, the proposed method outperforms the exiting methods for large training sample in the two real datasets. The AUC scores of SVM are less than those of our scDLC but much higher than the other methods.
<fig id="Fig4"><label>Fig. 4</label><caption><p>The AUC scores of all classifiers with different training sample sizes for the first four real datasets with small sample size</p></caption><graphic xlink:href="12864_2022_8715_Fig4_HTML" id="MO4"/></fig><fig id="Fig5"><label>Fig. 5</label><caption><p>The AUC scores of all classifiers with different training sample sizes for the last two real datasets with large sample</p></caption><graphic xlink:href="12864_2022_8715_Fig5_HTML" id="MO5"/></fig></p>
      <p>Finally, we consider the performance of each classifier under different selected feature genes. Specifically, we use 70% of the dataset as the training set and the rest as the test set. According to the degree of differential expression, the top 20 to 100 genes are selected to test the performance of each classification method. Figure <xref rid="Fig6" ref-type="fig">6</xref> and <xref rid="MOESM1" ref-type="media">Supplementary Figs. S5-S7</xref> show the AUC scores of the eight methods with different selected feature genes. For the GSE123454 and GSE99933 datasets in Fig. <xref rid="Fig6" ref-type="fig">6</xref> and <xref rid="MOESM1" ref-type="media">Supplementary Fig. S5</xref>, the scPred method is comparable to the scDLC method and much better than the other methods. However, NBLDA is comparable to the scDLC method in <xref rid="MOESM1" ref-type="media">Supplementary Fig. S7</xref>. In <xref rid="MOESM1" ref-type="media">Supplementary Figs.</xref><xref rid="MOESM1" ref-type="media">S6</xref> and <xref rid="MOESM1" ref-type="media">S7</xref>, we observe a similar result that the scDLC method outperforms the other methods in the GSE84133 and GSE113069 datasets. The four Figures show that the comparison results of the classifiers are relatively consistent under different choices of the selected genes and the proportion. Finally, it is noteworthy that the AUC scores of scDLC are not affected much by the number of feature genes.
<fig id="Fig6"><label>Fig. 6</label><caption><p>The AUC scores of all classifiers with different feature gene number for GSE123454 dataset</p></caption><graphic xlink:href="12864_2022_8715_Fig6_HTML" id="MO6"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec7" sec-type="discussion">
    <title>Discussion</title>
    <p>The single-cell RNA sequencing (scRNA-seq) technology has been increasingly used in molecular diagnosis of clinical diseases. In this paper, we proposed a deep learning framework with two layers of LSTMs, namely scDLC, to classify large sample scRNA-seq data. The innovation of scDLC is mainly manifested in two aspects. Firstly, compared to the existing discriminant rules, our new method does not require a distribution assumption so that it can be widely applied in practice. Secondly, our scDLC also amplifies the features of the selected genes through the first fully connected layer. It is thus beneficial to improve the classification accuracy and stability of the model, and meanwhile our scDLC can be trained with less computer resource using only the top selected feature genes.</p>
    <p>To evaluate the performance of our new classifier, we considered both the binary classification and the multiple classification. Simulation results show that our deep learning method can sufficiently capture the difference information of classes in gene sequences, and that it performs much better than, or at least as well as, the existing competitors in a wide range of settings with large sample sizes. We also analyzed six real scRNA-seq datasets, including both small and large sample sizes, and they all support that our new scDLC always performs the best.</p>
    <p>As a future work, we will study from the network structure level why scDLC can efficiently capture class differences from gene sequences, and we expect that understanding the mechanism can bring deep insights to gene expression and regulation. Moreover, it can also be interesting to extend deep learning techniques to conduct in-depth research in precision medicine such as neonatal genetic disease-related gene screening.</p>
  </sec>
  <sec id="Sec8">
    <title>Methods</title>
    <p>We first review the framework of long short-term memory recurrent neural networks (LSTMs), and then introduce a new workflow of the deep learning classifier (scDLC) for large sample size scRNA-seq data.</p>
    <p>Hochreiter and Schmidhuber [<xref ref-type="bibr" rid="CR29">29</xref>] proposed a recurrent neural network with long short-term memory network. This network has a great performance to solve the sequential data related learning problem. LSTMs can effectively capture both short-term and long-term time dependence. Sak et al. [<xref ref-type="bibr" rid="CR38">38</xref>] showed that the long short-term memory network is effective for acoustic modeling. Marchi et al. [<xref ref-type="bibr" rid="CR39">39</xref>] proposed a bidirectional LSTMs for audio onset detection. Due to the gate mechanism, LSTMs solves the problem of gradient vanishing which cannot be overcomed by the simple recurrent neural network. The early LSTMs was refined and popularized by many people in the following work. The structure of this model was further improved by Graves et al. [<xref ref-type="bibr" rid="CR40">40</xref>] based on the previous research [<xref ref-type="bibr" rid="CR41">41</xref>, <xref ref-type="bibr" rid="CR42">42</xref>]. The core idea of the LSTMs is several non-linear gating units that control information retention and forgetting, as well as a memory cell that can maintain its state over time. As shown in Fig. <xref rid="Fig7" ref-type="fig">7</xref>, it includes a single cell, two tanh activation blocks and three gates (input gate, forget gate, output gate). The input gate controls the input information and whether the input will be read. The forget gate controls the internal state information and whether the current cell value is forgotten. The output gate controls the output information and whether new cell values are output. The input of the three gates is the output of the previous time and the input of the current time. The activation function of three gates is the sigmoid function. Let <italic>x</italic><sub><italic>t</italic></sub>,<italic>h</italic><sub><italic>t</italic></sub> and <italic>C</italic><sub><italic>t</italic></sub> denote the input value, the output value and the cell state at time <italic>t</italic>, respectively. Let <italic>b</italic> denote the bias term, and <italic>W</italic> denote the weight matrix. Let also <italic>f</italic>, <italic>i</italic> and <italic>o</italic> denote the forget gate, the input gate and the output gate, respectively. The recurrent process of LSTMs can be expressed as follows: 
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \begin{aligned} f_{t}&amp;=\sigma(W_{f}\cdot[h_{t-1},x_{t}]+b_{f})\\ i_{t}&amp;=\sigma(W_{i}\cdot[h_{t-1},x_{t}]+b_{i})\\ \tilde{C}_{t}&amp;=tanh(W_{C}\cdot[h_{t-1},x_{t}]+b_{C})\\ C_{t}&amp;=f_{t}*C_{t-1}+i_{t}*\tilde{C}_{t}\\ o_{t}&amp;=\sigma(W_{o}\cdot[h_{t-1},x_{t}]+b_{o})\\ h_{t}&amp;=o_{t}*tanh(C_{t}), \end{aligned}  $$ \end{document}</tex-math><mml:math id="M12"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">tanh</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∗</mml:mo><mml:mtext mathvariant="italic">tanh</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12864_2022_8715_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula><fig id="Fig7"><label>Fig. 7</label><caption><p>The framework of LSTMs. It consists of three gates (input gate, forget gate and output gate) and two tanh modules. The data of the current time and the cell state of the previous time are combined and input into the LSTMs. After a series of nonlinear transformations, the current cell state and output are obtained</p></caption><graphic xlink:href="12864_2022_8715_Fig7_HTML" id="MO7"/></fig></p>
    <p>where <inline-formula id="IEq5"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\tilde {C}_{t}$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12864_2022_8715_Article_IEq5.gif"/></alternatives></inline-formula> is a vector of new candidate values, <inline-formula id="IEq6"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\sigma (z)=\frac {1}{1+e^{-z}}$\end{document}</tex-math><mml:math id="M16"><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12864_2022_8715_Article_IEq6.gif"/></alternatives></inline-formula> is the sigmoid function, and <inline-formula id="IEq7"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$tanh(z)=\frac {e^{z}-e^{-z}}{e^{z}+e^{-z}}$\end{document}</tex-math><mml:math id="M18"><mml:mtext mathvariant="italic">tanh</mml:mtext><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12864_2022_8715_Article_IEq7.gif"/></alternatives></inline-formula> is the tanh function. In addition, “.” represents the matrix multiplication and “*” represents the multiplication with scalars.</p>
    <sec id="Sec9">
      <title>Deep learning classifier for scRNA-seq data</title>
      <p>The scDLC framework is shown in Fig. <xref rid="Fig8" ref-type="fig">8</xref>, which includes two fully connected layers and a two-layer LSTMs. The fully connected layers are located at the first layer and the last layer, respectively. After the model training, it results in a scRNA-seq data classifier. Inputting a gene sequence sample into scDLC, the probability that the gene sequence sample belongs to each class will be obtained. Finally, we identify which class the sample belongs to based on the probability vector.
<fig id="Fig8"><label>Fig. 8</label><caption><p>The framework of scDLC with three layers. The first layer and the third layer are two fully connected layers, and the middle layer is an LSTMs layer that consists of two long short-term memory network sub layers. A softmax layer is connected at the end to map the output of the classifier to a probability distribution</p></caption><graphic xlink:href="12864_2022_8715_Fig8_HTML" id="MO8"/></fig></p>
      <p><bold>Fully connected layers</bold>: Each node of the fully connected layer is connected to all nodes of the previous layer. It can synthesize the extracted features through the rectified linear unit (<italic>ReLU</italic>) activation function. The function of the first fully connected layer in scDLC is to amplify the information of the gene sequence and make the class difference more obvious. This layer can greatly improve the accuracy of discrimination. The <italic>ReLU</italic> activation function is 
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ a=max(0,Wx+b),  $$ \end{document}</tex-math><mml:math id="M20"><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">max</mml:mtext><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext mathvariant="italic">Wx</mml:mtext><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12864_2022_8715_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <italic>x</italic> is the input vector, <italic>W</italic> is the weight matrix, <italic>b</italic> is the bias vector, and <italic>a</italic> is the activation vector which is the output of the fully connected layer. Using the <italic>ReLU</italic> activation function in the network can make the classifier perform better. At the end of the model, we map the output of the second fully connected layer to the probability distribution of the class through a <italic>softmax</italic> function as 
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ softmax(y_{c})=\frac{e^{y_{c}}}{\sum^{M}_{j=1}e^{y_{j}}},  $$ \end{document}</tex-math><mml:math id="M22"><mml:mtext mathvariant="italic">softmax</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12864_2022_8715_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <italic>M</italic> is the number of classes.</p>
      <p><bold>LSTMs layer</bold>: In the LSTMs layer, we take two LSTMs sublayers to learn data. The horizontal connection between sublayers means that the output <italic>h</italic> of the first sublayer is entered into the second sublayer as input. The vertical connection means that the cell state <italic>C</italic> of the previous time is transferred to the next time in the same sublayer. The output of this layer will be used as the input to the second fully connected layer. The forward recursions of this layer refer to the formulas in (Fig. <xref rid="Fig7" ref-type="fig">7</xref>).</p>
      <p>The trainable parameters (all weights and biases) in this deep model are denoted as <italic>θ</italic>. The partial derivatives <italic>∂</italic><italic>L</italic>/<italic>∂</italic><italic>θ</italic> of the loss function <italic>L</italic> with respect to any trainable parameter in the network can be calculated by the back propagation algorithm [<xref ref-type="bibr" rid="CR43">43</xref>]. We further take the cross entropy as the loss function since it can well describe the difference between the true probability distribution and the predicted probability distribution. To be specific, we define the loss function as 
<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ L=-\frac{1}{N}\sum^{N}_{i=1}\sum^{M}_{c=1}y_{ic}log(p_{ic}),  $$ \end{document}</tex-math><mml:math id="M24"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ic</mml:mtext></mml:mrow></mml:msub><mml:mtext mathvariant="italic">log</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">ic</mml:mtext></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12864_2022_8715_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <italic>N</italic> is the sample size, <italic>M</italic> is the number of classes, <italic>y</italic><sub><italic>ic</italic></sub> is an indication variable which is 1 if class <italic>c</italic> is the same as the class of the sample or otherwise 0, and <italic>p</italic><sub><italic>ic</italic></sub> represents the prediction probability that sample <italic>i</italic> belongs to class <italic>c</italic>.</p>
      <p>The gradient descent method is a widely used optimization algorithm in machine learning. We use a mini-batch gradient descent algorithm (MBGD) [<xref ref-type="bibr" rid="CR44">44</xref>] to train our model. For a set of training samples, MBGD does not use all the training samples to calculate the real gradient of the target, but instead calculates the gradient of a small batch samples. We then minimize the loss function by updating the trainable parameter <italic>θ</italic>. According to the MBGD algorithm, the rule for updating is as follows: 
<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \theta\gets\theta-\eta\frac{\partial L}{\partial \theta},  $$ \end{document}</tex-math><mml:math id="M26"><mml:mi>θ</mml:mi><mml:mo>←</mml:mo><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:mfrac><mml:mrow><mml:mi>∂L</mml:mi></mml:mrow><mml:mrow><mml:mi>∂θ</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12864_2022_8715_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <italic>η</italic> is the learning rate. In order to avoid fluctuation in the later stage of training, we further set the learning rate decay exponentially during the training. That is 
<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \tilde{\eta}=\eta e^{\gamma/s},  $$ \end{document}</tex-math><mml:math id="M28"><mml:mover accent="true"><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>/</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12864_2022_8715_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <inline-formula id="IEq8"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\tilde {\eta }$\end{document}</tex-math><mml:math id="M30"><mml:mover accent="true"><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mo>~</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12864_2022_8715_Article_IEq8.gif"/></alternatives></inline-formula> is the learning rate after decay, <italic>γ</italic> is the decay rate, and <italic>s</italic> is the global step. The exponential-decay learning rate means that the learning rate is correlated with the number of training times, and it will decline exponentially with the increase of training times. Here, <italic>r</italic> is the decay rate, <italic>s</italic> is the global step, the maximum learning rate is set to <italic>m</italic><italic>a</italic><italic>x</italic>_<italic>l</italic><italic>r</italic>=0.005, the minimum learning rate is set to <italic>m</italic><italic>i</italic><italic>n</italic>_<italic>l</italic><italic>r</italic>=0.001, epoch is the training times, <italic>x</italic> is the sample size in the total training set, <italic>b</italic><italic>a</italic><italic>t</italic><italic>c</italic><italic>h</italic>_<italic>s</italic><italic>i</italic><italic>z</italic><italic>e</italic> represents the sample size in a batch, then decay rate is computed with <italic>r</italic>=<italic>l</italic><italic>o</italic><italic>g</italic>(<italic>m</italic><italic>a</italic><italic>x</italic>_<italic>l</italic><italic>r</italic>/<italic>m</italic><italic>i</italic><italic>n</italic>_<italic>l</italic><italic>r</italic>)/(<italic>e</italic><italic>p</italic><italic>o</italic><italic>c</italic><italic>h</italic>∗<italic>x</italic>/<italic>b</italic><italic>a</italic><italic>t</italic><italic>c</italic><italic>h</italic>_<italic>s</italic><italic>i</italic><italic>z</italic><italic>e</italic>). Then the learning rate after decay can be obtained according to the calculated <italic>d</italic><italic>e</italic><italic>c</italic><italic>a</italic><italic>y</italic>_<italic>r</italic><italic>a</italic><italic>t</italic><italic>e</italic>.</p>
    </sec>
    <sec id="Sec10">
      <title>Hyperparameter settings</title>
      <p>To implement the proposed scDLC, it is further needed to determine the hyperparameters in the model. Note that the hyperparameters are the configuration outside the model, and their values cannot be estimated from the data. Appropriate hyperparameters can greatly improve the performance of the model. According to the test of different hyperparameter combinations, we set the following parameters that can yield a good performance for the classification.<bold>hidden size =64</bold>: The parameter represents the size of the hidden state of LSTMs and we set it as 64.<bold>batch size =11</bold>: For the number of samples in a batch, we randomly choose 11 samples throughout the simulations.<bold>grad clip =5</bold>: To stabilize the network in the process of training, we set the threshold as 5 for the gradient to control the weight update within a certain range. <bold>train keep prob =0.3</bold>: To prevent overfitting, we let the train keep probability equal to 0.3, which means that only 30% of the information will be used in the next time. <bold>initial learning rate =0.005</bold>: For the appropriate learning rate that can make the objective function converge to a local minimum at a suitable time, we set the initial learning rate as 0.005. Since the learning rate will decline with training, we further set the minimum learning rate as 0.001.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec11">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12864_2022_8715_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1</bold> Supplementary figures and tables. This file contains related figures and tables for simulated and real datasets.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>scDLC</term>
        <def>
          <p>Deep learning classifier for large sample scRNA-seq data</p>
        </def>
      </def-item>
      <def-item>
        <term>LSTMs</term>
        <def>
          <p>Long short-term memory recurrent neural networks</p>
        </def>
      </def-item>
      <def-item>
        <term>scRNA-seq</term>
        <def>
          <p>Single-cell RNA sequencing</p>
        </def>
      </def-item>
      <def-item>
        <term>FDR</term>
        <def>
          <p>False discovery rate</p>
        </def>
      </def-item>
      <def-item>
        <term>ROC</term>
        <def>
          <p>Receiver operating characteristic</p>
        </def>
      </def-item>
      <def-item>
        <term>AUC</term>
        <def>
          <p>Area under the curve</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>Yan Zhou and Minjiao Peng are shared first authorship.</p>
    </fn>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Our sincere thanks go to the editor and two reviewers for their valuable comments and helpful suggestions that have led to substantial improvements of the article.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>YZ and NT conceived the idea. BZ and BY processed the data and conducted simulation and real dataset experiments. YZ and TT wrote the manuscript. YZ, MP, BZ, TT and NT revised the manuscript. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Yan Zhou’s research was supported by the National Natural Science Foundation of China (Grant No. 12071305, 11871390 and 11871411), Natural Science Foundation of Guangdong Province of China under grant 2020B1515310008, Project of Educational Commission of Guangdong Province of China under grant 2019KZDZX1007. Niansheng Tang’s research was supported by the National Natural Science Foundation of China (Grant No. 11731011). Tiejun Tong’s research was supported by the General Research Fund (HKBU12303918), the National Natural Science Foundation of China (1207010822), and the Initiation Grant for Faculty Niche Research Areas (RC-FNRA-IG/20-21/SCI/03) of Hong Kong Baptist University.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The datasets are from National Center for Biotechnology Information Search database (NCBI, <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/">https://www.ncbi.nlm.nih.gov/</ext-link>). The first dataset GSE99933 was released in [<xref ref-type="bibr" rid="CR31">31</xref>]. The second dataset GSE123454 illustrates the high information content of nuclear RNA for characterization of cellular diversity in brain tissues [<xref ref-type="bibr" rid="CR32">32</xref>]. The third dataset GSE113069 is a testament to the diversity of subiculum pyramidal cells from the hippocampus [<xref ref-type="bibr" rid="CR33">33</xref>]. The fourth dataset GSE84133 Baron1 was created by [<xref ref-type="bibr" rid="CR34">34</xref>]. The fifth dataset GSE107585 was released in [<xref ref-type="bibr" rid="CR35">35</xref>]. The sixth dataset PBMC can be downloaded from the Single Cell Portal with accession numbers SCP424 [<xref ref-type="bibr" rid="CR36">36</xref>]. All the R scripts that analysed the data are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/scDLC-code/scDLC">https://github.com/scDLC-code/scDLC</ext-link>. Additional supporting Figures and Tables are included as Additional files.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p>Not applicable. Humans, animals or plants have not been directly used in this study.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p>Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p>The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mardis</surname>
            <given-names>ER</given-names>
          </name>
          <name>
            <surname>Next-Generation</surname>
            <given-names>DNA</given-names>
          </name>
        </person-group>
        <article-title>sequencing methods</article-title>
        <source>Annu Rev Genomics Hum Genet</source>
        <year>2008</year>
        <volume>9</volume>
        <issue>1</issue>
        <fpage>387</fpage>
        <lpage>402</lpage>
        <pub-id pub-id-type="doi">10.1146/annurev.genom.9.081307.164359</pub-id>
        <pub-id pub-id-type="pmid">18576944</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Gerstein</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Snyder</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>RNA-Seq: a revolutionary tool for transcriptomics</article-title>
        <source>Nat Rev Genet</source>
        <year>2009</year>
        <volume>10</volume>
        <issue>1</issue>
        <fpage>57</fpage>
        <lpage>63</lpage>
        <pub-id pub-id-type="doi">10.1038/nrg2484</pub-id>
        <pub-id pub-id-type="pmid">19015660</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Morozova</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Hirst</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Marra</surname>
            <given-names>MA</given-names>
          </name>
        </person-group>
        <article-title>Applications of new sequencing technologies for transcriptome analysis</article-title>
        <source>Annu Rev Genomics Hum Genet</source>
        <year>2009</year>
        <volume>10</volume>
        <issue>1</issue>
        <fpage>135</fpage>
        <lpage>51</lpage>
        <pub-id pub-id-type="doi">10.1146/annurev-genom-082908-145957</pub-id>
        <pub-id pub-id-type="pmid">19715439</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mortazavi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Williams</surname>
            <given-names>BA</given-names>
          </name>
          <name>
            <surname>McCue</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Schaeffer</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wold</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Mapping and quantifying mammalian transcriptomes by RNA-Seq</article-title>
        <source>Nat Methods</source>
        <year>2008</year>
        <volume>5</volume>
        <issue>7</issue>
        <fpage>621</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.1226</pub-id>
        <pub-id pub-id-type="pmid">18516045</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nagalakshmi</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Waern</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Shou</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Raha</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Gerstein</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The transcriptional landscape of the yeast genome defined by RNA sequencing</article-title>
        <source>Science</source>
        <year>2008</year>
        <volume>320</volume>
        <issue>5881</issue>
        <fpage>1344</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1126/science.1158441</pub-id>
        <pub-id pub-id-type="pmid">18451266</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wilhelm</surname>
            <given-names>BT</given-names>
          </name>
          <name>
            <surname>Landry</surname>
            <given-names>JR</given-names>
          </name>
        </person-group>
        <article-title>RNA-Seq-quantitative measurement of expression through massively parallel RNA-sequencing</article-title>
        <source>Methods</source>
        <year>2009</year>
        <volume>48</volume>
        <issue>3</issue>
        <fpage>249</fpage>
        <lpage>57</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ymeth.2009.03.016</pub-id>
        <pub-id pub-id-type="pmid">19336255</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ozsolak</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Milos</surname>
            <given-names>PM</given-names>
          </name>
        </person-group>
        <article-title>RNA sequencing: advances, challenges and opportunities</article-title>
        <source>Nat Rev Genet</source>
        <year>2011</year>
        <volume>12</volume>
        <issue>2</issue>
        <fpage>87</fpage>
        <lpage>98</lpage>
        <pub-id pub-id-type="doi">10.1038/nrg2934</pub-id>
        <pub-id pub-id-type="pmid">21191423</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Barbacioru</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Nordman</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>mRNA-Seq whole-transcriptome analysis of a single cell</article-title>
        <source>Nat Methods</source>
        <year>2009</year>
        <volume>6</volume>
        <issue>5</issue>
        <fpage>377</fpage>
        <lpage>82</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.1315</pub-id>
        <pub-id pub-id-type="pmid">19349980</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Picelli</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Björklund</surname>
            <given-names>ÅK</given-names>
          </name>
          <name>
            <surname>Faridani</surname>
            <given-names>OR</given-names>
          </name>
          <name>
            <surname>Sagasser</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Winberg</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Sandberg</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Smart-seq2 for sensitive full-length transcriptome profiling in single cells</article-title>
        <source>Nat Methods</source>
        <year>2013</year>
        <volume>10</volume>
        <issue>11</issue>
        <fpage>1096</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2639</pub-id>
        <pub-id pub-id-type="pmid">24056875</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Klein</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Mazutis</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Akartuna</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Tallapragada</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Veres</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>V</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Droplet barcoding for single-cell transcriptomics applied to embryonic stem cells</article-title>
        <source>Cell</source>
        <year>2015</year>
        <volume>161</volume>
        <issue>5</issue>
        <fpage>1187</fpage>
        <lpage>201</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2015.04.044</pub-id>
        <pub-id pub-id-type="pmid">26000487</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Macosko</surname>
            <given-names>EZ</given-names>
          </name>
          <name>
            <surname>Basu</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Satija</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Nemesh</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Shekhar</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Goldman</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Highly parallel genome-wide expression profiling of individual cells using nanoliter droplets</article-title>
        <source>Cell</source>
        <year>2015</year>
        <volume>161</volume>
        <issue>5</issue>
        <fpage>1202</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2015.05.002</pub-id>
        <pub-id pub-id-type="pmid">26000488</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>GXY</given-names>
          </name>
          <name>
            <surname>Terry</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Belgrader</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Ryvkin</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Bent</surname>
            <given-names>ZW</given-names>
          </name>
          <name>
            <surname>Wilson</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Massively parallel digital transcriptional profiling of single cells</article-title>
        <source>Nat Commun</source>
        <year>2017</year>
        <volume>8</volume>
        <issue>1</issue>
        <fpage>14049</fpage>
        <pub-id pub-id-type="doi">10.1038/ncomms14049</pub-id>
        <pub-id pub-id-type="pmid">28091601</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Darling</surname>
            <given-names>EM</given-names>
          </name>
          <name>
            <surname>Guilak</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>A neural network model for cell classification based on single-cell biomechanical properties</article-title>
        <source>Tissue Eng A</source>
        <year>2008</year>
        <volume>14</volume>
        <issue>9</issue>
        <fpage>1507</fpage>
        <lpage>15</lpage>
        <pub-id pub-id-type="doi">10.1089/ten.tea.2008.0180</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Jia</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ai</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Normalization and noise reduction for single cell RNA-seq experiments</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>31</volume>
        <issue>13</issue>
        <fpage>2225</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btv122</pub-id>
        <pub-id pub-id-type="pmid">25717193</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Diaz</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Sandoval</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Pollen</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Nowakowski</surname>
            <given-names>TJ</given-names>
          </name>
          <name>
            <surname>Lim</surname>
            <given-names>DA</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>SCell: integrated analysis of single-cell RNA-seq data</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <issue>14</issue>
        <fpage>2219</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw201</pub-id>
        <pub-id pub-id-type="pmid">27153637</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Miao</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>DEsingle for detecting three types of differential expression in single-cell RNA-seq data</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>18</issue>
        <fpage>3223</fpage>
        <lpage>4</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty332</pub-id>
        <pub-id pub-id-type="pmid">29688277</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Trapnell</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Defining cell types and states with single-cell genomics</article-title>
        <source>Genome Res</source>
        <year>2015</year>
        <volume>25</volume>
        <fpage>1491</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.190595.115</pub-id>
        <pub-id pub-id-type="pmid">26430159</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Pierson</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Ramazzotti</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Batzoglou</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Visualization and analysis of single-cell RNA-seq data by kernel-based similarity learning</article-title>
        <source>Nat Methods</source>
        <year>2017</year>
        <volume>14</volume>
        <fpage>414</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.4207</pub-id>
        <pub-id pub-id-type="pmid">28263960</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grün</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Oudenaarden</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Design and analysis of single-cell sequencing experiments</article-title>
        <source>Cell</source>
        <year>2015</year>
        <volume>163</volume>
        <fpage>799</fpage>
        <lpage>810</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2015.10.039</pub-id>
        <pub-id pub-id-type="pmid">26544934</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Tan</surname>
            <given-names>KM</given-names>
          </name>
          <name>
            <surname>Petersen</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Witten</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <source>Classification of RNA-seq data. Statistical analysis of next generation sequencing data</source>
        <year>2014</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <source>Discriminant Analysis and Normalization Methods for Next-Generation Sequencing Data. New Frontiers of Biostatistics and Bioinformatics</source>
        <year>2018</year>
        <publisher-loc>Cham</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Witten</surname>
            <given-names>DM</given-names>
          </name>
        </person-group>
        <article-title>Classification and clustering of sequencing data using a Poisson model</article-title>
        <source>Ann Appl Stat</source>
        <year>2011</year>
        <volume>5</volume>
        <issue>4</issue>
        <fpage>2493</fpage>
        <lpage>518</lpage>
        <pub-id pub-id-type="doi">10.1214/11-AOAS493</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dong</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Tong</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Wan</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>NBLDA: negative binomial linear discriminant analysis for RNA-Seq data</article-title>
        <source>BMC Bioinformatics</source>
        <year>2016</year>
        <volume>17</volume>
        <issue>1</issue>
        <fpage>369</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-016-1208-1</pub-id>
        <pub-id pub-id-type="pmid">27623864</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Tong</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Classifying next-generation sequencing data using a zero-inflated Poisson model</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>8</issue>
        <fpage>1329</fpage>
        <lpage>35</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx768</pub-id>
        <pub-id pub-id-type="pmid">29186294</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alquicira-Hernandez</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sathe</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hanlee</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>Q</given-names>
          </name>
        </person-group>
        <article-title>Powell JE. scPred: accurate supervised method for celltype classification from single-cell RNA-seq data</article-title>
        <source>Genome Biol</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>264</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-019-1862-5</pub-id>
        <pub-id pub-id-type="pmid">31829268</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Evaluation of single-cell classifiers for single-cell RNA sequencing data sets</article-title>
        <source>Brief Bioinforma</source>
        <year>2020</year>
        <volume>21</volume>
        <issue>5</issue>
        <fpage>1581</fpage>
        <lpage>95</lpage>
        <pub-id pub-id-type="doi">10.1093/bib/bbz096</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>scClassify: sample size estimation and multiscale classification of cells using single and multiple reference</article-title>
        <source>Mol Syst Biol</source>
        <year>2020</year>
        <volume>16</volume>
        <fpage>e9389</fpage>
        <pub-id pub-id-type="doi">10.15252/msb.20199389</pub-id>
        <pub-id pub-id-type="pmid">32567229</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>SINC: a scale-invariant deep-neural-network classifier for bulk and single-cell RNA-seq data</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>6</issue>
        <fpage>1779</fpage>
        <lpage>84</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btz801</pub-id>
        <pub-id pub-id-type="pmid">31647523</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hochreiter</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Long short-term memory</article-title>
        <source>Neural Comput</source>
        <year>1997</year>
        <volume>9</volume>
        <issue>8</issue>
        <fpage>1735</fpage>
        <lpage>80</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
        <pub-id pub-id-type="pmid">9377276</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zappia</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Phipson</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Oshlack</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Splatter: simulation of single-cell RNA sequencing data</article-title>
        <source>Genome Biol</source>
        <year>2017</year>
        <volume>18</volume>
        <issue>1</issue>
        <fpage>174</fpage>
        <pub-id pub-id-type="doi">10.1186/s13059-017-1305-0</pub-id>
        <pub-id pub-id-type="pmid">28899397</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Furlan</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Dyachuk</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Kastriti</surname>
            <given-names>ME</given-names>
          </name>
          <name>
            <surname>Calvo-Enrique</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Abdo</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Hadjab</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Multipotent peripheral glial cells generate neuroendocrine cells of the adrenal medulla</article-title>
        <source>Science</source>
        <year>2017</year>
        <volume>357</volume>
        <issue>6346</issue>
        <fpage>eaal3753</fpage>
        <pub-id pub-id-type="doi">10.1126/science.aal3753</pub-id>
        <pub-id pub-id-type="pmid">28684471</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bakken</surname>
            <given-names>TE</given-names>
          </name>
          <name>
            <surname>Hodge</surname>
            <given-names>RD</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>TN</given-names>
          </name>
          <name>
            <surname>Aevermann</surname>
            <given-names>B</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Single-nucleus and single-cell transcriptomes compared in matched cortical cell types</article-title>
        <source>PLoS ONE</source>
        <year>2018</year>
        <volume>13</volume>
        <issue>12</issue>
        <fpage>e0209648</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0209648</pub-id>
        <pub-id pub-id-type="pmid">30586455</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cembrowski</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Lemire</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Copeland</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>DiLisio</surname>
            <given-names>SF</given-names>
          </name>
          <name>
            <surname>Clements</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <source>eLife</source>
        <year>2018</year>
        <volume>7</volume>
        <fpage>e37701</fpage>
        <pub-id pub-id-type="doi">10.7554/eLife.37701</pub-id>
        <pub-id pub-id-type="pmid">30375971</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baron</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Veres</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wolock</surname>
            <given-names>SL</given-names>
          </name>
          <name>
            <surname>Faust</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Gaujoux</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Vetere</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A single-cell transcriptomic map of the human and mouse pancreas reveals inter- and intra-cell population structure</article-title>
        <source>Cell Syst</source>
        <year>2016</year>
        <volume>3</volume>
        <issue>4</issue>
        <fpage>346</fpage>
        <lpage>60</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cels.2016.08.011</pub-id>
        <pub-id pub-id-type="pmid">27667365</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Park</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Shrestha</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>CX</given-names>
          </name>
          <name>
            <surname>Kondo</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Single-cell transcriptomics of the mouse kidney reveals potential cellular targets of kidney disease</article-title>
        <source>Science</source>
        <year>2018</year>
        <volume>360</volume>
        <issue>6390</issue>
        <fpage>758</fpage>
        <lpage>63</lpage>
        <pub-id pub-id-type="doi">10.1126/science.aar2131</pub-id>
        <pub-id pub-id-type="pmid">29622724</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ding</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Adiconis</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Simmons</surname>
            <given-names>SK</given-names>
          </name>
          <name>
            <surname>Kowalczyk</surname>
            <given-names>MS</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Systematic comparison of single-cell and single-nucleus RNA-sequencing methods</article-title>
        <source>Nat Biotechnol</source>
        <year>2020</year>
        <volume>38</volume>
        <fpage>737</fpage>
        <lpage>746</lpage>
        <pub-id pub-id-type="doi">10.1038/s41587-020-0465-8</pub-id>
        <pub-id pub-id-type="pmid">32341560</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lobo</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Jiménez-Valverde</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Real</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>AUC: a misleading measure of the performance of predictive distribution models</article-title>
        <source>Glob Ecol Biogeogr</source>
        <year>2008</year>
        <volume>17</volume>
        <issue>2</issue>
        <fpage>145</fpage>
        <lpage>51</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1466-8238.2007.00358.x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38</label>
      <mixed-citation publication-type="other">Sak H, Senior AW, Beaufays F. Long short-term memory recurrent neural network architectures for large scale acoustic modeling. 2014. <ext-link ext-link-type="uri" xlink:href="https://research.google/pubs/pub43905.pdf">https://research.google/pubs/pub43905.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39</label>
      <mixed-citation publication-type="other">Marchi E, Ferroni G, Eyben F, et al.Multi-resolution linear prediction based features for audio onset detection with bidirectional LSTM neural networks. In: 2014 IEEE international conference on acoustics, speech and signal processing (ICASSP). IEEE: 2014. p. 2164–8.</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Graves</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Framewise phoneme classification with bidirectional LSTM and other neural network architectures</article-title>
        <source>Int Joint Conf Neural Netw</source>
        <year>2005</year>
        <volume>18</volume>
        <fpage>602</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neunet.2005.06.042</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gers</surname>
            <given-names>FA</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Cummins</surname>
            <given-names>FA</given-names>
          </name>
        </person-group>
        <article-title>Learning to forget: continual prediction with LSTM</article-title>
        <source>Neural Comput</source>
        <year>2000</year>
        <volume>12</volume>
        <issue>10</issue>
        <fpage>2451</fpage>
        <lpage>71</lpage>
        <pub-id pub-id-type="doi">10.1162/089976600300015015</pub-id>
        <pub-id pub-id-type="pmid">11032042</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42</label>
      <mixed-citation publication-type="other">Gers FA, Schmidhuber J. Recurrent nets that time and count. In: Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium, vol 3. IEEE: 2000. p. 189–94. <ext-link ext-link-type="uri" xlink:href="https://ieeexplore.ieee.org/abstract/document/861302">https://ieeexplore.ieee.org/abstract/document/861302</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rumelhart</surname>
            <given-names>DE</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>GE</given-names>
          </name>
          <name>
            <surname>Williams</surname>
            <given-names>RJ</given-names>
          </name>
        </person-group>
        <article-title>Learning representations by back-propagating errors</article-title>
        <source>Nature</source>
        <year>1986</year>
        <volume>323</volume>
        <fpage>533</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1038/323533a0</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44</label>
      <mixed-citation publication-type="other">Ruder S. An overview of gradient descent optimization algorithms. arXiv preprint arXiv:160904747. 2016.</mixed-citation>
    </ref>
  </ref-list>
</back>
