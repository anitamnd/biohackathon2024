<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d1 20130915//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Plant Genome</journal-id>
    <journal-id journal-id-type="iso-abbrev">Plant Genome</journal-id>
    <journal-id journal-id-type="publisher-id">TPG</journal-id>
    <journal-title-group>
      <journal-title>The Plant Genome</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1940-3372</issn>
    <publisher>
      <publisher-name>Crop Science Society of America</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7822055</article-id>
    <article-id pub-id-type="pmid">30512047</article-id>
    <article-id pub-id-type="publisher-id">TPG-11-03-0013</article-id>
    <article-id pub-id-type="doi">10.3835/plantgenome2018.02.0013</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Science Note</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>An R Package for Multitrait and Multienvironment Data with the Item-Based Collaborative Filtering Algorithm</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Montesinos-López</surname>
          <given-names>Osval A.</given-names>
        </name>
        <xref ref-type="aff" rid="aff0002"/>
        <xref ref-type="corresp" rid="cor1">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Luna-Vázquez</surname>
          <given-names>Francisco Javier</given-names>
        </name>
        <xref ref-type="aff" rid="aff0001"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Montesinos-López</surname>
          <given-names>Abelardo</given-names>
        </name>
        <xref ref-type="aff" rid="aff0001"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Juliana</surname>
          <given-names>Philomin</given-names>
        </name>
        <xref ref-type="aff" rid="aff0003"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Singh</surname>
          <given-names>Ravi</given-names>
        </name>
        <xref ref-type="aff" rid="aff0001"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Crossa</surname>
          <given-names>José</given-names>
        </name>
        <xref ref-type="aff" rid="aff0003"/>
        <xref ref-type="corresp" rid="cor1">*</xref>
      </contrib>
      <aff id="aff0001"><label>1</label>Facultad de Telemática, Univ. de Colima, 28040, Colima, Colima, México</aff>
      <aff id="aff0002"><label>2</label>Dep. de Matemáticas, Centro Univ. de Ciencias Exactas e Ingenierías, Univ. de Guadalajara, 44430, Guadalajara, Jalisco, México</aff>
      <aff id="aff0003"><label>3</label>CIMMYT, Apdo. Postal 6-641, 06600, Ciudad de México, México</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>*</label>Corresponding authors (<email xlink:href="oamontes2@hotmail.com">oamontes2@hotmail.com</email>, <email xlink:href="j.crossa@cgiar.org">j.crossa@cgiar.org</email>).</corresp>
      <fn>
        <p>Montesinos-López, O.A., F.J. Luna-Vázquez, A. Montesinos-López, P. Juliana, R. Singh, J. Crossa, 2018. An R Package for Multitrait and Multienvironment Data with the Item-Based Collaborative Filtering Algorithm. Plant Genome 11:180013. doi: 10.3835/plantgenome2018.02.0013</p>
        <p><bold>Abbreviations:</bold> DH, days to heading; GS, genomic selection; GY, grain yield; IBCF, item-based collaborative filtering; ICBF.MTME, Item-Based Collaborative Filtering for Multitrait and Multienvironment Data package; MSEP, mean square error of prediction; PTesting, the percentage of data to be used for the testing dataset; TRN, training dataset; TST, testing dataset.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>23</day>
      <month>8</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <year>2018</year>
    </pub-date>
    <volume>11</volume>
    <issue>3</issue>
    <elocation-id content-type="doi">10.3835/plantgenome2018.02.0013</elocation-id>
    <history>
      <date date-type="received">
        <day>24</day>
        <month>2</month>
        <year>2018</year>
      </date>
      <date date-type="accepted">
        <day>24</day>
        <month>5</month>
        <year>2018</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2019 Crop Science Society of America</copyright-statement>
      <copyright-year>2016</copyright-year>
      <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/">
        <license-p>This is an open access article distributed under the CC BY-NC-ND license.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>The Item-Based Collaborative Filtering for Multitrait and Multienvironment Data (IBCF.MTME) package was developed to implement the item-based collaborative filtering (IBCF) algorithm for continuous phenotypic data in the context of plant breeding where data are collected for various traits and environments. The main difference between this package and the other available packages that can implement IBCF is that this one was developed for continuous phenotypic data, which cannot be implemented in the current packages because they can implement IBCF only for binary and ordinary phenotypes. In the following article, we will show how to both install the package and use it for studying the prediction accuracy of multitrait and multienvironment data under phenotypic and genomic selection. We illustrate its use with seven examples (with information from two datasets, Wheat_IBCF and Year_IBCF, which are included in the package) comprising multienvironment data, multitrait data, and both multitrait and multienvironment data that cover scenarios in which breeding scientists are interested. The package offers many advantages for studying the genomic-enabled prediction accuracy of multitrait and multienvironment data, ultimately helping plant breeders make better decisions.</p>
    </abstract>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>CORE IDEAS</title>
    <list list-type="bullet">
      <list-item>
        <p>We provide software for a recommender system.</p>
      </list-item>
      <list-item>
        <p>This software will assist plant breeders to make predictions of unobserved primary traits from other observed secondary traits.</p>
      </list-item>
      <list-item>
        <p>The software could be useful in conventional phenotypic selections or in genomic selection.</p>
      </list-item>
    </list>
    <p>GLOBAL FOOD PRODUCTION must increase by 70% by 2050 to feed an additional 2.3 billion people; in developing countries, it needs to almost double. Although production will not need to grow as fast as in previous decades because of a slowdown in population growth rates, it must be pointed out that incomes are growing, and the volume requirements are remarkable. For example, an additional one billion tons of cereals and 200 million tons of meat will need to be produced annually by 2050 (Food and Agriculture Organization of the United Nations, <xref rid="cit0007" ref-type="bibr">2009</xref>). Therefore, there is an urgent need to increase agricultural productivity to meet the enormous challenges facing humanity. Simply stated, current improvements in crop production through genetics and agronomy are insufficient (less than half of what is needed) to support the predicted human activities caused by population growth and increased prosperity by 2050. The predicted 9 billion people in 2050 will consume the same amount of agricultural products that 12 billion people would consume today (Godfray et al., <xref rid="cit0008" ref-type="bibr">2010</xref>).</p>
    <p>Consequently, breeding scientists need innovative methods to be able to reach the goal of increasing food production without significantly increasing the land used for agricultural production. Genomic selection (GS) facilitates the rapid selection of superior genotypes and accelerates the breeding cycle (Crossa et al., <xref rid="cit0004" ref-type="bibr">2017</xref>), which could increase grain production in less time and revolutionize animal breeding and plant breeding. For example, in some beef breeds, GS is now applied on a large scale, as in the United States where more than 52,000 ‘Angus’ cattle (<italic>Bos taurus</italic> L.) have now been genotyped for genomic estimated breeding value evaluation (Lourenco et al., <xref rid="cit0014" ref-type="bibr">2015</xref>). Furthermore, the results of simulations and applications in some breeding programs show evidence of the power of GS (Meuwissen et al., <xref rid="cit0016" ref-type="bibr">2001</xref>; Bernardo and Yu, <xref rid="cit0002" ref-type="bibr">2007</xref>; Lorenzana and Bernardo, <xref rid="cit0013" ref-type="bibr">2009</xref>; Heffner et al., <xref rid="cit0009" ref-type="bibr">2009</xref>; <xref rid="cit0010" ref-type="bibr">2010</xref>), since it has been shown to improve genetic gains (Massman et al., <xref rid="cit0015" ref-type="bibr">2013</xref>; Asoro et al., <xref rid="cit0001" ref-type="bibr">2013</xref>; Combs and Bernardo, <xref rid="cit0005" ref-type="bibr">2013</xref>; Beyene et al., <xref rid="cit0003" ref-type="bibr">2015</xref>; Rutkoski et al., <xref rid="cit0021" ref-type="bibr">2015</xref>) and significantly reduce the time needed to release new varieties of plants and animals. If we compare the results of maize (<italic>Zea mays</italic> L.) and wheat (<italic>Triticum aestivum</italic> L.) breeding programs that use traditional selection to programs that use GS, though it is comparable to the traditional scheme, GS produces considerable savings in time and resources (Massman et al., <xref rid="cit0015" ref-type="bibr">2013</xref>; Asoro et al., <xref rid="cit0001" ref-type="bibr">2013</xref>; Combs and Bernardo, <xref rid="cit0005" ref-type="bibr">2013</xref>; Beyene et al., <xref rid="cit0003" ref-type="bibr">2015</xref>; Rutkoski et al., <xref rid="cit0021" ref-type="bibr">2015</xref>).</p>
    <p>However, the GS approach depends heavily on the quality of the data at hand and on the statistical methods: GS uses statistical models for predicting individuals in the validation set that were genotyped by using only the individuals in the training set that were phenotyped and genotyped. As such, when the data quality is poor, we cannot expect good predictions. Along the same lines, when the training set is very small, the model will most probably not work well for prediction. When the structure and size of the data are complex, it is more difficult to make good predictions because we cannot process the very large datasets that are becoming more common in GS. Last but not least, the type of statistical model used is essential for making good predictions. Accordingly, plant breeders and statisticians are continuously searching for better statistical methods to improve the prediction power of the GS paradigm. Whereas this type of research has increased the number of statistical methods that are currently used in GS, there is still a need for better statistical methods to increase prediction power considerably.</p>
    <p>This lack of statistical methods for GS is more evident in the context of multitrait and multienvironment data, since many of today´s breeding programs want to improve lines with multiple traits tested in different environments simultaneously. In this sense, there are some models available, such as the Bayesian multitrait and multienvironment model proposed by Montesinos-López et al. (<xref rid="cit0017" ref-type="bibr">2016</xref>) for continuous data, and its Bayesian counterpart for count data (Montesinos-López et al., <xref rid="cit0018" ref-type="bibr">2017</xref>). However, the main disadvantage of these models is that they are not at all efficient in the context of the large datasets that are becoming more and more common in the GS context. Therefore, to address the lack of methods for multitrait and multienvironment data, Montesinos-López et al. (<xref rid="cit0018" ref-type="bibr">2018</xref>) proposed the IBCF algorithm, which proved to be comparable to the conventional multitrait and multienvironment models, but had the advantage of being very efficient in terms of the time required for its implementation.</p>
    <p>The IBCF is an algorithm attributed to <ext-link ext-link-type="uri" xlink:href="http://Amazon.com">Amazon.com</ext-link> (Linden et al., <xref rid="cit0011" ref-type="bibr">2003</xref>). It is a type of collaborative filtering method for recommender systems based on the similarity between items calculated from people’s ratings of those items (Linden et al., <xref rid="cit0011" ref-type="bibr">2003</xref>; Sarwar et al., <xref rid="cit0022" ref-type="bibr">2001</xref>). This method first executes a model-building stage by finding the similarity between all pairs of items. This similarity function can take many forms, such as the correlation between ratings or the cosine of those rating vectors. Afterwards, the system executes a recommendation stage. It uses the items that are most similar to a user’s already-rated items to generate a list of recommendations. Usually, this calculation is a weighted sum or linear regression. This form of recommendation is similar to “People who rate Item X highly, like you, also tend to rate Item Y highly, and you haven’t rated Item Y yet, so you should try it” (Linden et al., <xref rid="cit0011" ref-type="bibr">2003</xref>; Sarwar et al., <xref rid="cit0022" ref-type="bibr">2001</xref>). This algorithm is used for making online recommendations of products like movies, music, news, books, research articles, search queries, social tags, and products in general. Although software for implementing this method is available, the available software for IBCF works only for binary or ordinal responses, since most products are rated on a binary or ordinal scale. The advantage of this method is that it can be successfully implemented in the context of plant breeding for continuous phenotypes to make predictions in the context of multitrait and multienvironment data, as was done by Montesinos-López et al. (<xref rid="cit0019" ref-type="bibr">2018</xref>). However, no software is available for its implementation in the context of plant breeding for continuous traits.</p>
    <p>Therefore, we propose an R package called IBCF. MTME for studying the prediction accuracy of datasets that are collected as multitrait and multienvironment data (R Core Team, <xref rid="cit0020" ref-type="bibr">2018</xref>). However, it can only be used with multitrait or multienvironment data and is only appropriate for continuous phenotypes. We provide many useful tools that facilitate the study of the prediction accuracy of multitrait and multienvironment datasets, which are very common in plant breeding. We illustrate the use of the package by giving six examples that cover many practical scenarios of interest to plant breeders. Additionally, we provide tools for data transformation and summary plots to help breeders prepare the dataset the package requires as input, as well as explain how to interpret its results.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec2">
    <title>MATERIALS AND METHODS</title>
    <sec id="sec2.1">
      <title>The IBCF Algorithm</title>
      <p>The IBCF algorithm is very popular with electronic commerce websites for recommending items and products, in which they use inputs about a customer’s interests to generate a list of recommended items. This algorithm was recently implemented in GS and proved to be comparable to conventional whole-genome prediction models when the correlation between traits and environments was moderate or high (Montesinos-López et al., <xref rid="cit0019" ref-type="bibr">2018</xref>). The IBCF algorithm basically works by building a database of users’ preferences (lines) for items (trait–environment combinations), as can be seen in <xref rid="t0001" ref-type="table">Table 1</xref>, which provides the raw phenotypic data on six lines evaluated in two different environments (E1 and E2) for two different traits (T1 and T2), with both traits measured in different scales. This raw phenotypic dataset has four missing values. By column, we then standardize <xref ref-type="disp-formula" rid="eq1">Eq. [1]</xref> for each column in <xref rid="t0001" ref-type="table">Table 1</xref> (except the first one):</p>
      <disp-formula id="eq1">
        <alternatives>
          <mml:math id="M1">
            <mml:mrow>
              <mml:mo stretchy="false">(</mml:mo>
              <mml:mo stretchy="false">[</mml:mo>
              <mml:msub>
                <mml:mi>z</mml:mi>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mtext> </mml:mtext>
              <mml:mo>=</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:mo stretchy="false">(</mml:mo>
              <mml:msub>
                <mml:mi>y</mml:mi>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mtext> </mml:mtext>
              <mml:mo>−</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:msub>
                <mml:mi>μ</mml:mi>
                <mml:mi>j</mml:mi>
              </mml:msub>
              <mml:mo stretchy="false">)</mml:mo>
              <mml:msubsup>
                <mml:mi>σ</mml:mi>
                <mml:mi>j</mml:mi>
                <mml:mrow>
                  <mml:mo>−</mml:mo>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
              </mml:msubsup>
              <mml:mo stretchy="false">]</mml:mo>
              <mml:mo stretchy="false">)</mml:mo>
              <mml:mtext>,                                           </mml:mtext>
              <mml:mo stretchy="false">[</mml:mo>
              <mml:mn>1</mml:mn>
              <mml:mo stretchy="false">]</mml:mo>
            </mml:mrow>
          </mml:math>
          <graphic xlink:href="TPG-11-03-0013-eq1.jpg" position="float" orientation="portrait"/>
        </alternatives>
      </disp-formula>
      <table-wrap id="t0001" orientation="portrait" position="float">
        <label>Table 1</label>
        <caption>
          <p>Example of item-based collaborative filtering: Raw phenotypic data.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="bottom">
            <tr>
              <th align="left" rowspan="1" colspan="1">Line<xref ref-type="table-fn" rid="tf1-1">†</xref>
</th>
              <th align="left" rowspan="1" colspan="1">T1_E1</th>
              <th align="left" rowspan="1" colspan="1">T1_E2</th>
              <th align="left" rowspan="1" colspan="1">T2_E1</th>
              <th align="left" rowspan="1" colspan="1">T2_E2</th>
            </tr>
          </thead>
          <tbody valign="bottom">
            <tr>
              <td align="left" rowspan="1" colspan="1">Line 1</td>
              <td align="center" rowspan="1" colspan="1">NA<xref ref-type="table-fn" rid="tf1-2">‡</xref>
</td>
              <td align="center" rowspan="1" colspan="1">8.0423</td>
              <td align="center" rowspan="1" colspan="1">70.833</td>
              <td align="center" rowspan="1" colspan="1">79.3463</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Line 2</td>
              <td align="center" rowspan="1" colspan="1">6.0971</td>
              <td align="center" rowspan="1" colspan="1">8.2061</td>
              <td align="center" rowspan="1" colspan="1">70.539</td>
              <td align="center" rowspan="1" colspan="1">NA</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Line 3</td>
              <td align="center" rowspan="1" colspan="1">7.9828</td>
              <td align="center" rowspan="1" colspan="1">8.7582</td>
              <td align="center" rowspan="1" colspan="1">71.1034</td>
              <td align="center" rowspan="1" colspan="1">81.3512</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Line 4</td>
              <td align="center" rowspan="1" colspan="1">5.2876</td>
              <td align="center" rowspan="1" colspan="1">NA</td>
              <td align="center" rowspan="1" colspan="1">70.5082</td>
              <td align="center" rowspan="1" colspan="1">78.3059</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Line 5</td>
              <td align="center" rowspan="1" colspan="1">7.1267</td>
              <td align="center" rowspan="1" colspan="1">8.6252</td>
              <td align="center" rowspan="1" colspan="1">71.2019</td>
              <td align="center" rowspan="1" colspan="1">80.8350</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Line 6</td>
              <td align="center" rowspan="1" colspan="1">8.3658</td>
              <td align="center" rowspan="1" colspan="1">8.5061</td>
              <td align="center" rowspan="1" colspan="1">NA</td>
              <td align="center" rowspan="1" colspan="1">82.1754</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tf1-1">
            <label>†</label>
            <p>Line denotes the lines; T1 and T2 denote Traits 1 and 2, respectively; E1 and E2 denote Environments 1 and 2, respectively.</p>
          </fn>
          <fn id="tf1-2">
            <label>‡</label>
            <p>This raw phenotypic dataset has four missing values [denoted not available (NA)].</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>where <italic>i</italic> denotes the users (lines) and <italic>j</italic> denotes the columns (trait–environment combinations). We then use the standardized information to form <xref rid="t0002" ref-type="table">Table 2</xref>. In this example, <italic>i</italic> = 1,…,6, <italic>j</italic> = 1,2…,4, μ<italic><sub>j</sub></italic> is the mean of column <italic>j</italic>, and σ<italic><sub>j</sub></italic> denotes the SD of Column <italic>j</italic>. In addition, for purposes of comparison, the true values of the missing values are: <italic>y</italic>
<sub>11</sub> = 5.4387, <italic>y</italic>
<sub>24</sub> = 80.009, <italic>y</italic>
<sub>42</sub> = 6.979, and <italic>y</italic>
<sub>63</sub> = 72.085. We then calculated Pearson’s correlations among the columns of <xref rid="t0002" ref-type="table">Table 2</xref> (trait–environment combinations), which are given in <xref rid="t0003" ref-type="table">Table 3</xref>. We used the following formula (Sarwar et al., <xref rid="cit0022" ref-type="bibr">2001</xref>; Montesinos-López et al., <xref rid="cit0019" ref-type="bibr">2018</xref>) to calculate the predictions for the missing phenotypes of line <italic>i</italic> in item <italic>j</italic>:.</p>
      <disp-formula id="eq2">
        <alternatives>
          <mml:math id="M2">
            <mml:mrow>
              <mml:msub>
                <mml:mover accent="true">
                  <mml:mi>y</mml:mi>
                  <mml:mo>^</mml:mo>
                </mml:mover>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mtext> </mml:mtext>
              <mml:mo>=</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:msub>
                <mml:mi>μ</mml:mi>
                <mml:mi>j</mml:mi>
              </mml:msub>
              <mml:mtext> </mml:mtext>
              <mml:mo>+</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:msub>
                <mml:mi>σ</mml:mi>
                <mml:mi>j</mml:mi>
              </mml:msub>
              <mml:mtext> </mml:mtext>
              <mml:msub>
                <mml:mover accent="true">
                  <mml:mi>z</mml:mi>
                  <mml:mo>^</mml:mo>
                </mml:mover>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mi>j</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mtext>                                    </mml:mtext>
              <mml:mo stretchy="false">[</mml:mo>
              <mml:mn>2</mml:mn>
              <mml:mo stretchy="false">]</mml:mo>
            </mml:mrow>
          </mml:math>
          <graphic xlink:href="TPG-11-03-0013-eq2.jpg" position="float" orientation="portrait"/>
        </alternatives>
      </disp-formula>
      <table-wrap id="t0002" orientation="portrait" position="float">
        <label>Table 2</label>
        <caption>
          <p>Example of item-based collaborative filtering: Standardized phenotypic data.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="bottom">
            <tr>
              <th align="left" rowspan="1" colspan="1">Line<xref ref-type="table-fn" rid="tf2-1">†</xref>
</th>
              <th align="left" rowspan="1" colspan="1">T1_E1</th>
              <th align="left" rowspan="1" colspan="1">T1_E2</th>
              <th align="left" rowspan="1" colspan="1">T2_E1</th>
              <th align="left" rowspan="1" colspan="1">T2_E2</th>
            </tr>
          </thead>
          <tbody valign="bottom">
            <tr>
              <td align="left" rowspan="1" colspan="1">Line 1</td>
              <td align="center" rowspan="1" colspan="1">NA<xref ref-type="table-fn" rid="tf2-2">‡</xref>
</td>
              <td align="center" rowspan="1" colspan="1">-1.2988</td>
              <td align="center" rowspan="1" colspan="1">-0.0127</td>
              <td align="center" rowspan="1" colspan="1">-0.6769</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Line 2</td>
              <td align="center" rowspan="1" colspan="1">-0.6815</td>
              <td align="center" rowspan="1" colspan="1">-0.7465</td>
              <td align="center" rowspan="1" colspan="1">-0.9407</td>
              <td align="center" rowspan="1" colspan="1">NA</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Line 3</td>
              <td align="center" rowspan="1" colspan="1">0.7874</td>
              <td align="center" rowspan="1" colspan="1">1.1144</td>
              <td align="center" rowspan="1" colspan="1">0.8407</td>
              <td align="center" rowspan="1" colspan="1">0.6077</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Line 4</td>
              <td align="center" rowspan="1" colspan="1">-1.3122</td>
              <td align="center" rowspan="1" colspan="1">NA</td>
              <td align="center" rowspan="1" colspan="1">-1.0395</td>
              <td align="center" rowspan="1" colspan="1">-1.3436</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Line 5</td>
              <td align="center" rowspan="1" colspan="1">0.1205</td>
              <td align="center" rowspan="1" colspan="1">0.6662</td>
              <td align="center" rowspan="1" colspan="1">1.1522</td>
              <td align="center" rowspan="1" colspan="1">0.2770</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Line 6</td>
              <td align="center" rowspan="1" colspan="1">1.0858</td>
              <td align="center" rowspan="1" colspan="1">0.2647</td>
              <td align="center" rowspan="1" colspan="1">NA</td>
              <td align="center" rowspan="1" colspan="1">1.1358</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tf2-1">
            <label>†</label>
            <p>Line denotes the lines; T1 and T2 denote Traits 1 and 2, respectively; E1 and E2 denote Environments 1 and 2, respectively.</p>
          </fn>
          <fn id="tf2-2">
            <label>‡</label>
            <p>This dataset has four missing values [denoted not available (NA)].</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap id="t0003" orientation="portrait" position="float">
        <label>Table 3</label>
        <caption>
          <p>Example of item-based collaborative filtering: Matrix of correlation.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="bottom">
            <tr>
              <th align="left" rowspan="1" colspan="1">Line<xref ref-type="table-fn" rid="tf3-1">†</xref>
</th>
              <th align="left" rowspan="1" colspan="1">T1_E1</th>
              <th align="left" rowspan="1" colspan="1">T1_E2</th>
              <th align="left" rowspan="1" colspan="1">T2_E1</th>
              <th align="left" rowspan="1" colspan="1">T2_E2</th>
            </tr>
          </thead>
          <tbody valign="bottom">
            <tr>
              <td align="left" rowspan="1" colspan="1">T1_E1</td>
              <td align="center" rowspan="1" colspan="1">1.000</td>
              <td align="center" rowspan="1" colspan="1">0.7103</td>
              <td align="center" rowspan="1" colspan="1">0.8838</td>
              <td align="center" rowspan="1" colspan="1">0. 9912</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">T1_E2</td>
              <td align="center" rowspan="1" colspan="1">0.7103</td>
              <td align="center" rowspan="1" colspan="1">1.0000</td>
              <td align="center" rowspan="1" colspan="1">0.7741</td>
              <td align="center" rowspan="1" colspan="1">0.7463</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">T2_E1</td>
              <td align="center" rowspan="1" colspan="1">0.8838</td>
              <td align="center" rowspan="1" colspan="1">0.7741</td>
              <td align="center" rowspan="1" colspan="1">1.000</td>
              <td align="center" rowspan="1" colspan="1">0.9521</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">T2_E2</td>
              <td align="center" rowspan="1" colspan="1">0.9912</td>
              <td align="center" rowspan="1" colspan="1">0.7463</td>
              <td align="center" rowspan="1" colspan="1">0.9521</td>
              <td align="center" rowspan="1" colspan="1">1.0000</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tf3-1">
            <label>†</label>
            <p>Line denotes the lines; T1 and T2 denote Traits 1 and 2, respectively; E1 and E2 denote Environments 1 and 2, respectively.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>where 
<inline-formula id="ieq1"><alternatives><mml:math id="I1"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>j</mml:mi><mml:mo>′</mml:mo><mml:mo>∈</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>j</mml:mi><mml:mo>′</mml:mo><mml:mo>∈</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mstyle><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mi>j</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="TPG-11-03-0013-ieq1.jpg"/></alternatives></inline-formula> is the scaled predictive phenotype for user (line) <italic>i</italic> on item (trait–environment) <italic>j</italic>, <italic>N<sub>i</sub></italic>(<italic>j</italic>) denotes the items rated by user (line) <italic>i</italic> as being most similar to item <italic>j</italic>, <italic>w<sub>jjʹ</sub></italic> is the weight between items j and <italic>jʹ</italic>. The weights used in <xref ref-type="disp-formula" rid="eq2">Eq. [2]</xref> are obtained from an item-to-item similarity matrix built from Pearson’s correlation (given in <xref rid="t0003" ref-type="table">Table 3</xref>), which provides information on how similar an item is to another item.</p>
      <p>Next, we illustrate how to calculate the four missing values via <xref ref-type="disp-formula" rid="eq2">Eq. [2]</xref>. First, we calculate the scaled predicted value for <italic>y</italic>
<sub>11</sub>:</p>
      <disp-formula id="eq3">
        <alternatives>
          <mml:math id="M3">
            <mml:mrow>
              <mml:msub>
                <mml:mover accent="true">
                  <mml:mi>z</mml:mi>
                  <mml:mo>^</mml:mo>
                </mml:mover>
                <mml:mrow>
                  <mml:mn>11</mml:mn>
                </mml:mrow>
              </mml:msub>
              <mml:mtext> </mml:mtext>
              <mml:mo>=</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>−</mml:mo>
                  <mml:mn>1.2988</mml:mn>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>×</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mn>0.7103</mml:mn>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>−</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mn>0.0127</mml:mn>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>×</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mn>0.8838</mml:mn>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>−</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mn>0.6769</mml:mn>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>×</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mn>0.9912</mml:mn>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>|</mml:mo>
                  <mml:mn>0.7103</mml:mn>
                  <mml:mo>|</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>+</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>|</mml:mo>
                  <mml:mn>0.8838</mml:mn>
                  <mml:mo>|</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>+</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>|</mml:mo>
                  <mml:mn>0.9912</mml:mn>
                  <mml:mo>|</mml:mo>
                </mml:mrow>
              </mml:mfrac>
              <mml:mtext> </mml:mtext>
              <mml:mo>=</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:mo>−</mml:mo>
              <mml:mn>0.6207.</mml:mn>
              <mml:mtext>              </mml:mtext>
              <mml:mo stretchy="false">[</mml:mo>
              <mml:mn>3</mml:mn>
              <mml:mo stretchy="false">]</mml:mo>
            </mml:mrow>
          </mml:math>
          <graphic xlink:href="TPG-11-03-0013-eq3.jpg" position="float" orientation="portrait"/>
        </alternatives>
      </disp-formula>
      <p>The predicted value of <italic>y</italic>
<sub>11</sub> in its original scale is equal to <italic>ŷ</italic>
<sub>11</sub> = <italic>ẑ</italic>
<sub>11</sub>
<italic>σ<sub>j</sub></italic> + <italic>μ<sub>j</sub></italic> = −0.6207 × 1.2836 + 6.9719 = 6.1752.</p>
      <p>This means that the predicted value of Line 1 in trait–environment Combination 1 (<italic>ŷ</italic>
<sub>11</sub>) is 6.1752, which is close to the true value of 5.4386873. Next, we show how to calculate the predicted value of the missing value, <italic>ŷ</italic>
<sub>24</sub>; first, the scaled predicted value is equal to the following:</p>
      <disp-formula id="eq4">
        <alternatives>
          <mml:math id="M4">
            <mml:mrow>
              <mml:msub>
                <mml:mover accent="true">
                  <mml:mi>z</mml:mi>
                  <mml:mo>^</mml:mo>
                </mml:mover>
                <mml:mrow>
                  <mml:mn>24</mml:mn>
                </mml:mrow>
              </mml:msub>
              <mml:mtext> </mml:mtext>
              <mml:mo>=</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>−</mml:mo>
                  <mml:mtext>0.6815 </mml:mtext>
                  <mml:mo>×</mml:mo>
                  <mml:mtext> 0.9912 </mml:mtext>
                  <mml:mo>−</mml:mo>
                  <mml:mtext> 0.7465 </mml:mtext>
                  <mml:mo>×</mml:mo>
                  <mml:mtext> 0.7463 </mml:mtext>
                  <mml:mo>−</mml:mo>
                  <mml:mtext> 0.9406 </mml:mtext>
                  <mml:mo>×</mml:mo>
                  <mml:mtext> 0.9521</mml:mtext>
                </mml:mrow>
                <mml:mrow>
                  <mml:mrow>
                    <mml:mo>|</mml:mo>
                    <mml:mrow>
                      <mml:mtext>0.9912</mml:mtext>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                        <mml:mrow>
                          <mml:mtext> </mml:mtext>
                          <mml:mo>+</mml:mo>
                          <mml:mtext> </mml:mtext>
                        </mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mtext>0.7463</mml:mtext>
                      <mml:mrow>
                        <mml:mo>|</mml:mo>
                        <mml:mrow>
                          <mml:mtext> </mml:mtext>
                          <mml:mo>+</mml:mo>
                          <mml:mtext> </mml:mtext>
                        </mml:mrow>
                        <mml:mo>|</mml:mo>
                      </mml:mrow>
                      <mml:mtext>0.9521</mml:mtext>
                    </mml:mrow>
                    <mml:mo>|</mml:mo>
                  </mml:mrow>
                </mml:mrow>
              </mml:mfrac>
              <mml:mtext> </mml:mtext>
              <mml:mo>=</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:mo>−</mml:mo>
              <mml:mtext>0.7913</mml:mtext>
              <mml:mo>.</mml:mo>
              <mml:mtext>              </mml:mtext>
              <mml:mo stretchy="false">[</mml:mo>
              <mml:mn>4</mml:mn>
              <mml:mo stretchy="false">]</mml:mo>
            </mml:mrow>
          </mml:math>
          <graphic xlink:href="TPG-11-03-0013-eq4.jpg" position="float" orientation="portrait"/>
        </alternatives>
      </disp-formula>
      <p>The predicted value of <italic>y</italic>
<sub>24</sub> in its original scale is then equal to <italic>ŷ</italic>
<sub>24</sub> = <italic>ẑ</italic>
<sub>24</sub> × σ<italic><sub>j</sub></italic> + μ<italic><sub>j</sub></italic> = −0.7913 × 1.5606 + 80.4028 = 79.1679.</p>
      <p>Now the predicted value of Line 2 in trait–environment Combination 4 (<italic>ŷ</italic>
<sub>24</sub>) is 79.1679 , which is close to its true value of 80.0092. We then present the scaled predicted response for Line 4 and trait–environment Combination 2, <italic>y</italic>
<sub>42</sub>, which is:</p>
      <disp-formula id="eq5">
        <alternatives>
          <mml:math id="M5">
            <mml:mrow>
              <mml:msub>
                <mml:mover accent="true">
                  <mml:mi>z</mml:mi>
                  <mml:mo>^</mml:mo>
                </mml:mover>
                <mml:mrow>
                  <mml:mn>42</mml:mn>
                </mml:mrow>
              </mml:msub>
              <mml:mtext> </mml:mtext>
              <mml:mo>=</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>−</mml:mo>
                  <mml:mtext>1.3122 </mml:mtext>
                  <mml:mo>×</mml:mo>
                  <mml:mtext> 0.7103 </mml:mtext>
                  <mml:mo>−</mml:mo>
                  <mml:mtext> 1.0395 </mml:mtext>
                  <mml:mo>×</mml:mo>
                  <mml:mtext> 0.7741 </mml:mtext>
                  <mml:mo>−</mml:mo>
                  <mml:mtext> 1.3437 </mml:mtext>
                  <mml:mo>×</mml:mo>
                  <mml:mtext> 0.7463</mml:mtext>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>|</mml:mo>
                  <mml:mtext>0.7103</mml:mtext>
                  <mml:mo>|</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>+</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>|</mml:mo>
                  <mml:mtext>0.7741</mml:mtext>
                  <mml:mo>|</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>+</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>|</mml:mo>
                  <mml:mtext>0.7463</mml:mtext>
                  <mml:mo>|</mml:mo>
                </mml:mrow>
              </mml:mfrac>
              <mml:mtext> </mml:mtext>
              <mml:mo>=</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:mo>−</mml:mo>
              <mml:mtext>1.2281</mml:mtext>
              <mml:mo>.</mml:mo>
              <mml:mtext>              </mml:mtext>
              <mml:mo stretchy="false">[</mml:mo>
              <mml:mn>5</mml:mn>
              <mml:mo stretchy="false">]</mml:mo>
            </mml:mrow>
          </mml:math>
          <graphic xlink:href="TPG-11-03-0013-eq5.jpg" position="float" orientation="portrait"/>
        </alternatives>
      </disp-formula>
      <p>The predicted value of <italic>y</italic>
<sub>42</sub> in its original scale is equal to <italic>ŷ</italic>
<sub>42</sub> = <italic>ẑ</italic>
<sub>42</sub> × σ<italic><sub>j</sub></italic> + μ<italic><sub>j</sub></italic> = −1.2281 × 0.2967 + 8.4276 = 8.0632.</p>
      <p>This means that the predicted value of Line 4 in trait–environment Combination 2 (<italic>ŷ</italic>
<sub>42</sub>) is 8.0632, which is close to its true value of 6.9786 . Finally, we present the scaled predicted value of Line 6 in trait–environment Combination 3:</p>
      <disp-formula id="eq6">
        <alternatives>
          <mml:math id="M6">
            <mml:mrow>
              <mml:msub>
                <mml:mover accent="true">
                  <mml:mi>z</mml:mi>
                  <mml:mo>^</mml:mo>
                </mml:mover>
                <mml:mrow>
                  <mml:mn>63</mml:mn>
                </mml:mrow>
              </mml:msub>
              <mml:mtext> </mml:mtext>
              <mml:mo>=</mml:mo>
              <mml:mtext> </mml:mtext>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mtext>1.0858 </mml:mtext>
                  <mml:mo>×</mml:mo>
                  <mml:mtext> 0.8838 </mml:mtext>
                  <mml:mo>+</mml:mo>
                  <mml:mtext> 0.2646 </mml:mtext>
                  <mml:mo>×</mml:mo>
                  <mml:mtext> 0.7741 </mml:mtext>
                  <mml:mo>+</mml:mo>
                  <mml:mtext> 1.1359 </mml:mtext>
                  <mml:mo>×</mml:mo>
                  <mml:mtext> 0.9521</mml:mtext>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>|</mml:mo>
                  <mml:mtext>0.8838</mml:mtext>
                  <mml:mo>|</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>+</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>|</mml:mo>
                  <mml:mtext>0.7741</mml:mtext>
                  <mml:mo>|</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>+</mml:mo>
                  <mml:mtext> </mml:mtext>
                  <mml:mo>|</mml:mo>
                  <mml:mtext>0.9521</mml:mtext>
                  <mml:mo>|</mml:mo>
                </mml:mrow>
              </mml:mfrac>
              <mml:mtext> </mml:mtext>
              <mml:mo>=</mml:mo>
              <mml:mtext> 0.8605</mml:mtext>
              <mml:mo>.</mml:mo>
              <mml:mtext>               </mml:mtext>
              <mml:mo stretchy="false">[</mml:mo>
              <mml:mn>6</mml:mn>
              <mml:mo stretchy="false">]</mml:mo>
            </mml:mrow>
          </mml:math>
          <graphic xlink:href="TPG-11-03-0013-eq6.jpg" position="float" orientation="portrait"/>
        </alternatives>
      </disp-formula>
      <p>The predicted value of <italic>y</italic>
<sub>63</sub> in its original scale is equal to <italic>ŷ</italic>
<sub>63</sub> = <italic>ẑ</italic>
<sub>63</sub> × σ<italic><sub>j</sub></italic> + μ<italic><sub>j</sub></italic> = 0.8605 × 0.3165 + 70.8373 = 71.1097.</p>
      <p>This means that the predicted value of Line 6 in trait–environment Combination 3 (<italic>ŷ</italic>
<sub>63</sub>) is 71.1097, which is close to its true value, 72.0845.</p>
      <p>As this example shows, the calculations are easy but laborious; however, the IBCF.MTME package does this job automatically for us and the dataset required can be on different scales (not standardized) for the traits; in other words, the traits can be measured on different scales. Internally, the IBCF.MTME package standardizes <inline-formula id="ieq2"><alternatives><mml:math id="I2"><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>μ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:math><inline-graphic xlink:href="TPG-11-03-0013-ieq2.jpg"/></alternatives></inline-formula> in each column of the dataset given in <xref rid="t0004" ref-type="table">Table 4</xref> (which shows the format of the type of data required) for the training dataset obtained in each random partition. This implies that to use the formula given in <xref ref-type="disp-formula" rid="eq2">Eq. [2]</xref> for making predictions about a particular trait–environment combinations, the data are standardized and the similarity matrix resulting from the corresponding training dataset of a particular partition selected from the whole dataset in <xref rid="t0004" ref-type="table">Table 4</xref> is computed. Therefore, the predictions are obtained by using <xref ref-type="disp-formula" rid="eq2">Eq. [2]</xref> with the parameters estimates obtained from the training dataset corresponding to each partition and the predictions are made for the observations in the testing dataset.</p>
      <table-wrap id="t0004" orientation="portrait" position="float">
        <label>Table 4</label>
        <caption>
          <p>Phenotypic information in its original scale for building the rating matrix for multitrait and multienvironment data for <italic>J</italic> genotypes, <italic>I</italic> environments, and <italic>L</italic> traits.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="bottom">
            <tr>
              <th align="left" rowspan="1" colspan="1">Genotypes</th>
              <th align="left" rowspan="1" colspan="1">
</th>
              <th align="left" rowspan="1" colspan="1">
</th>
              <th colspan="5" rowspan="1">Trait–environment combinations</th>
              <th align="left" rowspan="1" colspan="1">
</th>
              <th align="left" rowspan="1" colspan="1">
</th>
              <th align="left" rowspan="1" colspan="1">
</th>
            </tr>
          </thead>
          <tbody valign="bottom">
            <tr>
              <td align="left" rowspan="1" colspan="1"/>
              <td align="center" rowspan="1" colspan="1">T1_E1</td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">T1_EI</td>
              <td align="center" rowspan="1" colspan="1">T2_E1</td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">T2_E1</td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">TL_EI</td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">TL_EI</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">G1<xref ref-type="table-fn" rid="tf4-1">†</xref>
</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y</italic>
                <sub>111</sub>
              </td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y<sub>I</sub></italic>
                <sub>11</sub>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y</italic>
                <sub>112</sub>
              </td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y<sub>I</sub></italic>
                <sub>12</sub>
              </td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y</italic>
                <sub>11</sub>
                <italic>
                  <sub>L</sub>
                </italic>
              </td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y<sub>I L</sub></italic>
                <sub>1</sub>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">G2</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y</italic>
                <sub>121</sub>
              </td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y<sub>I</sub></italic>
                <sub>21</sub>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y</italic>
                <sub>122</sub>
              </td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y<sub>I</sub></italic>
                <sub>22</sub>
              </td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y</italic>
                <sub>12</sub>
                <italic>
                  <sub>L</sub>
                </italic>
              </td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y<sub>I L</sub></italic>
                <sub>2</sub>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">⋮</td>
              <td align="center" rowspan="1" colspan="1">⋮</td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">⋮</td>
              <td align="center" rowspan="1" colspan="1">⋮</td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">⋮</td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">⋮</td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">⋮</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">GJ</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y</italic>
                <sub>1</sub>
                <italic>
                  <sub>J</sub>
                </italic>
                <sub>1</sub>
              </td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y<sub>IJ</sub></italic>
                <sub>1</sub>
              </td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y</italic>
                <sub>1</sub>
                <italic>
                  <sub>J</sub>
                </italic>
                <sub>2</sub>
              </td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y<sub>IJ</sub></italic>
                <sub>2</sub>
              </td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1">
                <italic>y</italic>
                <sub>1</sub>
                <italic>
                  <sub>JL</sub>
                </italic>
              </td>
              <td align="center" rowspan="1" colspan="1">…</td>
              <td align="center" rowspan="1" colspan="1"><italic>y<sub>IJL</sub></italic> .</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tf4-1">
            <label>†</label>
            <p>G, genotypes; E, environment; T, trait; <italic>y<sub>ijl</sub></italic>, the phenotype from the <italic>j</italic>
<sup>th</sup> line in the <italic>i</italic>
<sup>th</sup> environment for the <italic>l</italic>
<sup>th</sup> trait.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="sec2.2">
      <title>Evaluation of Prediction Accuracy in the IBCF.MTME Package</title>
      <p>The IBCF.MTME package can implement a random cross-validation. This method consists of randomly dividing the whole dataset into two subsets: the training (TRN) dataset and the testing (TST) dataset. The percentage of the whole dataset assigned to the TRN and TST datasets is fixed by the user. For example, for each random partition, 80% of the whole dataset can be assigned to the TRN and the remaining 20% to the TST dataset. Random cross-validation is different from <italic>K</italic>-fold cross-validation because the partitions are not mutually exclusive; this means that in the random cross-validation approach, one observation can appear in more than one partition. Consequently, some samples cannot be evaluated, whereas others can be evaluated more than once, meaning that the testing and training subsets can be superimposed.</p>
      <p>The random cross-validation procedure explained above is the best option when the data are not stratified. For this reason, the datasets for breeding programs in the context of multienvironment data are stratified by environments. Therefore, the random cross-validation explained above was modified so it could be implemented in the IBCF.MTME package. For multienvironment data on only one trait, the problem of predicting the performance of lines in environments where they have not been evaluated was considered. This validation design mimics the prediction problem faced by breeders in incomplete field trials where lines have been evaluated in some but not all target environments. The TRN–TST partitions for this prediction problem were obtained as follows: since the total number of records available for the dataset with multienvironments and only one trait is <italic>N</italic> = <italic>J</italic> × <italic>I</italic>, to select the lines in the TST data set, the user fixes the percentage of data to be used for TST (PTesting). We then chose PTesting × <italic>N</italic> (lines) at random; subsequently, one environment per line was randomly picked from the index of environments (<italic>i</italic> = 1, 2, …, <italic>I</italic>). The resulting cells (<italic>ij</italic>) were assigned to the TST dataset and the ones not selected through this algorithm were used for the TRN dataset. Lines were sampled without replacement if <italic>J</italic> ≥ PTesting × <italic>N</italic> and with replacement otherwise (López-Cruz et al., <xref rid="cit0012" ref-type="bibr">2015</xref>). The construction of the TRN–TST datasets for multitrait and multienvironment data was similar to the construction of the multienvironment data explained above. However, since the data are now for multiple traits and multiple environments, we assume that the response variable is missing for all the traits under study and not just for the one missing in the multienvironment dataset. On the other hand, for multitrait data with only one environment, the construction of the TRN–TST datasets was exactly the same as the construction of the multienvironment data, with the assumption that environments are taken as traits.</p>
      <p>We also provide another type of cross-validation that is only useful when we want to predict certain traits of some lines that are missing in one or more years (or environments) but are present in others. However, in this type of cross-validation, there is only one partition (one testing set and one training set; no subsampling); subsequently, in the output for each year–trait or environment–trait combination for both metrics [Pearson’s correlation and mean square error of prediction (MSEP)], it was impossible to estimate the SE. This type of cross-validation is needed when breeders want to predict certain traits for some years (or environments) based on the information for all traits in other years or environments.</p>
      <p>Under all types of scenarios for constructing the TRN–TST dataset for each partition, the IBCF model is fitted with the TRN dataset and calculates predictions for the TST dataset. Finally, with the output of each TST dataset, two metrics (in this package, they were Pearson’s correlation and MSEP) were used to measure prediction accuracy; they were calculated with the information on the observed and predicted values of the testing dataset. The final outputs for both metrics are the arithmetic mean and SE of the random partitions implemented.</p>
      <p>A summary of prediction accuracies is given for trait–environment combinations or trait–year combinations, since it is very important in varietal recommendations to evaluate prediction accuracy at the environment level for genotypes and traits because of the importance of genotype × environment and genotype × environment × trait interactions. As such, in this article, we use “environment” in its general connotation—that is, as synonymous to a region—because, when recommending cultivars, it is often more important to evaluate prediction accuracy when modeling the genotype × region interaction rather than the genotype × environment interaction.</p>
    </sec>
    <sec id="sec2.3">
      <title>About the IBCF.MTME Package</title>
      <p>To start using the package, you will need to install the IBCF.MTME R package (R Core Team, <xref rid="cit0020" ref-type="bibr">2018</xref>) from GitHub via the devtools package, with the command devtools::install_github(’frahik/IBCF.MTME’). To adjust the model with the IBCF() function, first, you have to generate the partitions needed to implement the cross-validation with the auxiliary function CV.RandomPart() as follows:</p>
      <disp-quote>
        <p>CV.RandomPart(Dataset, NPartitions = 10,</p>
        <p>PTesting = .35, Traits.testing = NULL, Set_seed = NULL).</p>
      </disp-quote>
      <p>By default, the function generates 10 random partitions of the dataset; in each partition, 65% of the data is assigned to the training sample and the rest (35%) is assigned to the validation sample. If you want to modify the default values, you can change both parameters. The NPartitions parameter represents the number of partitions generated to implement the cross-validation, PTesting is the percentage of observations used as a validation sample in each partition, and Traits.testing is null by default and uses all the traits in the TST to fit the model; otherwise, those traits specified in Traits.testing are assumed to be missing. On the other hand, Set_seed is the seed to be used when generating random numbers to form random partitions for reproducible research. In other words, the CV.RandomPart() function is used to generate training and validation samples to study the predictive ability under IBCF for the dataset. In addition, the output of this function is an input of the IBCF() function. The dataset object is a data.frame object that contains four columns in the “Tidy Data” format:</p>
      <list list-type="bullet">
        <list-item>
          <p>$Line: The line or genotype identifier; the name of this column can be changed.</p>
        </list-item>
        <list-item>
          <p>$Env: The name of the evaluated environment(s); the name of this column must be respected.</p>
        </list-item>
        <list-item>
          <p>$Trait: the name of the evaluated trait (s); this name must be respected.</p>
        </list-item>
        <list-item>
          <p>$Response: The variable response obtained for the row corresponding to a line, environment, and trait combination; this name should not be modified.</p>
        </list-item>
      </list>
      <p>As output of the above function, a cross-validation object is returned with the following data:</p>
      <list list-type="bullet">
        <list-item>
          <p>Dataset: This is a data.frame object of size <italic>n</italic> × (<italic>m</italic> + 1), where <italic>n</italic> is the number of entered lines under study and <italic>m</italic> is the value that results from multiplying the number of environments under study by the number of evaluated traits. In addition, the first column corresponds to the identifier of each line.</p>
        </list-item>
        <list-item>
          <p>CrossValidation_list: A list that contains the partitions, NPartitions, where each index contains an <italic>n</italic> × <italic>m</italic> dimension matrix, where <italic>n</italic> is the number of lines under study, and <italic>m</italic> is the length of the combination of traits and the environments evaluated; each value should be 1 if the observation will be present in TRN and 2 if the observation will be in TST.</p>
        </list-item>
        <list-item>
          <p>Environments: The name of the evaluated environment(s).</p>
        </list-item>
        <list-item>
          <p>Traits.testing: The names of the traits used as part of TST for traits; this means that the other traits are assumed to be known but these can be missing. If Traits.testing is null, all traits can be missing.</p>
        </list-item>
        <list-item>
          <p>Traits: The name of the evaluated trait(s).</p>
        </list-item>
        <list-item>
          <p>Observations: Unique identifiers found in the dataset.</p>
        </list-item>
        <list-item>
          <p>Class: Cross-validation</p>
        </list-item>
      </list>
      <p>Once the object generated by the previous function has been successfully obtained, the IBCF method can be implemented as follows: IBCF(CrossValidation_Object, dec = 4), with the following parameters:</p>
      <list list-type="bullet">
        <list-item>
          <p>CrossValidation_Object: An object generated by the function CV.RandomPart().</p>
        </list-item>
        <list-item>
          <p>Dec: The number of decimal places to be displayed in the output.</p>
        </list-item>
      </list>
      <p>By using the IBCF() function, an object of the IBCF class is generated, containing the following:</p>
      <list list-type="bullet">
        <list-item>
          <p>NPartitions: The number of random partitions evaluated.</p>
        </list-item>
        <list-item>
          <p>predictions_Summary: A data.frame object with the data summary containing the following columns:</p>
          <list list-type="bullet">
            <list-item>
              <p>Trait_Env: The combination of traits and environments evaluated.</p>
            </list-item>
            <list-item>
              <p>Pearson: The mean Pearson’s correlation obtained from the number of the implemented random partitions.</p>
            </list-item>
            <list-item>
              <p>SE_Cor: The SE of the mean Pearson’s correlation,</p>
            </list-item>
            <list-item>
              <p>MSEP: The mean square error of prediction calculated from the number of random partitions implemented.</p>
            </list-item>
            <list-item>
              <p>SE_MSEP: The SE of the MSEP.</p>
            </list-item>
          </list>
        </list-item>
        <list-item>
          <p>observed: All values used to fit the model.</p>
        </list-item>
        <list-item>
          <p>yHat: All predicted values.</p>
        </list-item>
        <list-item>
          <p>predicted_Partition: A list of matrices with the predicted values for each partition.</p>
        </list-item>
        <list-item>
          <p>Data.Obs_Pred: A data.frame object in matrix form to obtain the $observed and the predicted values ($yHat) that contains the following columns:</p>
          <list list-type="bullet">
            <list-item>
              <p>Gids: Line or genotype identifier; the name of this column may be changed.</p>
            </list-item>
            <list-item>
              <p>Traits_Env: Contains the entered trait–environment combinations under study.</p>
            </list-item>
            <list-item>
              <p>Traits_Env.1: Contains the predicted values of the trait–environment combinations evaluated.</p>
            </list-item>
          </list>
        </list-item>
        <list-item>
          <p>Class: IBCF.</p>
        </list-item>
      </list>
      <p>The package also includes a variation of the IBCF() function dedicated to studying predictive ability. For example, when we are interested in predicting all lines in a year or years or if we want to use information from other years as TRN. This function is denoted as: IBCF.Years(Dataset, colYears = 1, Years.testing = “ ”, Traits.testing = “ ”). For this, the parameters required as input are as follows:</p>
      <list list-type="bullet">
        <list-item>
          <p>Dataset: A data.frame with at least three columns distributed in the matrix format, where the first $Years column must contain the identifier of each year under study, the next column gives the identifier of each line or genotype, and the following columns give the traits evaluated for each line in each year.</p>
        </list-item>
        <list-item>
          <p>colYears: The name or position of the column containing all years; by default, this column is the first column of the dataset.</p>
        </list-item>
        <list-item>
          <p>Years.testing: A vector that contains some of the years entered in the first column of the dataset object to use as testing values to fit the model. It is important to mention that the vector Years.testing must contain at least 1 yr and should be less than all the years under study; otherwise, there will be no information for the training model.</p>
        </list-item>
        <list-item>
          <p>Traits.testing: A vector that contains some of the names corresponding to the columns that identify the traits; this vector indicates the traits that will be used to form the validation sample. It is important for the length of the vector Traits.testing to be less than the total number of traits under study.</p>
        </list-item>
      </list>
      <p>The output of IBCF.Years() results in an object that contains the following:</p>
      <list list-type="bullet">
        <list-item>
          <p>Years.testing: Contains the names of the years used as testing.</p>
        </list-item>
        <list-item>
          <p>Traits.testing: Contains the traits used as testing.</p>
        </list-item>
        <list-item>
          <p>predictions_Summary: A data.frame object that contains the following columns:</p>
          <list list-type="bullet">
            <list-item>
              <p>Year_Trait: The combination of the year with the evaluated trait.</p>
            </list-item>
            <list-item>
              <p>Pearson: The mean Pearson’s correlation obtained.</p>
            </list-item>
            <list-item>
              <p>MSEP: The mean square error of prediction calculated.</p>
            </list-item>
          </list>
        </list-item>
        <list-item>
          <p>observed: A vector with the observed values;</p>
        </list-item>
        <list-item>
          <p>predicted: A vector with the predicted values;</p>
        </list-item>
        <list-item>
          <p>Data.Obs_Pred: A data.frame object that contains the following columns:</p>
          <list list-type="bullet">
            <list-item>
              <p>Years: Contains the years used in the cross-validation as testing.</p>
            </list-item>
            <list-item>
              <p>Gids: Line or genotype identifier; the name of this column may be changed.</p>
            </list-item>
            <list-item>
              <p>Traits: Contains the entered observations of the evaluated traits.</p>
            </list-item>
            <list-item>
              <p>Traits.1: Contains the predictions of the evaluated traits.</p>
            </list-item>
          </list>
        </list-item>
        <list-item>
          <p>Class: IBCFY.</p>
        </list-item>
      </list>
    </sec>
    <sec id="sec2.4">
      <title>Useful Functions of the Package</title>
      <p>The package includes two other tools for data transformation that make the user’s work easier.</p>
      <sec id="s2d1">
        <title>The getMatrixForm() Function</title>
        <p>The getMatrixForm(TidyDataset, onlyTrait = FALSE) function is used for transforming the tidy data into the matrix form required by the program and requires the following parameters:</p>
        <list list-type="bullet">
          <list-item>
            <p>TidyDataset: A data.frame object that contains four columns:</p>
            <list list-type="bullet">
              <list-item>
                <p>$Line: The line or genotype identifier; the name of this column may change.</p>
              </list-item>
              <list-item>
                <p>$Env: The name of the evaluated environment(s); the name of this column cannot be changed.</p>
              </list-item>
              <list-item>
                <p>$Trait: The name of the evaluated trait(s); the name of this column cannot be changed.</p>
              </list-item>
              <list-item>
                <p>$Response: The variable response obtained for the rows corresponding to the combinations of line, environment and trait; the name of this column cannot be changed.</p>
              </list-item>
            </list>
          </list-item>
          <list-item>
            <p>onlyTrait: Logical value that, by default, is FALSE and uses the $Trait and $Env columns for the matrix format; if true, it only uses the $Trait column.</p>
          </list-item>
        </list>
        <p>The output of this function is a data.frame object of <italic>n</italic> × (<italic>m</italic> + 1) dimensions, where <italic>n</italic> is the number of lines entered (without repetition) and <italic>m</italic> is the length of the combination of traits and environments plus the first column of the corresponding lines.</p>
      </sec>
      <sec id="s2d2">
        <title>The getTidyForm() Function</title>
        <p>The getTidyForm(Mat, onlyTrait = FALSE) is the inverse function of getMatrixForm() and converts a data matrix form to a Tidy Data form; to use this function, the following parameters are required:</p>
        <list list-type="bullet">
          <list-item>
            <p>Mat: A data.frame object of a <italic>n</italic> × (<italic>m</italic> + 1) dimensions, where <italic>n</italic> is the number of lines under study and <italic>m</italic> is the length of the combination of traits and environments under study plus the first column corresponding to the lines.</p>
          </list-item>
          <list-item>
            <p>onlyTrait: A logical value; by default, it is false and ignores the first column to transform the rest of the columns with the expected ‘Trait_Env’ names format and summarizes the data in three columns: $Trait, $Env, and $Response. If the value is true, it ignores the first two columns to transform the rest of the columns, considering them as the evaluated traits, and summarizes them in two columns: $Trait and $Response.</p>
          </list-item>
        </list>
        <p>The output of this function is a data.frame object with transformed data of <italic>q</italic> × 4 dimensions, where <italic>q</italic> results from the product of the number of lines, the number of environments, and the number of traits evaluated and 4 represents the number of columns corresponding to lines, environments, traits, and responses.</p>
      </sec>
    </sec>
    <sec id="sec2.5">
      <title>Wheat Dataset</title>
      <p>The package includes a dataset used in a study by Montesinos-López et al. (<xref rid="cit0019" ref-type="bibr">2018</xref>). This dataset, called <italic>Wheat_IBCF</italic>, consists of 250 wheat lines evaluated in three environments with four traits (i.e., 3000 observations).</p>
      <p>You must use the data() function.</p>
      <disp-quote>
        <p>data(‘Wheat_IBCF’)</p>
      </disp-quote>
      <p>The data are contained in a data.frame object divided as follows:</p>
      <list list-type="bullet">
        <list-item>
          <p>$GID: The genotype identifier (with 250 different identifiers).</p>
        </list-item>
        <list-item>
          <p>$Trait: The name of the evaluated traits (with four different traits).</p>
        </list-item>
        <list-item>
          <p>$Env: The name of the evaluated environments (with three different environments).</p>
        </list-item>
        <list-item>
          <p>$Response: The wheat yield for the corresponding combination of traits, environments, and lines (with 3000 observations).</p>
        </list-item>
      </list>
      <p>To see more details on this dataset, we will use the head() function to obtain the first six observations:</p>
      <disp-quote>
        <p>head(Wheat_IBCF)</p>
        <p>##     GID    Trait  Env  Response</p>
        <p>## 1 6569128  DH Bed2IR -17.565895</p>
        <p>## 2 6688880  DH Bed2IR   -4.565895</p>
        <p>## 3 6688916  DH Bed2IR   -3.565895</p>
        <p>## 4 6688933  DH Bed2IR   -4.565895</p>
        <p>## 5 6688934  DH Bed2IR   -7.565895</p>
        <p>## 6 6688949  DH Bed2IR   -7.565895</p>
      </disp-quote>
      <p>The dataset is in the Tidy Data format, meaning that each column represents a variable, each row is an observation, and each cell is the value belonging to the combination of trait, line, and environment. This way of preparing a dataset was proposed by Wickham (<xref rid="cit0023" ref-type="bibr">2014</xref>). To observe the entire structure of the dataset, we use the str() function:</p>
      <disp-quote>
        <p>str(Wheat_IBCF)</p>
        <p>## ‘data.frame’:  3000 obs. of 4 variables:</p>
        <p>## $ GID   : int 6569128 6688880 6688916 6688933 6688934 6688949 6689268 6689407 6689482 6689550 …</p>
        <p>## $ Trait     : chr “DH” “DH” “DH” “DH” …</p>
        <p>## $ Env   : chr “Bed2IR” “Bed2IR” “Bed2IR” “Bed2IR” …</p>
        <p>## $ Response: num -17.57 -4.57 -3.57 -4.57 -7.57 …</p>
      </disp-quote>
      <p>We have 3000 observations for four variables in this dataset, which is consistent with the explanation above.</p>
    </sec>
    <sec id="sec2.6">
      <title>Year Dataset</title>
      <p>The package includes a dataset based on simulated data; Appendix A includes the code used to simulate this dataset. The dataset, called <italic>Year_IBCF</italic>, consists of 60 lines evaluated in the 3 yr under study (20 lines per year) for 12 traits, which gives a total of 720 observations.</p>
      <p>The data() function must be used to load the data.</p>
      <disp-quote>
        <p>data(‘Year_IBCF’)</p>
      </disp-quote>
      <p>The data are contained in a data.frame object divided as follows:</p>
      <list list-type="bullet">
        <list-item>
          <p>Years: Each year where each line was evaluated,</p>
        </list-item>
        <list-item>
          <p>Gid: The identifier of each line evaluated,</p>
        </list-item>
        <list-item>
          <p>Trait: The name of each trait evaluated, and</p>
        </list-item>
        <list-item>
          <p>Response: The response variable corresponding to a line or trait in each year.</p>
        </list-item>
      </list>
      <p>Again, to see how this dataset is composed, you can use head(Year_IBCF) to see the first six observations.</p>
      <p>Note that this dataset is also in Tidy Data format and the structure of the object is as follows:</p>
      <disp-quote>
        <p>str(Year_IBCF)</p>
        <p>## ‘data.frame’:  720 obs. of 4 variables:</p>
        <p>## $ Years    : num 2014 2014 2014 2014 2014 …</p>
        <p>## $ Gids     : num 1 2 3 4 5 6 7 8 9 10 …</p>
        <p>## $ Trait     : chr   “T1” “T1” “T1” “T1” …</p>
        <p>## $ Response: num 5.14 5.68 4.85 3.57 5.02 …</p>
      </disp-quote>
      <p>Note that it is consistent with the explanation above: 720 observations of four variables.</p>
    </sec>
  </sec>
  <sec id="sec3">
    <title>EXAMPLES</title>
    <p>This section illustrates the use of the <bold>IBCF.MTME</bold> package and gives several examples of GS to predict continuous traits.</p>
    <sec id="sec3.1">
      <title>Example 1: Data Transformation</title>
      <p>In this example, you will find more details about the two formats established in this package for data processing. First, you will find the Tidy Data format and then the matrix format. The function getMatrixForm() is useful for transforming a dataset from the Tidy Data format to the matrix format, whereas the getTidyForm() transforms a dataset from the matrix format to the Tidy Data format. The two datasets provided in the package are in Tidy Data format, so we will use the Wheat_IBCF dataset to exemplify how to use these two functions.</p>
      <p>First, in a clean R environment, the IBCF.MTME library should be loaded and, with it, the Wheat_IBCF dataset through the use of the data() command, as shown in the following code block:</p>
      <disp-quote>
        <p>rm(<underline>list =</underline> ls())</p>
        <p>library(IBCF.MTME)</p>
        <p>data(‘Wheat_IBCF’)</p>
      </disp-quote>
      <p>Once the data are loaded, the head() function shows that this dataset is in the Tidy Data format, since it only has four columns corresponding to lines [genotypic identifier of lines (GID)], traits (Trait), environments (Env), and the response variables (Response). In this dataset, GID is the identifier of the lines.</p>
      <disp-quote>
        <p>head(Wheat_IBCF)</p>
        <p>##     GID  Trait   Env  Response</p>
        <p>## 1 6569128   DH Bed2IR -17.565895</p>
        <p>## 2 6688880   DH Bed2IR   -4.565895</p>
        <p>## 3 6688916   DH Bed2IR   -3.565895</p>
        <p>## 4 6688933   DH Bed2IR   -4.565895</p>
        <p>## 5 6688934   DH Bed2IR   -7.565895</p>
        <p>## 6 6688949   DH Bed2IR   -7.565895</p>
      </disp-quote>
      <p>The $GID column contains the identifier of each line, days to heading (DH) is the trait evaluated in the first six observations for the “bed planting system with two irrigations” (Bed2IR) environment, and the $Response column stores the responses obtained for each row that corresponds to a specific line, trait, or environment. We can observe the dimension of this dataset through the dim(Wheat_IBCF) command, which indicates that this dataset has 3000 rows and four columns. In addition, if we are looking to transform this format into the matrix format, we can do it through the getMatrixForm() function. The first six observations can be seen with the head() command, as detailed below:</p>
      <disp-quote>
        <p>M &lt;- getMatrixForm(Wheat_IBCF)</p>
        <p>head(M)</p>
        <p>##  GID  DH_Bed2IR  DH_Bed5IR  DH_Drip  GY_Bed2IR  GY_Bed5IR  GY_Drip</p>
        <p>## 1 6569128 -17.565895 1.6923078 0.945047 -0.35188724 -0.38496851 -0.44365852</p>
        <p>## 2 6688880 -4.565895 -0.3076922 0.945047 -0.61107566 -0.29930171 -0.19868885</p>
        <p>## 3 6688916 -3.565895 -1.3076922 -2.054953 -0.03534797 -0.30202380 -0.09566196</p>
        <p>## 4 6688933 -4.565895 -3.3076922 -1.054953 -0.11721194 0.08545996 -0.03161493</p>
        <p>## 5 6688934 -7.565895 -3.3076922 -0.054953 0.05415546 -0.24010219 -0.35510868</p>
        <p>## 6 6688949 -7.565895 -6.3076922 -2.054953 -0.48406932 0.19542652 -0.04798615</p>
        <p>##  NDVI_Bed2IR  NDVI_Bed5IR  NDVI_Drip  PH_Bed2IR  PH_Bed5IR  PH_Drip</p>
        <p>## 1 -0.016692414 -0.002449404 0.006528357 -6.968964 -1.282471 3.6682234</p>
        <p>## 2 -0.016657172 -0.011380990 -0.022684209 -11.030829 -8.725086 -3.6481125</p>
        <p>## 3 0.002233731 -0.000877320 -0.030087900 -10.494572 -6.680635 -6.1052408</p>
        <p>## 4 -0.009772406 -0.011128989 0.003965353 -4.033027 -5.546853 0.7411906</p>
        <p>## 5 -0.002767986 -0.010064999 0.008624755 -12.103778 -11.590284 -6.4430134</p>
        <p>## 6 -0.015566957 0.002153392 -0.021943740 -5.316197 -1.954483 3.0296975</p>
      </disp-quote>
      <p>Note that the first column does not appear to be completely altered; however, in this column, the identifiers of the line now appear without repetition but in subsequent columns, the names are the combinations of the traits and environments. Therefore, each value represents the observation measured in each line for a given trait–environment combination. The data have been considerably reduced, with the dim(M) function are shown to have 250 rows and 13 columns. The size of the dataset is now 250 rows that correspond to the unique identifiers of the lines; the columns correspond to 12 different trait–environment combinations plus the column of the line identifiers. This format is popular among researchers because of the compact way it represents the data. However, the cross-validation function of the package requires the tidy format to work, so if you do not have a set of data in this format, you need to convert them to the tidy format with the getTidyForm() function. In this example, we will obtain the original version of the dataset again, as shown in the following block form:</p>
      <disp-quote>
        <p>Tidy &lt;- getTidyForm(M)</p>
      </disp-quote>
      <p>With the head() command, the data are once again in the Tidy Data format:</p>
      <disp-quote>
        <p>head(Tidy)</p>
        <p>##     GID    Trait    Env    Response</p>
        <p>## 1 6569128   DH Bed2IR -17.565895</p>
        <p>## 2 6688880   DH Bed2IR   -4.565895</p>
        <p>## 3 6688916   DH Bed2IR   -3.565895</p>
        <p>## 4 6688933   DH Bed2IR   -4.565895</p>
        <p>## 5 6688934   DH Bed2IR   -7.565895</p>
        <p>## 6 6688949   DH Bed2IR   -7.565895</p>
      </disp-quote>
      <p>This fact can also be verified through the dimensions of the dataset with the dim(Tidy) function, which shows it has 3000 rows and four columns.</p>
      <sec id="sec3.2">
        <title>Example 2: Predictions with a Single Environment and Multiple Traits</title>
        <p>This example shows how to study prediction accuracy when the data only have one environment and four traits. This is done with the Wheat_IBCF dataset included in the package. The following code block is used to load this dataset:</p>
        <disp-quote>
          <p>rm(<underline>list =</underline> ls())</p>
          <p>library(IBCF.MTME)</p>
          <p>data(‘Wheat_IBCF’)</p>
        </disp-quote>
        <p>With this, we loaded the object Wheat_IBCF, which was described in the wheat dataset section. Although this dataset has information from four environments, we will only work with the Bed5IR environment; therefore, the dataset to use is:</p>
        <disp-quote>
          <p>Dataset &lt;- Wheat_IBCF[which(Wheat_IBCF$Env == ‘Bed5IR’), ]</p>
        </disp-quote>
        <p>With dim(Dataset), we get that the dimension of this dataset that is 1000 rows and four columns. The matrix has been reduced from 3000 rows (observations) to 1000. Next, we use the CV.RandomPart() function to obtain the partitions of the sample for cross-validation:</p>
        <disp-quote>
          <p>CrossV &lt;- CV.RandomPart(Dataset, <underline>NPartitions =</underline> 10, <underline>PTesting =</underline> 0.25, <underline>Set_seed =</underline> 5)</p>
        </disp-quote>
        <p>“Dataset” is the dataset in tidy format that contains information on the multitrait and multienvironment experiment; with NPartitions = 10, you are specifying that you want to make a cross-validation with 10 random partitions; and with PTesting = 0.25, you are specifying that 25% of the whole dataset in each partition will be assigned to TST and the remaining 75% to TRN. In addition, you must specify the number of seeds needed to obtain a reproducible work, regardless of the operating system and the person who runs it.</p>
        <p>We now have an object of the “CrossValidation” class that has been named CrossV; its structure can be obtained via R with str(CrossV). This object contains the new $Dataset with the matrix format automatically, 10 matrices that are part of each random partition of the required cross-validation, the environments and features that were recognized by the function, and the number of observations.</p>
        <p>With this object, it is possible to perform a cross-validation study with the model by simply calling the IBCF() function and inserting this object as a parameter; the predictive model will be adjusted automatically.</p>
        <disp-quote>
          <p>pm1 &lt;- IBCF(CrossV)</p>
        </disp-quote>
        <p>To view the results provided by this function, simply use the summary() function on the object where the results were stored, as shown below:</p>
        <disp-quote>
          <p>summary(pm1)</p>
          <p>##       Trait_Env Pearson SE_Cor  MSEP   SE_MSEP</p>
          <p>## 1   DH_Bed5IR  0.3488   0.0242    33.4035    1.5099</p>
          <p>## 2   GY_Bed5IR  0.1637   0.0325   0.1106    0.0062</p>
          <p>## 3 NDVI_Bed5IR   0.5794   0.0370   0.0001    0.0000</p>
          <p>## 4   PH_Bed5IR   0.0602   0.0241    41.7650    1.4914</p>
        </disp-quote>
        <p>As a result of the summary() function, five columns are obtained. The first corresponds to the trait–environment combination for which prediction accuracies are provided under two metrics: Pearson’s correlation and MSEP. The second column provides the average predictive ability of the partitions implemented in terms of Pearson’s correlation and the third column provides the SE of the mean Pearson’s correlation given in Column 2. In the fourth column, the average MSEP of the randomly implemented partitions are given, and in the last column, the corresponding SE for the MSEP are provided.</p>
        <p>To further understand the structure of this object, we can use the str(pm1) command. Use of this command shows that this object contains six components: the number of partitions evaluated; the summary of the predictions [which is retrieved through the summary() function]; the observed values and predicted values, which also appear in $Data.Obs_Pred ordered by the line identifier; and the trait–environment combination. The predictions obtained in each partition also appear. Below we show the first six observed and predicted values obtained by the model:</p>
        <disp-quote>
          <p>head(pm1$Data.Obs_Pred)</p>
          <p>##   GID  DH_Bed5IR  GY_Bed5IR  NDVI_Bed5IR  PH_Bed5IR  DH_Bed5IR.1  …  PH_Bed5IR.1</p>
          <p>## 1 6569128 1.6923078 -0.38496851 -0.002449404 -1.282471 -3.42715638 … -6.3549369</p>
          <p>## 2 6688880 -0.3076922 -0.29930171 -0.011380990 -8.725086 -6.81057189 … -6.3010208</p>
          <p>## 3 6688916 -1.3076922 -0.30202380 -0.000877320 -6.680635 -3.53399864 … -5.6198338</p>
          <p>## 4 6688933 -3.3076922 0.08545996 -0.011128989 -5.546853 -4.36973174 … -2.6316550</p>
          <p>## 5 6688934 -3.3076922 -0.24010219 -0.010064999 -11.590284 -6.49925946 … -6.3959559</p>
          <p>## 6 6688949 -6.3076922 0.19542652 0.002153392 -1.954483 -0.07608169 … -0.7451675</p>
        </disp-quote>
        <p>These are the trait–environment combinations of observed and predicted values, those that appear in the output above without .1, after the name of the trait-environment combination correspond to the observed values, while those with .1 after the trait-environment combination correspond to the predicted values. In addition, a plot can be made with the summarized predictions for the trait-environment combinations under study. For example, <xref ref-type="fig" rid="f0001">Fig. 1a</xref> was obtained via the plot(…) function by entering the IBCF object, generated with the IBCF() function. The “select” parameter allows you to obtain a graph with a summary of the predictions with the Pearson’s correlation or MSEP metric.</p>
        <fig id="f0001" orientation="portrait" position="float">
          <label>Fig. 1</label>
          <caption>
            <p>Prediction accuracy in terms of (a) Pearson’s correlation and (b) mean square error of prediction (MSEP) of the item-based collaborative filtering (IBCF) model for each trait–environment combination. The data are only from an environment called ‘Bed5IR’ (bed planting system with five irrigations).</p>
          </caption>
          <graphic xlink:href="TPG-11-03-0013-g001"/>
        </fig>
        <disp-quote>
          <p>par(<underline>mai =</underline> c(2, 1, 1, 1))</p>
          <p>plot(pm1, <underline>select =</underline> ‘Pearson’)</p>
        </disp-quote>
        <p>Note that the code of the par() function has served as an auxiliary to adjust the margins of the plot, since the names on the <italic>x</italic> axis cannot be longer than what the plot’s default parameters can support. The parameter mai allows us to modify the distance between the margins of the plot and the edge of the image. In other words, the first value corresponds to the margin with respect to the lower part of the graph, the second value with respect to the left part of the graph, the third value with respect to the upper part of the graph, and the last value with respect to the right part of the graph.</p>
        <p><xref ref-type="fig" rid="f0001">Figure 1a</xref> shows Pearson’s correlation along with its corresponding confidence interval for each trait–environment combination. The results are sorted: on the left side are the trait–environment combinations with the lowest prediction abilities; on the right side are the trait–environment combinations with the best prediction abilities.</p>
        <p>It is also possible to plot the results obtained with the MSEP metric; it is enough to change MSEP in the “select” parameter. <xref ref-type="fig" rid="f0001">Figure 1b</xref> was generated with the code shown below.</p>
        <disp-quote>
          <p>plot(pm1, <underline>select =</underline> ‘MSEP’)</p>
        </disp-quote>
      </sec>
      <sec id="sec3.3">
        <title>Example 3: Predictions with Many Environments and Traits</title>
        <p>This example shows how to study the prediction ability of a dataset containing three environments and four traits. The whole Wheat_IBCF dataset included in the package is also used for this purpose. The way the data are loaded is the same as in the previous example, so this step was omitted. Therefore, the partitions are first generated for cross-validation and then the model is adjusted with the IBCF() function, as shown below.</p>
        <disp-quote>
          <p>CrossV &lt;- CV.RandomPart(Wheat_IBCF, <underline>NPartitions =</underline> 10, <underline>PTesting =</underline> 0.25, <underline>Set_seed =</underline> 5)</p>
          <p>pm3 &lt;- IBCF(CrossV)</p>
        </disp-quote>
        <p>Once the model has been adjusted, the results can be consulted through the summary() function, as shown in the following code.</p>
        <disp-quote>
          <p>summary(pm3)</p>
          <p>##    Trait_Env  Pearson SE_Cor    MSEP SE_MSEP</p>
          <p>## 1   DH_Bed2IR   0.8201   0.0208  15.5682  1.7460</p>
          <p>## 2   DH_Bed5IR   0.8920   0.0160    8.0849  1.3425</p>
          <p>## 3     DH_Drip   0.9235   0.0068    1.9281  0.0988</p>
          <p>## 4   GY_Bed2IR   0.0978   0.0483    0.3121  0.0194</p>
          <p>## 5   GY_Bed5IR   0.5768   0.0225    0.0605  0.0040</p>
          <p>## 6     GY_Drip   0.5591   0.0212    0.1388  0.0093</p>
          <p>## 7 NDVI_Bed2IR   0.7356   0.0192    0.0001  0.0000</p>
          <p>## 8 NDVI_Bed5IR   0.8321   0.0090    0.0001  0.0000</p>
          <p>## 9   NDVI_Drip   0.7160   0.0292    0.0002  0.0000</p>
          <p>## 10    PH_Bed2IR   0.3281   0.0374  12.6455  0.7628</p>
          <p>## 11    PH_Bed5IR   0.5436   0.0194  28.6222  0.9848</p>
          <p>## 12   PH_Drip   0.5356   0.0194  24.9261  1.0128</p>
        </disp-quote>
        <p>The only difference between the output of the summary and that of the two previous examples is that now the first column contains predictions for all combinations of four traits and three environments (i.e., 12 combinations in total).</p>
        <p>Likewise, to obtain the summary of prediction ability with MSEP (or Pearson’s correlation) for each trait-environment combination, the following code can be used:</p>
        <disp-quote>
          <p>par(<underline>mai =</underline> c(2, 1, 1, 1))</p>
          <p>plot(pm3, <underline>select =</underline> ‘MSEP’)</p>
        </disp-quote>
        <p><xref ref-type="fig" rid="f0002">Figure 2</xref> shows that the best predictions in terms of MSEP were observed for the Normalized Difference Vegetation Index trait in all environments under study, whereas the worst predictions were observed for the plant height trait in the ‘bed planting system with five irrigations” (Bed5IR) and drip irrigation (Drip) environments. If we want to plot the prediction accuracies in terms of Pearson’s correlation, then change the select parameter to ‘Pearson’.</p>
        <fig id="f0002" orientation="portrait" position="float">
          <label>Fig. 2</label>
          <caption>
            <p>Prediction abilities, in terms of mean square error of prediction (MSEP), of the model for each trait–environment combination. The data correspond to the Wheat_IBCF dataset with four traits and three environments.</p>
          </caption>
          <graphic xlink:href="TPG-11-03-0013-g002"/>
        </fig>
      </sec>
      <sec id="sec3.4">
        <title>Example 4: Predictions for Multiple Environments and Multiple Traits with Only Two Traits as Testing</title>
        <p>This example shows how to study the predictive capability of a dataset with multiple environments and multiple traits with only two traits as testing. The dataset used is the same as the one in the previous examples, so we omitted the process of loading the dataset. With the CV.RandomPart() function, we then obtained the partitions required for implementing cross-validation.</p>
        <disp-quote>
          <p>CrossV &lt;- CV.RandomPart(Wheat_IBCF, <underline>Traits.testing =</underline> c(‘DH’, ‘GY’), <underline>NPartitions =</underline> 10,</p>
          <p><underline>PTesting =</underline> 0.25, <underline>Set_seed =</underline> 123)</p>
        </disp-quote>
        <p>We also generated 10 random partitions; in each partition, 25% of the data should be assigned to the TST dataset and the remaining 75% to the TRN dataset. The only traits that should be predicted by the model are DH and grain yield (GY). With this object, we can perform a cross-validation study with the following code:</p>
        <disp-quote>
          <p>pm2 &lt;- IBCF(CrossV)</p>
        </disp-quote>
        <p>To view the output, simply use the summary() function with the object where the results were stored, as shown below.</p>
        <disp-quote>
          <p>summary(pm2)</p>
          <p>##     Trait_Env Pearson  SE_Cor    MSEP  SE_MSEP</p>
          <p>## 1 DH_Bed2IR   0.8769   0.0121  10.6964    0.8170</p>
          <p>## 2 DH_Bed5IR   0.8749   0.0185    9.6067    1.5266</p>
          <p>## 3   DH_Drip   0.9208   0.0064    2.0380    0.1339</p>
          <p>## 4 GY_Bed2IR   0.1819   0.0384    0.2607    0.0136</p>
          <p>## 5 GY_Bed5IR   0.6432   0.0213    0.0544    0.0032</p>
          <p>## 6   GY_Drip   0.6593   0.0120    0.1148    0.0068</p>
        </disp-quote>
        <p>It is important to point out that now the summary of the prediction ability only contains information for all the environments evaluated and for the traits specified in the traits TST set. To obtain the plot of the summary of prediction abilities in terms of Pearson’s correlation for each trait–environment combination, it is not necessary to specify the “select” parameter, as shown below.</p>
        <disp-quote>
          <p>par(<underline>mai =</underline> c(2, 1, 1, 1))</p>
          <p>plot(pm2)</p>
        </disp-quote>
        <p><xref ref-type="fig" rid="f0003">Figure 3a</xref> shows the results for only two traits (DH and GY) that were specified in the Traits.testing argument and for the three different environments, with their respective confidence intervals. Similarly, the following code can be used to observe predictive capability in MSEP terms (<xref ref-type="fig" rid="f0003">Fig. 3b</xref>):</p>
        <fig id="f0003" orientation="portrait" position="float">
          <label>Fig. 3</label>
          <caption>
            <p>Prediction accuracy in terms of (a) Pearson’s correlation and (b) mean square error of prediction (MSEP) of the item-based collaborative filtering (IBCF) model for each trait in three environments. The data correspond to the Wheat_IBCF dataset.</p>
          </caption>
          <graphic xlink:href="TPG-11-03-0013-g003"/>
        </fig>
        <disp-quote>
          <p>par(<underline>mai =</underline> c(2, 1, 1, 1))</p>
          <p>plot(pm2, <underline>select =</underline> ‘MSEP’)</p>
        </disp-quote>
      </sec>
      <sec id="sec3.5">
        <title>Example 5: Predictions for 2015 and 2016 with 2014 as Training</title>
        <p>This example shows how to make predictions with the IBCF package when you have several traits under study and you want to predict some of them for the following years, but with information on the remaining traits in all the years that conform the training and testing data sets. This is done with the Year_IBCF dataset included in the package. The following code is used to load this dataset:</p>
        <disp-quote>
          <p>rm(<underline>list =</underline> ls())</p>
          <p>library(IBCF.MTME)</p>
          <p>data(“Year_IBCF”)</p>
        </disp-quote>
        <p>This loads the Year_IBCF object into the R environment. However, the IBCF.Years command requires the data in matrix format and because now the dataset is in Tidy Data format, we will need to transform it into the matrix format so that can be used for the IBCF.Years command. This is achieved automatically with the getMatrixForm() function, as shown below.</p>
        <disp-quote>
          <p>Dataset &lt;- getMatrixForm(Year_IBCF, <underline>onlyTrait =</underline> T)</p>
        </disp-quote>
        <p>Notice that onlyTrait = T has been specified to take the years as the first column, respecting the formatting set for the package. The dataset has been transformed from a Tidy Data format to the matrix format required by the IBCF.MTME package by consulting the first six observations through the head() command.</p>
        <disp-quote>
          <p>head(Dataset)</p>
          <p>##   Years Gids  T1  T10  T11  T12  T2  T3  …  T9</p>
          <p>## 1 2014 1 5.144009 8.514278 7.089700 9.167756 6.214348 7.538577 … 8.361184</p>
          <p>## 2 2014 2 5.678792 8.215685 7.896449 9.944295 5.806136 7.899465 … 8.672661</p>
          <p>## 3 2014 3 4.854895 7.725762 5.781978 7.530579 4.061641 6.119972 … 7.056119</p>
          <p>## 4 2014 4 3.570019 8.570091 5.733429 7.499954 4.583116 5.224950 … 6.488097</p>
          <p>## 5 2014 5 5.018380 8.573483 6.974145 9.030811 4.981920 5.651253 … 6.540473</p>
          <p>## 6 2014 6 3.196160 6.835883 5.123118 7.398668 5.812636 4.805169 … 5.847054</p>
        </disp-quote>
        <p>To fit the model, we will use a modified version of the main function, which we denote as IBCF.Years(), which receives the dataset in matrix format as a parameter and the years and traits to be used as the testing set.</p>
        <disp-quote>
          <p>pm4 &lt;- IBCF.Years(Dataset, <underline>Years.testing =</underline> c(‘2015’, ‘2016’), <underline>Traits.testing =</underline> c(‘T5’, ‘T6’))</p>
        </disp-quote>
        <p>Once the model is fitted, a summary of the predictions can be retrieved through the summary() command, as detailed below.</p>
        <disp-quote>
          <p>summary(pm4)</p>
          <p>##      Year_Trait  Pearson  MSEP</p>
          <p>## 2015_T5  2015_T5   0.8582  0.3525</p>
          <p>## 2015_T6  2015_T6   0.8475  0.3245</p>
          <p>## 2016_T5  2016_T5   0.7953  0.3525</p>
          <p>## 2016_T6  2016_T6   0.8539  0.3245</p>
        </disp-quote>
        <p>Note that the function returns prediction accuracies for year–trait combinations under Pearson’s correlation and MSEP. Other components that this object contains can be observed by using the str(pm4) command. This object of the IBCFY class contains a list with six values. In this case, it contains the 2 yr used for the testing set (2015 and 2016), as well as the traits in TST: T5 and T6. It also contains a data.frame object that contains the summary of the predictions, which is shown through the summary() function. The object also provides the $observed and $predicted values. Finally, we have another data.frame object that can be retrieved as $Data. Obs_Pred, which contains the original array, along with duplicate features that correspond to the predicted values. Columns that have been added with the suffix “.1” represent the predictions made by the model for each of the traits in TST.</p>
        <p>Next, we show the first six observations for the testing of year 2015 with the observed predicted values that return the algorithm.</p>
        <disp-quote>
          <p>head(pm4$Data_Obs_Pred)</p>
          <p>##  Years  Gids     T5       T6    T5.1   T6.1</p>
          <p>## 21 2015  21  8.181751  6.912622  7.529652  7.007596</p>
          <p>## 22 2015  22  6.865868  6.388473  7.163454  6.574511</p>
          <p>## 23 2015  23  7.072818  6.282973  6.575581  6.110108</p>
          <p>## 24 2015  24  9.529347  8.118168  8.462467  7.813604</p>
          <p>## 25 2015  25  6.741211  6.101720  6.891962  6.325226</p>
          <p>## 26 2015  26  7.693102  7.158682  7.329256  6.704499</p>
        </disp-quote>
        <p>Note that Columns T5 and T6 are the observed values of the original dataset for these traits, whereas Columns T5.1 and T6.1 are the predicted values generated by the model for these traits. We can also make a plot with the summary of the predictions in terms of Pearson’s correlation (or MSEP) for the year–trait combinations, as shown in <xref ref-type="fig" rid="f0004">Fig. 4a</xref>. However, there are now no estimates of the SE because there was no resampling to form the TRN and TST dataset. This plot is obtained with the barplot() function:</p>
        <fig id="f0004" orientation="portrait" position="float">
          <label>Fig. 4</label>
          <caption>
            <p>Prediction accuracy in terms of (a) Pearson’s correlation and (b) mean square error of prediction (MSEP) of the item-based collaborative filtering (IBCF) model for each year–trait combination. The data correspond to the dataset “Year_dataset”.</p>
          </caption>
          <graphic xlink:href="TPG-11-03-0013-g004"/>
        </fig>
        <disp-quote>
          <p>barplot(pm4, <underline>select =</underline> ‘Pearson’)</p>
        </disp-quote>
        <p><xref ref-type="fig" rid="f0004">Figure 4a</xref> shows that the worst predictions in terms of Pearson’s correlation are observed in Trait T5 for 2016, whereas similar predictions are obtained in the other year–trait combinations.</p>
        <p>The “select” parameter can also be modified to obtain the predictions in terms of MSEP, as shown in <xref ref-type="fig" rid="f0004">Fig. 4b</xref>, using the following code: barplot(pm4, select = ‘MSEP’). <xref ref-type="fig" rid="f0004">Figure 4b</xref> shows that the best predictions in terms of MSEP are observed for Trait T6 in all the years under study, whereas the worst predictions are for Trait T5.</p>
      </sec>
      <sec id="sec3.6">
        <title>Example 6: Predictions for 2016 with 2014 and 2015 as Training</title>
        <p>This example shows how to make predictions with the IBCF package when you have several traits under study and you want to predict Traits T5 and T6 in 2016 with 2 yr (2014 and 2015) as training but with information on the remaining traits in all the years that form the TRN and TST sets. To do this, we used the same dataset that was used in the previous example. To adjust the model, we will use the IBCF.Years() function.</p>
        <disp-quote>
          <p>pm5 &lt;- IBCF.Years(Dataset , <underline>Years.testing =</underline> c(‘2016’), Traits.testing = c(‘T5’,’T6’))</p>
        </disp-quote>
        <p>Once the model is adjusted, a summary of the predictions can be obtained through the summary() command, as detailed below.</p>
        <disp-quote>
          <p>summary(pm5)</p>
          <p>##     Year_Trait  Pearson   MSEP</p>
          <p>## 2016_T5    2016_T5   0.7547   0.3577</p>
          <p>## 2016_T6    2016_T6   0.8551   0.2623</p>
        </disp-quote>
        <p>Finally, we obtain <xref ref-type="fig" rid="f0005">Fig. 5b</xref> through the command: barplot(pm5, select = ‘Pearson’). <xref ref-type="fig" rid="f0005">Figure 5a</xref> shows that the best predictions in terms of Pearson’s correlation are observed for Trait T6 in 2016 under study, whereas the worst predictions are observed for Trait T5 also for 2015.</p>
        <fig id="f0005" orientation="portrait" position="float">
          <label>Fig. 5</label>
          <caption>
            <p>Prediction accuracy in terms of Pearson’s correlation of the item-based collaborative filtering (IBCF) model for (a) each year–trait combination for the data used that corresponds to the dataset for the year and (b) for each trait–environment combination in the testing set with the Wheat_dataset.</p>
          </caption>
          <graphic xlink:href="TPG-11-03-0013-g005"/>
        </fig>
      </sec>
      <sec id="sec3.7">
        <title>Example 7: Predictions of Drip Environment with Three Environments as Training</title>
        <p>As in the previous examples, we used the first dataset for the IBCF() function (Wheat_IBCF). However, we are now interested in predicting the information of the whole environment with the remaining three environments used as TRN. To adjust the model, we will use the IBCF.Years() function again.</p>
        <disp-quote>
          <p>pm6 &lt;- IBCF.Years(Dataset, <underline>colYears = “Env”, Years. testing = ‘Drip’</underline>, Traits.testing = c(‘DH’,’GY’))</p>
        </disp-quote>
        <p>The vector Years.testing specifies the environment to be used in the validation sample. In this dataset, we have information from three environments and, given that the Drip environment is being used for the validation sample, this implies that the information on the remaining environments will be used to train the model. However, in the environment that makes up TST, only the traits specified in the vector traits are missing, which, in this case, are the traits DH and GY only. Therefore, the predictive ability will be studied only for these two traits.</p>
        <disp-quote>
          <p>summary(pm6)</p>
          <p>##      Year_Trait  Pearson    MSEP</p>
          <p>## Drip_DH   Drip_DH    0.6576  25.0166</p>
          <p>## Drip_GY   Drip_GY    0.4617    0.3211</p>
        </disp-quote>
        <p>We can use the barplot() function to obtain a bar plot of the summary of the predictions, as shown in the following code: barplot(pm4, select = ‘Pearson’). <xref ref-type="fig" rid="f0005">Figure 5b</xref> shows that the best predictions in terms of Pearson´s correlation were observed for DH traits for the Drip environment, whereas the worst predictions were observed for GY traits in the Drip environment.</p>
      </sec>
      <sec id="sec3.8">
        <title>Example 8: Predictions of Breeding Values Taking Marker or Genomic Information into Account</title>
        <p>This example was done with the purpose of showing how to use the IBCF.MTME package for making predictions of breeding values taking marker information or pedigree information into account. Since the IBCF.MTME package does not allow the direct incorporation of genomic (marker data) or pedigree information, to take this information into account, we need to do this in two steps. In the first step, we need to adjust the phenotypic data for the markers via a simple regression model (phenotype~ <italic>Markers + error</italic>). For illustration purposes, we used a wheat dataset containing 599 lines that belong to the Bayesian Generalized Linear Regression package (de los Campos and Pérez-Rodríguez, <xref rid="cit0006" ref-type="bibr">2014</xref>). This dataset has phenotypic information for four traits (T1, …, T4) and information on 1279 markers (in binary format). To load this dataset, we used the following code:</p>
        <disp-quote>
          <p>library(BGLR)</p>
          <p>data(wheat)</p>
        </disp-quote>
        <p>We then extracted the marker matrix and the responses of the traits, with the following code:</p>
        <disp-quote>
          <p>Markers &lt;- wheat.X</p>
          <p>Wheat &lt;- wheat.Y</p>
        </disp-quote>
        <p>After this, we transformed the wheat dataset from matrix form to Tidy Data form with the IBCF. MTME package</p>
        <disp-quote>
          <p>Wheat &lt;- data.frame(rownames(Wheat), Wheat)</p>
          <p>colnames(Wheat) &lt;- c(‘GID’, ‘T1_’, ‘T2_’, ‘T3_’, ‘T4_’)</p>
          <p>Data_Wheat &lt;- getTidyForm(Wheat)</p>
        </disp-quote>
        <p>To adjust for the markers each of the four traits with the model above (phenotype ~ <italic>Markers + error</italic>) , we used the BGLR function of the BGLR package as follows:</p>
        <disp-quote>
          <p>ETA &lt;- list(<underline>Marker =</underline> list(<underline>X =</underline> Markers, <underline>model =</underline> ‘BRR’))</p>
          <p>FM_T1 &lt;- BGLR(Data_Wheat$Response[Data_Wheat$Trait == ‘T1’], <underline>ETA =</underline> ETA, <underline>nIter =</underline> 20000, <underline>burnIn =</underline> 15000, <underline>verbose =</underline> FALSE)</p>
          <p>FM_T2 &lt;- BGLR(Data_Wheat$Response[Data_Wheat$Trait == ‘T2’], <underline>ETA =</underline> ETA, <underline>nIter =</underline> 20000, <underline>burnIn =</underline> 15000, <underline>verbose =</underline> FALSE)</p>
          <p>FM_T3 &lt;- BGLR(Data_Wheat$Response[Data_Wheat$Trait == ‘T3’], <underline>ETA =</underline> ETA, <underline>nIter =</underline> 20000, <underline>burnIn =</underline> 15000, <underline>verbose =</underline> FALSE)</p>
          <p>FM_T4 &lt;- BGLR(Data_Wheat$Response[Data_Wheat$Trait == ‘T4’], <underline>ETA =</underline> ETA, <underline>nIter =</underline> 20000, <underline>burnIn =</underline> 15000, <underline>verbose =</underline> FALSE)</p>
        </disp-quote>
        <p>Four models were adjusted, one for each trait. With the fitted values, we generated a new dataset with the genomic breeding values, which we will call “breeding values” for short.</p>
        <disp-quote>
          <p>BreedingValue &lt;- data.frame(<underline>GID =</underline> rownames(Wheat), <underline>T1_ =</underline> FM_T1$yHat, <underline>T2_ =</underline> FM_T2$yHat, <underline>T3_ =</underline> FM_T3$yHat, <underline>T4_ =</underline> FM_T4$yHat)</p>
        </disp-quote>
        <p>Next, we transformed these breeding values into Tidy Data form:</p>
        <disp-quote>
          <p>library(IBCF.MTME)</p>
          <p>Breeding_DS &lt;- getTidyForm(BreedingValue)</p>
        </disp-quote>
        <p>Finally, we implemented a cross-validation for 10 random partitions with 20% of the 599 lines as TST and 80% as TRN; with these partitions, we used the IBCF. MTME function to predict the breeding values of the missing lines as follows:</p>
        <disp-quote>
          <p>Breeding_DS_Missing &lt;- CV.RandomPart(Breeding_DS, NPartitions = 10, PTesting = 0.20)</p>
          <p>PM_Breeding &lt;- IBCF(Breeding_DS_Missing)</p>
          <p>summary(PM_Breeding)</p>
          <p>##  Trait_Env  Pearson  SE_Cor   MSEP   SE_MSEP</p>
          <p>## 1     T1_  -0.2440    0.0259   0.6388   0.0183</p>
          <p>## 2     T2_   0.8222    0.0097   0.1015   0.0033</p>
          <p>## 3     T3_   0.8570    0.0080   0.0608   0.0027</p>
          <p>## 4     T4_   0.5278    0.0127   0.2257   0.0089</p>
        </disp-quote>
        <p>To compare the prediction accuracies without markers (working directly with the phenotypes), we obtained the predictions with the data without the markers by using the phenotypic information directly.</p>
        <disp-quote>
          <p>Response_DS_Missing &lt;- CV.RandomPart(Data_Wheat, NPartitions = 10, PTesting = 0.20)</p>
          <p>PM_Response &lt;- IBCF(Response_DS_Missing)</p>
          <p>summary(PM_Response)</p>
          <p>##  Trait_Env  Pearson  SE_Cor   MSEP   SE_MSEP</p>
          <p>## 1     T1_  -0.0823    0.0256   1.7856   0.0674</p>
          <p>## 2     T2_   0.6683    0.0110   0.5414   0.0171</p>
          <p>## 3     T3_   0.6378    0.0195   0.6218   0.0342</p>
          <p>## 4     T4_   0.3473    0.0193   0.9490   0.0309</p>
        </disp-quote>
        <p>The best predictions were observed when the breeding values were used instead of the phenotypic data.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="discussion" id="sec5">
    <title>DISCUSSION</title>
    <p>The package we developed, IBCF.MTME, enables the study of the prediction accuracies of datasets with continuous phenotypes in the context of multitrait and multienvironment data. The package offers many useful tools that help breeders perform studies of prediction accuracy more easily. Some of these tools provide: (i) an easy way to transform a dataset from the matrix format to the Tidy Data format, (ii) a way to create training and testing datasets with the function CV.RandomPart(), (iii) a summary of the prediction accuracies for the trait–environment combinations or the year–trait combinations that are given with numerical values or with plots for both metrics implemented (Pearson’s correlation and the MSEP), (iv) a way to extract the observed and predicted values for the information in the testing set for each partition (or a summary of all partitions) implemented for further processing, and (v) a way to study the prediction accuracy for the information of some traits (or environments) missing in all the lines in some years (or environments) but available in other years (or environments). For these reasons, we believe that this package can help breeders become efficient in the decision-making process.</p>
    <p>We provide some examples for transforming the whole dataset at hand from the matrix format to the Tidy Data format and vice versa. We believe this will simplify work for breeders, since they frequently need to transform their datasets from one format to the other. In six out of seven examples, we tried to cover scenarios that may be of interest to breeders. The first scenario involved prediction accuracies when breeders are interested in making predictions and the data set has only a single environment and many traits. The second scenario, on the other hand, studied prediction accuracies for datasets with multiple environments and traits, while the third scenario examined prediction accuracies with datasets with multiple traits and environments but with only two traits as TST. The fourth scenario includes datasets with information from several years when the breeder is interested in making predictions for certain traits of some the lines in 2 yr using information from only 1 yr as the TRN. The fifth scenario is similar to the previous one, but now the predictions are only for 1 yr, using 2 yr as TRN. Finally, the sixth scenario can be useful when breeders are interested in predicting the information of a whole environment with the information of three other environments as TRN.</p>
    <p>The main advantage of the IBCF algorithm over the existing statistical models for studying prediction accuracies in multitrait and multienvironment data is that in addition to providing competitive predictions, IBCF can be implemented with reasonably large datasets, as the time required for its implementation is minimal for small and moderately large datasets. As such, we believe that this algorithm can be very useful in the context of plant breeding and that with the help of the proposed package, breeders can implement it more easily. However, a disadvantage of the proposed method is that we cannot directly incorporate pedigree or marker information in the model. For this reason, as shown in most of the examples (except Example 8), it can only be used for phenotypic selection directly. Although this often improves prediction accuracy in genomic mixed models, when the correlation between the trait–environment combination is reasonably high, the predictive power of this method is good.</p>
    <p>However, as shown in Example 8, it is possible to include genomic information (markers) or pedigree information. However, to be able to take this information into account, a two-step process is required: in the first step, the breeding values are obtained by adjusting the phenotypes for markers; in the second step, the breeding values for the missed values of some lines are predicted. It is important to point out that at CIMMYT in some wheat datasets, the IBCF.MTME algorithm has been implemented for predicting breeding values from this two-step process. The IBCF. MTME algorithm has also been implemented for predicting GY in maize from correlated covariates resulting from high-throughput phenotyping datasets collected by highresolution imaging and environmental sensors. With these real applications, we found that the IBCF.MTME algorithm competes well with the conventional genomic mixed models, with the advantage that its implementation is not computationally expensive. However, more empirical evidence is required to get a clear picture of the performance of the IBCF.MTME approach.</p>
    <p>It is important to point out that the IBCF.MTME method is not a model-based approach and therefore cannot estimate genetic variances or variance components in general; however, it can be used as a new alternative for making predictions of phenotypic or genetic information in the context of GS, as shown here with the seven examples. We believe that it can also be used for imputation of phenotypic or genetic information when there is correlated information available. All these tasks can be implemented in the proposed IBCF.MTME R package.</p>
    <p>Finally, we believe that there are opportunities to improve this algorithm (or similar algorithms like the matrix factorization algorithm) to directly take genetic and pedigree information into account, which would be really helpful, since it would allow us to take advantage of all the information that breeders are generating. In addition, we believe that we need to be willing to test other prediction techniques that are being developed in other fields and that could be useful for genomic prediction. For this reason, we encourage people to do research on this topic because they could make a significant contribution to improving the prediction accuracy in breeding programs.</p>
  </sec>
  <sec sec-type="conclusions" id="sec6">
    <title>CONCLUSIONS</title>
    <p>The package we developed provides the user with a framework for studying the prediction accuracies of multitrait and multienvironment data, which are very common in plant breeding. The developed examples cover different scenarios that could be of interest to plant breeders: (i) assessing the prediction accuracy of multitrait and multienvironment data and (ii) the prediction accuracy of year (or environment) from information from one or more years (or environments) as training. Additionally, the package provides a very user-friendly framework for transforming a dataset to a matrix format, constructing random cross-validation scenarios that could be of interest to plant breeders, and studying the prediction abilities of trait–environment combinations or year–trait combinations of interest to plant breeders. In addition, the package can plot a summary of prediction accuracies (Pearson’s correlation and MSEP) for the trait–environment or year–trait combinations that would facilitate the decision-making processes of plant breeders.</p>
  </sec>
</body>
<back>
  <sec sec-type="COI-statement">
    <title>Conflict of Interest Disclosure</title>
    <p>The authors declare that there is no conflict of interest.</p>
  </sec>
  <app-group>
    <app id="app1">
      <title>APPENDIX A: DATA SIMULATION</title>
      <p>The code used for simulating the dataset Year_IBCF is shown below.</p>
      <disp-quote>
        <p>
          <bold>library(IBCF.MTME)</bold>
        </p>
        <p>
          <bold>library(mvtnorm)</bold>
        </p>
        <p>
          <bold>set.seed(2)</bold>
        </p>
        <p>A &lt;- <bold>matrix</bold>(0.65,<underline>ncol=</underline>12,<underline>nrow=</underline>12)</p>
        <p><bold>diag</bold>(A) &lt;- 1</p>
        <p>Sdv &lt;- <bold>diag</bold></p>
        <p>(<bold>c</bold>(0.9^0.5,0.8^0.5,0.9^0.5,0.8^0.5,0.86^0.5,0.7^0.5,0.9 ^0.5,0.8^0.5,0.9^0.5,0.7^0.5,0.7^0.5,0.85^0.5))</p>
        <p>Sigma &lt;- Sdv%*%A%*%Sdv</p>
        <p>No.Lines &lt;- 60</p>
        <p>Z &lt;- <bold>rmvnorm</bold>(No.Lines,<underline>mean=</underline>
<bold>c</bold>(5,5.5,6,5.5,7,6.5,6.0,7,6.6,8,6.3,8),<underline>sigma=</underline>Sigma)</p>
        <p>Years &lt;- <bold>c</bold>(<bold>rep</bold>(2014,20),<bold>rep</bold>(2015,20),<bold>rep</bold>(2016,20))</p>
        <p>Gids &lt;- <bold>c</bold>(1:No.Lines)</p>
        <p>Data.Final &lt;- <bold>data.frame</bold>(<bold>cbind</bold>(Years,Gids,Z))</p>
        <p><bold>colnames</bold>(Data.Final) &lt;- <bold>c</bold>(“Years”,”Gids”,”T1”,”T2”, ”T3”,”T4”,”T5”,”T6”,”T7”,”T8”,”T9”,”T10”,”T11”,”T12”)</p>
        <p><bold>head</bold>(Data.Final)</p>
        <p>Year_IBCF &lt;- <bold>getTidyForm</bold>(Data.Final, <underline>onlyTrait =</underline> T)</p>
      </disp-quote>
    </app>
  </app-group>
  <ref-list id="references">
    <title>REFERENCES</title>
    <ref id="cit0001">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Asoro</surname><given-names>F.G.</given-names></name>, <name name-style="western"><surname>Newell</surname><given-names>M.A.</given-names></name>, <name name-style="western"><surname>Beavis</surname><given-names>W.D.</given-names></name>, <name name-style="western"><surname>Scott</surname><given-names>M.P.</given-names></name>, <name name-style="western"><surname>Tinker</surname><given-names>N.A.</given-names></name>, and <name name-style="western"><surname>Jannink</surname><given-names>J.-L.</given-names></name></person-group><year>2013</year><article-title>Genomic, marker-assisted, and pedigree–BLUP selection methods for β-glucan concentration in elite oat</article-title>. <source>Crop Sci</source>. <volume>53</volume>(<issue>5</issue>):<fpage>1894</fpage>–<lpage>1906</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.2135/cropsci2012.09.0526">10.2135/cropsci2012.09.0526</ext-link></comment></mixed-citation>
    </ref>
    <ref id="cit0002">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bernardo</surname><given-names>R.</given-names></name>, and <name name-style="western"><surname>Yu</surname><given-names>J.M.</given-names></name></person-group><year>2007</year><article-title>Prospects for genome-wide selection for quantitative traits in maize</article-title>. <source>Crop Sci</source>. <volume>47</volume>:<fpage>1082</fpage>–<lpage>1090</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.2135/cropsci2006.11.0690">10.2135/cropsci2006.11.0690</ext-link></comment></mixed-citation>
    </ref>
    <ref id="cit0003">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Beyene</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Semagn</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Mugo</surname><given-names>S.M.</given-names></name>, <name name-style="western"><surname>Tarekegne</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Babu</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Meisel</surname><given-names>B.</given-names></name>, <etal>et al</etal></person-group><year>2015</year><article-title>Genetic gains in grain yield through genomic selection in eight biparental maize populations under drought stress</article-title>. <source>Crop Sci</source>. <volume>55</volume>:<fpage>154</fpage>–<lpage>163</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.2135/cropsci2014.07.0460">10.2135/cropsci2014.07.0460</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="cit0004">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Crossa</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Pérez-Rodríguez</surname><given-names>P.</given-names></name>, <name name-style="western"><surname>Cuevas</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Montesinos-López</surname><given-names>O.A.</given-names></name>, <name name-style="western"><surname>Jarquín</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>de Los Campos</surname><given-names>G.</given-names></name>, <etal>et al</etal></person-group><year>2017</year><article-title>Genomic selection in plant breeding: Methods, models, and perspectives</article-title>. <source>Trends Plant Sci</source>. <volume>22</volume>(<issue>11</issue>):<fpage>961</fpage>–<lpage>975</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.1016/j.tplants.2017.08.011">10.1016/j.tplants.2017.08.011</ext-link></comment><pub-id pub-id-type="pmid">28965742</pub-id></mixed-citation>
    </ref>
    <ref id="cit0005">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Combs</surname><given-names>E.</given-names></name>, and <name name-style="western"><surname>Bernardo</surname><given-names>R.</given-names></name></person-group><year>2013</year><article-title>Genome-wide selection to introgress semidwarf corn germplasm into U.S. Corn Belt inbreds</article-title>. <source>Crop Sci</source>. <volume>53</volume>:<fpage>1427</fpage>–<lpage>1436</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.2135/cropsci2012.11.0666">10.2135/cropsci2012.11.0666</ext-link></comment></mixed-citation>
    </ref>
    <ref id="cit0006">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>de los Campos</surname><given-names>G.</given-names></name>, and <name name-style="western"><surname>Pérez-Rodríguez</surname><given-names>P.</given-names></name></person-group><year>2014</year><article-title>Bayesian generalized linear regression. R package version 1.0.4</article-title>. <source>The R Foundation</source>. <comment><ext-link ext-link-type="uri" xlink:href="http://CRAN.R-project.org/package=BGLR">http://CRAN.R-project.org/package=BGLR</ext-link> (accessed 16 July 2018</comment>).</mixed-citation>
    </ref>
    <ref id="cit0007">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>Food and Agriculture Organization of the United Nations</collab></person-group><year>2009</year><article-title>FAO’s Director-General on how to feed the world in 2050</article-title>. <source>Popul. Dev. Rev</source>. <volume>35</volume>:<fpage>837</fpage>–<lpage>839</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.1111/j.1728-4457.2009.00312.x">10.1111/j.1728-4457.2009.00312.x</ext-link></comment></mixed-citation>
    </ref>
    <ref id="cit0008">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Godfray</surname><given-names>H.C.J.</given-names></name>, <name name-style="western"><surname>Beddington</surname><given-names>J.R.</given-names></name>, <name name-style="western"><surname>Crute</surname><given-names>I.R.</given-names></name>, <name name-style="western"><surname>Haddad</surname><given-names>L.</given-names></name>, <name name-style="western"><surname>Lawrence</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Muir</surname><given-names>J.F.</given-names></name>, <etal>et al</etal></person-group><year>2010</year><article-title>Food security: The challenge of feeding 9 billion people</article-title>. <source>Science</source><volume>327</volume>:<fpage>812</fpage>–<lpage>818</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.1126/science.1185383">10.1126/science.1185383</ext-link></comment><pub-id pub-id-type="pmid">20110467</pub-id></mixed-citation>
    </ref>
    <ref id="cit0009">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Heffner</surname><given-names>E.L.</given-names></name>, <name name-style="western"><surname>Sorrells</surname><given-names>M.E.</given-names></name>, and <name name-style="western"><surname>Jannink</surname><given-names>J.-L.</given-names></name></person-group><year>2009</year><article-title>Genomic selection for crop improvement</article-title>. <source>Crop Sci</source>. <volume>49</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>12</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.2135/cropsci2008.08.0512">10.2135/cropsci2008.08.0512</ext-link></comment></mixed-citation>
    </ref>
    <ref id="cit0010">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Heffner</surname><given-names>E.L.</given-names></name>, <name name-style="western"><surname>Lorenz</surname><given-names>A.J.</given-names></name>, <name name-style="western"><surname>Jannink</surname><given-names>J.-L.</given-names></name>, and <name name-style="western"><surname>Sorrells</surname><given-names>M.E.</given-names></name></person-group><year>2010</year><article-title>Plant breeding with genomic selection: Gain per unit time and cost</article-title>. <source>Crop Sci</source>. <volume>50</volume>(<issue>5</issue>):<fpage>1681</fpage>–<lpage>1690</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.2135/cropsci2009.11.0662">10.2135/cropsci2009.11.0662</ext-link></comment></mixed-citation>
    </ref>
    <ref id="cit0011">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Linden</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Smith</surname><given-names>B.</given-names></name>, and <name name-style="western"><surname>York</surname><given-names>J.</given-names></name></person-group> (<year>2003</year>) <article-title>Amazon.com recommendations: Item-to-item collaborative filtering</article-title>. <source>IEEE Internet Comput</source>. <volume>7</volume>(<issue>1</issue>):<fpage>76</fpage>–<lpage>80</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.1109/MIC.2003.1167344.">10.1109/MIC.2003.1167344.</ext-link></comment></mixed-citation>
    </ref>
    <ref id="cit0012">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>López-Cruz</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Crossa</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Bonnett</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Dreisigacker</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Poland</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Jannink</surname><given-names>J.-L.</given-names></name>, <etal>et al</etal></person-group> (<year>2015</year>) <article-title>Increased prediction accuracy in wheat breeding trials using a marker × environment interaction genomic selection model</article-title>. <source>G3 (Bethesda)</source>
<volume>5</volume>(<issue>4</issue>):<fpage>569</fpage>–<lpage>582</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.1534/g3.114.016097.">10.1534/g3.114.016097.</ext-link></comment><pub-id pub-id-type="pmid">25660166</pub-id></mixed-citation>
    </ref>
    <ref id="cit0013">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lorenzana</surname><given-names>R.E.</given-names></name>, and <name name-style="western"><surname>Bernardo</surname><given-names>R.</given-names></name></person-group><year>2009</year><article-title>Accuracy of genotypic value predictions for marker-based selection in biparental plant populations</article-title>. <source>Theor. Appl. Genet</source>. <volume>120</volume>:<fpage>151</fpage>–<lpage>161</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.1007/s00122-009-1166-3">10.1007/s00122-009-1166-3</ext-link></comment><pub-id pub-id-type="pmid">19841887</pub-id></mixed-citation>
    </ref>
    <ref id="cit0014">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lourenco</surname><given-names>D.A.L.</given-names></name>, <name name-style="western"><surname>Tsuruta</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Fragomeni</surname><given-names>B.O.</given-names></name>, <name name-style="western"><surname>Masuda</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Aguilar</surname><given-names>I.</given-names></name>, <name name-style="western"><surname>Legarra</surname><given-names>A.</given-names></name>, <etal>et al</etal></person-group><year>2015</year><article-title>Genetic evaluation using single-step genomic best linear unbiased predictor in American Angus</article-title>. <source>J. Anim. Sci</source>. <volume>93</volume>(<issue>6</issue>):<fpage>2653</fpage>–<lpage>2662</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.2527/jas.2014-8836">10.2527/jas.2014-8836</ext-link></comment><pub-id pub-id-type="pmid">26115253</pub-id></mixed-citation>
    </ref>
    <ref id="cit0015">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Massman</surname><given-names>J.M.</given-names></name>, <name name-style="western"><surname>Jung</surname><given-names>H.-J.G.</given-names></name>, and <name name-style="western"><surname>Bernardo</surname><given-names>R.</given-names></name></person-group><year>2013</year><article-title>Genome-wide selection versus marker-assisted recurrent selection to improve grain yield and stover-quality traits for cellulosic ethanol in maize</article-title>. <source>Crop Sci</source>. <volume>53</volume>:<fpage>58</fpage>–<lpage>66</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.2135/cropsci2012.02.0112">10.2135/cropsci2012.02.0112</ext-link></comment></mixed-citation>
    </ref>
    <ref id="cit0016">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Meuwissen</surname><given-names>T.H.</given-names></name>, <name name-style="western"><surname>Hayes</surname><given-names>B.J.</given-names></name>, <name name-style="western"><surname>Goddard</surname><given-names>M.E.</given-names></name></person-group><year>2001</year><article-title>Prediction of total genetic value using genome-wide dense marker maps</article-title>. <source>Genetics</source><volume>157</volume>:<fpage>1819</fpage>–<lpage>1829</lpage>.<pub-id pub-id-type="pmid">11290733</pub-id></mixed-citation>
    </ref>
    <ref id="cit0017">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Montesinos-López</surname><given-names>O.A.</given-names></name>, <name name-style="western"><surname>Montesinos-López</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Crossa</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Toledo</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Pérez-Hernández</surname><given-names>O.</given-names></name>, <name name-style="western"><surname>Eskridge</surname><given-names>K.M.</given-names></name>, <etal>et al</etal></person-group><year>2016</year><article-title>A genomic Bayesian multi-trait and multi-environment model</article-title>. <source>G3 (Bethesda)</source>: <volume>6</volume>(<issue>9</issue>):<fpage>2725</fpage>–<lpage>2744</lpage>.<pub-id pub-id-type="pmid">27342738</pub-id></mixed-citation>
    </ref>
    <ref id="cit0018">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Montesinos-López</surname><given-names>O.A.</given-names></name>, <name name-style="western"><surname>Montesinos-López</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Crossa</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Toledo</surname><given-names>F.H.</given-names></name>, <name name-style="western"><surname>Montesinos-López</surname><given-names>J.C.</given-names></name>, <name name-style="western"><surname>Singh</surname><given-names>P.</given-names></name>, <etal>et al</etal></person-group><year>2017</year><article-title>A Bayesian Poisson-lognormal model for count data for multiple-trait multiple-environment genomicenabled prediction</article-title>. <source>G3 (Bethesda)</source><volume>7</volume>(<issue>5</issue>):<fpage>1595</fpage>–<lpage>1606</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.1534/g3.117.039974">10.1534/g3.117.039974</ext-link></comment>.<pub-id pub-id-type="pmid">28364037</pub-id></mixed-citation>
    </ref>
    <ref id="cit0019">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Montesinos-López</surname><given-names>O.A.</given-names></name>, <name name-style="western"><surname>Montesinos-López</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Crossa</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Montesinos-López</surname><given-names>J.C.</given-names></name>, <name name-style="western"><surname>Mota-Sanchez</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Estrada-González</surname><given-names>F.</given-names></name>, <etal>et al</etal></person-group><year>2018</year><article-title>Prediction of multiple-trait and multiple-environment genomic data using recommender systems</article-title>. <source>G3 (Bethedsa)</source><volume>8</volume>(<issue>1</issue>):<fpage>131</fpage>–<lpage>147</lpage>.</mixed-citation>
    </ref>
    <ref id="cit0020">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><collab>R Core Team</collab></person-group> (<year>2018</year>) <article-title>R: A language and environment for statistical computing</article-title>
. <source>R Foundation for Statistical Computing</source>. <comment><ext-link ext-link-type="uri" xlink:href="https://www.R-project.org">https://www.R-project.org/</ext-link> (accessed 17 July 2018</comment>).</mixed-citation>
    </ref>
    <ref id="cit0021">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rutkoski</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Singh</surname><given-names>R.P.</given-names></name>, <name name-style="western"><surname>Huerta-Espino</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Bhavani</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Poland</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Jannink</surname><given-names>J.L.</given-names></name>, <etal>et al</etal></person-group><year>2015</year><article-title>Genetic gain from phenotypic and genomic selection for quantitative resistance to stem rust of wheat</article-title>. <source>Plant Genome</source><volume>8</volume>(<issue>2</issue>):<fpage>1</fpage>–<lpage>10</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.3835/plantgenome2014.10.0074">10.3835/plantgenome2014.10.0074</ext-link></comment></mixed-citation>
    </ref>
    <ref id="cit0022">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Sarwar</surname><given-names>B.</given-names></name>, <name name-style="western"><surname>Karypis</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Konstan</surname><given-names>J.</given-names></name>, and <name name-style="western"><surname>Riedl</surname><given-names>J.</given-names></name></person-group><year>2001</year><article-title>Item-based collaborative filtering recommendation algorithms</article-title>. In: <person-group person-group-type="editor"><name name-style="western"><surname>Shen</surname><given-names>V.Y.</given-names></name>, <name name-style="western"><surname>Saito</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Lyu</surname><given-names>M.R.</given-names></name>, <name name-style="western"><surname>Zurko</surname><given-names>M.E.</given-names></name></person-group>, editors, <source>Proceedings of the 10th International Conference on the World Wide Web, Hong Kong</source>. <day>1–5</day><month>5</month><year>2001</year><publisher-name>ACM</publisher-name>, <publisher-loc>New York</publisher-loc><fpage>p. 285</fpage>–<lpage>295</lpage>.</mixed-citation>
    </ref>
    <ref id="cit0023">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wickham</surname><given-names>H.</given-names></name></person-group><year>2014</year><article-title>Tidy data</article-title>. <source>J. Stat. Softw</source>. <volume>59</volume>(<issue>10</issue>):<fpage>1</fpage>–<lpage>22</lpage>. doi:<comment><ext-link ext-link-type="uri" xlink:href="http://10.18637/jss.v059.i10">10.18637/jss.v059.i10</ext-link></comment><pub-id pub-id-type="pmid">26917999</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
