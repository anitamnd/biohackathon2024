<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8016489</article-id>
    <article-id pub-id-type="pmid">33325516</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa1044</article-id>
    <article-id pub-id-type="publisher-id">btaa1044</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Genome Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Helixer: cross-species gene annotation of large eukaryotic genomes using deep learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Stiehler</surname>
          <given-names>Felix</given-names>
        </name>
        <xref ref-type="aff" rid="btaa1044-aff1">btaa1044-aff1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Steinborn</surname>
          <given-names>Marvin</given-names>
        </name>
        <xref ref-type="aff" rid="btaa1044-aff1">btaa1044-aff1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Scholz</surname>
          <given-names>Stephan</given-names>
        </name>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dey</surname>
          <given-names>Daniela</given-names>
        </name>
        <xref ref-type="aff" rid="btaa1044-aff2">btaa1044-aff2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Weber</surname>
          <given-names>Andreas P M</given-names>
        </name>
        <xref ref-type="aff" rid="btaa1044-aff1">btaa1044-aff1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-1132-0224</contrib-id>
        <name>
          <surname>Denton</surname>
          <given-names>Alisandra K</given-names>
        </name>
        <xref ref-type="corresp" rid="btaa1044-cor1"/>
        <xref ref-type="aff" rid="btaa1044-aff1">btaa1044-aff1</xref>
        <!--<email>alisandra.denton@hhu.de</email>-->
      </contrib>
    </contrib-group>
    <aff id="btaa1044-aff1"><label>btaa1044-aff1</label><institution>Institue of Plant Biochemistry, Faculty of Mathematics and Natural Sciences, Heinrich-Heine-University</institution>, Dusseldorf 40225, <country country="DE">Germany</country></aff>
    <aff id="btaa1044-aff2"><label>btaa1044-aff2</label><institution>Institute of Human Genetics, Medical Faculty, RWTH Aachen University</institution>, Aachen 52062, <country country="DE">Germany</country></aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Birol</surname>
          <given-names>Inanc</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btaa1044-cor1">To whom correspondence should be addressed. <email>alisandra.denton@hhu.de</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>12</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-12-16">
      <day>16</day>
      <month>12</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>16</day>
      <month>12</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>36</volume>
    <issue>22-23</issue>
    <fpage>5291</fpage>
    <lpage>5298</lpage>
    <history>
      <date date-type="received">
        <day>31</day>
        <month>7</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>06</day>
        <month>11</month>
        <year>2020</year>
      </date>
      <date date-type="editorial-decision">
        <day>04</day>
        <month>12</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>07</day>
        <month>12</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa1044.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Current state-of-the-art tools for the <italic>de novo</italic> annotation of genes in eukaryotic genomes have to be specifically fitted for each species and still often produce annotations that can be improved much further. The fundamental algorithmic architecture for these tools has remained largely unchanged for about two decades, limiting learning capabilities. Here, we set out to improve the cross-species annotation of genes from DNA sequence alone with the help of deep learning. The goal is to eliminate the dependency on a closely related gene model while also improving the predictive quality in general with a fundamentally new architecture.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We present Helixer, a framework for the development and usage of a cross-species deep learning model that improves significantly on performance and generalizability when compared to more traditional methods. We evaluate our approach by building a single vertebrate model for the base-wise annotation of 186 animal genomes and a separate land plant model for 51 plant genomes. Our predictions are shown to be much less sensitive to the length of the genome than those of a current state-of-the-art tool. We also present two novel post-processing techniques that each worked to further strengthen our annotations and show in-depth results of an RNA-Seq based comparison of our predictions. Our method does not yet produce comprehensive gene models but rather outputs base pair wise probabilities.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The source code of this work is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/weberlab-hhu/Helixer">https://github.com/weberlab-hhu/Helixer</ext-link> under the GNU General Public License v3.0. The trained models are available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.3974409">https://doi.org/10.5281/zenodo.3974409</ext-link></p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Deutsche Forschungsgemeinschaft</institution>
            <institution-id institution-id-type="DOI">10.13039/501100001659</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Germany’s Excellence Strategy–EXC-2048/1–Project</institution>
          </institution-wrap>
        </funding-source>
        <award-id>390686111</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>BMBF-funded de.NBI Cloud</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>German Network for Bioinformatics Infrastructure</institution>
            <institution-id institution-id-type="DOI">10.13039/501100018929</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>031A537B</award-id>
        <award-id>031A533A</award-id>
        <award-id>031A538A</award-id>
        <award-id>031A533B</award-id>
        <award-id>031A535A</award-id>
        <award-id>031A537C</award-id>
        <award-id>031A534A</award-id>
        <award-id>031A532B</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Annotating genes is an integral part of genomic DNA sequence analysis, with many downstream taks dependent on annotation quality. Gene annotation can be performed at different levels of precision, from simple coding—non-coding classification to detailed structural labeling. Because of the sheer size of genomes alone, manual gene annotation is generally intractable. Instead, researchers can use pipelines such as Maker (<xref rid="btaa1044-B9" ref-type="bibr">Cantarel <italic>et al.</italic>, 2007</xref>), PASA (<xref rid="btaa1044-B15" ref-type="bibr">Haas <italic>et al.</italic>, 2003</xref>) or those offered by genomic database providers like NCBI (<xref rid="btaa1044-B29" ref-type="bibr">Thibaud-Nissen <italic>et al.</italic>, 2013</xref>) and Ensembl (<xref rid="btaa1044-B2" ref-type="bibr">Aken <italic>et al.</italic>, 2016</xref>). These pipelines integrate experimental data (from e.g. RNA-seq or proteogenomics) with homologous sequences in the database and ab-initio gene predictions. The latter is an attractive approach, because it is cheap and fast. State-of-the-art performance is achieved by higher order hidden markov models (HMMs), such as Genscan (<xref rid="btaa1044-B8" ref-type="bibr">Burge and Karlin, 1997</xref>), AUGUSTUS (<xref rid="btaa1044-B28" ref-type="bibr">Stanke and Waack, 2003</xref>) or SNAP (<xref rid="btaa1044-B20" ref-type="bibr">Johnson <italic>et al.</italic>, 2008</xref>). Their accuracy, however, leaves room for improvement. By encoding possible states and transitions in a probalistic model, designers of HMMs assume structure in the sequence that may limit its predictive power. In practice HMMs have trouble generalizing across species and the actual learning of sequence motifs is limited to very short sequences that indicate state transitions.</p>
    <p>In the last decade, deep neural networks (DNN) have been applied with great success in many areas of statistical modeling, including biology (<xref rid="btaa1044-B11" ref-type="bibr">Ching <italic>et al.</italic>, 2018</xref>). For sequence data, such as DNA, speech or text, a special kind of recurrent neural network (RNN) called long-short term memory (LSTM) (<xref rid="btaa1044-B16" ref-type="bibr">Hochreiter and Schmidhuber, 1997</xref>) is an established building block for many different architectures. LSTM units can also be used to process sequential input starting from both ends, forming a bidirectional LSTM (BLSTM). It has also been shown that HMMs can be successfully combined with DNNs (<xref rid="btaa1044-B24" ref-type="bibr">Liu <italic>et al.</italic>, 2016a</xref>,<xref rid="btaa1044-B25" ref-type="bibr">b</xref>).</p>
    <p>For the purpose of gene annotation, RNNs have already shown promising results. (<xref rid="btaa1044-B12" ref-type="bibr">Choudhary, 2017</xref>) carries out preliminary explorations on the potential of BLSTMs for cross species gene prediction and trains his model on human genes to test it later on two more species. DeepAnnotator (<xref rid="btaa1044-B3" ref-type="bibr">Amin <italic>et al.</italic>, 2018</xref>) uses BLSTMs for gene finding in prokaryotes. Gene prediction in prokaryotes is considered more amenable than in eukaryotes, as genes in prokaryotes are proportionately more frequent in the genome, feature simpler control structures and do not use splicing (<xref rid="btaa1044-B33" ref-type="bibr">Wang et al., 2004</xref>). DanQ (<xref rid="btaa1044-B27" ref-type="bibr">Quang and Xie, 2016</xref>) proposes the use of a BLSTM after a convolutional neural net (CNN) to find detailed motifs in the human genome. DeePromoter (<xref rid="btaa1044-B26" ref-type="bibr">Oubounyt <italic>et al.</italic>, 2019</xref>) trains a similar architecture for the recognition of promoter regions. Recently, several groups (<xref rid="btaa1044-B19" ref-type="bibr">Jaganathan <italic>et al.</italic>, 2019</xref>; <xref rid="btaa1044-B32" ref-type="bibr">Wang et al., 2019</xref>) successfully used CNNs to find splicing sites.</p>
    <p>In this work, we present Helixer, a novel prototype software for training and utilizing a general purpose DNN for the ab-initio cross-species base-wise gene annotation of large eukaryotic genomes using only DNA sequence as input. Our model is trained to differentiate between four regions: Intergenic, Untranslated (UTR), Coding (CDS) and Intron. We demonstrate the effectiveness of this approach by training two models, one each for the annotation of a large set of genomes from the domains metazoa and viridiplantae, respectively, which we will call <italic>animal</italic> and <italic>plant</italic> from now on. We worked with the full data of 192 animal genomes and 60 plant genomes. These datasets were rich in vertebrates and land plants, respectively, which is reflected in a much better average model performance on those phylogenetic groups. We will thus call our models <italic>vertebrate model</italic> and <italic>land plant model</italic>.</p>
    <p>Both the ability to generalize across species as well as the scope of the evaluation represent cutting edge progress in this field. The source code and all input data are publicly available.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Datasets</title>
      <p>The foundation of our work are 192 animal and 60 plant genomes. The data of each genome consists of the latest publicly available genomic assembly in form of a FASTA file and the latest annotation in the GFF format. We used one genome for each animal species in EnsemblMetazoa 45 (<xref rid="btaa1044-B18" ref-type="bibr">Howe <italic>et al.</italic>, 2020</xref>; <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S1</xref>) as well as all non-embargoed plant species from the JGI Phytosome 13 database (<xref rid="btaa1044-B14" ref-type="bibr">Goodstein <italic>et al.</italic>, 2012</xref>; <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S2</xref>); The exact genomes are listed in the aforementioned tables. Data was downloaded on the October 15, 2019 and March 29, 2019 from EnsembleMetazoa and Phytozome respectively. Both data groups were used completely separately throughout.</p>
      <p>Directly after obtaining the data, we split off 19 or 6 <italic>test genomes</italic> from either group of genomes and set those aside for the final evaluation at the very end of the development process (<xref ref-type="fig" rid="btaa1044-F1">Fig. 1</xref>). These genomes were chosen to be of decent quality and diversity based on collected metadata (see Supplementary Section S1 and <xref ref-type="supplementary-material" rid="sup1">Supplementary Data</xref>set S1) while also representing a broad phylogenetic spread.</p>
      <fig id="btaa1044-F1" orientation="portrait" position="float">
        <label>Fig. 1.</label>
        <caption>
          <p>Division of the total set of genomes in both the animal and plant case</p>
        </caption>
        <graphic xlink:href="btaa1044f1"/>
      </fig>
      <p>The remaining genomes were seperated into a set of <italic>training genomes</italic>, which were used to actually train the neural networks, and <italic>evaluation genomes</italic>, which provided crucial feedback on the generalization capabilities during development (<xref ref-type="fig" rid="btaa1044-F1">Fig. 1</xref>). The exact division of which genomes we train with and which are just used for evaluation was changed multiple times and was found to be crucial for model performance.</p>
      <p>To select the training genomes, we had to balance multiple conflicting trade-offs. On the one hand, we want to train with as much data as possible, but on the other not all data has sufficient quality to enable a powerful generalization. It is also very desirable to have diverse training genomes with a broad phylogenetic spread, a variety of genome sizes and average gene lengths as the model is increasingly unlikely to generalize well beyond the borders given by the training data. However, it also may be difficult for the model to learn and generalize if the genomic patterns inside the data are too different from each other. Practically, it was important for us to limit the size of our training genomes set to be small enough that we could get experimental results within a couple of days and thereby be able to test many different data and model configurations.</p>
      <p>We used an iterative approach to effectively select a proper set of training genomes. We started with 3–4 genomes that were expected to be of the highest quality and then evaluated the performance of the resulting model on all training and evaluation genomes individually. There, we looked for candidates to add to the set of training genomes (which were evaluation genomes and had high Genic F1) or to remove from it (which were training genomes and had a rather low Genic F1). To make these decisions, we also factored in information like genomic metadata (Supplementary Section S1 and <xref ref-type="supplementary-material" rid="sup1">Supplementary Data</xref>set S1) and the phylogenetic spread our new set of training genomes would have. This process was repeated multiple times alternatingly with the model search as the decisions about the model architecture and the training data tend to depend on each other. We stopped this process when we saw no more room for substantial improvement given our computational constraints.</p>
      <p>We report only the generalization performance on the combined set of evaluation and test genomes as the evaluation genomes are by far the largest set, and there was not a noticeable difference in performance between those two groups (see Supplementary Section S2 for a performance breakdown by each species).</p>
      <p>Once a set of training genomes was selected, we further split the sequences therein into a <italic>training and validation set</italic>. This split of the training genomes was done to get a quicker sense of the generalization capabilities and was used after each training epoch. We split off the validation set by selecting 20% of the FASTA sequences above and below the N90 of each training genome at random, ensuring a proper distribution of large and short sequences in both sets and a split on the chromosome level. Evaluation of the annotations on all training and evaluation genomes was done regularly after a promising model candidate was found based on its validation set performance. Ultimately we used the cross-species performance on all evaluation genomes as the decisive measure of model quality.</p>
    </sec>
    <sec>
      <title>2.2 Data pre-processing</title>
      <p>We first pre-processed and stored the raw genomic information by using GeenuFF (<ext-link ext-link-type="uri" xlink:href="https://github.com/weberlab-hhu/GeenuFF">https://github.com/weberlab-hhu/GeenuFF</ext-link>). GeenuFF is a tool for checking and exploring genomic data and annotations, that stores all information inside a SQL database. Training and evaluation-ready data was generated by querying this database and then transforming the returned data into a numerical format suitable for machine learning. The encoding of the genomic sequence was done in line with the IUPAC nucleic acid notation and the structural gene annotation used as labels during training is transformed to a one hot encoding with the four classes <italic>Intergenic</italic>, <italic>UTR</italic>, <italic>CDS</italic> and <italic>Intron</italic>. See <xref rid="btaa1044-T1" ref-type="table">Table 1</xref> for a more detailed description of the generated data types. </p>
      <table-wrap id="btaa1044-T1" orientation="portrait" position="float">
        <label>Table 1.</label>
        <caption>
          <p>Data arrays generated and used by Helixer</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1">Name</th>
              <th rowspan="1" colspan="1">Information</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Input</td>
              <td rowspan="1" colspan="1">Genomic sequence in the 4-dimensional IUPAC encoding</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">(one hot encoding for non-ambiguous bases)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Output</td>
              <td rowspan="1" colspan="1">Labels in a 4-dimensional one hot encoding representing</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">the classes <italic>Intergenic</italic>, <italic>UTR</italic>, <italic>CDS</italic> and <italic>Intron</italic></td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Sample weights</td>
              <td rowspan="1" colspan="1">One of {0, 1}; whether there is an error at a base</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic>Note:</italic> The encoding does not differentiate between introns in coding and non-coding regions.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>During data generation, we queried for the transcript with the longest protein of each gene and disregard FASTA sequences that have no structural gene annotation as it is ambiguous whether such sequences contain no genes or were simply not annotated in the reference. GeenuFF checks the genomic annotations for potential errors during import and is able to mark those areas. We used this information to effectively mask those bases during training by using the sample weights described in <xref rid="btaa1044-T1" ref-type="table">Table 1</xref>. The vast majority of masked bases lie in the intergenic region as the most prevalent error is a missing UTR and GeenuFF marks a potentially large intergenic region for it. <xref rid="btaa1044-T2" ref-type="table">Table 2</xref> shows statistics about the masking.</p>
      <table-wrap id="btaa1044-T2" orientation="portrait" position="float">
        <label>Table 2.</label>
        <caption>
          <p>Data group statistics for all data </p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Animals</th>
              <th rowspan="1" colspan="1">Plants</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Average genome size in Gbp</td>
              <td rowspan="1" colspan="1">2.936 (±1.562)</td>
              <td rowspan="1" colspan="1">0.787 (±0.995)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Average gene length</td>
              <td rowspan="1" colspan="1">31 223 (±13 974)</td>
              <td rowspan="1" colspan="1">3368 (±1510)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Geenuff error rate</td>
              <td rowspan="1" colspan="1">0.311 (±0.129)</td>
              <td rowspan="1" colspan="1">0.351 (±0.249)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Fraction of class Intergenic</td>
              <td rowspan="1" colspan="1">0.777 (±0.042)</td>
              <td rowspan="1" colspan="1">0.799 (±0.089)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Fraction of class UTR</td>
              <td rowspan="1" colspan="1">0.006 (±0.006)</td>
              <td rowspan="1" colspan="1">0.017 (±0.016)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Fraction of class CDS</td>
              <td rowspan="1" colspan="1">0.016 (±0.014)</td>
              <td rowspan="1" colspan="1">0.085 (±0.071)</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Fraction of class Intron</td>
              <td rowspan="1" colspan="1">0.201 (±0.035)</td>
              <td rowspan="1" colspan="1">0.099 (±0.057)</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic>Note:</italic> Values are averages of the individual values of each genome in a data group. All statistics except the average gene lengths exclude FASTA sequences without a gene and any 20 000 bp subsequences that were masked as completely erroneous. Each strand of DNA was counted separately. The gene length was determined by the length of the pre-mRNA of the longest protein at each loci. Brackets show the standard deviation.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>For the training itself, we divided each continuous genomic sequence into 20 000 bp long subsequences, for which one-hot vectors of the base pairs and annotations are generated and respectively used as input and label for the neural network together with the sample weights. We appended zero padding if the subsequences are shorter than 20 000 bp. If a subsequence is fully marked as erroneous, we excluded it from all analyses.</p>
    </sec>
    <sec>
      <title>2.3 Metrics</title>
      <p>We mainly used two metrics to judge model performance against the references. The <italic>Genic F1</italic> was selected as our primary metric and provides the most comprehensive picture of annotation quality in one number. The <italic>Subgenic F1</italic> is similar to the Genic F1, except that it does not take UTR predictions into account. This was calculated for comparability with AUGUSTUS as further explained in Supplementary Section 2.7.</p>
      <p>Both metrics work by first transforming the probalistic output of the model into concrete predictions with an <italic>argmax</italic> operation, as is commonly done in classification. As we are now given the true and predicted class of each base, we calculate the full confusion matrix for all classes. From there, the True Positives (TP), False Positives (FP) and False Negatives (FN) of each considered class are summed up. This means that if, for example, an intronic base is incorrectly labeled as CDS, it would lead to a FP for the CDS class and FN for the intron class. These three values are then combined into precision and recall before the final F1 score is calculated. The formulas 1-6 describe the calculations given the confusion matrix with <italic>C</italic> containing the set of the considered classes. 
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:munder><mml:mi mathvariant="normal">T</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mrow><mml:mtext>FP</mml:mtext><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:munder><mml:mi mathvariant="normal">F</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mrow><mml:mtext>FN</mml:mtext><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:munder><mml:mi mathvariant="normal">F</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">N</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:mrow><mml:mtext>Precision</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext></mml:mrow><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FP</mml:mtext></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E5"><label>(5)</label><mml:math id="M5"><mml:mrow><mml:mtext>Recall</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext></mml:mrow><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FN</mml:mtext></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E6"><label>(6)</label><mml:math id="M6"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>·</mml:mo><mml:mfrac><mml:mrow><mml:mtext>Precision</mml:mtext><mml:mo>·</mml:mo><mml:mtext>Recall</mml:mtext></mml:mrow><mml:mrow><mml:mtext>Precision</mml:mtext><mml:mo>+</mml:mo><mml:mtext>Recall</mml:mtext></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>Neither metric includes the intergenic class, as this class is very abundant and appears to be by far the easiest to predict. (See <xref rid="btaa1044-T2" ref-type="table">Table 2</xref> for the class distribution and <xref ref-type="supplementary-material" rid="sup1">Supplementary Tables S3 and S4</xref> for a more in-depth report our model performance including the intergenic class). In the case of the Genic F1, this means that effectively only the TP of the intergenic class were disregarded. The metrics essentially provide a weighted mean of the performances in the considered classes, with weights proportional to class frequency.</p>
      <p>In <xref ref-type="fig" rid="btaa1044-F2">Figure 2c</xref>, we also report on the overall base pair level accuracy (correctly predicted base pairs/total base pairs) besides the Genic F1.</p>
      <fig id="btaa1044-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Main overall results and other investigations. The top and bottom rows show the animal and plant data, respectively. Orange dots are for AUGUSTUS and the blue ones are for Helixer (top vertebrate model, bottom land plant model). (<bold>a</bold>) Swarm—and boxplots showing the Subgenic F1 versus the reference scores for all evaluation and test genomes. Each dot represents the prediction performance for one genome. The median prediction scores are shown by the red line. Details of how AUGUSTUS was used are given in Supplementary Section S2.7. (<bold>b</bold>) Scatterplots showing the prediction performances measured in Subgenic F1 versus the reference by genome length. The regression line is shown with a 95% confidence interval. (<bold>c</bold>) The average Genic F1 (in red) and basepair wise accuracy (in purple) versus the reference with respect to the position in the 20 000 basepair long input sequences. The dashed line shows the same without overlapping. Each value is the average performance of a 200 basepair long subsection by one of the models of the final ensemble. See Supplementary Section S10 of for the effects of overlapping in individual species</p>
        </caption>
        <graphic xlink:href="btaa1044f2"/>
      </fig>
    </sec>
    <sec>
      <title>2.4 Model architecture and training</title>
      <p>We used a 4-layer deep stacked BLSTM network with 256 units per layer and layer normalization (<xref rid="btaa1044-B4" ref-type="bibr">Ba <italic>et al.</italic>, 2016</xref>) between each BLSTM layer to produce the predictions in the form of a base pair wise classification. The model consists of circa 5.4 million parameters and was implemented with the deep learning library Keras (<ext-link ext-link-type="uri" xlink:href="https://keras.io">https://keras.io</ext-link>) on top of TensorFlow (<xref rid="btaa1044-B1" ref-type="bibr">Abadi <italic>et al.</italic>, 2016</xref>). We tested multiple different architectures before arriving at this model configuration, including convolutional neural networks (CNN) and hybrid architectures. We also used class weights as the class frequencies are both unbalanced and vary greatly between animals and plants. For example, the trade-off between the number of intergenic and intronic bases is quite different in both groups (see <xref rid="btaa1044-T2" ref-type="table">Table 2</xref>).</p>
      <p>A class wise evaluation including the calculation of the Genic F1 score was performed on the validation set after every epoch. The best model from any training run was selected as the model with the highest Genic F1 after either maximum epochs were reached or Genic F1 stopped improving and training was interrupted.</p>
      <p>The hyperparameters were optimized by a combination of manual and automatic optimization. Automatic optimization was carried out by using either the TPE algorithm (<xref rid="btaa1044-B5" ref-type="bibr">Bergstra <italic>et al.</italic>, 2011</xref>), random search or grid search depending on the situation. We used NNI (<ext-link ext-link-type="uri" xlink:href="https://github.com/microsoft/nni">https://github.com/microsoft/nni</ext-link>) to facilitate the search. All relevant hyperparameters can be found in <xref ref-type="supplementary-material" rid="sup1">Supplementary Tables S6 and S7</xref> or in the Helixer source code repository.</p>
      <p>Our final model (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figs S5 and S6</xref>) was trained with 10 bases of genomic sequence as input during each time step and produces individual predictions for each of those 10 bases simultaneously. This grouping enabled us to train effectively with far longer sequences than usual, as 10 bases can be processed essentially in the time of 1. The tradeoff is, that the data setup is now more complex from the point of view of the neural network. A donor splice site at the beginning of a 10 base pair block now has to result in a fundamentally different set of 40 (10 bases x 4 classes) floating point numbers than a donor splice site at the end.</p>
      <p>These four floating point numbers per base are the final output of our model as we are currently not producing a fully coherent gene model in the form of a GFF file.</p>
      <p>We also compared our final models to a dilated CNN (dCNN) and a hybrid architecture, that we call DanQ after an existing approach (<xref rid="btaa1044-B27" ref-type="bibr">Quang and Xie, 2016</xref>). These were chosen as both dilated CNN and hybrid architectures have been used when working with DNA data as input (<xref rid="btaa1044-B31" ref-type="bibr">Trabelsi et al., 2019</xref>). Details of the neural architecture search are given in Supplementary Section S3.</p>
    </sec>
    <sec>
      <title>2.5 Inference techniques</title>
      <p>We also used multiple techniques to improve the prediction quality after the training was done. One very effective way for genomes with larger genes was inputting longer sequences during inference than during training. This was done for all animal genomes except the invertebrates. The input sequences were up to 10 times longer, depending on the phylogenetic group and assembly quality. This also demonstrates the ability of our model to generalize as it is able to make successful prediction on far longer sequences than it has ever seen. The concrete lengths were chosen to keep the typical average gene length roughly proportional to the length of the sequence input. For more implementation details on this see Supplementary Section S9 or the source code.</p>
      <p>The final predictions of a single model were constructed by overlapping predictions, which were made from a sliding window and then cropped to a core sequence. This was done to strongly reduce a typical drop in performance of the models toward the beginning and end of each sequence (see <xref ref-type="fig" rid="btaa1044-F2">Fig. 2c</xref>). It also improves the average model performance by providing the model with multiple different starting points. The different overlapping sequences were combined by averaging the individual softmax values of each base. The figures in Supplementary Section S10 show the effect of overlapping for each genome, ordered by N75. We found that overlapping tends to work best if the genomes are not very fragmented and we used it for both animals and plants.</p>
      <p>For both the vertebrate and land plant model, a model ensemble with 8 components was used to generate the final predictions for each species. To produce these 8 components, we performed 4 separate training runs and selected two checkpoints each (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S19</xref>). First we selected the checkpoint from the epoch with the highest genic F1, which, as it happens, also had either the highest precision or recall. The second checkpoint was selected to complement this, so that checkpoints from the epochs with both the best precision and the best recall were ultimately selected. This was done to increase the diversity of the model ensemble. As with the overlapping, the fusion of the eight individual predictions was done by simply averaging the softmax values of each base pair prediction.</p>
    </sec>
    <sec>
      <title>2.6 Training and inference times</title>
      <p>The training of one vertebrate and one land plant model took on average 9.5 or 5 h per epoch, respectively. The best model performance in terms of Genic F1 was reached in 7–9 epochs with the animal data and 10–13 epochs for the plants. We stopped the training when either there was no improvement in Genic F1 larger than 0.0001 for at least 2 epochs or the training diverged into a situation where a loss of zero was output for only intergenic predictions. This was likely caused by a floating point overflow in the GPU and usually happened as the improvements in model performance appeared to taper off.</p>
      <p>We used a single Nvidia GeForce GTX 1080 TI provided by the HPC of the University of Dusseldorf for the training of six of the eight models that make up the final ensembles and a Nvidia GeForce RTX 2080 TI inside a desktop PC with a SSD attached for the other two (with one full GPU per training in each scenario). All times reported here are for the former setup up and training on the latter was roughly 1.5 times faster.</p>
      <p>Inference on <italic>Homo sapiens</italic> (circa 6.12Gbp, including padding) took about 8.5 h with overlapping and circa 70 min without. Generating probalistic predictions for <italic>Arabidopsis thaliana</italic> (about 0.22Gbp) finished after close to 7 min. Inference was done on a Nvidia GeForce RTX 2080 TI attached to a regular HDD.</p>
    </sec>
    <sec>
      <title>2.7 Evaluation of AUGUSTUS</title>
      <p>Due to the practical time constraints for retraining and running, we decided to compare our Helixer models only to one existing <italic>de novo</italic> tool, namely the popular gene caller AUGUSTUS (<xref rid="btaa1044-B28" ref-type="bibr">Stanke and Waack, 2003</xref>). Typical usage requires retraining AUGUSTUS for each species, with the exception of a few lucky cases where a model for a sufficiently close relative is already available. To scale this for the large plant and animal datasets, we used protein-homology to create an AUGUSTUS training set and therefore could train and evaluate only models without UTRs.</p>
      <p>Orthologs of highly conserved generally single-copy genes were identified in each genome using BUSCO (<xref rid="btaa1044-B01196143" ref-type="bibr">Simão, 2015</xref>). The <italic>viridiplantae</italic> set was used for plants and the <italic>metazoa</italic> set for animals. The training genbank files were generated directly by BUSCO, by utilizing the ‘–long’ parameter. For plants, the entire retraining could be performed as above; however, for animals we randomly selected only half the BUSCO-generated training set, which resulted in a training set size and runtime comparable to the plants (about 400 genes and several CPU days per species). For animals the training was carried out with the subsetted training file and using the following scripts provided by AUGUSTUS. An untrained model was setup with ‘new_species.pl’, and the model was fit by running ‘etraining’ before and after the major hyper-parameter optimization with ‘optimize_augustus.pl’. Using the trained model for each species, we ran the main prediction (‘augustus’) with ‘–UTR=off’ and ‘–gff3 = on’. The gffs produced by AUGUSTUS were imported into GeenuFF and exported as HDF5 files in the same manor as the reference, allowing for the direct comparison with both the reference and Helixer predictions. While this method was feasible for some 237 species, it allowed neither training nor prediction of UTR regions with AUGUSTUS, so the metric Subgenic F1, which disregards the class UTR, was used for all comparisons between AUGUSTUS and Helixer (see Supplementary Section S2.3 for more details).</p>
    </sec>
    <sec>
      <title>2.8 Evaluation against independent RNAseq data</title>
      <p>The reference annotations were created with existing tools and largely with a pipeline incorporating <italic>de novo</italic> gene predictions with RNAseq and homology data. As the references, like any data, are expected to contain errors we chose to use RNAseq data for an independent evaluation. In plants there is the additional concern that the references may share biases with AUGUSTUS or HMMs as AUGUSTUS was used as the <italic>de novo</italic> gene caller for the reference of many plant species and other HMM-based tools for many more. The Ensemble animal dataset by and large used the Ensembl annotation pipeline, which primarily uses extrinsic data but never-the-less incorporates Genscan (<xref rid="btaa1044-B8" ref-type="bibr">Burge and Karlin, 1997</xref>) predictions.</p>
      <p>We downloaded and processed public RNAseq data to obtain an independent option for evaluating model performance. We selected three each of plant and animal genomes for detailed evaluation with RNAseq. These were selected to have relatively good (<italic>Manihot esculenta</italic> and <italic>Papio anubis</italic>), typical (<italic>Medicago truncatula</italic> and <italic>Equus caballus</italic>) and poor (<italic>Theobroma cacao</italic> and <italic>Petromyzon marinus</italic>) performance compared to AUGUSTUS (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S7</xref> and S8) within our generalizable range (i.e. excluding the outgroups algae and invertebrates). Selections were further constrained by the availability of stranded RNAseq data.</p>
      <p>For each of these six species the following search was performed on Sequence Read Archive (Leinonen <italic>et al.</italic>, 2010) ‘((‘&lt;species name&gt;’[Organism] OR &lt;species name&gt;[All Fields]) AND stranded[All Fields]) AND (‘biomol rna’[Properties] AND ‘library layout paired’[Properties])’. If more than 50 samples were identified, every Nth sample was selected so that in total under 50 samples were chosen for further processing (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S15</xref>). Each sample was prepped, mapped and quality controlled in a pipeline using Trimmomatic (<xref rid="btaa1044-B6" ref-type="bibr">Bolger <italic>et al.</italic>, 2014</xref>), Hisat2 (<xref rid="btaa1044-B21" ref-type="bibr">Kim <italic>et al.</italic>, 2019</xref>), Samtools (<xref rid="btaa1044-B23" ref-type="bibr">Li <italic>et al.</italic>, 2009</xref>), PicardTools (<ext-link ext-link-type="uri" xlink:href="http://broadinstitute.github.io/picard/">http://broadinstitute.github.io/picard/</ext-link>), FastQC (<ext-link ext-link-type="uri" xlink:href="http://www.bioinformatics.babraham.ac.uk/projects/fastqc/">www.bioinformatics.babraham.ac.uk/projects/fastqc/</ext-link>) and MultiQC (<xref rid="btaa1044-B13" ref-type="bibr">Ewels <italic>et al.</italic>, 2016</xref>; see <xref ref-type="supplementary-material" rid="sup1">Supplementary Table S16</xref> for details). This pipeline was automated and the results visualized with the code available here (<ext-link ext-link-type="uri" xlink:href="https://github.com/weberlab-hhu/RNAsleek">https://github.com/weberlab-hhu/RNAsleek</ext-link>). The samples were filtered to those with relatively high mapping rates, high mapping to exonic relative to non-exonic regions, low 3’ bias, normal FastQC and Trimmomatic stats, and a stranded mapping pattern (2nd read is sense strand). If more remained, seven of the high quality samples were selected randomly.</p>
      <p>Finally, the selected and mapped RNAseq samples (<xref ref-type="supplementary-material" rid="sup1">Supplementary Table S15</xref>) were merged with Samtools and quantified to get the coverage (number of reads matching; i.e. cigar =, M or X), and spliced coverage (number of reads with gap or splice; i.e. cigar N or D) for every base pair in the genomes as implemented in Helixer’s ‘training_rnaseq.py’ script.</p>
    </sec>
    <sec>
      <title>2.9 <italic>In Silico</italic> mutagenesis</title>
      <p>To get a better sense of how our models are making their predicitions, two types of <italic>In Silico</italic> mutagenesis were performed. Base pairs of known motifs at targetted splice sites, start and stop codons were replaced with ’N’ characters (encoded as [0.25, 0.25, 0.25, 0.25]) to see how the network responded to an absence of the motif. We also manipulated coding potential (<xref rid="btaa1044-B7" ref-type="bibr">Brocchieri <italic>et al.</italic>, 2005</xref>) by scambling the chosen region in 3 bp steps to remove any codon-positional biases without changing the overall base composition. Perturbations were performed on an arbitrarily selected example gene in <italic>M.esculenta</italic> (Manes.01G003200.1.v6.1), and predictions for the modified sequence were created with the single best land plant bLSTM model (plants_a_e10.h5) with overlapping on.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <p><xref ref-type="fig" rid="btaa1044-F2">Figure 2a</xref> shows the side-by-side comparison of the distribution of performances on all non-training genomes in the animal and plant case by Subgenic F1 versus the reference. In the case of Helixer, these scores represent cross-species predictions. We also compare the median performances of different configurations of Helixer with AUGUSTUS and a dilated CNN architecture in <xref rid="btaa1044-T3" ref-type="table">Table 3</xref>. The results show a clear improvement over the AUGUSTUS both in higher median performance and reduced spread. We also outperform a dilated CNN architecture, and, for plants the hybrid DanQ architecture. Interestingly, during the review process, a single DanQ model topped the performance of the single best vertebrate bLSTM model, which will warrant further investigation.</p>
    <table-wrap id="btaa1044-T3" orientation="portrait" position="float">
      <label>Table 3.</label>
      <caption>
        <p>Summary of experimental results</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="center" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="1" colspan="1"/>
            <th rowspan="1" colspan="1">Animals</th>
            <th rowspan="1" colspan="1">Plants</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">AUGUSTUS</td>
            <td rowspan="1" colspan="1">0.632</td>
            <td rowspan="1" colspan="1">0.757</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Dilated CNN</td>
            <td rowspan="1" colspan="1">0.666</td>
            <td rowspan="1" colspan="1">0.802</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">DanQ hybrid</td>
            <td rowspan="1" colspan="1">0.788</td>
            <td rowspan="1" colspan="1">0.813</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">bLSTM model</td>
            <td rowspan="1" colspan="1">0.770</td>
            <td rowspan="1" colspan="1">0.833</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">bLSTM model + varied input length</td>
            <td rowspan="1" colspan="1">0.834</td>
            <td rowspan="1" colspan="1">–</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">bLSTM model (+varied input length) + overlapping</td>
            <td rowspan="1" colspan="1">0.844</td>
            <td rowspan="1" colspan="1">0.843</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Ensemble of 8 (+varied input length) + overlapping</td>
            <td rowspan="1" colspan="1">0.868</td>
            <td rowspan="1" colspan="1">0.863</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="tblfn3">
          <p><italic>Note:</italic> Values are the median in Subgenic F1 versus the reference across all evaluation and test genomes of the respective group. Varied input length was only used in the animal case. The shown best bLSTM model (for vertebrates: animals_a_e07, for land plants: plants_a_e10) was chosen out of the eight models of the ensemble for having the best performance on the validation set of the training genomes.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <p>Our models, however, tend to perform less well for the very smallest and largest genomes or species that are phylogenetically the furthest away from our training genomes. This is the case for both animals and plants and is visualized in Supplementary Figures S1 and S3. We do not, for example, consistently predict very well on the algae nor on the non-avian reptiles. While one of the algae was included in our training genomes it accounted for a tiny proportion of the total training data and the non-avian reptiles were not included at all.</p>
    <p>AUGUSTUS outperforms us on some of the smallest genomes, but falls off much more drastically as the genomes get larger. The difference in prediction quality is especially strong for mammals, which tend to have big genomes with very long genes as well as the largest plants. Supplementary Figures S2 and S4 display the comparison to AUGUSTUS by phylogenetic position.</p>
    <p>Two techniques were used during inference to improve performance and limit model bias. The usage of longer input lengths helped especially for genomes that tend to have longer genes and was enabled by our model architecture being a relatively simple BLSTM stack without any fully connected layers on top. We also constructed the final predictions out of overlapping ones, which greatly helped to reduce prediction bias in most genomes. To our knowledge, neither technique has been used before in a model developed for gene annotation.</p>
    <p>To make an independent qualitative and quantitative evaluation of performance we compared Helixer predictions, AUGUSTUS predictions and the reference to RNAseq coverage data. Evaluation with RNAseq data was performed for three each of animal and plant species. RNAseq coverage provides support for an exonic annotation (UTR or CDS), spliced coverage provides support for an annotation of intron, and neither coverage nor spliced coverage is expected for intergenic annotations. Looking at selected subsequences (<xref ref-type="fig" rid="btaa1044-F3">Fig. 3</xref>) we identified cases where RNAseq supported (i) both the annotations of the reference and Helixer, (ii) neither, (iii) the reference, but not Helixer and (iv) Helixer, but not the reference.</p>
    <fig id="btaa1044-F3" orientation="portrait" position="float">
      <label>Fig. 3.</label>
      <caption>
        <p>Four example helixer predictions in the context of RNAseq data, the reference and AUGUSTUS’ prediction for <italic>M.esculenta</italic>. The examples were chosen so that (<bold>a</bold>) Helixer had high accuracy against the reference and the reference was supported by the RNAseq data, (<bold>b</bold>) Helixer had high accuracy but the reference was not supported by the RNAseq data, (<bold>c</bold>) Helixer had low accuracy and the reference was supported by the RNAseq data and (<bold>d</bold>) Helixer had low accuracy but the reference was not supported by RNAseq data. Feasibility for visualization was a major secondary consideration. Each subplot shows from top to bottom (i) the natural log of the coverage (‘cov’, solid) and spliced coverage (‘sc’, dotted) + 1, (ii) the reference annotation in matrix form, (iii) AUGUSTUS’ predictions in matrix form (the dashed line is a reminder that no UTR predictions are expected) and (iv) Helixer’s predictions. The reference and AUGUSTUS have either 0 (white) or 1 (black) for each base pair and category, while Helixer emits a probability from 0-1 represented via gray-scale. ‘Ntrn’ stand for intron, and ‘IG’ stands for intergenic</p>
      </caption>
      <graphic xlink:href="btaa1044f3"/>
    </fig>
    <p>Helixer models do not yet have post-processing to make finalized single predictions, but instead output base-wise probabilities. We see that the model exhibits higher uncertainty around transitions between annotation classes, for instance between UTR and CDS, or more dramatically between UTR and intergenic even where Helixer predictions closely match the reference and RNAseq data (a). Helixer’s uncertainty around transitions from UTR to intergenic regions may relate to a fundamentally harder problem (there is no conserved motif at the site as is observed for splice sites and start/stop codons), lack of a precise one base pair biological site (<xref rid="btaa1044-B10" ref-type="bibr">Carninci <italic>et al.</italic>, 2006</xref>; <xref rid="btaa1044-B17" ref-type="bibr">Hon <italic>et al.</italic>, 2013</xref>) or noise in the reference, which we observed relative to the RNAseq data (<xref ref-type="supplementary-material" rid="sup1">Supplementary Figs S13 and S14</xref>).</p>
    <p>Helixer models also sometimes showed uncertainty for larger regions. In some cases where Helixer did not receive RNAseq support for its highest probability annotation, it assigned a low but non-trivial probability to the RNAseq-supported exon/intron pattern (<xref ref-type="fig" rid="btaa1044-F3">Fig. 3b</xref> and c, <xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S11c</xref>). However, in the extreme, there are cases where the Helixer model exhibits substantial indecision or confusion and shifts gradually between classes with no single class receiving a high probability for extended stretches (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S11c</xref> and d). Notably, in one of the examples (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S11d</xref>) the RNAseq shows evidence of alternative splicing; and in another (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S11c</xref>) Helixer’s prediction falls between that of the reference and of AUGUSTUS.</p>
    <p>Coverage and Spliced coverage were broken down by the confusion matrix of both Helixer versus AUGUSTUS as well as Helixer versus the reference for all genomes (<xref ref-type="fig" rid="btaa1044-F4">Fig. 4</xref> and <xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S15</xref>). Where both tools agree on far left in the figure, coverage and spliced coverage closely matched expectations. Specifically for CDS: CDS and UTR: UTR most base pairs had some, and many had moderate or high coverage. The same pattern was seen for intron: intron and spliced coverage. Finally, intergenic: intergenic showed only a small fraction of base pairs with any of either coverage or spliced coverage. In all conflicts the amount of RNAseq support fell between the cases where tools agreed, indicating that all options were at least capable of finding weak-spots in the other annotations.</p>
    <fig id="btaa1044-F4" orientation="portrait" position="float">
      <label>Fig. 4.</label>
      <caption>
        <p>Fraction of bp with color-indicated (<bold>a</bold>) coverage and (<bold>b</bold>) spliced coverage of genomic positions broken down by the confusion matrix of AUGUSTUS’ and Helixer’s predictions. Categories are only displayed if they can be meaningfully compared by examining (a) coverage or (b) spliced coverage. The displayed fractions are the averages of the individual fractions for the six RNAseq-evaluation species. The left-most bars show cases where the two tools agree, while the remaining bars show paired conflicts. ‘Ntrn’ stand for intron, and ‘IG’ stands for intergenic</p>
      </caption>
      <graphic xlink:href="btaa1044f4"/>
    </fig>
    <p>In cases of conflict, Helixer’s predictions were substantially more consistent with the RNAseq data than those of AUGUSTUS. Specifically, for base pairs where one tool predicted CDS and the other intergenic or intron, there was more coverage when Helixer predicted CDS (<xref ref-type="fig" rid="btaa1044-F4">Fig. 4a</xref>). Similarly, for base pairs where one tool predicted intron and the other CDS or intergenic, there was more spliced coverage when Helixer predicted intron (<xref ref-type="fig" rid="btaa1044-F4">Fig. 4b</xref>). These patterns were consistent in direction but varied in magnitude in the individual species, with the exception of <italic>P.marinus</italic> where Helixer and AUGUSTUS performed comparably at differentiating between CDS and intron regions (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S16</xref>).</p>
    <p>RNAseq-based comparison of Helixer and the reference was less clear cut. Averaged across species, Helixer’s predictions received slightly more support than the reference when differentiating CDS, UTR and introns from intergenic; however Helixer’s predictions received slightly less support than the reference when differentiating CDS and UTR from introns (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S15</xref>). Performance varies between individual species, from <italic>P.marinus</italic>, where the reference receives more support in every conflict, to <italic>T.cacao</italic>, where Helixer models receive equivalent or more support in every conflict (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S17</xref>). Interestingly, these two species were selected as examples where Helixer had poor Subgenic F1 versus the reference; for the former the RNAseq confirms relatively weak performance for Helixer, while the for the latter RNAseq rather indicates a sub-par reference.</p>
    <p>Finally, to take a first look at how Helixer models respond to known factors and motifs, we performed <italic>in silico</italic> mutagenesis on an example gene. The Helixer predictions were sensitive to perturbations of a donor and acceptor splice site, the stop codon and the coding potential, but indifferent to removal of the start codon (Supplementary Figs S18–S22). Most perturbations induced uncertainty in Helixer’s prediction, with the exception of removing the stop codon, where the network could simply use a second, proximal down-stream stop codon. This indicates the Helixer model often uses, but does not entirely rely on, known patterns.</p>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>With Helixer, we introduce a novel, deep-learning based framework for the development of more effective tools for gene annotation prediction. Helixer outperforms AUGUSTUS on base pair wise metrics and on consistency with independent RNASeq data while also predicting cross-species for a wide range of genomes with one model.</p>
    <p>We include trained models for land plants and vertebrates which achieve high prediction accuracy on gene annotation for broad phylogenetic groups (land plants and vertebrates, respectively). Within these groups, this eliminates the dependency on retraining and the expertise and data required therefore. Production of comparable, single-method annotations for broad groups has the potential to greatly facilitate downstream analyses; for instance it could avoid some of the inconsistency and errors that are otherwise seen in RNAseq analyses when different annotations are used (<xref rid="btaa1044-B30" ref-type="bibr">Torres-Oliva <italic>et al.</italic>, 2016</xref>; <xref rid="btaa1044-B34" ref-type="bibr">Zhao and Zhang, 2015</xref>).</p>
    <p>We found our models to be highly sensitive to the training genomes we chose. A different set could lead to a significant shift in strengths and weaknesses of the model and a larger and more spread out set of high quality genomes could also result in a wider range of genomes with decent predictions. For this, more computational resources would be required. Simply training with a similar amount of data, but for a different group (e.g. invertebrates of fungi) could also be used to increase the functional predictive range.</p>
    <p>An avenue for future research could be the addition of RNASeq data as additional input. This would bring Helixer on even footing with current tools and could lead to real world applicable performance improvements if the results of this work are any indication, as deep learning has been shown to excel in a multimodal settings (<xref rid="btaa1044-B11" ref-type="bibr">Ching <italic>et al.</italic>, 2018</xref>).</p>
    <p>Finally, development of a post-processing method to go from base pair wise predictions to integrated predictions for whole transcripts at each loci could both further improve performance and would greatly increase real world applications. A post-processing method could for instance take the form of an HMM that worked with the current Helixer output instead of or in addition to raw sequence, or could even take the form of additional neural network layers that output precise locations of transitions (e.g. start &amp; stop codons).</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btaa1044_Supplementary_Data</label>
      <media xlink:href="btaa1044_supplementary_data.zip">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors are grateful for the computational support and GPU access provided by both the Centre for Information and Media Technology (ZIM) and the Institute of Quantitative and Theoretical Biology at Heinrich Heine University.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany’s Excellence Strategy–EXC-2048/1–Project ID: 390686111, and by the BMBF-funded de.NBI Cloud within the German Network for Bioinformatics Infrastructure (de.NBI) (031A537B, 031A533A, 031A538A, 031A533B, 031A535A, 031A537C, 031A534A, 031A532B). </p>
      <p><italic>Conflict of Interest</italic>: none declared. </p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa1044-B1">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Abadi</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) Tensorflow: A system for large-scale machine learning. In: <italic>OSDI'16: Proceedings of the 12th USENIX Symposium on Operating Systems Design and Implementation, </italic>pp. 265–283. Savannah, GA, USA. USENIX Association, Savannah, GA, USA. </mixed-citation>
    </ref>
    <ref id="btaa1044-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aken</surname><given-names>B.L.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>The ensembl gene annotation system</article-title>. <source>Database</source>, <volume>2016</volume>, baw093.</mixed-citation>
    </ref>
    <ref id="btaa1044-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Amin</surname><given-names>M.R.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) Deepannotator: genome annotation with deep learning. In: <italic>BCB '18: Proceedings of the 2018 ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics</italic>, pp. <fpage>254</fpage>–<lpage>259</lpage>. Association for Computing Machinery, New York, NY, USA.</mixed-citation>
    </ref>
    <ref id="btaa1044-B4">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ba</surname><given-names>J.L.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) Layer normalization. <italic>arXiv Preprint arXiv : 1607.06450</italic>.</mixed-citation>
    </ref>
    <ref id="btaa1044-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bergstra</surname><given-names>J.S.</given-names></string-name></person-group><etal>et al</etal> (<year>2011</year>) Algorithms for hyper-parameter optimization. In: <italic>Proceedings of the 24th International Conference on Neural Information Processing Systems</italic>, 24, pp. <fpage>2546</fpage>–<lpage>2554</lpage>. Curran Associates Inc., Red Hook, NY, USA.</mixed-citation>
    </ref>
    <ref id="btaa1044-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bolger</surname><given-names>A.M.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Trimmomatic: a flexible trimmer for illumina sequence data</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>2114</fpage>–<lpage>2120</lpage>.<pub-id pub-id-type="pmid">24695404</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brocchieri</surname><given-names>L.</given-names></string-name></person-group><etal>et al</etal> (<year>2005</year>) 
<article-title>Predicting coding potential from genome sequence: application to betaherpesviruses infecting rats and mice</article-title>. <source>J. Virol</source>., <volume>79</volume>, <fpage>7570</fpage>–<lpage>7596</lpage>.<pub-id pub-id-type="pmid">15919911</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Burge</surname><given-names>C.</given-names></string-name>, <string-name><surname>Karlin</surname><given-names>S.</given-names></string-name></person-group> (<year>1997</year>) 
<article-title>Prediction of complete gene structures in human genomic dna</article-title>. <source>J. Mol. Biol</source>., <volume>268</volume>, <fpage>78</fpage>–<lpage>94</lpage>.<pub-id pub-id-type="pmid">9149143</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cantarel</surname><given-names>B.L.</given-names></string-name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Maker: an easy-to-use annotation pipeline designed for emerging model organism genomes</article-title>. <source>Genome Res</source>., <volume>18</volume>, <fpage>188</fpage>–<lpage>196</lpage>.<pub-id pub-id-type="pmid">18025269</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carninci</surname><given-names>P.</given-names></string-name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>Genome-wide analysis of mammalian promoter architecture and evolution</article-title>. <source>Nat. Genet</source>., <volume>38</volume>, <fpage>626</fpage>–<lpage>635</lpage>.<pub-id pub-id-type="pmid">16645617</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ching</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Opportunities and obstacles for deep learning in biology and medicine</article-title>. <source>J. R. Soc. Interface</source>, <volume>15</volume>, <fpage>20170387</fpage>.<pub-id pub-id-type="pmid">29618526</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B12">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Choudhary</surname><given-names>S.</given-names></string-name></person-group> (<year>2017</year>) <italic>Predicting protein coding boundaries using RNNs</italic>. <ext-link ext-link-type="uri" xlink:href="http://www.saket-choudhary.me/rnn-cds-prediction/predicting-protein-coding.pdf">http://www.saket-choudhary.me/rnn-cds-prediction/predicting-protein-coding.pdf</ext-link>. (11 April 2020, date last accessed).</mixed-citation>
    </ref>
    <ref id="btaa1044-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ewels</surname><given-names>P.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>MultiQC: summarize analysis results for multiple tools and samples in a single report</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>3047</fpage>–<lpage>3048</lpage>.<pub-id pub-id-type="pmid">27312411</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goodstein</surname><given-names>D.M.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Phytozome: a comparative platform for green plant genomics</article-title>. <source>Nucleic Acids Res</source>., <volume>40</volume>, <fpage>D1178</fpage>–<lpage>D1186</lpage>.<pub-id pub-id-type="pmid">22110026</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haas</surname><given-names>B.J.</given-names></string-name></person-group><etal>et al</etal> (<year>2003</year>) 
<article-title>Improving the arabidopsis genome annotation using maximal transcript alignment assemblies</article-title>. <source>Nucleic Acids Res</source>., <volume>31</volume>, <fpage>5654</fpage>–<lpage>5666</lpage>.<pub-id pub-id-type="pmid">14500829</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hochreiter</surname><given-names>S.</given-names></string-name>, <string-name><surname>Schmidhuber</surname><given-names>J.</given-names></string-name></person-group> (<year>1997</year>) 
<article-title>Long short-term memory</article-title>. <source>Neural Comput</source>., <volume>9</volume>, <fpage>1735</fpage>–<lpage>1780</lpage>.<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hon</surname><given-names>C.-C.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Quantification of stochastic noise of splicing and polyadenylation in entamoeba histolytica</article-title>. <source>Nucleic Acids Res</source>., <volume>41</volume>, <fpage>1936</fpage>–<lpage>1952</lpage>.<pub-id pub-id-type="pmid">23258700</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Howe</surname><given-names>K.L.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) 
<article-title>Ensembl genomes 2020-enabling non-vertebrate genomic research</article-title>. <source>Nucleic Acids Res</source>., <volume>48</volume>, <fpage>D689</fpage>–<lpage>D695</lpage>.<pub-id pub-id-type="pmid">31598706</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jaganathan</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Predicting splicing from primary sequence with deep learning</article-title>. <source>Cell</source>, <volume>176</volume>, <fpage>535</fpage>–<lpage>548</lpage>.<pub-id pub-id-type="pmid">30661751</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname><given-names>A.D.</given-names></string-name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>Snap: a web-based tool for identification and annotation of proxy snps using hapmap</article-title>. <source>Bioinformatics</source>, <volume>24</volume>, <fpage>2938</fpage>–<lpage>2939</lpage>.<pub-id pub-id-type="pmid">18974171</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>D.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Graph-based genome alignment and genotyping with hisat2 and hisat-genotype</article-title>. <source>Nat. Biotechnol</source>., <volume>37</volume>, <fpage>907</fpage>–<lpage>915</lpage>.<pub-id pub-id-type="pmid">31375807</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Leinonen</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal>; on behalf of the International Nucleotide Sequence Database Collaboration. (<year>2011</year>) 
<article-title>The sequence read archive</article-title>. <source>Nucleic Acids Res</source>., <volume>39</volume>, <fpage>D19</fpage>–<lpage>D21</lpage>.<pub-id pub-id-type="pmid">21062823</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname><given-names>H.</given-names></string-name></person-group><etal>et al</etal>; 1000 Genome Project Data Processing Subgroup. (<year>2009</year>) 
<article-title>The sequence alignment/map format and samtools</article-title>. <source>Bioinformatics</source>, <volume>25</volume>, <fpage>2078</fpage>–<lpage>2079</lpage>.<pub-id pub-id-type="pmid">19505943</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>F.</given-names></string-name></person-group><etal>et al</etal> (<year>2016a</year>) 
<article-title>De novo identification of replication-timing domains in the human genome by deep learning</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>641</fpage>–<lpage>649</lpage>.<pub-id pub-id-type="pmid">26545821</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>F.</given-names></string-name></person-group><etal>et al</etal> (<year>2016b</year>) 
<article-title>Pedla: predicting enhancers with a deep learning-based algorithmic framework</article-title>. <source>Scientific Rep</source>., <volume>6</volume>, <fpage>28517</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa1044-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oubounyt</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Deepromoter: robust promoter predictor using deep learning</article-title>. <source>Front. Genet</source>., <volume>10</volume>, <fpage>286</fpage>.<pub-id pub-id-type="pmid">31024615</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Quang</surname><given-names>D.</given-names></string-name>, <string-name><surname>Xie</surname><given-names>X.</given-names></string-name></person-group> (<year>2016</year>) 
<article-title>DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences</article-title>. <source>Nucleic Acids Res</source>., <volume>44</volume>, <fpage>e107</fpage>.<pub-id pub-id-type="pmid">27084946</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B01196143">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Simão</surname>,<given-names>F.A.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>BUSCO: assessing genome assembly and annotation completeness with single-copy orthologs</article-title>. <source>Bioinformatics</source>, <volume>31</volume>, <fpage>3210</fpage>–<lpage>3212</lpage>.<pub-id pub-id-type="pmid">26059717</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stanke</surname><given-names>M.</given-names></string-name>, <string-name><surname>Waack</surname><given-names>S.</given-names></string-name></person-group> (<year>2003</year>) 
<article-title>Gene prediction with a hidden Markov model and a new intron submodel</article-title>. <source>Bioinformatics</source>, <volume>19</volume>, <fpage>ii215</fpage>–<lpage>ii225</lpage>.<pub-id pub-id-type="pmid">14534192</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B29">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Thibaud-Nissen</surname><given-names>F.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <chapter-title>Eukaryotic genome annotation pipeline</chapter-title>. In: <source>The NCBI Handbook [Internet]</source>. <edition>2nd edn</edition>. 
<publisher-name>National Center for Biotechnology Information (US</publisher-name>), pp. <fpage>1</fpage>–<lpage>20</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1044-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Torres-Oliva</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>A robust (re-) annotation approach to generate unbiased mapping references for rna-seq-based analyses of differential expression across closely related species</article-title>. <source>BMC Genomics</source>, <volume>17</volume>, <fpage>392</fpage>.<pub-id pub-id-type="pmid">27220689</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Trabelsi</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Comprehensive evaluation of deep learning architectures for prediction of DNA/RNA sequence binding specificities</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>i269</fpage>–<lpage>i277</lpage>.<pub-id pub-id-type="pmid">31510640</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Splicefinder: ab initio prediction of splice sites using convolutional neural network</article-title>. <source>BMC Bioinformatics</source>, <volume>20</volume>, <fpage>652</fpage>.<pub-id pub-id-type="pmid">31881982</pub-id></mixed-citation>
    </ref>
    <ref id="btaa1044-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2004</year>) 
<article-title>A brief review of computational gene prediction methods</article-title>. <source>Genomics Proteomics Bioinf</source>., <volume>2</volume>, <fpage>216</fpage>–<lpage>221</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa1044-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname><given-names>S.</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>B.</given-names></string-name></person-group> (<year>2015</year>) 
<article-title>A comprehensive evaluation of ensembl, refseq, and ucsc annotations in the context of rna-seq read mapping and gene quantification</article-title>. <source>BMC Genomics</source>, <volume>16</volume>, <fpage>97</fpage>.<pub-id pub-id-type="pmid">25765860</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
