<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6020310</article-id>
    <article-id pub-id-type="publisher-id">2238</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-018-2238-7</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>GenoGAM 2.0: scalable and efficient implementation of genome-wide generalized additive models for gigabase-scale genomes</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2949-1758</contrib-id>
        <name>
          <surname>Stricker</surname>
          <given-names>Georg</given-names>
        </name>
        <address>
          <email>gagneur@in.tum.de</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Galinier</surname>
          <given-names>Mathilde</given-names>
        </name>
        <address>
          <email>mathildeemmanuelle.galinier@unimore.it</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Gagneur</surname>
          <given-names>Julien</given-names>
        </name>
        <address>
          <email>gagneur@in.tum.de</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="ISNI">0000000123222966</institution-id><institution-id institution-id-type="GRID">grid.6936.a</institution-id><institution>Department of Informatics, Technical University Munich, </institution></institution-wrap>Boltzmannstr. 3, Garching, Germany </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>27</day>
      <month>6</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>27</day>
      <month>6</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2018</year>
    </pub-date>
    <volume>19</volume>
    <elocation-id>247</elocation-id>
    <history>
      <date date-type="received">
        <day>9</day>
        <month>2</month>
        <year>2018</year>
      </date>
      <date date-type="accepted">
        <day>12</day>
        <month>6</month>
        <year>2018</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2018</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p>GenoGAM (Genome-wide generalized additive models) is a powerful statistical modeling tool for the analysis of ChIP-Seq data with flexible factorial design experiments. However large runtime and memory requirements of its current implementation prohibit its application to gigabase-scale genomes such as mammalian genomes.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>Here we present GenoGAM 2.0, a scalable and efficient implementation that is 2 to 3 orders of magnitude faster than the previous version. This is achieved by exploiting the sparsity of the model using the SuperLU direct solver for parameter fitting, and sparse Cholesky factorization together with the sparse inverse subset algorithm for computing standard errors. Furthermore the HDF5 library is employed to store data efficiently on hard drive, reducing memory footprint while keeping I/O low. Whole-genome fits for human ChIP-seq datasets (ca. 300 million parameters) could be obtained in less than 9 hours on a standard 60-core server. GenoGAM 2.0 is implemented as an open source R package and currently available on GitHub. A Bioconductor release of the new version is in preparation.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p>We have vastly improved the performance of the GenoGAM framework, opening up its application to all types of organisms. Moreover, our algorithmic improvements for fitting large GAMs could be of interest to the statistical community beyond the genomics field.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Genome-wide analysis</kwd>
      <kwd>ChIP-Seq</kwd>
      <kwd>Generalized additive models</kwd>
      <kwd>Sparse inverse subset algorithm</kwd>
      <kwd>Transcription factors</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100007601</institution-id>
            <institution>Horizon 2020</institution>
          </institution-wrap>
        </funding-source>
        <award-id>633974</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100007601</institution-id>
            <institution>Horizon 2020</institution>
          </institution-wrap>
        </funding-source>
        <award-id>633974</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>TUM Open Access Publishing Fund</institution>
        </funding-source>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2018</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p>Chromatin immunoprecipitation followed by deep sequencing (ChIP-Seq), is the reference method for quantification of protein-DNA interactions genome-wide [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. ChIP-Seq allows studying a wide range of fundamental cellular processes such as transcription, replication and genome maintenance, which are characterized by occupancy profiles of specific proteins along the genome. In ChIP-Seq based studies, the quantities of interest are often the differential protein occupancies between experiments and controls, or between two genetic backgrounds, or between two treatments, or combinations thereof.</p>
    <p>We have recently developed a statistical method, GenoGAM (Genome-wide Generalized Additive Model), to flexibly model ChIP-Seq factorial design experiments [<xref ref-type="bibr" rid="CR3">3</xref>]. GenoGAM models ChIP-Seq read count frequencies as products of smooth functions along chromosomes. It provides base-level and region-level significance testing. An important advantage of GenoGAM over competing methods is that smoothing parameters are objectively estimated from the data by cross-validation, eliminating ad-hoc binning and windowing. It leads to increased sensitivity in detecting differential protein occupancies over competing methods, while controlling for type I error rates.</p>
    <p>GenoGAM is implemented as an R package based on the well-established and flexible generalized additive models (GAM) framework [<xref ref-type="bibr" rid="CR4">4</xref>]. On the one hand, it builds on top of the infrastructure provided by the <italic>Bioconductor</italic> software project [<xref ref-type="bibr" rid="CR5">5</xref>]. On the other hand, it uses the mgcv package [<xref ref-type="bibr" rid="CR6">6</xref>], a general-purpose R library for fitting GAMs [<xref ref-type="bibr" rid="CR7">7</xref>] that provides a rich functionality for GAMs with a variety of basis functions, distributions and further features for variable and smoothness selection. In its general form, the implementation for fitting a GAM minimizes a cost function using iterations whose time complexity are quadratic in the number of parameters. Moreover, the time complexity of the implementation for estimating the standard errors of the parameters, which are required for any statistical significance assessment, is cubic in the number of parameters. To allow the fitting of GAMs on complete genomes, which involves millions of parameters, we had proceeded with a tiling approach [<xref ref-type="bibr" rid="CR3">3</xref>]. Genome-wide fits were obtained by fitting models on <italic>tiles</italic>, defined as overlapping genomic intervals of a tractable size, and joining together tile fits at overlap midpoints. With long enough overlaps, this approximation yielded computation times linear in the number of parameters at no practical precision cost. Furthermore, it allowed for parallelization, with speed-ups being linear in the number of cores.</p>
    <p>Nonetheless, application of the current implementation remains limited in practice to small genomes organisms such as yeast or bacteria, or to selected subsets of larger genomes. A genome-wide fit for the yeast genome (ca. 1 million parameters) took 20 hours on a 60-core server. Fits for the human genome could only be done for chromosome 22, the smallest human chromosome.</p>
    <p>Here we introduce a new implementation of GenoGAM that is 2 to 3 orders of magnitude faster. This is achieved by exploiting the sparsity of the model and by using out-of-core data processing. The computing time for parameter and standard error estimation, as well as the memory footprint, is now linear in the number of parameters per tile. The same genome-wide fit for yeast is now obtained in 13 min on a standard 8-core desktop machine. Whole-genome fits for human datasets (ca. 300 million parameters each) are obtained in less than 9 hours on the same 60-core server.</p>
    <p>Before describing the new implementation and results, we provide some necessary mathematical background.</p>
    <sec id="Sec2">
      <title>GenoGAM models</title>
      <p>In a GenoGAM model, we assume ChIP-Seq read counts <italic>y</italic><sub><italic>i</italic></sub> at genomic position <italic>x</italic><sub><italic>i</italic></sub> in the ChIP-Seq sample <italic>j</italic><sub><italic>i</italic></sub> to follow a negative binomial distribution with mean <italic>μ</italic><sub><italic>i</italic></sub> and dispersion parameter <italic>θ</italic>: 
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}} y_{i} \sim \text{NB}(\mu_{i}, \theta) \end{array} $$ \end{document}</tex-math><mml:math id="M2"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mtext>NB</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2238_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where the logarithm of the mean <italic>μ</italic><sub><italic>i</italic></sub> is the sum of an offset <italic>o</italic><sub><italic>i</italic></sub> and one or more smooth functions <italic>f</italic><sub><italic>k</italic></sub> of the genomic position <italic>x</italic><sub><italic>i</italic></sub>: 
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}} \log (\mu_{i}) = o_{i} + \sum\limits_{k = 1}^{K} f_{k} (x_{i}) z_{j_{i}, k} \end{array} $$ \end{document}</tex-math><mml:math id="M4"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:mo>log</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2238_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>The offsets <italic>o</italic><sub><italic>i</italic></sub> are predefined data-point specific constants that account for sequencing depth variations. The elements <inline-formula id="IEq1"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$z_{j_{i}, k}$\end{document}</tex-math><mml:math id="M6"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="12859_2018_2238_Article_IEq1.gif"/></alternatives></inline-formula> of the experimental design matrix <bold>Z</bold> is 1 if smooth function <italic>f</italic><sub><italic>k</italic></sub> contributes to the mean counts of sample <italic>j</italic><sub><italic>i</italic></sub> and 0 otherwise. A typical application is the comparison of treatment versus control samples, for which a GenoGAM model would read: 
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}} \log (\mu_{i}) = o_{i} + f_{\text{control}} (x_{i}) + z_{j_{i}}f_{\text{treatment/control}}(x_{i}) \text{,} \end{array} $$ \end{document}</tex-math><mml:math id="M8"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:mo>log</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mtext>control</mml:mtext></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mtext>treatment/control</mml:mtext></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mtext>,</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2238_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <inline-formula id="IEq2"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$z_{j_{i}}= 0$\end{document}</tex-math><mml:math id="M10"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math><inline-graphic xlink:href="12859_2018_2238_Article_IEq2.gif"/></alternatives></inline-formula> for all control sample data points and <inline-formula id="IEq3"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$z_{j_{i}}= 1$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="12859_2018_2238_Article_IEq3.gif"/></alternatives></inline-formula> for all treatment sample data points. The quantity of interest in such a scenario is the log fold-change of treatment versus control at every genomic position <italic>f</italic><sub>treatment/control</sub>(<italic>x</italic><sub><italic>i</italic></sub>).</p>
      <p>The smooth functions <italic>f</italic><sub><italic>k</italic></sub> are piecewise polynomials consisting of a linear combination of basis functions <italic>b</italic><sub><italic>r</italic></sub> and the respective coefficients <inline-formula id="IEq4"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\beta ^{(k)}_{r}$\end{document}</tex-math><mml:math id="M14"><mml:msubsup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2238_Article_IEq4.gif"/></alternatives></inline-formula>: 
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}} f_{k} (x_{i}) = \sum\limits_{r} \beta_{r}^{(k)} b_{r} (x_{i}) := \left(\mathbf{X}_{k} \boldsymbol{\beta}^{(k)} \right)_{i} \text{,} \end{array} $$ \end{document}</tex-math><mml:math id="M16"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mtext>,</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2238_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <italic>b</italic><sub><italic>r</italic></sub> are cubic B-splines, which are bell-shaped cubic polynomials over a finite local support [<xref ref-type="bibr" rid="CR8">8</xref>]. The column of the <italic>n</italic>×<italic>p</italic><sub><italic>k</italic></sub> matrix <bold>X</bold><sub><italic>k</italic></sub>, where <italic>p</italic><sub><italic>k</italic></sub> is the number of basis functions in smooth <italic>f</italic><sub><italic>k</italic></sub>, represents a basis function <italic>b</italic><sub><italic>r</italic></sub> evaluated at each position <italic>x</italic><sub><italic>i</italic></sub>.</p>
      <p>Typically all smooth functions have the same bases and knot positioning, implying that all <bold>X</bold><sub><italic>k</italic></sub> are equal to each other. Consequently, the complete design matrix <bold>X</bold> is the Kronecker product of the experimental design matrix <bold>Z</bold> and <bold>X</bold><sub><italic>k</italic></sub>. 
<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}} \log (\mu_{i}) = o_{i} + (\mathbf{X} \boldsymbol{\beta})_{i}, \end{array} $$ \end{document}</tex-math><mml:math id="M18"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:mo>log</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2238_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <bold>X</bold>=<bold>Z</bold>⊗<bold>X</bold><sub><italic>k</italic></sub> and the vector <bold><italic>β</italic></bold> is the concatenation of all <bold><italic>β</italic></bold><sup>(<italic>k</italic>)</sup>.</p>
      <p>The fitting of the parameters <bold><italic>β</italic></bold> is carried out by maximizing the negative binomial log-likelihood plus a penalty function: 
<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}} \hat{\boldsymbol{\beta}} = \text{argmax} \left\{l_{\text{NB}} (\boldsymbol{\beta}; \boldsymbol{y}, \theta) - \lambda \boldsymbol{\beta}^{T} (\mathbf{S} + \epsilon \mathbf{I}) \boldsymbol{\beta}\right\} \end{array} $$ \end{document}</tex-math><mml:math id="M20"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mtext>argmax</mml:mtext><mml:mfenced close="}" open="{" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mtext>NB</mml:mtext></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mi mathvariant="bold">S</mml:mi><mml:mo>+</mml:mo><mml:mi>ε</mml:mi><mml:mi mathvariant="bold">I</mml:mi><mml:mo>)</mml:mo><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow></mml:mfenced></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2238_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <bold>S</bold> is a symmetric positive matrix that approximately penalizes the second order derivatives of the smooth functions. This approach is called penalized B-splines or P-splines [<xref ref-type="bibr" rid="CR9">9</xref>]. The <italic>ε</italic><bold>I</bold> term adds regularization on the squared values of the <bold><italic>β</italic></bold>’s, which is particularly useful for regions with many zero counts. The smoothing parameter <italic>λ</italic> controls the amount of regularization. Both the smoothing parameter <italic>λ</italic> and the dispersion parameter <italic>θ</italic> are considered as hyperparameters that are estimated by cross-validation [<xref ref-type="bibr" rid="CR3">3</xref>].</p>
      <p>Newton-Raphson methods are used to maximize Eq. (<xref rid="Equ6" ref-type="">6</xref>). The idea is to iteratively maximize quadratic approximations of the objective function around the current estimate. The current parameter vector <bold><italic>β</italic></bold><sub><italic>t</italic></sub> is updated as: 
<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}} \boldsymbol{\beta}_{t + 1} = \boldsymbol{\beta}_{t} - \mathbf{H}^{-1} (\boldsymbol{\beta}_{t}) \triangledown f(\boldsymbol{\beta}_{t}) \end{array} $$ \end{document}</tex-math><mml:math id="M22"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>▿</mml:mo><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2238_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where the negative inverse Hessian <bold>H</bold><sup>−1</sup>(<bold><italic>β</italic></bold><sub><italic>t</italic></sub>) captures the local curvature of the objective function, and the gradient vector <inline-formula id="IEq5"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\triangledown f(\boldsymbol {\beta }_{t})$\end{document}</tex-math><mml:math id="M24"><mml:mo>▿</mml:mo><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><inline-graphic xlink:href="12859_2018_2238_Article_IEq5.gif"/></alternatives></inline-formula> captures the local slope. The iteration stops when the change in the log-likelihood or the norm of the gradient of the log-likelihood falls below a specified convergence threshold. Because the negative binomial distribution with known dispersion parameter <italic>θ</italic> is part of the exponential family, the penalized log-likelihood is convex and thus convergence is guaranteed.</p>
    </sec>
    <sec id="Sec3">
      <title>Standard error computation</title>
      <p>For the purpose of statistical testing, variance of the smooth estimates are also needed. These are of the form: 
<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}} \text{Var}(f_{k}(x_{i})) = \sigma^{2}_{i,k} = \left(\mathbf{X}_{k} \mathbf{H}_{k}^{-1} \mathbf{X}_{k}^{T}\right)_{i,i} \text{,} \end{array} $$ \end{document}</tex-math><mml:math id="M26"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:mtext>Var</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mtext>,</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2238_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <bold>H</bold><sub><italic>k</italic></sub> is the Hessian with respect to the parameters <bold><italic>β</italic></bold><sup>(<italic>k</italic>)</sup> and can be simply extracted from <bold>H</bold>.</p>
    </sec>
    <sec id="Sec4">
      <title>Remarks on sparsity</title>
      <p>The Hessian <bold>H</bold> is computed as: 
<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}} \mathbf{H} = \mathbf{X}^{T} \mathbf{W} \mathbf{X} - 2 \lambda (\mathbf{S} + \epsilon \mathbf{I}) \end{array} $$ \end{document}</tex-math><mml:math id="M28"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:mi mathvariant="bold">H</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi mathvariant="bold">W</mml:mi><mml:mi mathvariant="bold">X</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>λ</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold">S</mml:mi><mml:mo>+</mml:mo><mml:mi>ε</mml:mi><mml:mi mathvariant="bold">I</mml:mi><mml:mo>)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2238_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>with <bold>W</bold> a diagonal matrix [<xref ref-type="bibr" rid="CR6">6</xref>].</p>
      <p>However, the number of nonzeros for each row of the design matrix <bold>X</bold> is at most 5 times the number of smooth functions because every genomic position <italic>x</italic><sub><italic>i</italic></sub> is overlapped by 5 cubic B-splines <italic>b</italic><sub><italic>r</italic></sub> only. Moreover, the penalization matrix <bold>S</bold> only has 5 nonzeros per row, as it encodes the second-order difference penalties between coefficients of neighboring splines [<xref ref-type="bibr" rid="CR9">9</xref>]. Hence, the matrices <bold>X</bold> and <bold>S</bold>, and therefore <bold>H</bold>, which appears in the majority of the computations via Eqs. (<xref rid="Equ7" ref-type="">7</xref>) and (<xref rid="Equ8" ref-type="">8</xref>), are very sparse. Here we make use of the sparsity of these matrices to drastically speed up the fitting of the parameters.</p>
    </sec>
  </sec>
  <sec id="Sec5">
    <title>Implementation</title>
    <sec id="Sec6">
      <title>Workflow</title>
      <p>Data preprocessing consists of reading raw read alignments from BAM files, centering the fragments, computing the coverage <bold><italic>y</italic></bold>, and splitting the data by genomic tiles (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). Afterwards, normalization factors for sequencing depth variation are computed using DESeq2 [<xref ref-type="bibr" rid="CR10">10</xref>]. In the new version of GenoGAM we store the preprocessed data in HDF5 files [<xref ref-type="bibr" rid="CR11">11</xref>] through the R packages HDF5Array [<xref ref-type="bibr" rid="CR12">12</xref>] and rhdf5 [<xref ref-type="bibr" rid="CR13">13</xref>]. This allows writing in parallel as the data is being preprocessed, which reduces the memory footprint of this step. For all subsequent matrix operations the Matrix package is used, which implements routines for storage, manipulation and operations on sparse matrices [<xref ref-type="bibr" rid="CR14">14</xref>].
<fig id="Fig1"><label>Fig. 1</label><caption><p>Schematic overview highlighting the difference between GenoGAM 1.0 and GenoGAM 2.0: Raw BAM Files are read-in, pre-processed normalized and written to hard drive in HDF5 format. Moreover, normalization factors for sequencing depth variation are computed using DESeq2 [<xref ref-type="bibr" rid="CR10">10</xref>]. The resulting object is the dataset upon which fitting is done. Then global hyperparameters are estimated by cross-validation and for each tile coefficients are estimated via Newton-Raphson and standard errors via sparse inverse subset algorithm. The final model is written as a new object to hard drive in HDF5 format. Note, that the schematic view is a simplification: The pre-processed dataset and the fitted model are not generated in memory and written to HDF5 in the end. Instead, all HDF5 matrices are initialized on hard drive directly and the writing is done on the fly. Blue (GenoGAM 1.0) and orange colors (GenoGAM 2.0) mark differences between both GenoGAM versions, simultaneously displaying the content of this paper</p></caption><graphic xlink:href="12859_2018_2238_Fig1_HTML" id="MO1"/></fig>
</p>
      <p>Fitting GenoGAM models on tiles is achieved by the Newton-Raphson algorithm (Eq. <xref rid="Equ7" ref-type="">7</xref>). This is done on few representative tiles during cross-validation in order to identify optimal hyperparameters <italic>λ</italic> and <italic>θ</italic>, and subsequently when fitting the model on the full dataset.</p>
      <p>The variance of the smooth estimates (Eq. <xref rid="Equ8" ref-type="">8</xref>) is obtained using the sparse inverse subset algorithm as detailed in a subsection below. The implementation is based on the R package sparseinv [<xref ref-type="bibr" rid="CR15">15</xref>], which wraps relevant code from the SuiteSparse software [<xref ref-type="bibr" rid="CR16">16</xref>]. As in the previous GenoGAM model [<xref ref-type="bibr" rid="CR3">3</xref>], fitting on different tiles is conducted in parallel. The result objects for the fits, variances and parameters are initialized prior to fitting on hard drive. This allows the processes to write results in parallel on the fly, ensuring fast computation and low memory footprint. The HDF5 storage is further optimized for reading time by adjusting HDF5 chunk size to the size of the tiles (for preprocessed count data) and chunks (for fits and variance). As HDF5 is not process-safe on R level, writing is serialized by a queuing mechanism.</p>
      <p>The parallelization backend is provided by the R package BiocParallel. It offers an interface to a variety of backends and can be registered independently of GenoGAM. Parallelization is performed over chromosomes during the read-in process. Over tuples of folds and tiles during cross-validation process and over tiles during fitting process. Because some backends have a particular long start-up time, the use of many processes might end up dominating computation time. Specifically during cross-validation on small and limited number of regions, this might pose a problem. Therefore an optimal number of workers is automatically obtained and registered by the cross-validation function and reset on exit.</p>
    </sec>
    <sec id="Sec7">
      <title>Newton-Raphson implementation for sparse matrices</title>
      <p>We estimate the parameters <bold><italic>β</italic></bold> by maximizing the penalized log-likelihood using the Newton-Raphson iteration (Eq. <xref rid="Equ7" ref-type="">7</xref>). Due to the sparsity of the matrices <bold>X</bold>, <bold>D</bold> and <bold>S</bold>, <bold>H</bold> is sparse and cheap to compute. The inverse is never explicitly formed. Instead the linear system is solved by a direct solver using the SuperLU library [<xref ref-type="bibr" rid="CR17">17</xref>]. Furthermore all matrices are stored in a sparse format, avoiding redundant storage of zeros.</p>
      <p>Our new fitting algorithm differs from the one of mgcv in two ways. First, mgcv uses Iteratively Reweighted Least Squares, a Newton-Raphson method that employs the Fisher information matrix <inline-formula id="IEq6"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\boldsymbol {\mathcal {I}}$\end{document}</tex-math><mml:math id="M30"><mml:mi mathvariant="bold-script">I</mml:mi></mml:math><inline-graphic xlink:href="12859_2018_2238_Article_IEq6.gif"/></alternatives></inline-formula>, defined as the negative expectation of the Hessian <bold>H</bold>, instead of the Hessian in the iteration (Eq. <xref rid="Equ7" ref-type="">7</xref>). However, this did not lead to any measurable differences in the fitted parameters. Second, mgcv uses QR decomposition of the design matrix <bold>X</bold> [<xref ref-type="bibr" rid="CR6">6</xref>]. However, general QR decomposition destroys the sparse structure of <bold>X</bold>. We have investigated the use of sparse QR decompositions but this was less efficient than our final implementation.</p>
    </sec>
    <sec id="Sec8">
      <title>Variance computation using the sparse inverse subset algorithm</title>
      <p>The Hessian <bold>H</bold> is sparse, but its inverse, the covariance matrix <bold>H</bold><sup>−1</sup>, usually is not. However, the variances of interest (Eq. <xref rid="Equ8" ref-type="">8</xref>) can be computed using only a subset of the elements of the inverse <bold>H</bold><sup>−1</sup>. Specifically, denoting for any matrix <bold>A</bold>: 
<list list-type="bullet"><list-item><p>NZ(<bold>A</bold>)={(<italic>i</italic>,<italic>j</italic>),<bold>A</bold><sub><italic>i</italic>,<italic>j</italic></sub>≠0} the indices of nonzero elements,</p></list-item><list-item><p><italic>C</italic><sub><italic>i</italic></sub>(<bold>A</bold>)={<italic>j</italic>:<bold>A</bold><sub><italic>i</italic>,<italic>j</italic></sub>≠0} the column indices of nonzero elements for the i-th row,</p></list-item><list-item><p><italic>R</italic><sub><italic>j</italic></sub>(<bold>A</bold>)={<italic>i</italic>:<bold>A</bold><sub><italic>i</italic>,<italic>j</italic></sub>≠0} the column indices of nonzero elements for the j-th row,</p></list-item></list></p>
      <p>then <bold><italic>σ</italic></bold><sup>2</sup> can be computed only using the elements (<bold>H</bold><sup>−1</sup>)<sub><italic>l</italic>,<italic>j</italic></sub>, where (<italic>l</italic>,<italic>j</italic>)∈ NZ(<bold>H</bold>). Indeed, on the one hand we have: 
<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{*{20}l}\sigma^{2}_{i} &amp;= \sum\limits_{l,j} \mathbf{X}_{i,l} \left(\mathbf{H}^{-1}\right)_{l,j} \mathbf{X}_{i,j}\\ &amp;= \sum\limits_{(l,j) \in C_{i}^{2} (\mathbf{X})} \mathbf{X}_{i,l} \left(\mathbf{H}^{-1}\right)_{l,j} \mathbf{X}_{i,j}  \end{array} $$ \end{document}</tex-math><mml:math id="M32"><mml:mtable class="align" columnalign="left"><mml:mtr><mml:mtd class="align-1"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mtd><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="2em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd class="align-1"/><mml:mtd class="align-2"><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">∑</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">H</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mspace width="2em"/></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2238_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>On the other hand, Eq. <xref rid="Equ9" ref-type="">9</xref> implies that NZ(<bold>H</bold>)= NZ(<bold>X</bold><sup><italic>T</italic></sup><bold>W</bold><bold>X</bold>)∪ NZ(<bold>S</bold>)∪ NZ(<bold>I</bold>). Since 
<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}} (\mathbf{X}^{T} \mathbf{W} \mathbf{X})_{l,j} = \left(\sum\limits_{i} \mathbf{X}_{i,l} \mathbf{W}_{i,i} \mathbf{X}_{i,j}\right), \end{array} $$ \end{document}</tex-math><mml:math id="M34"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi mathvariant="bold">W</mml:mi><mml:mi mathvariant="bold">X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2238_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>it follows that: 
<disp-formula id="Equa"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{*{20}l} {} \left(\mathbf{X}^{T} \mathbf{W} \mathbf{X}\right)_{l,j} \neq 0 &amp;\Leftrightarrow \exists i, i \in R_{l} (\mathbf{X}) \text{ and}~ i \in R_{j} (\mathbf{X}) \\&amp;\Leftrightarrow \exists i, (l,j) \in C_{i}^{2} (\mathbf{X}) \end{array} $$ \end{document}</tex-math><mml:math id="M36"><mml:mtable class="align" columnalign="left"><mml:mtr><mml:mtd class="align-1"><mml:msub><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi mathvariant="bold">W</mml:mi><mml:mi mathvariant="bold">X</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mtd><mml:mtd class="align-2"><mml:mo>⇔</mml:mo><mml:mo>∃</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>)</mml:mo><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>)</mml:mo><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mspace width="2em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd class="align-1"/><mml:mtd class="align-2"><mml:mo>⇔</mml:mo><mml:mo>∃</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo><mml:mo>∈</mml:mo><mml:msubsup><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>)</mml:mo><mml:mspace width="2em"/></mml:mtd><mml:mtd><mml:mspace width="2em"/></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2238_Article_Equa.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>Moreover, the nonzeros of the identity matrix <bold>I</bold> is a subset of the nonzeros of the second-order differences penalization matrix <bold>S</bold> [<xref ref-type="bibr" rid="CR9">9</xref>]. Furthermore, the nonzeros of the second-order differences penalization matrix <bold>S</bold>, which penalizes differences between triplets of consecutive splines, is a subset of the nonzeros of <bold>X</bold><sup><italic>T</italic></sup><bold>X</bold>, since genomic positions overlap five consecutive splines when using cubic B-splines. Hence, <inline-formula id="IEq7"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\operatorname {NZ}(\mathbf {H}) = \left \{ (l,j), \exists i, (l,j) \in C_{i}^{2} (\mathbf {X}) \right \}$\end{document}</tex-math><mml:math id="M38"><mml:mo>NZ</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfenced close="}" open="{" separators=""><mml:mrow><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mo>∃</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>(</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>)</mml:mo><mml:mo>∈</mml:mo><mml:munderover><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:mo>(</mml:mo><mml:mi mathvariant="bold">X</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2018_2238_Article_IEq7.gif"/></alternatives></inline-formula>. Together with Eq. <xref rid="Equ10" ref-type="">10</xref>, this proves the result.</p>
      <p>Using only the elements of <bold>H</bold><sup>−1</sup> that are in NZ(<bold>H</bold>) applies to computing the variance of any linear combinations of the <bold><italic>β</italic></bold> based on the same sparse structure of <bold>X</bold> or a subset of it. Hence, it applies to computing the variance of the predicted value for any smooth function <italic>f</italic><sub><italic>k</italic></sub>(<italic>x</italic>) or computing the variance of the derivatives of any order <italic>r</italic> of any smooth <inline-formula id="IEq8"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\frac {d^{r} f_{k}(x)}{d^{r} x}$\end{document}</tex-math><mml:math id="M40"><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msup><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12859_2018_2238_Article_IEq8.gif"/></alternatives></inline-formula>.</p>
      <p>To obtain the elements of <bold>H</bold><sup>−1</sup> that are in NZ(<bold>H</bold>), we used the sparse inverse subset algorithm [<xref ref-type="bibr" rid="CR18">18</xref>]. Given a sparse Cholesky decomposition of symmetric matrix <bold>A</bold>=<bold>L</bold><bold>L</bold><sup><italic>T</italic></sup>, the sparse inverse subset algorithm returns the values of the inverse <bold>A</bold><sup>−1</sup> that are nonzero in the Cholesky factor <bold>L</bold>. Since nonzero in the lower triangle of <bold>A</bold> are nonzeros in the Cholesky factor <bold>L</bold> [<xref ref-type="bibr" rid="CR19">19</xref>], the sparse inverse subset algorithm provides the required elements of <bold>H</bold><sup>−1</sup> when applied to a sparse Cholesky decomposition of <bold>H</bold>. See also Rue [<xref ref-type="bibr" rid="CR20">20</xref>] for similar ideas for Gaussian Markov Fields. To perform the sparse inverse subset algorithm, we used the R package sparseinv [<xref ref-type="bibr" rid="CR15">15</xref>], itself a wrapper of relevant code from the SuiteSparse software [<xref ref-type="bibr" rid="CR16">16</xref>].</p>
      <p>Once the sparse inverse subset of the Hessian is obtained, <inline-formula id="IEq9"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\sigma _{i}^{2}$\end{document}</tex-math><mml:math id="M42"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2238_Article_IEq9.gif"/></alternatives></inline-formula> can be computed according to Eq. (<xref rid="Equ10" ref-type="">10</xref>) with a slight improvement: Because only the diagonal is needed from the final matrix product, the implementation does not perform two matrix multiplications. Instead, only the first product is computed, then multiplied element-wise with <inline-formula id="IEq10"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\mathbf {X}^{T}_{k}$\end{document}</tex-math><mml:math id="M44"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2238_Article_IEq10.gif"/></alternatives></inline-formula> and summed over the columns.</p>
    </sec>
  </sec>
  <sec id="Sec9" sec-type="results">
    <title>Results</title>
    <sec id="Sec10">
      <title>Leveraging the sparse data structure allows for faster parameter estimation</title>
      <p>Figure <xref rid="Fig2" ref-type="fig">2</xref> displays the comparison in fitting runtime (A) and memory usage (B) of our Newton-Raphson method versus the method underlying the previous GenoGAM version on a single core. Computation was capped at approximately 2 h, which leads the blue line (GenoGAM 1.0) to end after around 1100 parameters. It can be clearly seen that exploiting the advantages of the data structures leads to improvements by 2 to 3 orders of magnitude. At the last comparable point at 1104 parameters it took the previous method 1 hours and 37 min, while it was only 1 s for the Newton-Raphson method. This number increased a little bit towards the end to almost 5 s for 5000 parameters.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Coefficient estimation performance. <bold>a</bold> Empirical runtime for the estimation of coefficients vector <bold><italic>β</italic></bold> is plotted in log-scale against increasing number of parameters (also log-scale). The runtime is capped at around 2 hours, such that runtime of previous GenoGAM version (blue line) terminates after 1100 parameters. The new version of GenoGAM (orange line) achieves linear runtime in <italic>p</italic> (dotted line <italic>p</italic>), the number of parameters, compared to the previous cubic complexity (dotted line <italic>p</italic><sup>3</sup>). <bold>b</bold> Memory consumption in MByte for the estimation of coefficients vector <bold><italic>β</italic></bold> is plotted against number of parameters (also log-scale). Due to the runtime cap at around 2 hours the runtime of previous GenoGAM version (blue line) does terminate after 1100 parameters. The storage of matrices in sparse format and direct solvers avoiding full inversion keep the memory footprint low and linear in <italic>p</italic> (dotted line <italic>p</italic>) for the new GenoGAM version (orange line) compared to quadratic in the previous version (blue line, dotted line <italic>p</italic><sup>2</sup>)</p></caption><graphic xlink:href="12859_2018_2238_Fig2_HTML" id="MO2"/></fig>
</p>
      <p>Additionally, the more efficient storage of sparse matrices and the lightweight implementation reduces the overhead and memory footprint. Again at the last comparable point, the memory used by the previous method is 8 Gbyte while it is 52 MByte by the new method, increasing to 250 MByte at the 5000 parameters mark. Moreover, runtime per tile drops empirically from growing cubically with the number of parameters in GenoGAM 1.0 to linearly in GenoGAM 2.0. Also, The memory footprint drops empirically from growing quadratically with the number of parameters in GenoGAM 1.0 to linearly in GenoGAM 2.0 (dashed black lines fitted to the performance data).</p>
    </sec>
    <sec id="Sec11">
      <title>Exact <bold><italic>σ</italic></bold><sup>2</sup> computation by the sparse inverse subset algorithm</title>
      <p>Alternatively to the direct computation of the inverse Hessian with consecutive computation of variance vector <bold><italic>σ</italic></bold><sup>2</sup>, it is also possible to directly compute <bold><italic>σ</italic></bold><sup>2</sup>. Here and hereafter the smooth function specific index <italic>k</italic> is dropped for simplicity. In a comment to the paper of Lee and Wand [<xref ref-type="bibr" rid="CR21">21</xref>], a direct way to compute <bold><italic>σ</italic></bold><sup>2</sup> without inverting <bold>H</bold> was proposed by Simon Wood [<xref ref-type="bibr" rid="CR22">22</xref>]. The comment states, that in general, if <italic>y</italic>=<bold>X</bold><italic>β</italic>, then 
<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{@{}rcl@{}} \sigma^{2}_{i} = \sum\limits^{p}_{j = 1} \left(\left(\mathbf{X} \mathbf{P}^{T} \mathbf{L}^{-1}\right)_{i,j}\right)^{2} \end{array} $$ \end{document}</tex-math><mml:math id="M46"><mml:mtable class="eqnarray" columnalign="left center right"><mml:mtr><mml:mtd class="eqnarray-1"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi mathvariant="bold">X</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant="bold">L</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2018_2238_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>Where <bold>P</bold> is the permutation matrix and <bold>L</bold><sup>−1</sup> is the inverted lower triangular matrix resulting from Cholesky decomposition of <bold>X</bold><sup><italic>T</italic></sup><bold>H</bold><sup>−1</sup><bold>X</bold>.</p>
      <p>Figure <xref rid="Fig3" ref-type="fig">3</xref> shows the comparison of both methods in time and memory on a single core, with the above proposed method depicted as “indirect” (blue). While both methods have linear memory footprint, the slope of the indirect method is around four times higher. The computation time is significantly in favor of the sparse inverse algorithm. This is because for every <inline-formula id="IEq11"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\sigma ^{2}_{i}$\end{document}</tex-math><mml:math id="M48"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2238_Article_IEq11.gif"/></alternatives></inline-formula> a triangular system has to be solved to obtain (<bold>X</bold><bold>P</bold><sup><italic>T</italic></sup>)<sub><italic>i</italic></sub><bold>L</bold><sup>−1</sup>. Although solving the complete system at once is faster, it had a high memory consumption when it came to increased number of parameters in our implementation. Thus the performance presented is based on batches of <inline-formula id="IEq12"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$\sigma ^{2}_{i}$\end{document}</tex-math><mml:math id="M50"><mml:msubsup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="12859_2018_2238_Article_IEq12.gif"/></alternatives></inline-formula> to obtain a fair trade-off between runtime and memory. Nevertheless, the difference remains around 2 orders of magnitude. Moreover runtime goes now linearly in practice for the sparse inverse subset algorithm compared to quadratically for the indirect method (dashed black lines fitted to the performance data).
<fig id="Fig3"><label>Fig. 3</label><caption><p>Standard error computation. <bold>a</bold> Empirical runtime for the computation of standard error vector <bold><italic>σ</italic></bold><sup>2</sup> is plotted in log-scale against increasing number of parameters (also log-scale). Computation based on sparse inverse subset algorithm (orange line) achieves linear runtime in <italic>p</italic> (dotted line <italic>p</italic>), the number of parameters, compared to quadratic complexity (dotted line <italic>p</italic><sup>2</sup>) of the “indirect” method (blue line). <bold>b</bold> Memory consumption in MByte for the computation of standard error vector <bold><italic>σ</italic></bold><sup>2</sup> is plotted against number of parameters. Though both methods achieve linear memory consumption in <italic>p</italic>, the slope of the “indirect” method (blue line) is around 4 times greater than of the sparse inverse subset algorithm (orange line) likely due to the recursive computation of the inverse instead of solving of a triangular system</p></caption><graphic xlink:href="12859_2018_2238_Fig3_HTML" id="MO3"/></fig>
</p>
    </sec>
    <sec id="Sec12">
      <title>Performance on human and yeast ChIP-Seq datasets</title>
      <p>The previous version of GenoGAM could only be partially applied genome-wide for megabase-scale genomes such as the yeast genome and was impractical for gigabase-scale genomes such as the human genome. A genome-wide model fit with two conditions and two replicates each took approximately 20 h on 60 cores [<xref ref-type="bibr" rid="CR3">3</xref>]. With computational and numerical improvement on one side and a data model largely stored on hard drive on the other side, runtime and memory requirements have dropped significantly. Figure <xref rid="Fig4" ref-type="fig">4</xref> shows the runtime performance on seven human ChIP-Seq datasets with two replicates for the IP and one or two replicates for the control. The analysis was performed with 60 cores on a cluster, the memory usage never exceeded 1.5 GB per core and was mostly significantly lower. The overall results show that around 20 min are spent with pre-processing the data, which is largely occupied by writing the data to HDF5 files. One hour of cross-validation, to find the right hyperparameters and around 7 to 8 h of fitting, amounting to a total runtime of 8 to 9 h. It is also notable, that the transcription factors NRF1, MNT and FOXA1 include two controls instead of one, thus efficiently increasing the amount of data to fit by a third, but the runtime by around 40 min.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Genome-wide performance for human and yeast. The performance of GenoGAM 2.0 on seven human ChIP-Seq datasets for the transcription factors NRF1, MNT, FOXA1, MAFG, KLF1, IRF9 and CEBPB. The first three of which contain two replicates for the control, while the rest contains only one. This increases the data by around a 1/3, but the runtime by around 40 min, equivalent to approximately 1/11. Overall ca. 20 min are spent on data processing (blue), up to one hour on cross-validation (green) and 7 - 8 h of fitting (orange) amounting to a total of 8 - 9 h runtime on 60 cores, with the snow parallel backend and HDF5 data structure. At the very top yeast runtime is shown on a regular machine with 8 cores, the multicore backend and all data kept in memory avoiding I/O to hard drive. Data processing (blue, almost not visible) takes 40 s, cross-validation around 9 min (green) and fitting 3.5 min (red)</p></caption><graphic xlink:href="12859_2018_2238_Fig4_HTML" id="MO4"/></fig>
</p>
      <p>Additionally, the same yeast analysis is shown by running on a laptop with 8 cores for comparison to the previous version. The total runtime is around 13 min with the cross-validation significantly dominating both other steps (around 9 min). This is due to the fact, that the number of regions used is fixed at 20, resulting in 200 model fitting runs for one 10-fold cross-validation iteration. Hence, for a small genome like the yeast genome, hyperparameter optimization may take more time than the actual model fitting. Note, that during cross-validation the only difference between human and yeast analysis is the underlying data and the parallel backend. However the runtime on yeast is only 1/6 of the runtime in human. Both factors play a role in this: First, the parallel backend in the yeast run uses the Multicore backend, allowing for shared memory on one machine. While the human run uses the Snow (<bold>s</bold>imple <bold>n</bold>etwork <bold>o</bold>f <bold>w</bold>orkstations) backend, which needs to initiate the workers and copy the needed data first, resulting in an overall greater overhead. Second, convergence on yeast data is generally faster due to higher coverage resulting not only in less iterations by the Newton-Raphson, but also during cross-validation.</p>
    </sec>
    <sec id="Sec13">
      <title>Replication of previous benchmark analyses show equivalent biological accuracy</title>
      <p>To demonstrate that GenoGAM 2.0 leads to the same results than GenoGAM 1.0 we have re-generated benchmark analyses of the first paper [<xref ref-type="bibr" rid="CR3">3</xref>]. The first benchmark is a differential occupancy application that demonstrates that GenoGAM has greater sensitivity for same specificities than alternative methods (Fig. <xref rid="Fig5" ref-type="fig">5</xref><xref rid="Fig5" ref-type="fig">a</xref>-<xref rid="Fig5" ref-type="fig">b</xref>). The second benchmark shows that GenoGAM is on par with alternative methods to infer peak summit positions in ChIP-Seq data of transcription factors (Fig. <xref rid="Fig5" ref-type="fig">5</xref><xref rid="Fig5" ref-type="fig">c</xref>). Consistently, with the fact that GenoGAM 2.0 fits the same function than GenoGAM 1.0, the performance on these two benchmarks matched.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Replication from our previous study [<xref ref-type="bibr" rid="CR3">3</xref>] with GenoGAM 2.0. <bold>a</bold> Replication of figure 3A from our previous study [<xref ref-type="bibr" rid="CR3">3</xref>]. ROC curve based on a quantile cutoff of 0.15 (15% of the genes are assumed to be true negatives). GenoGAM (orange and blue) has a constantly higher recall with a lower false positive rate. <bold>b</bold> Replication of Fig. <xref rid="Fig3" ref-type="fig">3</xref><xref rid="Fig3" ref-type="fig">b</xref> from our previous study [<xref ref-type="bibr" rid="CR3">3</xref>]. Area under the curve (AUC) for all possible quantile cutoffs from 0 to 1 in steps of 0.01. GenoGAM 1.0 (blue) and GenoGAM 2.0 (orange) are almost identical and are thus largely overlapping. Up to a cutoff of 0.6, GenoGAM (orange and blue) performs consistently better than all competitor methods by around 0.03-0.04 points above the second best method (csaw and DESeq2, pink and green, respectively). The entire range of quantile cutoffs is shown out of completeness, reasonable values are between 0.15 and 0.25. <bold>c</bold> Replication of supplementary figure S9C from our previous study [<xref ref-type="bibr" rid="CR3">3</xref>]. Proportion of significant peaks within 30 bp of motif center and 95% bootstrap confidence interval (error bars) for six ENCODE transcription factors (CEBPB, CTCF, USF1, MAX, PAX5, YY1) on chromosome 22 and for the yeast TFIIB dataset</p></caption><graphic xlink:href="12859_2018_2238_Fig5_HTML" id="MO5"/></fig>
</p>
      <p>These improvements have required us to re-implement the fitting of generalized additive models, since GenoGAM 1.0 was based on an generic R package for fitting generalized additive models. We have restricted the implementation so far to the negative binomial distribution. Therefore, application to methylation data, which requires the quasi-binomial distribution, is not yet supported.</p>
    </sec>
  </sec>
  <sec id="Sec14" sec-type="conclusion">
    <title>Conclusion</title>
    <p>We have significantly improved the implementation of GenoGAM [<xref ref-type="bibr" rid="CR3">3</xref>] on three main aspects: Data storage, coefficient estimation and standard error computation. We showed its runtime and memory footprint to scale linearly with the number of parameters per tiles. As a result, GenoGAM can be applied overnight to gigabase-scale genome datasets on a typical lab server. Runtime for mega-base genomes like the yeast genome is within minutes on a standard PC. Finally, our algorithmic improvements apply to GAMs of long longitudinal data and can therefore be relevant for a broader community beyond the field of genomics.</p>
  </sec>
  <sec id="Sec15">
    <title>Availability and requirements</title>
    <p><bold>Project name:</bold> GenoGAM</p>
    <p>
      <bold>Project home page:</bold>
      <ext-link ext-link-type="uri" xlink:href="https://github.com/gstricker/fastGenoGAM">https://github.com/gstricker/fastGenoGAM</ext-link>
    </p>
    <p><bold>Operating system(s):</bold> Platform independent</p>
    <p><bold>Programming language:</bold> R, C++</p>
    <p><bold>Other requirements:</bold> R 3.4.1 (<ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/">https://cran.r-project.org/</ext-link>) or higher</p>
    <p><bold>License:</bold> GPL-2</p>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>ChIP-Seq</term>
        <def>
          <p>chromatin immunoprecipitation with massively parallel DNA sequencing</p>
        </def>
      </def-item>
      <def-item>
        <term>GAM</term>
        <def>
          <p>Generalized additive model</p>
        </def>
      </def-item>
      <def-item>
        <term>HDF5</term>
        <def>
          <p>Hierarchical data format</p>
        </def>
      </def-item>
      <def-item>
        <term>IP</term>
        <def>
          <p>Immunoprecipitation</p>
        </def>
      </def-item>
      <def-item>
        <term>NB</term>
        <def>
          <p>Negative binomial distribution</p>
        </def>
      </def-item>
      <def-item>
        <term>P-splines</term>
        <def>
          <p>Penalized B-splines</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank Alexander Bertram, Parham Solaimani, Martin Morgan and Hervé Pagès for support and advice during the implementation of the second version of GenoGAM, Thomas Huckle and Simon Wood for fruitful discussions and advice on sparse matrix methods.</p>
    <sec id="d29e2872">
      <title>Funding</title>
      <p>This project has received funding from the European Union’s Horizon 2020 research and innovation program under grant agreement No. 633974 (J.G. and G.S.). This work was supported by the German Research Foundation (DFG) and the Technical University of Munich within the funding program Open Access Publishing. The funding bodies played no role in the design of the study, the collection, analysis, or interpretation of data or in writing the manuscript.</p>
    </sec>
    <sec id="d29e2877">
      <title>Availability of data and materials</title>
      <p>The datasets analyzed during the current study are available from ENCODE:</p>
      <p>∙ CEBPB: <ext-link ext-link-type="uri" xlink:href="https://www.encodeproject.org/experiments/ENCSR000EHE">https://www.encodeproject.org/experiments/ENCSR000EHE</ext-link></p>
      <p>∙ FOXA1: <ext-link ext-link-type="uri" xlink:href="https://www.encodeproject.org/experiments/ENCSR267DFA">https://www.encodeproject.org/experiments/ENCSR267DFA</ext-link></p>
      <p>∙ IRF9: <ext-link ext-link-type="uri" xlink:href="https://www.encodeproject.org/experiments/ENCSR926KTP">https://www.encodeproject.org/experiments/ENCSR926KTP</ext-link></p>
      <p>∙ KLF1: <ext-link ext-link-type="uri" xlink:href="https://www.encodeproject.org/experiments/ENCSR550HCT">https://www.encodeproject.org/experiments/ENCSR550HCT</ext-link></p>
      <p>∙ MAFG: <ext-link ext-link-type="uri" xlink:href="https://www.encodeproject.org/experiments/ENCSR818DQV">https://www.encodeproject.org/experiments/ENCSR818DQV</ext-link></p>
      <p>∙ MNT: <ext-link ext-link-type="uri" xlink:href="https://www.encodeproject.org/experiments/ENCSR261EDU">https://www.encodeproject.org/experiments/ENCSR261EDU</ext-link></p>
      <p>∙ NRF1: <ext-link ext-link-type="uri" xlink:href="https://www.encodeproject.org/experiments/ENCSR135ANT">https://www.encodeproject.org/experiments/ENCSR135ANT</ext-link></p>
      <p>Yeast data analyzed during this study is included in this published article from Thornton et al. [<xref ref-type="bibr" rid="CR23">23</xref>].</p>
    </sec>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>Conceived the project and supervised the work: JG Developed the software and carried out the analysis: GS, MG and JG Wrote the manuscript: GS and JG All authors read and approved the final version of the manuscript.</p>
  </notes>
  <notes notes-type="COI-statement">
    <sec id="d29e2935">
      <title>Ethics approval and consent to participate</title>
      <p>Not applicable</p>
    </sec>
    <sec id="d29e2940">
      <title>Consent for publication</title>
      <p>Not applicable</p>
    </sec>
    <sec id="d29e2945">
      <title>Competing interests</title>
      <p>The authors declare that they have no competing interests.</p>
    </sec>
    <sec id="d29e2950">
      <title>Publisher’s Note</title>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </sec>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Barski</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Cuddapah</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Roh</surname>
            <given-names>T-Y</given-names>
          </name>
          <name>
            <surname>Schones</surname>
            <given-names>DE</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Chepelev</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>High-Resolution Profiling of Histone Methylations in the Human Genome</article-title>
        <source>Cell</source>
        <year>2007</year>
        <volume>129</volume>
        <issue>4</issue>
        <fpage>823</fpage>
        <lpage>37</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cell.2007.05.009</pub-id>
        <?supplied-pmid 17512414?>
        <pub-id pub-id-type="pmid">17512414</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Johnson</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Mortazavi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Myers</surname>
            <given-names>RM</given-names>
          </name>
          <name>
            <surname>Wold</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Genome-Wide Mapping of in Vivo Protein-DNA Interactions</article-title>
        <source>Science</source>
        <year>2007</year>
        <volume>316</volume>
        <issue>5830</issue>
        <fpage>1497</fpage>
        <pub-id pub-id-type="doi">10.1126/science.1141319</pub-id>
        <?supplied-pmid 17540862?>
        <pub-id pub-id-type="pmid">17540862</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3</label>
      <mixed-citation publication-type="other">Stricker G, Engelhardt A, Schulz D, Schmid M, Tresch A, Gagneur J. GenoGAM: Genome-wide generalized additive models for ChIP-Seq analysis. Bioinformatics. 2017. 10.1093/bioinformatics/btx150.</mixed-citation>
    </ref>
    <ref id="CR4">
      <label>4</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hastie</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Tibshirani</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Generalized Additive Models</article-title>
        <source>Stat Sci</source>
        <year>1986</year>
        <volume>1</volume>
        <issue>3</issue>
        <fpage>297</fpage>
        <lpage>318</lpage>
        <pub-id pub-id-type="doi">10.1214/ss/1177013604</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huber</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Carey</surname>
            <given-names>JV</given-names>
          </name>
          <name>
            <surname>Gentleman</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Anders</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Carlson</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Carvalho</surname>
            <given-names>SB</given-names>
          </name>
          <name>
            <surname>Bravo</surname>
            <given-names>CH</given-names>
          </name>
          <name>
            <surname>Davis</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Gatto</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Girke</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Gottardo</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Hahne</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Hansen</surname>
            <given-names>DK</given-names>
          </name>
          <name>
            <surname>Irizarry</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Lawrence</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Love</surname>
            <given-names>IM</given-names>
          </name>
          <name>
            <surname>MacDonald</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Obenchain</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Ole’s</surname>
            <given-names>KA</given-names>
          </name>
          <name>
            <surname>Pag‘es</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Reyes</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Shannon</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Smyth</surname>
            <given-names>KG</given-names>
          </name>
          <name>
            <surname>Tenenbaum</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Waldron</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Morgan</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Orchestrating high-throughput genomic analysis with Bioconductor</article-title>
        <source>Nat Methods</source>
        <year>2015</year>
        <volume>12</volume>
        <issue>2</issue>
        <fpage>115</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.3252</pub-id>
        <?supplied-pmid 25633503?>
        <pub-id pub-id-type="pmid">25633503</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Wood</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <source>Generalized Additive Models: An Introduction with R</source>
        <year>2006</year>
        <publisher-loc>Boca Rota</publisher-loc>
        <publisher-name>Chapman and Hall/CRC</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7</label>
      <mixed-citation publication-type="other">Wood SN. Fast stable restricted maximum likelihood and marginal likelihood estimation of semiparametric generalized linear models. J R Stat Soc Ser B Stat Methodol. 2011. 10.1111/j.1467-9868.2010.00749.x.</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>De Boor</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <source>A Practical Guide to Splines vol 27</source>
        <year>1978</year>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Eilers</surname>
            <given-names>PHC</given-names>
          </name>
          <name>
            <surname>Marx</surname>
            <given-names>BD</given-names>
          </name>
        </person-group>
        <article-title>Flexible smoothing with B -splines and penalties</article-title>
        <source>Stat Sci</source>
        <year>1996</year>
        <volume>11</volume>
        <issue>2</issue>
        <fpage>89</fpage>
        <lpage>121</lpage>
        <pub-id pub-id-type="doi">10.1214/ss/1038425655</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10</label>
      <mixed-citation publication-type="other">Love MI, Huber W, Anders S. Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2. Genome Biol. 2011; 15. 10.1186/s13059-014-0550-8.</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11</label>
      <mixed-citation publication-type="other">The HDF Group. Hierarchical Data Format Version 5. <ext-link ext-link-type="uri" xlink:href="http://www.hdfgroup.org/HDF5">http://www.hdfgroup.org/HDF5</ext-link>. Accessed 02 June 2018.</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12</label>
      <mixed-citation publication-type="other">Pagès H. HDF5Array: HDF5 back end for DelayedArray objects. 2017. <ext-link ext-link-type="uri" xlink:href="https://bioconductor.org/packages/release/bioc/html/HDF5Array.html">https://bioconductor.org/packages/release/bioc/html/HDF5Array.html</ext-link>. Accessed 02 June 2018.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13</label>
      <mixed-citation publication-type="other">Fischer B, Pau G, Smith M. rhdf5: HDF5 interface to R. 2017. <ext-link ext-link-type="uri" xlink:href="https://bioconductor.org/packages/release/bioc/html/rhdf5.html">https://bioconductor.org/packages/release/bioc/html/rhdf5.html</ext-link>. Accessed 02 June 2018.</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14</label>
      <mixed-citation publication-type="other">Bates D, Maechler M. Matrix: Sparse and Dense Matrix Classes and Methods. 2017. <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/package=Matrix">https://cran.r-project.org/package=Matrix</ext-link>. Accessed 02 June 2018.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15</label>
      <mixed-citation publication-type="other">Zammit-Mangion A. sparseinv: Computation of the Sparse Inverse Subset. 2018. <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/sparseinv/index.html">https://cran.r-project.org/web/packages/sparseinv/index.html</ext-link>. Accessed 02 June 2018.</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16</label>
      <mixed-citation publication-type="other">Davis TA. SuiteSparse: A suite of sparse matrix software. <ext-link ext-link-type="uri" xlink:href="http://faculty.cse.tamu.edu/davis/suitesparse.html">http://faculty.cse.tamu.edu/davis/suitesparse.html</ext-link>. Accessed 02 June 2018.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>XS</given-names>
          </name>
        </person-group>
        <article-title>An Overview of SuperLU: Algorithms, Implementation, and User Interface</article-title>
        <source>ACM Transactions on Mathematical Software (TOMS) - Special issue on the Advanced CompuTational Software (ACTS) Collection</source>
        <year>2005</year>
        <volume>31</volume>
        <issue>3</issue>
        <fpage>302</fpage>
        <lpage>25</lpage>
        <pub-id pub-id-type="doi">10.1145/1089014.1089017</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Campbell</surname>
            <given-names>YE</given-names>
          </name>
          <name>
            <surname>Davis</surname>
            <given-names>TA</given-names>
          </name>
        </person-group>
        <source>Computing the Sparse Inverse Subset : An inverse multifrontal approach. Technical report</source>
        <year>1995</year>
        <publisher-loc>Gainesville, FL</publisher-loc>
        <publisher-name>Computer and Information Sciences Deparment, University of Florida</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Davis</surname>
            <given-names>TA</given-names>
          </name>
        </person-group>
        <source>Direct Methods for Sparse Linear Systems</source>
        <year>2006</year>
        <publisher-loc>Philadelphia</publisher-loc>
        <publisher-name>Society for Industrial and Applied Mathematics</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Rue</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Held</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <source>Gaussian Markov Random Fields: Theory and Applications</source>
        <year>2005</year>
        <publisher-loc>Boca Rota</publisher-loc>
        <publisher-name>Chapman and Hall/CRC</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>CYY</given-names>
          </name>
          <name>
            <surname>Wand</surname>
            <given-names>MP</given-names>
          </name>
        </person-group>
        <article-title>Streamlined mean field variational Bayes for longitudinal and multilevel data analysis</article-title>
        <source>Biom J</source>
        <year>2016</year>
        <volume>58</volume>
        <issue>4</issue>
        <fpage>868</fpage>
        <lpage>95</lpage>
        <pub-id pub-id-type="doi">10.1002/bimj.201500007</pub-id>
        <?supplied-pmid 27214238?>
        <pub-id pub-id-type="pmid">27214238</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wood</surname>
            <given-names>SN</given-names>
          </name>
        </person-group>
        <article-title>Comment</article-title>
        <source>J Am Stat Assoc</source>
        <year>2017</year>
        <volume>112</volume>
        <issue>517</issue>
        <fpage>164</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1080/01621459.2016.1270050</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thornton</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Westfield</surname>
            <given-names>GH</given-names>
          </name>
          <name>
            <surname>Takahashi</surname>
            <given-names>Y-H</given-names>
          </name>
          <name>
            <surname>Cook</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Woodfin</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>J-S</given-names>
          </name>
          <name>
            <surname>Morgan</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Jackson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>ER</given-names>
          </name>
          <name>
            <surname>Couture</surname>
            <given-names>J-F</given-names>
          </name>
          <name>
            <surname>Skiniotis</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Shilatifard</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Context dependency of Set1/ COMPASS-mediated histone H3 Lys4 trimethylation</article-title>
        <source>Genes Dev</source>
        <year>2014</year>
        <volume>28</volume>
        <issue>2</issue>
        <fpage>115</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="doi">10.1101/gad.232215.113</pub-id>
        <?supplied-pmid 24402317?>
        <pub-id pub-id-type="pmid">24402317</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
