<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">G3 (Bethesda)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Genetics</journal-id>
    <journal-id journal-id-type="publisher-id">g3journal</journal-id>
    <journal-title-group>
      <journal-title>G3: Genes|Genomes|Genetics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2160-1836</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8664437</article-id>
    <article-id pub-id-type="pmid">34499130</article-id>
    <article-id pub-id-type="doi">10.1093/g3journal/jkab254</article-id>
    <article-id pub-id-type="publisher-id">jkab254</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Investigation</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01180</subject>
        <subject>AcademicSubjects/SCI01140</subject>
        <subject>AcademicSubjects/SCI00010</subject>
        <subject>AcademicSubjects/SCI00960</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Speeding up eQTL scans in the BXD population using GPUs</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8788-8043</contrib-id>
        <name>
          <surname>Trotter</surname>
          <given-names>Chelsea</given-names>
        </name>
        <xref rid="jkab254-aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-2368-4850</contrib-id>
        <name>
          <surname>Kim</surname>
          <given-names>Hyeonju</given-names>
        </name>
        <xref rid="jkab254-aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-4268-9507</contrib-id>
        <name>
          <surname>Farage</surname>
          <given-names>Gregory</given-names>
        </name>
        <xref rid="jkab254-aff1" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-8021-9162</contrib-id>
        <name>
          <surname>Prins</surname>
          <given-names>Pjotr</given-names>
        </name>
        <xref rid="jkab254-aff2" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-8924-4447</contrib-id>
        <name>
          <surname>Williams</surname>
          <given-names>Robert W</given-names>
        </name>
        <xref rid="jkab254-aff2" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-4914-6671</contrib-id>
        <name>
          <surname>Broman</surname>
          <given-names>Karl W</given-names>
        </name>
        <xref rid="jkab254-aff3" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-4519-6361</contrib-id>
        <name>
          <surname>Sen</surname>
          <given-names>Śaunak</given-names>
        </name>
        <xref rid="jkab254-aff1" ref-type="aff">1</xref>
        <xref rid="jkab254-cor1" ref-type="corresp"/>
        <!--sen@uthsc.edu-->
      </contrib>
    </contrib-group>
    <aff id="jkab254-aff1"><label>1</label><institution>Department of Preventive Medicine, University of Tennessee Health Science Center</institution>, Memphis, TN 38163, <country country="US">USA</country></aff>
    <aff id="jkab254-aff2"><label>2</label><institution>Department of Genetics, Genomics and Informatics, University of Tennessee Health Science Center</institution>, Memphis, TN 38163, <country country="US">USA</country></aff>
    <aff id="jkab254-aff3"><label>3</label><institution>Department of Biostatistics and Medical Informatics, University of Wisconsin-Madison</institution>, Madison, WI 53706, <country country="US">USA</country></aff>
    <author-notes>
      <corresp id="jkab254-cor1">Corresponding author: Department of Preventive Medicine, University of Tennessee Health Science Center, Memphis, TN. 66 North Pauline, Memphis, TN, 38103, USA. Email: <email>sen@uthsc.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>12</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2021-08-16">
      <day>16</day>
      <month>8</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>16</day>
      <month>8</month>
      <year>2021</year>
    </pub-date>
    <volume>11</volume>
    <issue>12</issue>
    <elocation-id>jkab254</elocation-id>
    <history>
      <date date-type="accepted">
        <day>27</day>
        <month>5</month>
        <year>2021</year>
      </date>
      <date date-type="received">
        <day>21</day>
        <month>10</month>
        <year>2020</year>
      </date>
      <date date-type="corrected-typeset">
        <day>03</day>
        <month>12</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2021. Published by Oxford University Press on behalf of Genetics Society of America.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="jkab254.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>The BXD family of mouse strains are an important reference population for systems biology and genetics that have been fully sequenced and deeply phenotyped. To facilitate interactive use of genotype–phenotype relations using many massive omics data sets for this and other segregating populations, we have developed new algorithms and code that enable near-real-time whole-genome quantitative trait locus (QTL) scans for up to one million traits. By using easily parallelizable operations including matrix multiplication, vectorized operations, and element-wise operations, our method is more than 700 times faster than a R/qtl linear model genome scan using 16 threads. We used parallelization of different CPU threads as well as GPUs. We found that the speed advantage of GPUs is dependent on problem size and shape (the number of cases, number of genotypes, and number of traits). Our approach is ideal for interactive web services, such as GeneNetwork.org that need to display results in real-time. Our implementation is available as the Julia language package LiteQTL at <ext-link xlink:href="https://github.com/senresearch/LiteQTL.jl" ext-link-type="uri">https://github.com/senresearch/LiteQTL.jl</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>linear model</kwd>
      <kwd>genome scan</kwd>
      <kwd>BXD</kwd>
      <kwd>GPU</kwd>
    </kwd-group>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Instiutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>P30DA044223</award-id>
        <award-id>R01GM123489</award-id>
        <award-id>R01GM070683</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro">
    <title>Introduction</title>
    <p>The BXD family is a deeply phenotyped cohort of recombinant inbred mouse strains that have been used since the early 1970s for genetic analysis and quantitative trait locus (QTL) mapping (<xref rid="jkab254-B1" ref-type="bibr">Ashbrook <italic toggle="yes">et al.</italic> 2019</xref>). For the past 20 years, they have been used in many large-scale omics and expression quantitative trait locus (eQTL) studies (<xref rid="jkab254-B8" ref-type="bibr">Chesler <italic toggle="yes">et al.</italic> 2004</xref>). There are currently 150 fully inbred BXD strains, all of which have been repeatedly genotyped at many thousands of SNPs and SSLPs. Thus any new omics data can be immediately used for quantitative expression trait locus (QTL or eQTL) mapping and for association analyses with previously collected phenotypes. For omic data sets collected using high-throughput technologies, additional analyses, such as transcriptional network construction or causal mediation analyses, are also practical.</p>
    <p>The open-source GeneNetwork web service (<ext-link xlink:href="http://www.genenetwork.org" ext-link-type="uri">www.genenetwork.org</ext-link>) (<xref rid="jkab254-B8" ref-type="bibr">Chesler <italic toggle="yes">et al.</italic> 2004</xref>; <xref rid="jkab254-B18" ref-type="bibr">Sloan <italic toggle="yes">et al.</italic> 2016</xref>; <xref rid="jkab254-B12" ref-type="bibr">Mulligan <italic toggle="yes">et al.</italic> 2017</xref>) facilitates systems genetics and mapping by providing a searchable and exportable database of phenotypes and genotypes for a variety of organisms (including mouse, rat, and <italic toggle="yes">Arabidopsis</italic>). It also provides a suite of interactive tools for browsing data, generating QTL maps, correlational analyses, network construction, and genome browsing. We wanted to develop a backend for web services such as GeneNetwork to perform real-time eQTL analysis of tens of thousands of omics traits using key populations such as the BXDs.</p>
    <p>To perform eQTL scans in the BXD family, one has to perform as many genome scans as there are phenotypes. This can be done in an “embarrassingly parallel” fashion by using standard algorithms for QTL analysis, such as those employed by R/qtl (<xref rid="jkab254-B6" ref-type="bibr">Broman <italic toggle="yes">et al.</italic> 2003</xref>). In practice, this is too slow, and speedup tricks are useful. For example, by using the Haley-Knott algorithm (<xref rid="jkab254-B9" ref-type="bibr">Haley and Knott 1992</xref>) using genotype probabilities instead of the Expectation-Maximization (EM) algorithm (<xref rid="jkab254-B10" ref-type="bibr">Lander and Botstein 1989</xref>), and processing phenotypes with the same missing data pattern in batches, instead of processing each phenotype individually, substantial speedups are possible. This is a well-known trick and is used by R/qtl. In addition, if only additive effects are tested, or if the population has only two genotype categories (as in a backcross or recombinant inbred line), then matrix multiplication can be used to perform Haley-Knott regression (<xref rid="jkab254-B17" ref-type="bibr">Shabalin 2012</xref>).</p>
    <p>Processing large data sets have been a challenge for genome scans. We have benefited from Moore’s Law for decades, but the central processing unit (CPU) technology is approaching the physical limits of packing transistors. Graphical processing units (GPUs), originally used as an image processing component of a computer, have shown some compelling results to accelerate computation in various fields. General purpose graphics processor units (GPGPUs) became popular in the early 2000s because of their ability to natively handle matrix and vector operations. Such power is attractive to the scientific computing community. <xref rid="jkab254-B21" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> (2015)</xref> used GPUs to simultaneously dissect various genetic effects with a mixed linear model. <xref rid="jkab254-B7" ref-type="bibr">Chapuis <italic toggle="yes">et al.</italic> (2013)</xref> utilized GPU to offset heavy computation to deploy various ways for a more precise calculation of a QTL detection threshold. By using GPU-backed machine learning libraries such as PyTorch, <xref rid="jkab254-B19" ref-type="bibr">Taylor-Weiner <italic toggle="yes">et al.</italic> (2019)</xref> re-implemented QTL mapping and Bayesian nonnegative matrix factorization and reported achieving greater than 200-fold speedup compared to CPU versions. The ease of using such libraries has motivated the development of new methods for genomic research.</p>
    <p>We build upon these efforts to perform real-time eQTL scans for the BXD family using both CPU and GPU systems. Since programming for GPUs is often nontrivial, needing the use of low-level languages such as C++, we used the Julia programming language (<xref rid="jkab254-B4" ref-type="bibr">Bezanson <italic toggle="yes">et al.</italic> 2017</xref>) that offers GPU programming capabilities while retaining the simplicity of a high-level language such as R or MATLAB. Finally, since most phenotype-marker associations are null, we examined the impact of storage precision, and of only returning the highest association (log of odds, LOD) score for each trait instead of a matrix of LOD scores for every pair of marker and phenotypes (returning the maximum LOD per trait speeds computation by reducing output size). We have achieved computing speeds to the extent that almost all response latency is now related to data transfer and browser display, rather than the computation. This makes real-time eQTL scans practical for the BXDs and many other similar populations.</p>
  </sec>
  <sec>
    <title>Materials and methods</title>
    <p>We used two BXD transcriptome datasets for developing and refining our methods. All data were downloaded from GeneNetwork (see <italic toggle="yes">Data Availability</italic> section). The genotype file includes 7321 markers by 198 BXD strains; the spleen dataset has data for 79 BXD strains and for 35,556 transcripts while the hippocampus dataset has data for 70 BXD strains and 1,236,087 probe sets. Data cleaning and wrangling were performed using R/qtl (<xref rid="jkab254-B6" ref-type="bibr">Broman <italic toggle="yes">et al.</italic> 2003</xref>) and R/qtl2 (<xref rid="jkab254-B5" ref-type="bibr">Broman <italic toggle="yes">et al.</italic> 2019</xref>).</p>
    <sec>
      <title>Linear model</title>
      <p>Let <italic toggle="yes">y<sub>i</sub></italic> denote a vector for the <italic toggle="yes">i</italic>-th expression trait (<inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula>) for <italic toggle="yes">n</italic> individuals. We define a univariate linear model as follows:
<disp-formula id="E1"><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mo>ϵ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mo>ϵ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mi>I</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a matrix including the intercept and the <italic toggle="yes">j</italic>-th candidate genetic marker (<inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:math></inline-formula>) without covariate(s), <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a vector of the <italic toggle="yes">j</italic>-th eQTL effects, and <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>ϵ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is random error distributed as <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>σ</mml:mo></mml:mrow><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mi>I</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. We assume to be interested in one-df tests as would be the case for genome scans in the BXDs. Suppose <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the residual sum of squares under the null hypothesis of no eQTL, and <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the residual sum of squares under the alternative of existing eQTL at the <italic toggle="yes">i</italic>-th trait and the <italic toggle="yes">j</italic>-th genetic marker. Then, the <italic toggle="yes">LOD<sub>ij</sub></italic> score for a one-df test can be written as:
<disp-formula id="E2"><mml:math id="M2" display="block" overflow="scroll"><mml:mtable><mml:mtr><mml:mtd><mml:mi>L</mml:mi><mml:mi>O</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mtext>log</mml:mtext></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mtext>log</mml:mtext></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
where <italic toggle="yes">r<sub>ij</sub></italic> is the correlation between the <italic toggle="yes">i</italic>-th expression trait and <italic toggle="yes">j</italic>-th marker. If <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> are respectively standardized trait (<italic toggle="yes">Y</italic>) and genotype (<italic toggle="yes">G</italic>) matrices (<italic toggle="yes">i.e.</italic>, with the columns centered and scaled to have mean 0 and variance 1), then the correlation matrix is simply
<disp-formula id="E3"><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>Since matrix multiplication is a parallelizable operation for which optimized routines are available, this formula is very attractive for bulk calculation of LOD scores. The formula can be extended for LOD scores adjusted by covariates. The idea is to project genetic markers and gene expressions onto the space orthogonal to the covariates and to compute the corresponding correlation matrix just as we did for the case without covariates. In other words, let <italic toggle="yes">Z</italic> be a matrix of covariates including intercept. The projection orthogonal to the covariate space is then <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:mo>−</mml:mo><mml:mi>Z</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>Z</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>Z</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Z</mml:mi><mml:mo>′</mml:mo></mml:mrow></mml:math></inline-formula>. The genotype matrix (<italic toggle="yes">G</italic>) and gene expressions (<italic toggle="yes">Y</italic>) are now transformed into <italic toggle="yes">G<sub>z</sub></italic> = <italic toggle="yes">PG</italic>, <italic toggle="yes">Y <sub>z</sub></italic> = <italic toggle="yes">PY</italic>, respectively. This is the same as calculating the residuals after regressing on <italic toggle="yes">Z</italic>. Standardization followed by multiplication of the matrices yields the correlation matrix (<inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mi>z</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>z</mml:mi><mml:mrow><mml:mo>∗</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mi>z</mml:mi><mml:mo>∗</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula>) just as shown above. <xref rid="jkab254-F1" ref-type="fig">Figure 1</xref> gives a visual representation of the matrix multiplication.</p>
      <fig position="float" id="jkab254-F1">
        <label>Figure 1</label>
        <caption>
          <p>Schematic of data and correlation calculation: <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> is a standardized expression phenotype matrix, <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> is a standardized genotype matrix, and <italic toggle="yes">R</italic> is a correlation matrix. An entry in <italic toggle="yes">R</italic> (shaded dark gray) is obtained by summing the product of the entries of the corresponding row of <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and the corresponding column of <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (both shaded light gray). The matrix of LOD scores is an element-wise function of the correlation matrix.</p>
        </caption>
        <graphic xlink:href="jkab254f1" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>Acceleration techniques</title>
      <p>While it is true that many programs can achieve 10- or even 100-fold speedup by utilizing GPUs, the difference needs to be examined with care. Sometimes, a reported CPU time is using a single thread, and multithreaded CPU time may bring the performance gap between CPU and GPU narrower than claimed. Also depending on the library chosen for the CPU, the speed might vary depending on whether the library is optimized for such computation or hardware. We believe for a fair comparison, both CPU and GPU functions should be optimized at maximum performance and should account for all necessary overhead. The following section explains optimization efforts of CPU and GPU functions.</p>
      <sec>
        <title>Multithreaded CPU operations</title>
        <p>Our goal was to build a backend for web services such as GeneNetwork that allow researchers to interact with data in real-time. That requires that the genome scan finish within seconds. To bring out the best performance of CPUs, we use multi-threaded operations whenever possible. Julia (<xref rid="jkab254-B4" ref-type="bibr">Bezanson <italic toggle="yes">et al.</italic> 2017</xref>), our choice of programming language, provides simple yet safe syntax for multi-threading. It is done by adding the Threads.@thread macro to indicate to Julia that the following for loop is the multi-threaded region. The Threads.nthreads() function shows the number of threads in Julia, and the default number of threads we use is 16.</p>
      </sec>
      <sec>
        <title>GPU operations</title>
        <p>Originally used in graphics, GPUs have taken off as a general computing device in recent years because they provide a massive number of cores at a lower price range and because of the availability of fast GPGPU libraries such as CUDA (Compute Unified Device Architecture) and OpenCL (Open Computing Language). Based on our profiling results, the time consuming parts of our genome scan method are matrix multiplication and element-wise operations. Both are amenable to GPU heterogeneous computing architecture since they have no data race conditions (where processes depend on each other’s results) and low data dependencies. However, the GPU also has its own limitations. To truly utilize the maximum computing power of GPUs, one needs to think creatively to work around those limitations. For example, during our experiments, we found that memory transfer between host and device is really slow. Profiling the result shows that 98% of total genome scan time is spent on memory transfer. This is because the size of the output matrix (of genome scan LOD scores) is much larger than the size of the input matrices (of genotype probabilities and phenotypes). To cope with this capacity constraint, instead of offloading the entire correlation matrix, we use the GPU to calculate the maximum LOD score of each expression trait and output the maximum. The output matrix is now much smaller, and the memory transfer times are reduced. This allows us to identify transcripts with at least one eQTL and speeds up the computation substantially.</p>
      </sec>
      <sec>
        <title>Matrix and vectorized operations</title>
        <p>Since our algorithm largely depends on matrix operations, it is natural to find the fastest way to achieve the best result regardless of computing platforms. There are various matrix libraries available for CPU, such as gslBLAS and OpenBLAS (<xref rid="jkab254-B20" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2013</xref>). They target different hardware or use various techniques to get optimal results. Multi-threaded matrix multiplication is the default in OpenBLAS, and does not require extra coding effort to parallelize the CPU version of matrix multiplication. We, therefore, chose OpenBLAS as our CPU computing library.</p>
        <p>Matrix multiplication and element-wise operations are algorithmically free of data and function dependency, so that they are amenable to GPU’s parallel computing power. Julia provides various packages for GPU including CUDA (<xref rid="jkab254-B13" ref-type="bibr">Nickolls <italic toggle="yes">et al.</italic> 2008</xref>) bindings. Our chosen hardware for GPU is from Nvidia, which requires its proprietary library, CUDA, which is mature and well-recognized in the scientific computing community. For matrix operations on GPU, we used the cuBLAS library (<xref rid="jkab254-B14" ref-type="bibr">Nvidia 2021a</xref>), which provides a fast GPU implementation of BLAS (Basic Linear Algebra Subprograms) from Nvidia.</p>
        <p>We investigated the effect of matrix shape on the speedup in addition to the effect of using the GPU for multiplication. Of course, most of the time, one cannot pick the size and shape of data in a matrix form, but such information would help researchers as a rough guidance of whether it is worth considering the GPU option before investing programming efforts for GPUs. We ran matrix multiplication with different shapes of matrices and compared the runtime of CPU and GPU. CPU time is measured by matrix multiplication from the OpenBLAS library using 16 threads. GPU time includes all overhead of using GPU, which involves device launch, data transfer, and all necessary API calls. In order to make a fair comparison between CPU and GPU, we needed to use maximum strength of both and include all necessary cost.</p>
        <p>The experiment setup was to multiply two input matrices, A(m × n), and B(n × p), and produce an output matrix C (m × p). The range of <italic toggle="yes">m</italic>, <italic toggle="yes">n</italic>, and <italic toggle="yes">p</italic> is between 2<sup>4</sup> and 2<sup>17</sup> in powers of 2. We compared the result when the size of input and output (I/O size) matrices, in total, was between 11 and 16 GB.</p>
      </sec>
      <sec>
        <title>Single precision</title>
        <p>Precision means the smallest difference between two representable numbers. Floating point numbers, in scientific computing, are usually stored in double precision. Double precision floating point numbers take up 8 bytes in memory while single-precision numbers take up 4 bytes. In addition to the difference in storage size, the speed for calculation using single and double precision also varies by hardware. For example, the GPU throughput (the number of floating point calculation per second, measured in FLOPS) for double precision is 1/32 of single precision on a Nvidia GTX 1050 GPU, and 1/4 on a Nvidia Tesla K80. Thus, single-precision brings multiple benefits when precision is not the primary concern.</p>
      </sec>
      <sec>
        <title>Julia language</title>
        <p>Although a programming language cannot really be classified as an optimization technique, the choice of programming language can affect run time as well as development time. We chose Julia, an interpreted language with a just-in-time compiler, that provides fast runtimes approaching compiled languages such as C/C++ with the development ease of interpreted languages such as Python or R. Julia also has packages that make it easy to use GPUs, and even program some GPU kernels purely in Julia without resorting to C or C++.</p>
      </sec>
      <sec>
        <title>Comparison with tensorQTL</title>
        <p>TensorQTL (<xref rid="jkab254-B19" ref-type="bibr">Taylor-Weiner <italic toggle="yes">et al.</italic> 2019</xref>) is a GPU-enabled QTL mapper that reported approximately 200- to 300-fold faster QTL mapping compared to CPU-based implementations. We compared our implementation to tensorQTL noting that our implementation was primarily developed for experimental cross populations (such as the BXD population) while tensorQTL was optimized for outbred populations such as humans. We used the open-source code of tensorQTL to time key parts of the computational pipelines: data transfer (getting data to and from device), core computation (eQTL scans), post processing (other related cost to generate a meaningful output, such as calculating <italic toggle="yes">P</italic>-values, concatenating dataframes, adding additional genotype and phenotype information, type conversions, and so on), and the total elapsed time. No alterations to the tensorQTL algorithm were made. For each program, we timed two versions, one that returned the full matrix of LOD scores (LiteQTL) or <italic toggle="yes">P</italic>-values (tensorQTL), and the other that returned a filtered set: maximum LOD score for each transcript, (LiteQTL) or all <italic toggle="yes">P</italic>-values lower than <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> (tensorQTL). Both programs filtered for MAF (minor allele frequency).</p>
        <p>Runtimes were based on the mean of 10 runs on the same hardware using the GEUVADIS dataset provided by tensorQTL. We analyzed 19,836 traits and 20,000 genotypes on chromosome 9 to ensure that the data fitted in the GPU. For a more detailed description, please see the Supplementary material.</p>
      </sec>
    </sec>
    <sec>
      <title>Platform</title>
      <p>Our platform for computation:</p>
      <p>Hardware:
</p>
      <list list-type="bullet">
        <list-item>
          <p>CPU: Intel(R) Xeon(R) Gold 6148 CPUs @ 2.40 GHz; 80 cores, 187 GB</p>
        </list-item>
        <list-item>
          <p>GPU: Tesla V100-PCIE-16 GB; 5120 CUDA cores</p>
        </list-item>
      </list>
      <p>Software:
</p>
      <list list-type="bullet">
        <list-item>
          <p>OS: Debian GNU/Linux 10</p>
        </list-item>
        <list-item>
          <p>Programming environment: Julia v1.5</p>
        </list-item>
        <list-item>
          <p>Libraries: CUDA v10.1 and cuBLAS; OpenBLAS</p>
        </list-item>
        <list-item>
          <p>Profilers: Julia Profiler; nvprof</p>
        </list-item>
        <list-item>
          <p>tensorQTL v1.0.4; LiteQTL v0.2.0; R/qtl v1.47</p>
        </list-item>
      </list>
    </sec>
    <sec>
      <title>Software availability</title>
      <p>We have created a Julia package for performing the computations mentioned in this study. It can be installed from the Julia command line as the LiteQTL package from the Julia General registry. The source code for this package is publicly available on Github (<ext-link xlink:href="https://github.com/senresearch/LiteQTL.jl" ext-link-type="uri">https://github.com/senresearch/LiteQTL.jl</ext-link>) The repository contains an example directory with a Jupyter notebook that shows how to compute eQTL scans for the BXD spleen dataset and make a plot of the eQTLs. To benefit from the GPU options, users will need an Nvidia GPU in their machine and have the Julia executable, openBLAS, and CUDA libraries installed. The Supplementary material accompanying this study can be found at <ext-link xlink:href="https://github.com/senresearch/LiteQTL-G3-supplement" ext-link-type="uri">https://github.com/senresearch/LiteQTL-G3-supplement</ext-link>.</p>
    </sec>
  </sec>
  <sec sec-type="results">
    <title>Results</title>
    <p>We performed eQTL scans in the spleen dataset (36K traits) in 0.06 seconds, and for the hippocampus dataset (1.2M traits) in 2.82 s with our hardware. Below, we show how the algorithm choice, CPU/GPU, precision, and programming language impacted our results. For the spleen dataset, <xref rid="jkab254-F2" ref-type="fig">Figure 2</xref> shows the position of the strongest eQTL for transcripts with a maximum LOD score greater than 5 against the physical position of the cognate gene, if known, of the transcripts. Of the 35,554 transcripts, 2057 (5.8%) had a maximum LOD exceeding 5.</p>
    <fig position="float" id="jkab254-F2">
      <label>Figure 2</label>
      <caption>
        <p>Distribution of eQTL across genome in the BXD spleen dataset. On the vertical axis, we plot the physcal location of the cognate gene for a transcript; transcripts without a good match to a known gene are not shown. On the horizontal axis, we plot the location of the marker with the highest LOD score for each transcript provided it exceeded 5.</p>
      </caption>
      <graphic xlink:href="jkab254f2" position="float"/>
    </fig>
    <sec>
      <title>Effect of matrix shape on matrix multiplication speed in GPU</title>
      <p>The result of our experiment is shown in <xref rid="jkab254-F3" ref-type="fig">Figure 3</xref>. The <italic toggle="yes">x</italic>-axis of <xref rid="jkab254-F3" ref-type="fig">Figure 3</xref> is the dimensions of matrix. The two ends of <italic toggle="yes">x</italic>-axis represent matrices with slender or wider matrices, while the middle of <italic toggle="yes">x</italic>-axis represents matrices closer to square shape. The <italic toggle="yes">y</italic>-axis is the speedup of GPU compared with CPU on a linear scale. From this figure, we see that matrices whose shapes are relatively closer to square get better speedups from GPU. Matrix multiplication is up to 3.85 times faster on GPU than on 16 threaded CPU on our hardware.</p>
      <fig position="float" id="jkab254-F3">
        <label>Figure 3</label>
        <caption>
          <p>Variation of GPU <italic toggle="yes">vs</italic> CPU speedup with matrix shape for calculating <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="bold">C</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="bold">A</mml:mi><mml:mi mathvariant="bold">B</mml:mi></mml:mrow></mml:math></inline-formula>. The matrix with more squared shapes gains relatively better speedup compared to the ones with long or wide shapes. The <italic toggle="yes">x</italic>-axis shows <italic toggle="yes">m</italic>, <italic toggle="yes">n</italic>, <italic toggle="yes">p</italic>, where dimension of <italic toggle="yes">A</italic> is m × n, n × p for <italic toggle="yes">B</italic>, and m × p for <italic toggle="yes">C</italic>.</p>
        </caption>
        <graphic xlink:href="jkab254f3" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>Benefit of customized algorithm for eQTL scans</title>
      <p>R/qtl is a general-purpose QTL mapping program. To provide a baseline for our approach customized for eQTL scans, we compared runtimes to R/qtl. The timing of our method and R/qtl is shown in <xref rid="jkab254-T1" ref-type="table">Table 1</xref>. By simplifying the genome scan process, using matrix multiplication, and returning the maximum LOD, we observed a significant speedup. For the spleen data, our method was 48 times faster (0.83 s for LiteQTL on CPU only <italic toggle="yes">vs</italic> 40.02 s for R/qtl). For the hippocampus data the speedup was 125 times (16.57 s on CPU only <italic toggle="yes">vs</italic> 2070.71 s for R/qtl), and 734.2 times if R/qtl is compared with LiteQLTL’s CPU &amp; GPU option.</p>
      <table-wrap position="float" id="jkab254-T1">
        <label>Table 1</label>
        <caption>
          <p> eQTL scan runtimes for R/qtl and LiteQTL</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1">Dataset</th>
              <th rowspan="2" colspan="1">Precision</th>
              <th colspan="3" align="center" rowspan="1">LiteQTL<hr/></th>
              <th rowspan="1" colspan="1">R/qtl</th>
              <th colspan="2" rowspan="1">LiteQTL speedup <italic toggle="yes">vs</italic> R/qtl<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">CPU only</th>
              <th rowspan="1" colspan="1">CPU and GPU</th>
              <th rowspan="1" colspan="1">GPU speedup</th>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">CPU only</th>
              <th rowspan="1" colspan="1">CPU and GPU</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="2" colspan="1">Spleen (35K traits)</td>
              <td rowspan="1" colspan="1">Single</td>
              <td rowspan="1" colspan="1">0.56 s</td>
              <td rowspan="1" colspan="1">0.04 s</td>
              <td rowspan="1" colspan="1">14.0x</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Double</td>
              <td rowspan="1" colspan="1">0.83 s</td>
              <td rowspan="1" colspan="1">0.06 s</td>
              <td rowspan="1" colspan="1">13.8x</td>
              <td rowspan="1" colspan="1">40.02 s</td>
              <td rowspan="1" colspan="1">48.2x</td>
              <td rowspan="1" colspan="1">667.0x</td>
            </tr>
            <tr>
              <td rowspan="2" colspan="1">Hippocampus (1.2M traits)</td>
              <td rowspan="1" colspan="1">Single</td>
              <td rowspan="1" colspan="1">12.36 s</td>
              <td rowspan="1" colspan="1">1.66 s</td>
              <td rowspan="1" colspan="1">7.4x</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
              <td rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Double</td>
              <td rowspan="1" colspan="1">16.57 s</td>
              <td rowspan="1" colspan="1">2.82 s</td>
              <td rowspan="1" colspan="1">5.4x</td>
              <td rowspan="1" colspan="1">2070.71 s</td>
              <td rowspan="1" colspan="1">124.9x</td>
              <td rowspan="1" colspan="1">734.2x</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p>We show the time taken in seconds to perform eQTL genome scans with LiteQTL and R/qtl. LiteQTL times are shown by precision (single <italic toggle="yes">vs</italic> double), and whether the GPU was used or not. The GPU speedup column computes the speedup for LiteQTL using the CPU and GPU <italic toggle="yes">vs</italic> using the CPU only. LiteQTL was used with the maximum LOD output option to reduce data transfer time.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>Benefit of using GPU</title>
      <p>In parallel computing, Amdahl’s law indicates the theoretical maximum speedup that could be attained when improving a particular part of a program. For example, if a program takes 10 min for a serial processor and a function that takes nine of those 10 mins can be parallelized, then the theoretical speedup, no matter how many processors are used, cannot be more than 10 times because the minimum execution time of this program is 1 min. Therefore, profiling the entire genome scan process is a prerequisite for optimization. Often, profiling would consider space and time complexity. Our primary concern is the time taken by each function, and therefore only timing information is considered in our profiling. We used Julia’s built-in sampling profiler to find our target functions for GPU because it is less intrusive than the other profiling methods.</p>
      <p>The genome scan process includes the following steps:
</p>
      <list list-type="bullet">
        <list-item>
          <p>Calculate standardized matrices (<inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>) for input matrices (<italic toggle="yes">G</italic>, <italic toggle="yes">Y</italic>)</p>
        </list-item>
        <list-item>
          <p>Get a correlation matrix (<italic toggle="yes">R</italic>) by multiplying the standardized matrices</p>
        </list-item>
        <list-item>
          <p>Calculate LOD scores</p>
        </list-item>
      </list>
      <p>Our profiling result shows that the second and third steps take up over 90% of the computation time and involve parallelizable matrix operations. Hence, they are our candidates for GPU acceleration.</p>
      <p>We used a GPU profiler <italic toggle="yes">nvprof</italic> (<xref rid="jkab254-B16" ref-type="bibr">Nvidia 2021c</xref>) to identify bottleneck of GPU. The results indicate that 98% of the GPU running time is spent on data transfer from GPU to CPU (device to host). As shown in <xref rid="jkab254-F1" ref-type="fig">Figure 1</xref>, the input matrices Y’ and G are small compared with the output matrix R. For the BXD spleen dataset, Y’ matrix is 17 MB, G matrix is 21 MB, but R matrix is about 4GB. Data offloading is the main bottleneck for our GPU implementation.</p>
      <p>To overcome this limitation of GPUs, we only offload the maximum of LOD score of every phenotype since that is the primary interest for initial exploration. Finding the maximum is highly parallelizable, can utilize GPU’s massive cores, and reduces the amount of data that needs to be transferred back to host.</p>
      <p>The timing shown in <xref rid="jkab254-T1" ref-type="table">Table 1</xref> is the total execution time and necessary overhead for genome scan. We ran the genome scan process 10 times and chose the median to remove the randomness of each run and warm-up time of GPUs.</p>
      <p>In <xref rid="jkab254-T1" ref-type="table">Table 1</xref>, CPU &amp; GPU implementation gains 5–14 times speedup compared to CPU only. The former took only 0.83 and 16.57 s for spleen and hippocampus dataset, while the latter took 0.06, and 2.82 s respectively. Our algorithm exploits parallelism in two ways, by simplifying the genome scan process to matrix multiplication, and by getting the maximum LOD score of each phenotype. Such arrangement is ideal for GPU processing: maximum parallelization for computation while minimizing data input and output.</p>
    </sec>
    <sec>
      <title>Benefit of using single precision</title>
      <p><xref rid="jkab254-T1" ref-type="table">Table 1</xref> also shows the execution time using single and double precision. In all cases, genome scans run faster using single precision than using double precision. The speedup are more appreciable in the larger, hippocampus dataset compared to the spleen dataset. Using single precision provides benefits in three aspects: memory storage, data transfer, and arithmetic calculation.</p>
    </sec>
    <sec>
      <title>Benefit of using Julia</title>
      <p>In our explorations of matrix multiplication, Julia’s speed is comparable to C/C++ (results not shown). However, the low learning curve, clean syntax, as well as support for GPU programming libraries such as CUDAnative (<xref rid="jkab254-B3" ref-type="bibr">Besard <italic toggle="yes">et al.</italic> 2018</xref>) reduce programming effort relative to C/C++. Compared with writing GPU functions in C/C++, writing in Julia is cleaner and easier because it requires much less boilerplate code. Below are some example code snippets. The first example shows how to call cuBLAS from Julia, and the second example shows how to write a custom kernel in Julia. To respect page limits, we will not show the corresponding C code. An example of using cuBLAS with C can be found online (<xref rid="jkab254-B15" ref-type="bibr">Nvidia 2021b</xref>).</p>
      <p>
        <italic toggle="yes">
          <monospace>
            <italic toggle="yes">## Example 1:</italic>
          </monospace>
        </italic>
      </p>
      <p>
        <monospace>using CUDA</monospace>
      </p>
      <p>
        <monospace>A = rand(1000,1000)</monospace>
      </p>
      <p>
        <monospace>B = rand(1000,1000)</monospace>
      </p>
      <p>
        <italic toggle="yes">
          <monospace>
            <italic toggle="yes"># Data transfer from CPU to GPU</italic>
          </monospace>
        </italic>
      </p>
      <p>
        <monospace>d_a=CuArray(A)</monospace>
      </p>
      <p>
        <monospace>d_b=CuArray(B)</monospace>
      </p>
      <p>
        <italic toggle="yes">
          <monospace>
            <italic toggle="yes"># GPU matrix multiplication calling CuBLAS library</italic>
          </monospace>
        </italic>
      </p>
      <p>
        <monospace>d_c = CUDA.CUBLAS.gemm('T', ‘N’, d_a, d_b);</monospace>
      </p>
      <p>
        <italic toggle="yes">
          <monospace>
            <italic toggle="yes"># Data Transfer from GPU to CPU</italic>
          </monospace>
        </italic>
      </p>
      <p>
        <monospace>C=collect(d_c)</monospace>
      </p>
      <p>
        <italic toggle="yes">
          <monospace>
            <italic toggle="yes">## Example 2:</italic>
          </monospace>
        </italic>
      </p>
      <p>
        <italic toggle="yes">
          <monospace>
            <italic toggle="yes"># Custom kernel for matrix element-wise calculation</italic>
          </monospace>
        </italic>
      </p>
      <p>
        <monospace>function log_kernel(data, MAX)</monospace>
      </p>
      <p>
        <monospace> </monospace>
        <italic toggle="yes">
          <monospace>
            <italic toggle="yes"># calculating GPU thread ID</italic>
          </monospace>
        </italic>
      </p>
      <p>
        <monospace> i=(blockIdx().x-1)*blockDim().x+threadIdx().x</monospace>
      </p>
      <p>
        <monospace> </monospace>
        <italic toggle="yes">
          <monospace>
            <italic toggle="yes"># Check thread ID is in bound.</italic>
          </monospace>
        </italic>
      </p>
      <p><monospace> if(i &lt; MAX</monospace> <monospace>+</monospace> <monospace>1)</monospace></p>
      <p>
        <monospace>  </monospace>
        <italic toggle="yes">
          <monospace>
            <italic toggle="yes"># Call log function on GPU</italic>
          </monospace>
        </italic>
      </p>
      <p>
        <monospace>  data[i]=CUDAnative.log(data[i])</monospace>
      </p>
      <p>
        <monospace> end</monospace>
      </p>
      <p>
        <monospace> return</monospace>
      </p>
      <p>
        <monospace>end</monospace>
      </p>
      <p>
        <italic toggle="yes">
          <monospace><italic toggle="yes"># initialize and transfer data to GPU</italic>.</monospace>
        </italic>
      </p>
      <p>
        <monospace>MAX= 64000</monospace>
      </p>
      <p>
        <monospace>d_data=CuArray(rand(MAX))</monospace>
      </p>
      <p>
        <italic toggle="yes">
          <monospace>
            <italic toggle="yes"># Launching GPU</italic>
          </monospace>
        </italic>
      </p>
      <p><monospace>d_res = @cuda blocks</monospace> <monospace>=</monospace> <monospace>1000threads</monospace> <monospace>=</monospace> <monospace>64</monospace></p>
      <p>
        <monospace>      log_kernel(d_data, MAX)</monospace>
      </p>
      <p>
        <italic toggle="yes">
          <monospace>
            <italic toggle="yes"># Transfer result back to CPU</italic>
          </monospace>
        </italic>
      </p>
      <p>
        <monospace>res=collect(d_res)</monospace>
      </p>
    </sec>
    <sec>
      <title>Comparison with tensorQTL</title>
      <p><xref rid="jkab254-T2" ref-type="table">Table 2</xref> shows the comparison of runtimes broken down by time taken for data transfer, core computation, and post processing. The main finding is that the data transfer and core computation take about the same time for tensorQTL and LiteQTL for both CPU and GPU. Both program timings indicate a speedup factor of 20 times for the core computation of the full matrix. For the filtered version, the GPU was about 56 times faster than CPU only for tensorQTL and about 18 times faster for LiteQTL.</p>
      <table-wrap position="float" id="jkab254-T2">
        <label>Table 2</label>
        <caption>
          <p> Timing comparison between tensorQTL and LiteQTL: Times are averaged over 10 runs and expressed in seconds</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="3" colspan="1"/>
              <th colspan="4" align="center" rowspan="1">tensorQTL<hr/></th>
              <th colspan="4" align="center" rowspan="1">LiteQTL<hr/></th>
            </tr>
            <tr>
              <th colspan="2" align="center" rowspan="1">Full matrix<hr/></th>
              <th colspan="2" align="center" rowspan="1">Filtered <italic toggle="yes">P</italic>-value<hr/></th>
              <th colspan="2" align="center" rowspan="1">Full matrix<hr/></th>
              <th colspan="2" align="center" rowspan="1">Filtered max<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">CPU only</th>
              <th rowspan="1" colspan="1">CPU and GPU</th>
              <th rowspan="1" colspan="1">CPU only</th>
              <th rowspan="1" colspan="1">CPU and GPU</th>
              <th rowspan="1" colspan="1">CPU only</th>
              <th rowspan="1" colspan="1">CPU and GPU</th>
              <th rowspan="1" colspan="1">CPU only</th>
              <th rowspan="1" colspan="1">CPU and GPU</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Data transfer</td>
              <td rowspan="1" colspan="1">0.015</td>
              <td rowspan="1" colspan="1">0.561</td>
              <td rowspan="1" colspan="1">0.018</td>
              <td rowspan="1" colspan="1">0.069</td>
              <td rowspan="1" colspan="1">0.000</td>
              <td rowspan="1" colspan="1">0.660</td>
              <td rowspan="1" colspan="1">0.000</td>
              <td rowspan="1" colspan="1">0.020</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Core computation</td>
              <td rowspan="1" colspan="1">0.940</td>
              <td rowspan="1" colspan="1">0.055</td>
              <td rowspan="1" colspan="1">1.601</td>
              <td rowspan="1" colspan="1">0.029</td>
              <td rowspan="1" colspan="1">1.022</td>
              <td rowspan="1" colspan="1">0.054</td>
              <td rowspan="1" colspan="1">0.536</td>
              <td rowspan="1" colspan="1">0.030</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Post processing</td>
              <td rowspan="1" colspan="1">9.865</td>
              <td rowspan="1" colspan="1">8.060</td>
              <td rowspan="1" colspan="1">0.777</td>
              <td rowspan="1" colspan="1">0.719</td>
              <td rowspan="1" colspan="1">0.000</td>
              <td rowspan="1" colspan="1">0.785</td>
              <td rowspan="1" colspan="1">0.000</td>
              <td rowspan="1" colspan="1">0.030</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Elapsed</td>
              <td rowspan="1" colspan="1">10.820</td>
              <td rowspan="1" colspan="1">8.676</td>
              <td rowspan="1" colspan="1">2.396</td>
              <td rowspan="1" colspan="1">0.817</td>
              <td rowspan="1" colspan="1">1.022</td>
              <td rowspan="1" colspan="1">1.499</td>
              <td rowspan="1" colspan="1">0.536</td>
              <td rowspan="1" colspan="1">0.080</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p>Full matrix timings are done without any filtering threshold. Filtering threshold is different for tensorQTL and LiteQTL. For tensorQTL, the MAF (Minor Allele Frequency) threshold is 0.05, and the <italic toggle="yes">P</italic>-value threshold is <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. For LiteQTL, the MAF threshold is 0.05, and the maximum LOD score for each transcript. The main conclusion is that the core computation and data transfer between tensorQTL and LiteQTL is very similar. The difference lies in post processing, which varies a lot depending on filtering threshold, and user-defined output.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Depending on user-defined options, the output may need further processing after the core computation. This post processing is responsible for the main differences in elapsed time. Because it depends on user options, both programs exclude that time in calculating the GPU speedup. In our tests, the elapsed time for tensorQTL was longer than for LiteQTL.</p>
    </sec>
  </sec>
  <sec sec-type="discussion">
    <title>Discussion</title>
    <p>We examined the effectiveness of using GPUs for speeding up eQTL scans in the BXD family of recombinant inbred lines. We are able to run genome scans for the spleen data (36K traits) in 0.06 s and for the hippocampus data (1.2M traits) in 2.82 s. This meets the requirements for real-time performance. Although there are additional hurdles in deploying the GeneNetwork front-end web service, this is very encouraging. Users can use our stand-alone Julia package for running eQTL scans.</p>
    <p>For us, the GPU speedup compared to CPU implementation is best when the matrices are closer to square shapes. On our test hardware, matrix multiplication is up to 4 times faster on GPU than on 16 threaded CPUs. The exact speedups with our algorithm and software will depend on the hardware configurations.</p>
    <p>The 200–300 times speedup reported by <xref rid="jkab254-B19" ref-type="bibr">Taylor-Weiner <italic toggle="yes">et al.</italic> (2019)</xref> does not include data transfer, and for this specific speedup, reported CPU time is single-threaded. The supplement of <xref rid="jkab254-B19" ref-type="bibr">Taylor-Weiner <italic toggle="yes">et al.</italic> (2019)</xref> reported the speedup when GPU data transfer is included, and that brought it down in the range of 10–100. This is the same as our observation. Data transfer time needs to be included when reporting GPU time, since this is a cost associated with using GPU. Sometimes, it is a very significant cost. When LiteQTL returns the full matrix of LOD scores, the data transfer time amounts to more than 90% of total GPU time. It is also more realistic to report a multithreaded CPU time (16 threads or more), since the speedup for CPU from multithreading is easily achievable. These two factors shrink the gap between CPU and GPU. However, when the CPU multithreading acceleration is capped (the cost of maintaining multithread communication surpass the computation time), GPU can provide that extra boost, for time critical use cases.</p>
    <p>Returning the maximum LOD score for each transcript reduces data size and speeds up computations substantially. However, this comes at a cost: to identify all eQTLs, one would need to run a secondary genome scan with all transcripts with at least one eQTL.</p>
    <p>Our experience in this project indicates that the excitement about using GPUs for speeding computations needs to be tempered by the limitations of GPU. It takes significant additional development time and therefore, is most useful for high-value (deep learning) or routine-use (graphics rendering) projects. We also need to reconsider algorithms with the GPU in mind, and pay attention to the speed and size of data to be transfered to/from CPU to GPU. In many problems it is much easier to throw additional CPU cores to the problem with minimal programming than to devote effort into GPU programming. Both <xref rid="jkab254-B19" ref-type="bibr">Taylor-Weiner <italic toggle="yes">et al.</italic> (2019)</xref> and LiteQTL attempt to address this barrier, making GPU algorithms more available to a broader range of users.</p>
    <p>LiteQTL only supports a 1-degree freedom test currently and assumes missing data in the input data set; any missing data has to be handled in pre-processing and will add to the computation time. Currently, the LOD scores are fit using a linear model; for many problems a linear mixed model (LMM) (<xref rid="jkab254-B11" ref-type="bibr">Lippert <italic toggle="yes">et al.</italic> 2011</xref>) is of interest. We expect to build on the current work to tackle that problem in the future.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was funded by National Instiutes of Health grants P30DA044223 (P.P., R.W.W., and S.S.), R01GM123489 (C.T., H.K., P.P., R.W.W., K.W.B., and S.S.), and R01GM070683 (K.W.B. and S.S.).</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The BXD Genotype Database (GN Accession: GN600) and two sets of transcriptome data, UTHSCAffy MoGene 1.0 ST Spleen (GN Accession: GN283) and UMUTAffy Hippocampus Exon (GN Accession: GN206) can be obtained from GeneNetwork <ext-link xlink:href="https://GeneNetwork.org" ext-link-type="uri">https://GeneNetwork.org</ext-link>. The GEUVADIS data for tensorQTL comparison can be obtained from tensorQTL’s Github repository: <ext-link xlink:href="https://github.com/broadinstitute/tensorqtl/blob/master/example/tensorqtl_examples.ipynb" ext-link-type="uri">https://github.com/broadinstitute/tensorqtl/blob/master/example/tensorqtl_examples.ipynb</ext-link> Supplemental material is available at figshare: <ext-link xlink:href="https://doi.org/10.25387/g3.14622603" ext-link-type="uri">https://doi.org/10.25387/g3.14622603</ext-link>.</p>
  </sec>
  <sec>
    <title>Conflicts of interest</title>
    <p>The authors declare that there is no conflict of interest.</p>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>Literature cited</title>
    <ref id="jkab254-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ashbrook</surname><given-names>DG</given-names></string-name>, <string-name><surname>Arends</surname><given-names>D</given-names></string-name>, <string-name><surname>Prins</surname><given-names>P</given-names></string-name>, <string-name><surname>Mulligan</surname><given-names>MK</given-names></string-name>, <string-name><surname>Roy</surname><given-names>S</given-names></string-name></person-group>, <etal>et al</etal><year>2019</year>. <article-title>The expanded BXD family of mice: a cohort for experimental systems genetics and precision medicine</article-title>. <source>BioRxiv</source>. <fpage>672097</fpage>.</mixed-citation>
    </ref>
    <ref id="jkab254-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Besard</surname><given-names>T</given-names></string-name>, <string-name><surname>Foket</surname><given-names>C</given-names></string-name>, <string-name><surname>Sutter</surname><given-names>BD.</given-names></string-name></person-group><year>2018</year>. <article-title>Effective extensible programming: unleashing Julia on GPUs</article-title>. <source>IEEE Trans Parallel Distrib Syst</source>. <volume>30</volume>:<fpage>827</fpage>–<lpage>841</lpage>.</mixed-citation>
    </ref>
    <ref id="jkab254-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bezanson</surname><given-names>J</given-names></string-name>, <string-name><surname>Edelman</surname><given-names>A</given-names></string-name>, <string-name><surname>Karpinski</surname><given-names>S</given-names></string-name>, <string-name><surname>Shah</surname><given-names>VB.</given-names></string-name></person-group><year>2017</year>. <article-title>Julia: a fresh approach to numerical computing</article-title>. <source>SIAM Rev</source>. <volume>59</volume>:<fpage>65</fpage>–<lpage>98</lpage>.</mixed-citation>
    </ref>
    <ref id="jkab254-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Broman</surname><given-names>KW</given-names></string-name>, <string-name><surname>Gatti</surname><given-names>DM</given-names></string-name>, <string-name><surname>Simecek</surname><given-names>P</given-names></string-name>, <string-name><surname>Furlotte</surname><given-names>NA</given-names></string-name>, <string-name><surname>Prins</surname><given-names>P</given-names></string-name></person-group>, <etal>et al</etal><year>2019</year>. <article-title>R/qtl2: software for mapping quantitative trait loci with high-dimensional data and multiparent populations</article-title>. <source>Genetics</source>. <volume>211</volume>:<fpage>495</fpage>–<lpage>502</lpage>.<pub-id pub-id-type="pmid">30591514</pub-id></mixed-citation>
    </ref>
    <ref id="jkab254-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Broman</surname><given-names>KW</given-names></string-name>, <string-name><surname>Wu</surname><given-names>H</given-names></string-name>, <string-name><surname>Sen</surname><given-names>Ś</given-names></string-name>, <string-name><surname>Churchill</surname><given-names>GA.</given-names></string-name></person-group><year>2003</year>. <article-title>R/qtl: QTL mapping in experimental crosses</article-title>. <source>Bioinformatics</source>. <volume>19</volume>:<fpage>889</fpage>–<lpage>890</lpage>.<pub-id pub-id-type="pmid">12724300</pub-id></mixed-citation>
    </ref>
    <ref id="jkab254-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chapuis</surname><given-names>G</given-names></string-name>, <string-name><surname>Filangi</surname><given-names>O</given-names></string-name>, <string-name><surname>Elsen</surname><given-names>J-M</given-names></string-name>, <string-name><surname>Lavenier</surname><given-names>D</given-names></string-name>, <string-name><surname>Roy</surname><given-names>PL.</given-names></string-name></person-group><year>2013</year>. <article-title>Graphics processing unit–accelerated quantitative trait loci detection</article-title>. <source>J Comput Biol</source>. <volume>20</volume>:<fpage>672</fpage>–<lpage>686</lpage>.<pub-id pub-id-type="pmid">24000926</pub-id></mixed-citation>
    </ref>
    <ref id="jkab254-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chesler</surname><given-names>EJ</given-names></string-name>, <string-name><surname>Lu</surname><given-names>L</given-names></string-name>, <string-name><surname>Wang</surname><given-names>J</given-names></string-name>, <string-name><surname>Williams</surname><given-names>RW</given-names></string-name>, <string-name><surname>Manly</surname><given-names>KF.</given-names></string-name></person-group><year>2004</year>. <article-title>WebQTL: rapid exploratory analysis of gene expression and genetic networks for brain and behavior</article-title>. <source>Nat Neurosci</source>. <volume>7</volume>:<fpage>485</fpage>–<lpage>486</lpage>.<pub-id pub-id-type="pmid">15114364</pub-id></mixed-citation>
    </ref>
    <ref id="jkab254-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haley</surname><given-names>CS</given-names></string-name>, <string-name><surname>Knott</surname><given-names>SA.</given-names></string-name></person-group><year>1992</year>. <article-title>A simple regression method for mapping quantitative trait loci in line crosses using flanking markers</article-title>. <source>Heredity (Edinb)</source>. <volume>69</volume>:<fpage>315</fpage>–<lpage>324</lpage>.<pub-id pub-id-type="pmid">16718932</pub-id></mixed-citation>
    </ref>
    <ref id="jkab254-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lander</surname><given-names>ES</given-names></string-name>, <string-name><surname>Botstein</surname><given-names>D.</given-names></string-name></person-group><year>1989</year>. <article-title>Mapping mendelian factors underlying quantitative traits using RFLP linkage maps</article-title>. <source>Genetics</source>. <volume>121</volume>:<fpage>185</fpage>–<lpage>199</lpage>.<pub-id pub-id-type="pmid">2563713</pub-id></mixed-citation>
    </ref>
    <ref id="jkab254-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lippert</surname><given-names>C</given-names></string-name>, <string-name><surname>Listgarten</surname><given-names>J</given-names></string-name>, <string-name><surname>Liu</surname><given-names>Y</given-names></string-name>, <string-name><surname>Kadie</surname><given-names>CM</given-names></string-name>, <string-name><surname>Davidson</surname><given-names>RI</given-names></string-name></person-group>, <etal>et al</etal><year>2011</year>. <article-title>FaST linear mixed models for genome-wide association studies</article-title>. <source>Nat Methods</source>. <volume>8</volume>:<fpage>833</fpage>–<lpage>835</lpage>.<pub-id pub-id-type="pmid">21892150</pub-id></mixed-citation>
    </ref>
    <ref id="jkab254-B12">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Mulligan</surname><given-names>MK</given-names></string-name>, <string-name><surname>Mozhui</surname><given-names>K</given-names></string-name>, <string-name><surname>Prins</surname><given-names>P</given-names></string-name>, <string-name><surname>Williams</surname><given-names>RW.</given-names></string-name></person-group><year>2017</year>. <part-title>Systems Genetics</part-title>. In: Klaus Schughart and Robert W. Williams, editors. <source>GeneNetwork: a toolbox for systems genetics</source>. New York: <publisher-name>Springer</publisher-name>, p. <fpage>75</fpage>–<lpage>120</lpage>.</mixed-citation>
    </ref>
    <ref id="jkab254-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nickolls</surname><given-names>J</given-names></string-name>, <string-name><surname>Buck</surname><given-names>I</given-names></string-name>, <string-name><surname>Garland</surname><given-names>M</given-names></string-name>, <string-name><surname>Skadron</surname><given-names>K.</given-names></string-name></person-group><year>2008</year>. <article-title>Scalable parallel programming with CUDA</article-title>. <source>Queue</source>. <volume>6</volume>:<fpage>40</fpage>–<lpage>53</lpage>.</mixed-citation>
    </ref>
    <ref id="jkab254-B14">
      <mixed-citation publication-type="other">Nvidia <year>2021a</year>. cuBLAS. <ext-link xlink:href="https://developer.nvidia.com/cublas" ext-link-type="uri">https://developer.nvidia.com/cublas (Accessed: 2021 August 4)</ext-link>.</mixed-citation>
    </ref>
    <ref id="jkab254-B15">
      <mixed-citation publication-type="other">Nvidia <year>2021b</year>. CuBLAS example code. <ext-link xlink:href="https://docs.nvidia.com/cuda/cublas/index.html#example-code" ext-link-type="uri">https://docs.nvidia.com/cuda/cublas/index.html#example-code (Accessed: 2021 August 4)</ext-link>.</mixed-citation>
    </ref>
    <ref id="jkab254-B16">
      <mixed-citation publication-type="other">Nvidia <year>2021c</year>. nvprof. <ext-link xlink:href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html" ext-link-type="uri">https://docs.nvidia.com/cuda/profiler-users-guide/index.html (Accessed: 2021 August 4)</ext-link>.</mixed-citation>
    </ref>
    <ref id="jkab254-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shabalin</surname><given-names>AA.</given-names></string-name></person-group><year>2012</year>. <article-title>Matrix eQTL: ultra fast eqtl analysis via large matrix operations</article-title>. <source>Bioinformatics</source>. <volume>28</volume>:<fpage>1353</fpage>–<lpage>1358</lpage>.<pub-id pub-id-type="pmid">22492648</pub-id></mixed-citation>
    </ref>
    <ref id="jkab254-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sloan</surname><given-names>Z</given-names></string-name>, <string-name><surname>Arends</surname><given-names>D</given-names></string-name>, <string-name><surname>Broman</surname><given-names>KW</given-names></string-name>, <string-name><surname>Centeno</surname><given-names>A</given-names></string-name>, <string-name><surname>Furlotte</surname><given-names>N</given-names></string-name></person-group>, <etal>et al</etal><year>2016</year>. <article-title>GeneNetwork: framework for web-based genetics</article-title>. <source>JOSS</source>. <volume>1</volume>:<fpage>25</fpage>.</mixed-citation>
    </ref>
    <ref id="jkab254-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Taylor-Weiner</surname><given-names>A</given-names></string-name>, <string-name><surname>Aguet</surname><given-names>F</given-names></string-name>, <string-name><surname>Haradhvala</surname><given-names>NJ</given-names></string-name>, <string-name><surname>Gosai</surname><given-names>S</given-names></string-name>, <string-name><surname>Anand</surname><given-names>S</given-names></string-name></person-group>, <etal>et al</etal><year>2019</year>. <article-title>Scaling computational genomics to millions of individuals with GPUs</article-title>. <source>Genome Biol</source>. <volume>20</volume>:<fpage>228</fpage>.<pub-id pub-id-type="pmid">31675989</pub-id></mixed-citation>
    </ref>
    <ref id="jkab254-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Q</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>X</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name><surname>Yi</surname><given-names>Q.</given-names></string-name></person-group><year>2013</year>. <article-title>AUGEM</article-title>: automatically generate high performance dense linear algebra kernels on x86 CPUs. In <italic toggle="yes">SC’13: Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis</italic>, pp. <fpage>1</fpage>–<lpage>12</lpage>, New York: IEEE.</mixed-citation>
    </ref>
    <ref id="jkab254-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>F-T</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>Z-H</given-names></string-name>, <string-name><surname>Tong</surname><given-names>X-R</given-names></string-name>, <string-name><surname>Zhu</surname><given-names>Z-X</given-names></string-name>, <string-name><surname>Qi</surname><given-names>T</given-names></string-name></person-group>, <etal>et al</etal><year>2015</year>. <article-title>Mixed linear model approaches of association mapping for complex traits based on omics variants</article-title>. <source>Sci Rep</source>. <volume>5</volume>:<fpage>10298</fpage>.<pub-id pub-id-type="pmid">26223539</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
