<?properties open-access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-id journal-id-type="pmc">plosone</journal-id>
    <journal-title-group>
      <journal-title>PLoS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">4986961</article-id>
    <article-id pub-id-type="pmid">27529547</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0160439</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-16-11758</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Agriculture</subject>
          <subj-group>
            <subject>Crop Science</subject>
            <subj-group>
              <subject>Crops</subject>
              <subj-group>
                <subject>Fruits</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Organisms</subject>
          <subj-group>
            <subject>Plants</subject>
            <subj-group>
              <subject>Fruits</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Equipment</subject>
          <subj-group>
            <subject>Optical Equipment</subject>
            <subj-group>
              <subject>Cameras</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Phenotypes</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Neural Networks</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Neural Networks</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Computer Software</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Data Acquisition</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Plant Genetics</subject>
            <subj-group>
              <subject>Crop Genetics</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Plant Science</subject>
          <subj-group>
            <subject>Plant Genetics</subject>
            <subj-group>
              <subject>Crop Genetics</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Agriculture</subject>
          <subj-group>
            <subject>Crop Science</subject>
            <subj-group>
              <subject>Crops</subject>
              <subj-group>
                <subject>Vegetables</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Organisms</subject>
          <subj-group>
            <subject>Plants</subject>
            <subj-group>
              <subject>Vegetables</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>GiNA, an Efficient and High-Throughput Software for Horticultural Phenotyping</article-title>
      <alt-title alt-title-type="running-head">GiNA, High-Throughput Phenotyping</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Diaz-Garcia</surname>
          <given-names>Luis</given-names>
        </name>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Covarrubias-Pazaran</surname>
          <given-names>Giovanny</given-names>
        </name>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Schlautman</surname>
          <given-names>Brandon</given-names>
        </name>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zalapa</surname>
          <given-names>Juan</given-names>
        </name>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff003">
          <sup>3</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>University of Wisconsin, Department of Horticulture, Madison, Wisconsin, United States of America</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Instituto Nacional de Investigaciones Forestales y Agr√≠colas y Pecuarias, Aguascalientes, Mexico</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>USDA-ARS, Vegetable Crops Research Unit, University of Wisconsin, Madison, Wisconsin, United States of America</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Pang</surname>
          <given-names>Xiaoming</given-names>
        </name>
        <role>Editor</role>
        <xref ref-type="aff" rid="edit1"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Beijing Forestry University, CHINA</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have received funding from a commercial source: Ocean Spray Cranberries, Inc., but this does not alter the authors' adherence to PLOS ONE policies on sharing data and materials. The authors do not have any other relevant declarations relating to employment, consultancy, patents, products in development, marketed products, etc. The authors declare that they have no other financial or nonfinancial, professional, or personal potential competing interests.</p>
      </fn>
      <fn fn-type="con">
        <p>
          <list list-type="simple">
            <list-item>
              <p><bold>Conceived and designed the experiments:</bold> LDG BS GCP JZ.</p>
            </list-item>
            <list-item>
              <p><bold>Performed the experiments:</bold> LDG GCP BS.</p>
            </list-item>
            <list-item>
              <p><bold>Analyzed the data:</bold> LDG BS GCP.</p>
            </list-item>
            <list-item>
              <p><bold>Contributed reagents/materials/analysis tools:</bold> JZ.</p>
            </list-item>
            <list-item>
              <p><bold>Wrote the paper:</bold> LDG BS JZ.</p>
            </list-item>
          </list>
        </p>
      </fn>
      <corresp id="cor001">* E-mail: <email>jezalapa@wisc.edu</email> (JZ); <email>diaz.antonio@inifap.gob.mx</email> (LDG)</corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>16</day>
      <month>8</month>
      <year>2016</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2016</year>
    </pub-date>
    <volume>11</volume>
    <issue>8</issue>
    <elocation-id>e0160439</elocation-id>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>3</month>
        <year>2016</year>
      </date>
      <date date-type="accepted">
        <day>19</day>
        <month>7</month>
        <year>2016</year>
      </date>
    </history>
    <permissions>
      <license xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">
        <license-p>This is an open access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">Creative Commons CC0</ext-link> public domain dedication.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pone.0160439.pdf"/>
    <abstract>
      <p>Traditional methods for trait phenotyping have been a bottleneck for research in many crop species due to their intensive labor, high cost, complex implementation, lack of reproducibility and propensity to subjective bias. Recently, multiple high-throughput phenotyping platforms have been developed, but most of them are expensive, species-dependent, complex to use, and available only for major crops. To overcome such limitations, we present the open-source software GiNA, which is a simple and free tool for measuring horticultural traits such as shape- and color-related parameters of fruits, vegetables, and seeds. GiNA is multiplatform software available in both R and MATLAB<sup>¬Æ</sup> programming languages and uses conventional images from digital cameras with minimal requirements. It can process up to 11 different horticultural morphological traits such as length, width, two-dimensional area, volume, projected skin, surface area, RGB color, among other parameters. Different validation tests produced highly consistent results under different lighting conditions and camera setups making GiNA a very reliable platform for high-throughput phenotyping. In addition, five-fold cross validation between manually generated and GiNA measurements for length and width in cranberry fruits were 0.97 and 0.92. In addition, the same strategy yielded prediction accuracies above 0.83 for color estimates produced from images of cranberries analyzed with GiNA compared to total anthocyanin content (TAcy) of the same fruits measured with the standard methodology of the industry. Our platform provides a scalable, easy-to-use and affordable tool for massive acquisition of phenotypic data of fruits, seeds, and vegetables.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution>Consejo Nacional de Ciencia y Tecnolog√≠a (MX)</institution>
        </funding-source>
        <principal-award-recipient>
          <name>
            <surname>Diaz-Garcia</surname>
            <given-names>Luis</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution>USDA-ARS</institution>
        </funding-source>
        <award-id>Project no. 3655-21220-001-00</award-id>
        <principal-award-recipient>
          <name>
            <surname>Zalapa</surname>
            <given-names>Juan</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award003">
        <funding-source>
          <institution>WI-DATCP</institution>
        </funding-source>
        <award-id>SCBG Project #14-002</award-id>
        <principal-award-recipient>
          <name>
            <surname>Zalapa</surname>
            <given-names>Juan</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award004">
        <funding-source>
          <institution>Ocean Spray Cranberries, Inc.</institution>
        </funding-source>
        <principal-award-recipient>
          <name>
            <surname>Zalapa</surname>
            <given-names>Juan</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award005">
        <funding-source>
          <institution>Wisconsin Cranberry Growers Association</institution>
        </funding-source>
        <principal-award-recipient>
          <name>
            <surname>Zalapa</surname>
            <given-names>Juan</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award006">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100009991</institution-id>
            <institution>Cranberry Institute</institution>
          </institution-wrap>
        </funding-source>
        <principal-award-recipient>
          <name>
            <surname>Zalapa</surname>
            <given-names>Juan</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award007">
        <funding-source>
          <institution>Frank B. Koller Cranberry Fellowship for Graduate Students</institution>
        </funding-source>
        <principal-award-recipient>
          <name>
            <surname>Schlautman</surname>
            <given-names>Brandon</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award008">
        <funding-source>
          <institution>Consejo Nacional de Ciencia y Tecnolog√≠a (CONACYT, Mexico)</institution>
        </funding-source>
        <principal-award-recipient>
          <name>
            <surname>Covarrubias-Pazaran</surname>
            <given-names>Giovanny</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>This project was supported by USDA-ARS (project no. 3655-21220-001-00 provided to JZ); WI-DATCP (SCBG Project #14-002); National Science Foundation (DBI-1228280); Ocean Spray Cranberries, Inc.; Wisconsin Cranberry Growers Association; Cranberry Institute. BS was supported by the Frank B. Koller Cranberry Fellowship for Graduate Students. GCP and LDG were supported by the Consejo Nacional de Ciencia y Tecnolog√≠a (CONACYT, Mexico). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="2"/>
      <table-count count="2"/>
      <page-count count="12"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All relevant data are within the paper and its Supporting Information files. The functions are deposited in the Cranberry Genetics and Genomics Lab (<ext-link ext-link-type="uri" xlink:href="http://cggl.horticulture.wisc.edu/home-page/">http://cggl.horticulture.wisc.edu/home-page/</ext-link>) at the University of Wisconsin-Madison; the version written in R is also available in the Comprehensive R Archive Network (CRAN). Details of the software and operation manuals are also available in CRAN.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All relevant data are within the paper and its Supporting Information files. The functions are deposited in the Cranberry Genetics and Genomics Lab (<ext-link ext-link-type="uri" xlink:href="http://cggl.horticulture.wisc.edu/home-page/">http://cggl.horticulture.wisc.edu/home-page/</ext-link>) at the University of Wisconsin-Madison; the version written in R is also available in the Comprehensive R Archive Network (CRAN). Details of the software and operation manuals are also available in CRAN.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>The last decades have been marked by important biological discoveries driven in large part by the acquisition of massive amounts of genomic data. To fully utilize this knowledge and to apply it to plant breeding programs and the agricultural industry, strategies focused on quantifying phenotypic traits must evolve as quickly as the genome sequencing technologies [<xref rid="pone.0160439.ref001" ref-type="bibr">1</xref>]. Most of the current tools for high-throughput phenotyping in crop genetics research or industry are species-dependent and very complex to implement [<xref rid="pone.0160439.ref002" ref-type="bibr">2</xref>‚Äì<xref rid="pone.0160439.ref006" ref-type="bibr">6</xref>]. In most cases, the phenotyping technology is not accessible for small research groups or scientists working in minor crops.</p>
    <p>Traditionally, breeding programs of minor crops have focused on a limited set of traits such as yield, fruit quality and resistance to abiotic or biotic stress using manually-collected phenotypic data. Manual phenotyping approaches are limited by the amount of data that can be recorded and processed, by the human error intrinsic to the measurement process, and by the difficulty of quantifying complex traits such as fruit or seed color [<xref rid="pone.0160439.ref007" ref-type="bibr">7</xref>]. Therefore, the availability of new technologies for massive acquisition and analysis of phenotypic data is critical to develop newer, more efficient strategies for genetic improvement in minor crops.</p>
    <p>Machine vision technology has been successfully applied in different agricultural sectors for yield prediction [<xref rid="pone.0160439.ref008" ref-type="bibr">8</xref>,<xref rid="pone.0160439.ref009" ref-type="bibr">9</xref>], measuring physiological status of the plant in response to stresses [<xref rid="pone.0160439.ref010" ref-type="bibr">10</xref>], precision farming, fruit sorting and classification [<xref rid="pone.0160439.ref011" ref-type="bibr">11</xref>,<xref rid="pone.0160439.ref012" ref-type="bibr">12</xref>], and automated phenotyping [<xref rid="pone.0160439.ref013" ref-type="bibr">13</xref>]. Using automatic imaging technology allows the acquisition of quantitative data accurately, consistently, and nondestructively [<xref rid="pone.0160439.ref013" ref-type="bibr">13</xref>]. Some of these automatic systems for image data collection have already been used in quantitative trait loci (QTL) mapping and genome wide association studies. For example, image-based technologies and genetic association analysis were used in rice in order to identify the architecture of temporal salinity response [<xref rid="pone.0160439.ref004" ref-type="bibr">4</xref>]. The use of a rice automated and scalable phenotyping system allowed the collection of data for association analysis based on 97 digital traits in almost 400 genotypes over a 14-day period. In <italic>Arabidopsis thaliana</italic>, genome-wide association mapping of growth was conducted by combining top-view imaging, high-throughput image analysis, modeling of growth dynamics, and end-point fresh weight determination [<xref rid="pone.0160439.ref014" ref-type="bibr">14</xref>]. In triticale, a non-invasive and highly precise methodology was applied to identify QTLs related with the dynamic temporal patterns of biomass accumulation [<xref rid="pone.0160439.ref003" ref-type="bibr">3</xref>]. The previous examples are a small sample of studies in which image-based phenomics has been applied to measure important plant traits and to conduct genome-wide and QTL studies.</p>
    <p>For the most part, phenomics has not been fully exploited in fruit crop research. Fruit phenomics studies have predominantly focused on developing detection, sorting and classification systems for the commercial fruit industry. Rakun <italic>et al</italic>. [<xref rid="pone.0160439.ref015" ref-type="bibr">15</xref>] created a system for apple yield prediction by detecting fruits in orchard trees using spatial-frequency based texture analysis and multi-view geometry. In citrus, a multivariate image-based approach was developed for automatically detecting skin defects [<xref rid="pone.0160439.ref016" ref-type="bibr">16</xref>]. Also, a very straightforward method based on neural networks for determining cherry color parameters during ripening was developed by Taghadomi-Sabery <italic>et al</italic>. [<xref rid="pone.0160439.ref017" ref-type="bibr">17</xref>]. Gonzalo and van der Knaap [<xref rid="pone.0160439.ref018" ref-type="bibr">18</xref>] used Tomato Analyzer for the genetic analysis of tomato varieties that exhibited elongated fruit shape.</p>
    <p>In this study, we present a simple, user friendly, and scalable software called GiNA for the accurate measurement of shape and color related traits in fruits, vegetables and seeds. GiNA is a multiplatform software available in R and MATLAB<sup>¬Æ</sup> that uses conventional pictures to perform high-throughput measurements of the physical properties of different objects. We emphasize the utility and applicability of GiNA for minor crops such as horticultural crops, where phenotyping resources are limited.</p>
  </sec>
  <sec id="sec002">
    <title>GiNA, step by step</title>
    <sec id="sec003">
      <title>An overall description of the platform</title>
      <p>The GiNA platform was designed to solve the common deficiencies of traditional phenotyping methods such as reproducibility, scalability, and affordability. Nowadays, several phenotyping systems are available, but most of them are very complex to use, are not robust enough for high-throughput phenotyping, are too expensive, or work only for the plant species for which they were created. GiNA‚Äôs platform uses a very simple strategy for measuring shape and color trait parameters and offers several advantages: 1) it is highly reproducible, 2) it does not require programing experience, 3) it can be applied to many different crops, and 4) the cost of implementation and equipment required can be as low as $300 USD.</p>
      <p>GiNA relies on two main steps, conventional digital-picture recording and image processing by either R or MATLAB<sup>¬Æ</sup> (users‚Äô choice) algorithm implementation (<xref ref-type="fig" rid="pone.0160439.g001">Fig 1</xref>). A brief description of the software is provided in this manuscript; for more details and operating instructions, an illustrative tutorial is available at: <ext-link ext-link-type="uri" xlink:href="http://cggl.horticulture.wisc.edu/home-page/">http://cggl.horticulture.wisc.edu/home-page/</ext-link> and in The Comprehensive R Archive Network (<ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org">https://cran.r-project.org</ext-link>).</p>
      <fig id="pone.0160439.g001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0160439.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>Example of computations performed by GiNA for background extraction on cranberry fruits.</title>
          <p>The algorithm works in two steps, image segmentation (by applying a predefined threshold or using a neural network approach) and object recognition to calculate the physical parameters.</p>
        </caption>
        <graphic xlink:href="pone.0160439.g001"/>
      </fig>
    </sec>
    <sec id="sec004">
      <title>Picture recording</title>
      <p>Our methodology can measure fruits, vegetables and seeds of different sizes, from millimeters (such as peas) to decimeters (such as melon or squash fruit). Although we have included features in GiNA to help cope with image to image variation, parameter standardization for each project and across photography sessions must be performed to ensure best results. For example, GiNA‚Äôs users must standardize lighting conditions and camera settings such as light sensitivity, shutter speed, aperture and avoid camera flashes to reduce light reflection, which can appear as bright spots on objects in the image. In addition, camera alignment with the center of the background and proper focus on the fruits is required for best results. Since GiNA precisely estimates different parameters related with the shape of the object, the users must arrange the fruits/seeds in the scene such that they do not touch. Finally, references on each side of the background must be included to allow data normalization. The pictures analyzed in this study were taken using a home-made camera holder (as the shown in <xref ref-type="supplementary-material" rid="pone.0160439.s002">S1 Fig</xref>) and a DSLR camera Canon EOS REBEL T5. However, simpler cameras and/or tripod setups can be used as long as the described requirements are met.</p>
    </sec>
    <sec id="sec005">
      <title>Algorithm implementation</title>
      <p>The image-processing algorithm implemented in GiNA is divided into two parts, image segmentation and object analysis. The image-segmentation step performs a background extraction and prepares the image for data collection in the next step. The data-analysis step uses the segmented image and applies built-in R or MATLAB<sup>¬Æ</sup> functions for extracting object properties. Finally, the measurements of all objects in the image are grouped and normalized for their comprehensive analysis.</p>
      <p>Depending on the color contrast between the object (e.g., fruit) and background, two strategies can be applied for segmentation. When there is a very marked contrast between the object and the picture background, a threshold in one or multiple RGB channels can be set as cutoff value for removing the background from the picture. Commonly, darker (on a white background) or lighter (on a dark background) objects with small color variation can be analyzed by using threshold-based segmentation. When there is significant variation in the color of the object (e.g., one side of the object is dark red and the other side is yellow), or there is not evident contrast between the objects and background, a neural network approach can be implemented. This strategy requires an extra set of images including one picture of the color and texture variation in the background (without the references), and another one from the objects (see <xref ref-type="supplementary-material" rid="pone.0160439.s003">S2 Fig</xref> for examples of training pictures in cranberry). These figures can easily be made by creating a collage of screenshots. These two figures (or more if multiple colors are present in the fruits/vegetables) are used for training the neural network. GiNA automatically reads (in RGB format) each of the images provided, extracts the R, G and B values of each pixel and uses them as input for generate the network. Subsequently, GiNA produces 2 numeric values (or more if multiple figures representing the fruit color were provided) corresponding to the probability of each pixel to be part of the background or the fruits/vegetables. In terms of the network architecture, it consists of 10 hidden neurons, 70% of the pixels are used for training, 15% for validation, and 15% for testing. Data division is assigned randomly, and network training is done using scaled conjugate gradient and the performance is evaluated minimizing cross-entropy. Increasing resolution of the training pictures provides increased network performance for classifying pixels, but pictures of 1000x1000 pixels are sufficient for most analyses. The neural network approach can be also used in all the same situations that the threshold-based segmentation strategy is appropriate.</p>
      <p>Once the segmentation has been applied (either by the threshold-based or neuronal network approach), it is necessary to clean the segmented figure in order to optimize the measurement computation. For example, if too much light was used in the picture, the inner parts of the fruits will be recognized as background. To deal with this situation, GiNA uses an algorithm for filling in holes in each picture. In other cases, and depending of the camera and lens used, the picture can have less illumination around the borders (even when external sources of light are used); in this situations, GiNA uses a function to stabilize the illumination among all the areas. Pictures corrections such as light border adjustments and filling in holes are applied automatically, thus the user does not have to take any additional processing steps.</p>
      <p>Following segmentation of all the objects and proper post processing, customized functions normalize the photos using the references and generate biologically useful measurements for all objects. Among the measurements that this platform can obtain are those related to the object‚Äôs shape (e.g., two-dimensional area, length, width, shape, projected skin surface, two-dimensional perimeter, projected volume, eccentricity and solidity). Additionally, color related measurements such as RGB color, gray-scale color and color variation are also computed. All these parameters are computed solely based on the segmentation mask. A better description mathematical definition of the parameters generated by GiNA is available in <xref ref-type="supplementary-material" rid="pone.0160439.s006">S1 Table</xref>.</p>
      <p>For user practicality, GiNA was written as a single function for both R and MATLAB<sup>¬Æ</sup>. However, multiple arguments can be declared to obtain the best estimates from the pictures, such as (1) the directory location of the pictures to be analyzed, (2) a resizing factor to reduce the number of pixels (large pictures take more time to process), (3) the minimum area of an object to be considered, (4) the desired segmentation method (either threshold or neural network approach), (5) the RGB channels to be used if the threshold segmentation method is used, (6) the number of references in each picture, (7) the actual size of the references in a specific unit (e.g., cm or inches) in order to convert the corresponding measurements (originally produced in pixels), and (8) arguments to generate figures and write.<italic>csv</italic> files of the data.</p>
    </sec>
    <sec id="sec006">
      <title>GiNA produces consistent data under different system configurations</title>
      <p>The GiNA software is very robust and produces consistent data even in variable lighting conditions and with different camera setups. A common concern about phenotyping systems based on conventional imaging a threshold-based segmentation methods is that the pictures must have extremely standardized lighting conditions and that the objects must be arranged in a specific way. In order to test GiNA‚Äôs robustness to cope with unfavorable photographic conditions, we performed an analysis to measure the correlation between measurements under different lighting conditions and different camera setups.</p>
      <p><xref rid="pone.0160439.t001" ref-type="table">Table 1</xref> shows the correlation between three pictures (containing the same 24 fruits) under different lighting conditions. In order to simulate light variations, different shutter speeds in the camera were used. As illustrated in <xref ref-type="supplementary-material" rid="pone.0160439.s004">S3 Fig</xref>, the pictures used are extreme cases of light variations. Among all the variables, a correlation of 0.92 was obtained, but most correlations were above 0.98 for all the comparisons between shape-related parameters, except for solidity (the extent that the shape is convex or concave), which had low correlation values among different lighting conditions. As expected, the parameters related with color showed lower average correlation (gray-scale color = 0.94 and color variation = 0.83) than shape and size related parameters. In general, although our tests showed that GiNA can cope with variable lighting conditions, we recommend to implementing a light standardization procedure prior to the start of massive phenotyping and maintaining the same lighting conditions throughout the experiment.</p>
      <table-wrap id="pone.0160439.t001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0160439.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>Pearson‚Äôs correlation between three pictures taken using different lighting conditions.</title>
          <p>Shutter speed was modified in each picture in order to simulate light variation. All correlations were statistically significant at <italic>p-value</italic>&lt;0.05. Used for this test can be found in <xref ref-type="supplementary-material" rid="pone.0160439.s004">S3 Fig</xref>.</p>
        </caption>
        <alternatives>
          <graphic id="pone.0160439.t001g" xlink:href="pone.0160439.t001"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" colspan="2" rowspan="2">Parameters</th>
                <th align="center" colspan="3" rowspan="1">Lighting conditions</th>
              </tr>
              <tr>
                <th align="center" rowspan="1" colspan="1">Normal (N)</th>
                <th align="center" rowspan="1" colspan="1">Overexposed (O)</th>
                <th align="center" rowspan="1" colspan="1">Dark (D)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" colspan="2" rowspan="1">ISO</td>
                <td align="center" rowspan="1" colspan="1">400</td>
                <td align="center" rowspan="1" colspan="1">400</td>
                <td align="center" rowspan="1" colspan="1">400</td>
              </tr>
              <tr>
                <td align="center" colspan="2" rowspan="1">Shutter speed</td>
                <td align="center" rowspan="1" colspan="1">80</td>
                <td align="center" rowspan="1" colspan="1">20</td>
                <td align="center" rowspan="1" colspan="1">400</td>
              </tr>
              <tr>
                <td align="center" colspan="2" rowspan="1">Segmentation channel</td>
                <td align="center" rowspan="1" colspan="1">Blue</td>
                <td align="center" rowspan="1" colspan="1">Blue</td>
                <td align="center" rowspan="1" colspan="1">Blue</td>
              </tr>
              <tr>
                <td align="center" colspan="2" rowspan="1">Threshold value</td>
                <td align="center" rowspan="1" colspan="1">50</td>
                <td align="center" rowspan="1" colspan="1">125</td>
                <td align="center" rowspan="1" colspan="1">10</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Shape</td>
                <td align="left" rowspan="1" colspan="1">N</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.88</td>
                <td align="center" rowspan="1" colspan="1">0.92</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">O</td>
                <td align="center" rowspan="1" colspan="1">0.88</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.97</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">D</td>
                <td align="center" rowspan="1" colspan="1">0.92</td>
                <td align="center" rowspan="1" colspan="1">0.97</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Length</td>
                <td align="left" rowspan="1" colspan="1">N</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">O</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">D</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Width</td>
                <td align="left" rowspan="1" colspan="1">N</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">O</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">D</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Area</td>
                <td align="left" rowspan="1" colspan="1">N</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">O</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">D</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Perimeter</td>
                <td align="left" rowspan="1" colspan="1">N</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">O</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">D</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">surface</td>
                <td align="left" rowspan="1" colspan="1">N</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">O</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">D</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Volume</td>
                <td align="left" rowspan="1" colspan="1">N</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">O</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">D</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Eccentricity</td>
                <td align="left" rowspan="1" colspan="1">N</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.86</td>
                <td align="center" rowspan="1" colspan="1">0.90</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">O</td>
                <td align="center" rowspan="1" colspan="1">0.86</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.96</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">D</td>
                <td align="center" rowspan="1" colspan="1">0.90</td>
                <td align="center" rowspan="1" colspan="1">0.96</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Solidity</td>
                <td align="left" rowspan="1" colspan="1">N</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.15</td>
                <td align="center" rowspan="1" colspan="1">0.40</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">O</td>
                <td align="center" rowspan="1" colspan="1">0.15</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.51</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">D</td>
                <td align="center" rowspan="1" colspan="1">0.40</td>
                <td align="center" rowspan="1" colspan="1">0.51</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Gray-scale color</td>
                <td align="left" rowspan="1" colspan="1">N</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.94</td>
                <td align="center" rowspan="1" colspan="1">0.93</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">O</td>
                <td align="center" rowspan="1" colspan="1">0.94</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.97</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">D</td>
                <td align="center" rowspan="1" colspan="1">0.93</td>
                <td align="center" rowspan="1" colspan="1">0.97</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Color variation</td>
                <td align="left" rowspan="1" colspan="1">N</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.90</td>
                <td align="center" rowspan="1" colspan="1">0.83</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">O</td>
                <td align="center" rowspan="1" colspan="1">0.90</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.77</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">D</td>
                <td align="center" rowspan="1" colspan="1">0.83</td>
                <td align="center" rowspan="1" colspan="1">0.77</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>In addition to testing GiNA‚Äôs performance under different lighting conditions, we evaluated the consistency of the data produced when changing camera positions. To do that, we photographed cucumber seeds at different camera heights (7, 15 and 22 inches from the background) and obtained Pearson‚Äôs correlation between measurements (see the pictures used in this test in <xref ref-type="supplementary-material" rid="pone.0160439.s005">S4 Fig</xref>). <xref rid="pone.0160439.t002" ref-type="table">Table 2</xref> shows an average correlation = 0.79 among all camera setups. Most of the shape-related parameters showed high correlation; however, because the flat shape of the seeds volume and solidity showed lower correlations than some of the other traits with different heights of the camera. Additionally, due to the decreased number of pixels in the measured objects with increased camera heights, gray-scale color and color variation possessed comparatively low average correlations in our height tests, 0.22 and 0.51, respectively. Although our tests indicated that different height camera setups can produce bias, we suggest that the bias can be easily avoided by using the same camera settings during each experiment.</p>
      <table-wrap id="pone.0160439.t002" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0160439.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Pearson‚Äôs correlation between three pictures on different system setups.</title>
          <p>All pictures contained the same 25 seeds and were taken at the same focal distance and all other camera parameters were the constant. Pictures used for this test can be found in <xref ref-type="supplementary-material" rid="pone.0160439.s005">S4 Fig</xref>.</p>
        </caption>
        <alternatives>
          <graphic id="pone.0160439.t002g" xlink:href="pone.0160439.t002"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" colspan="2" rowspan="2">Parameters</th>
                <th align="center" colspan="3" rowspan="1">Camera location (inches from background)</th>
              </tr>
              <tr>
                <th align="center" rowspan="1" colspan="1">7 (L1)</th>
                <th align="center" rowspan="1" colspan="1">15 (L2)</th>
                <th align="center" rowspan="1" colspan="1">22 (L3)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" colspan="2" rowspan="1">Segmentation channel</td>
                <td align="center" rowspan="1" colspan="1">Blue</td>
                <td align="center" rowspan="1" colspan="1">Blue</td>
                <td align="center" rowspan="1" colspan="1">Blue</td>
              </tr>
              <tr>
                <td align="center" colspan="2" rowspan="1">Threshold value</td>
                <td align="center" rowspan="1" colspan="1">95</td>
                <td align="center" rowspan="1" colspan="1">100</td>
                <td align="center" rowspan="1" colspan="1">105</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Shape</td>
                <td align="left" rowspan="1" colspan="1">L1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.91</td>
                <td align="center" rowspan="1" colspan="1">0.92</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L2</td>
                <td align="center" rowspan="1" colspan="1">0.91</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L3</td>
                <td align="center" rowspan="1" colspan="1">0.92</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Length</td>
                <td align="left" rowspan="1" colspan="1">L1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.97</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L2</td>
                <td align="center" rowspan="1" colspan="1">0.97</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L3</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Width</td>
                <td align="left" rowspan="1" colspan="1">L1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.60</td>
                <td align="center" rowspan="1" colspan="1">0.73</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L2</td>
                <td align="center" rowspan="1" colspan="1">0.60</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.97</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L3</td>
                <td align="center" rowspan="1" colspan="1">0.73</td>
                <td align="center" rowspan="1" colspan="1">0.97</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Area</td>
                <td align="left" rowspan="1" colspan="1">L1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.75</td>
                <td align="center" rowspan="1" colspan="1">0.85</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L2</td>
                <td align="center" rowspan="1" colspan="1">0.75</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L3</td>
                <td align="center" rowspan="1" colspan="1">0.85</td>
                <td align="center" rowspan="1" colspan="1">0.98</td>
                <td align="center" rowspan="1" colspan="1">1.00</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Perimeter</td>
                <td align="left" rowspan="1" colspan="1">L1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.93</td>
                <td align="center" rowspan="1" colspan="1">0.89</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L2</td>
                <td align="center" rowspan="1" colspan="1">0.93</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.91</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L3</td>
                <td align="center" rowspan="1" colspan="1">0.89</td>
                <td align="center" rowspan="1" colspan="1">0.91</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Surface</td>
                <td align="left" rowspan="1" colspan="1">L1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.85</td>
                <td align="center" rowspan="1" colspan="1">0.91</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L2</td>
                <td align="center" rowspan="1" colspan="1">0.85</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L3</td>
                <td align="center" rowspan="1" colspan="1">0.91</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Volume</td>
                <td align="left" rowspan="1" colspan="1">L1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.63</td>
                <td align="center" rowspan="1" colspan="1">0.76</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L2</td>
                <td align="center" rowspan="1" colspan="1">0.63</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.97</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L3</td>
                <td align="center" rowspan="1" colspan="1">0.76</td>
                <td align="center" rowspan="1" colspan="1">0.97</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Eccentricity</td>
                <td align="left" rowspan="1" colspan="1">L1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.95</td>
                <td align="center" rowspan="1" colspan="1">0.95</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L2</td>
                <td align="center" rowspan="1" colspan="1">0.95</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L3</td>
                <td align="center" rowspan="1" colspan="1">0.95</td>
                <td align="center" rowspan="1" colspan="1">0.99</td>
                <td align="center" rowspan="1" colspan="1">1.00</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Solidity</td>
                <td align="left" rowspan="1" colspan="1">L1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.84</td>
                <td align="center" rowspan="1" colspan="1">0.26</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L2</td>
                <td align="center" rowspan="1" colspan="1">0.84</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.36</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L3</td>
                <td align="center" rowspan="1" colspan="1">0.26</td>
                <td align="center" rowspan="1" colspan="1">0.36</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Gray-scale color</td>
                <td align="left" rowspan="1" colspan="1">L1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">-0.18</td>
                <td align="center" rowspan="1" colspan="1">0.33</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L2</td>
                <td align="center" rowspan="1" colspan="1">-0.18</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.51</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L3</td>
                <td align="center" rowspan="1" colspan="1">0.33</td>
                <td align="center" rowspan="1" colspan="1">0.51</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
              <tr>
                <td align="center" rowspan="3" colspan="1">Color variation</td>
                <td align="left" rowspan="1" colspan="1">L1</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.42</td>
                <td align="center" rowspan="1" colspan="1">0.39</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L2</td>
                <td align="center" rowspan="1" colspan="1">0.42</td>
                <td align="center" rowspan="1" colspan="1">1</td>
                <td align="center" rowspan="1" colspan="1">0.73</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">L3</td>
                <td align="center" rowspan="1" colspan="1">0.39</td>
                <td align="center" rowspan="1" colspan="1">0.73</td>
                <td align="center" rowspan="1" colspan="1">1</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>In conclusion, our test showed that GiNA is robust enough to deal with moderate-to-strong variations in lighting conditions. However, lighting conditions are technically harder to control and maintain constant among several photography sessions. On the other hand, our software produced less consistent data when different camera heights were tested for some of the examined traits. Nevertheless, camera height and other camera settings are simple and easy to control with proper camera setup and equipment use. Given the difficulty controlling lighting conditions, we suggest that the careful standardization of light is a prerequisite for using GiNA in most experiments as is the case when using other similar software for horticultural phenotyping [<xref rid="pone.0160439.ref017" ref-type="bibr">17</xref>, <xref rid="pone.0160439.ref018" ref-type="bibr">18</xref>].</p>
    </sec>
    <sec id="sec007">
      <title>Validation of GiNA with manually-taken measurements</title>
      <p>The validation of GiNA was performed separately for color related measurements and shape-related measurements. For color measurements, total anthocyanin content (TAcy) in cranberry fruits was correlated with the color estimation produced by GiNA from images of the same fruits. Over a 4-week period, 22 samples of cranberry fruits from multiple cultivars were collected from a commercial cranberry farm. The field component of this study was performed at Cranberry Creek Cranberries Inc., Wisconsin USA with permission of Bill Hatch and Nicole Hansen. None of the field studies conducted involved endangered or protected species. Sampling consisted of picking all fruits in one square foot ring at three different locations in the same field. The fruits from the three locations were mixed, and a random selection of 100 fruits were used for taking pictures in four batches of 25 fruits. Then, the fruits were mixed again with the rest of the sample and TAcy was determined according to Vorsa <italic>et al</italic>. [<xref rid="pone.0160439.ref019" ref-type="bibr">19</xref>]. The fruits were harvested during the cranberry ripening period. During this time, fruit color changed from yellow to red, which provided a wide color spectrum for the validation analysis. Since anthocyanins are accumulated primarily in the fruit skin [<xref rid="pone.0160439.ref020" ref-type="bibr">20</xref>], and therefore responsible of fruit coloration in cranberry, high correlation between the two measurements was expected.</p>
      <p>GiNA‚Äôs algorithm is very robust in terms of copping with different picture conditions (e.g., the presence of lights or shadows) when used for measuring shape-oriented parameters. However, color-related parameters can be affected by variations in natural light if pictures are taken on different days. Since cranberry pictures were obtained multiple times over a 4-week period, slightly differences in light were detected even when the camera parameters were not changed. Color validation was made by bootstrapping cross-validation (five-fold), in which 82% of the data points (TAcy measurements and digital color estimates, selected at random, with replace) were used for build a model <italic>Y</italic><sub><italic>ij</italic></sub> ~ <italic>DC</italic><sub><italic>i</italic></sub> + <italic>Date</italic><sub><italic>j</italic></sub>, where <italic>Y</italic><sub><italic>ij</italic></sub> is the TAcy of the <italic>i</italic> sample in the <italic>j</italic> day, <italic>DC</italic><sub><italic>i</italic></sub> is the digital color of the sample <italic>i</italic>, and <italic>Date</italic><sub><italic>j</italic></sub> is the date <italic>j</italic> when the picture was taken. This model helped to account for the variability in light among days. This strategy could also be implemented in further analyses by including the time when the picture was taken (if more than one batch of pictures are produced) as a block term. For the validation, the other 18% of the points was used for comparing the model-predicted TAcy estimates and the real TAcy values. A total of 1000 iterations were conducted and Pearson's correlations were computed for each iteration. The mean correlation across the 1000 iterations was 0.829 (the 95% CI was 0.808 to 0.851).</p>
      <p>Since some of the shape-related parameters are highly correlated (mean correlation among shape-related parameters = 0.705, see <xref ref-type="supplementary-material" rid="pone.0160439.s001">S1 Dataset</xref>) and some of the traits (such as volume of projected area) are not easily measurable using manual methods, validation of shape parameters was made using only length and width. Measurements for length (cm) and width (cm) of 75 cranberry fruits were manually recorded using a caliper, and pictures of these fruits were taken in batches of 25 fruits. Similar to our color validation, bootstrapping cross-validation (five-fold, 1000 iterations, 82% of the data points for model construction) was computed separately for both length and width, and mean correlations as well as confidence intervals were determined. For width, mean correlation was 0.924 (the 95% CI was 0.921 to 0.927), and for length, the mean correlation was 0.970 (95% CI was 0.969 to 0.972). Since the GiNA recognition algorithm assumes length to be the axis with the maximum length, and width to be the axis with the minimum length, length and width will be flipped in highly circular objects where the width is longer than the length. A complete dataset with all the measurements generated by GiNA as well as the manually generated data for the described analysis is available in <xref ref-type="supplementary-material" rid="pone.0160439.s001">S1 Dataset</xref>.</p>
    </sec>
    <sec id="sec008">
      <title>Noteworthy aspects of GiNA for massive phenotyping</title>
      <p>The GiNA image analysis framework is highly accessible and freely available to scientists and groups working in major and minor crop research programs (<xref ref-type="fig" rid="pone.0160439.g002">Fig 2</xref>). The application and use of this software is simple, but very helpful in terms of the massive amount of high-quality measurements that can be generated. For small fruits such as grapes, cranberries, or cherries (<xref ref-type="fig" rid="pone.0160439.g002">Fig 2</xref>), a picture of 40 fruits can be taken every minute (or less). Therefore, in an hour, at least 20 different parameters for 2400 fruits can be accurately measured from 60 images. The same amount of work would represent at least 20 man-hours to collect using traditional manual measurements. As discussed before, although many image-based phenotyping technologies are available, they are not easy-to-use and optimize, and they are not economically accessible for scientists that commonly face limitations related with massive phenotyping activities.</p>
      <fig id="pone.0160439.g002" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0160439.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Examples of object recognition using GiNA in potato and cherry pictures.</title>
          <p>The labels in each fruit indicate preliminary parameters such as area, perimeter and gray-scale color. The lines indicate perimeter (green), length (magenta) and width (blue).</p>
        </caption>
        <graphic xlink:href="pone.0160439.g002"/>
      </fig>
      <p>In crop breeding programs, massive phenotyping is key for the efficient evaluation and selection of new cultivars and varieties. In these cases, multiple populations with numerous individuals are constantly evaluated phenotypically requiring a considerable investment in time and money. The need for new approaches to acquire high-dimensional phenotypic data on an organism-wide scale will continue to increase in coming years. Although abundant genomic information is available for many plant species, as Houle <italic>et al</italic>. [<xref rid="pone.0160439.ref001" ref-type="bibr">1</xref>] commented, the characteristics of organisms of greatest interest to most biologists are phenotypes rather than genotypes. In this sense, GiNA represents an accessible and very useful tool for image-based phenomics that can lead to an accelerated progress in crop improvement and a more efficient characterization of traits of interest for both science and industry.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material" id="sec009">
    <title>Supporting Information</title>
    <supplementary-material content-type="local-data" id="pone.0160439.s001">
      <label>S1 Dataset</label>
      <caption>
        <title>Comparison between manual-taken measurements and GiNA estimates (75 cranberry fruits in three pictures).</title>
        <p>(XLSX)</p>
      </caption>
      <media xlink:href="pone.0160439.s001.xlsx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pone.0160439.s002">
      <label>S1 Fig</label>
      <caption>
        <title>Image capture device. In the figure different angles of the imaging devices is shown to highlight the simplicity required to implement this methodoloy.</title>
        <p>The device was a hand-made wooden structure with the camera set at the top of the structure facing down to capture the fruits in the white mat with black reference circles.</p>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pone.0160439.s002.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pone.0160439.s003">
      <label>S2 Fig</label>
      <caption>
        <title>An example of extra images required for neural network training.</title>
        <p>In the upper panels, a representation of two colors present in fruits as well as the color of the background.</p>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pone.0160439.s003.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pone.0160439.s004">
      <label>S3 Fig</label>
      <caption>
        <title>Pictures used for estimating correlation of measurements across different light conditions.</title>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pone.0160439.s004.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pone.0160439.s005">
      <label>S4 Fig</label>
      <caption>
        <title>Pictures used for estimating correlation of measurements in different system set ups.</title>
        <p>(TIF)</p>
      </caption>
      <media xlink:href="pone.0160439.s005.tif">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pone.0160439.s006">
      <label>S1 Table</label>
      <caption>
        <title>Description of the parameters generated by GiNA.</title>
        <p>Mathematical formulation and description of parameters returned by the software.</p>
        <p>(DOCX)</p>
      </caption>
      <media xlink:href="pone.0160439.s006.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>J.Z. and B.S. wish to express their gratitude through Mt 10:32. We wish to thank Bill Hatch, Nicole Hansen, and Leah Hyatt from Cranberry Creek Cranberries Inc. for allowing us to harvest the cranberry samples used to validate GiNA. Also, thank Eric Wiesman, Walter Salazar, Yiwen Ge and Sarah Hodapp for their help in taking pictures and processing fruit samples. This project was supported by USDA-ARS (project no. 3655-21220-001-00 provided to J.Z.); WI-DATCP (SCBG Project #14‚Äì002); National Science Foundation (DBI-1228280); Ocean Spray Cranberries, Inc.; Wisconsin Cranberry Growers Association; Cranberry Institute. B.S. was supported by the Frank B. Koller Cranberry Fellowship for Graduate Students. GCP and LDG were supported by the Consejo Nacional de Ciencia y Tecnolog√≠a (CONACYT, Mexico). We thank to the anonymous reviewers who helped to enhance the quality of this paper.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pone.0160439.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Houle</surname><given-names>D</given-names></name>, <name><surname>Govindaraju</surname><given-names>DR</given-names></name>, <name><surname>Omholt</surname><given-names>S</given-names></name>. <article-title>Phenomics: the next challenge</article-title>. <source>Nat Rev Genet</source>. <year>2010</year>;<volume>11</volume>: <fpage>855</fpage>‚Äì<lpage>66</lpage>. <pub-id pub-id-type="doi">10.1038/nrg2897</pub-id><?supplied-pmid 21085204?><pub-id pub-id-type="pmid">21085204</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>White</surname><given-names>JW</given-names></name>, <name><surname>Andrade-Sanchez</surname><given-names>P</given-names></name>, <name><surname>Gore</surname><given-names>MA</given-names></name>, <name><surname>Bronson</surname><given-names>KF</given-names></name>, <name><surname>Coffelt</surname><given-names>TA</given-names></name>, <name><surname>Conley</surname><given-names>MM</given-names></name>, <etal>et al</etal><article-title>Field-based phenomics for plant genetics research</article-title>. <source>F Crop Res</source>. <year>2012</year>;<volume>133</volume>: <fpage>101</fpage>‚Äì<lpage>112</lpage>. <pub-id pub-id-type="doi">10.1016/j.fcr.2012.04.003</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Busemeyer</surname><given-names>L</given-names></name>, <name><surname>Ruckelshausen</surname><given-names>A</given-names></name>, <name><surname>M√∂ller</surname><given-names>K</given-names></name>, <name><surname>Melchinger</surname><given-names>AE</given-names></name>, <name><surname>Alheit</surname><given-names>KV</given-names></name>, <name><surname>Maurer</surname><given-names>HP</given-names></name>, <etal>et al</etal><article-title>Precision phenotyping of biomass accumulation in triticale reveals temporal genetic patterns of regulation</article-title>. <source>Sci Rep</source>. <year>2013</year>;<volume>3</volume>: <fpage>1</fpage>‚Äì<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1038/srep02442</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Campbell</surname><given-names>MT</given-names></name>, <name><surname>Knecht</surname><given-names>AC</given-names></name>, <name><surname>Berger</surname><given-names>B</given-names></name>, <name><surname>Brien</surname><given-names>CJ</given-names></name>, <name><surname>Wang</surname><given-names>D</given-names></name>, <name><surname>Walia</surname><given-names>H</given-names></name>. <article-title>Integrating Image-Based Phenomics and Association Analysis to Dissect the Genetic Architecture of Temporal Salinity Responses in Rice</article-title>. <source>Plant Physiol</source>. <year>2015</year>;<volume>168</volume>: <fpage>1476</fpage>‚Äì<lpage>1489</lpage>. <pub-id pub-id-type="doi">10.1104/pp.15.00450</pub-id><?supplied-pmid 26111541?><pub-id pub-id-type="pmid">26111541</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>D</given-names></name>, <name><surname>Neumann</surname><given-names>K</given-names></name>, <name><surname>Friedel</surname><given-names>S</given-names></name>, <name><surname>Kilian</surname><given-names>B</given-names></name>, <name><surname>Chen</surname><given-names>M</given-names></name>, <name><surname>Altmann</surname><given-names>T</given-names></name>, <etal>et al</etal><article-title>Dissecting the Phenotypic Components of Crop Plant Growth and Drought Responses Based on High-Throughput Image Analysis</article-title>. <source>Plant Cell</source>. <year>2014</year>;<volume>26</volume>: <fpage>4636</fpage>‚Äì<lpage>4655</lpage>. <pub-id pub-id-type="doi">10.1105/tpc.114.129601</pub-id><?supplied-pmid 25501589?><pub-id pub-id-type="pmid">25501589</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Chern</surname><given-names>CG</given-names></name>, <name><surname>Fan</surname><given-names>MJ</given-names></name>, <name><surname>Huang</surname><given-names>SC</given-names></name>, <name><surname>Yu</surname><given-names>SM</given-names></name>, <name><surname>Wei</surname><given-names>FJ</given-names></name>, <name><surname>Wu</surname><given-names>CC</given-names></name>, <etal>et al</etal><article-title>Methods for rice phenomics studies</article-title>. <source>Methods Mol Biol</source>. <year>2011</year>;<volume>678</volume>: <fpage>129</fpage>‚Äì<lpage>138</lpage>. <pub-id pub-id-type="doi">10.1007/978-1-60761-682-5_10</pub-id><?supplied-pmid 20931377?><pub-id pub-id-type="pmid">20931377</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>L</given-names></name>, <name><surname>Zhang</surname><given-names>Q</given-names></name>, <name><surname>Huang</surname><given-names>D</given-names></name>. <article-title>A Review of Imaging Techniques for Plant Phenotyping</article-title>. <source>Sensors</source>. <year>2014</year>;<volume>14</volume>: <fpage>20078</fpage>‚Äì<lpage>20111</lpage>. <pub-id pub-id-type="doi">10.3390/s141120078</pub-id><?supplied-pmid 25347588?><pub-id pub-id-type="pmid">25347588</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Berge</surname><given-names>TW</given-names></name>, <name><surname>Goldberg</surname><given-names>S</given-names></name>, <name><surname>Kaspersen</surname><given-names>K</given-names></name>, <name><surname>Netland</surname><given-names>J</given-names></name>. <article-title>Towards machine vision based site-specific weed management in cereals</article-title>. <source>Comput Electron Agric</source>. <year>2012</year>;<volume>81</volume>: <fpage>79</fpage>‚Äì<lpage>86</lpage>. <pub-id pub-id-type="doi">10.1016/j.compag.2011.11.004</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Aggelopoulou</surname><given-names>AD</given-names></name>, <name><surname>Bochtis</surname><given-names>D</given-names></name>, <name><surname>Fountas</surname><given-names>S</given-names></name>, <name><surname>Swain</surname><given-names>KC</given-names></name>, <name><surname>Gemtos</surname><given-names>TA</given-names></name>, <name><surname>Nanos</surname><given-names>GD</given-names></name>. <article-title>Yield prediction in apple orchards based on image processing</article-title>. <source>Precis Agric</source>. <year>2011</year>;<volume>12</volume>: <fpage>448</fpage>‚Äì<lpage>456</lpage>. <pub-id pub-id-type="doi">10.1007/s11119-010-9187-0</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Omasa</surname><given-names>K</given-names></name>, <name><surname>Hosoi</surname><given-names>F</given-names></name>, <name><surname>Konishi</surname><given-names>A</given-names></name>. <article-title>3D lidar imaging for detecting and understanding plant responses and canopy structure</article-title>. <source>J Exp Bot</source>. <year>2007</year>;<volume>58</volume>: <fpage>881</fpage>‚Äì<lpage>898</lpage>. <pub-id pub-id-type="doi">10.1093/jxb/erl142</pub-id><?supplied-pmid 17030540?><pub-id pub-id-type="pmid">17030540</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>ElMasry</surname><given-names>G</given-names></name>, <name><surname>Wang</surname><given-names>N</given-names></name>, <name><surname>ElSayed</surname><given-names>A</given-names></name>, <name><surname>Ngadi</surname><given-names>M</given-names></name>. <article-title>Hyperspectral imaging for nondestructive determination of some quality attributes for strawberry</article-title>. <source>J Food Eng</source>. <year>2007</year>;<volume>81</volume>: <fpage>98</fpage>‚Äì<lpage>107</lpage>. <pub-id pub-id-type="doi">10.1016/j.jfoodeng.2006.10.016</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Kleynen</surname><given-names>O</given-names></name>, <name><surname>Leemans</surname><given-names>V</given-names></name>, <name><surname>Destain</surname><given-names>MF</given-names></name>. <article-title>Development of a multi-spectral vision system for the detection of defects on apples</article-title>. <source>J Food Eng</source>. <year>2005</year>;<volume>69</volume>: <fpage>41</fpage>‚Äì<lpage>49</lpage>. <pub-id pub-id-type="doi">10.1016/j.jfoodeng.2004.07.008</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Walter</surname><given-names>A</given-names></name>, <name><surname>Liebisch</surname><given-names>F</given-names></name>, <name><surname>Hund</surname><given-names>A</given-names></name>. <article-title>Plant phenotyping: from bean weighing to image analysis</article-title>. <source>Plant Methods</source>. <year>2015</year>;<volume>11</volume>: <fpage>14</fpage><pub-id pub-id-type="doi">10.1186/s13007-015-0056-8</pub-id><?supplied-pmid 25767559?><pub-id pub-id-type="pmid">25767559</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Bac-Molenaar</surname><given-names>JA</given-names></name>, <name><surname>Vreugdenhil</surname><given-names>D</given-names></name>, <name><surname>Granier</surname><given-names>C</given-names></name>, <name><surname>Keurentjes</surname><given-names>JJB</given-names></name>. <article-title>Genome-wide association mapping of growth dynamics detects time-specific and general quantitative trait loci</article-title>. <source>J Exp Bot</source>. <year>2015</year>;<volume>66</volume>: <fpage>5567</fpage>‚Äì<lpage>5580</lpage>. <pub-id pub-id-type="doi">10.1093/jxb/erv176</pub-id><?supplied-pmid 25922493?><pub-id pub-id-type="pmid">25922493</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Rakun</surname><given-names>J</given-names></name>, <name><surname>Stajnko</surname><given-names>D</given-names></name>, <name><surname>Zazula</surname><given-names>D</given-names></name>. <article-title>Detecting fruits in natural scenes by using spatial-frequency based texture analysis and multiview geometry</article-title>. <source>Comput Electron Agric. Elsevier B.V.</source>; <year>2011</year>;<volume>76</volume>: <fpage>80</fpage>‚Äì<lpage>88</lpage>. <pub-id pub-id-type="doi">10.1016/j.compag.2011.01.007</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>L√≥pez-Garc√≠a</surname><given-names>F</given-names></name>, <name><surname>Andreu-Garc√≠a</surname><given-names>G</given-names></name>, <name><surname>Blasco</surname><given-names>J</given-names></name>, <name><surname>Aleixos</surname><given-names>N</given-names></name>, <name><surname>Valiente</surname><given-names>J-M</given-names></name>. <article-title>Automatic detection of skin defects in citrus fruits using a multivariate image analysis approach</article-title>. <source>Comput Electron Agric</source>. <year>2010</year>;<volume>71</volume>: <fpage>189</fpage>‚Äì<lpage>197</lpage>. <pub-id pub-id-type="doi">10.1016/j.compag.2010.02.001</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Taghadomi-Saberi</surname><given-names>S</given-names></name>, <name><surname>Omid</surname><given-names>M</given-names></name>, <name><surname>Faraji-Mahyari</surname><given-names>Z</given-names></name>, <name><surname>Emam-Djomeh</surname><given-names>K</given-names></name>. <article-title>Determination of Cherry Color Parameters during Ripening by Artificial Neural Network Assisted Image Processing Technique</article-title>. <source>J Agric Sci Technol</source>. <year>2015</year>;<volume>17</volume>: <fpage>589</fpage>‚Äì<lpage>600</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0160439.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Gonzalo</surname><given-names>MJ</given-names></name>, <name><surname>van der Knaap</surname><given-names>E</given-names></name>. <article-title>A comparative analysis into the genetic bases of morphology in tomato varieties exhibiting elongated fruit shape</article-title>. <source>Theor Appl Genet</source>. <year>2008</year>;<volume>116</volume>: <fpage>647</fpage>‚Äì<lpage>656</lpage>. <pub-id pub-id-type="doi">10.1007/s00122-007-0698-7</pub-id><?supplied-pmid 18185917?><pub-id pub-id-type="pmid">18185917</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0160439.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Vorsa</surname><given-names>N</given-names></name>, <name><surname>Polashock</surname><given-names>J</given-names></name>, <name><surname>Cunningham</surname><given-names>DG</given-names></name>, <name><surname>Roderick</surname><given-names>R</given-names></name>. <article-title>Genetic inferences and breeding implications from analysis of cranberry germplasm anthocyanin profiles</article-title>. <source>J Am Soc Hortic Sci</source>. <year>2003</year>;<volume>128</volume>: <fpage>691</fpage>‚Äì<lpage>697</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0160439.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Zhou</surname><given-names>Y</given-names></name>, <name><surname>Singh</surname><given-names>BR</given-names></name>. <article-title>Red light stimulates flowering and anthocyanin biosynthesis in American cranberry</article-title>. <source>Plant Growth Regul</source>. <year>2002</year>;<volume>38</volume>: <fpage>165</fpage>‚Äì<lpage>171</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
