<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName archivearticle.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Genet</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Genet</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Genet.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Genetics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1664-8021</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9091563</article-id>
    <article-id pub-id-type="publisher-id">884589</article-id>
    <article-id pub-id-type="doi">10.3389/fgene.2022.884589</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Genetics</subject>
        <subj-group>
          <subject>Methods</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>i2APP: A Two-Step Machine Learning Framework For Antiparasitic Peptides Identification</article-title>
      <alt-title alt-title-type="left-running-head">Jiang et al.</alt-title>
      <alt-title alt-title-type="right-running-head">Antiparasitic Peptides Identification</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Jiang</surname>
          <given-names>Minchao</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="fn1" ref-type="author-notes">
          <sup>†</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1712836/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhang</surname>
          <given-names>Renfeng</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="fn1" ref-type="author-notes">
          <sup>†</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/835131/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xia</surname>
          <given-names>Yixiao</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1717874/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jia</surname>
          <given-names>Gangyong</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1769945/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yin</surname>
          <given-names>Yuyu</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1769865/overview"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Wang</surname>
          <given-names>Pu</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">*</xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1016227/overview"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Wu</surname>
          <given-names>Jian</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">*</xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1489948/overview"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Ge</surname>
          <given-names>Ruiquan</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">*</xref>
        <uri xlink:href="https://loop.frontiersin.org/people/867328/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>School of Computer Science and Technology</institution>, <institution>Hangzhou Dianzi University</institution>, <addr-line>Hangzhou</addr-line>, <country>China</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Shandong Provincial Hospital Affiliated to Shandong First Medical University</institution>, <addr-line>Jinan</addr-line>, <country>China</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Computer School</institution>, <institution>Hubei University of Arts and Science</institution>, <addr-line>Xiangyang</addr-line>, <country>China</country></aff>
    <aff id="aff4"><sup>4</sup><institution>MyGenostics Inc.</institution>, <addr-line>Beijing</addr-line>, <country>China</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p><bold>Edited by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/89738/overview" ext-link-type="uri">Alfredo Pulvirenti</ext-link>, University of Catania, Italy</p>
      </fn>
      <fn fn-type="edited-by">
        <p><bold>Reviewed by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/1064518/overview" ext-link-type="uri">Leyi Wei</ext-link>, Shandong University, China</p>
        <p><ext-link xlink:href="https://loop.frontiersin.org/people/1443291/overview" ext-link-type="uri">Piyush Agrawal</ext-link>, National Cancer Institute (NIH), United States</p>
      </fn>
      <corresp id="c001">*Correspondence: Pu Wang, <email>nywangpu@yeah.net</email>; Jian Wu, <email>jw2231@mygeno.cn</email>; Ruiquan Ge, <email>gespring@hdu.edu.cn</email>
</corresp>
      <fn fn-type="equal" id="fn1">
        <label>
          <sup>†</sup>
        </label>
        <p>These authors have Co-first authors</p>
      </fn>
      <fn fn-type="other">
        <p>This article was submitted to Computational Genomics, a section of the journal Frontiers in Genetics</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>27</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>13</volume>
    <elocation-id>884589</elocation-id>
    <history>
      <date date-type="received">
        <day>26</day>
        <month>2</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>11</day>
        <month>4</month>
        <year>2022</year>
      </date>
      <date date-type="publishedonline">
        <day>11</day>
        <month>4</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2022 Jiang, Zhang, Xia, Jia, Yin, Wang, Wu and Ge.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <copyright-holder>Jiang, Zhang, Xia, Jia, Yin, Wang, Wu and Ge</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Parasites can cause enormous damage to their hosts. Studies have shown that antiparasitic peptides can inhibit the growth and development of parasites and even kill them. Because traditional biological methods to determine the activity of antiparasitic peptides are time-consuming and costly, a method for large-scale prediction of antiparasitic peptides is urgently needed. We propose a computational approach called i2APP that can efficiently identify APPs using a two-step machine learning (ML) framework. First, in order to solve the imbalance of positive and negative samples in the training set, a random under sampling method is used to generate a balanced training data set. Then, the physical and chemical features and terminus-based features are extracted, and the first classification is performed by Light Gradient Boosting Machine (LGBM) and Support Vector Machine (SVM) to obtain 264-dimensional higher level features. These features are selected by Maximal Information Coefficient (MIC) and the features with the big MIC values are retained. Finally, the SVM algorithm is used for the second classification in the optimized feature space. Thus the prediction model i2APP is fully constructed. On independent datasets, the accuracy and AUC of i2APP are 0.913 and 0.935, respectively, which are better than the state-of-arts methods. The key idea of the proposed method is that multi-level features are extracted from peptide sequences and the higher-level features can distinguish well the APPs and non-APPs.</p>
    </abstract>
    <kwd-group>
      <kwd>antiparasitic peptides</kwd>
      <kwd>feature representation</kwd>
      <kwd>maximum information coefficient</kwd>
      <kwd>feature selection</kwd>
      <kwd>T-distributed stochastic neighbor embedding</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>Introduction</title>
    <p>Parasites are a very common source of disease. Parasitic diseases can affect almost all living things, including plants and mammals. The effects of parasitic diseases can range from mild discomfort to death (<xref rid="B23" ref-type="bibr">Momčilović et al., 2019</xref>). It is estimated that one billion people worldwide are infected with ascariasis, although it is usually harmless. Necator americanus and Ancylostoma duodenale can cause hookworm infections in humans, resulting in anemia, malnutrition, shortness of breath and weakness. This infection affects about 740 million people in the developing countries, including children and adults (<xref rid="B6" ref-type="bibr">Diemert et al., 2018</xref>). Malaria is very harmful to humans. It causes 300 to 500 million illnesses and about 2 million deaths each year, with about half of those deaths occurring in children under the age of 5 (<xref rid="B1" ref-type="bibr">Barber et al., 2017</xref>). The main method of treating parasitic diseases today is the use of antibiotics (<xref rid="B36" ref-type="bibr">Zahedifard and Rafati, 2018</xref>). However, frequent use of antibiotics can increase parasite resistance and even have some undetected side effects (<xref rid="B7" ref-type="bibr">Ertabaklar et al., 2020</xref>). Studies have found that anti-parasite peptide (APP) can effectively inhibit the growth of parasites and even kill them (<xref rid="B13" ref-type="bibr">Lacerda et al., 2016</xref>). Anti-parasite peptides are usually composed of 5–50 amino acids and are relatively short in length. They are usually changed by antimicrobial peptides (AMPs) (<xref rid="B22" ref-type="bibr">Mehta et al., 2014</xref>). APPs can kill parasites by destroying the cell membrane of the parasite or inhibiting the reductase in the parasite (<xref rid="B2" ref-type="bibr">Bell, 2011</xref>; <xref rid="B29" ref-type="bibr">Torrent et al., 2012</xref>). Therefore, it is very important to be able to identify APPs.</p>
    <p>In the past few years, many methods for predicting functional peptides based on machine learning have been proposed, such as AAPred-CNN (<xref rid="B15" ref-type="bibr">Lin et al., 2022</xref>) for anti-angiogenic peptides, mAHTPred (<xref rid="B20" ref-type="bibr">Manavalan et al., 2019</xref>) for anti-hypertensive peptides, AVPIden (<xref rid="B24" ref-type="bibr">Pang et al., 2021</xref>) for anti-viral peptides. PredictFP2 can predict fusion peptide domains in all retroviruses (<xref rid="B34" ref-type="bibr">Wu et al., 2019</xref>). AMPfun (<xref rid="B3" ref-type="bibr">Chung et al., 2020</xref>) and PredAPP (<xref rid="B37" ref-type="bibr">Zhang et al., 2021</xref>) are proposed for antiparasitic peptides identifiction. Based on random forests, the AMPfun tool can be used to identify anticancer peptides, APP, and antiviral peptides. AMPfun can be used to characterize and identify antimicrobial peptides with different functional activities, but the prediction results for APPs are not very good. In 2021, (<xref rid="B37" ref-type="bibr">Zhang et al., 2021</xref>) proposed PredAPP, a model for predicting antiparasitic peptides using an under sampling and ensemble approach. A variety of data under sampling methods are proposed for data balance. This model adopts an ensemble approach, combining 9 feature groups and 6 machine learning algorithms, and finally achieves good results, but there is still room for improvement.</p>
    <p>In this work, we propose a new model named i2APP for identifying APPs, which uses a two-stage machine learning framework. In the first stage, we extract dozens of feature groups for each peptide sequence, and then build the first-layer classifiers with these feature groups. The outputs of the first-layer classifiers are used as the higher-level features. What’s more, MIC (<xref rid="B12" ref-type="bibr">Kinney and Atwal, 2014</xref>; <xref rid="B9" ref-type="bibr">Ge et al., 2016</xref>) is used here to filter out the insignificant features. In the second stage, with the higher-level features, we build the second-layer classifier, whose outputs are the final results of identifying APPs. Through independent test, we will find that the proposed model is better than the state-of-arts methods in most metrics. The tool i2APP is available at <ext-link xlink:href="https://github.com/greyspring/i2APP" ext-link-type="uri">https://github.com/greyspring/i2APP</ext-link>.</p>
  </sec>
  <sec sec-type="materials|methods" id="s2">
    <title>Materials and Methods</title>
    <sec id="s2-1">
      <title>Datasets</title>
      <p>A benchmark dataset is the premise for an effective and reliable model. To train our model and compare it with others, the dataset studied by (<xref rid="B37" ref-type="bibr">Zhang et al., 2021</xref>) were used in this work, in which 301 APPs were used as positive samples and 1909 non-APPs were negative ones. For the positive samples, 301 APPs were taken out as positive training samples, and the remaining 46 APPs were used as positive testing samples. 46 non-APPs were randomly selected from the negative samples as negative testing samples, and the remaining 1863 non-APPs were used as negative training samples. In this way, 255 APPs and 1863 non-APPs constituted the original training set, and 46 APPs and 46 non-APPs constituted the testing set. Since the samples in the training set are very unbalanced, we use random under sampling (<xref rid="B28" ref-type="bibr">Tahir et al., 2012</xref>; <xref rid="B27" ref-type="bibr">Stilianoudakis et al., 2021</xref>) on the training set and get 255 APPs and 255 non-APPs to constitute the final training set. For the sake of simplicity, the final training dataset is marked as T255p + 255n, and the testing dataset is marked as V46p + 46n.</p>
      <p>We take out the 5 amino acids at the N-terminus and C-terminus of each peptide sequence to compare the differences between positive and negative samples by Two Sample Logo application (<xref rid="B26" ref-type="bibr">Schneider and Stephens, 1990</xref>; <xref rid="B4" ref-type="bibr">Crooks et al., 2004</xref>), which calculates and visualizes the differences between two sets of aligned samples of amino acids or nucleotides. At each position in the aligned groups of sequences, statistically significant amino acid symbols are plotted using the size of the symbol that is proportional to the difference between the two samples. It can be seen from the comparison in <xref rid="F1" ref-type="fig">Figure 1</xref> that the amino acid composition at both ends of the APPs and non-APPs sequences have some differences, so it can be considered to extract features from both ends of peptide sequence to distinguish the two types of samples.</p>
      <fig position="float" id="F1">
        <label>FIGURE 1</label>
        <caption>
          <p>Different distribution between APP and non-APP sequences. <bold>(A)</bold> V46p+46n <bold>(B)</bold> T255p+1863n.</p>
        </caption>
        <graphic xlink:href="fgene-13-884589-g001" position="float"/>
      </fig>
    </sec>
    <sec id="s2-2">
      <title>Features Representation</title>
      <p>Good features are beneficial to the training of machine learning models and obtain good prediction performance. The classification of peptides mainly depends on the feature set constructed by the structural and functional properties. Extracting features from peptide sequences that effectively reflect their sequence pattern information is a challenging problem. In this study, we extract 18 kinds of physicochemical features from the peptide sequences, some of which contain very important information, such as functional domains, gene ontology and sequential evolution, etc (<xref rid="B16" ref-type="bibr">Liu et al., 2015</xref>; <xref rid="B17" ref-type="bibr">Liu et al., 2017</xref>). Thus 18 groups of sequence-based features will be obtained for each peptide sequence.</p>
      <p>In addition, the N-terminus and C-terminus of a protein or peptide often have very important biological function, so we also extract features from the both ends of peptide sequence. In this study, we take out a fragment with three or five amino acids at the N-terminus or C-terminus of a peptide sequence, and use 12 types of feature extraction method for this fragment (<xref rid="B11" ref-type="bibr">Jing et al., 2019</xref>). In such a way, 48 groups of terminus-based features will be obtained for each peptide sequence.</p>
      <p>All these feature extraction methods are listed in <xref rid="T1" ref-type="table">Table 1</xref>.</p>
      <table-wrap position="float" id="T1">
        <label>TABLE 1</label>
        <caption>
          <p>Peptide sequence features.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1"/>
              <th align="center" rowspan="1" colspan="1">Features</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td rowspan="18" align="left" colspan="1">Sequence-based</td>
              <td align="left" rowspan="1" colspan="1">Basic Kmer (kmer)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Distance-based Residue (DR)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Distance Pair (DP)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Auto covariance (feature-AC)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Auto-cross covariance (ACC)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Cross covariance (feature-CC)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Physicochemical distance transformation (PDT)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Parallel correlation pseudo amino acid composition (PC-PseAAC)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Series correlation pseudo amino acid composition (SC-PseAAC)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">General parallel correlation pseudo amino acid composition (PC-PseAAC-General)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">General series correlation pseudo amino acid composition (SC-PseAAC-General)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Select and combine the nmost frequenct aminoacids according to their frequencies (Top-n-gram)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Profile-based Physicochemical distance transformation (PDT-Profile)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Distance-based Top-n-gram (DT)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Profile-based Auto covariance (AC-PSSM)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Profile-based Cross covariance (CC-PSSM)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Profile-based Distance-based Top-n-gram (PSSM-DT)</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Profile-based Auto-cross covariance (ACC-PSSM)</td>
            </tr>
            <tr>
              <td rowspan="12" align="left" colspan="1">Terminus-based</td>
              <td align="left" rowspan="1" colspan="1">One_hot</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">One_hot_6_bit</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Binary_5_bit</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Hydrophobicity_matrix</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Meiler_parameters</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Acthely_factors</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">PAM250</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">BLOSUM62</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Miyazawa_energies</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Micheletti_potentials</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AESNN3</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">ANN4D</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="s2-3">
      <title>Computational Models</title>
      <p>As shown in <xref rid="F2" ref-type="fig">Figure 2</xref>, the overall framework of i2APP includes four main steps. As a first step, the benchmark datasets are collected from various databases and literates, and then divided into training dataset and testing dataset. To get a balanced training dataset, the random under sampling procedure is performed on the negative training samples. In the second step, we adopt 18 types of feature extraction methods on the whole peptide sequence to get 18 groups of sequence-based features, and 12 types of feature extraction methods on the N-terminus and C-terminus of peptide sequence. Considering that all peptide sequences are at least 5 residues in length, we take 3 and 5 residues at both ends of the sequence. So, a total of 48 groups of terminal-based features are extracted. For each feature group, SVM and LGBM are trained respectively, and 132 probability outputs are got for each peptide sequence. These probabilities can be seemed as higher-level features for further classification. What’s more, the probability greater than 0.5 is recorded as 1, and the probability less than 0.5 is recorded as 0. These binarized values help remove noise from the model. Stacking the probabilities and their binarized values, a total of 264 higher-level features are obtained. However, these higher-level features may have information redundancy, so a feature selection method is needed here to filter out the superfluous ones. In this study, the maximum information coefficient (MIC) is calculated for each feature, and the threshold is set to 0.4, that is, only the feature with the MIC value greater than 0.4 is retained. The third step is to use ten-fold cross-validation to select the best classifier based on the reduced higher-level feature set. The candidate include the popular classifiers, such as SVM, Bayes (<xref rid="B10" ref-type="bibr">Jahromi and Taheri, 2017</xref>), Decision Tree (DT) (<xref rid="B33" ref-type="bibr">Wang et al., 2019</xref>), K-Nearest Neighbor (KNN) (<xref rid="B32" ref-type="bibr">Wang et al., 2017</xref>), Random Forest (RF), Adaboost (Ada) and so on. In the fourth step, we test the effect of the proposed model on an independent test dataset, and compare its performance with other models. In this work, we used the scikit-learn package (<xref rid="B25" ref-type="bibr">Pedregosa et al., 2011</xref>) to implement all classifiers.</p>
      <fig position="float" id="F2">
        <label>FIGURE 2</label>
        <caption>
          <p>The whole model consists of four parts. The first part is the collection, division and down sampling of the dataset. The second part is feature extraction and feature selection for each peptide sequence. The third part is to analyze the effect of different classifiers through 10-fold cross-validation. In the fourth part, the proposed model is evaluated through independent test.</p>
        </caption>
        <graphic xlink:href="fgene-13-884589-g002" position="float"/>
      </fig>
    </sec>
    <sec id="s2-4">
      <title>Evaluation</title>
      <p>In order to evaluate the results of the final classification and facilitate comparison with other models, we used five commonly used indicators in bioinformatics research (<xref rid="B19" ref-type="bibr">Luo et al., 2019</xref>; <xref rid="B35" ref-type="bibr">Yang et al., 2021</xref>), including specificity (SP), sensitivity (SN), F1 score (F1), Matthew correlation coefficient (MCC) and accuracy (ACC). The specific calculation formula of these measured values is as follows:<disp-formula id="equ1"><mml:math id="m1" overflow="scroll"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
<disp-formula id="equ2"><mml:math id="m2" overflow="scroll"><mml:mrow><mml:mi>S</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
<disp-formula id="equ3"><mml:math id="m3" overflow="scroll"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
<disp-formula id="equ4"><mml:math id="m4" overflow="scroll"><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
<disp-formula id="equ5"><mml:math id="m5" overflow="scroll"><mml:mrow><mml:mi>M</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>⋅</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>⋅</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>Where TP means the number of APPs correctly predicted by the model; TN means the number of non-APPs that the model correctly predicts; FP means the number of non-APPs that the model mispredicts; FN means the number of APPs that the model mispredicts. In addition, we also use other metrics to evaluate the performance of i2APP, including receiver operating characteristic (ROC) curve (<xref rid="B8" ref-type="bibr">Fawcett, 2006</xref>), the area under the ROC curve (AUC) (<xref rid="B18" ref-type="bibr">Lobo et al., 2008</xref>), precision-recall (PR) curve (<xref rid="B5" ref-type="bibr">Davis and Goadrich, 2006</xref>), and the area under the PR curve (AUPR).</p>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <title>Results</title>
    <sec id="s3-1">
      <title>Effects of Different Classifiers</title>
      <p>First, we fix the classifier of the second layer as SVM because it is very effective in small sample learning, and then compare the different classification models in the first layer. Through cross-validation experiments, it is found that the effects of SVM and LGBM are better, so we use these two classification models in the first layer. Now we can compare different classifiers in the second layer. As can be seen from <xref rid="T2" ref-type="table">Table 2</xref>, different classifiers are tested on the training dataset T255p + 255n through ten-fold cross-validation, and the final result is the average of ten evaluations. After parameter tuning, SVM is higher than other classifiers in most metrics, and reaches 90.0%, 0.952, 93.2%, 86.9%, 0.803, and 0.900% in ACC, AUC, SN, SP, MCC, and F1, respectively. Among all classifiers, ACC, AUC, SN, MCC, and F1 obtained by SVM achieved the first position. So we also focused on using SVM as a classifier for the independent test set.</p>
      <table-wrap position="float" id="T2">
        <label>TABLE 2</label>
        <caption>
          <p>The results of cross-validation on the training set with different classifiers.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1"/>
              <th align="center" rowspan="1" colspan="1">Model</th>
              <th align="center" rowspan="1" colspan="1">ACC (%)</th>
              <th align="center" rowspan="1" colspan="1">SN (%)</th>
              <th align="center" rowspan="1" colspan="1">SP (%)</th>
              <th align="center" rowspan="1" colspan="1">AUC</th>
              <th align="center" rowspan="1" colspan="1">MCC</th>
              <th align="center" rowspan="1" colspan="1">F1</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td rowspan="6" align="left" colspan="1">Training Set</td>
              <td align="left" rowspan="1" colspan="1">SVM</td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>90.0</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>93.2</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">86.9</td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.952</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.803</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.900</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Bayes</td>
              <td align="char" char="." rowspan="1" colspan="1">86.5</td>
              <td align="char" char="." rowspan="1" colspan="1">83.2</td>
              <td align="char" char="." rowspan="1" colspan="1">87.9</td>
              <td align="char" char="." rowspan="1" colspan="1">0.865</td>
              <td align="char" char="." rowspan="1" colspan="1">0.729</td>
              <td align="char" char="." rowspan="1" colspan="1">0.838</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Knn</td>
              <td align="char" char="." rowspan="1" colspan="1">86.3</td>
              <td align="char" char="." rowspan="1" colspan="1">93.0</td>
              <td align="char" char="." rowspan="1" colspan="1">80.5</td>
              <td align="char" char="." rowspan="1" colspan="1">0.893</td>
              <td align="char" char="." rowspan="1" colspan="1">0.736</td>
              <td align="char" char="." rowspan="1" colspan="1">0.867</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DT</td>
              <td align="char" char="." rowspan="1" colspan="1">82.7</td>
              <td align="char" char="." rowspan="1" colspan="1">82.0</td>
              <td align="char" char="." rowspan="1" colspan="1">84.5</td>
              <td align="char" char="." rowspan="1" colspan="1">0.833</td>
              <td align="char" char="." rowspan="1" colspan="1">0.660</td>
              <td align="char" char="." rowspan="1" colspan="1">0.824</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">RF</td>
              <td align="char" char="." rowspan="1" colspan="1">87.5</td>
              <td align="char" char="." rowspan="1" colspan="1">91.9</td>
              <td align="char" char="." rowspan="1" colspan="1">83.7</td>
              <td align="char" char="." rowspan="1" colspan="1">0.951</td>
              <td align="char" char="." rowspan="1" colspan="1">0.753</td>
              <td align="char" char="." rowspan="1" colspan="1">0.877</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Ada</td>
              <td align="char" char="." rowspan="1" colspan="1">82.2</td>
              <td align="char" char="." rowspan="1" colspan="1">84.8</td>
              <td align="char" char="." rowspan="1" colspan="1">79.8</td>
              <td align="char" char="." rowspan="1" colspan="1">0.823</td>
              <td align="char" char="." rowspan="1" colspan="1">0.645</td>
              <td align="char" char="." rowspan="1" colspan="1">0.822</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>The bold values indicate the best performance.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>As can be seen from <xref rid="T3" ref-type="table">Table 3</xref>, SVM has a huge advantage over other classifiers on the independent test set V46p + 46n. The values of ACC, AUC, SN, SP, MCC, and F1 are 91.3%, 0.935, 97.8%, 84.8%, 0.833, and 0.918%, respectively. The values of ACC, AUC, SN, MCC, and F1 obtained by SVM all rank first among all classifiers. Especially MCC and AUC by SVM is 0.033 and 0.025 higher than the second-ranked classifier. The comparison of these results shows that SVM is the most suitable classifier in our work.</p>
      <table-wrap position="float" id="T3">
        <label>TABLE 3</label>
        <caption>
          <p>The results of independent test on the testing set with different classifiers.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1"/>
              <th align="center" rowspan="1" colspan="1">Model</th>
              <th align="center" rowspan="1" colspan="1">ACC (%)</th>
              <th align="center" rowspan="1" colspan="1">SN (%)</th>
              <th align="center" rowspan="1" colspan="1">SP (%)</th>
              <th align="center" rowspan="1" colspan="1">AUC</th>
              <th align="center" rowspan="1" colspan="1">MCC</th>
              <th align="center" rowspan="1" colspan="1">F1</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td rowspan="6" align="left" colspan="1">Testing Set</td>
              <td align="left" rowspan="1" colspan="1">SVM</td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>91.3</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>97.8</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">84.8</td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.935</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.833</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.918</bold>
              </td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Bayes</td>
              <td align="char" char="." rowspan="1" colspan="1">85.9</td>
              <td align="char" char="." rowspan="1" colspan="1">84.8</td>
              <td align="char" char="." rowspan="1" colspan="1">87.0</td>
              <td align="char" char="." rowspan="1" colspan="1">0.868</td>
              <td align="char" char="." rowspan="1" colspan="1">0.718</td>
              <td align="char" char="." rowspan="1" colspan="1">0.857</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Knn</td>
              <td align="char" char="." rowspan="1" colspan="1">89.1</td>
              <td align="char" char="." rowspan="1" colspan="1">97.8</td>
              <td align="char" char="." rowspan="1" colspan="1">80.4</td>
              <td align="char" char="." rowspan="1" colspan="1">0.910</td>
              <td align="char" char="." rowspan="1" colspan="1">0.800</td>
              <td align="char" char="." rowspan="1" colspan="1">0.900</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">DT</td>
              <td align="char" char="." rowspan="1" colspan="1">82.6</td>
              <td align="char" char="." rowspan="1" colspan="1">80.4</td>
              <td align="char" char="." rowspan="1" colspan="1">84.8</td>
              <td align="char" char="." rowspan="1" colspan="1">0.826</td>
              <td align="char" char="." rowspan="1" colspan="1">0.653</td>
              <td align="char" char="." rowspan="1" colspan="1">0.822</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">RF</td>
              <td align="char" char="." rowspan="1" colspan="1">88.0</td>
              <td align="char" char="." rowspan="1" colspan="1">93.5</td>
              <td align="char" char="." rowspan="1" colspan="1">82.6</td>
              <td align="char" char="." rowspan="1" colspan="1">0.931</td>
              <td align="char" char="." rowspan="1" colspan="1">0.765</td>
              <td align="char" char="." rowspan="1" colspan="1">0.887</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">Ada</td>
              <td align="char" char="." rowspan="1" colspan="1">88.0</td>
              <td align="char" char="." rowspan="1" colspan="1">91.3</td>
              <td align="char" char="." rowspan="1" colspan="1">84.8</td>
              <td align="char" char="." rowspan="1" colspan="1">0.880</td>
              <td align="char" char="." rowspan="1" colspan="1">0.762</td>
              <td align="char" char="." rowspan="1" colspan="1">0.884</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>The bold values indicate the best performance.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p><xref rid="F3" ref-type="fig">Figure 3</xref> shows the ROC curves and PR curves of different classifiers on the independent test set. The ROC curve of SVM is closest to the upper left corner, surpassing other classifiers. The AUC value of SVM is 0.935, which is the highest and 0.025 higher than the second-ranked classifier KNN. Although the AUPR value of SVM is not the largest, when the recall rate is 1, the precision rate of SVM reaches 0.836, which is the highest.</p>
      <fig position="float" id="F3">
        <label>FIGURE 3</label>
        <caption>
          <p>The performance of different classifiers through cross-validation on the training set.</p>
        </caption>
        <graphic xlink:href="fgene-13-884589-g003" position="float"/>
      </fig>
    </sec>
    <sec id="s3-2">
      <title>Comparison With Other Methods</title>
      <p>Our model is compared with others through ten-fold cross-validation on the training dataset, and the results are shown in <xref rid="T4" ref-type="table">Table 4</xref>. NM-BD and RUS-BD are both proposed in (<xref rid="B37" ref-type="bibr">Zhang et al., 2021</xref>), and the imbalanced training set was down sampled using NearMiss method (<xref rid="B21" ref-type="bibr">Mani and Zhang, 2003</xref>; <xref rid="B14" ref-type="bibr">Li et al., 2021</xref>) for the former, while the random under sampling method was used for the latter, which is also adopted in this study. Compared with RUS-BD, our model outperforms it on all metrics, with improvement of 1.8% on ACC, 0.7% on SN, 3% on SP, 1.8% on SP, 0.013 on F1, and 0.035 on MCC. When compared with NM-BD, our model is also the winner on nearly all metrics except SP. These results show that the performance of our model on the training set is better than the others on the whole.</p>
      <table-wrap position="float" id="T4">
        <label>TABLE 4</label>
        <caption>
          <p>Comparison of our model with the existing methods through cross-validation on the training set.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1">Method</th>
              <th align="center" rowspan="1" colspan="1">ACC (%)</th>
              <th align="center" rowspan="1" colspan="1">SN (%)</th>
              <th align="center" rowspan="1" colspan="1">SP (%)</th>
              <th align="center" rowspan="1" colspan="1">MCC</th>
              <th align="center" rowspan="1" colspan="1">F1</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">NM-BD</td>
              <td align="char" char="." rowspan="1" colspan="1">88.8</td>
              <td align="char" char="." rowspan="1" colspan="1">85.5</td>
              <td align="char" char="." rowspan="1" colspan="1">92.2</td>
              <td align="char" char="." rowspan="1" colspan="1">0.778</td>
              <td align="char" char="." rowspan="1" colspan="1">0.884</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">RUS-BD</td>
              <td align="char" char="." rowspan="1" colspan="1">88.2</td>
              <td align="char" char="." rowspan="1" colspan="1">92.5</td>
              <td align="char" char="." rowspan="1" colspan="1">83.9</td>
              <td align="char" char="." rowspan="1" colspan="1">0.768</td>
              <td align="char" char="." rowspan="1" colspan="1">0.887</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>i2APP</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>90.0</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>93.2</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">86.9</td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.803</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.900</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>The bold values indicate the best performance.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>To further verify the validity of the proposed model, we compare it with other models on an independent test dataset, and the results are shown in <xref rid="T5" ref-type="table">Table 5</xref>, from which we can see that the metrics of i2APP are nearly all better than that of other models. The values of ACC, SN, MCC and F1 are 17.4, 45.6, 0.302 and 0.251% higher than AMPfun, and the values of ACC, MCC, F1, and SP are 178 3.3, 0.107, 0.027, and 6.5% higher than PredAPP. All these results show that the proposed model has better generalization ability than the state-of-the-art models for APP prediction.</p>
      <table-wrap position="float" id="T5">
        <label>TABLE 5</label>
        <caption>
          <p>Comparison of our model with the existing methods through independent test on the testing set.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1">Method</th>
              <th align="center" rowspan="1" colspan="1">ACC (%)</th>
              <th align="center" rowspan="1" colspan="1">SN (%)</th>
              <th align="center" rowspan="1" colspan="1">SP (%)</th>
              <th align="center" rowspan="1" colspan="1">MCC</th>
              <th align="center" rowspan="1" colspan="1">F1</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">AMPfun</td>
              <td align="char" char="." rowspan="1" colspan="1">73.9</td>
              <td align="char" char="." rowspan="1" colspan="1">52.2</td>
              <td align="char" char="." rowspan="1" colspan="1">95.7</td>
              <td align="char" char="." rowspan="1" colspan="1">0.531</td>
              <td align="char" char="." rowspan="1" colspan="1">0.667</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">PredAPP</td>
              <td align="char" char="." rowspan="1" colspan="1">88.0</td>
              <td align="char" char="." rowspan="1" colspan="1">97.8</td>
              <td align="char" char="." rowspan="1" colspan="1">78.3</td>
              <td align="char" char="." rowspan="1" colspan="1">0.776</td>
              <td align="char" char="." rowspan="1" colspan="1">0.891</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">
                <bold>i2APP</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>91.3</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>97.8</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">84.8</td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.833</bold>
              </td>
              <td align="char" char="." rowspan="1" colspan="1">
                <bold>0.918</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>The bold values indicate the best performance.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="s3-3">
      <title>Impact of Dataset Balancing</title>
      <p>We performed 10-fold cross-validation on the original dataset containing 255 APPs and 1863 non-APPs, and the results were listed in <xref rid="T6" ref-type="table">Table 6</xref>. It can be found that compared with the balanced dataset, the SP, MCC and ACC metrics have a greater improvement on the unbalanced dataset. However, because there are too few positive samples, the SE metric decreases a lot. In addition, our model achieves large improvements in various metrics compared to the model PredAPP (IMBD) (<xref rid="B37" ref-type="bibr">Zhang et al., 2021</xref>) using the same unbalanced dataset.</p>
      <table-wrap position="float" id="T6">
        <label>TABLE 6</label>
        <caption>
          <p>The results of ten-fold cross-validation on the balanced or unbalanced datasets.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1">Method</th>
              <th align="center" rowspan="1" colspan="1">ACC (%)</th>
              <th align="center" rowspan="1" colspan="1">SN (%)</th>
              <th align="center" rowspan="1" colspan="1">SP (%)</th>
              <th align="center" rowspan="1" colspan="1">MCC</th>
              <th align="center" rowspan="1" colspan="1">F1</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">PredAPP (unbalanced)</td>
              <td align="char" char="." rowspan="1" colspan="1">91.9</td>
              <td align="char" char="." rowspan="1" colspan="1">52.5</td>
              <td align="char" char="." rowspan="1" colspan="1">97.3</td>
              <td align="char" char="." rowspan="1" colspan="1">0.574</td>
              <td align="char" char="." rowspan="1" colspan="1">0.609</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">i2APP (balanced)</td>
              <td align="char" char="." rowspan="1" colspan="1">90.0</td>
              <td align="char" char="." rowspan="1" colspan="1">93.2</td>
              <td align="char" char="." rowspan="1" colspan="1">86.9</td>
              <td align="char" char="." rowspan="1" colspan="1">0.803</td>
              <td align="char" char="." rowspan="1" colspan="1">0.900</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">i2APP (unbalanced)</td>
              <td align="char" char="." rowspan="1" colspan="1">96.5</td>
              <td align="char" char="." rowspan="1" colspan="1">76.7</td>
              <td align="char" char="." rowspan="1" colspan="1">99.3</td>
              <td align="char" char="." rowspan="1" colspan="1">0.826</td>
              <td align="char" char="." rowspan="1" colspan="1">0.839</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>With the unbalanced dataset as the training set, we tested the proposed model on the independent test set including 46 APPs and 46 non-APPs and listed the results in <xref rid="T7" ref-type="table">Table 7</xref>, from which we can see that whether using balanced or unbalanced training sets, i2APP has good generalization ability.</p>
      <table-wrap position="float" id="T7">
        <label>TABLE 7</label>
        <caption>
          <p>The results of independent test using the balanced or unbalanced datasets as the training set.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead valign="top">
            <tr>
              <th align="left" rowspan="1" colspan="1">Method</th>
              <th align="center" rowspan="1" colspan="1">ACC (%)</th>
              <th align="center" rowspan="1" colspan="1">SN (%)</th>
              <th align="center" rowspan="1" colspan="1">SP (%)</th>
              <th align="center" rowspan="1" colspan="1">MCC</th>
              <th align="center" rowspan="1" colspan="1">F1</th>
            </tr>
          </thead>
          <tbody valign="top">
            <tr>
              <td align="left" rowspan="1" colspan="1">i2APP (balanced)</td>
              <td align="char" char="." rowspan="1" colspan="1">91.3</td>
              <td align="char" char="." rowspan="1" colspan="1">97.8</td>
              <td align="char" char="." rowspan="1" colspan="1">84.8</td>
              <td align="char" char="." rowspan="1" colspan="1">0.833</td>
              <td align="char" char="." rowspan="1" colspan="1">0.918</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">i2APP (unbalanced)</td>
              <td align="char" char="." rowspan="1" colspan="1">93.5</td>
              <td align="char" char="." rowspan="1" colspan="1">100.0</td>
              <td align="char" char="." rowspan="1" colspan="1">87.0</td>
              <td align="char" char="." rowspan="1" colspan="1">0.877</td>
              <td align="char" char="." rowspan="1" colspan="1">0.939</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="s3-4">
      <title>Impact of Shuffled Sequence</title>
      <p>After shuffling the sequence of negative samples in the training set, we randomly sampled 255 new negative samples to form the training set together with 255 positive samples. The results of independent test are shown in <xref rid="F4" ref-type="fig">Figure 4</xref>. It can be seen that the performance of the model decreases after using the shuffled negative samples, probably because the effect of the terminus-based features is reduced after the sequence is shuffled.</p>
      <fig position="float" id="F4">
        <label>FIGURE 4</label>
        <caption>
          <p>The effect of shuffling the sequence.</p>
        </caption>
        <graphic xlink:href="fgene-13-884589-g004" position="float"/>
      </fig>
    </sec>
    <sec id="s3-5">
      <title>Interpretability Analysis</title>
      <p>T-distributed stochastic neighbor embedding (t-SNE) (<xref rid="B30" ref-type="bibr">Van der Maaten and Hinton, 2008</xref>) is a very popular data visualization tool that can reduce high-dimensional data to 2-3 dimensions, so as to draw samples on a plane or 3D space and observe the sample distribution. <xref rid="F5" ref-type="fig">Figure 5</xref> shows the visualization results of the test dataset V46p + 46n after dimensionality reduction on the higher-level features, which are the outputs of the first layer classification. The orange points in the figure are APPs, and the blue points are non-APPs. As can be seen from the figure, the two types of samples can be well distinguished with the higher-level features, so that our model can achieve better performance. What’s more, it can be found that the aggregation degree of APPs is higher than that of non-APPs, indicating that it is easier to identify APPs than non-APPs, so the metric SN in our model will be higher than SP.</p>
      <fig position="float" id="F5">
        <label>FIGURE 5</label>
        <caption>
          <p><italic>t</italic>-SNE visualization results of the testing set after dimensionality reduction of the higher-level features.</p>
        </caption>
        <graphic xlink:href="fgene-13-884589-g005" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="conclusion" id="s4">
    <title>Conclusion</title>
    <p>In this study, we propose a novel model named i2APP to identify APPs efficiently. The main structure of this work consists of four steps. Firstly, the random under sampling method is used to balance the training set. Secondly, a variety of sequence-based and terminus-based features are extracted from any peptide sequence, and then enter these raw features into the first layer classifiers, SVM and LGBM, to get the higher-level features. The maximum information coefficient (MIC) is calculated for each higher-level feature, and only the significant features are retained. Thirdly, based on the optimal feature subset, several popular classifiers are evaluated through cross-validation on the training dataset, and SVM is chosen as the second layer classifier. Finally, independent test is performed on the proposed model and the others, and we can see that i2APP has better generalization ability than the state-of-the-art models for APP prediction. The sequence features used in this paper are all extracted by hand, and some of them are quite complex. Although we simplify the model by two-step learning and feature selection, the overall model still looks complicated. In the future, as the amount of data increases, the RNN or Transformer model can be used for automatic feature learning, which may further improve the accuracy of APP recognition.</p>
  </sec>
</body>
<back>
  <sec sec-type="data-availability" id="s5">
    <title>Data Availability Statement</title>
    <p>Publicly available datasets were analyzed in this study. This data can be found here: <ext-link xlink:href="https://github.com/greyspring/i2APP/tree/master/datasets" ext-link-type="uri">https://github.com/greyspring/i2APP/tree/master/datasets</ext-link>.</p>
  </sec>
  <sec id="s6">
    <title>Author Contributions</title>
    <p>RG and PW designed the method and Supervised the whole project. MJ and YX developed the prediction models. RZ, GJ, YY, and JW analysed the data and results. RZ and JW participated in the design, helped in writing the manuscript. All authors have read and approved the revised manuscript.</p>
  </sec>
  <sec id="s7">
    <title>Funding</title>
    <p>This work has been supported by the Zhejiang Provincial Natural Science Foundation of China (No. LY21F020017, 2022C03043), the National key research and development program of China (No. 2019YFC0118404, 2019YFC0118403), Joint Funds of the Zhejiang Provincial Natural Science Foundation of China (U20A20386), National Natural Science Foundation of China (No. 61702146).</p>
  </sec>
  <sec sec-type="COI-statement" id="s8">
    <title>Conflict of Interest</title>
    <p>Author JW is employed by MyGenostics Inc. The remaining authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s9">
    <title>Publisher’s Note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barber</surname><given-names>B. E.</given-names></name><name><surname>Rajahram</surname><given-names>G. S.</given-names></name><name><surname>Grigg</surname><given-names>M. J.</given-names></name><name><surname>William</surname><given-names>T.</given-names></name><name><surname>Anstey</surname><given-names>N. M.</given-names></name></person-group> (<year>2017</year>). <article-title>World Malaria Report: Time to Acknowledge Plasmodium Knowlesi Malaria</article-title>. <source>Malar. J.</source>
<volume>16</volume> (<issue>1</issue>), <fpage>135</fpage>. <pub-id pub-id-type="doi">10.1186/s12936-017-1787-y</pub-id>
<pub-id pub-id-type="pmid">28359340</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bell</surname><given-names>A.</given-names></name></person-group> (<year>2011</year>). <article-title>Antimalarial Peptides: the Long and the Short of it</article-title>. <source>Cpd</source>
<volume>17</volume> (<issue>25</issue>), <fpage>2719</fpage>–<lpage>2731</lpage>. <pub-id pub-id-type="doi">10.2174/138161211797416057</pub-id>
</mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chung</surname><given-names>C.-R.</given-names></name><name><surname>Kuo</surname><given-names>T.-R.</given-names></name><name><surname>Wu</surname><given-names>L.-C.</given-names></name><name><surname>Lee</surname><given-names>T.-Y.</given-names></name><name><surname>Horng</surname><given-names>J.-T.</given-names></name></person-group> (<year>2020</year>). <article-title>Characterization and Identification of Antimicrobial Peptides with Different Functional Activities</article-title>. <source>Brief. Bioinformatics</source>
<volume>21</volume> (<issue>3</issue>), <fpage>1098</fpage>–<lpage>1114</lpage>. <pub-id pub-id-type="doi">10.1093/bib/bbz043</pub-id>
</mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crooks</surname><given-names>G. E.</given-names></name><name><surname>Hon</surname><given-names>G.</given-names></name><name><surname>Chandonia</surname><given-names>J.-M.</given-names></name><name><surname>Brenner</surname><given-names>S. E.</given-names></name></person-group> (<year>2004</year>). <article-title>WebLogo: A Sequence Logo Generator: Figure 1</article-title>. <source>Genome Res.</source>
<volume>14</volume> (<issue>6</issue>), <fpage>1188</fpage>–<lpage>1190</lpage>. <pub-id pub-id-type="doi">10.1101/gr.849004</pub-id>
<pub-id pub-id-type="pmid">15173120</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>J.</given-names></name><name><surname>Goadrich</surname><given-names>M.</given-names></name></person-group> (<year>2006</year>). “<article-title>The Relationship between Precision-Recall and ROC Curves</article-title>,” in <source><italic>Proceedings of the 23rd International Conference on Machine Learning</italic></source>. <publisher-loc>Pittsburgh, PA</publisher-loc>: <publisher-name>Association for Computing Machinery</publisher-name>, <fpage>233</fpage>–<lpage>240</lpage>. </mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diemert</surname><given-names>D.</given-names></name><name><surname>Campbell</surname><given-names>D.</given-names></name><name><surname>Brelsford</surname><given-names>J.</given-names></name><name><surname>Leasure</surname><given-names>C.</given-names></name><name><surname>Li</surname><given-names>G.</given-names></name><name><surname>Peng</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2018</year>). “<article-title>Controlled Human Hookworm Infection: Accelerating Human Hookworm Vaccine Development</article-title>,” in <source>Open Forum Infectious Diseases</source>
<volume>5</volume> (<issue>5</issue>). <pub-id pub-id-type="doi">10.1093/ofid/ofy083</pub-id>
</mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ertabaklar</surname><given-names>H.</given-names></name><name><surname>Malatyali</surname><given-names>E.</given-names></name><name><surname>Malatyali</surname><given-names>E.</given-names></name><name><surname>Ertug</surname><given-names>S.</given-names></name></person-group> (<year>2020</year>). <article-title>Drug Resistance in Parasitic Diseases</article-title>. <source>Eur. J. Ther.</source>
<volume>26</volume>, <fpage>1</fpage>–<lpage>5</lpage>. <pub-id pub-id-type="doi">10.5152/eurjther.2019.18075</pub-id>
</mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fawcett</surname><given-names>T.</given-names></name></person-group> (<year>2006</year>). <article-title>An Introduction to ROC Analysis</article-title>. <source>Pattern recognition Lett.</source>
<volume>27</volume> (<issue>8</issue>), <fpage>861</fpage>–<lpage>874</lpage>. <pub-id pub-id-type="doi">10.1016/j.patrec.2005.10.010</pub-id>
</mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ge</surname><given-names>R.</given-names></name><name><surname>Zhou</surname><given-names>M.</given-names></name><name><surname>Luo</surname><given-names>Y.</given-names></name><name><surname>Meng</surname><given-names>Q.</given-names></name><name><surname>Mai</surname><given-names>G.</given-names></name><name><surname>Ma</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>McTwo: a Two-step Feature Selection Algorithm Based on Maximal Information Coefficient</article-title>. <source>BMC bioinformatics</source>
<volume>17</volume> (<issue>1</issue>), <fpage>142</fpage>. <pub-id pub-id-type="doi">10.1186/s12859-016-0990-0</pub-id>
<pub-id pub-id-type="pmid">27006077</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jahromi</surname><given-names>A. H.</given-names></name><name><surname>Taheri</surname><given-names>M.</given-names></name></person-group> (<year>2017</year>). “<article-title>A Non-parametric Mixture of Gaussian Naive Bayes Classifiers Based on Local Independent Features</article-title>,” in <source>Artificial Intelligence and Signal Processing Conference</source> (<publisher-loc>Shiraz, Iran</publisher-loc>: <publisher-name>AISP IEEE</publisher-name>), <fpage>209</fpage>–<lpage>212</lpage>. <pub-id pub-id-type="doi">10.1109/aisp.2017.8324083</pub-id>
</mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jing</surname><given-names>X.</given-names></name><name><surname>Dong</surname><given-names>Q.</given-names></name><name><surname>Hong</surname><given-names>D.</given-names></name><name><surname>Lu</surname><given-names>R.</given-names></name></person-group> (<year>2019</year>). <article-title>Amino Acid Encoding Methods for Protein Sequences: a Comprehensive Review and Assessment</article-title>. <source>Ieee/acm Trans. Comput. Biol. Bioinform</source>
<volume>17</volume> (<issue>6</issue>), <fpage>1918</fpage>–<lpage>1931</lpage>. <pub-id pub-id-type="doi">10.1109/TCBB.2019.2911677</pub-id>
</mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kinney</surname><given-names>J. B.</given-names></name><name><surname>Atwal</surname><given-names>G. S.</given-names></name></person-group> (<year>2014</year>). <article-title>Equitability, Mutual Information, and the Maximal Information Coefficient</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A.</source>
<volume>111</volume> (<issue>9</issue>), <fpage>3354</fpage>–<lpage>3359</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1309933111</pub-id>
<pub-id pub-id-type="pmid">24550517</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lacerda</surname><given-names>A. F.</given-names></name><name><surname>Pelegrini</surname><given-names>P. B.</given-names></name><name><surname>de Oliveira</surname><given-names>D. M.</given-names></name><name><surname>Vasconcelos</surname><given-names>É. A. R.</given-names></name><name><surname>Grossi-de-Sá</surname><given-names>M. F.</given-names></name></person-group> (<year>2016</year>). <article-title>Anti-parasitic Peptides from Arthropods and Their Application in Drug Therapy</article-title>. <source>Front. Microbiol.</source>
<volume>7</volume>, <fpage>91</fpage>. <pub-id pub-id-type="doi">10.3389/fmicb.2016.00091</pub-id>
<pub-id pub-id-type="pmid">26903970</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>M.</given-names></name><name><surname>Wu</surname><given-names>Z.</given-names></name><name><surname>Wang</surname><given-names>W.</given-names></name><name><surname>Lu</surname><given-names>K.</given-names></name><name><surname>Zhang</surname><given-names>J.</given-names></name><name><surname>Zhou</surname><given-names>Y.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Protein-Protein Interaction Sites Prediction Based on an Under-Sampling Strategy and Random Forest Algorithm</article-title>. <source>IEEE/ACM Trans. Comput. Biol. Bioinformatics</source>, <fpage>1</fpage>–<lpage>1</lpage>. <pub-id pub-id-type="doi">10.1109/tcbb.2021.3123269</pub-id>
</mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>C.</given-names></name><name><surname>Wang</surname><given-names>L.</given-names></name><name><surname>Shi</surname><given-names>L.</given-names></name></person-group> (<year>2022</year>). <article-title>AAPred-CNN: Accurate Predictor Based on Deep Convolution Neural Network for Identification of Anti-angiogenic Peptides</article-title>. <source>Methods</source>. <pub-id pub-id-type="doi">10.1016/j.ymeth.2022.01.004</pub-id>
</mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>B.</given-names></name><name><surname>Liu</surname><given-names>F.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Chen</surname><given-names>J.</given-names></name><name><surname>Fang</surname><given-names>L.</given-names></name><name><surname>Chou</surname><given-names>K.-C.</given-names></name></person-group> (<year>2015</year>). <article-title>Pse-in-One: a Web Server for Generating Various Modes of Pseudo Components of DNA, RNA, and Protein Sequences</article-title>. <source>Nucleic Acids Res.</source>
<volume>43</volume> (<issue>W1</issue>), <fpage>W65</fpage>–<lpage>W71</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkv458</pub-id>
<pub-id pub-id-type="pmid">25958395</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>B.</given-names></name><name><surname>Wu</surname><given-names>H.</given-names></name><name><surname>Chou</surname><given-names>K.-C.</given-names></name></person-group> (<year>2017</year>). <article-title>Pse-in-One 2.0: an Improved Package of Web Servers for Generating Various Modes of Pseudo Components of DNA, RNA, and Protein Sequences</article-title>. <source>Ns</source>
<volume>09</volume> (<issue>04</issue>), <fpage>67</fpage>–<lpage>91</lpage>. <pub-id pub-id-type="doi">10.4236/ns.2017.94007</pub-id>
</mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lobo</surname><given-names>J. M.</given-names></name><name><surname>Jiménez-Valverde</surname><given-names>A.</given-names></name><name><surname>Real</surname><given-names>R.</given-names></name></person-group> (<year>2008</year>). <article-title>AUC: a Misleading Measure of the Performance of Predictive Distribution Models</article-title>. <source>Glob. Ecol Biogeogr.</source>
<volume>17</volume> (<issue>2</issue>), <fpage>145</fpage>–<lpage>151</lpage>. <pub-id pub-id-type="doi">10.1111/j.1466-8238.2007.00358.x</pub-id>
</mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>F.</given-names></name><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Zhao</surname><given-names>X.-M.</given-names></name><name><surname>Li</surname><given-names>A.</given-names></name></person-group> (<year>2019</year>). <article-title>DeepPhos: Prediction of Protein Phosphorylation Sites with Deep Learning</article-title>. <source>Bioinformatics</source>
<volume>35</volume> (<issue>16</issue>), <fpage>2766</fpage>–<lpage>2773</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bty1051</pub-id>
<pub-id pub-id-type="pmid">30601936</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manavalan</surname><given-names>B.</given-names></name><name><surname>Basith</surname><given-names>S.</given-names></name><name><surname>Shin</surname><given-names>T. H.</given-names></name><name><surname>Wei</surname><given-names>L.</given-names></name><name><surname>Lee</surname><given-names>G.</given-names></name></person-group> (<year>2019</year>). <article-title>mAHTPred: a Sequence-Based Meta-Predictor for Improving the Prediction of Anti-hypertensive Peptides Using Effective Feature Representation</article-title>. <source>Bioinformatics</source>
<volume>35</volume> (<issue>16</issue>), <fpage>2757</fpage>–<lpage>2765</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bty1047</pub-id>
<pub-id pub-id-type="pmid">30590410</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mani</surname><given-names>I.</given-names></name><name><surname>Zhang</surname><given-names>I.</given-names></name></person-group> (<year>2003</year>). “<article-title>kNN Approach to Unbalanced Data Distributions: a Case Study Involving Information Extraction</article-title>,” in <source><italic>Proceedings of Workshop on Learning from Imbalanced Datasets</italic></source>. <publisher-loc>Washington, DC</publisher-loc>: <publisher-name>ICML</publisher-name>, <fpage>1</fpage>–<lpage>7</lpage>. </mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehta</surname><given-names>D.</given-names></name><name><surname>Anand</surname><given-names>P.</given-names></name><name><surname>Kumar</surname><given-names>V.</given-names></name><name><surname>Joshi</surname><given-names>A.</given-names></name><name><surname>Mathur</surname><given-names>D.</given-names></name><name><surname>Singh</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2014</year>). <article-title>ParaPep: a Web Resource for Experimentally Validated Antiparasitic Peptide Sequences and Their Structures</article-title>. <source>Database</source>
<volume>2014</volume>, <fpage>bau051</fpage>. <pub-id pub-id-type="doi">10.1093/database/bau051</pub-id>
<pub-id pub-id-type="pmid">24923818</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Momčilović</surname><given-names>S.</given-names></name><name><surname>Cantacessi</surname><given-names>C.</given-names></name><name><surname>Arsić-Arsenijević</surname><given-names>V.</given-names></name><name><surname>Otranto</surname><given-names>D.</given-names></name><name><surname>Tasić-Otašević</surname><given-names>S.</given-names></name></person-group> (<year>2019</year>). <article-title>Rapid Diagnosis of Parasitic Diseases: Current Scenario and Future Needs</article-title>. <source>Clin. Microbiol. Infect.</source>
<volume>25</volume> (<issue>3</issue>), <fpage>290</fpage>–<lpage>309</lpage>. <pub-id pub-id-type="doi">10.1016/j.cmi.2018.04.028</pub-id>
<pub-id pub-id-type="pmid">29730224</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pang</surname><given-names>Y.</given-names></name><name><surname>Yao</surname><given-names>L.</given-names></name><name><surname>Jhong</surname><given-names>J. H.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name><name><surname>Lee</surname><given-names>T. Y.</given-names></name></person-group> (<year>2021</year>). <article-title>AVPIden: a New Scheme for Identification and Functional Prediction of Antiviral Peptides Based on Machine Learning Approaches</article-title>. <source>Brief Bioinform</source>
<volume>22</volume> (<issue>6</issue>), <fpage>bbab263</fpage>. <pub-id pub-id-type="doi">10.1093/bib/bbab263</pub-id>
<pub-id pub-id-type="pmid">34279599</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F.</given-names></name><name><surname>Varoquaux</surname><given-names>G.</given-names></name><name><surname>Gramfort</surname><given-names>A.</given-names></name><name><surname>Michel</surname><given-names>V.</given-names></name><name><surname>Thirion</surname><given-names>B.</given-names></name><name><surname>Grisel</surname><given-names>O.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Scikit-learn: Machine Learning in Python</article-title>. <source>J. machine Learn. Res.</source>
<volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>. <pub-id pub-id-type="doi">10.48550/arXiv.1201.0490</pub-id>
</mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>T. D.</given-names></name><name><surname>Stephens</surname><given-names>R. M.</given-names></name></person-group> (<year>1990</year>). <article-title>Sequence Logos: a New Way to Display Consensus Sequences</article-title>. <source>Nucl. Acids Res.</source>
<volume>18</volume> (<issue>20</issue>), <fpage>6097</fpage>–<lpage>6100</lpage>. <pub-id pub-id-type="doi">10.1093/nar/18.20.6097</pub-id>
<pub-id pub-id-type="pmid">2172928</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stilianoudakis</surname><given-names>S. C.</given-names></name><name><surname>Marshall</surname><given-names>M. A.</given-names></name><name><surname>Dozmorov</surname><given-names>M. G.</given-names></name></person-group> (<year>2021</year>). <article-title>preciseTAD: a Transfer Learning Framework for 3D Domain Boundary Prediction at Base-Pair Resolution</article-title>. <source>Bioinformatics</source>
<volume>38</volume> (<issue>3</issue>), <fpage>621</fpage>–<lpage>630</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btab743</pub-id>
</mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tahir</surname><given-names>M. A.</given-names></name><name><surname>Kittler</surname><given-names>J.</given-names></name><name><surname>Yan</surname><given-names>F.</given-names></name></person-group> (<year>2012</year>). <article-title>Inverse Random under Sampling for Class Imbalance Problem and its Application to Multi-Label Classification</article-title>. <source>Pattern Recognition</source>
<volume>45</volume> (<issue>10</issue>), <fpage>3738</fpage>–<lpage>3750</lpage>. <pub-id pub-id-type="doi">10.1016/j.patcog.2012.03.014</pub-id>
</mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Torrent</surname><given-names>M.</given-names></name><name><surname>Pulido</surname><given-names>D.</given-names></name><name><surname>Rivas</surname><given-names>L.</given-names></name><name><surname>Andreu</surname><given-names>D.</given-names></name></person-group> (<year>2012</year>). <article-title>Antimicrobial Peptide Action on Parasites</article-title>. <source>Cdt</source>
<volume>13</volume> (<issue>9</issue>), <fpage>1138</fpage>–<lpage>1147</lpage>. <pub-id pub-id-type="doi">10.2174/138945012802002393</pub-id>
</mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van der Maaten</surname><given-names>L.</given-names></name><name><surname>Hinton</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>). <article-title>Visualizing Data Using T-SNE</article-title>. <source>J. machine Learn. Res.</source>
<volume>9</volume> (<issue>86</issue>), <fpage>2579</fpage>–<lpage>2605</lpage>. </mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>G.</given-names></name><name><surname>Li</surname><given-names>X.</given-names></name><name><surname>Wang</surname><given-names>Z.</given-names></name></person-group> (<year>2016</year>). <article-title>APD3: the Antimicrobial Peptide Database as a Tool for Research and Education</article-title>. <source>Nucleic Acids Res.</source>
<volume>44</volume> (<issue>D1</issue>), <fpage>D1087</fpage>–<lpage>D1093</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkv1278</pub-id>
<pub-id pub-id-type="pmid">26602694</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Yang</surname><given-names>B.</given-names></name><name><surname>An</surname><given-names>Y.</given-names></name><name><surname>Marquez-Lago</surname><given-names>T.</given-names></name><name><surname>Leier</surname><given-names>A.</given-names></name><name><surname>Wilksch</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>Systematic Analysis and Prediction of Type IV Secreted Effector Proteins by Machine Learning Approaches</article-title>. <source>Brief. Bioinform.</source>
<volume>20</volume> (<issue>3</issue>), <fpage>931</fpage>–<lpage>951</lpage>. <pub-id pub-id-type="doi">10.1093/bib/bbx164</pub-id>
</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>P.-H.</given-names></name><name><surname>Tu</surname><given-names>Y.-S.</given-names></name><name><surname>Tseng</surname><given-names>Y. J.</given-names></name></person-group> (<year>2019</year>). <article-title>PgpRules: a Decision Tree Based Prediction Server for P-Glycoprotein Substrates and Inhibitors</article-title>. <source>Bioinformatics</source>
<volume>35</volume> (<issue>20</issue>), <fpage>4193</fpage>–<lpage>4195</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btz213</pub-id>
<pub-id pub-id-type="pmid">30918935</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>S.</given-names></name><name><surname>Wu</surname><given-names>X.</given-names></name><name><surname>Tian</surname><given-names>J.</given-names></name><name><surname>Zhou</surname><given-names>X.</given-names></name><name><surname>Huang</surname><given-names>L.</given-names></name></person-group> (<year>2019</year>). <article-title>PredictFP2: a New Computational Model to Predict Fusion Peptide Domain in All Retroviruses</article-title>. <source>Ieee/acm Trans. Comput. Biol. Bioinform</source>
<volume>17</volume> (<issue>5</issue>), <fpage>1714</fpage>–<lpage>1720</lpage>. <pub-id pub-id-type="doi">10.1109/TCBB.2019.2898943</pub-id>
<pub-id pub-id-type="pmid">30762564</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>H.</given-names></name><name><surname>Wang</surname><given-names>M.</given-names></name><name><surname>Liu</surname><given-names>X.</given-names></name><name><surname>Zhao</surname><given-names>X.-M.</given-names></name><name><surname>Li</surname><given-names>A.</given-names></name></person-group> (<year>2021</year>). <article-title>PhosIDN: an Integrated Deep Neural Network for Improving Protein Phosphorylation Site Prediction by Combining Sequence and Protein-Protein Interaction Information</article-title>. <source>Bioinformatics</source>
<volume>37</volume> (<issue>24</issue>), <fpage>4668</fpage>–<lpage>4676</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btab551</pub-id>
</mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zahedifard</surname><given-names>F.</given-names></name><name><surname>Rafati</surname><given-names>S.</given-names></name></person-group> (<year>2018</year>). <article-title>Prospects for Antimicrobial Peptide-Based Immunotherapy Approaches in Leishmania Control</article-title>. <source>Expert Rev. anti-infective Ther.</source>
<volume>16</volume> (<issue>6</issue>), <fpage>461</fpage>–<lpage>469</lpage>. <pub-id pub-id-type="doi">10.1080/14787210.2018.1483720</pub-id>
</mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>W.</given-names></name><name><surname>Xia</surname><given-names>E.</given-names></name><name><surname>Dai</surname><given-names>R.</given-names></name><name><surname>Tang</surname><given-names>W.</given-names></name><name><surname>Bin</surname><given-names>Y.</given-names></name><name><surname>Xia</surname><given-names>J.</given-names></name></person-group> (<year>2021</year>). <article-title>PredAPP: Predicting Anti-parasitic Peptides with Undersampling and Ensemble Approaches</article-title>. <source>Interdiscip. Sci. Comput. Life Sci.</source>
<volume>14</volume> (<issue>1</issue>)–<lpage>258268</lpage>. <pub-id pub-id-type="doi">10.1007/s12539-021-00484-x</pub-id>
</mixed-citation>
    </ref>
  </ref-list>
</back>
