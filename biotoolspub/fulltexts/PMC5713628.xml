<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PeerJ</journal-id>
    <journal-id journal-id-type="iso-abbrev">PeerJ</journal-id>
    <journal-id journal-id-type="publisher-id">peerj</journal-id>
    <journal-id journal-id-type="pmc">peerj</journal-id>
    <journal-title-group>
      <journal-title>PeerJ</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2167-8359</issn>
    <publisher>
      <publisher-name>PeerJ Inc.</publisher-name>
      <publisher-loc>San Francisco, USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">5713628</article-id>
    <article-id pub-id-type="publisher-id">4088</article-id>
    <article-id pub-id-type="doi">10.7717/peerj.4088</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Agricultural Science</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Bioinformatics</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Computational Biology</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Plant Science</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Data Mining and Machine Learning</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>PlantCV v2: Image analysis software for high-throughput plant phenotyping</article-title>
    </title-group>
    <contrib-group>
      <contrib id="author-1" contrib-type="author" corresp="yes" equal-contrib="yes">
        <name>
          <surname>Gehan</surname>
          <given-names>Malia A.</given-names>
        </name>
        <email>mgehan@danforthcenter.org</email>
        <xref ref-type="aff" rid="aff-1">1</xref>
      </contrib>
      <contrib id="author-2" contrib-type="author" corresp="yes" equal-contrib="yes">
        <name>
          <surname>Fahlgren</surname>
          <given-names>Noah</given-names>
        </name>
        <email>nfahlgren@danforthcenter.org</email>
        <xref ref-type="aff" rid="aff-1">1</xref>
      </contrib>
      <contrib id="author-3" contrib-type="author">
        <name>
          <surname>Abbasi</surname>
          <given-names>Arash</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
      </contrib>
      <contrib id="author-4" contrib-type="author">
        <name>
          <surname>Berry</surname>
          <given-names>Jeffrey C.</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
      </contrib>
      <contrib id="author-5" contrib-type="author">
        <name>
          <surname>Callen</surname>
          <given-names>Steven T.</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
        <xref ref-type="aff" rid="aff-8">8</xref>
      </contrib>
      <contrib id="author-6" contrib-type="author">
        <name>
          <surname>Chavez</surname>
          <given-names>Leonardo</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
      </contrib>
      <contrib id="author-7" contrib-type="author">
        <name>
          <surname>Doust</surname>
          <given-names>Andrew N.</given-names>
        </name>
        <xref ref-type="aff" rid="aff-2">2</xref>
      </contrib>
      <contrib id="author-8" contrib-type="author">
        <name>
          <surname>Feldman</surname>
          <given-names>Max J.</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
      </contrib>
      <contrib id="author-9" contrib-type="author">
        <name>
          <surname>Gilbert</surname>
          <given-names>Kerrigan B.</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
      </contrib>
      <contrib id="author-10" contrib-type="author">
        <name>
          <surname>Hodge</surname>
          <given-names>John G.</given-names>
        </name>
        <xref ref-type="aff" rid="aff-2">2</xref>
      </contrib>
      <contrib id="author-11" contrib-type="author">
        <name>
          <surname>Hoyer</surname>
          <given-names>J. Steen</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
        <xref ref-type="aff" rid="aff-3">3</xref>
      </contrib>
      <contrib id="author-12" contrib-type="author">
        <name>
          <surname>Lin</surname>
          <given-names>Andy</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
        <xref ref-type="aff" rid="aff-9">9</xref>
      </contrib>
      <contrib id="author-13" contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Suxing</given-names>
        </name>
        <xref ref-type="aff" rid="aff-4">4</xref>
        <xref ref-type="aff" rid="aff-10">10</xref>
      </contrib>
      <contrib id="author-14" contrib-type="author">
        <name>
          <surname>Lizárraga</surname>
          <given-names>César</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
        <xref ref-type="aff" rid="aff-11">11</xref>
      </contrib>
      <contrib id="author-15" contrib-type="author">
        <name>
          <surname>Lorence</surname>
          <given-names>Argelia</given-names>
        </name>
        <xref ref-type="aff" rid="aff-5">5</xref>
      </contrib>
      <contrib id="author-16" contrib-type="author">
        <name>
          <surname>Miller</surname>
          <given-names>Michael</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
        <xref ref-type="aff" rid="aff-12">12</xref>
      </contrib>
      <contrib id="author-17" contrib-type="author">
        <name>
          <surname>Platon</surname>
          <given-names>Eric</given-names>
        </name>
        <xref ref-type="aff" rid="aff-6">6</xref>
      </contrib>
      <contrib id="author-18" contrib-type="author">
        <name>
          <surname>Tessman</surname>
          <given-names>Monica</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
        <xref ref-type="aff" rid="aff-2">2</xref>
      </contrib>
      <contrib id="author-19" contrib-type="author">
        <name>
          <surname>Sax</surname>
          <given-names>Tony</given-names>
        </name>
        <xref ref-type="aff" rid="aff-7">7</xref>
      </contrib>
      <aff id="aff-1"><label>1</label><institution>Donald Danforth Plant Science Center</institution>, <city>St. Louis</city>, <state>MO</state>, <country>United States of America</country></aff>
      <aff id="aff-2"><label>2</label><institution>Department of Plant Biology, Ecology, and Evolution, Oklahoma State University</institution>, <city>Stillwater</city>, <state>OK</state>, <country> United States of America</country></aff>
      <aff id="aff-3"><label>3</label><institution>Computational and Systems Biology Program, Washington University in St. Louis</institution>, <city>St. Louis</city>, <state>MO</state>, <country> United States of America</country></aff>
      <aff id="aff-4"><label>4</label><institution>Arkansas Biosciences Institute, Arkansas State University</institution>, <city>Jonesboro</city>, <state>AR</state>, <country>United States of America</country></aff>
      <aff id="aff-5"><label>5</label><institution>Arkansas Biosciences Institute, Department of Chemistry and Physics, Arkansas State University</institution>, <city>Jonesboro</city>, <state>AR</state>, <country>United States of America</country></aff>
      <aff id="aff-6"><label>6</label><institution>Cosmos X</institution>, <city>Tokyo</city>, <country>Japan</country></aff>
      <aff id="aff-7"><label>7</label><institution>Missouri University of Science and Technology</institution>, <city>Rolla</city>, <state>MO</state>, <country>United States of America</country></aff>
      <aff id="aff-8"><label>8</label> Current affiliation:  <institution>Monsanto Company</institution>, <city>St. Louis</city>, <state>MO</state>, <country>United States of America</country></aff>
      <aff id="aff-9"><label>9</label> Current affiliation:  <institution>Unidev</institution>, <city>St. Louis</city>, <state>MO</state>, <country>United States of America</country></aff>
      <aff id="aff-10"><label>10</label> Current affiliation:  <institution>Department of Plant Biology, University of Georgia</institution>, <city>Athens</city>, <state>GA</state>, <country> United States of America</country></aff>
      <aff id="aff-11"><label>11</label> Current affiliation:  <institution>CiBO Technologies</institution>, <city>Cambridge</city>, <state>MA</state>, <country>United States of America</country></aff>
      <aff id="aff-12"><label>12</label> Current affiliation:  <institution>Department of Agronomy and Horticulture, Center for Plant Science Innovation, Beadle Center for Biotechnology, University of Nebraska - Lincoln</institution>, <city>Lincoln</city>, <state>NE</state>, <country>United States of America</country></aff>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Loraine</surname>
          <given-names>Ann</given-names>
        </name>
      </contrib>
    </contrib-group>
    <pub-date pub-type="epub" date-type="pub" iso-8601-date="2017-12-01">
      <day>1</day>
      <month>12</month>
      <year iso-8601-date="2017">2017</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2017</year>
    </pub-date>
    <volume>5</volume>
    <elocation-id>e4088</elocation-id>
    <history>
      <date date-type="received" iso-8601-date="2017-09-07">
        <day>7</day>
        <month>9</month>
        <year iso-8601-date="2017">2017</year>
      </date>
      <date date-type="accepted" iso-8601-date="2017-11-03">
        <day>3</day>
        <month>11</month>
        <year iso-8601-date="2017">2017</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>©2017 Gehan et al.</copyright-statement>
      <copyright-year>2017</copyright-year>
      <copyright-holder>Gehan et al.</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, reproduction and adaptation in any medium and for any purpose provided that it is properly attributed. For attribution, the original author(s), title, publication source (PeerJ) and either DOI or URL of the article must be cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="https://peerj.com/articles/4088"/>
    <abstract>
      <p>Systems for collecting image data in conjunction with computer vision techniques are a powerful tool for increasing the temporal resolution at which plant phenotypes can be measured non-destructively. Computational tools that are flexible and extendable are needed to address the diversity of plant phenotyping problems. We previously described the Plant Computer Vision (PlantCV) software package, which is an image processing toolkit for plant phenotyping analysis. The goal of the PlantCV project is to develop a set of modular, reusable, and repurposable tools for plant image analysis that are open-source and community-developed. Here we present the details and rationale for major developments in the second major release of PlantCV. In addition to overall improvements in the organization of the PlantCV project, new functionality includes a set of new image processing and normalization tools, support for analyzing images that include multiple plants, leaf segmentation, landmark identification tools for morphometrics, and modules for machine learning.</p>
    </abstract>
    <kwd-group kwd-group-type="author">
      <kwd>Plant phenotyping</kwd>
      <kwd>Image analysis</kwd>
      <kwd>Computer vision</kwd>
      <kwd>Machine learning</kwd>
      <kwd>Morphometrics</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="fund-1">
        <funding-source>Donald Danforth Plant Science Center</funding-source>
      </award-group>
      <award-group id="fund-2">
        <funding-source>US National Science Foundation</funding-source>
        <award-id>IIA-1430427</award-id>
        <award-id>IIA-1430428</award-id>
        <award-id>IIA-1355406</award-id>
        <award-id>IOS-1202682</award-id>
        <award-id>MCB-1330562</award-id>
        <award-id>DBI-1156581</award-id>
      </award-group>
      <award-group id="fund-3">
        <funding-source>US Department of Energy</funding-source>
        <award-id>DE-AR0000594</award-id>
        <award-id>DE-SC0014395</award-id>
      </award-group>
      <award-group id="fund-4">
        <funding-source>US Department of Agriculture</funding-source>
        <award-id>MOW-2012-01361</award-id>
        <award-id>2016-67009-25639</award-id>
      </award-group>
      <funding-statement>This work was supported by the Donald Danforth Plant Science Center, the US National Science Foundation (IIA-1430427, IIA-1430428, IIA-1355406, IOS-1202682, MCB-1330562, and DBI-1156581), the US Department of Energy (DE-AR0000594, DE-SC0014395), and the US Department of Agriculture (MOW-2012-01361 and 2016-67009-25639). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
  </article-meta>
</front>
<body>
  <sec sec-type="intro">
    <title>Introduction</title>
    <p>All approaches for improving crops eventually require measurement of traits (phenotyping) (<xref rid="ref-12" ref-type="bibr">Fahlgren, Gehan &amp; Baxter, 2015</xref>). However, manual plant measurements are time-consuming and often require destruction of plant materials in the process, which prevents measurement of traits for a single plant through time. Consequently, plant phenotyping is widely recognized as a major bottleneck in crop improvement (<xref rid="ref-15" ref-type="bibr">Furbank &amp; Tester, 2011</xref>). Targeted plant phenotypes can range from measurement of gene expression, to flowering time, to grain yield; therefore, the software and hardware tools used are often diverse. Here, we focus on the software tools required to nondestructively measure plant traits through images. This is a challenging area of research because the visual definition of phenotypes vary depending on the target species. For example, identification of petals can be used to measure flowering time, but petal color can vary by species. Therefore, software tools needed to process high-throughput image data need to be flexible and amenable to community input.</p>
    <p>The term ‘high-throughput’ is relative to the difficulty to collect the measurement. The scale that might be considered high-throughput for root phenotyping might not be the same for shoot phenotyping, which can be technically easier to collect depending on the trait and species. Here we define high-throughput as thousands or hundreds of thousands of images per dataset. PlantCV is an open-source, open-development suite of analysis tools capable of analyzing high-throughput image-based phenotyping data (<xref rid="ref-11" ref-type="bibr">Fahlgren et al., 2015</xref>). Version 1.0 of PlantCV (PlantCV v1.0) was released in 2015 alongside the introduction of the Bellwether Phenotyping Facility at the Donald Danforth Plant Science Center (<xref rid="ref-11" ref-type="bibr">Fahlgren et al., 2015</xref>). PlantCV v1.0 was envisioned as a base suite of tools that the community could build upon, which lead to several design decisions aimed at encouraging participation. First, GitHub was used as a platform to organize the community by integrating version control, code distribution, documentation, issue tracking, and communication between users and contributors (<xref rid="ref-33" ref-type="bibr">Perez-Riverol et al., 2016</xref>). Second, PlantCV was written in Python, a high-level language widely used for both teaching and bioinformatics (<xref rid="ref-26" ref-type="bibr">Mangalam, 2002</xref>; <xref rid="ref-10" ref-type="bibr">Dudley &amp; Butte, 2009</xref>), to facilitate contribution from both biologists and computer scientists. Additionally, the use of Python allows extension of PlantCV with the many tools available from the Python scientific computing community (<xref rid="ref-30" ref-type="bibr">Oliphant, 2007</xref>; <xref rid="ref-28" ref-type="bibr">Millman &amp; Aivazis, 2011</xref>). Third, a focus on modular development fosters code reuse and makes it easier to integrate PlantCV with new or existing systems. Finally, the use of a permissive, open-source license (MIT) allows PlantCV to be used, reused, or repurposed with limited restrictions, for both academic and proprietary applications. The focus of the paper associated with the original release of PlantCV v1.0 (<xref rid="ref-11" ref-type="bibr">Fahlgren et al., 2015</xref>) was not the structure and function of PlantCV for image analysis, but rather an example of the type of biological question that can be answered with high-throughput phenotyping hardware and software platforms. Since the release of PlantCV v1.0 major improvements have been made to increase the flexibility, usability, and functionality of PlantCV, while maintaining all of the functionality in v1.0. Here we document the structure of PlantCV v2 along with examples that demonstrate new functionality.</p>
  </sec>
  <sec sec-type="materials|methods">
    <title>Materials &amp; Methods</title>
    <p>The latest version or a specific release of PlantCV can be cloned from GitHub. The release for this paper is v2.1. Scripts, notebooks, SQL schema, and simple input data associated with the figures and results presented in this paper are available on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/danforthcenter/plantcv-v2-paper">https://github.com/danforthcenter/plantcv-v2-paper</ext-link>. Project-specific GitHub repositories are kept separate from the PlantCV software repository because their purpose is to make project-specific analyses available for reproducibility, while the main PlantCV software repository contains general purpose image analysis modules, utilities, and documentation.</p>
    <p>Images of <italic>Arabidopsis thaliana</italic> were captured with a Raspberry Pi computer and camera in a Conviron growth chamber. Additional details about the imaging set-up are provided in a companion paper (<xref rid="ref-41" ref-type="bibr">Tovar et al., 2017</xref>). Images of <italic>Setaria viridis</italic> (A10) and <italic>Setaria italica</italic> (B100) are from publicly available datasets that are available at <ext-link ext-link-type="uri" xlink:href="http://plantcv.danforthcenter.org/pages/data.html">http://plantcv.danforthcenter.org/pages/data.html</ext-link> (<xref rid="ref-11" ref-type="bibr">Fahlgren et al., 2015</xref>; <xref rid="ref-13" ref-type="bibr">Feldman et al., 2017</xref>). Images of wheat (<italic>Triticum aestivum L.</italic>) infected with wheat stem rust (<italic>Puccinia graminis f. sp. tritici</italic>) were acquired with a flatbed scanner.</p>
    <p>Image analysis was done in PlantCV using Python v2.7.5, OpenCV v2.4.5 (<xref rid="ref-6" ref-type="bibr">Bradski, 2000</xref>), NumPy v1.12.1 (<xref rid="ref-43" ref-type="bibr">Van der Walt, Colbert &amp; Varoquaux, 2011</xref>), Matplotlib v2.0.2 (<xref rid="ref-19" ref-type="bibr">Hunter, 2007</xref>), SciPy v0.19.0 (<xref rid="ref-20" ref-type="bibr">Jones, Oliphant &amp; Peterson, 2014</xref>), Pandas v0.20.1 (<xref rid="ref-27" ref-type="bibr">McKinney, 2010</xref>), scikit-image v0.13.0 (<xref rid="ref-44" ref-type="bibr">Van der Walt et al., 2014</xref>), and Jupyter Notebook v4.2.1 (<xref rid="ref-22" ref-type="bibr">Kluyver et al., 2016</xref>). Statistical analysis and data visualization was done using R v3.3 (<xref rid="ref-39" ref-type="bibr">R Core Team, 2017</xref>) and RStudio v1.0 (<xref rid="ref-40" ref-type="bibr">RStudio Team, 2016</xref>). Graphs were produced using Matplotlib v2.0.2 (<xref rid="ref-19" ref-type="bibr">Hunter, 2007</xref>) and ggplot2 v2.2.1 (<xref rid="ref-45" ref-type="bibr">Wickham, 2009</xref>).</p>
  </sec>
  <sec>
    <title>Results and Discussion</title>
    <p>The following are details on improvements to the structure, usability, and functionality of PlantCV since the v1.0 release. Further documentation for using PlantCV can be found at the project website (<ext-link ext-link-type="uri" xlink:href="http://plantcv.danforthcenter.org/">http://plantcv.danforthcenter.org/</ext-link>).</p>
    <sec>
      <title>Organization of the PlantCV project</title>
      <p>PlantCV is a collection of modular Python functions, which are reusable units of Python code with defined inputs and outputs (<xref ref-type="fig" rid="fig-1">Fig. 1A</xref>). PlantCV functions can be assembled into simple sequential or branching/merging pipelines. A pipeline can be as long or as short as it needs to be, allowing for maximum flexibility for users using different imaging systems and analyzing features of seed, shoot, root, or other plant systems. Suggestions on how to approach image analysis with PlantCV, in addition to specific tutorials, are available through online documentation (<ext-link ext-link-type="uri" xlink:href="http://plantcv.readthedocs.io/en/latest/analysis_approach/">http://plantcv.readthedocs.io/en/latest/analysis_approach/</ext-link>). Each function has a debugging option to allow users to view and evaluate the output of a single step and adjust parameters as necessary. A PlantCV pipeline is written by the user as a Python script. Once a satisfactory pipeline script is developed, the PlantCV parallelization script (‘plantcv-pipeline.py’) can be used to deploy the pipeline across a large set of image data (<xref ref-type="fig" rid="fig-1">Fig. 1A</xref>). The parallelization script also functions to manage data by consolidating measurements and metadata into an SQLite database (<xref ref-type="fig" rid="fig-1">Fig. 1B</xref>). In terms of speed, the user is only limited by the complexity of the pipeline and the number of available processors.</p>
      <fig id="fig-1" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.4088/fig-1</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Diagram of the components of PlantCV.</title>
          <p>(A) PlantCV is an open-source, open-development suite of image analysis tools. PlantCV contains a library of modular Python functions that can be assembled into simple sequential or branching/merging processing pipelines. Image processing pipelines, which process single images (possibly containing multiple plants), can be deployed over large image sets using PlantCV parallelization, which outputs an SQLite database of both measurements and image/experimental metadata. (B) Overview of the structure of the SQLite database.</p>
        </caption>
        <graphic xlink:href="peerj-05-4088-g001"/>
      </fig>
      <p>The modular structure of the PlantCV package makes it easier for members of the community to become contributors. Contributors to PlantCV submit bug reports, develop new functions and unit tests, or extend existing functionality or documentation. Core PlantCV developers do not filter additions of new functions in terms of perceived impact or number of users but do check that new functions follow the PlantCV contribution guide (see the sections on contributing in the online documentation). PlantCV contributors are asked to follow the PEP8 Python style guide (<ext-link ext-link-type="uri" xlink:href="https://www.python.org/dev/peps/pep-0008/">https://www.python.org/dev/peps/pep-0008/</ext-link>). Additions or revisions to the PlantCV code or documentation are submitted for review using pull requests via GitHub. The pull request mechanism is essential to protect against merge conflicts, which are sections of code that have been edited by multiple users in potentially incompatible ways.</p>
      <p>In PlantCV v2, several service integrations were added to automate common tasks during pull requests and updates to the code repository. A continuous integration framework using the Travis CI service (<ext-link ext-link-type="uri" xlink:href="https://travis-ci.org/">https://travis-ci.org/</ext-link>) was added so that software builds and unit tests can be run automatically upon pull requests and other software updates. Continuous integration provides a safeguard against code updates that break existing functionality by providing a report that shows which tests passed or failed for each build (<xref rid="ref-46" ref-type="bibr">Wilson et al., 2014</xref>). The effectiveness of continuous integration depends on having thorough unit test coverage of the PlantCV code base. Unit test coverage of the PlantCV Python package is monitored through the Coveralls service (<ext-link ext-link-type="uri" xlink:href="https://coveralls.io/">https://coveralls.io/</ext-link>), which provides a report on which parts of the code are covered by existing unit tests. In addition to the code, the PlantCV documentation was enhanced to use a continuous documentation framework using the Read the Docs service (<ext-link ext-link-type="uri" xlink:href="https://readthedocs.org/">https://readthedocs.org/</ext-link>), which allows documentation to be updated automatically and versioned in parallel with updates to PlantCV. The documentation was updated to cover all functions in the PlantCV library, tutorials on building pipelines and using specialized tools (e.g., multi-plant analysis and machine learning tools), a frequently asked questions section, and several guides such as installation, Jupyter notebooks, and instructions for contributors.</p>
    </sec>
    <sec>
      <title>Improved usability</title>
      <p>PlantCV v1.0 required pipeline development to be done using the command line, where debug mode is used to write intermediate image files to disk for each step. In command-line mode, an entire pipeline script must be executed, even if only a single step is being evaluated. To improve the pipeline and function development process in PlantCV v2, the debugging system was updated to allow for seamless integration with the Juptyer Notebook system (<ext-link ext-link-type="uri" xlink:href="http://jupyter.org/">http://jupyter.org/</ext-link>; <xref rid="ref-22" ref-type="bibr">Kluyver et al., 2016</xref>). Jupyter compatibility allows users to immediately visualize output and to iteratively rerun single steps in a multi-step PlantCV pipeline, which makes parameters like thresholds or regions of interest much easier to adjust. Once a pipeline is developed in Jupyter, it can then be converted into a Python script that is compatible with PlantCV parallelization (see online documentation for detailed instructions on conversion; <ext-link ext-link-type="uri" xlink:href="http://plantcv.readthedocs.io/en/latest/jupyter/">http://plantcv.readthedocs.io/en/latest/jupyter/</ext-link>). Because ofthe web-based interface and useful export options, Jupyter notebooks are also a convenient method of sharing pipelines with collaborators, or in publications, and teaching others to use PlantCV.</p>
      <p>PlantCV was initially created to analyze data generated by the Bellwether Phenotyping Facility at the Donald Danforth Plant Science Center. Several updates to PlantCV v2 addressed the need to increase the flexibility of PlantCV to analyze data from other plant phenotyping systems. The PlantCV SQLite database schema was simplified so that new tables do not need to be added for every new camera system (<xref ref-type="fig" rid="fig-1">Fig. 1B</xref>). The full database schema is available on GitHub (see ‘Materials and Methods’) and in PlantCV documentation. New utilities were added to PlantCV v2 that allow data to be quickly and efficiently exported from the SQLite database into text files that are compatible with R (<xref rid="ref-39" ref-type="bibr">R Core Team, 2017</xref>) for further statistical analysis and data visualization.</p>
      <p>Because standards for data collection and management for plant phenotyping data are still being developed (<xref rid="ref-32" ref-type="bibr">Pauli et al., 2016</xref>), image metadata is often stored in a variety of formats on different systems. A common approach is to include metadata within image filenames, but because there is a lack of file naming standards, it can be difficult to robustly capture this data automatically. In PlantCV v2, a new metadata processing system was added to allow for flexibility in file naming both within and between experiments and systems. The PlantCV metadata processing system is part of the parallelization tool and works by using a user-provided template to process filenames. User-provided templates are built using a restricted vocabulary so that metadata can be collected in a standardized way. The vocabulary used can be easily updated to accommodate future community standards.</p>
    </sec>
    <sec>
      <title>Performance</title>
      <p>In PlantCV v1.0, image analysis parallelization was achieved using a Perl-based multi-threading system that was not thread-safe, which occasionally resulted in issues with data output that had to be manually corrected. Additionally, the use of the Python package Matplotlib (<xref rid="ref-19" ref-type="bibr">Hunter, 2007</xref>) in PlantCV v1.0 limited the number of usable processors to 10–12. For PlantCV v2, the parallelization framework was completely rewritten in Python using a multiprocessing framework, and the use of Matplotlib was updated to mitigate the issues and processor constraints in v1.0. The output of image files mainly used to assess image segmentation quality is now optional, which should generally increase computing performance. Furthermore, to decentralize the computational resources needed for parallel processing and prepare for future integration with high-throughput computing resources that use file-in-file-out operations, results from PlantCV pipeline scripts (one per image) are now written out to temporary files that are aggregated by the parallelization tool after all image processing is complete.</p>
    </sec>
    <sec>
      <title>New functionality</title>
      <p>PlantCV v2 has added new functions for image white balancing, auto-thresholding, size marker normalization, multi-plant detection, combined image processing, watershed segmentation, landmarking, and a trainable naive Bayes classifier for image segmentation (machine learning). The following are short descriptions and sample applications of new PlantCV functions.</p>
      <sec>
        <title>White balancing</title>
        <p>If images are captured in a greenhouse, growth chamber, or other situation where light intensity is variable, image segmentation based on global thresholding of image intensity values can become variable. To help mitigate image inconsistencies that might impair the ability to use a single global threshold and thus a single pipeline over a set of images, a white balance function was developed. If a white color standard is visible within the image, the user can specify a region of interest. If a specific area is not selected then the whole image is used. Each channel of the image is scaled relative to the reference maximum.</p>
      </sec>
      <sec>
        <title>Auto-thresholding functions</title>
        <p>An alternative approach to using a fixed, global threshold for image segmentation is to use an auto-thresholding technique that either automatically selects an optimal global threshold value or introduces a variable threshold for different regions in an image. Triangle, Otsu, mean, and Gaussian auto-thresholding functions were added to PlantCV to further improve object detection when image light sources are variable. The ‘triangle_auto_threshold’ function implements the method developed by <xref rid="ref-47" ref-type="bibr">Zack, Rogers &amp; Latp (1977)</xref>. The triangle threshold method uses the histogram of pixel intensities to differentiate the target object (plant) from background by generating a line from the peak pixel intensity (<xref rid="ref-9" ref-type="bibr">Duarte, 2015</xref>) to the last pixel value and then finding the point (i.e., the threshold value) on the histogram that maximizes distance to that line. In addition to producing the thresholded image in debug mode, the ‘triangle_auto_threshold’ function outputs the calculated threshold value and the histogram of pixel intensities that was used to calculate the threshold. In cases where the auto-threshold value does not adequately separate the target object from background, the threshold can be adjusted by modifying the stepwise input. Modifying the stepwise input shifts the distance calculation along the <italic>x</italic>-axis, which subsequently calculates a new threshold value to use.</p>
        <p>The Otsu, mean, and Gaussian threshold functions in PlantCV are implemented using the OpenCV library (<xref rid="ref-6" ref-type="bibr">Bradski, 2000</xref>). Otsu’s binarization (‘otsu_auto_threshold;’ (<xref rid="ref-31" ref-type="bibr">Otsu, 1979</xref>)) is best implemented when a grayscale image histogram has two peaks since the Otsu method selects a threshold value that minimizes the weighted within-class variance. In other words, the Otsu method identifies the value between two peaks where the variances of both classes are minimized. Mean and Gaussian thresholding are executed by indicating the desired threshold type in the function ‘adaptive_threshold.’ The mean and Gaussian methods will produce a variable local threshold where the threshold value of a pixel location depends on the intensities of neighboring pixels. For mean adaptive thresholding, the threshold of a pixel location is calculated by the mean of surrounding pixel values; for Gaussian adaptive thresholding, the threshold value of a pixel is the weighted sum of neighborhood values using a Gaussian window (<xref rid="ref-16" ref-type="bibr">Gonzalez &amp; Woods, 2002</xref>; <xref rid="ref-21" ref-type="bibr">Kaehler &amp; Bradski, 2016</xref>).</p>
      </sec>
      <sec>
        <title>Gaussian blur</title>
        <p>In addition to the ‘median_blur’ function included in PlantCV v1.0, we have added a Gaussian blur smoothing function to reduce image noise and detail. Both the median and Gaussian blur methods are implemented using the OpenCV library (<xref rid="ref-6" ref-type="bibr">Bradski, 2000</xref>) and are typically used to smooth a grayscale image or a binary image that has been previously thresholded. Image blurring, while reducing detail, can help remove or reduce signal from background noise (e.g., edges in imaging cabinets), generally with minimal impact on larger structures of interest. Utilizing a rectangular neighborhood around a center pixel, ‘median_blur’ replaces each pixel in the neighborhood with the median value. Alternatively, ‘gaussian_blur’ determines the value of the central pixel by multiplying its and neighboring pixel values by a normalized kernel and then averaging these weighted values (i.e., image convolution) (<xref rid="ref-21" ref-type="bibr">Kaehler &amp; Bradski, 2016</xref>). The extent of image blurring can be modified by increasing (for greater blur) or decreasing the kernel size (which takes only odd numbers; commonly, 3 × 3) or by changing the standard deviation in the X and/or Y directions.</p>
      </sec>
      <sec>
        <title>Size marker normalization</title>
        <p>Images that are not collected from a consistent vantage point require one or more size markers as references for absolute or relative scale. The size marker function allows users to either detect a size marker within a user-defined region of interest or to select a specific region of interest to use as the size marker. The pixel area of the marker is returned as a value that can be used to normalize measurements to the same scale. For this module to function correctly we assume that the size marker stays in frame, is unobstructed, and is relatively consistent in position throughout a dataset, though some movement is allowed as long as the marker remains within the defined marker region of interest.</p>
      </sec>
      <sec>
        <title>Multi-plant detection</title>
        <p>There is growing interest among the PlantCV user community to process images with multiple plants grown in flats or trays, but PlantCV v1.0 was built to processes images containing single plants. The major challenge with analyzing multiple plants in an image is successfully identifying individual whole plants as distinct objects. Leaves or other plant parts can sometimes be detected as distinct contours from the rest of the plant and need to be grouped with other contours from the same plant to correctly form a single plant/target object. While creating multiple regions of interest (ROI) to demarcate each area containing an individual plant/target is an option, we developed two modules, ‘cluster_contours’ and ‘cluster_contours_split_img,’ that allow contours to be clustered and then parsed into multiple images without having to manually create multiple ROIs (<xref ref-type="fig" rid="fig-2">Fig. 2</xref>).</p>
        <fig id="fig-2" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.4088/fig-2</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Analysis of images containing multiple plants.</title>
            <p>New functions have been added to PlantCV v2 that enable individual plants from images containing multiple plants to be analyzed. The ‘cluster_contours’ function clusters contour objects using a flexible grid arrangement (approximate rows and columns defined by a user). (A) An image produced by ‘cluster_contours’ in debug mode highlights plants by their cluster group with unique colors on a sequential scale. The ‘cluster_contours_split_img’ function creates a new image for each cluster group. The resulting images of individual plants can be processed by standard PlantCV methods. (B) The ‘cluster_contours_split_img’ function was used to split the full image into individual plants. The shape of each plant was then analyzed with ‘analyze_objects’ and printed on a common image background.</p>
          </caption>
          <graphic xlink:href="peerj-05-4088-g002"/>
        </fig>
        <p>The ‘cluster_contours’ function takes as input: an image, the contours that need to be clustered, a number of rows, and a number of columns. Total image size is detected, and the rows and columns create a grid to serve as approximate ROIs to cluster the contours (<xref ref-type="fig" rid="fig-2">Fig. 2A</xref>). The number of rows and columns approximate the desired size of the grid cells. There does not need to be an object in each of the grid cells. Several functions were also added to aid the clustering function. The ‘rotate_img’ and ‘shift_img’ functions allow the image to be adjusted so objects are better aligned to a grid pattern.</p>
        <p>After objects are clustered, the ‘cluster_contour_split_img’ function splits images into the individual grid cells and outputs each as a new image so that there is a single clustered object per image. If there is no clustered object in a grid cell, no image is outputted. With the ‘cluster_contour_split_img’ function, a text file with genotype names can be included to add them to image names. The ‘cluster_contour_split_img’ function also checks that there are the same number of names as objects. If there is a conflict in the number of names and objects, a warning is printed and a correction is attempted. Alternatively, if the file option is not used, all of the object groups are labeled by position. Once images are split, they can be processed like single plant images using additional PlantCV tools (<xref ref-type="fig" rid="fig-2">Fig. 2B</xref>). See the online documentation for an example multi-plant imaging pipeline (<ext-link ext-link-type="uri" xlink:href="http://plantcv.readthedocs.io/en/latest/multi-plant_tutorial/">http://plantcv.readthedocs.io/en/latest/multi-plant_tutorial/</ext-link>).</p>
        <p>The current method for multi-plant identification in PlantCV is flexible but relies on a grid arrangement of plants, which is common for controlled-environment-grown plants. Future releases of PlantCV may incorporate additional strategies for detection and identification of plants, such as arrangement-independent <italic>K</italic>-means clustering approaches (<xref rid="ref-29" ref-type="bibr">Minervini, Abdelsamea &amp; Tsaftaris, 2014</xref>).</p>
      </sec>
      <sec>
        <title>Combined image processing</title>
        <p>The Bellwether Phenotyping Facility has both RGB visible light (VIS) and near-infrared (NIR) cameras, and images are captured ∼1 min apart (<xref rid="ref-11" ref-type="bibr">Fahlgren et al., 2015</xref>). Compared to VIS images, NIR images are grayscale with much less contrast between object and background. It can be difficult to segment plant material from NIR images directly, even with edge detection steps. Therefore, several functions were added to allow the plant binary mask that results from VIS image processing pipelines to be resized and used as a mask for NIR images. Combining VIS and NIR camera pipelines also has the added benefit of decreasing the number of steps necessary to process images from both camera types, thus increasing image processing throughput. The ‘get_nir’ function identifies the path of the NIR image that matches VIS image. The ‘get_nir’ function requires that the image naming scheme is consistent and that the matching image is in the same image directory. The ‘resize’ function then resizes the VIS plant mask in both the x and y directions to match the size of the NIR image. Resizing values are determined by measuring the same reference object in an example image taken from both VIS and NIR cameras (for example the width of the pot or pot carrier in each image). The ‘crop_position_mask’ function is then used to adjust the placement of the VIS mask over the NIR image and to crop/adjust the VIS mask so it is the same size as the NIR image. It is assumed that the pot position changes consistently between VIS and NIR image datasets. An example VIS/NIR dual pipeline to follow can be accessed online (<ext-link ext-link-type="uri" xlink:href="http://plantcv.readthedocs.io/en/latest/vis_nir_tutorial/">http://plantcv.readthedocs.io/en/latest/vis_nir_tutorial/</ext-link>).</p>
        <fig id="fig-3" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.4088/fig-3</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Leaf segmentation by a distance-based watershed transformation.</title>
            <p>The watershed segmentation function can be used to segment and estimate the number of objects in an image. For the three example images, the watershed segmentation function was used to estimate the number of leaves for <italic>Arabidopsis thaliana</italic> (estimated leaf count for top: 13, middle: 14, and bottom: eight). Images shown are the output from the ‘watershed_segmentation’ function (A, C, E) and the segmented plants (B, D, F).</p>
          </caption>
          <graphic xlink:href="peerj-05-4088-g003"/>
        </fig>
      </sec>
      <sec>
        <title>Object count estimation with watershed segmentation</title>
        <p>While segmentation and analysis of whole plants in images provides useful information about plant size and growth, a more detailed understanding of plant growth and development can be obtained by measuring individual plant organs. However, fully automated segmentation of individual organs such as leaves remains a challenge, due to issues such as occlusion (<xref rid="ref-35" ref-type="bibr">Scharr et al., 2016</xref>). Multiple methods for leaf segmentation have been proposed (<xref rid="ref-35" ref-type="bibr">Scharr et al., 2016</xref>), and in PlantCV v2 we have implemented a watershed segmentation approach. The ‘watershed_segmentation’ function can be used to estimate the number of leaves for plants where leaves are distinctly separate from other plant structures (e.g., <italic>A. thaliana</italic> leaves are separated by thin petioles; <xref ref-type="fig" rid="fig-3">Fig. 3</xref>). The inputs required are an image, an object mask, and a minimum distance to separate object peaks. The function uses the input mask to calculate a Euclidean distance map (<xref rid="ref-23" ref-type="bibr">Liberti et al., 2014</xref>). Marker peaks calculated from the distance map that meet the minimum distance setting are used in a watershed segmentation algorithm (<xref rid="ref-44" ref-type="bibr">Van der Walt et al., 2014</xref>) to segment and count the objects. Segmented objects are visualized in different colors, and the number of segmented objects is reported (<xref ref-type="fig" rid="fig-3">Fig. 3</xref>). An example of how the watershed segmentation method was used to assess the effect of water deficit stress on the number of leaves of <italic>A. thaliana</italic> plants can be found in <xref rid="ref-2" ref-type="bibr">Acosta-Gamboa et al. (2017)</xref>.</p>
      </sec>
      <sec>
        <title>Landmarking functions for morphometrics</title>
        <p>To extend PlantCV beyond quantification of size-based morphometric features, we developed several landmarking functions. Landmarks are generally geometric points located along the contours of a shape that correspond to homologous biological features that can be compared between subjects (<xref rid="ref-4" ref-type="bibr">Bookstein, 1991</xref>). Typical examples of landmarks include eyes between human subjects or suture joins in a skull. For a growing plant, potential landmarks include the tips of leaves and pedicel and branch angles. When specified <italic>a priori</italic>, landmarks should be assigned to provide adequate coverage of the shape morphology across a single dimensional plane (<xref rid="ref-4" ref-type="bibr">Bookstein, 1991</xref>). Additionally, the identification of landmark points should be repeatable and reliable across subjects while not altering their topological positions relative to other landmark positions (<xref rid="ref-4" ref-type="bibr">Bookstein, 1991</xref>). Type I landmarks provide the strongest support for homology because they are defined by underlying biological features, but it is problematic to assign Type I landmarks <italic>a priori</italic> when analyzing high-throughput plant imagery. To address this, PlantCV v2 contains functions to identify anatomical landmarks based upon the mathematical properties of object contours (Type II) and non-anatomical pseudo-landmarks/semilandmarks (Type III), as well as functions to rescale and analyze biologically relevant shape properties (<xref rid="ref-4" ref-type="bibr">Bookstein, 1991</xref>; <xref rid="ref-5" ref-type="bibr">Bookstein, 1997</xref>; <xref rid="ref-18" ref-type="bibr">Gunz, Mitteroecker &amp; Bookstein, 2005</xref>; <xref rid="ref-17" ref-type="bibr">Gunz &amp; Mitteroecker, 2013</xref>).</p>
        <p>The ‘acute’ function identifies Type II landmarks by implementing a pseudo-landmark identification algorithm that operates using a modified form of chain coding (<xref rid="ref-14" ref-type="bibr">Freeman, 1961</xref>). Unlike standard chain coding methods that attempt to capture the absolute shape of a contour, the acute method operates by measuring the angle between a pixel coordinate and two neighboring pixels on opposite sides of it that fall within a set distance, or window, along the length of the contour. The two neighboring points are used to calculate an angle score for the center pixel. When the angle score is calculated for each position along the length of a contour, clusters of acute points can be identified, which can be segmented out by applying an angle threshold. The middle position within each cluster of acute points is then identified for use as a pseudo-landmark (<xref ref-type="fig" rid="fig-4">Fig. 4A</xref>). The ability to subjectively adjust the window size used for generating angle scores also helps to tailor analyses for identifying points of interest that may differ in resolution. For example, an analysis of leaf data might utilize a larger window size to identify the tips of lobes whereas smaller window sizes would be able to capture more minute patterns such as individual leaf serrations. Further segmentation can also be done using the average pixel values output (pt_vals) for each pseudo-landmark, which estimates the mean pixel intensity within the convex hull of each acute region based on the binary mask used in the analysis. The average pixel value output allows for concave landmarks (e.g., leaf axils and grass ligules) and convex landmarks (e.g., leaf tips and apices) on a contour to be differentiated in downstream analyses. Additionally, PlantCV v2 includes the ‘acute_vertex’ function that uses the same chain code-based pseudo-landmark identification algorithm used in the ‘acute’ function except that it uses an adjustable local search space criteria to reduce the number of angle calculations, which speeds up landmark identification.</p>
        <fig id="fig-4" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.4088/fig-4</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Landmark-based analysis of plant shape in PlantCV.</title>
            <p>(A) Automatic identification of leaf tip landmarks using the ‘acute’ and ‘acute_vertex’ functions (blue dots). (B) Geometrically homologous semi/pseudo-landmarks across both the <italic>x</italic>- and <italic>y</italic>-axes. Semi/pseudo-landmarks identified by scanning the <italic>x</italic>-axis are denoted by light blue (top side of the contour), brown (bottom side of the contour), and light orange (centroid location of horizontal bins) dots. Semi/pseudo-landmarks identified by scanning the <italic>y</italic>-axis are denoted by dark blue (left side of the contour), pink (right side of the contour), and dark orange (centroid location of vertical bins) dots. The plant centroid is plotted larger in red. (C) A representation of the rescaled plant landmarks identified in panel (A). White points correspond to the leaf tips. The orange point is the location of the plant centroid. The blue point is the location of the plant centroid where the plant emerges from the soil. Red lines are the vertical distance from leaf tip points relative to the plant centroid. (D) Analysis of the average scaled vertical distance from each leaf tip to the centroid diverges in response to water limitation.</p>
          </caption>
          <graphic xlink:href="peerj-05-4088-g004"/>
        </fig>
        <p>For Type III landmarks, the ‘x_axis_pseudolandmarks’ and ‘y_axis_pseudolandmarks’ functions identify homologous points along a single dimension of an object (<italic>x</italic>-axis or <italic>y</italic>-axis) based on equidistant point locations within an object contour. The plant object is divided up into twenty equidistant bins, and the minimum and maximum extent of the object along the axis and the centroid of the object within each bin is calculated. These sixty points located along each axis possess the properties of semi/pseudo-landmark points (an equal number of reference points that are approximately geometrically homologous between subjects to be compared) that approximate the contour and shape of the object (<xref ref-type="fig" rid="fig-4">Fig. 4B</xref>). Such semi/pseudo-landmarking strategies have been utilized in cases where traditional homologous landmark points are difficult to assign or poorly represent the features of object shape (<xref rid="ref-5" ref-type="bibr">Bookstein, 1997</xref>; <xref rid="ref-18" ref-type="bibr">Gunz, Mitteroecker &amp; Bookstein, 2005</xref>; <xref rid="ref-17" ref-type="bibr">Gunz &amp; Mitteroecker, 2013</xref>).</p>
        <p>Frequently, comparison of shape attributes requires rescaling of landmark points to eliminate the influence of size on the relative position of landmark points. The landmark functions in PlantCV output untransformed point values that can either be directly input into morphometric programs in R (shapes (<xref rid="ref-8" ref-type="bibr">Dryden &amp; Mardia, 2016</xref>) or morpho (<xref rid="ref-36" ref-type="bibr">Schlager, 2017</xref>)) or uniformly rescaled to a 0-1 coordinate system using the PlantCV ‘scale_features’ function. The location of landmark points can be used to examine multidimensional growth curves for a broad variety of study systems and tissue types and can be used to compare properties of plant shape throughout development or in response to differences in plant growth environment. An example of one such application is the ‘landmark_reference_pt_dist’ function. This function estimates the vertical, horizontal, Euclidean distance, and angle of landmark points from two landmarks (centroid of the plant object and centroid localized to the base of the plant). Preliminary evidence from a water limitation experiment performed using a <italic>Setaria</italic> recombinant inbred population indicates that vertical distance from rescaled leaf tip points identified by the ‘acute_vertex’ function to the centroid is decreased in response to water limitation and thus may provide a proximity measurement of plant turgor pressure (<xref ref-type="fig" rid="fig-4">Figs. 4C</xref> and <xref ref-type="fig" rid="fig-4">4D</xref>).</p>
      </sec>
      <sec>
        <title>Two-class or multiclass naive Bayes classifier</title>
        <p>Pixel-level segmentation of images into two or more classes is not always straightforward using traditional image processing techniques. For example, two classes of features in an image may be visually distinct but similar enough in color that simple thresholding is not sufficient to separate the two groups. Furthermore, even with methods that adjust for inconsistencies between images (e.g., white balancing and auto-thresholding functions), inconsistent lighting conditions in a growth chamber, greenhouse, or field can still make bulk processing of images with a single workflow difficult. Methods that utilize machine learning techniques are a promising approach to tackle these and other phenotyping challenges (<xref rid="ref-29" ref-type="bibr">Minervini, Abdelsamea &amp; Tsaftaris, 2014</xref>; <xref rid="ref-38" ref-type="bibr">Singh et al., 2016</xref>; <xref rid="ref-42" ref-type="bibr">Ubbens &amp; Stavness, 2017</xref>; <xref rid="ref-3" ref-type="bibr">Atkinson et al., 2017</xref>; <xref rid="ref-34" ref-type="bibr">Pound et al., 2017</xref>). With PlantCV v2, we have started to integrate machine learning methods to detect features of interest (e.g., the plant), starting with a naive Bayes classifier (<xref rid="ref-1" ref-type="bibr">Abbasi &amp; Fahlgren, 2016</xref>). The naive Bayes classifier can be trained using two different approaches for two-class or multiclass (two or more) segmentation problems. During the training phase using the ‘plantcv-train.py’ script, pixel RGB values for each input class are converted to the hue, saturation and value (HSV) color space. Kernel density estimation (KDE) is used to calculate a probability density function (PDF) from a vector of values for each HSV channel from each class. The output PDFs are used to parameterize the naive Bayes classifier function (‘naive_bayes_classifier’), which can be used to replace the thresholding steps in a PlantCV pipeline. The ‘naive_bayes_classifer’ function uses these PDFs to calculate the probability (using Bayes’ theorem) that a given pixel is in each class. The output of the ‘naive_bayes_classifier’ is a binary image for each class where the pixels are white if the probability the pixel was in the given class was highest of all classes and is black otherwise. A tutorial of how to implement naive Bayes plant detection into an image processing pipeline is online (<ext-link ext-link-type="uri" xlink:href="http://plantcv.readthedocs.io/en/latest/machine_learning_tutorial/">http://plantcv.readthedocs.io/en/latest/machine_learning_tutorial/</ext-link>).</p>
        <p>For the two-class approach, the training dataset includes color images and corresponding binary masks where the background is black and the foreground (plant or other target object) is white. PlantCV can be used to generate binary masks for the training set using the standard image processing methods and the new ‘output_mask’ function. It is important for the training dataset to be representative of the larger dataset. For example, if there are large fluctuations in light intensity throughout the day or plant color throughout the experiment, the training dataset should try to cover the range of variation. A random sample of 10% of the foreground pixels and the same number background pixels are used to build the PDFs.</p>
        <p>To assess how well the two-class naive Bayes method identifies plant material in comparison to thresholding methods, we reanalyzed <italic>Setaria</italic> images (<xref rid="ref-11" ref-type="bibr">Fahlgren et al., 2015</xref>) using the naive Bayes classifier and compared the pixel area output to pipelines that utilize thresholding steps (<xref ref-type="fig" rid="fig-5">Fig. 5</xref>). We used 99 training images (14 top view and 85 side view images) from a total of 6,473 images. We found that the plant pixel area calculated by naive Bayes was highly correlated with that calculated from pipelines that use thresholding for both side-view images (<italic>R</italic><sup>2</sup> = 0.99; <xref ref-type="fig" rid="fig-5">Fig. 5A</xref>) and top-view images (<italic>R</italic><sup>2</sup> = 0.96; <xref ref-type="fig" rid="fig-5">Fig. 5B</xref>). Naive Bayes segmentation enabled use of pipelines that were both simpler (fewer steps) and more flexible: five new scripts were sufficient for processing the dataset (five categories of photo data), whereas nine threshold-based pipeline scripts had previously been required.</p>
        <fig id="fig-5" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.4088/fig-5</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Plant segmentation using a naive Bayes classifier.</title>
            <p>Correlation between plant area in pixels (px) detected using thresholding pipelines (<xref rid="ref-11" ref-type="bibr">Fahlgren et al., 2015</xref>) on the <italic>x</italic>-axis compared to plant area detected using a trained naive Bayes classifier on the <italic>y</italic>-axis. (A) Side-view images. (B) Top-view images.</p>
          </caption>
          <graphic xlink:href="peerj-05-4088-g005"/>
        </fig>
        <p>The multiclass naive Bayes approach requires a tab-delimited table for training where each column is a class (minimum two) and each cell is a comma-separated list of RGB pixel values from the column class. We currently use the Pixel Inspection Tool in ImageJ (<xref rid="ref-37" ref-type="bibr">Schneider, Rasband &amp; Eliceiri, 2012</xref>) to collect samples of pixel RGB values used to generate the training text file. As noted above for the two-class approach, it is important to adequately capture the variation in the image dataset for each class when generating the training text file to improve pixel classification. If images are consistent, only one image needs to be sampled for generating the training table; however, if they vary, several images may be needed. For complex backgrounds (or non-targeted objects), several classes may be required to capture all of the variation. Once the training table is generated, it is input into the ‘plantcv-train.py’ script to generate PDFs for each class. As an example, we used images of wheat leaves infected with wheat rust to collect pixel samples from four classes: non-plant background, unaffected leaf tissue, rust pustule, and chlorotic leaf tissue, and then used the naive Bayes classifier to segment the images into each class simultaneously (<xref ref-type="fig" rid="fig-6">Fig. 6</xref>). This method can likely be used for a variety of applications, such as identifying a plant under variable lighting conditions or quantifying specific areas of stress on a plant.</p>
        <fig id="fig-6" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.4088/fig-6</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Simultaneous segmentation of four feature groups using the naive Bayes classifier.</title>
            <p>An example of the naive Bayes classifier used to assign pixels into four classes: background, unaffected plant tissue, chlorotic tissue, and wheat stem rust pustules. (A) Probability density functions (PDFs) from the ‘plantcv-train.py’ script that show hue, saturation, and value color channel distributions of four classes estimated from training data. (B) Example of a classified image. Photo credit: Katie Liberatore and Shahryar Kianian. (C) Example of a merged pseudocolored image with pixels classified by the ‘naive_bayes_classifier’ as background (black), unaffected leaf tissue (green), chlorotic leaf tissue (blue), and pustules (red).</p>
          </caption>
          <graphic xlink:href="peerj-05-4088-g006"/>
        </fig>
        <p>In summary, the naive Bayes classifier offers several advantages over threshold-based segmentation: (1) two or more classes can be segmented simultaneously; (2) probabilistic segmentation can be more robust across images than fixed thresholds; and (3) classifier-based segmentation replaces multiple steps in threshold-based pipelines, reducing pipeline complexity.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="conclusions">
    <title>Conclusions</title>
    <p>The field of digital plant phenotyping is at an exciting stage of development where it is beginning to shift from a bottleneck to one that will have a positive impact on plant research, especially in agriculture. The Plant Image Analysis database currently lists over 150 tools that can be used for plant phenotyping (<ext-link ext-link-type="uri" xlink:href="http://www.plant-image-analysis.org/">http://www.plant-image-analysis.org/</ext-link>; <xref rid="ref-25" ref-type="bibr">Lobet, Draye &amp; Périlleux, 2013</xref>). Despite the abundance of software packages, long-term sustainability of individual projects may become an issue due to the lack of incentives for maintaining bioinformatics software developed in academia (<xref rid="ref-24" ref-type="bibr">Lobet, 2017</xref>). In a survey of corresponding authors of plant image analysis tools by Lobet, 60% either said the tool was no longer being maintained or did not respond (<xref rid="ref-24" ref-type="bibr">Lobet, 2017</xref>). To develop PlantCV as a sustainable project we have adopted an open, community-based development framework using GitHub as a central service for the organization of developer activities and the dissemination of information to users. We encourage contribution to the project by posting bug reports and issues, developing or revising analysis methods, adding or updating unit tests, writing documentation, and posting ideas for new features. We aim to periodically publish updates, such as the work presented here, to highlight the work of contributors to the PlantCV project.</p>
    <p>There are several areas where we envision future PlantCV development. <bold>Standards and interoperability</bold>: Improved interoperability of PlantCV with data providers and downstream analysis tools will require adoption of community-based standards for data and metadata (e.g., Minimum Information About a Plant Phenotyping Experiment; <xref rid="ref-7" ref-type="bibr">Ćwiek Kupczyńska et al., 2016</xref>). Improved interoperability will make it easier to develop standardized tools for statistical analysis of image processing results, both within the PlantCV project or with tools from other projects. <bold>New data sources</bold>: Handling and analysis of data from specialized cameras that measure three-dimensional structure or hyperspectral reflectance will require development or integration of additional methods into PlantCV. <bold>Machine learning</bold>: Our goal is to develop additional tools for machine learning and collection of training data. In some cases, where these methods can be implemented in a modular and reusable framework, they can be integrated directly into PlantCV. In other cases, PlantCV can be combined with new and existing tools. A recent example of this latter approach built on PlantCV, using its image preprocessing and segmentation functions alongside a modular framework for building convolutional neural networks (<xref rid="ref-42" ref-type="bibr">Ubbens &amp; Stavness, 2017</xref>). As noted throughout, we see great potential for modular tools such as PlantCV and we welcome community feedback.</p>
  </sec>
</body>
<back>
  <ack>
    <p>We would like to thank Melinda Darnell, Leonardo Chavez, Kevin Reilly, and the staff of both the Danforth Center Facilities and Support Services group and the Plant Growth Facility for careful maintenance of the Danforth Center phenotyping facilities. We thank Katie Liberatore and Shahryar Kianian for images of wheat (<italic>Triticum aestivum L.</italic>). We would also like to thank all of the other people who have given us input on the PlantCV project in person or on GitHub.</p>
  </ack>
  <sec sec-type="additional-information">
    <title>Additional Information and Declarations</title>
    <fn-group content-type="competing-interests">
      <title>Competing Interests</title>
      <fn id="conflict-1" fn-type="COI-statement">
        <p>Malia A. Gehan, Noah Fahlgren, Arash Abbasi, Jeffrey C. Berry, Steven T. Callen, Leonardo Chavez, Max J. Feldman, Kerrigan B. Gilbert, Steen Hoyer, Andy Lin, César Lizárraga, Michael Miller and Monica Tessman contributed to the research described while working at the Donald Danforth Plant Science Center, a 501(c)(3) nonprofit research institute. Suxing Liu and Argelia Lorence contributed to the research described while working at the University of Arkansas. John G. Hodge and Andrew N. Doust contributed to the research described while working at the University of Oklahoma. Eric Platon contributed to the research described while working as a founder and employee of Cosmos X. Tony Sax contributed to the research described while a full-time student at the Missouri University of Science and Technology.</p>
      </fn>
    </fn-group>
    <fn-group content-type="author-contributions">
      <title>Author Contributions</title>
      <fn id="contribution-1" fn-type="con">
        <p><xref ref-type="contrib" rid="author-1">Malia A. Gehan</xref>, <xref ref-type="contrib" rid="author-2">Noah Fahlgren</xref> and <xref ref-type="contrib" rid="author-8">Max J. Feldman</xref> conceived and designed the experiments, performed the experiments, analyzed the data, contributed reagents/materials/analysis tools, wrote the paper, prepared figures and/or tables, reviewed drafts of the paper.</p>
      </fn>
      <fn id="contribution-3" fn-type="con">
        <p><xref ref-type="contrib" rid="author-3">Arash Abbasi</xref>, <xref ref-type="contrib" rid="author-7">Andrew N. Doust</xref> and <xref ref-type="contrib" rid="author-10">John G. Hodge</xref> contributed reagents/materials/analysis tools, wrote the paper, reviewed drafts of the paper.</p>
      </fn>
      <fn id="contribution-4" fn-type="con">
        <p><xref ref-type="contrib" rid="author-4">Jeffrey C. Berry</xref>, <xref ref-type="contrib" rid="author-6">Leonardo Chavez</xref>, <xref ref-type="contrib" rid="author-12">Andy Lin</xref>, <xref ref-type="contrib" rid="author-14">César Lizárraga</xref>, <xref ref-type="contrib" rid="author-16">Michael Miller</xref>, <xref ref-type="contrib" rid="author-17">Eric Platon</xref>, <xref ref-type="contrib" rid="author-18">Monica Tessman</xref> and <xref ref-type="contrib" rid="author-19">Tony Sax</xref> contributed reagents/materials/analysis tools, reviewed drafts of the paper.</p>
      </fn>
      <fn id="contribution-5" fn-type="con">
        <p><xref ref-type="contrib" rid="author-5">Steven T. Callen</xref> analyzed the data, contributed reagents/materials/analysis tools, wrote the paper, reviewed drafts of the paper.</p>
      </fn>
      <fn id="contribution-9" fn-type="con">
        <p><xref ref-type="contrib" rid="author-9">Kerrigan B. Gilbert</xref> prepared figures and/or tables, reviewed drafts of the paper.</p>
      </fn>
      <fn id="contribution-11" fn-type="con">
        <p><xref ref-type="contrib" rid="author-11">J. Steen Hoyer</xref> performed the experiments, contributed reagents/materials/analysis tools, wrote the paper, reviewed drafts of the paper.</p>
      </fn>
      <fn id="contribution-13" fn-type="con">
        <p><xref ref-type="contrib" rid="author-13">Suxing Liu</xref> and <xref ref-type="contrib" rid="author-15">Argelia Lorence</xref> conceived and designed the experiments, contributed reagents/materials/analysis tools, wrote the paper, reviewed drafts of the paper.</p>
      </fn>
    </fn-group>
    <fn-group content-type="other">
      <title>Data Availability</title>
      <fn id="addinfo-1">
        <p>The following information was supplied regarding data availability:</p>
        <p>PlantCV is available on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/danforthcenter/plantcv">https://github.com/danforthcenter/plantcv</ext-link>. PlantCV v2.1 is archived on Zenodo at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.1035894">https://doi.org/10.5281/zenodo.1035894</ext-link>. Scripts used for image and statistical analysis are available on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/danforthcenter/plantcv-v2-paper">https://github.com/danforthcenter/plantcv-v2-paper</ext-link>.</p>
      </fn>
    </fn-group>
  </sec>
  <ref-list content-type="authoryear">
    <title>References</title>
    <ref id="ref-1">
      <label>Abbasi &amp; Fahlgren (2016)</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Abbasi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Fahlgren</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <year>2016</year>
        <article-title>Naive Bayes pixel-level plant segmentation</article-title>
        <conf-name>2016 IEEE western New York image and signal processing workshop (WNYISPW)</conf-name>
        <fpage>1</fpage>
        <lpage>4</lpage>
        <pub-id pub-id-type="doi">10.1109/WNYIPW.2016.7904790</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-2">
      <label>Acosta-Gamboa et al. (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Acosta-Gamboa</surname>
            <given-names>LM</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Langley</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Campbell</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Castro-Guerrero</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Mendoza-Cozatl</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Lorence</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>Moderate to severe water limitation differentially affects the phenome and ionome of Arabidopsis</article-title>
        <source>Functional Plant Biology</source>
        <volume>44</volume>
        <fpage>94</fpage>
        <lpage>106</lpage>
        <pub-id pub-id-type="doi">10.1071/FP16172</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-3">
      <label>Atkinson et al. (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Atkinson</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Lobet</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Noll</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Meyer</surname>
            <given-names>PE</given-names>
          </name>
          <name>
            <surname>Griffiths</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wells</surname>
            <given-names>DM</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>Combining semi-automated image analysis techniques with machine learning algorithms to accelerate large scale genetic studies</article-title>
        <source>GigaScience</source>
        <volume>6</volume>
        <fpage>1</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="doi">10.1093/gigascience/gix084</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-4">
      <label>Bookstein (1991)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Bookstein</surname>
            <given-names>FL</given-names>
          </name>
        </person-group>
        <year>1991</year>
        <source>Morphometric tools for landmark data</source>
        <publisher-name>Cambridge University Press</publisher-name>
        <publisher-loc>New York</publisher-loc>
      </element-citation>
    </ref>
    <ref id="ref-5">
      <label>Bookstein (1997)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Bookstein</surname>
            <given-names>FL</given-names>
          </name>
        </person-group>
        <year>1997</year>
        <source>Morphometric tools for landmark data: geometry and biology</source>
        <publisher-name>Cambridge University Press</publisher-name>
        <publisher-loc>New York</publisher-loc>
      </element-citation>
    </ref>
    <ref id="ref-6">
      <label>Bradski (2000)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bradski</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <year>2000</year>
        <article-title>The opencv library</article-title>
        <source>Doctor Dobbs Journal</source>
        <volume>25</volume>
        <fpage>120</fpage>
        <lpage>126</lpage>
      </element-citation>
    </ref>
    <ref id="ref-7">
      <label>Ćwiek Kupczyńska et al. (2016)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ćwiek Kupczyńska</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Altmann</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Arend</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Arnaud</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Cornut</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Fiorani</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Frohmberg</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Junker</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Klukas</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Lange</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Mazurek</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Nafissi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Neveu</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Van Oeveren</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Pommier</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Poorter</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Rocca-Serra</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Sansone</surname>
            <given-names>S-A</given-names>
          </name>
          <name>
            <surname>Scholz</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Van Schriek</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Seren</surname>
            <given-names>Ü</given-names>
          </name>
          <name>
            <surname>Usadel</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Weise</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kersey</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Krajewski</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <year>2016</year>
        <article-title>Measures for interoperability of phenotypic data: minimum information requirements and formatting</article-title>
        <source>Plant Methods</source>
        <volume>12</volume>
        <comment>Article 44</comment>
        <pub-id pub-id-type="doi">10.1186/s13007-016-0144-4</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-8">
      <label>Dryden &amp; Mardia (2016)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Dryden</surname>
            <given-names>IL</given-names>
          </name>
          <name>
            <surname>Mardia</surname>
            <given-names>KV</given-names>
          </name>
        </person-group>
        <year>2016</year>
        <source>Statistical shape analysis: with applications in R</source>
        <publisher-name>John Wiley &amp; Sons</publisher-name>
        <publisher-loc>Hoboken</publisher-loc>
      </element-citation>
    </ref>
    <ref id="ref-9">
      <label>Duarte (2015)</label>
      <element-citation publication-type="data">
        <person-group person-group-type="author">
          <name>
            <surname>Duarte</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <year>2015</year>
        <data-title>Notes on scientific computing for biomechanics and motor control</data-title>
        <source>GitHub repository</source>
        <uri xlink:href="https://github.com/demotu/BMC">https://github.com/demotu/BMC</uri>
      </element-citation>
    </ref>
    <ref id="ref-10">
      <label>Dudley &amp; Butte (2009)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dudley</surname>
            <given-names>JT</given-names>
          </name>
          <name>
            <surname>Butte</surname>
            <given-names>AJ</given-names>
          </name>
        </person-group>
        <year>2009</year>
        <article-title>A quick guide for developing effective bioinformatics programming skills</article-title>
        <source>PLOS Computational Biology</source>
        <volume>5</volume>
        <elocation-id>e1000589</elocation-id>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1000589</pub-id>
        <pub-id pub-id-type="pmid">20041221</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-11">
      <label>Fahlgren et al. (2015)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fahlgren</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Feldman</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Gehan</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Wilson</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Shyu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Bryant</surname>
            <given-names>DW</given-names>
          </name>
          <name>
            <surname>Hill</surname>
            <given-names>ST</given-names>
          </name>
          <name>
            <surname>McEntee</surname>
            <given-names>CJ</given-names>
          </name>
          <name>
            <surname>Warnasooriya</surname>
            <given-names>SN</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Ficor</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Turnipseed</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Gilbert</surname>
            <given-names>KB</given-names>
          </name>
          <name>
            <surname>Brutnell</surname>
            <given-names>TP</given-names>
          </name>
          <name>
            <surname>Carrington</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Mockler</surname>
            <given-names>TC</given-names>
          </name>
          <name>
            <surname>Baxter</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <year>2015</year>
        <article-title>A versatile phenotyping system and analytics platform reveals diverse temporal responses to water availability in Setaria</article-title>
        <source>Molecular Plant</source>
        <volume>8</volume>
        <fpage>1520</fpage>
        <lpage>1535</lpage>
        <pub-id pub-id-type="doi">10.1016/j.molp.2015.06.005</pub-id>
        <pub-id pub-id-type="pmid">26099924</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-12">
      <label>Fahlgren, Gehan &amp; Baxter (2015)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fahlgren</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Gehan</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Baxter</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <year>2015</year>
        <article-title>Lights, camera, action: high-throughput plant phenotyping is ready for a close-up</article-title>
        <source>Current Opinion in Plant Biology</source>
        <volume>24</volume>
        <fpage>93</fpage>
        <lpage>99</lpage>
        <pub-id pub-id-type="doi">10.1016/j.pbi.2015.02.006</pub-id>
        <pub-id pub-id-type="pmid">25733069</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-13">
      <label>Feldman et al. (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Feldman</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Paul</surname>
            <given-names>RE</given-names>
          </name>
          <name>
            <surname>Banan</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Barrett</surname>
            <given-names>JF</given-names>
          </name>
          <name>
            <surname>Sebastian</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yee</surname>
            <given-names>M-C</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lipka</surname>
            <given-names>AE</given-names>
          </name>
          <name>
            <surname>Brutnell</surname>
            <given-names>TP</given-names>
          </name>
          <name>
            <surname>Dinneny</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Leakey</surname>
            <given-names>ADB</given-names>
          </name>
          <name>
            <surname>Baxter</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>Time dependent genetic analysis links field and controlled environment phenotypes in the model C4 grass Setaria</article-title>
        <source>PLOS Genetics</source>
        <volume>13</volume>
        <elocation-id>e1006841</elocation-id>
        <pub-id pub-id-type="doi">10.1371/journal.pgen.1006841</pub-id>
        <pub-id pub-id-type="pmid">28644860</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-14">
      <label>Freeman (1961)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Freeman</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <year>1961</year>
        <article-title>On the encoding of arbitrary geometric configurations</article-title>
        <source>IRE Transactions on Electronic Computers</source>
        <volume>EC-10</volume>
        <fpage>260</fpage>
        <lpage>268</lpage>
        <pub-id pub-id-type="doi">10.1109/TEC.1961.5219197</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-15">
      <label>Furbank &amp; Tester (2011)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Furbank</surname>
            <given-names>RT</given-names>
          </name>
          <name>
            <surname>Tester</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <year>2011</year>
        <article-title>Phenomics—technologies to relieve the phenotyping bottleneck</article-title>
        <source>Trends in Plant Science</source>
        <volume>16</volume>
        <fpage>635</fpage>
        <lpage>644</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tplants.2011.09.005</pub-id>
        <pub-id pub-id-type="pmid">22074787</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-16">
      <label>Gonzalez &amp; Woods (2002)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Gonzalez</surname>
            <given-names>RC</given-names>
          </name>
          <name>
            <surname>Woods</surname>
            <given-names>RE</given-names>
          </name>
        </person-group>
        <year>2002</year>
        <source>Digital image processing</source>
        <publisher-name>Prentice Hall</publisher-name>
        <publisher-loc>Upper Saddle River</publisher-loc>
      </element-citation>
    </ref>
    <ref id="ref-17">
      <label>Gunz &amp; Mitteroecker (2013)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gunz</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Mitteroecker</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <year>2013</year>
        <article-title>Semilandmarks: a method for quantifying curves and surfaces</article-title>
        <source>Hystrix</source>
        <volume>24</volume>
        <fpage>103</fpage>
        <lpage>109</lpage>
        <pub-id pub-id-type="doi">10.4404/hystrix-24.1-6292</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-18">
      <label>Gunz, Mitteroecker &amp; Bookstein (2005)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Gunz</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Mitteroecker</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Bookstein</surname>
            <given-names>FL</given-names>
          </name>
        </person-group>
        <year>2005</year>
        <article-title>Semilandmarks in three dimensions</article-title>
        <source>Modern morphometrics in physical anthropology</source>
        <series>Developments in primatology: progress and prospects</series>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>Boston</publisher-loc>
        <fpage>73</fpage>
        <lpage>98</lpage>
      </element-citation>
    </ref>
    <ref id="ref-19">
      <label>Hunter (2007)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hunter</surname>
            <given-names>JD</given-names>
          </name>
        </person-group>
        <year>2007</year>
        <article-title>Matplotlib: A 2D graphics environment</article-title>
        <source>Computing in Science &amp; Engineering</source>
        <volume>9</volume>
        <fpage>90</fpage>
        <lpage>95</lpage>
        <pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-20">
      <label>Jones, Oliphant &amp; Peterson (2014)</label>
      <element-citation publication-type="software">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Oliphant</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Peterson</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <year>2014</year>
        <data-title>SciPy: open source scientific tools for Python</data-title>
        <uri xlink:href="http://www.scipy.org/">http://www.scipy.org/</uri>
      </element-citation>
    </ref>
    <ref id="ref-21">
      <label>Kaehler &amp; Bradski (2016)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Kaehler</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bradski</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <year>2016</year>
        <source>Learning OpenCV 3: computer vision in C++ with the OpenCV library</source>
        <publisher-name>O’Reilly Media</publisher-name>
        <publisher-loc>Sebastopol</publisher-loc>
      </element-citation>
    </ref>
    <ref id="ref-22">
      <label>Kluyver et al. (2016)</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Kluyver</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Ragan-Kelley</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Pérez</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Granger</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Bussonnier</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Frederic</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kelley</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Hamrick</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Grout</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Corlay</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ivanov</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Avila</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Abdalla</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Willing</surname>
            <given-names>C</given-names>
          </name>
          <collab>Jupyter Development Team</collab>
        </person-group>
        <year>2016</year>
        <article-title>Jupyter Notebooks—a publishing format for reproducible computational workflows</article-title>
        <conf-name>Positioning and power in academic publishing: players, agents and agendas: proceedings of the 20th international conference on electronic publishing</conf-name>
        <conf-sponsor>IOS Press</conf-sponsor>
        <conf-loc>Amsterdam</conf-loc>
        <person-group person-group-type="editor">
          <name>
            <surname>Loizides</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Schmidt</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <fpage>87</fpage>
        <lpage>90</lpage>
      </element-citation>
    </ref>
    <ref id="ref-23">
      <label>Liberti et al. (2014)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liberti</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Lavor</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Maculan</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Mucherino</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <year>2014</year>
        <article-title>Euclidean distance geometry and applications</article-title>
        <source>SIAM Review</source>
        <volume>56</volume>
        <fpage>3</fpage>
        <lpage>69</lpage>
        <pub-id pub-id-type="doi">10.1137/120875909</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-24">
      <label>Lobet (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lobet</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>Image analysis in plant sciences: publish then perish</article-title>
        <source>Trends in Plant Science</source>
        <volume>22</volume>
        <fpage>559</fpage>
        <lpage>566</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tplants.2017.05.002</pub-id>
        <pub-id pub-id-type="pmid">28571940</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-25">
      <label>Lobet, Draye &amp; Périlleux (2013)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lobet</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Draye</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Périlleux</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <year>2013</year>
        <article-title>An online database for plant image analysis software tools</article-title>
        <source>Plant Methods</source>
        <volume>9</volume>
        <comment>Article 38</comment>
        <pub-id pub-id-type="doi">10.1186/1746-4811-9-38</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-26">
      <label>Mangalam (2002)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mangalam</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <year>2002</year>
        <article-title>The Bio* toolkits—a brief overview</article-title>
        <source>Briefings in Bioinformatics</source>
        <volume>3</volume>
        <fpage>296</fpage>
        <lpage>302</lpage>
        <pub-id pub-id-type="doi">10.1093/bib/3.3.296</pub-id>
        <pub-id pub-id-type="pmid">12230038</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-27">
      <label>McKinney (2010)</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>McKinney</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <year>2010</year>
        <article-title>Data structures for statistical computing in python</article-title>
        <conf-name>Proceedings of the 9th Python in Science Conference</conf-name>
        <conf-sponsor>SciPy Austin, TX</conf-sponsor>
        <fpage>51</fpage>
        <lpage>56</lpage>
      </element-citation>
    </ref>
    <ref id="ref-28">
      <label>Millman &amp; Aivazis (2011)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Millman</surname>
            <given-names>KJ</given-names>
          </name>
          <name>
            <surname>Aivazis</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <year>2011</year>
        <article-title>Python for scientists and engineers</article-title>
        <source>Computing in Science &amp; Engineering</source>
        <volume>13</volume>
        <fpage>9</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1109/MCSE.2011.36</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-29">
      <label>Minervini, Abdelsamea &amp; Tsaftaris (2014)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Minervini</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Abdelsamea</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>Tsaftaris</surname>
            <given-names>SA</given-names>
          </name>
        </person-group>
        <year>2014</year>
        <article-title>Image-based plant phenotyping with incremental learning and active contours</article-title>
        <source>Ecological Informatics</source>
        <volume>23</volume>
        <fpage>35</fpage>
        <lpage>48</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ecoinf.2013.07.004</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-30">
      <label>Oliphant (2007)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Oliphant</surname>
            <given-names>TE</given-names>
          </name>
        </person-group>
        <year>2007</year>
        <article-title>Python for scientific computing</article-title>
        <source>Computing in Science &amp; Engineering</source>
        <volume>9</volume>
        <fpage>10</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="doi">10.1109/MCSE.2007.58</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-31">
      <label>Otsu (1979)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Otsu</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <year>1979</year>
        <article-title>A threshold selection method from gray-level histograms</article-title>
        <source>IEEE Transactions on Systems, Man, and Cybernetics</source>
        <volume>9</volume>
        <fpage>62</fpage>
        <lpage>66</lpage>
        <pub-id pub-id-type="doi">10.1109/TSMC.1979.4310076</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-32">
      <label>Pauli et al. (2016)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pauli</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Chapman</surname>
            <given-names>SC</given-names>
          </name>
          <name>
            <surname>Bart</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Topp</surname>
            <given-names>CN</given-names>
          </name>
          <name>
            <surname>Lawrence-Dill</surname>
            <given-names>CJ</given-names>
          </name>
          <name>
            <surname>Poland</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Gore</surname>
            <given-names>MA</given-names>
          </name>
        </person-group>
        <year>2016</year>
        <article-title>The quest for understanding phenotypic variation via integrated approaches in the field environment</article-title>
        <source>Plant Physiology</source>
        <volume>172</volume>
        <fpage>622</fpage>
        <lpage>634</lpage>
        <pub-id pub-id-type="doi">10.1104/pp.16.00592</pub-id>
        <pub-id pub-id-type="pmid">27482076</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-33">
      <label>Perez-Riverol et al. (2016)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Perez-Riverol</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Gatto</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Sachsenberg</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Uszkoreit</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Leprevost F da</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Fufezan</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ternent</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Eglen</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Katz</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Pollard</surname>
            <given-names>TJ</given-names>
          </name>
          <name>
            <surname>Konovalov</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Flight</surname>
            <given-names>RM</given-names>
          </name>
          <name>
            <surname>Blin</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Vizcaíno</surname>
            <given-names>JA</given-names>
          </name>
        </person-group>
        <year>2016</year>
        <article-title>Ten simple rules for taking advantage of Git and GitHub</article-title>
        <source>PLOS Computational Biology</source>
        <volume>12</volume>
        <elocation-id>e1004947</elocation-id>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1004947</pub-id>
        <pub-id pub-id-type="pmid">27415786</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-34">
      <label>Pound et al. (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pound</surname>
            <given-names>MP</given-names>
          </name>
          <name>
            <surname>Atkinson</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Townsend</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Wilson</surname>
            <given-names>MH</given-names>
          </name>
          <name>
            <surname>Griffiths</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Jackson</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>Bulat</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tzimiropoulos</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Wells</surname>
            <given-names>DM</given-names>
          </name>
          <name>
            <surname>Murchie</surname>
            <given-names>EH</given-names>
          </name>
          <name>
            <surname>Pridmore</surname>
            <given-names>TP</given-names>
          </name>
          <name>
            <surname>French</surname>
            <given-names>AP</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>Deep machine learning provides state-of-the-art performance in image-based plant phenotyping</article-title>
        <source>GigaScience</source>
        <volume>6</volume>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1093/gigascience/gix083</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-35">
      <label>Scharr et al. (2016)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scharr</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Minervini</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>French</surname>
            <given-names>AP</given-names>
          </name>
          <name>
            <surname>Klukas</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Kramer</surname>
            <given-names>DM</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Luengo</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Pape</surname>
            <given-names>J-M</given-names>
          </name>
          <name>
            <surname>Polder</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Vukadinovic</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Yin</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Tsaftaris</surname>
            <given-names>SA</given-names>
          </name>
        </person-group>
        <year>2016</year>
        <article-title>Leaf segmentation in plant phenotyping: a collation study</article-title>
        <source>Machine Vision and Applications</source>
        <volume>27</volume>
        <fpage>585</fpage>
        <lpage>606</lpage>
        <pub-id pub-id-type="doi">10.1007/s00138-015-0737-3</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-36">
      <label>Schlagerr (2017)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Schlager</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>Morpho and Rvcg—shape analysis in R</article-title>
        <source>Statistical shape and deformation analysis</source>
        <publisher-name>Academic Press</publisher-name>
        <publisher-loc>San Diego</publisher-loc>
        <person-group person-group-type="editor">
          <name>
            <surname>Zheng</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Szekely</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <fpage>217</fpage>
        <lpage>256</lpage>
      </element-citation>
    </ref>
    <ref id="ref-37">
      <label>Schneider, Rasband &amp; Eliceiri (2012)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schneider</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Rasband</surname>
            <given-names>WS</given-names>
          </name>
          <name>
            <surname>Eliceiri</surname>
            <given-names>KW</given-names>
          </name>
        </person-group>
        <year>2012</year>
        <article-title>NIH Image to ImageJ: 25 years of image analysis</article-title>
        <source>Nature Methods</source>
        <volume>9</volume>
        <fpage>671</fpage>
        <lpage>675</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2089</pub-id>
        <pub-id pub-id-type="pmid">22930834</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-38">
      <label>Singh et al. (2016)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Singh</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ganapathysubramanian</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>AK</given-names>
          </name>
          <name>
            <surname>Sarkar</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <year>2016</year>
        <article-title>Machine learning for high-throughput stress phenotyping in plants</article-title>
        <source>Trends in Plant Science</source>
        <volume>21</volume>
        <fpage>110</fpage>
        <lpage>124</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tplants.2015.10.015</pub-id>
        <pub-id pub-id-type="pmid">26651918</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-39">
      <label>R Core Team (2017)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <collab>R Core Team</collab>
        </person-group>
        <year>2017</year>
        <data-title>R: a language and environment for statistical computing</data-title>
        <uri xlink:href="https://www.R-project.org/">https://www.R-project.org/</uri>
        <publisher-loc>Vienna</publisher-loc>
        <publisher-name>the R Foundation for Statistical Computing</publisher-name>
      </element-citation>
    </ref>
    <ref id="ref-40">
      <label>RStudio Team (2016)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <collab>RStudio Team</collab>
        </person-group>
        <year>2016</year>
        <data-title>RStudio: integrated development environment for R</data-title>
        <publisher-name>RStudio, Inc</publisher-name>
        <publisher-loc>Boston</publisher-loc>
        <uri xlink:href="https://www.rstudio.com/products/rstudio/">https://www.rstudio.com/products/rstudio/</uri>
      </element-citation>
    </ref>
    <ref id="ref-41">
      <label>Tovar et al. (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tovar</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hoyer</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tielking</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Callen</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Castillo</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Tessman</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Fahlgren</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Carrington</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Nusinow</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Gehan</surname>
            <given-names>MA</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>Raspberry Pi powered imaging for plant phenotyping</article-title>
        <source>BioRxiv</source>
        <pub-id pub-id-type="doi">10.1101/183822</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-42">
      <label>Ubbens &amp; Stavness (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ubbens</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Stavness</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>Deep plant phenomics: a deep learning platform for complex plant phenotyping tasks</article-title>
        <source>Frontiers in Plant Science</source>
        <volume>8</volume>
        <comment>Article 1190</comment>
        <pub-id pub-id-type="doi">10.3389/fpls.2017.01190</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-43">
      <label>Van der Walt, Colbert &amp; Varoquaux (2011)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Van der Walt</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Colbert</surname>
            <given-names>SC</given-names>
          </name>
          <name>
            <surname>Varoquaux</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <year>2011</year>
        <article-title>The NumPy array: a structure for efficient numerical computation</article-title>
        <source>Computing in Science &amp; Engineering</source>
        <volume>13</volume>
        <fpage>22</fpage>
        <lpage>30</lpage>
        <pub-id pub-id-type="doi">10.1109/MCSE.2011.37</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-44">
      <label>Van der Walt et al. (2014)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Van der Walt</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schönberger</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Nunez-Iglesias</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Boulogne</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Warner</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>Yager</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Gouillart</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>T</given-names>
          </name>
          <collab>scikit-image contributors</collab>
        </person-group>
        <year>2014</year>
        <article-title>scikit-image: image processing in Python</article-title>
        <source>PeerJ</source>
        <volume>2</volume>
        <elocation-id>e453</elocation-id>
        <pub-id pub-id-type="doi">10.7717/peerj.453</pub-id>
        <pub-id pub-id-type="pmid">25024921</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-45">
      <label>Wickham (2009)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Wickham</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <year>2009</year>
        <data-title>ggplot2: elegant graphics for data analysis</data-title>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>New York</publisher-loc>
      </element-citation>
    </ref>
    <ref id="ref-46">
      <label>Wilson et al. (2014)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wilson</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Aruliah</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Brown</surname>
            <given-names>CT</given-names>
          </name>
          <name>
            <surname>Chue Hong</surname>
            <given-names>NP</given-names>
          </name>
          <name>
            <surname>Davis</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Guy</surname>
            <given-names>RT</given-names>
          </name>
          <name>
            <surname>Haddock</surname>
            <given-names>SHD</given-names>
          </name>
          <name>
            <surname>Huff</surname>
            <given-names>KD</given-names>
          </name>
          <name>
            <surname>Mitchell</surname>
            <given-names>IM</given-names>
          </name>
          <name>
            <surname>Plumbley</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Waugh</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>White</surname>
            <given-names>EP</given-names>
          </name>
          <name>
            <surname>Wilson</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <year>2014</year>
        <article-title>Best practices for scientific computing</article-title>
        <source>PLOS Biology</source>
        <volume>12</volume>
        <elocation-id>e1001745</elocation-id>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.1001745</pub-id>
        <pub-id pub-id-type="pmid">24415924</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-47">
      <label>Zack, Rogers &amp; Latp (1977)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zack</surname>
            <given-names>GW</given-names>
          </name>
          <name>
            <surname>Rogers</surname>
            <given-names>WE</given-names>
          </name>
          <name>
            <surname>Latp</surname>
            <given-names>SA</given-names>
          </name>
        </person-group>
        <year>1977</year>
        <article-title>Automatic measurement of sister chromatid exchange frequency</article-title>
        <source>Journal of Histochemistry and Cytochemistry</source>
        <volume>25</volume>
        <fpage>741</fpage>
        <lpage>753</lpage>
        <pub-id pub-id-type="doi">10.1177/25.7.70454</pub-id>
        <pub-id pub-id-type="pmid">70454</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
