<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinform Adv</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinform Adv</journal-id>
    <journal-id journal-id-type="publisher-id">bioadv</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics Advances</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2635-0041</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10115468</article-id>
    <article-id pub-id-type="doi">10.1093/bioadv/vbad042</article-id>
    <article-id pub-id-type="publisher-id">vbad042</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Structural Bioinformatics</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SAINT-Angle: self-attention augmented inception-inside-inception network and transfer learning improve protein backbone torsion angle prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Hasan</surname>
          <given-names>A K M Mehedi</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, Bangladesh University of Engineering and Technology</institution>, Dhaka 1205, <country country="BD">Bangladesh</country></aff>
        <xref rid="vbad042-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ahmed</surname>
          <given-names>Ajmain Yasar</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, Bangladesh University of Engineering and Technology</institution>, Dhaka 1205, <country country="BD">Bangladesh</country></aff>
        <xref rid="vbad042-FM1" ref-type="author-notes"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mahbub</surname>
          <given-names>Sazan</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, Bangladesh University of Engineering and Technology</institution>, Dhaka 1205, <country country="BD">Bangladesh</country></aff>
        <aff><institution>Department of Computer Science, University of Maryland</institution>, College Park, MD 20742, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-9887-4456</contrib-id>
        <name>
          <surname>Rahman</surname>
          <given-names>M Saifur</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, Bangladesh University of Engineering and Technology</institution>, Dhaka 1205, <country country="BD">Bangladesh</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0002-5640-0615</contrib-id>
        <name>
          <surname>Bayzid</surname>
          <given-names>Md Shamsuzzoha</given-names>
        </name>
        <aff><institution>Department of Computer Science and Engineering, Bangladesh University of Engineering and Technology</institution>, Dhaka 1205, <country country="BD">Bangladesh</country></aff>
        <xref rid="vbad042-cor1" ref-type="corresp"/>
        <!--shams_bayzid@cse.buet.ac.bd-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Gromiha</surname>
          <given-names>Michael</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="vbad042-cor1">To whom correspondence should be addressed. <email>shams_bayzid@cse.buet.ac.bd</email></corresp>
      <fn id="vbad042-FM1">
        <p>The authors wish it to be known that, in their opinion, A K M Mehedi Hasan and Ajmain Yasar Ahmed authors should be regarded as Joint First Authors.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-04-05">
      <day>05</day>
      <month>4</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>05</day>
      <month>4</month>
      <year>2023</year>
    </pub-date>
    <volume>3</volume>
    <issue>1</issue>
    <elocation-id>vbad042</elocation-id>
    <history>
      <date date-type="received">
        <day>29</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>21</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>02</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>04</day>
        <month>4</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>19</day>
        <month>4</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="vbad042.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Protein structure provides insight into how proteins interact with one another as well as their functions in living organisms. Protein backbone torsion angles (<inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula> and <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>) prediction is a key sub-problem in predicting protein structures. However, reliable determination of backbone torsion angles using conventional experimental methods is slow and expensive. Therefore, considerable effort is being put into developing computational methods for predicting backbone angles.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We present SAINT-Angle, a highly accurate method for predicting protein backbone torsion angles using a self-attention-based deep learning network called SAINT, which was previously developed for the protein secondary structure prediction. We extended and improved the existing SAINT architecture as well as used transfer learning to predict backbone angles. We compared the performance of SAINT-Angle with the state-of-the-art methods through an extensive evaluation study on a collection of benchmark datasets, namely, TEST2016, TEST2018, TEST2020-HQ, CAMEO and CASP. The experimental results suggest that our proposed self-attention-based network, together with transfer learning, has achieved notable improvements over the best alternate methods.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>SAINT-Angle is freely available as an open-source project at <ext-link xlink:href="https://github.com/bayzidlab/SAINT-Angle" ext-link-type="uri">https://github.com/bayzidlab/SAINT-Angle</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics Advances</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>BUET</institution>
            <institution-id institution-id-type="DOI">10.13039/501100009500</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>2021-01-016</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Proteins are responsible for various functions in cells and their functions are usually determined by their 3D structures. However, the experimental determination of protein structures using X-ray crystallography, cryogenic electron microscopy (cryo-EM) and nuclear magnetic resonance spectroscopy is costly and time- and labour-intensive (<xref rid="vbad042-B23" ref-type="bibr">Jiang <italic toggle="yes">et al.</italic>, 2017</xref>). Therefore, developing efficient computational approaches for determining protein structures has been gaining increasing attention from the scientific community (<xref rid="vbad042-B2" ref-type="bibr">AlQuraishi, 2019</xref>; <xref rid="vbad042-B15" ref-type="bibr">Greener <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="vbad042-B39" ref-type="bibr">Senior <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="vbad042-B54" ref-type="bibr">Xu, 2019</xref>; <xref rid="vbad042-B53" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2020</xref>). The backbone torsion angles [the measurements of the residue-wise torsion (<xref rid="vbad042-B34" ref-type="bibr">Ramachandran <italic toggle="yes">et al.</italic>, 1963</xref>)] play a critical role in protein structure prediction and investigating protein folding (<xref rid="vbad042-B1" ref-type="bibr">Adhikari <italic toggle="yes">et al.</italic>, 2012</xref>; <xref rid="vbad042-B14" ref-type="bibr">Gao <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="vbad042-B45" ref-type="bibr">Tian <italic toggle="yes">et al.</italic>, 2020</xref>). Therefore, protein structure prediction is often divided into smaller and more doable sub-problems (<xref rid="vbad042-B20" ref-type="bibr">Heffernan <italic toggle="yes">et al.</italic>, 2017</xref>) such as backbone torsion angles prediction. As a result, accurate prediction of torsion angles can significantly advance our understanding of the 3D structures of proteins.</p>
    <p>Given the growing availability of protein databases and rapid advances in machine learning (ML) methods (especially, the deep learning techniques), application of ML techniques to leverage the available data in accurate prediction of backbone angles has gained significant attention.</p>
    <p>Earlier ML-based methods used neural network (<xref rid="vbad042-B52" ref-type="bibr">Wu and Zhang, 2008</xref>), support vector machine (SVM) (<xref rid="vbad042-B52" ref-type="bibr">Wu and Zhang, 2008</xref>) and hidden Markov model (HMM) (<xref rid="vbad042-B5" ref-type="bibr">Bystroff <italic toggle="yes">et al.</italic>, 2000</xref>; <xref rid="vbad042-B25" ref-type="bibr">Karchin <italic toggle="yes">et al.</italic>, 2003</xref>) to predict discrete states of torsion angles <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula> and <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>. Real-SPINE (<xref rid="vbad042-B9" ref-type="bibr">Dor and Zhou, 2007</xref>) leveraged an integrated system of neural networks to predict the real values of dihedral angles.</p>
    <p>Several deep learning-based techniques have recently been developed that can predict backbone torsion angles with a reasonable accuracy. SPIDER2 (<xref rid="vbad042-B19" ref-type="bibr">Heffernan <italic toggle="yes">et al.</italic>, 2015</xref>) used iterative neural network to predict the backbone torsion angles, while SPIDER3 (<xref rid="vbad042-B20" ref-type="bibr">Heffernan <italic toggle="yes">et al.</italic>, 2017</xref>) leveraged the bidirectional recurrent neural network (BiRNN) (<xref rid="vbad042-B38" ref-type="bibr">Schuster and Paliwal, 1997</xref>) to capture the long-range interactions among amino acid residues in a protein molecule. MUFOLD (<xref rid="vbad042-B13" ref-type="bibr">Fang <italic toggle="yes">et al.</italic>, 2018b</xref>) used deep residual inception models (<xref rid="vbad042-B44" ref-type="bibr">Szegedy <italic toggle="yes">et al.</italic>, 2017</xref>) to measure the short-range and long-range interactions among different amino acid residues. Similar to SPIDER3, NetSurfP-2.0 (<xref rid="vbad042-B27" ref-type="bibr">Klausen <italic toggle="yes">et al.</italic>, 2019</xref>) used the bidirectional recurrent neural network to capture the long-range interactions. Some studies also emphasized on input feature selection. RaptorX-Angle (<xref rid="vbad042-B14" ref-type="bibr">Gao <italic toggle="yes">et al.</italic>, 2018</xref>) took advantage of both discrete and continuous representation of the backbone torsion angles and explored the efficacy of different types of features, such as position-specific scoring matrix (PSSM) using PSI-BLAST (<xref rid="vbad042-B3" ref-type="bibr">Altschul <italic toggle="yes">et al.</italic>, 1997</xref>) and position-specific frequency matrix (PSFM) using HHpred (<xref rid="vbad042-B36" ref-type="bibr">Remmert <italic toggle="yes">et al.</italic>, 2012</xref>; <xref rid="vbad042-B43" ref-type="bibr">Söding, 2005</xref>).</p>
    <p>SPOT-1D (<xref rid="vbad042-B17" ref-type="bibr">Hanson <italic toggle="yes">et al.</italic>, 2019</xref>) is an ensemble of nine base models based on the architecture of long short-term memory (LSTM) (<xref rid="vbad042-B21" ref-type="bibr">Hochreiter and Schmidhuber, 1997</xref>), bidirectional recurrent neural network (BiRNN) (<xref rid="vbad042-B38" ref-type="bibr">Schuster and Paliwal, 1997</xref>) and deep residual network (ResNet) (<xref rid="vbad042-B18" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2016</xref>). They leveraged the predicted contact-map information produced by SPOT-Contact (<xref rid="vbad042-B16" ref-type="bibr">Hanson <italic toggle="yes">et al.</italic>, 2018</xref>) to improve the performance. OPUS-TASS (<xref rid="vbad042-B53" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2020</xref>) is another state-of-the-art method, which is an ensemble of 11 base models based on convolutional neural network (CNN) modules (<xref rid="vbad042-B28" ref-type="bibr">LeCun <italic toggle="yes">et al.</italic>, 1998</xref>), bidirectional long short-term memory (BiLSTM) modules (<xref rid="vbad042-B21" ref-type="bibr">Hochreiter and Schmidhuber, 1997</xref>) and modified Transformer modules (<xref rid="vbad042-B48" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic>, 2017</xref>). OPUS-TASS is a multi-task learning model (<xref rid="vbad042-B29" ref-type="bibr">Lounici <italic toggle="yes">et al.</italic>, 2009</xref>), maximizing the generalization of neural network, in which the same network was trained for six different prediction tasks. Accuracy of the backbone torsion angles prediction does not rely only on the architecture used in deep learning-based methods but also on the input features extracted from protein sequences. PSSM profiles, HMM profiles (<xref rid="vbad042-B36" ref-type="bibr">Remmert <italic toggle="yes">et al.</italic>, 2012</xref>), physicochemical properties (PP) (<xref rid="vbad042-B32" ref-type="bibr">Meiler <italic toggle="yes">et al.</italic>, 2001</xref>) and amino acid (AA) labels of the residues in proteins are widely used features in predicting protein properties. Recently, the authors of ESIDEN (<xref rid="vbad042-B55" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>) introduced four evolutionary signatures as novel features, namely relative entropy (RE), degree of conservation (DC), position-specific substitution probabilities (PSSP) and Ramachandran basin potential (RBP). ESIDEN is an evolutionary signatures-driven deep neural network developed based on the architecture of long short-term memory (LSTM) and bidirectional long short-term memory (BiLSTM) and achieved notable improvements over other alternate methods. Protein language models, motivated by natural language processing (NLP), have lately been introduced to extract features from protein primary sequence for downstream analyses. The authors of SPOT-1D-LM (<xref rid="vbad042-B42" ref-type="bibr">Singh et al., 2022b</xref>) explored two of the contemporary protein language models ProtTrans (<xref rid="vbad042-B11" ref-type="bibr">Elnaggar <italic toggle="yes">et al</italic>., 2021</xref>) and ESM-1b (<xref rid="vbad042-B35" ref-type="bibr">Rao <italic toggle="yes">et al.</italic>, 2021</xref>) to extract features from protein sequence and developed a method to predict 1D structural properties of proteins.</p>
    <p>In this study, we present SAINT-Angle, a highly accurate method for protein backbone torsion angle prediction, which is built on our previously proposed architecture of self-attention augmented inception-inside-inception network (SAINT) (<xref rid="vbad042-B46" ref-type="bibr">Uddin <italic toggle="yes">et al.</italic>, 2020</xref>) for protein secondary structure (SS) prediction. We adapted the SAINT architecture for torsion angle prediction and further augmented the basic architecture of SAINT by incorporating the deep residual network (<xref rid="vbad042-B18" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2016</xref>). We present a successful utilization of transfer-learning from pretrained transformer-like models by ProtTrans (<xref rid="vbad042-B11" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic>, 2021</xref>) in backbone angle prediction. SAINT-Angle is capable of capturing both short- and long-range interactions among amino acid residues. SAINT-Angle was compared with the best alternate methods on a collection of widely used benchmark datasets, namely TEST2016 (<xref rid="vbad042-B16" ref-type="bibr">Hanson <italic toggle="yes">et al.</italic>, 2018</xref>), TEST2018 (<xref rid="vbad042-B17" ref-type="bibr">Hanson <italic toggle="yes">et al.</italic>, 2019</xref>), TEST2020-HQ (<xref rid="vbad042-B42" ref-type="bibr">Singh et al., 2022b</xref>), CAMEO (<xref rid="vbad042-B55" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>) and CASP (<xref rid="vbad042-B46" ref-type="bibr">Uddin <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="vbad042-B55" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>). SAINT-Angle significantly outperformed other competing methods and achieved the best known <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula> and <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula> prediction accuracy.</p>
  </sec>
  <sec id="sec2">
    <title>2 Approach</title>
    <sec id="sec2.1">
      <title>2.1 Feature representation</title>
      <p>SAINT-Angle takes a protein sequence feature vector <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mn>…..</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> as input, where <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the vector corresponding to the <italic toggle="yes">i</italic>th residue of that protein. For each of the residue, SAINT-Angle has four regression nodes which predict <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mtext>sin</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>ϕ</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mtext>cos</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>ϕ</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mtext>sin</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>ψ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mtext>cos</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>ψ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, respectively. SAINT-Angle uses three different sets of features which we call (i) <italic toggle="yes">Base features</italic>, (ii) <italic toggle="yes">ProtTrans features</italic> and (iii) <italic toggle="yes">Window features</italic>.</p>
      <p>The <italic toggle="yes">Base feature</italic> class consists of a feature vector of length 57 for each residue. It contains features from PSSM profiles, HMM profiles and physicochemical properties (PCP) (<xref rid="vbad042-B32" ref-type="bibr">Meiler <italic toggle="yes">et al.</italic>, 2001</xref>). We ran PSI-BLAST (<xref rid="vbad042-B3" ref-type="bibr">Altschul <italic toggle="yes">et al.</italic>, 1997</xref>) against the <italic toggle="yes">Uniref</italic>90 (<xref rid="vbad042-B47" ref-type="bibr">UniProt Consortium, 2007</xref>) database with an inclusion threshold of 0.001 and 3 iterations to generate PSSM profiles. We used HHblits (<xref rid="vbad042-B36" ref-type="bibr">Remmert <italic toggle="yes">et al.</italic>, 2012</xref>) using the default parameters against the <italic toggle="yes">uniprot20_2013_03</italic> sequence database to generate the HMM profiles. HHblits also generates seven transition probabilities and three local alignment diversity values, which we used as features as well. Seven physicochemical properties of each amino acid [steric parameters (graph-shape index), polarizability, normalized van der Waals volume, hydrophobicity, isoelectric point, helix probability and sheet probability] were obtained from <xref rid="vbad042-B32" ref-type="bibr">Meiler <italic toggle="yes">et al.</italic> (2001)</xref>. Thus, the dimension of our base feature class for each residue is 57 as this is the concatenation of 20 features from PSSM, 30 features from HMM and 7 features from physicochemical properties.</p>
      <p>The <italic toggle="yes">ProtTrans features</italic>, generated by the pretrained language model for proteins developed by <xref rid="vbad042-B11" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic> (2021)</xref>, consist of a feature vector of length 1024 for each residue. <xref rid="vbad042-B11" ref-type="bibr">Elnaggar <italic toggle="yes">et al.</italic> (2021)</xref> trained two auto regression language models [Transformer-XL (<xref rid="vbad042-B7" ref-type="bibr">Dai <italic toggle="yes">et al.</italic>, 2019</xref>) and XLNet (<xref rid="vbad042-B56" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2019</xref>)] on data containing up to 393 billion amino acids from 2.1 billion protein sequences in a self-supervised manner, considering each residue as a ‘word’ [similar to language modeling in natural language processing (<xref rid="vbad042-B8" ref-type="bibr">Devlin et al., 2019</xref>)]. Features extracted from ProtT5-XL-UniRef50 language model were used in our experiments because, in general, these features from protein language models, including ProtTrans and ESM-1b (<xref rid="vbad042-B35" ref-type="bibr">Rao <italic toggle="yes">et al.</italic>, 2021</xref>), were shown to contribute to improving the performance of methods on residue-level prediction tasks (<xref rid="vbad042-B31" ref-type="bibr">Mahbub and Bayzid, 2022</xref>; <xref rid="vbad042-B41" ref-type="bibr">Singh et al., 2022a</xref>,<xref rid="vbad042-B42" ref-type="bibr">b</xref>). Other suitable protein language models, apart from ProtT5-XL-UniRef50, may also be used because our proposed architecture is agnostic about these language models. ProtT5-XL-UniRef50 language model generates a sequence of embedding vectors <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>prottrans</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo> </mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>prottrans</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1024</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> for each residue <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p>
      <p><italic toggle="yes">Window features</italic> are generated by windowing the predicted contact information as was done in SPOT-1D and was subsequently used in SAINT. We used SPOT-Contact to generate the contact-maps. We varied the window lengths (the number of preceding or succeeding residues whose pairwise contact information were extracted for a target residue) to generate different dimensional features. We used three different window lengths <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>20</mml:mn><mml:mo>,</mml:mo><mml:mn>50</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to generate the window features, and denote them by Win10, Win20 and Win50, respectively.</p>
    </sec>
    <sec id="sec2.2">
      <title>2.2 Architecture of SAINT-Angle</title>
      <p>The architecture of SAINT-Angle can be split into three separate discussions: (i) the architecture of SAINT (<xref rid="vbad042-B46" ref-type="bibr">Uddin <italic toggle="yes">et al.</italic>, 2020</xref>), which was proposed for protein secondary structure prediction and our proposed modifications, (ii) the base model architectures of SAINT-Angle that have been applied in the ensemble and (iii) the overall pipeline of SAINT-Angle.</p>
      <sec id="sec2.2.1">
        <title>2.2.1 Architecture of SAINT</title>
        <p>We discuss the architecture of SAINT briefly here so as to make this article self-contained and easy to follow. For details of SAINT, we refer the reader to <xref rid="vbad042-B46" ref-type="bibr">Uddin <italic toggle="yes">et al.</italic> (2020)</xref>. We also discuss the modifications that we have made to the original SAINT architecture to make it suitable for the task of backbone torsion angle prediction. Two of the core components of SAINT are: (i) the self-attention module, and (ii) 2A3I module, which will be discussed in subsequent sections.</p>
        <sec>
          <title>2.2.1.1 Self-attention module</title>
          <p>The self-attention module, as shown in <xref rid="vbad042-F1" ref-type="fig">Figure 1a</xref>, that we designed and augmented with the Deep3I network (<xref rid="vbad042-B12" ref-type="bibr">Fang <italic toggle="yes">et al.</italic>, 2018a</xref>) is inspired by the self-attention module developed by <xref rid="vbad042-B48" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic> (2017)</xref>. We pass two inputs to our self-attention module: (i) the features from the previous inception module or layer, <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo> </mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>protein</mml:mtext></mml:mrow></mml:msub><mml:mn>×</mml:mn><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>feature</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, and (ii) position identifiers, <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">pos</mml:mi><mml:mo>_</mml:mo><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mo> </mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>protein</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, where <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>protein</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the length of the protein sequence, and <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>feature</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the length of the feature vector.</p>
          <fig position="float" id="vbad042-F1">
            <label>Fig. 1.</label>
            <caption>
              <p>Schematic diagrams of various components of the SAINT-Angle architecture. (<bold>a</bold>) Self-attention module, (<bold>b</bold>) scaled-dot product attention sub-module (<xref rid="vbad042-B48" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic>, 2017</xref>), (<bold>c</bold>) 2A3I module proposed by <xref rid="vbad042-B46" ref-type="bibr">Uddin <italic toggle="yes">et al.</italic> (2020)</xref> and (<bold>d</bold>) RES-2A3I module which augments the 2A3I module with residual connections. <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">Conv</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denotes a 1-D convolution layer with a kernel of size <italic toggle="yes">x</italic></p>
            </caption>
            <graphic xlink:href="vbad042f1" position="float"/>
          </fig>
        </sec>
        <sec>
          <title>2.2.1.2 Positional encoding sub-module</title>
          <p>As the relative or absolute positions of the residues in a protein sequence are important, we need to provide this positional information in our model as shown in <xref rid="vbad042-F1" ref-type="fig">Figure 1a</xref>. The <italic toggle="yes">Positional Encoding</italic> <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="italic">PosEn</mml:mi><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for a position <italic toggle="yes">p</italic> can be defined as follows (<xref rid="vbad042-B48" ref-type="bibr">Vaswani <italic toggle="yes">et al.</italic>, 2017</xref>).
where <italic toggle="yes">i</italic> is the dimension. The above-mentioned function allows the model to learn to attend by relative positions. The inputs <italic toggle="yes">x</italic> is added to the output of positional encoding, resulting in a new representation <italic toggle="yes">h</italic> (<xref rid="E3" ref-type="disp-formula">Eqn. 3</xref>). This new representation <italic toggle="yes">h</italic> not only contains the information extracted by the previous layers or modules but also the information about individual positions.
</p>
          <disp-formula id="E1">
            <label>(1)</label>
            <mml:math id="M1" display="block" overflow="scroll">
              <mml:mrow>
                <mml:mi mathvariant="italic">PosEn</mml:mi>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>c</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>p</mml:mi>
                    <mml:mo>,</mml:mo>
                    <mml:mn>2</mml:mn>
                    <mml:mi>i</mml:mi>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mtext>sin</mml:mtext>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:mi>p</mml:mi>
                <mml:mo>/</mml:mo>
                <mml:mn>10</mml:mn>
                <mml:mo> </mml:mo>
                <mml:msup>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mn>000</mml:mn>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>2</mml:mn>
                    <mml:mi>i</mml:mi>
                    <mml:mo>/</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>d</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mtext>feature</mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:msup>
                <mml:mo stretchy="false">)</mml:mo>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <disp-formula id="E2">
            <label>(2)</label>
            <mml:math id="M2" display="block" overflow="scroll">
              <mml:mrow>
                <mml:mi mathvariant="italic">PosEn</mml:mi>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>c</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mi>p</mml:mi>
                    <mml:mo>,</mml:mo>
                    <mml:mn>2</mml:mn>
                    <mml:mi>i</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mn>1</mml:mn>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mtext>cos</mml:mtext>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:mi>p</mml:mi>
                <mml:mo>/</mml:mo>
                <mml:mn>10</mml:mn>
                <mml:mo> </mml:mo>
                <mml:msup>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mn>000</mml:mn>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mn>2</mml:mn>
                    <mml:mi>i</mml:mi>
                    <mml:mo>/</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>d</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mtext>feature</mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:msup>
                <mml:mo stretchy="false">)</mml:mo>
                <mml:mo>,</mml:mo>
              </mml:mrow>
            </mml:math>
          </disp-formula>
          <disp-formula id="E3">
            <label>(3)</label>
            <mml:math id="M3" display="block" overflow="scroll">
              <mml:mrow>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>h</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mtext>pos</mml:mtext>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>x</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mtext>pos</mml:mtext>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>+</mml:mo>
                <mml:mi mathvariant="italic">PosEn</mml:mi>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>c</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mtext>pos</mml:mtext>
                  </mml:mrow>
                </mml:msub>
              </mml:mrow>
            </mml:math>
          </disp-formula>
        </sec>
        <sec>
          <title>2.2.1.3 Scaled dot-product attention sub-module</title>
          <p>We provide the output of the positional encoding sub-module <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:mi>h</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>protein</mml:mtext></mml:mrow></mml:msub><mml:mn>×</mml:mn><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>feature</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> as the input to the <italic toggle="yes">scaled-dot product</italic> attention sub-module as shown in <xref rid="vbad042-F1" ref-type="fig">Figure 1b</xref>. This input vector is first transformed into three feature spaces <italic toggle="yes">Q</italic>, <italic toggle="yes">K</italic>, <italic toggle="yes">V</italic>, representing query, key and value, respectively. We use three learnable parameter matrices <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for this transformation such that <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>Q</mml:mi></mml:msub><mml:mi>h</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:msub><mml:mi>h</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mrow><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msub><mml:mi>h</mml:mi></mml:mrow></mml:math></inline-formula>. We then compute the scaled dot-product <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> of two vectors <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> using <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:mi>Q</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> vectors. This scaled dot-product <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is subsequently used to compute the attention weights <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (<inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:mi>e</mml:mi><mml:mo> </mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>protein</mml:mtext></mml:mrow></mml:msub><mml:mn>×</mml:mn><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mtext>feature</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>), representing how much attention to provide to the vector <italic toggle="yes">i</italic> while synthesizing the vector at position <italic toggle="yes">j</italic>. The output of the scaled dot-product attention sub module <italic toggle="yes">g</italic> is then computed by multiplying the value vector <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> with the previously calculated attention weights <italic toggle="yes">e</italic> and subsequently applying batch normalization (<xref rid="vbad042-B22" ref-type="bibr">Ioffe and Szegedy, 2015</xref>) to reduce the internal covariate shift (<xref rid="E4" ref-type="disp-formula">Eqn. 4</xref>). Please see <xref rid="vbad042-B46" ref-type="bibr">Uddin <italic toggle="yes">et al.</italic> (2020)</xref> for details.
</p>
          <disp-formula id="E4">
            <label>(4)</label>
            <mml:math id="M4" display="block" overflow="scroll">
              <mml:mrow>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>g</mml:mi>
                  </mml:mrow>
                  <mml:mi>j</mml:mi>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mi mathvariant="italic">BatchNorm</mml:mi>
                <mml:mo stretchy="true">(</mml:mo>
                <mml:munderover>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>n</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>d</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mtext>protein</mml:mtext>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                </mml:munderover>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi>e</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>j</mml:mi>
                      <mml:mo>,</mml:mo>
                      <mml:mi>i</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
                <mml:mi>V</mml:mi>
                <mml:mo stretchy="false">(</mml:mo>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>h</mml:mi>
                  </mml:mrow>
                  <mml:mi>i</mml:mi>
                </mml:msub>
                <mml:mo stretchy="false">)</mml:mo>
                <mml:mo stretchy="true">)</mml:mo>
              </mml:mrow>
            </mml:math>
          </disp-formula>
        </sec>
        <sec>
          <title>2.2.1.4 2A3I and RES-2A3I modules</title>
          <p><xref rid="vbad042-B12" ref-type="bibr">Fang <italic toggle="yes">et al.</italic> (2018a)</xref> used an assembly of inception modules, which they call 3I (Inception-Inside-Inception) module, in their proposed method MUFOLD-SS to predict protein SS. <xref rid="vbad042-B46" ref-type="bibr">Uddin <italic toggle="yes">et al.</italic> (2020)</xref> augmented this with attention modules in order to effectively capture both short- and long-range interactions by placing the self-attention modules (described in <xref rid="sec2.2.1" ref-type="sec">Sect. 2.2.1</xref>) in each branch of the 3I module as shown in <xref rid="vbad042-F1" ref-type="fig">Figure 1c</xref>. This is called the 2A3I (attention augmented inception-inside-inception) module. In this study, we further extended this module by placing residual connections in each of the inception and self-attention modules (<xref rid="vbad042-F1" ref-type="fig">Fig. 1d</xref>). Residual connections (<xref rid="vbad042-B18" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2016</xref>) tackle <italic toggle="yes">vanishing gradient problem</italic> (<xref rid="vbad042-B4" ref-type="bibr">Bengio <italic toggle="yes">et al.</italic>, 1994</xref>) and help make our model more stable. Weight gradients in a neural network are typically very small. During the training of a deep neural network, these small gradients are multiplied by additional small values, resulting in a very small gradient in the earlier layers, and sometimes little or no gradient update at all (as useful gradient information cannot be propagated from the output end of the model back to the layers). This vanishing gradient problem can be addressed by residual connections, producing a more noise stable model with improved learning capacity (<xref rid="vbad042-B57" ref-type="bibr">Yu and Tomasi, 2019</xref>). We call this residual connection-augmented module the <italic toggle="yes">RES-2A3I</italic> module.</p>
        </sec>
      </sec>
      <sec id="sec2.2.2">
        <title>2.2.2 Base models of SAINT-Angle</title>
        <p>We developed the following three architectures that we utilize in an ensemble network to create: (i) <italic toggle="yes">Basic</italic> architecture, (ii) <italic toggle="yes">ProtTrans</italic> architecture and (iii) <italic toggle="yes">Residual</italic> architecture.</p>
        <sec id="sec2.2.2.1">
          <title>2.2.2.1 Basic architecture</title>
          <p><xref rid="vbad042-F2" ref-type="fig">Figure 2a</xref> shows the schematic diagram of our <italic toggle="yes">Basic</italic> architecture which is identical to the original SAINT architecture proposed for protein SS prediction (<xref rid="vbad042-B46" ref-type="bibr">Uddin <italic toggle="yes">et al.</italic>, 2020</xref>). It starts with two consecutive 2A3I modules followed by a self-attention module. This self-attention module supplements the amount of non-local interactions that have been captured by previous two 2A3I modules. Next, we have an 1D convolutional layer with window size 11. The output of the convolutional layer is passed through another self-attention module, followed by two dense layers, with yet another self-attention module placed in between these two dense layers. This self-attention module helps in understanding how the residues align and interact, making it easier to comprehend the behavior of the model. The final dense layer has four regression nodes that infer <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:mtext>sin</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>ϕ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:mtext>cos</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>ϕ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mrow><mml:mtext>sin</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>ψ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mrow><mml:mtext>cos</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>ψ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
          <fig position="float" id="vbad042-F2">
            <label>Fig. 2.</label>
            <caption>
              <p>Schematic diagrams of the architectures of the base models used in SAINT-Angle. (<bold>a</bold>) The <italic toggle="yes">Basic</italic> architecture which was proposed by <xref rid="vbad042-B46" ref-type="bibr">Uddin <italic toggle="yes">et al.</italic> (2020)</xref>, (<bold>b</bold>) the <italic toggle="yes">ProtTrans</italic> architecture and (<bold>c</bold>) the <italic toggle="yes">Residual</italic> architecture which augments the <italic toggle="yes">ProtTrans</italic> architecture with residual connections</p>
            </caption>
            <graphic xlink:href="vbad042f2" position="float"/>
          </fig>
        </sec>
        <sec id="sec2.2.2.2">
          <title>2.2.2.2 ProtTrans architecture</title>
          <p>We developed the <italic toggle="yes">ProtTrans</italic> architecture (<xref rid="vbad042-F2" ref-type="fig">Fig. 2b</xref>) to effectively use the ProtTrans features by treating them differently from the base and window features. We pass the ProtTrans features to a 1D convolution layer with kernel size 7. This convolutional layer acts as a local feature extractor, capturing local interactions between residues and reducing the dimension of the ProtTrans features from a 1024D feature vector to a 300D feature vector, allowing the model to filter out less important information. It also aids in avoiding over-fitting and reducing the number of trainable parameters. The output of this 1D convolution layer is then concatenated with the base and window features. The concatenated vector is then passed through a single 2A3I module. Note that, unlike the basic SAINT architecture, we have only one 2A3I module as we observed that two 2A3I modules do not provide notable advantage in this architecture but increase the training time. The rest of the architecture is similar to the basic SAINT architecture.</p>
        </sec>
        <sec id="sec2.2.2.3">
          <title>2.2.2.3 Residual architecture</title>
          <p>The <italic toggle="yes">Residual</italic> architecture (<xref rid="vbad042-F2" ref-type="fig">Fig. 2c</xref>) is similar to the <italic toggle="yes">ProtTrans</italic> architecture except for two differences: (i) we have added residual connections (<xref rid="vbad042-B18" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2016</xref>) between different components as shown in <xref rid="vbad042-F2" ref-type="fig">Figure 2c</xref>, and (ii) we have used the RES-2A3I module instead of the 2A3I module. Residual connections enable the deeper layers to use the features extracted from the earlier layers. Usually, the deeper level layers use features that are highly convoluted and lower in resolution. Residual connections help the deeper layers leverage the low-level and high dimensional features. It also helps to make the model stable.</p>
        </sec>
      </sec>
      <sec id="sec2.2.3">
        <title>2.2.3 Overview of SAINT-Angle</title>
        <p><italic toggle="yes">SAINT-Angle</italic> is an ensemble network of eight models with different combinations of architectures (discussed in <xref rid="sec2.2.2" ref-type="sec">Sect. 2.2.2</xref>) and features (discussed in <xref rid="sec2.1" ref-type="sec">Sect. 2.1</xref>)—resulting in a set of diverse learning paths leveraging different types of features. <xref rid="vbad042-T1" ref-type="table">Table 1</xref> shows the architectures and features used in these eight models. Details of the ensemble and the individual models therein are presented in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>. We used the same training and validation sets that were used by SPOT-1D to train these models and tune necessary hyperparameters.</p>
        <table-wrap position="float" id="vbad042-T1">
          <label>Table 1.</label>
          <caption>
            <p>Eight models used in SAINT-angle</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="center" span="1"/>
              <col valign="top" align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Model</th>
                <th rowspan="1" colspan="1">Architecture</th>
                <th rowspan="1" colspan="1">Feature set</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">1</td>
                <td rowspan="1" colspan="1">Basic</td>
                <td rowspan="1" colspan="1">Base</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">2</td>
                <td rowspan="1" colspan="1">Basic</td>
                <td rowspan="1" colspan="1">Base+Win10</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">3</td>
                <td rowspan="1" colspan="1">ProtTrans</td>
                <td rowspan="1" colspan="1">Base+ProtTrans</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">4</td>
                <td rowspan="1" colspan="1">ProtTrans</td>
                <td rowspan="1" colspan="1">Base+ProtTrans+Win10</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">5</td>
                <td rowspan="1" colspan="1">ProtTrans</td>
                <td rowspan="1" colspan="1">Base+ProtTrans+Win20</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">6</td>
                <td rowspan="1" colspan="1">ProtTrans</td>
                <td rowspan="1" colspan="1">Base+ProtTrans+Win50</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">7</td>
                <td rowspan="1" colspan="1">Residual</td>
                <td rowspan="1" colspan="1">Base+ProtTrans</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">8</td>
                <td rowspan="1" colspan="1">Residual</td>
                <td rowspan="1" colspan="1">Base+ProtTrans+Win10</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <p><italic toggle="yes">Note</italic>: We show the architectures and features used in these eight models.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>Each model was trained using Adam optimizer (<xref rid="vbad042-B26" ref-type="bibr">Kingma and Ba, 2015</xref>) with an initial learning rate of 0.0001 which was subsequently reduced by half when the accuracy of the validation set did not improve for five consecutive epochs.</p>
        <p>We performed an extensive ablation study to assess the contribution of different feature sets and model architectures used in SAINT-Angle (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Sect. S3</xref> in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>). The ablation studies demonstrate the motivation behind using different features and different model architectures that are tailored for particular feature sets.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>3 Results and discussion</title>
    <p>We performed an extensive evaluation study, comparing SAINT-Angle with the recent state-of-the-art methods on a collection of widely used benchmark dataset.</p>
    <sec>
      <title>3.1 Dataset</title>
      <sec>
        <title>3.1.1 Training and validation dataset</title>
        <p>The SPOT-1D dataset (<xref rid="vbad042-B16" ref-type="bibr">Hanson <italic toggle="yes">et al.</italic>, 2018</xref>, <xref rid="vbad042-B17" ref-type="bibr">2019</xref>) was used for training and validation of SAINT-Angle. These proteins were culled from the PISCES server (<xref rid="vbad042-B49" ref-type="bibr">Wang and Dunbrack, 2003</xref>) on February 2017 with resolution <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mo>&lt;</mml:mo></mml:math></inline-formula>2.5 Å, <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mtext>free</mml:mtext><mml:mo>&lt;</mml:mo></mml:mrow></mml:math></inline-formula>1, and a sequence identity cutoff of 25% according to BlastClust (<xref rid="vbad042-B3" ref-type="bibr">Altschul <italic toggle="yes">et al.</italic>, 1997</xref>). The proteins consisting of over 700 amino acid residues were removed by the authors of SPOT-1D to fit in the SPOT-Contact (<xref rid="vbad042-B16" ref-type="bibr">Hanson <italic toggle="yes">et al.</italic>, 2018</xref>) pipeline. As a result, 10 029 and 983 proteins remained in the training and validation sets, respectively.</p>
      </sec>
      <sec>
        <title>3.1.2 Test dataset</title>
        <p>We assessed the performance of SAINT-Angle and other competing methods on a collection of widely used test sets, which are briefly described in <xref rid="sup1" ref-type="supplementary-material">Supplementary Sect. 4</xref> in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
      </sec>
    </sec>
    <sec>
      <title>3.2 Performance evaluation</title>
      <p>We compared our proposed SAINT-Angle with several state-of-the-art methods: SPOT-1D-LM, SPOT-1D-Single (<xref rid="vbad042-B40" ref-type="bibr">Singh <italic toggle="yes">et al.</italic>, 2021</xref>), OPUS-TASS, SPOT-1D, NetSurfP-2.0, MUFOLD, SPIDER3 and RaptorX-Angle. We also compared SAINT-Angle with a recent and highly accurate method ESIDEN (<xref rid="vbad042-B55" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>). We evaluated the performance of backbone torsion angles prediction methods using mean absolute error (MAE) which is the measure of average absolute difference between native values (<italic toggle="yes">T</italic>) and predicted values (<italic toggle="yes">P</italic>) over all amino acid residues in a protein. The minimum value between <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>360</mml:mn></mml:mrow></mml:mrow><mml:mo>°</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mo>|</mml:mo><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula> was taken in order to reduce the periodicity of an angle (<xref rid="vbad042-B55" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>) as given in <xref rid="E5" ref-type="disp-formula">Eqn. 5</xref>. Here <italic toggle="yes">N</italic> is the number of proteins, <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the total number of amino acid residues in the <italic toggle="yes">i</italic>th protein. <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are the values of native and predicted angles of the <italic toggle="yes">j</italic>th amino acid residue in the <italic toggle="yes">i</italic>th protein, respectively. We performed Wilcoxon signed-rank test (<xref rid="vbad042-B51" ref-type="bibr">Wilcoxon <italic toggle="yes">et al.</italic>, 1970</xref>) (with <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mrow><mml:mo>α</mml:mo><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>) to measure the statistical significance of the differences between two methods.
</p>
      <disp-formula id="E5">
        <label>(5)</label>
        <mml:math id="M5" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mtext>MAE</mml:mtext>
            <mml:mo>=</mml:mo>
            <mml:mfrac>
              <mml:mn>1</mml:mn>
              <mml:mrow>
                <mml:msubsup>
                  <mml:mo>∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>=</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mi>N</mml:mi>
                </mml:msubsup>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi>L</mml:mi>
                    </mml:mrow>
                    <mml:mi>i</mml:mi>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mfrac>
            <mml:munderover>
              <mml:mo>∑</mml:mo>
              <mml:mrow>
                <mml:mi>i</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mn>1</mml:mn>
              </mml:mrow>
              <mml:mi>N</mml:mi>
            </mml:munderover>
            <mml:mrow>
              <mml:munderover>
                <mml:mo>∑</mml:mo>
                <mml:mrow>
                  <mml:mi>j</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi>L</mml:mi>
                    </mml:mrow>
                    <mml:mi>i</mml:mi>
                  </mml:msub>
                </mml:mrow>
              </mml:munderover>
              <mml:mrow>
                <mml:mtext>min</mml:mtext>
              </mml:mrow>
            </mml:mrow>
            <mml:mo stretchy="false">(</mml:mo>
            <mml:mo>|</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mi>T</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>i</mml:mi>
                <mml:mi>j</mml:mi>
              </mml:mrow>
            </mml:msub>
            <mml:mo>−</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mi>P</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>i</mml:mi>
                <mml:mi>j</mml:mi>
              </mml:mrow>
            </mml:msub>
            <mml:mo>|</mml:mo>
            <mml:mo>,</mml:mo>
            <mml:mo> </mml:mo>
            <mml:msup>
              <mml:mrow>
                <mml:mrow>
                  <mml:mn>360</mml:mn>
                </mml:mrow>
              </mml:mrow>
              <mml:mo>°</mml:mo>
            </mml:msup>
            <mml:mo>−</mml:mo>
            <mml:mo>|</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mi>T</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>i</mml:mi>
                <mml:mi>j</mml:mi>
              </mml:mrow>
            </mml:msub>
            <mml:mo>−</mml:mo>
            <mml:msub>
              <mml:mrow>
                <mml:mi>P</mml:mi>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>i</mml:mi>
                <mml:mi>j</mml:mi>
              </mml:mrow>
            </mml:msub>
            <mml:mo>|</mml:mo>
            <mml:mo stretchy="false">)</mml:mo>
          </mml:mrow>
        </mml:math>
      </disp-formula>
    </sec>
    <sec>
      <title>3.3 Results on benchmark datasets</title>
      <p>The comparison of SAINT-Angle with other state-of-the-art methods on TEST2016 and TEST2018 is shown in <xref rid="vbad042-T2" ref-type="table">Table 2</xref>. Experimental results show that SAINT-Angle outperforms all other methods on both TEST2016 and TEST2018 datasets except that SPOT-1D-LM is slightly better than SAINT-Angle in <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula> angle prediction on TEST2018 dataset. Especially, the improvement in MAE(<inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>) is substantial—almost two degrees over the third best method OPUS-TASS, and more than 2–6 degrees compared to other methods. Notably, even the individual eight base models used in SAINT-Angle achieve comparable or better performance than most other methods (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref> in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>). Among these individual base models, the improvements of the models with <italic toggle="yes">ProtTrans</italic> architecture and ProtTrans features (Models 3, 4, 5 and 6 in <xref rid="vbad042-T1" ref-type="table">Table 1</xref>) over the <italic toggle="yes">Basic</italic> architecture with base features (Models 1 and 2) are notable—indicating the successful utilization of ProtTrans-based transfer learning. Statistical tests suggests that these improvements of SAINT-Angle over other methods are statistically significant (<italic toggle="yes">P</italic>-value <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mrow><mml:mo>≪</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>). RaptorX-Angle performed poorly compared to other methods on both these datasets. OPUS-TASS and SPOT-1D produced similar results, with OPUS-TASS obtaining marginally better results than SPOT-1D. Both OPUS-TASS and SPOT-1D obtained notably better results than NetSurfP, MUFOLD and SPIDER3.</p>
      <table-wrap position="float" id="vbad042-T2">
        <label>Table 2.</label>
        <caption>
          <p>Performance [in terms of MAE(<inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>) and MAE(<inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>)] of SAINT-Angle and other state-of-the-art methods on TEST2016 and TEST2018</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="center" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1">Method</th>
              <th colspan="2" rowspan="1">TEST2016<hr/></th>
              <th colspan="2" align="center" rowspan="1">TEST2018<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE58"><mml:math id="IM58" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE59"><mml:math id="IM59" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE60"><mml:math id="IM60" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">RaptorX-Angle<xref rid="tblfn3" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">18.08</td>
              <td rowspan="1" colspan="1">26.68</td>
              <td rowspan="1" colspan="1">21.01</td>
              <td rowspan="1" colspan="1">35.95</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SPIDER3<xref rid="tblfn3" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">17.88</td>
              <td rowspan="1" colspan="1">26.66</td>
              <td rowspan="1" colspan="1">18.38</td>
              <td rowspan="1" colspan="1">28.10</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">MUFOLD<xref rid="tblfn3" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">17.78</td>
              <td rowspan="1" colspan="1">27.24</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">NetSurfP-2.0<xref rid="tblfn3" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">17.90</td>
              <td rowspan="1" colspan="1">26.63</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SPOT-1D<xref rid="tblfn3" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">16.27</td>
              <td rowspan="1" colspan="1">23.26</td>
              <td rowspan="1" colspan="1">16.89</td>
              <td rowspan="1" colspan="1">24.87</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">OPUS-TASS<xref rid="tblfn4" ref-type="table-fn"><sup>b</sup></xref></td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">15.78</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">22.46</italic>
              </td>
              <td rowspan="1" colspan="1">16.40</td>
              <td rowspan="1" colspan="1">24.06</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SPOT-1D-LM<xref rid="tblfn5" ref-type="table-fn"><sup>c</sup></xref></td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">
                <bold>15.99</bold>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">23.74</italic>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SAINT-Angle</td>
              <td rowspan="1" colspan="1">
                <bold>15.45</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>20.77</bold>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">16.25</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>22.37</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic toggle="yes">Note</italic>: The best and the second best results are shown in bold and italic, respectively. Values which were not reported by the corresponding source are indicated by ‘–’.</p>
          </fn>
          <fn id="tblfn3">
            <label>a</label>
            <p>Results reported by SPOT-1D (<xref rid="vbad042-B17" ref-type="bibr">Hanson <italic toggle="yes">et al.</italic>, 2019</xref>).</p>
          </fn>
          <fn id="tblfn4">
            <label>b</label>
            <p>Results reported by OPUS-TASS (<xref rid="vbad042-B53" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2020</xref>).</p>
          </fn>
          <fn id="tblfn5">
            <label>c</label>
            <p>Results reported by SPOT-1D-LM (<xref rid="vbad042-B42" ref-type="bibr">Singh et al., 2022b</xref>).</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>The performance of SAINT-Angle and other competing methods on three CASP datasets (CASP12, CASP13 and CASP-FM) is shown in <xref rid="vbad042-T3" ref-type="table">Table 3</xref>. SAINT-Angle consistently outperformed other methods on these datasets, with only one exception on CASP-FM where OPUS-TASS obtained a better MAE(<inline-formula id="IE61"><mml:math id="IM61" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>) than SAINT-Angle albeit the difference is very small (0.01 degree). Similar to TEST2016 and TEST2018 datasets, the improvements of SAINT-Angle over other methods in MAE(<inline-formula id="IE62"><mml:math id="IM62" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>) are more substantial than those in MAE(<inline-formula id="IE63"><mml:math id="IM63" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>). The improvements of SAINT-Angle over other methods are statistically significant (<italic toggle="yes">P</italic>-value <inline-formula id="IE64"><mml:math id="IM64" display="inline" overflow="scroll"><mml:mrow><mml:mo>≪</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>).</p>
      <table-wrap position="float" id="vbad042-T3">
        <label>Table 3.</label>
        <caption>
          <p>Performance [in terms of MAE(<inline-formula id="IE65"><mml:math id="IM65" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>) and MAE(<inline-formula id="IE66"><mml:math id="IM66" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>)] of SAINT-Angle and other state-of-the-art methods on three CASP datasets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1">Method</th>
              <th colspan="2" rowspan="1">CASP12 (55)<hr/></th>
              <th colspan="2" rowspan="1">CASP13 (32)<hr/></th>
              <th colspan="2" rowspan="1">CASP-FM (56)<hr/></th>
            </tr>
            <tr>
              <th colspan="6" align="center" rowspan="1">MAE<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th align="center" rowspan="1" colspan="1">
                <bold>(</bold>
                <inline-formula id="IE67">
                  <mml:math id="IM67" display="inline" overflow="scroll">
                    <mml:mo>ϕ</mml:mo>
                  </mml:math>
                </inline-formula>
                <bold>)</bold>
              </th>
              <th align="center" rowspan="1" colspan="1">
                <bold>(</bold>
                <inline-formula id="IE68">
                  <mml:math id="IM68" display="inline" overflow="scroll">
                    <mml:mo>ψ</mml:mo>
                  </mml:math>
                </inline-formula>
                <bold>)</bold>
              </th>
              <th align="center" rowspan="1" colspan="1">
                <bold>(</bold>
                <inline-formula id="IE69">
                  <mml:math id="IM69" display="inline" overflow="scroll">
                    <mml:mo>ϕ</mml:mo>
                  </mml:math>
                </inline-formula>
                <bold>)</bold>
              </th>
              <th align="center" rowspan="1" colspan="1">
                <bold>(</bold>
                <inline-formula id="IE70">
                  <mml:math id="IM70" display="inline" overflow="scroll">
                    <mml:mo>ψ</mml:mo>
                  </mml:math>
                </inline-formula>
                <bold>)</bold>
              </th>
              <th align="center" rowspan="1" colspan="1">
                <bold>(</bold>
                <inline-formula id="IE71">
                  <mml:math id="IM71" display="inline" overflow="scroll">
                    <mml:mo>ϕ</mml:mo>
                  </mml:math>
                </inline-formula>
                <bold>)</bold>
              </th>
              <th align="center" rowspan="1" colspan="1">
                <bold>(</bold>
                <inline-formula id="IE72">
                  <mml:math id="IM72" display="inline" overflow="scroll">
                    <mml:mo>ψ</mml:mo>
                  </mml:math>
                </inline-formula>
                <bold>)</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SPOT-1D<xref rid="tblfn7" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">18.44</td>
              <td rowspan="1" colspan="1">26.90</td>
              <td rowspan="1" colspan="1">18.48</td>
              <td rowspan="1" colspan="1">26.73</td>
              <td rowspan="1" colspan="1">19.39</td>
              <td rowspan="1" colspan="1">30.10</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">OPUS-TASS<xref rid="tblfn7" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">18.08</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">25.98</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">17.89</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">25.93</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>18.85</bold>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">28.00</italic>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SAINT-Angle</td>
              <td rowspan="1" colspan="1">
                <bold>17.91</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>24.76</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>17.55</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>23.96</bold>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">18.86</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>27.65</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn6">
            <p><italic toggle="yes">Note</italic>: The best and the second best results are shown in bold and italic, respectively.</p>
          </fn>
          <fn id="tblfn7">
            <label>a</label>
            <p>Results reported in OPUS-TASS.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.4 Results on TEST2020-HQ dataset</title>
      <p>We further compared the backbone torsion angles prediction performance of SAINT-Angle with the best existing methods on a newly introduced dataset TEST2020-HQ dataset, which was previously assembled and analyzed by SPOT-1D-LM (<xref rid="vbad042-B42" ref-type="bibr">Singh et al., 2022b</xref>). Given the difficulty in generating window features, we excluded certain base models, from the eight models as listed in <xref rid="vbad042-T1" ref-type="table">Table 1</xref>, that required window features for prediction. Thus, we used an ensemble of only three base models (Models 1, 3 and 7).</p>
      <p>The performance comparison of SAINT-Angle with other methods is shown in <xref rid="vbad042-T4" ref-type="table">Table 4</xref>. SAINT-Angle outperformed other methods by a large margin (even with an ensemble of three models with base and ProtTrans features). This further supports the superiority of our model architectures over other methods.</p>
      <table-wrap position="float" id="vbad042-T4">
        <label>Table 4.</label>
        <caption>
          <p>Performance of SAINT-Angle (ensemble of three base models without window features), NetSurfP-2.0, SPOT-1D, SPOT-1D-Single and SPOT-1D-LM on TEST2020-HQ dataset</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1">Method</th>
              <th colspan="2" align="center" rowspan="1">TEST2020-HQ<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE73"><mml:math id="IM73" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE74"><mml:math id="IM74" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">NetSurfP-2.0<xref rid="tblfn8" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">19.90</td>
              <td rowspan="1" colspan="1">31.29</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SPOT-1D<xref rid="tblfn8" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">18.78</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">28.87</italic>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SPOT-1D-Single<xref rid="tblfn8" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">23.01</td>
              <td rowspan="1" colspan="1">42.62</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SPOT-1D-LM<xref rid="tblfn8" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">19.52</td>
              <td rowspan="1" colspan="1">32.01</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SAINT-Angle</td>
              <td rowspan="1" colspan="1">
                <bold>17.94</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>26.90</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn9">
            <p><italic toggle="yes">Note</italic>: The best and the second best results are shown in bold and italic, respectively.</p>
          </fn>
          <fn id="tblfn8">
            <label>a</label>
            <p>Results reported by SPOT-1D-LM.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.5 Comparison of SAINT-Angle with ESIDEN</title>
      <p>ESIDEN (<xref rid="vbad042-B55" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>)—a recent, highly accurate recurrent neural network-based method—introduced and leveraged four evolutionary signatures as novel features, namely relative entropy (RE), degree of conservation (DC), position-specific substitution probabilities (PSSP) and Ramachandran basin potential (RBP). They showed that these novel features, along with classical features such as PSSM, physicochemical properties (PP) and amino acid (AA), result in significant improvements in protein torsion angle prediction. As ESIDEN is not an ensemble-based network, in order to make a fair comparison with ESIDEN and to further assess the efficacy of the novel evolutionary features, we trained our basic architecture (discussed in <xref rid="sec2.2.2.1" ref-type="sec">Sect. 2.2.2.1</xref>) using the features used by ESIDEN and evaluated its performance on a collection of datasets compiled and analyzed by the authors of ESIDEN. This will enable us to assess the performance of the basic SAINT architecture using the features used by ESIDEN (i.e. without the ProtTrans-based transfer learning and the ensemble network). We call this <italic toggle="yes">Basic</italic> architecture with ESIDEN features <italic toggle="yes">SAINT-Angle-Single</italic>. We obtained the evolutionary features for the SPOT-1D training dataset and a collection of test datasets from the authors of ESIDEN. We also trained our ensemble network using the base features along with the novel ESIDEN features [i.e. 20 types of amino acids (AA) and four evolutionary features DC, RE, PSSP and RBP]. The evolutionary features of ESIDEN were shown to be reasonably powerful (<xref rid="vbad042-B55" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>), which has been further supported by our experimental results as well (discussed later in this section). On the other hand, the window features are difficult to compute (<xref rid="vbad042-B53" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2020</xref>). Therefore, in these experiments, we did not use the window features to keep the dimension of the feature vector manageable as well as to best take advantage of the evolutionary features used in ESIDEN. Thus, after removing the window features when ESIDEN features are available, we had three models (out of eight models listed in <xref rid="vbad042-T1" ref-type="table">Table 1</xref>) to use for the ensemble network (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Sect. 2.1</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S5</xref> in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>). In order to distinguish this ensemble of three base models using the ESIDEN features from the ensemble of eight models, we call this SAINT-Angle<inline-formula id="IE75"><mml:math id="IM75" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
      <p>The comparison of SAINT-Angle-Single, SAINT-Angle<inline-formula id="IE76"><mml:math id="IM76" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (ensemble of three models using the ESIDEN features) and SAINT-Angle (ensemble of eight models without ESIDEN features) with ESIDEN on TEST2016 and TEST2018 datasets is shown in <xref rid="vbad042-T5" ref-type="table">Table 5</xref>. ESIDEN is notably better than the SPOT-1D, OPUS-TASS, SPOT-1D-LM as well as SAINT-Angle, especially for predicting the <inline-formula id="IE77"><mml:math id="IM77" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula> angle [around <inline-formula id="IE78"><mml:math id="IM78" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mn>4</mml:mn></mml:mrow><mml:mo>°</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> improvement in MAE(<inline-formula id="IE79"><mml:math id="IM79" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>)]. Note however that SAINT-Angle, unlike ESIDEN, does not use the four evolutionary features. Interestingly, SAINT-Angle-Single, which leverages ESIDEN features, is remarkably better than ESIDEN [<inline-formula id="IE80"><mml:math id="IM80" display="inline" overflow="scroll"><mml:mrow><mml:mo>∼</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>°</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> improvement in MAE<inline-formula id="IE81"><mml:math id="IM81" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ψ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>] as well as other methods. This shows the superiority of our SAINT architecture over the ESIDEN architecture.</p>
      <table-wrap position="float" id="vbad042-T5">
        <label>Table 5.</label>
        <caption>
          <p>Performance of SAINT-Angle-Single (basic SAINT architecture with base and ESIDEN features), SAINT-Angle<inline-formula id="IE82"><mml:math id="IM82" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> (ensemble of three models using the ESIDEN features) and SAINT-Angle (ensemble of eight models without ESIDEN features), and ESIDEN on TEST2016 and TEST2018</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1">Method</th>
              <th colspan="2" align="center" rowspan="1">TEST2016<hr/></th>
              <th colspan="2" align="center" rowspan="1">TEST2018<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE83"><mml:math id="IM83" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE84"><mml:math id="IM84" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE85"><mml:math id="IM85" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE86"><mml:math id="IM86" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">SPOT-1D</td>
              <td rowspan="1" colspan="1">16.27</td>
              <td rowspan="1" colspan="1">23.26</td>
              <td rowspan="1" colspan="1">16.89</td>
              <td rowspan="1" colspan="1">24.87</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">OPUS-TASS</td>
              <td rowspan="1" colspan="1">15.78</td>
              <td rowspan="1" colspan="1">22.46</td>
              <td rowspan="1" colspan="1">16.40</td>
              <td rowspan="1" colspan="1">24.06</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SPOT-1D-LM</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">–</td>
              <td rowspan="1" colspan="1">15.99</td>
              <td rowspan="1" colspan="1">23.74</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ESIDEN<xref rid="tblfn10" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">15.48</td>
              <td rowspan="1" colspan="1">19.25</td>
              <td rowspan="1" colspan="1">16.00</td>
              <td rowspan="1" colspan="1">20.28</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SAINT-Angle</td>
              <td rowspan="1" colspan="1">15.45</td>
              <td rowspan="1" colspan="1">20.77</td>
              <td rowspan="1" colspan="1">16.25</td>
              <td rowspan="1" colspan="1">22.37</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SAINT-Angle-Single</td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">14.39</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">17.03</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>14.89</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>17.94</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SAINT-Angle<inline-formula id="IE87"><mml:math id="IM87" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula></td>
              <td rowspan="1" colspan="1">
                <bold>14.18</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>16.59</bold>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">15.48</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">18.77</italic>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn11">
            <p><italic toggle="yes">Note</italic>: The best and the second best results are shown in bold and italic, respectively.</p>
          </fn>
          <fn id="tblfn10">
            <label>a</label>
            <p>Results reported by ESIDEN (<xref rid="vbad042-B55" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>).</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>The performance of SAINT-Angle-Single and SAINT-Angle<inline-formula id="IE88"><mml:math id="IM88" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> is mixed on these two datasets. SAINT-Angle<inline-formula id="IE89"><mml:math id="IM89" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> is better than SAINT-Angle-Single on TEST2016 dataset whereas SAINT-Angle-Single is better than SAINT-Angle<inline-formula id="IE90"><mml:math id="IM90" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> on TEST2018. Remarkably, both of them achieved substantial improvements over ESIDEN. Moreover, both SAINT-Angle-Single and SAINT-Angle<inline-formula id="IE91"><mml:math id="IM91" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> outperformed SAINT-Angle—showing the power of the evolutionary features proposed by ESIDEN. The improvements of SAINT-Angle-Single and SAINT-Angle<inline-formula id="IE92"><mml:math id="IM92" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow/><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> over ESIDEN and SAINT-Angle are statistically significant (<inline-formula id="IE93"><mml:math id="IM93" display="inline" overflow="scroll"><mml:mrow><mml:mi>P</mml:mi><mml:mo>-</mml:mo><mml:mtext>value</mml:mtext><mml:mo>≪</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>).</p>
      <p>We further assessed the performance of SAINT-Angle-Single in comparison with ESIDEN and other methods on five other benchmark datasets that were compiled and used by the authors of ESIDEN, namely CAMEO109 and four CASP datasets (CASP11, CASP12, CASP13, CASP14). Note that these CASP datasets [analyzed in ESIDEN (<xref rid="vbad042-B55" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2021</xref>)] are different from the CASP datasets in <xref rid="vbad042-T3" ref-type="table">Table 3</xref> (which was used by SAINT). Results on the CAMEO109 dataset are shown in <xref rid="vbad042-T6" ref-type="table">Table 6</xref>. ESIDEN is better than other existing methods in terms of MAE<inline-formula id="IE94"><mml:math id="IM94" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ψ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (<inline-formula id="IE95"><mml:math id="IM95" display="inline" overflow="scroll"><mml:mrow><mml:mo>∼</mml:mo><mml:msup><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>°</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> improvement), but SPOT-1D obtained slightly better MAE<inline-formula id="IE96"><mml:math id="IM96" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ϕ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> than ESIDEN. SAINT-Angle-Single outperformed ESIDEN and other methods in terms of both MAE<inline-formula id="IE97"><mml:math id="IM97" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ϕ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and MAE<inline-formula id="IE98"><mml:math id="IM98" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ψ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Especially, it obtained around two degrees of improvement over ESIDEN in MAE<inline-formula id="IE99"><mml:math id="IM99" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ψ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
      <table-wrap position="float" id="vbad042-T6">
        <label>Table 6.</label>
        <caption>
          <p>Performance of SAINT-Angle-Single and other state-of-the-art methods on CAMEO109 and four CASP datasets</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" colspan="1">Method</th>
              <th colspan="2" align="center" rowspan="1">CAMEO109<hr/></th>
              <th colspan="2" align="center" rowspan="1">CASP11 (27)<hr/></th>
              <th colspan="2" align="center" rowspan="1">CASP12 (11)<hr/></th>
              <th colspan="2" align="center" rowspan="1">CASP13 (13)<hr/></th>
              <th colspan="2" align="center" rowspan="1">CASP14 (8)<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE100"><mml:math id="IM100" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE101"><mml:math id="IM101" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE102"><mml:math id="IM102" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE103"><mml:math id="IM103" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE104"><mml:math id="IM104" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE105"><mml:math id="IM105" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE106"><mml:math id="IM106" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE107"><mml:math id="IM107" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE108"><mml:math id="IM108" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>)</th>
              <th rowspan="1" colspan="1">MAE(<inline-formula id="IE109"><mml:math id="IM109" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">RaptorX-Angle<xref rid="tblfn13" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">19.57</td>
              <td rowspan="1" colspan="1">33.96</td>
              <td rowspan="1" colspan="1">20.33</td>
              <td rowspan="1" colspan="1">40.05</td>
              <td rowspan="1" colspan="1">21.71</td>
              <td rowspan="1" colspan="1">38.22</td>
              <td rowspan="1" colspan="1">22.73</td>
              <td rowspan="1" colspan="1">41.18</td>
              <td rowspan="1" colspan="1">24.95</td>
              <td rowspan="1" colspan="1">48.06</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SPIDER3<xref rid="tblfn13" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">17.89</td>
              <td rowspan="1" colspan="1">28.32</td>
              <td rowspan="1" colspan="1">19.19</td>
              <td rowspan="1" colspan="1">34.63</td>
              <td rowspan="1" colspan="1">21.14</td>
              <td rowspan="1" colspan="1">34.92</td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">22.48</italic>
              </td>
              <td rowspan="1" colspan="1">38.46</td>
              <td rowspan="1" colspan="1">23.41</td>
              <td rowspan="1" colspan="1">38.79</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SPOT-1D<xref rid="tblfn13" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">16.49</italic>
              </td>
              <td rowspan="1" colspan="1">25.17</td>
              <td rowspan="1" colspan="1">18.54</td>
              <td rowspan="1" colspan="1">25.77</td>
              <td rowspan="1" colspan="1">20.21</td>
              <td rowspan="1" colspan="1">31.71</td>
              <td rowspan="1" colspan="1">22.60</td>
              <td rowspan="1" colspan="1">34.28</td>
              <td rowspan="1" colspan="1">23.42</td>
              <td rowspan="1" colspan="1">33.44</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">ESIDEN<xref rid="tblfn13" ref-type="table-fn"><sup>a</sup></xref></td>
              <td rowspan="1" colspan="1">16.57</td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">24.25</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>17.25</bold>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">23.30</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">19.94</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">28.86</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>22.15</bold>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">32.40</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">23.01</italic>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">29.96</italic>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">SAINT-Angle-Single</td>
              <td rowspan="1" colspan="1">
                <bold>16.40</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>22.77</bold>
              </td>
              <td rowspan="1" colspan="1">
                <italic toggle="yes">17.40</italic>
              </td>
              <td rowspan="1" colspan="1">
                <bold>22.52</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>19.58</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>27.11</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>22.15</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>31.46</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>22.67</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>29.83</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn12">
            <p><italic toggle="yes">Notes:</italic> The numbers of proteins in these datasets are shown in parentheses. The best and the second best results are shown in bold and italic, respectively.</p>
          </fn>
          <fn id="tblfn13">
            <label>a</label>
            <p>Results reported by ESIDEN.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Results on four CASP datasets are shown in <xref rid="vbad042-T6" ref-type="table">Table 6</xref>. SAINT-Angle-Single and ESIDEN are significantly better than other existing methods, especially for <inline-formula id="IE110"><mml:math id="IM110" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula> where ESIDEN and SAINT-Angle achieved more than <inline-formula id="IE111"><mml:math id="IM111" display="inline" overflow="scroll"><mml:mrow><mml:mo>∼</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mo>°</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> improvements over other methods. Remarkably, SAINT-Angle-Single outperformed all other methods (including ESIDEN) across all the datasets in terms of both MAE<inline-formula id="IE112"><mml:math id="IM112" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ϕ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and MAE<inline-formula id="IE113"><mml:math id="IM113" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ψ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, with only one exception where ESIDEN obtained a better MAE<inline-formula id="IE114"><mml:math id="IM114" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ϕ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> than SAINT-Angle-Single on the CASP11 dataset.</p>
    </sec>
    <sec>
      <title>3.6 Analysis of the predicted angles</title>
      <p>We further investigated the predicted protein backbone torsion angles from SAINT-Angle and other contemporary methods to obtain better insights on the performances of various methods.</p>
      <sec>
        <title>3.6.1 Impact of long-range interactions</title>
        <p>We investigated the effect of long-range interactions among amino acid residues in protein torsion angle prediction. Two residues at sequence position <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic> are considered to have non-local contact or interaction if they are at least twenty residues apart (<inline-formula id="IE115"><mml:math id="IM115" display="inline" overflow="scroll"><mml:mrow><mml:mo>|</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mi>j</mml:mi><mml:mo>|</mml:mo><mml:mo>≥</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula>), but <inline-formula id="IE116"><mml:math id="IM116" display="inline" overflow="scroll"><mml:mo>&lt;</mml:mo></mml:math></inline-formula>8 Å away in terms of atomic distance between their alpha carbon (<inline-formula id="IE117"><mml:math id="IM117" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>α</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula>) atoms (<xref rid="vbad042-B20" ref-type="bibr">Heffernan <italic toggle="yes">et al.</italic>, 2017</xref>). We computed the average number of non-local interactions per residue for each of the 1213 target proteins in the TEST2016 dataset and sorted the proteins in an ascending order of their average number of non-local interactions per residue. Next, we put them in six equal-sized bins (<inline-formula id="IE118"><mml:math id="IM118" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mn>6</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) where the first bin contained the proteins with the lowest level of non-local interactions (0-0.61 non-local contacts per residue) and the sixth bin contains the proteins with the highest level of non-local interactions (1.64–2.70 non-local contacts per residue). <xref rid="vbad042-F3" ref-type="fig">Figure 3</xref> shows the MAE<inline-formula id="IE119"><mml:math id="IM119" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ϕ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and MAE<inline-formula id="IE120"><mml:math id="IM120" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ϕ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> for the best performing methods for these six bins.</p>
        <fig position="float" id="vbad042-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>MAE(<inline-formula id="IE121"><mml:math id="IM121" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>) and MAE(<inline-formula id="IE122"><mml:math id="IM122" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>) of SAINT-Angle and the best alternative methods under various levels of non-local interactions. We show the results on the TEST2016 test set using six bins of proteins. (<bold>a</bold>) MAE(<inline-formula id="IE123"><mml:math id="IM123" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>) of SAINT-Angle, OPUS-TASS and SPOT-1D under various levels of non-local contacts. (<bold>b</bold>) MAE(<inline-formula id="IE124"><mml:math id="IM124" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>) of SAINT-Angle, OPUS-TASS and SPOT-1D under various levels of non-local contacts. (<bold>c</bold>–<bold>d</bold>) MAE(<inline-formula id="IE125"><mml:math id="IM125" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>) and MAE(<inline-formula id="IE126"><mml:math id="IM126" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>) of SAINT-Angle-Single and ESIDEN under various levels of non-local contacts</p>
          </caption>
          <graphic xlink:href="vbad042f3" position="float"/>
        </fig>
        <p>These results show that—as expected—the performance of SAINT-Angle and other methods degrades as we increase the number of non-local contacts. However, SAINT-Angle is consistently and significantly (<italic toggle="yes">P</italic>-value <inline-formula id="IE127"><mml:math id="IM127" display="inline" overflow="scroll"><mml:mrow><mml:mo>≪</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula>) better than the best alternate methods across all levels of non-local interactions. Moreover, the improvements of SAINT-Angle (or SAINT-Angle-Single) over other methods tend to gradually increase with increasing levels of non-local interactions from <inline-formula id="IE128"><mml:math id="IM128" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> to <inline-formula id="IE129"><mml:math id="IM129" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mn>6</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> (with a few exceptions), especially for the torsion angle <inline-formula id="IE130"><mml:math id="IM130" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>.</p>
        <p>Similarly, there is no notable difference between SPOT-1D and OPUS-TASS on <inline-formula id="IE131"><mml:math id="IM131" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, whereas there are notable differences on <inline-formula id="IE132"><mml:math id="IM132" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mn>6</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. These results indicate that long-range interactions have an impact on torsion angle prediction, and that capturing non-local interactions by self-attention modules is one of the contributing factors in the improvement of SAINT-Angle.</p>
      </sec>
      <sec>
        <title>3.6.2 Impact of 8-class (Q8) secondary structure states</title>
        <p>We analyzed the performance of various methods on the 1213 target proteins in the TEST2016 dataset across eight types of secondary structure states, namely <inline-formula id="IE133"><mml:math id="IM133" display="inline" overflow="scroll"><mml:mo>β</mml:mo></mml:math></inline-formula>-bridge (B), coil (C), <inline-formula id="IE134"><mml:math id="IM134" display="inline" overflow="scroll"><mml:mo>β</mml:mo></mml:math></inline-formula>-strand (E), <inline-formula id="IE135"><mml:math id="IM135" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>-helix (G), <inline-formula id="IE136"><mml:math id="IM136" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula>-helix (H), <inline-formula id="IE137"><mml:math id="IM137" display="inline" overflow="scroll"><mml:mo>π</mml:mo></mml:math></inline-formula>-helix (I), bend (S) and <inline-formula id="IE138"><mml:math id="IM138" display="inline" overflow="scroll"><mml:mo>β</mml:mo></mml:math></inline-formula>-turn (T). <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure </xref><xref rid="sup1" ref-type="supplementary-material">S3</xref> in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> shows the average MAE<inline-formula id="IE139"><mml:math id="IM139" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ϕ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and MAE<inline-formula id="IE140"><mml:math id="IM140" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ψ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> against each of the Q8 labels for various methods. These results suggest that H (<inline-formula id="IE141"><mml:math id="IM141" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula>-helix), G (<inline-formula id="IE142"><mml:math id="IM142" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>-helix), E (<inline-formula id="IE143"><mml:math id="IM143" display="inline" overflow="scroll"><mml:mo>β</mml:mo></mml:math></inline-formula>-strand) and I (<inline-formula id="IE144"><mml:math id="IM144" display="inline" overflow="scroll"><mml:mo>π</mml:mo></mml:math></inline-formula>-helix) regions usually have lower prediction errors whereas the non-ordinary states (<xref rid="vbad042-B50" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2016</xref>), such as S (bend), C (coil), B (<inline-formula id="IE145"><mml:math id="IM145" display="inline" overflow="scroll"><mml:mo>β</mml:mo></mml:math></inline-formula>-bridge) and T (<inline-formula id="IE146"><mml:math id="IM146" display="inline" overflow="scroll"><mml:mo>β</mml:mo></mml:math></inline-formula>-turn) regions generally have higher prediction errors. Another notable observation is that SAINT-Angle consistently obtained superior performance across all Q8 labels compared to its competing methods, except that OPUS-TASS and ESIDEN obtained marginally better average MAE<inline-formula id="IE147"><mml:math id="IM147" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>ψ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> values than SAINT-Angle on I states (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3b and d</xref>). Note that the I (<inline-formula id="IE148"><mml:math id="IM148" display="inline" overflow="scroll"><mml:mo>π</mml:mo></mml:math></inline-formula>-helix) secondary state is extremely rare, appearing in only about 15% of all known protein structures, and is difficult to predict (<xref rid="vbad042-B30" ref-type="bibr">Ludwiczak <italic toggle="yes">et al.</italic>, 2019</xref>). Notably, while the performances of different methods on the easy regions (e.g. H regions) are comparable, SAINT-Angle is notably better than other methods on regions where angle prediction is relatively hard (e.g. S and T regions).</p>
      </sec>
    </sec>
    <sec>
      <title>3.7 Case study</title>
      <p>In order to visually demonstrate the efficacy of SAINT-Angle in predicting the torsion angles, we conducted a case study to compare the protein backbone torsion angles predicted by SAINT-Angle-Single, ESIDEN and OPUS-TASS on two representative proteins from TEST2016 dataset (<xref rid="vbad042-B16" ref-type="bibr">Hanson <italic toggle="yes">et al.</italic>, 2018</xref>), namely 5TDY (chain C) and 5LSI (chain D). For each method, we calculated the residue-wise absolute error (AE) of the predicted <inline-formula id="IE149"><mml:math id="IM149" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula> and <inline-formula id="IE150"><mml:math id="IM150" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula> angles for these two proteins. We then plotted these residue-wise absolute errors against the corresponding secondary structure states (see <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S9</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S1 and S2</xref>). These figures indicate that <inline-formula id="IE151"><mml:math id="IM151" display="inline" overflow="scroll"><mml:mo>α</mml:mo></mml:math></inline-formula>-helix (H), <inline-formula id="IE152"><mml:math id="IM152" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>-helix (G) and bend (S) regions generally have lower prediction errors, while non-ordinary states such as coil (C) and <inline-formula id="IE153"><mml:math id="IM153" display="inline" overflow="scroll"><mml:mo>β</mml:mo></mml:math></inline-formula>-turn (T) regions tend to have higher prediction errors. Our results show that SAINT-Angle-Single consistently provides better predictions across various secondary structure states compared to the other methods, especially for <inline-formula id="IE154"><mml:math id="IM154" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula> angles. <xref rid="vbad042-F4" ref-type="fig">Figure 4</xref> shows the predicted structures, superimposed on the native structures, of 5TDY (chain C) and 5LSI (chain D) proteins using the angles predicted by SAINT-Angle, OPUS-TASS and ESIDEN. The figure suggests that coiled and turn regions are not always in alignment with those regions in the native structures. However, helical and bend regions almost always bear similarities with those regions in the native structures.</p>
      <fig position="float" id="vbad042-F4">
        <label>Fig. 4.</label>
        <caption>
          <p>Superpositions of the structures of two representative proteins—5TDY (chain C) and 5LSI (chain D)—using the torsion angles estimated by SAINT-Angle, OPUS-TASS and ESIDEN with the structures using the native angles obtained from PDB. The structures with native angles are shown in green, and those with SAINT-Angle-Single, OPUS-TASS and ESIDEN predicted angles are shown in blue, red and orange, respectively. (<bold>a–c</bold>) Superpositions for the 5TDY (chain C) for SAINT-angle, OPUS-TASS and ESIDEN, respectively. (<bold>d–f</bold>) Superpositions for the 5LSI (chain D) protein. These images were made using PyMOL (<xref rid="vbad042-B37" ref-type="bibr">Schrödinger, 2015</xref>)</p>
        </caption>
        <graphic xlink:href="vbad042f4" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>3.8 Running time</title>
      <p>Running time comparisons are presented in <xref rid="sup1" ref-type="supplementary-material">Supplementary Sect. 5</xref> in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>.</p>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusions</title>
    <p>We have presented SAINT-Angle, a highly accurate method for protein backbone torsion angles (<inline-formula id="IE155"><mml:math id="IM155" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula> and <inline-formula id="IE156"><mml:math id="IM156" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>) prediction. We have augmented the basic SAINT architecture for effective angle prediction and showed a successful utilization of transfer learning from pre-trained transformer-like language models. SAINT-Angle was assessed for its performance against the state-of-the-art backbone angles prediction methods on a collection of widely used benchmark datasets. Experimental results suggest that SAINT-Angle consistently improved upon the best existing methods.</p>
    <p>The self-attention module in the SAINT architecture was particularly aimed for effectively capturing long-range interactions, and our systematic analyses of the performance of different methods under various model conditions with varying levels of long-range interactions indicate that SAINT-Angle can better handle complex models conditions with high levels of long-range interactions. The improvement of SAINT-Angle over other methods in <inline-formula id="IE157"><mml:math id="IM157" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula> prediction, which is typically harder to predict than <inline-formula id="IE158"><mml:math id="IM158" display="inline" overflow="scroll"><mml:mo>ϕ</mml:mo></mml:math></inline-formula>, is noteworthy as it achieved more than 2–6 degree less MAE(<inline-formula id="IE159"><mml:math id="IM159" display="inline" overflow="scroll"><mml:mo>ψ</mml:mo></mml:math></inline-formula>) than other methods on benchmark datasets.</p>
    <p>We utilized transfer learning using the extracted features from the protein language model ProtTrans . The <italic toggle="yes">ProtTrans</italic> architecture (discussed in <xref rid="sec2.2.2.2" ref-type="sec">Sect. 2.2.2.2</xref>) alone (i.e. without the ensemble network) performs better than the existing best methods like OPUS-TASS and SPOT-1D—showing the positive impact of transfer learning in protein attribute prediction. We also analyzed the novel evolutionary features proposed in <xref rid="vbad042-B55" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>. Our analyses with the evolutionary features reconfirms the effectiveness of the evolutionary features in protein angle prediction which was first demonstrated by <xref rid="vbad042-B55" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>. Our results also suggest that the architecture of SAINT-Angle is <italic toggle="yes">feature-robust</italic>, as it performs well with different types of features [e.g. ProtTrans features, evolutionary features proposed by <xref rid="vbad042-B55" ref-type="bibr">Xu <italic toggle="yes">et al.</italic> (2021)</xref>] and consistently outperforms other competing methods on varying feature sets. Given this demonstrated performance improvement on various benchmark datasets and under challenging model conditions, we believe SAINT-Angle advances the state-of-the-art in this domain, and will be considered as a useful tool for predicting the backbone torsion angles.</p>
    <p>This study can be extended in several directions. As an immediate future direction, we plan to train a multi-task learning model by leveraging the original SAINT and the proposed SAINT-Angle architectures, which will simultaneously predict residue-wise protein secondary structures along with backbone torsion angles. Although SAINT-Angle appears to be feature-robust, follow-up studies need to investigate various features and select a small set of simple features that are sufficient for SAINT-Angle to predict backbone angles with reasonable accuracy. Our study suggests that SAINT-Angle—even when run with only the ProtTrans features (i.e. without using any alignment profile-based features such as PSSM or HMM)—performs notably well. Therefore, pretrained protein language model-based methods do not appear to require a certain level of homologous sequences for reasonably accurate prediction. On the other hand, MSA-based methods are less successful on ‘orphan proteins’—proteins with few or no homologs (<xref rid="vbad042-B6" ref-type="bibr">Chowdhury <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="vbad042-B33" ref-type="bibr">Michaud <italic toggle="yes">et al.</italic>, 2022</xref>). For example, AlphaFold2 (<xref rid="vbad042-B24" ref-type="bibr">Jumper <italic toggle="yes">et al.</italic>, 2021</xref>)—which made remarkable advancements in protein structure prediction accuracy—requires at least 30 effective homologous sequences to achieve an accurate structure prediction (<xref rid="vbad042-B42" ref-type="bibr">Singh et al., 2022b</xref>). <xref rid="vbad042-B6" ref-type="bibr">Chowdhury <italic toggle="yes">et al.</italic> (2022)</xref> presented a protein language model (AminoBERT)-based method which outperformed AlphaFold2 in predicting structures of orphan proteins. However, further extensive studies are necessary to draw firm conclusions on how the performance of language model-based methods vary with varying amounts of homologous sequences. Another future research direction is to extend and utilize the proposed model as well as predicted angles to infer other protein attributes. This may allow us to observe the effect of the improvement, our method brings about, in downstream analyses.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>vbad042_Supplementary_Data</label>
      <media xlink:href="vbad042_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>The authors thank the anonymous reviewers for their valuable suggestions. They thank the authors of SPOT-1D-LM for sharing their dataset.</p>
  </ack>
  <sec>
    <title>Author contributions</title>
    <p>M.S.B. and M.S.R. conceived the study, M.S.B. and S.M. designed the study, A.K.M.M.H., A.Y.A., S.M. and M.S.B developed the method, A.K.M.M.H. and A.Y.A. implemented the code and performed all the analyses, M.S.B., A.Y.A. and A.K.M.M.H. wrote the first draft, all authors contributed to the final manuscript.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was partially supported by the Research and Innovation Centre for Science and Engineering at BUET (RISE-BUET) Internal Research Grant (Project ID: 2021-01-016).</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The software and data are available at <ext-link xlink:href="https://github.com/bayzidlab/SAINT-Angle" ext-link-type="uri">https://github.com/bayzidlab/SAINT-Angle</ext-link>.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="vbad042-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Adhikari</surname><given-names>A.N.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>De novo prediction of protein folding pathways and structure using the principle of sequential stabilization</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>109</volume>, <fpage>17442</fpage>–<lpage>17447</lpage>.<pub-id pub-id-type="pmid">23045636</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>AlQuraishi</surname><given-names>M.</given-names></string-name></person-group> (<year>2019</year>) <article-title>End-to-end differentiable learning of protein structure</article-title>. <source>Cell Syst</source>., <volume>8</volume>, <fpage>292</fpage>–<lpage>301.e3</lpage>.<pub-id pub-id-type="pmid">31005579</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altschul</surname><given-names>S.F.</given-names></string-name></person-group><etal>et al</etal> (<year>1997</year>) <article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>. <source>Nucleic Acids Res</source>., <volume>25</volume>, <fpage>3389</fpage>–<lpage>3402</lpage>.<pub-id pub-id-type="pmid">9254694</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bengio</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>1994</year>) <article-title>Learning long-term dependencies with gradient descent is difficult</article-title>. <source>IEEE Trans. Neural Netw</source>., <volume>5</volume>, <fpage>157</fpage>–<lpage>166</lpage>.<pub-id pub-id-type="pmid">18267787</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bystroff</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2000</year>) <article-title>HMMSTR: a hidden Markov model for local sequence–structure correlations in proteins</article-title>. <source>J. Mol. Biol</source>., <volume>301</volume>, <fpage>173</fpage>–<lpage>190</lpage>.<pub-id pub-id-type="pmid">10926500</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chowdhury</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>Single-sequence protein structure prediction using a language model and deep learning</article-title>. <source>Nat. Biotechnol</source>., <volume>40</volume>, <fpage>1617</fpage>–<lpage>1623</lpage>.<pub-id pub-id-type="pmid">36192636</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B7">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Dai</surname><given-names>Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) Transformer-xl: attentive language models beyond a fixed-length context. In: <italic toggle="yes">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</italic>, Florence, Italy, pp. <fpage>2978</fpage>–<lpage>2988</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B8">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Devlin</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) BERT: Pre-training of deep bidirectional transformers for language understanding. In: <italic toggle="yes">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</italic>, pp. <fpage>4171</fpage>–<lpage>4186</lpage>. Association for Computational Linguistics, Minneapolis, MN. doi:<pub-id pub-id-type="doi">10.18653/v1/N19-1423</pub-id>. <ext-link xlink:href="https://www.aclweb.org/anthology/N19-1423" ext-link-type="uri">https://www.aclweb.org/anthology/N19-1423</ext-link>.</mixed-citation>
    </ref>
    <ref id="vbad042-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dor</surname><given-names>O.</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>Y.</given-names></string-name></person-group> (<year>2007</year>) <article-title>Real-spine: an integrated system of neural networks for real-value prediction of protein structural properties</article-title>. <source>Proteins</source>, <volume>68</volume>, <fpage>76</fpage>–<lpage>81</lpage>.<pub-id pub-id-type="pmid">17397056</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Elnaggar</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>ProtTrans: towards cracking the language of life’s code through self-supervised learning</article-title>. <italic toggle="yes">IEEE Transactions on Pattern Analysis and Machine Intelligence</italic>, <volume>44</volume>, <fpage>7112</fpage>–<lpage>7127</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fang</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2018a</year>) <article-title>MUFold-SS: new deep inception-inside-inception networks for protein secondary structure prediction</article-title>. <source>Proteins</source>, <volume>86</volume>, <fpage>592</fpage>–<lpage>598</lpage>.<pub-id pub-id-type="pmid">29492997</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fang</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2018b</year>) <article-title>Prediction of protein backbone torsion angles using deep residual inception neural networks</article-title>. <source>IEEE/ACM Trans. Comput. Biol. Bioinf</source>., <volume>16</volume>, <fpage>1020</fpage>–<lpage>1028</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gao</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>RaptorX-Angle: real-value prediction of protein backbone dihedral angles through a hybrid method of clustering and deep learning</article-title>. <source>BMC Bioinformatics</source>, <volume>19</volume>, <fpage>73</fpage>–<lpage>84</lpage>.<pub-id pub-id-type="pmid">29490628</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Greener</surname><given-names>J.G.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Deep learning extends de novo protein modelling coverage of genomes using iteratively predicted structural constraints</article-title>. <source>Nat. Commun</source>., <volume>10</volume>, <fpage>1</fpage>–<lpage>13</lpage>.<pub-id pub-id-type="pmid">30602773</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hanson</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>Accurate prediction of protein contact maps by coupling residual two-dimensional bidirectional long short-term memory with convolutional neural networks</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>4039</fpage>–<lpage>4045</lpage>.<pub-id pub-id-type="pmid">29931279</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hanson</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Improving prediction of protein secondary structure, backbone angles, solvent accessibility and contact numbers by using predicted contact maps and an ensemble of recurrent and residual convolutional neural networks</article-title>. <source>Bioinformatics</source>, <volume>35</volume>, <fpage>2403</fpage>–<lpage>2410</lpage>.<pub-id pub-id-type="pmid">30535134</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B18">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) Deep residual learning for image recognition. In: <italic toggle="yes">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</italic>, Las Vegas, NV, USA, pp. <fpage>770</fpage>–<lpage>778</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heffernan</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) <article-title>Improving prediction of secondary structure, local backbone angles and solvent accessible surface area of proteins by iterative deep learning</article-title>. <source>Sci. Rep</source>., <volume>5</volume>, <fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heffernan</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Capturing non-local interactions by long short-term memory bidirectional recurrent neural networks for improving prediction of protein secondary structure, backbone angles, contact numbers and solvent accessibility</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>2842</fpage>–<lpage>2849</lpage>.<pub-id pub-id-type="pmid">28430949</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hochreiter</surname><given-names>S.</given-names></string-name>, <string-name><surname>Schmidhuber</surname><given-names>J.</given-names></string-name></person-group> (<year>1997</year>) <article-title>Long short-term memory</article-title>. <source>Neural Comput</source>., <volume>9</volume>, <fpage>1735</fpage>–<lpage>1780</lpage>.<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B22">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ioffe</surname><given-names>S.</given-names></string-name>, <string-name><surname>Szegedy</surname><given-names>C.</given-names></string-name></person-group> (<year>2015</year>) Batch normalization: accelerating deep network training by reducing internal covariate shift. In <italic toggle="yes">International Conference on Machine Learning</italic>, Lille, France, pp. <fpage>448</fpage>–<lpage>456</lpage>. PMLR.</mixed-citation>
    </ref>
    <ref id="vbad042-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiang</surname><given-names>Q.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Protein secondary structure prediction: a survey of the state of the art</article-title>. <source>J. Mol. Graph. Modell</source>., <volume>76</volume>, <fpage>379</fpage>–<lpage>402</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jumper</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Highly accurate protein structure prediction with alphafold</article-title>. <source>Nature</source>, <volume>596</volume>, <fpage>583</fpage>–<lpage>589</lpage>.<pub-id pub-id-type="pmid">34265844</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Karchin</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2003</year>) <article-title>Hidden Markov models that use predicted local structure for fold recognition: alphabets of backbone geometry</article-title>. <source>Proteins</source>, <volume>51</volume>, <fpage>504</fpage>–<lpage>514</lpage>.<pub-id pub-id-type="pmid">12784210</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B26">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>D.P.</given-names></string-name>, <string-name><surname>Ba</surname><given-names>J.</given-names></string-name></person-group> (<year>2015</year>) Adam: a method for stochastic optimization. In: Bengio, Y. and LeCun, Y. (eds), <italic toggle="yes">Proceedings of the 3rd International Conference on Learning Representations (ICLR), </italic>San Diego, CA<italic toggle="yes">.</italic></mixed-citation>
    </ref>
    <ref id="vbad042-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Klausen</surname><given-names>M.S.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Netsurfp-2.0: improved prediction of protein structural features by integrated deep learning</article-title>. <source>Proteins</source>, <volume>87</volume>, <fpage>520</fpage>–<lpage>527</lpage>.<pub-id pub-id-type="pmid">30785653</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>LeCun</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>1998</year>) <article-title>Gradient-based learning applied to document recognition</article-title>. <source>Proc. IEEE</source>, <volume>86</volume>, <fpage>2278</fpage>–<lpage>2324</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B29">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lounici</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2009</year>) Taking advantage of sparsity in multi-task learning. In: <italic toggle="yes">Proceedings of the 22nd Conference on Learning Theory (2009)</italic>, Montreal, Quebec.</mixed-citation>
    </ref>
    <ref id="vbad042-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ludwiczak</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>PiPred—a deep-learning method for prediction of <italic toggle="yes">π</italic>-helices in protein sequences</article-title>. <source>Sci. Rep</source>., <volume>9</volume>, <fpage>1</fpage>–<lpage>9</lpage>.<pub-id pub-id-type="pmid">30626917</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mahbub</surname><given-names>S</given-names></string-name>, <string-name><surname>Bayzid</surname><given-names>M.S.</given-names></string-name></person-group> (<year>2022</year>) <article-title>EGRET: edge aggregated graph attention networks and transfer learning improve protein–protein interaction site prediction</article-title>. <source>Brief. Bioinf</source>., <volume>23</volume>, <fpage>bbab578</fpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meiler</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2001</year>) <article-title>Generation and evaluation of dimension-reduced amino acid parameter representations by artificial neural networks</article-title>. <source>Mol. Model. Annu</source>., <volume>7</volume>, <fpage>360</fpage>–<lpage>369</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Michaud</surname><given-names>J.M.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>A language model beats alphafold2 on orphans</article-title>. <source>Nat. Biotechnol</source>., <volume>40</volume>, <fpage>1576</fpage>–<lpage>1577</lpage>.<pub-id pub-id-type="pmid">36192635</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ramachandran</surname><given-names>G.</given-names></string-name></person-group><etal>et al</etal> (<year>1963</year>) <article-title>Stereochemistry of polypeptide chain configurations</article-title>. <source>J. Mol. Biol</source>., <volume>7</volume>, <fpage>95</fpage>–<lpage>99</lpage>.<pub-id pub-id-type="pmid">13990617</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B35">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Rao</surname><given-names>R.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Transformer protein language models are unsupervised structure learners</article-title>. In: <source>Proceedings of the 9th International Conference on Learning Representations</source>, Vienna.</mixed-citation>
    </ref>
    <ref id="vbad042-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Remmert</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>HHblits: lightning-fast iterative protein sequence searching by HMM–HMM alignment</article-title>. <source>Nat. Methods</source>, <volume>9</volume>, <fpage>173</fpage>–<lpage>175</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B37">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Schrödinger</surname><given-names>L.</given-names></string-name></person-group> (<year>2015</year>) The PyMOL molecular graphics system, version 1.8.</mixed-citation>
    </ref>
    <ref id="vbad042-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schuster</surname><given-names>M.</given-names></string-name>, <string-name><surname>Paliwal</surname><given-names>K.K.</given-names></string-name></person-group> (<year>1997</year>) <article-title>Bidirectional recurrent neural networks</article-title>. <source>IEEE Trans. Signal Process</source>., <volume>45</volume>, <fpage>2673</fpage>–<lpage>2681</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Senior</surname><given-names>A.W.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Improved protein structure prediction using potentials from deep learning</article-title>. <source>Nature</source>, <volume>577</volume>, <fpage>706</fpage>–<lpage>710</lpage>.<pub-id pub-id-type="pmid">31942072</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singh</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>SPOT-1D-Single: improving the single-sequence-based prediction of protein secondary structure, backbone angles, solvent accessibility and half-sphere exposures using a large training set and ensembled deep learning</article-title>. <source>Bioinformatics</source>, <volume>37</volume>, <fpage>3464</fpage>–<lpage>3472</lpage>.<pub-id pub-id-type="pmid">33983382</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singh</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2022a</year>) <article-title>SPOT-Contact-LM: improving single-sequence-based prediction of protein contact map using a transformer language model</article-title>. <source>Bioinformatics</source>, <volume>38</volume>, <fpage>1888</fpage>–<lpage>1894</lpage>.<pub-id pub-id-type="pmid">35104320</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singh</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>May 2022b</year>) <article-title>Reaching alignment-profile-based accuracy in predicting protein secondary and tertiary structural properties without alignment</article-title>. <source>Sci. Rep</source>., <volume>12</volume>, <fpage>7607</fpage>.<pub-id pub-id-type="pmid">35534620</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Söding</surname><given-names>J.</given-names></string-name></person-group> (<year>2005</year>) <article-title>Protein homology detection by HMM–HMM comparison</article-title>. <source>Bioinformatics</source>, <volume>21</volume>, <fpage>951</fpage>–<lpage>960</lpage>.<pub-id pub-id-type="pmid">15531603</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B44">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Szegedy</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) Inception-v4, inception–ResNet and the impact of residual connections on learning. In: <italic toggle="yes">Thirty-First AAAI Conference on Artificial Intelligence</italic>, San Francisco, CA, USA.</mixed-citation>
    </ref>
    <ref id="vbad042-B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tian</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Amino acid torsion angles enable prediction of protein fold classification</article-title>. <source>Sci. Rep</source>., <volume>10</volume>, <fpage>21773</fpage>.<pub-id pub-id-type="pmid">33303802</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Uddin</surname><given-names>M.R.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>SAINT: self-attention augmented inception-inside-inception network improves protein secondary structure prediction</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>4599</fpage>–<lpage>4608</lpage>.<pub-id pub-id-type="pmid">32437517</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B47">
      <mixed-citation publication-type="journal"><collab>UniProt Consortium</collab>. (<year>2007</year>) <article-title>The universal protein resource (UniProt)</article-title>. <source>Nucleic Acids Res</source>., <volume>36</volume>, <fpage>D190</fpage>–<lpage>D195</lpage>.<pub-id pub-id-type="pmid">18045787</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vaswani</surname><given-names>A.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Attention is all you need</article-title>. In: Guyon, I. <italic toggle="yes">et al</italic>. (eds) <source>Advances in Neural Information Processing Systems</source>. Curran Associates, Inc., Long Beach, CA, pp. <fpage>5998</fpage>–<lpage>6008</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>G.</given-names></string-name>, <string-name><surname>Dunbrack</surname><given-names>R.L.</given-names><suffix>Jr</suffix></string-name></person-group>. (<year>2003</year>) <article-title>Pisces: a protein sequence culling server</article-title>. <source>Bioinformatics</source>, <volume>19</volume>, <fpage>1589</fpage>–<lpage>1591</lpage>.<pub-id pub-id-type="pmid">12912846</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>Protein secondary structure prediction using deep convolutional neural fields</article-title>. <source>Sci. Rep</source>., <volume>6</volume>, <fpage>1</fpage>–<lpage>11</lpage>.<pub-id pub-id-type="pmid">28442746</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilcoxon</surname><given-names>F.</given-names></string-name></person-group><etal>et al</etal> (<year>1970</year>) <article-title>Critical values and probability levels for the Wilcoxon rank sum test and the Wilcoxon signed rank test</article-title>. <source>Select. Tables Math. Stat</source>., <volume>1</volume>, <fpage>171</fpage>–<lpage>259</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname><given-names>S.</given-names></string-name>, <string-name><surname>Zhang</surname><given-names>Y.</given-names></string-name></person-group> (<year>2008</year>) <article-title>ANGLOR: a composite machine-learning algorithm for protein backbone torsion angle prediction</article-title>. <source>PLoS ONE</source>, <volume>3</volume>, <fpage>e3400</fpage>.<pub-id pub-id-type="pmid">18923703</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>G.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>OPUS-TASS: a protein backbone torsion angles and secondary structure predictor based on ensemble neural networks</article-title>. <source>Bioinformatics</source>, <volume>36</volume>, <fpage>5021</fpage>–<lpage>5026</lpage>.<pub-id pub-id-type="pmid">32678893</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>J.</given-names></string-name></person-group> (<year>2019</year>) <article-title>Distance-based protein folding powered by deep learning</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>116</volume>, <fpage>16856</fpage>–<lpage>16865</lpage>.<pub-id pub-id-type="pmid">31399549</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B55">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>Y.-C.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Accurate prediction of protein torsion angles using evolutionary signatures and recurrent neural network</article-title>. <source>Sci. Rep</source>., <volume>11</volume>, <fpage>1</fpage>–<lpage>11</lpage>.<pub-id pub-id-type="pmid">33414495</pub-id></mixed-citation>
    </ref>
    <ref id="vbad042-B56">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>XLNet: generalized autoregressive pretraining for language understanding</article-title>. In: Wallach, H. <italic toggle="yes">et al</italic>. (eds) <source>Advances in Neural Information Processing Systems</source>. Curran Associates, Inc., Van Couver, BC, Canada, pp. <fpage>5753</fpage>–<lpage>5763</lpage>.</mixed-citation>
    </ref>
    <ref id="vbad042-B57">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Yu</surname><given-names>S.</given-names></string-name>, <string-name><surname>Tomasi</surname><given-names>C.</given-names></string-name></person-group> (<year>2019</year>) Identity connections in residual nets improve noise stability. In: <italic toggle="yes">Proceedings of the ICML 2019 Workshop on Understanding and Improving Generalization in Deep Learning</italic>, Long Beach, CA.</mixed-citation>
    </ref>
  </ref-list>
</back>
