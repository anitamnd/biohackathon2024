<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?subarticle pone.0255674.r001?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS One</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLoS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8445633</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0255674</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-21-14202</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Organisms</subject>
          <subj-group>
            <subject>Eukaryota</subject>
            <subj-group>
              <subject>Animals</subject>
              <subj-group>
                <subject>Invertebrates</subject>
                <subj-group>
                  <subject>Annelids</subject>
                  <subj-group>
                    <subject>Earthworms</subject>
                  </subj-group>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Zoology</subject>
          <subj-group>
            <subject>Animals</subject>
            <subj-group>
              <subject>Invertebrates</subject>
              <subj-group>
                <subject>Annelids</subject>
                <subj-group>
                  <subject>Earthworms</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Digital Imaging</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Taxonomy</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Data Management</subject>
          <subj-group>
            <subject>Taxonomy</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Support Vector Machines</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Earth Sciences</subject>
        <subj-group>
          <subject>Soil Science</subject>
          <subj-group>
            <subject>Soil Ecology</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Management Engineering</subject>
          <subj-group>
            <subject>Decision Analysis</subject>
            <subj-group>
              <subject>Decision Trees</subject>
              <subj-group>
                <subject>Decision Tree Learning</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Decision Analysis</subject>
          <subj-group>
            <subject>Decision Trees</subject>
            <subj-group>
              <subject>Decision Tree Learning</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Decision Tree Learning</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Imaging Techniques</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>ESIDE: A computationally intelligent method to identify earthworm species (<italic toggle="yes">E. fetida</italic>) from digital images: Application in taxonomy</article-title>
      <alt-title alt-title-type="running-head">ESIDE: Earthworm species identification system</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Andleeb</surname>
          <given-names>Saiqa</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Data curation</role>
        <role content-type="https://casrai.org/credit/">Funding acquisition</role>
        <role content-type="https://casrai.org/credit/">Investigation</role>
        <role content-type="https://casrai.org/credit/">Supervision</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7691-5715</contrib-id>
        <name>
          <surname>Abbasi</surname>
          <given-names>Wajid Arshad</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Conceptualization</role>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Methodology</role>
        <role content-type="https://casrai.org/credit/">Software</role>
        <role content-type="https://casrai.org/credit/">Supervision</role>
        <role content-type="https://casrai.org/credit/">Validation</role>
        <role content-type="https://casrai.org/credit/">Writing – original draft</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ghulam Mustafa</surname>
          <given-names>Rozina</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Data curation</role>
        <role content-type="https://casrai.org/credit/">Validation</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Islam</surname>
          <given-names>Ghafoor ul</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Data curation</role>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Naseer</surname>
          <given-names>Anum</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Data curation</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shafique</surname>
          <given-names>Irsa</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Data curation</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Parween</surname>
          <given-names>Asma</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Data curation</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shaheen</surname>
          <given-names>Bushra</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Data curation</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shafiq</surname>
          <given-names>Muhamad</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff003" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Altaf</surname>
          <given-names>Muhammad</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff004" ref-type="aff">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ali Abbas</surname>
          <given-names>Syed</given-names>
        </name>
        <role content-type="https://casrai.org/credit/">Formal analysis</role>
        <role content-type="https://casrai.org/credit/">Resources</role>
        <role content-type="https://casrai.org/credit/">Validation</role>
        <role content-type="https://casrai.org/credit/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Biotechnology Laboratory, Department of Zoology, King Abdullah Campus, University of Azad Jammu &amp; Kashmir, Muzaffarabad, AJ&amp;K, Pakistan</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Computaional Biology and Data Analysis Laboratory, Department of Computer Sciences &amp; Information Technology, King Abdullah Campus, University of Azad Jammu &amp; Kashmir, Muzaffarabad, AJ&amp;K, Pakistan</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Environmental Protection Agency (AJK-EPA), Government of Azad Jammu and Kashmir, Muzaffarabad, AJ&amp;K, Pakistan</addr-line>
    </aff>
    <aff id="aff004">
      <label>4</label>
      <addr-line>Department of Forestry Range and Wildlife Management, The Islamia University of Bahawalpur, Bahawalpur, Pakistan</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Bhadauria</surname>
          <given-names>Tunira</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Feroze Gandhi Degree College, INDIA</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>wajidarshad@gmail.com</email>, <email>wajidarshad@ajku.edu.pk</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>16</day>
      <month>9</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>16</volume>
    <issue>9</issue>
    <elocation-id>e0255674</elocation-id>
    <history>
      <date date-type="received">
        <day>29</day>
        <month>4</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>21</day>
        <month>7</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2021 Andleeb et al</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Andleeb et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pdf" xlink:href="pone.0255674.pdf"/>
    <abstract>
      <p>Earthworms (Crassiclitellata) being ecosystem engineers significantly affect the physical, chemical, and biological properties of the soil by recycling organic material, increasing nutrient availability, and improving soil structure. The efficiency of earthworms in ecology varies along with species. Therefore, the role of taxonomy in earthworm study is significant. The taxonomy of earthworms cannot reliably be established through morphological characteristics because the small and simple body plan of the earthworm does not have anatomical complex and highly specialized structures. Recently, molecular techniques have been adopted to accurately classify the earthworm species but these techniques are time-consuming and costly. To combat this issue, in this study, we propose a machine learning-based earthworm species identification model that uses digital images of earthworms. We performed a stringent performance evaluation not only through 10-fold cross-validation and on an external validation dataset but also in real settings by involving an experienced taxonomist. In all the evaluation settings, our proposed model has given state-of-the-art performance and justified its use to aid earthworm taxonomy studies. We made this model openly accessible through a cloud-based webserver and python code available at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://sites.google.com/view/wajidarshad/software" ext-link-type="uri">https://sites.google.com/view/wajidarshad/software</ext-link> and <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/wajidarshad/ESIDE" ext-link-type="uri">https://github.com/wajidarshad/ESIDE</ext-link>.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100004681</institution-id>
            <institution>Higher Education Commission, Pakistan</institution>
          </institution-wrap>
        </funding-source>
        <award-id>NRPU-2907 &amp; TDF-02006</award-id>
        <principal-award-recipient>
          <name>
            <surname>Andleeb</surname>
            <given-names>Saiqa</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>Saiqa Andleeb acknowledges the support of the Higher Education Commission (HEC) of Pakistan for granting research projects under the National Research Program for Universities (NRPU) and Technology Development Fund (TDF)(Grant ids: NRPU-2907 &amp; TDF-02006). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="4"/>
      <table-count count="4"/>
      <page-count count="12"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value><ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/wajidarshad/ESIDE/tree/main/dataset" ext-link-type="uri">https://github.com/wajidarshad/ESIDE/tree/main/dataset</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p><ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/wajidarshad/ESIDE/tree/main/dataset" ext-link-type="uri">https://github.com/wajidarshad/ESIDE/tree/main/dataset</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>1. Background</title>
    <p>Earthworms (Crassiclitellata) also known as rainworms are terrestrial invertebrates, habitually found in soil, eating a wide variety of organic matter [<xref rid="pone.0255674.ref001" ref-type="bibr">1</xref>]. Earthworms normally burrow during the day and consume soil and extract nutrients from decomposing organic matter such as leaves and roots [<xref rid="pone.0255674.ref002" ref-type="bibr">2</xref>]. Earthworms vibrantly affect soil health by transporting nutrients and minerals from below to the surface through their waste and their passageways ventilate the ground. Earthworms being ecosystem engineers significantly affect the physical, chemical, and biological properties of the soil by recycling organic material, increasing nutrient availability, and improving soil structure [<xref rid="pone.0255674.ref003" ref-type="bibr">3</xref>].</p>
    <p>Earthworms with more than 6000 extant species constitute a highly diverse group of burrowing annelids [<xref rid="pone.0255674.ref004" ref-type="bibr">4</xref>]. The ecology niche and life strategies of earthworms vary from species to species [<xref rid="pone.0255674.ref004" ref-type="bibr">4</xref>]. Moreover, the presence of more than one species in mixed cultures leads to lower reproduction rates and ineffective ecosystem engineering [<xref rid="pone.0255674.ref004" ref-type="bibr">4</xref>]. Many important activities performed by pharmacologists, farmers, taxonomists, foresters, conservation biologists, and technical personnel of environmental agencies such as monitoring endangered species, studying biodiversity, and determining the impact of climate change depend on accurate species identification. Therefore, the role of taxonomy in earthworm study is significant as without a reliable taxonomy most of the ecological studies are irrelevant [<xref rid="pone.0255674.ref005" ref-type="bibr">5</xref>]. Based on feeding habits and soil profile, earthworms have been classified into three main categories: epigeic, anecic, and endogeic. These parameters are not sufficient to classify earthworms properly and therefore, for the vast majority, nothing is known about their biology and ecology [<xref rid="pone.0255674.ref004" ref-type="bibr">4</xref>, <xref rid="pone.0255674.ref005" ref-type="bibr">5</xref>].</p>
    <p>Mostly, the taxonomy of earthworms is established using different morphological characteristics such as prostomium shape, position, segment number and shape of clitellum, spermathecae, and the arrangements of setae [<xref rid="pone.0255674.ref004" ref-type="bibr">4</xref>, <xref rid="pone.0255674.ref005" ref-type="bibr">5</xref>]. However, taxonomic classification based on these morphological characteristics is difficult in most of the species and requires a high degree of expertise because the small and simple body plan of earthworms does not have anatomical complex and highly specialized structures [<xref rid="pone.0255674.ref006" ref-type="bibr">6</xref>, <xref rid="pone.0255674.ref007" ref-type="bibr">7</xref>]. Recent molecular-based techniques such as 16S rDNA, 18S rDNA, and COI sequences have been successfully used as an alternative approach for earthworm identification [<xref rid="pone.0255674.ref006" ref-type="bibr">6</xref>, <xref rid="pone.0255674.ref008" ref-type="bibr">8</xref>, <xref rid="pone.0255674.ref009" ref-type="bibr">9</xref>]. However, these technologies need a wide database of DNA sequences of earthworms and involve enormous time and budget. Therefore, there is an utmost requirement for a computational approach that can assist studies to identify and correctly establish the taxonomy of different earthworm species.</p>
    <p>In this study, we propose a machine learning-based earthworm species identification model that uses digital images of earthworms. Machine learning has successfully been used to classify different animal species in digital images [<xref rid="pone.0255674.ref010" ref-type="bibr">10</xref>, <xref rid="pone.0255674.ref011" ref-type="bibr">11</xref>]. Currently, as a pilot study, we have only focused on <italic toggle="yes">Eisenia fetida</italic> (tiger worm) because of its wide range of applications in the field of medicine, pharmaceutical, and agriculture and constraints of availability of data in the form of digital images. <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic> possessed anticoagulation and fibrinolytic activity [<xref rid="pone.0255674.ref012" ref-type="bibr">12</xref>], act as an antitumor, antioxidant, wound healing, and antibacterial agents [<xref rid="pone.0255674.ref012" ref-type="bibr">12</xref>, <xref rid="pone.0255674.ref013" ref-type="bibr">13</xref>], best for vermicomposting [<xref rid="pone.0255674.ref014" ref-type="bibr">14</xref>]. Here, we aim to develop a method that uses a digital image of an earthworm and predict whether it is <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic> or not. To the best of our knowledge, this is the first attempt to design such a method to identify earthworm species from digital images.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>2. Methods</title>
    <p>In this section, we give the detail of our methodology adopted to design and develop a machine learning-based earthworm species identification system and its evaluation.</p>
    <sec id="sec003">
      <title>2.1. Dataset and preprocessing</title>
      <p>For this study, we have collected samples of various earthworm species including <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic> from different localities of Azad Jammu and Kashmir, Pakistan. After carefully washing, we took digital images of all the collected samples with a high-quality digital camera (Nikon D5300). After getting high-quality images, we have sorted out these images into two categories <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic> and others by consulting taxonomy experts in the field. In this way, we have a dataset of 1240 images of <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic> and 772 images of other species.</p>
      <p>We have cropped and enhanced all the images in our dataset to be used in the proposed machine learning setting. Cropping involves removing the unwanted area of the image to emphasize earthworm only. We cropped images in our dataset by bounding boxes using Adobe Photoshop (version 19). Different image enhancement techniques such as adaptive histogram equalization (AHE) have also been applied to improve the quality and the local contrast of the images [<xref rid="pone.0255674.ref015" ref-type="bibr">15</xref>]. These enhancement techniques have been applied using a python based tool called Scikit-Image (version: 0.17.2) [<xref rid="pone.0255674.ref016" ref-type="bibr">16</xref>].</p>
    </sec>
    <sec id="sec004">
      <title>2.2. Proposed methodology</title>
      <p>We propose a machine learning-based approach for the identification of earthworm species (<italic toggle="yes">E. fetida</italic>) from raw digital images. Various steps involved in earthworm species (<italic toggle="yes">E. fetida</italic>) identification using our proposed scheme are given in <xref rid="pone.0255674.g001" ref-type="fig">Fig 1</xref> and discussed below (please also see <xref rid="pone.0255674.s001" ref-type="supplementary-material">S1 Video</xref>). We have used conventional (shallow) machine learning models such as support vector machines (SVMs) and transfer learning paradigm instead of deep learning due to data scarcity.</p>
      <fig position="float" id="pone.0255674.g001">
        <object-id pub-id-type="doi">10.1371/journal.pone.0255674.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>A proposed methodology for the development of computer-aided identification of earthworm species (<italic toggle="yes">E</italic>. <italic toggle="yes">Fetida</italic>) using machine learning and digital images.</title>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0255674.g001" position="float"/>
      </fig>
      <sec id="sec005">
        <title>2.2.1. Feature extraction</title>
        <p>In image analysis, feature extraction is important as it involves obtaining the most relevant details from the image by reducing dimensionality. If we employ a better feature extraction technique, then it can be expected that the extracted features will better represent the relevant information to perform well over the desired task. In this study, we have used both hand-crafted and deep features extracted using different off-the-shelf CNN based pre-trained models on ImageNet [<xref rid="pone.0255674.ref017" ref-type="bibr">17</xref>]. All of these feature representations <italic toggle="yes">ϕ</italic>(⋅) have been extracted from individual earthworm images. In what follows, we describe the different types of feature representations used in this study.</p>
        <list list-type="bullet">
          <list-item>
            <p>
              <bold>Hand-Crafted Features</bold>
            </p>
          </list-item>
        </list>
        <p>We have used various handcrafted features in this study such as Histogram of Oriented Gradients (HOG) [<xref rid="pone.0255674.ref018" ref-type="bibr">18</xref>], scale-invariant feature transform (SIFT) [<xref rid="pone.0255674.ref019" ref-type="bibr">19</xref>], DAISY [<xref rid="pone.0255674.ref020" ref-type="bibr">20</xref>], Grey Level Co-Occurrence matrix (GLCM) [<xref rid="pone.0255674.ref021" ref-type="bibr">21</xref>], HAAR features [<xref rid="pone.0255674.ref022" ref-type="bibr">22</xref>], Local binary patterns (LBP) [<xref rid="pone.0255674.ref023" ref-type="bibr">23</xref>]. We have extracted these features from all the images in our dataset using Scikit-image (version: 0.17.2) and OpenCV (version: 3.4.2) [<xref rid="pone.0255674.ref016" ref-type="bibr">16</xref>, <xref rid="pone.0255674.ref024" ref-type="bibr">24</xref>].</p>
        <list list-type="bullet">
          <list-item>
            <p>
              <bold>Deep Feature Maps</bold>
            </p>
          </list-item>
        </list>
        <p>We have used different off-the-shelf CNN-based pre-trained models on ImageNet to extract useful feature maps from the raw digital images of earthworms in our datasets [<xref rid="pone.0255674.ref017" ref-type="bibr">17</xref>]. These pre-trained models include Resnet50 [<xref rid="pone.0255674.ref025" ref-type="bibr">25</xref>], InceptionV3 [<xref rid="pone.0255674.ref026" ref-type="bibr">26</xref>], Xception [<xref rid="pone.0255674.ref027" ref-type="bibr">27</xref>], VGG16 [<xref rid="pone.0255674.ref028" ref-type="bibr">28</xref>], NASNetLarge [<xref rid="pone.0255674.ref029" ref-type="bibr">29</xref>], DenseNet121 [<xref rid="pone.0255674.ref030" ref-type="bibr">30</xref>]. The selection of these pre-trained CNN-based models was based on their reported accuracy. Preprocessing such as pixel scaling and resizing expected by the pre-trained models (varies from model to model) have been applied before extracting the required feature maps. We applied resizing with resampling using pixel area relation through a library for computer vision in python called OpenCV [<xref rid="pone.0255674.ref024" ref-type="bibr">24</xref>].</p>
      </sec>
      <sec id="sec006">
        <title>2.2.2. Classifiers for the identification of earthworm species</title>
        <p>In the proposed machine learning setting, we have posed <italic toggle="yes">E. fetida</italic> identification from digital images as a classification problem. For this purpose, we represent each digital image in our dataset as an example of the form (<italic toggle="yes">I<sub>i</sub>, y<sub>i</sub></italic>) where <italic toggle="yes">I<sub>i</sub></italic> is an earthworm image and <italic toggle="yes">y<sub>i</sub></italic> ∈ {+1, −1} is its associated label that indicates whether <italic toggle="yes">I<sub>i</sub></italic> is <italic toggle="yes">E. fetida</italic> (+1) or not (-1). For a given image <italic toggle="yes">I<sub>i</sub></italic> in our dataset, we extract hand-crafted features and deep feature maps which can be denoted as a feature vector <italic toggle="yes"><bold>x</bold><sub>i</sub></italic>. Our objective is to learn a function <italic toggle="yes">f</italic>(∙) using these feature vectors to identify whether an input image belongs to <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic> or some other species. For this purpose, we have used three different classifiers: classical Support Vector Machine (SVM), Random Forest (RF), and Gradient Boosting Machine (XGBoost) [<xref rid="pone.0255674.ref031" ref-type="bibr">31</xref>–<xref rid="pone.0255674.ref033" ref-type="bibr">33</xref>].</p>
        <list list-type="bullet">
          <list-item>
            <p>
              <bold>Support Vector Classification (SVC)</bold>
            </p>
          </list-item>
        </list>
        <p>We have used Support Vector Machines (SVMs) for the detection of earthworm species through a digital image by learning a function <italic toggle="yes">f</italic>(<bold><italic toggle="yes">x</italic></bold>) = 〈<bold><italic toggle="yes">w</italic></bold>,<italic toggle="yes">x</italic>〉 with <bold><italic toggle="yes">w</italic></bold> as parameters to be learned from the training data {(<italic toggle="yes"><bold>x</bold><sub>i</sub>, y<sub>i</sub></italic>)|<italic toggle="yes">i</italic> = 1,2,…,<italic toggle="yes">N</italic>} where, <bold><italic toggle="yes">x</italic></bold><sub><italic toggle="yes">i</italic></sub> is the feature representation of an earthworm image <italic toggle="yes">I<sub>i</sub></italic>. The optimal value of the <bold><italic toggle="yes">w</italic></bold> is obtained in SVM by solving the following optimization problem [<xref rid="pone.0255674.ref032" ref-type="bibr">32</xref>].</p>
        <disp-formula id="pone.0255674.e001">
          <alternatives>
            <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0255674.e001.jpg" id="pone.0255674.e001g" position="anchor"/>
            <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M1" display="block" overflow="scroll">
              <mml:mtable columnalign="left">
                <mml:mtr>
                  <mml:mtd>
                    <mml:msub>
                      <mml:mi mathvariant="italic">min</mml:mi>
                      <mml:mrow>
                        <mml:mi>w</mml:mi>
                        <mml:mo>,</mml:mo>
                        <mml:mi>ξ</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:mfrac>
                      <mml:mn>1</mml:mn>
                      <mml:mn>2</mml:mn>
                    </mml:mfrac>
                    <mml:mi>λ</mml:mi>
                    <mml:mi>‖</mml:mi>
                    <mml:mi mathvariant="bold-italic">w</mml:mi>
                    <mml:msup>
                      <mml:mi>‖</mml:mi>
                      <mml:mn>2</mml:mn>
                    </mml:msup>
                    <mml:mo>+</mml:mo>
                    <mml:mstyle displaystyle="true">
                      <mml:munderover>
                        <mml:mo>∑</mml:mo>
                        <mml:mrow>
                          <mml:mi>i</mml:mi>
                          <mml:mo>=</mml:mo>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                        <mml:mi>N</mml:mi>
                      </mml:munderover>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mi>ξ</mml:mi>
                          <mml:mi>i</mml:mi>
                        </mml:msub>
                      </mml:mrow>
                    </mml:mstyle>
                  </mml:mtd>
                </mml:mtr>
                <mml:mtr>
                  <mml:mtd>
                    <mml:mi>S</mml:mi>
                    <mml:mi>u</mml:mi>
                    <mml:mi>c</mml:mi>
                    <mml:mi>h</mml:mi>
                    <mml:mspace width="0.25em"/>
                    <mml:mi>t</mml:mi>
                    <mml:mi>h</mml:mi>
                    <mml:mi>a</mml:mi>
                    <mml:mi>t</mml:mi>
                    <mml:mspace width="0.25em"/>
                    <mml:mi>f</mml:mi>
                    <mml:mi>o</mml:mi>
                    <mml:mi>r</mml:mi>
                    <mml:mspace width="0.25em"/>
                    <mml:mi>a</mml:mi>
                    <mml:mi>l</mml:mi>
                    <mml:mi>l</mml:mi>
                    <mml:mspace width="0.25em"/>
                    <mml:mi>i</mml:mi>
                    <mml:mo>:</mml:mo>
                    <mml:mspace width="0.25em"/>
                    <mml:msub>
                      <mml:mi>y</mml:mi>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mi>〈</mml:mi>
                    <mml:mrow>
                      <mml:mi mathvariant="bold-italic">w</mml:mi>
                      <mml:mo>,</mml:mo>
                      <mml:msub>
                        <mml:mi mathvariant="bold-italic">x</mml:mi>
                        <mml:mi>i</mml:mi>
                      </mml:msub>
                    </mml:mrow>
                    <mml:mi>〉</mml:mi>
                    <mml:mo>≥</mml:mo>
                    <mml:mn>1</mml:mn>
                    <mml:mo>−</mml:mo>
                    <mml:msub>
                      <mml:mi>ξ</mml:mi>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mo>,</mml:mo>
                    <mml:msub>
                      <mml:mi>ξ</mml:mi>
                      <mml:mi>i</mml:mi>
                    </mml:msub>
                    <mml:mo>≥</mml:mo>
                    <mml:mn>0</mml:mn>
                  </mml:mtd>
                </mml:mtr>
              </mml:mtable>
            </mml:math>
          </alternatives>
          <label>(1)</label>
        </disp-formula>
        <p>The objective function in Eq (<xref rid="pone.0255674.e001" ref-type="disp-formula">1</xref>) maximizes the margin while minimizing margin violations (or slacks ξ) [<xref rid="pone.0255674.ref032" ref-type="bibr">32</xref>]. The hyper-parameter <inline-formula id="pone.0255674.e002"><alternatives><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0255674.e002.jpg" id="pone.0255674.e002g" position="anchor"/><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M2" display="inline" overflow="scroll"><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula> controls the tradeoff between margin maximization and margin violation. We used both linear and radial basis function (RBF) kernels and coarsely optimized the values of λ and γ using grid search with Scikit-learn (version: 0.23) [<xref rid="pone.0255674.ref034" ref-type="bibr">34</xref>, <xref rid="pone.0255674.ref035" ref-type="bibr">35</xref>].</p>
        <list list-type="bullet">
          <list-item>
            <p>
              <bold>Random Forest Classification (RFC)</bold>
            </p>
          </list-item>
        </list>
        <p>Random forest is a supervised learning algorithm that builds an ensemble of decision trees, usually trained with the “bagging” method. A random forest operates by constructing several decision trees in parallel during training and outputs the mean of the classes as the prediction of all trees [<xref rid="pone.0255674.ref031" ref-type="bibr">31</xref>]. It usually performs better on problems having features with non-linear relationships. Each classification tree in the RF is constructed on randomly sampled subsets of input features. In this study, we have optimized RF for the number of decision trees in the forest, the maximum number of features considered for splitting a node, the maximum number of levels in each decision tree, and a minimum number of samples required to split. We have also seen this machine learning technique effectively in use in many other studies [<xref rid="pone.0255674.ref036" ref-type="bibr">36</xref>–<xref rid="pone.0255674.ref039" ref-type="bibr">39</xref>].</p>
        <list list-type="bullet">
          <list-item>
            <p>
              <bold>XGBoost Classification (XGBC)</bold>
            </p>
          </list-item>
        </list>
        <p>XGBoost is a boosting-based ensemble learning technique that chains several weak learners into stronger ones in an iterative way [<xref rid="pone.0255674.ref033" ref-type="bibr">33</xref>, <xref rid="pone.0255674.ref040" ref-type="bibr">40</xref>]. At the core of XGBoost, there is boosting that lessens biases by supervising the model about what errors have been made by previous models and variance by maneuvering multiple models. In the XGBoost technique, each subsequent model is mentored using the residuals (the variance between the predicted and actual values), then models are fitted via subjective differentiable loss function and gradient descent optimization method by pushing the limits of computational resources for efficient throughput. Here, we used trees as default base learners and optimized XGBoost in terms of the number of boosting iterations, the learning rate, booster, maximum depth, and subsample ratio by employing grid search technique and a python-based package called XGBoost (version: 0.7) [<xref rid="pone.0255674.ref035" ref-type="bibr">35</xref>, <xref rid="pone.0255674.ref040" ref-type="bibr">40</xref>].</p>
      </sec>
    </sec>
    <sec id="sec007">
      <title>2.3. Experimental setup</title>
      <p>To train a machine learning-based model and to evaluate its performance to predict the earthworm species from a digital image, we have followed the following experimental setup. We have divided the preprocessed earthworm images into two sub-sets: train-test set (80%), held-out validation set (20%), and reported performance metrics on both the sub-sets. For the train-test set, we have used stratified 10-fold cross-validation (CV). In the stratified 10-fold CV, we have shuffled images in our datasets and then split them into 10 groups by preserving the percentage of samples for each class. 10 models have been trained and evaluated with each group given a chance to be held out as the test set [<xref rid="pone.0255674.ref041" ref-type="bibr">41</xref>]. Average values of performance metrics across folds have been reported in this study. Similarly, to further confirm the robustness of the generalization performance of our proposed technique, we have used the held-out validation dataset to mitigate the possible bias performance improvement under 10-fold CV with hyperparameter tuning using the same training set. For the held-out validation set, we trained the classification models using the whole train-test set and tested them on the validation set. We have used the area under the ROC curve (ROC), the area under the precision-recall curve (PR), and F-measure as performance measures for model evaluation and performance assessment [<xref rid="pone.0255674.ref041" ref-type="bibr">41</xref>–<xref rid="pone.0255674.ref043" ref-type="bibr">43</xref>]. We have computed these metrics using Scikit-learn (version: 0.23) [<xref rid="pone.0255674.ref034" ref-type="bibr">34</xref>]. We used grid search over the training data to find the optimal values of hyper-parameters of different classification models using a python based open-access library for machine learning called Scikit-learn [<xref rid="pone.0255674.ref034" ref-type="bibr">34</xref>, <xref rid="pone.0255674.ref035" ref-type="bibr">35</xref>]. This automatic grid search was performed once using the train-test set and then the optimum values of hyperparameters have been used during the whole cross-validation process.</p>
    </sec>
    <sec id="sec008">
      <title>2.4. Statistical analysis</title>
      <p>We have also performed the statistical analysis by checking the statistical significance of obtained performance (F1 score) across different features and classifiers. For this purpose, we have used Wilcoxon test [<xref rid="pone.0255674.ref044" ref-type="bibr">44</xref>]. The test considers the null hypothesis as the median of the performance scores of different models are equal. Alternatively, the performance scores of different models are different. We have used the test statistics at a 95% confidence interval (or α = 0.05). We have performed this analysis using an online webserver (URL: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://tec.citius.usc.es/stac/" ext-link-type="uri">https://tec.citius.usc.es/stac/</ext-link>) [<xref rid="pone.0255674.ref045" ref-type="bibr">45</xref>].</p>
    </sec>
    <sec id="sec009">
      <title>2.5. Webserver to identify <italic toggle="yes">E. fetida</italic></title>
      <p>We have developed and deployed a user-friendly cloud-based webserver that uses the optimal machine learning model for <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic> identification. This webserver takes an earthworm digital image and predicts whether this image belongs to <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic> or not. The webserver is available at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://sites.google.com/view/wajidarshad/software" ext-link-type="uri">https://sites.google.com/view/wajidarshad/software</ext-link>.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec010">
    <title>3. Results and discussion</title>
    <p>In this study, we have proposed and developed a machine learning-based computational model to identify earthworm species. For this purpose, we have used a dataset of earthworm digital images, various machine learning algorithms, and different features. In what follows we present results showing the earthworm species identification performance of our proposed method using digital images across different evaluation schemes.</p>
    <sec id="sec011">
      <title>3.1. Earthworm species identification performance using handcrafted features</title>
      <p>We have trained various classical machine learning models for the classification of <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic> versus other earthworm species with a range of handcrafted features and evaluated them using both 10-fold cross-validation (CV) and on an external validation dataset. In both the adopted settings results are shown in Tables <xref rid="pone.0255674.t001" ref-type="table">1</xref> and <xref rid="pone.0255674.t002" ref-type="table">2</xref>. Using 10-fold CV, we observed a maximum F1-score of 0.71 (<italic toggle="yes">p</italic>&lt;0.05) along with 0.75, and 0.86 as the area under the ROC curve, and the area under the PR curve, respectively with Support Vector Classifier and HAAR feature representation (<xref rid="pone.0255674.t001" ref-type="table">Table 1</xref>). The F1 score of 0.71 implies that using a trained machine learning model with SVMs and HAAR features, we have been able to classify <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic> correctly approximately 70% of the time. To further confirm the generalization performance of our trained machine learning models with handcrafted features, we have used an external validation dataset. Using an external validation dataset, we observed a maximum F1-score of 0.75 along with 0.77, and 0.85 as the area under the ROC curve, and the area under the PR curve, respectively with Support Vector Classifier and HAAR feature representation (<xref rid="pone.0255674.t002" ref-type="table">Table 2</xref>). We have also observed consistently better performance of HAAR feature representation across RF and XGB classifiers.</p>
      <table-wrap position="float" id="pone.0255674.t001">
        <object-id pub-id-type="doi">10.1371/journal.pone.0255674.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>Predictive performance for earthworm species prediction across different classification models and handcrafted features using 10-fold CV (<italic toggle="yes">E. fetida</italic> vs others).</title>
        </caption>
        <alternatives>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0255674.t001" id="pone.0255674.t001g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" rowspan="2" colspan="1">Features</th>
                <th align="center" colspan="3" rowspan="1">SVC</th>
                <th align="center" colspan="3" rowspan="1">RFC</th>
                <th align="center" colspan="3" rowspan="1">XGBC</th>
              </tr>
              <tr>
                <th align="center" rowspan="1" colspan="1">ROC</th>
                <th align="center" rowspan="1" colspan="1">PR</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
                <th align="center" rowspan="1" colspan="1">ROC</th>
                <th align="center" rowspan="1" colspan="1">PR</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
                <th align="center" rowspan="1" colspan="1">ROC</th>
                <th align="center" rowspan="1" colspan="1">PR</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>HOG</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.69±0.14</td>
                <td align="left" rowspan="1" colspan="1">0.81±0.09</td>
                <td align="left" rowspan="1" colspan="1">0.66</td>
                <td align="left" rowspan="1" colspan="1">0.75±0.13</td>
                <td align="left" rowspan="1" colspan="1">0.83±0.08</td>
                <td align="left" rowspan="1" colspan="1">0.64</td>
                <td align="left" rowspan="1" colspan="1">0.75±0.11</td>
                <td align="left" rowspan="1" colspan="1">0.85±0.06</td>
                <td align="left" rowspan="1" colspan="1">0.66</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>SIFT</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.75±0.10</td>
                <td align="left" rowspan="1" colspan="1">0.84±0.06</td>
                <td align="left" rowspan="1" colspan="1">0.70</td>
                <td align="left" rowspan="1" colspan="1">0.74±0.13</td>
                <td align="left" rowspan="1" colspan="1">0.82±0.11</td>
                <td align="left" rowspan="1" colspan="1">0.65</td>
                <td align="left" rowspan="1" colspan="1">0.71±0.10</td>
                <td align="left" rowspan="1" colspan="1">0.84±0.09</td>
                <td align="left" rowspan="1" colspan="1">0.68</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>DAISY</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.74±0.12</td>
                <td align="left" rowspan="1" colspan="1">0.85±0.08</td>
                <td align="left" rowspan="1" colspan="1">0.71</td>
                <td align="left" rowspan="1" colspan="1">0.76±0.13</td>
                <td align="left" rowspan="1" colspan="1">0.86±0.07</td>
                <td align="left" rowspan="1" colspan="1">0.64</td>
                <td align="left" rowspan="1" colspan="1">0.75±0.14</td>
                <td align="left" rowspan="1" colspan="1">0.86±0.08</td>
                <td align="left" rowspan="1" colspan="1">0.68</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>GLCM</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.69±0.14</td>
                <td align="left" rowspan="1" colspan="1">0.81±0.09</td>
                <td align="left" rowspan="1" colspan="1">0.66</td>
                <td align="left" rowspan="1" colspan="1">0.73±0.13</td>
                <td align="left" rowspan="1" colspan="1">0.81±0.08</td>
                <td align="left" rowspan="1" colspan="1">0.63</td>
                <td align="left" rowspan="1" colspan="1">0.75±0.11</td>
                <td align="left" rowspan="1" colspan="1">0.84±0.06</td>
                <td align="left" rowspan="1" colspan="1">0.66</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>HAAR</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.75±0.15</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.86±0.09</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.71</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.76±0.13</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.86±0.07</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.65</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.75±0.14</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.86±0.08</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.68</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>LBP</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.70±0.13</td>
                <td align="left" rowspan="1" colspan="1">0.80±0.10</td>
                <td align="left" rowspan="1" colspan="1">0.66</td>
                <td align="left" rowspan="1" colspan="1">0.65±0.13</td>
                <td align="left" rowspan="1" colspan="1">0.78±0.10</td>
                <td align="left" rowspan="1" colspan="1">0.62</td>
                <td align="left" rowspan="1" colspan="1">0.68±0.12</td>
                <td align="left" rowspan="1" colspan="1">0.80±0.08</td>
                <td align="left" rowspan="1" colspan="1">0.65</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t001fn001">
            <p>ROC (Area under the ROC curve), PR (Area under the precision-recall curve), F1 (F1 Score), SVC (Support Vector classifier), RF (Random Forest classifier), XGBC (XGBoost classifier). Bold-faced values indicate the best performance for each model.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap position="float" id="pone.0255674.t002">
        <object-id pub-id-type="doi">10.1371/journal.pone.0255674.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>Predictive performance for earthworm species prediction across different classification models and handcrafted features on external validation dataset (<italic toggle="yes">E. fetida</italic> vs others).</title>
        </caption>
        <alternatives>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0255674.t002" id="pone.0255674.t002g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" rowspan="2" colspan="1">Features</th>
                <th align="center" colspan="3" rowspan="1">SVC</th>
                <th align="center" colspan="3" rowspan="1">RFC</th>
                <th align="center" colspan="3" rowspan="1">XGBC</th>
              </tr>
              <tr>
                <th align="center" rowspan="1" colspan="1">ROC</th>
                <th align="center" rowspan="1" colspan="1">PR</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
                <th align="center" rowspan="1" colspan="1">ROC</th>
                <th align="center" rowspan="1" colspan="1">PR</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
                <th align="center" rowspan="1" colspan="1">ROC</th>
                <th align="center" rowspan="1" colspan="1">PR</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>HOG</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.72</td>
                <td align="left" rowspan="1" colspan="1">0.82</td>
                <td align="left" rowspan="1" colspan="1">0.72</td>
                <td align="left" rowspan="1" colspan="1">0.77</td>
                <td align="left" rowspan="1" colspan="1">0.81</td>
                <td align="left" rowspan="1" colspan="1">0.66</td>
                <td align="left" rowspan="1" colspan="1">0.76</td>
                <td align="left" rowspan="1" colspan="1">0.84</td>
                <td align="left" rowspan="1" colspan="1">0.69</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>SIFT</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.77</td>
                <td align="left" rowspan="1" colspan="1">0.80</td>
                <td align="left" rowspan="1" colspan="1">0.74</td>
                <td align="left" rowspan="1" colspan="1">0.77</td>
                <td align="left" rowspan="1" colspan="1">0.83</td>
                <td align="left" rowspan="1" colspan="1">0.68</td>
                <td align="left" rowspan="1" colspan="1">0.73</td>
                <td align="left" rowspan="1" colspan="1">0.82</td>
                <td align="left" rowspan="1" colspan="1">0.68</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>DAISY</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.75</td>
                <td align="left" rowspan="1" colspan="1">0.83</td>
                <td align="left" rowspan="1" colspan="1">0.73</td>
                <td align="left" rowspan="1" colspan="1">0.77</td>
                <td align="left" rowspan="1" colspan="1">0.87</td>
                <td align="left" rowspan="1" colspan="1">0.68</td>
                <td align="left" rowspan="1" colspan="1">0.74</td>
                <td align="left" rowspan="1" colspan="1">0.87</td>
                <td align="left" rowspan="1" colspan="1">0.70</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>GLCM</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.71</td>
                <td align="left" rowspan="1" colspan="1">0.80</td>
                <td align="left" rowspan="1" colspan="1">0.69</td>
                <td align="left" rowspan="1" colspan="1">0.70</td>
                <td align="left" rowspan="1" colspan="1">0.80</td>
                <td align="left" rowspan="1" colspan="1">0.60</td>
                <td align="left" rowspan="1" colspan="1">0.71</td>
                <td align="left" rowspan="1" colspan="1">0.83</td>
                <td align="left" rowspan="1" colspan="1">0.68</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>HAAR</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.77</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.85</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.75</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.79</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.88</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.68</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.77</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.87</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.70</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>LBP</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.72</td>
                <td align="left" rowspan="1" colspan="1">0.79</td>
                <td align="left" rowspan="1" colspan="1">0.70</td>
                <td align="left" rowspan="1" colspan="1">0.68</td>
                <td align="left" rowspan="1" colspan="1">0.80</td>
                <td align="left" rowspan="1" colspan="1">0.61</td>
                <td align="left" rowspan="1" colspan="1">0.68</td>
                <td align="left" rowspan="1" colspan="1">0.82</td>
                <td align="left" rowspan="1" colspan="1">0.69</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t002fn001">
            <p>ROC (Area under the ROC curve), PR (Area under the precision-recall curve), F1 (F1 Score), SVC (Support Vector classifier), RF (Random Forest classifier), XGBC (XGBoost classifier). Bold-faced values indicate the best performance for each model.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="sec012">
      <title>3.2. Earthworm species identification performance using deep feature maps</title>
      <p>We have trained various shallow machine learning models for the classification of <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic> versus other earthworm species with a range of deep learning-based feature maps and evaluated using both 10-fold cross-validation (CV) and on an external validation dataset. The results of our evaluation in both settings are shown in Tables <xref rid="pone.0255674.t003" ref-type="table">3</xref> and <xref rid="pone.0255674.t004" ref-type="table">4</xref> and <xref rid="pone.0255674.g002" ref-type="fig">Fig 2</xref>. Using 10-fold CV, we observed a maximum F1-score of 0.80 (<italic toggle="yes">p</italic>&lt;0.05) along with 0.95, and 0.98 as the area under the ROC curve, and the area under the PR curve, respectively with Support Vector Classifier and Densent121 feature map (<xref rid="pone.0255674.t003" ref-type="table">Table 3</xref>). PR score of 0.98 represents high accuracy with fewer false positives (Classifying Other Species as <italic toggle="yes">E. fetida</italic>) and false negatives(Classifying <italic toggle="yes">E. fetida</italic> as Other Species). To confirm further the classification accuracy of our trained machine learning models with deep feature maps, we have used an external validation dataset. Using an external validation dataset, we observed a maximum F1-score of 0.92 along with 0.96, and 0.99 as the area under the ROC curve, and the area under the PR curve, respectively with Support Vector Classifier and Densent121 feature map (<xref rid="pone.0255674.t004" ref-type="table">Table 4</xref>; <xref rid="pone.0255674.g002" ref-type="fig">Fig 2</xref>). F1 score of 0.92 and PR score of 0.98 represent a consistently improved performance of our proposed machine learning model to predict <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic> class with high precision and recall (i.e. by producing fewer false positives and false negatives). By observing these results obtained through deep feature maps and comparing with the results obtained through handcrafted features, we can easily conclude that deep feature maps perform consistently better across all the classification algorithms. This performance improvement of deep feature maps over handcrafted features has already been reported in a previous study on X-ray scans [<xref rid="pone.0255674.ref046" ref-type="bibr">46</xref>]. These results justify the use of the proposed earthworm species classification model in a real setting.</p>
      <fig position="float" id="pone.0255674.g002">
        <object-id pub-id-type="doi">10.1371/journal.pone.0255674.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Receiver Operating Characteristic (ROC) and Precision-Recall (PR) curves showing predictive performance of our proposed model for the classification of digital images of earthworms across different classifiers (SVM, RF, XGB) and DenseNet feature map on an external validation dataset.</title>
          <p><italic toggle="yes">E. fetida</italic> vs others: ROC(A), PR(B).</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0255674.g002" position="float"/>
      </fig>
      <table-wrap position="float" id="pone.0255674.t003">
        <object-id pub-id-type="doi">10.1371/journal.pone.0255674.t003</object-id>
        <label>Table 3</label>
        <caption>
          <title>Predictive performance for earthworm species prediction across different classification models and deep feature maps using 10-fold CV (<italic toggle="yes">E. fetida</italic> vs others).</title>
        </caption>
        <alternatives>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0255674.t003" id="pone.0255674.t003g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" rowspan="2" colspan="1">Feature Map</th>
                <th align="center" colspan="3" rowspan="1">SVC</th>
                <th align="center" colspan="3" rowspan="1">RFC</th>
                <th align="center" colspan="3" rowspan="1">XGBC</th>
              </tr>
              <tr>
                <th align="center" rowspan="1" colspan="1">ROC</th>
                <th align="center" rowspan="1" colspan="1">PR</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
                <th align="center" rowspan="1" colspan="1">ROC</th>
                <th align="center" rowspan="1" colspan="1">PR</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
                <th align="center" rowspan="1" colspan="1">ROC</th>
                <th align="center" rowspan="1" colspan="1">PR</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>DenseNet121</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.95±0.04</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.98±0.02</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.80</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.89±0.07</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.95±0.03</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.77</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.92±0.07</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.96±0.03</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.80</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Resnet50</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.84±0.12</td>
                <td align="left" rowspan="1" colspan="1">0.88±0.07</td>
                <td align="left" rowspan="1" colspan="1">0.74</td>
                <td align="left" rowspan="1" colspan="1">0.78±0.15</td>
                <td align="left" rowspan="1" colspan="1">0.86±0.10</td>
                <td align="left" rowspan="1" colspan="1">0.70</td>
                <td align="left" rowspan="1" colspan="1">0.80±0.15</td>
                <td align="left" rowspan="1" colspan="1">0.88±0.08</td>
                <td align="left" rowspan="1" colspan="1">0.70</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Xception</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.90±0.07</td>
                <td align="left" rowspan="1" colspan="1">0.95±0.04</td>
                <td align="left" rowspan="1" colspan="1">0.77</td>
                <td align="left" rowspan="1" colspan="1">0.85±0.08</td>
                <td align="left" rowspan="1" colspan="1">0.93±0.05</td>
                <td align="left" rowspan="1" colspan="1">0.74</td>
                <td align="left" rowspan="1" colspan="1">0.90±0.07</td>
                <td align="left" rowspan="1" colspan="1">0.94±0.04</td>
                <td align="left" rowspan="1" colspan="1">0.75</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>InceptionV3</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.88±0.05</td>
                <td align="left" rowspan="1" colspan="1">0.90±0.07</td>
                <td align="left" rowspan="1" colspan="1">0.76</td>
                <td align="left" rowspan="1" colspan="1">0.80±0.15</td>
                <td align="left" rowspan="1" colspan="1">0.88±0.08</td>
                <td align="left" rowspan="1" colspan="1">0.72</td>
                <td align="left" rowspan="1" colspan="1">0.86±0.13</td>
                <td align="left" rowspan="1" colspan="1">0.92±0.06</td>
                <td align="left" rowspan="1" colspan="1">0.76</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>VGG16</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.93±0.05</td>
                <td align="left" rowspan="1" colspan="1">0.97±0.03</td>
                <td align="left" rowspan="1" colspan="1">0.77</td>
                <td align="left" rowspan="1" colspan="1">0.87±0.08</td>
                <td align="left" rowspan="1" colspan="1">0.93±0.05</td>
                <td align="left" rowspan="1" colspan="1">0.70</td>
                <td align="left" rowspan="1" colspan="1">0.90±0.05</td>
                <td align="left" rowspan="1" colspan="1">0.94±0.03</td>
                <td align="left" rowspan="1" colspan="1">0.78</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>NASNetLarge</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.82±0.12</td>
                <td align="left" rowspan="1" colspan="1">0.90±0.07</td>
                <td align="left" rowspan="1" colspan="1">0.70</td>
                <td align="left" rowspan="1" colspan="1">0.78±0.13</td>
                <td align="left" rowspan="1" colspan="1">0.88±0.07</td>
                <td align="left" rowspan="1" colspan="1">0.70</td>
                <td align="left" rowspan="1" colspan="1">0.83±0.12</td>
                <td align="left" rowspan="1" colspan="1">0.90±0.07</td>
                <td align="left" rowspan="1" colspan="1">0.71</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t003fn001">
            <p>ROC (Area under the ROC curve), PR (Area under the precision-recall curve), F1 (F1 Score), SVC (Support Vector classifier), RF (Random Forest classifier), XGBC (XGBoost classifier). Bold-faced values indicate the best performance for each model.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap position="float" id="pone.0255674.t004">
        <object-id pub-id-type="doi">10.1371/journal.pone.0255674.t004</object-id>
        <label>Table 4</label>
        <caption>
          <title>Predictive performance for earthworm species prediction across different classification models and deep feature maps on external validation dataset (<italic toggle="yes">E. fetida</italic> vs others).</title>
        </caption>
        <alternatives>
          <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0255674.t004" id="pone.0255674.t004g" position="float"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" rowspan="2" colspan="1">Feature Map</th>
                <th align="center" colspan="3" rowspan="1">SVC</th>
                <th align="center" colspan="3" rowspan="1">RFC</th>
                <th align="center" colspan="3" rowspan="1">XGBC</th>
              </tr>
              <tr>
                <th align="center" rowspan="1" colspan="1">ROC</th>
                <th align="center" rowspan="1" colspan="1">PR</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
                <th align="center" rowspan="1" colspan="1">ROC</th>
                <th align="center" rowspan="1" colspan="1">PR</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
                <th align="center" rowspan="1" colspan="1">ROC</th>
                <th align="center" rowspan="1" colspan="1">PR</th>
                <th align="center" rowspan="1" colspan="1">F1</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>DenseNet121</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.96</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.99</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.92</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.92</td>
                <td align="left" rowspan="1" colspan="1">0.95</td>
                <td align="left" rowspan="1" colspan="1">0.85</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.90</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.95</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.92</bold>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Resnet50</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.90</td>
                <td align="left" rowspan="1" colspan="1">0.92</td>
                <td align="left" rowspan="1" colspan="1">0.90</td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.93</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.97</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">
                  <bold>0.86</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.88</td>
                <td align="left" rowspan="1" colspan="1">0.95</td>
                <td align="left" rowspan="1" colspan="1">0.91</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Xception</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.88</td>
                <td align="left" rowspan="1" colspan="1">0.90</td>
                <td align="left" rowspan="1" colspan="1">0.88</td>
                <td align="left" rowspan="1" colspan="1">0.86</td>
                <td align="left" rowspan="1" colspan="1">0.90</td>
                <td align="left" rowspan="1" colspan="1">0.87</td>
                <td align="left" rowspan="1" colspan="1">0.87</td>
                <td align="left" rowspan="1" colspan="1">0.91</td>
                <td align="left" rowspan="1" colspan="1">0.87</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>InceptionV3</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.92</td>
                <td align="left" rowspan="1" colspan="1">0.94</td>
                <td align="left" rowspan="1" colspan="1">0.92</td>
                <td align="left" rowspan="1" colspan="1">0.84</td>
                <td align="left" rowspan="1" colspan="1">0.96</td>
                <td align="left" rowspan="1" colspan="1">0.89</td>
                <td align="left" rowspan="1" colspan="1">0.88</td>
                <td align="left" rowspan="1" colspan="1">0.97</td>
                <td align="left" rowspan="1" colspan="1">0.87</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>VGG16</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.90</td>
                <td align="left" rowspan="1" colspan="1">0.93</td>
                <td align="left" rowspan="1" colspan="1">0.92</td>
                <td align="left" rowspan="1" colspan="1">0.90</td>
                <td align="left" rowspan="1" colspan="1">0.96</td>
                <td align="left" rowspan="1" colspan="1">0.88</td>
                <td align="left" rowspan="1" colspan="1">0.90</td>
                <td align="left" rowspan="1" colspan="1">0.93</td>
                <td align="left" rowspan="1" colspan="1">0.89</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>NASNetLarge</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">0.86</td>
                <td align="left" rowspan="1" colspan="1">0.90</td>
                <td align="left" rowspan="1" colspan="1">0.87</td>
                <td align="left" rowspan="1" colspan="1">0.84</td>
                <td align="left" rowspan="1" colspan="1">0.88</td>
                <td align="left" rowspan="1" colspan="1">0.84</td>
                <td align="left" rowspan="1" colspan="1">0.88</td>
                <td align="left" rowspan="1" colspan="1">0.97</td>
                <td align="left" rowspan="1" colspan="1">0.87</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="t004fn001">
            <p>ROC (Area under the ROC curve), PR (Area under the precision-recall curve), F1 (F1 Score), SVC (Support Vector classifier), RF (Random Forest classifier), XGBC (XGBoost classifier). Bold-faced values indicate the best performance for each model.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec id="sec013">
      <title>3.3. Predictive performance of the proposed model under a real setting</title>
      <p>We have also checked the generalization performance of our best-trained model for earthworm species identification in a real setting under the supervision of an experienced taxonomist at the Vermi Tech Unit, University of Azad Jammu and Kashmir. For this purpose, we have used 30 digital images of different classes (15 <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic>, and 15 other species). A subset of these images is shown in <xref rid="pone.0255674.g003" ref-type="fig">Fig 3</xref>. Results obtained through this evaluation are shown as a confusion matrix in <xref rid="pone.0255674.g004" ref-type="fig">Fig 4</xref>. Our proposed system (ESIDE) has been able to classify correctly 15 out of 15 provided images of <italic toggle="yes">E. fetida</italic> (<xref rid="pone.0255674.g004" ref-type="fig">Fig 4</xref>). Similarly, for the provided images of other species, our system classified correctly 11 out of 15 images, and 4 as <italic toggle="yes">E</italic>, <italic toggle="yes">fetida</italic> (<xref rid="pone.0255674.g004" ref-type="fig">Fig 4</xref>). These results show a reasonable performance of our proposed system and justify the use of this model in real settings.</p>
      <fig position="float" id="pone.0255674.g003">
        <object-id pub-id-type="doi">10.1371/journal.pone.0255674.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>Some of the images of earthworm species (<italic toggle="yes">E. fetida</italic> and other) used to test ESIDE in a real use under the supervision of a qualified taxonomist.</title>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0255674.g003" position="float"/>
      </fig>
      <fig position="float" id="pone.0255674.g004">
        <object-id pub-id-type="doi">10.1371/journal.pone.0255674.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>Confusion matrices: Showing the performance of our proposed model for earthworm species identification in a real setting under the supervision of a qualified taxonomist.</title>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0255674.g004" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec id="sec014">
    <title>4. Conclusions and future work</title>
    <p>In this study, we have proposed a machine learning-based model called ESIDE to classify earthworm species by using digital images. We have used both deep feature maps and handcrafted features in this study. Through a series of simulation experiments using both types of features and three different classification algorithms, we have shown that deep feature maps perform consistently better in comparison to handcrafted features while identifying earthworm species through digital images. The stringent performance evaluation through 10-fold CV, on an external validation dataset, and in a use under real settings show that our proposed system can effectively be used to identify <italic toggle="yes">E</italic>. <italic toggle="yes">fetida</italic> from a digital image. The use of our proposed model can aid biologists in taxonomical studies of earthworms. We have made our proposed system accessible through a publically open cloud-based webserver and open-source code. In the future, we will try to develop a generic model for the identification of maximum species of earthworm by incorporating more data.</p>
  </sec>
  <sec id="sec015" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pone.0255674.s001" position="float" content-type="local-data">
      <label>S1 Video</label>
      <caption>
        <title>A short video showing the scientific significance, workflow and design of the current study.</title>
        <p>(M4V)</p>
      </caption>
      <media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0255674.s001.m4v">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>We thank the reviewers and the editor for their valuable feedback and suggestions to improve the presentation of this work.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pone.0255674.ref001">
      <label>1</label>
      <mixed-citation publication-type="book"><name><surname>Edwards</surname><given-names>CA</given-names></name>, <name><surname>Hendrix</surname><given-names>PF</given-names></name>, <name><surname>Arancon</surname><given-names>NQ</given-names></name>, <name><surname>Dumanig</surname><given-names>F</given-names></name>. <source>Biology and Ecology of Earthworms</source>. <edition designator="4">4th ed.</edition><publisher-name>Springer</publisher-name><publisher-loc>US</publisher-loc>; <year>2021</year>. Available: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.springer.com/gp/book/9780387749426" ext-link-type="uri">https://www.springer.com/gp/book/9780387749426</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Bonkowski</surname><given-names>M</given-names></name>, <name><surname>Griffiths</surname><given-names>BS</given-names></name>, <name><surname>Ritz</surname><given-names>K</given-names></name>. <article-title>Food preferences of earthworms for soil fungi</article-title>. <source>Pedobiologia</source>. <year>2000</year>;<volume>44</volume>: <fpage>666</fpage>–<lpage>676</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1078/S0031-4056(04)70080-3</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Domínguez</surname><given-names>J</given-names></name>, <name><surname>Gómez-Brandón</surname><given-names>M</given-names></name>. <article-title>Vermicomposting: Composting with Earthworms to Recycle Organic Wastes.</article-title><source>Manag Org Waste.</source><year>2012</year> [cited 20 Dec 2020]. <comment>doi: </comment><pub-id pub-id-type="doi">10.5772/33874</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref004">
      <label>4</label>
      <mixed-citation publication-type="other">Earthworms and Vermicomposting. [cited 20 Dec 2020]. <comment>doi: </comment><pub-id pub-id-type="doi">10.5772/intechopen.76088</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Velando</surname><given-names>A</given-names></name>, <name><surname>Ferreiro</surname><given-names>A</given-names></name>. <article-title>Are Eisenia fetida (Savigny, 1826) and Eisenia andrei Bouche (1972) (Oligochaeta, Lumbricidae) different biological species?</article-title><source>Pedobiologia</source>. <year>2005</year>;<volume>49</volume>: <fpage>81</fpage>–<lpage>87</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.pedobi.2004.08.005</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Pop</surname><given-names>AA</given-names></name>, <name><surname>Wink</surname><given-names>M</given-names></name>, <name><surname>Pop</surname><given-names>VV</given-names></name>. <article-title>Use of 18S, 16S rDNA and cytochrome c oxidase sequences in earthworm taxonomy (Oligochaeta, Lumbricidae): The 7th international symposium on earthworm ecology · Cardiff · Wales · 2002.</article-title><source>Pedobiologia</source>. <year>2003</year>;<volume>47</volume>: <fpage>428</fpage>–<lpage>433</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1078/0031-4056-00208</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Pérez-Losada</surname><given-names>M</given-names></name>, <name><surname>Ricoy</surname><given-names>M</given-names></name>, <name><surname>Marshall</surname><given-names>JC</given-names></name>, <name><surname>Domínguez</surname><given-names>J</given-names></name>. <article-title>Phylogenetic assessment of the earthworm Aporrectodea caliginosa species complex (Oligochaeta: Lumbricidae) based on mitochondrial and nuclear DNA sequences.</article-title><source>Mol Phylogenet Evol</source>. <year>2009</year>;<volume>52</volume>: <fpage>293</fpage>–<lpage>302</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ympev.2009.04.003</pub-id><?supplied-pmid 19364539?><pub-id pub-id-type="pmid">19364539</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Boyer</surname><given-names>S</given-names></name>, <name><surname>Wratten</surname><given-names>SD</given-names></name>. <article-title>Using molecular tools to identify New Zealand endemic earthworms in a mine restoration project.</article-title><source>Zool Middle East</source>. <year>2010</year>;<volume>51</volume>: <fpage>31</fpage>–<lpage>40</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1080/09397140.2010.10638455</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Pop</surname><given-names>AA</given-names></name>, <name><surname>Cech</surname><given-names>G</given-names></name>, <name><surname>Wink</surname><given-names>M</given-names></name>, <name><surname>Csuzdi</surname><given-names>C</given-names></name>, <name><surname>Pop</surname><given-names>VV</given-names></name>. <article-title>Application of 16S, 18S rDNA and COI sequences in the molecular systematics of the earthworm family Lumbricidae (Annelida, Oligochaeta).</article-title><source>Eur J Soil Biol</source>. <year>2007</year>;<volume>43</volume>: <fpage>S43</fpage>–<lpage>S52</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ejsobi.2007.08.007</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Wäldchen</surname><given-names>J</given-names></name>, <name><surname>Mäder</surname><given-names>P</given-names></name>. <article-title>Machine learning for image based species identification.</article-title><source>Methods Ecol Evol</source>. <year>2018</year>;<volume>9</volume>: <fpage>2216</fpage>–<lpage>2225</lpage>. <pub-id pub-id-type="doi">10.1111/2041-210X.13075</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Tabak</surname><given-names>MA</given-names></name>, <name><surname>Norouzzadeh</surname><given-names>MS</given-names></name>, <name><surname>Wolfson</surname><given-names>DW</given-names></name>, <name><surname>Sweeney</surname><given-names>SJ</given-names></name>, <name><surname>Vercauteren</surname><given-names>KC</given-names></name>, <name><surname>Snow</surname><given-names>NP</given-names></name>, <etal>et al</etal>. <article-title>Machine learning to classify animal species in camera trap images: Applications in ecology</article-title>. <source>Methods Ecol Evol</source>. <year>2019</year>;<volume>10</volume>: <fpage>585</fpage>–<lpage>590</lpage>. <pub-id pub-id-type="doi">10.1111/2041-210X.13120</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Matausic-Pisl</surname><given-names>M</given-names></name>, <name><surname>Tomicic</surname><given-names>M</given-names></name>, <name><surname>Micek</surname><given-names>V</given-names></name>, <name><surname>Grdisa</surname><given-names>M</given-names></name>. <article-title>Influences of earthworm extract G-90 on haematological and haemostatic parameters in Wistar rats.</article-title><source>Eur Rev Med Pharmacol Sci</source>. <year>2011</year>;<volume>15</volume>: <fpage>71</fpage>–<lpage>78</lpage>. <?supplied-pmid 21381501?><pub-id pub-id-type="pmid">21381501</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Andleeb</surname><given-names>S</given-names></name>, <name><surname>Ejaz</surname><given-names>M</given-names></name>, <name><surname>Awan</surname><given-names>UA</given-names></name>, <name><surname>Ali</surname><given-names>S</given-names></name>, <name><surname>Kiyani</surname><given-names>A</given-names></name>, <name><surname>Shafique</surname><given-names>I</given-names></name>, <etal>et al</etal>. <article-title>In vitro screening of mucus and solvent extracts of Eisenia foetida against human bacterial and fungal pathogens</article-title>. <source>Pak J Pharm Sci</source>. <year>2016</year>;<volume>29</volume>: <fpage>969</fpage>–<lpage>977</lpage>. <?supplied-pmid 27166541?><pub-id pub-id-type="pmid">27166541</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Bellitürk</surname><given-names>K</given-names></name>, <name><surname>Arshad</surname><given-names>A</given-names></name>. <source>Vermicomposting Technology For Solid Waste Management in Sustainable Agricultural Production</source>. <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="pone.0255674.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Hummel</surname><given-names>R.</given-names></name><article-title>Image enhancement by histogram transformation.</article-title><source>Comput Graph Image Process</source>. <year>1977</year>;<volume>6</volume>: <fpage>184</fpage>–<lpage>195</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/S0146-664X(77)80011-7</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Walt</surname><given-names>S van der</given-names></name>, <name><surname>Schönberger</surname><given-names>JL</given-names></name>, <name><surname>Nunez-Iglesias</surname><given-names>J</given-names></name>, <name><surname>Boulogne</surname><given-names>F</given-names></name>, <name><surname>Warner</surname><given-names>JD</given-names></name>, <name><surname>Yager</surname><given-names>N</given-names></name>, <etal>et al</etal>. <article-title>scikit-image: image processing in Python.</article-title><source>PeerJ</source>. <year>2014</year>;<volume>2</volume>: <fpage>e453</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.7717/peerj.453</pub-id><?supplied-pmid 25024921?><pub-id pub-id-type="pmid">25024921</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Deng</surname><given-names>J</given-names></name>, <name><surname>Dong</surname><given-names>W</given-names></name>, <name><surname>Socher</surname><given-names>R</given-names></name>, <name><surname>Li</surname><given-names>L-J</given-names></name>, <name><surname>Li</surname><given-names>K</given-names></name>, <name><surname>Fei-Fei</surname><given-names>L</given-names></name>. <article-title>ImageNet: A large-scale hierarchical image database.</article-title><source>2009 IEEE Conference on Computer Vision and Pattern Recognition.</source><year>2009</year>. pp. <fpage>248</fpage>–<lpage>255</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/CVPR.2009.5206848</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Dalal</surname><given-names>N</given-names></name>, <name><surname>Triggs</surname><given-names>B</given-names></name>. <article-title>Histograms of oriented gradients for human detection.</article-title><source>2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05).</source><year>2005</year>. pp. <fpage>886</fpage>–<lpage>893</lpage> vol. <volume>1</volume>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/CVPR.2005.177</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref019">
      <label>19</label>
      <mixed-citation publication-type="book"><name><surname>Križaj</surname><given-names>J</given-names></name>, <name><surname>Štruc</surname><given-names>V</given-names></name>, <name><surname>Pavešić</surname><given-names>N</given-names></name>. <source>Adaptation of SIFT Features for Robust Face Recognition</source>. In: <name><surname>Campilho</surname><given-names>A</given-names></name>, <name><surname>Kamel</surname><given-names>M</given-names></name>, editors. <part-title>Image Analysis and Recognition.</part-title><publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2010</year>. pp. <fpage>394</fpage>–<lpage>404</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/978-3-642-13772-3</pub-id>_40</mixed-citation>
    </ref>
    <ref id="pone.0255674.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Tola</surname><given-names>E</given-names></name>, <name><surname>Lepetit</surname><given-names>V</given-names></name>, <name><surname>Fua</surname><given-names>P</given-names></name>. <article-title>DAISY: An Efficient Dense Descriptor Applied to Wide-Baseline Stereo</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source>. <year>2010</year>;<volume>32</volume>: <fpage>815</fpage>–<lpage>830</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/TPAMI.2009.77</pub-id><?supplied-pmid 20299707?><pub-id pub-id-type="pmid">20299707</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Singh</surname><given-names>S</given-names></name>, <name><surname>Srivastava</surname><given-names>D</given-names></name>, <name><surname>Agarwal</surname><given-names>S</given-names></name>. <article-title>GLCM and its application in pattern recognition.</article-title><source>2017 5th International Symposium on Computational and Business Intelligence (ISCBI).</source><year>2017</year>. pp. <fpage>20</fpage>–<lpage>25</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/ISCBI.2017.8053537</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Viola</surname><given-names>P</given-names></name>, <name><surname>Jones</surname><given-names>M</given-names></name>. <article-title>Rapid object detection using a boosted cascade of simple features.</article-title><source>Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition CVPR 2001.</source><year>2001</year>. p. <fpage>I</fpage>–I. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/CVPR.2001.990517</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Ojala</surname><given-names>T</given-names></name>, <name><surname>Pietikäinen</surname><given-names>M</given-names></name>, <name><surname>Harwood</surname><given-names>D</given-names></name>. <article-title>A comparative study of texture measures with classification based on featured distributions.</article-title><source>Pattern Recognit</source>. <year>1996</year>;<volume>29</volume>: <fpage>51</fpage>–<lpage>59</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/0031-3203(95)00067-4</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref024">
      <label>24</label>
      <mixed-citation publication-type="other">Bradski G, Kaehler A. Learning openCV: computer vision with the openCV library. In: CERN Document Server [Internet]. O’Reilly; 2008 [cited 18 Dec 2020]. Available: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://cds.cern.ch/record/1158218" ext-link-type="uri">https://cds.cern.ch/record/1158218</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref025">
      <label>25</label>
      <mixed-citation publication-type="other">He K, Zhang X, Ren S, Sun J. Deep Residual Learning for Image Recognition. ArXiv151203385 Cs. 2015 [cited 29 Nov 2020]. Available: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://arxiv.org/abs/1512.03385" ext-link-type="uri">http://arxiv.org/abs/1512.03385</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref026">
      <label>26</label>
      <mixed-citation publication-type="other">Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z. Rethinking the Inception Architecture for Computer Vision. ArXiv151200567 Cs. 2015 [cited 29 Nov 2020]. Available: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://arxiv.org/abs/1512.00567" ext-link-type="uri">http://arxiv.org/abs/1512.00567</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref027">
      <label>27</label>
      <mixed-citation publication-type="other">Chollet F. Xception: Deep Learning with Depthwise Separable Convolutions. ArXiv161002357 Cs. 2017 [cited 29 Nov 2020]. Available: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://arxiv.org/abs/1610.02357" ext-link-type="uri">http://arxiv.org/abs/1610.02357</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref028">
      <label>28</label>
      <mixed-citation publication-type="other">Simonyan K, Zisserman A. Very Deep Convolutional Networks for Large-Scale Image Recognition. ArXiv14091556 Cs. 2015 [cited 29 Nov 2020]. Available: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://arxiv.org/abs/1409.1556" ext-link-type="uri">http://arxiv.org/abs/1409.1556</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Zoph</surname><given-names>B</given-names></name>, <name><surname>Vasudevan</surname><given-names>V</given-names></name>, <name><surname>Shlens</surname><given-names>J</given-names></name>, <name><surname>Le</surname><given-names>QV</given-names></name>. <article-title>Learning Transferable Architectures for Scalable Image Recognition.</article-title><source>ArXiv170707012 Cs Stat.</source><year>2018</year> [cited 29 Nov 2020]. Available: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://arxiv.org/abs/1707.07012" ext-link-type="uri">http://arxiv.org/abs/1707.07012</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>G</given-names></name>, <name><surname>Liu</surname><given-names>Z</given-names></name>, <name><surname>van der Maaten</surname><given-names>L</given-names></name>, <name><surname>Weinberger</surname><given-names>KQ</given-names></name>. <article-title>Densely Connected Convolutional Networks.</article-title><source>ArXiv160806993 Cs.</source><year>2018</year> [cited 29 Nov 2020]. Available: <comment>doi: </comment><pub-id pub-id-type="doi">10.3969/j.issn.1673-4254.2018.06.04</pub-id>
<?supplied-pmid 29997087?><pub-id pub-id-type="pmid">29997087</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Breiman</surname><given-names>L.</given-names></name><article-title>Random Forests.</article-title><source>Mach Learn</source>. <year>2001</year>;<volume>45</volume>: <fpage>5</fpage>–<lpage>32</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Cortes</surname><given-names>C</given-names></name>, <name><surname>Vapnik</surname><given-names>V</given-names></name>. <article-title>Support-Vector Networks.</article-title><source>Mach Learn</source>. <year>1995</year>;<volume>20</volume>: <fpage>273</fpage>–<lpage>297</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1023/A:1022627411411</pub-id><?supplied-pmid 11099962?><pub-id pub-id-type="pmid">11099962</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Friedman</surname><given-names>JH</given-names></name>. <article-title>Greedy function approximation: A gradient boosting machine.</article-title><source>Ann Stat</source>. <year>2001</year>;<volume>29</volume>: <fpage>1189</fpage>–<lpage>1232</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1214/aos/1013203451</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Gramfort</surname><given-names>A</given-names></name>, <name><surname>Michel</surname><given-names>V</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <name><surname>Grisel</surname><given-names>O</given-names></name>, <etal>et al</etal>. <article-title>Scikit-learn: Machine Learning in Python.</article-title><source>J Mach Learn Res.</source><year>2011</year>;<volume>12</volume>: <fpage>2825</fpage>−2830.</mixed-citation>
    </ref>
    <ref id="pone.0255674.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Bergstra</surname><given-names>J</given-names></name>, <name><surname>Bengio</surname><given-names>Y</given-names></name>. <article-title>Random Search for Hyper-Parameter Optimization.</article-title><source>J Mach Learn Res.</source><year>2012</year>;<volume>13</volume>: <fpage>281</fpage>–<lpage>305</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0255674.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Abbasi</surname><given-names>WA</given-names></name>, <name><surname>Hassan</surname><given-names>FU</given-names></name>, <name><surname>Yaseen</surname><given-names>A</given-names></name>, <name><surname>Minhas</surname><given-names>FUAA</given-names></name>. <source>ISLAND: In-Silico Prediction of Proteins Binding Affinity Using Sequence Descriptors</source>. <year>2017</year> [cited 8 Jan 2018]. Available: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://128.84.21.199/abs/1711.10540" ext-link-type="uri">https://128.84.21.199/abs/1711.10540</ext-link></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>H</given-names></name>, <name><surname>Leung</surname><given-names>K-S</given-names></name>, <name><surname>Wong</surname><given-names>M-H</given-names></name>, <name><surname>Ballester</surname><given-names>PJ</given-names></name>. <article-title>Substituting random forest for multiple linear regression improves binding affinity prediction of scoring functions: Cyscore as a case study</article-title>. <source>BMC Bioinformatics</source>. <year>2014</year>;<volume>15</volume>: <fpage>291</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/1471-2105-15-291</pub-id><?supplied-pmid 25159129?><pub-id pub-id-type="pmid">25159129</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref038">
      <label>38</label>
      <mixed-citation publication-type="journal"><name><surname>Ballester</surname><given-names>PJ</given-names></name>, <name><surname>Mitchell</surname><given-names>JBO</given-names></name>. <article-title>A machine learning approach to predicting protein-ligand binding affinity with applications to molecular docking.</article-title><source>Bioinforma Oxf Engl</source>. <year>2010</year>;<volume>26</volume>: <fpage>1169</fpage>–<lpage>1175</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btq112</pub-id><?supplied-pmid 20236947?><pub-id pub-id-type="pmid">20236947</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Moal</surname><given-names>IH</given-names></name>, <name><surname>Agius</surname><given-names>R</given-names></name>, <name><surname>Bates</surname><given-names>PA</given-names></name>. <article-title>Protein-protein binding affinity prediction on a diverse set of structures</article-title>. <source>Bioinformatics</source>. <year>2011</year>; <fpage>btr513</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btr513</pub-id><?supplied-pmid 21903632?><pub-id pub-id-type="pmid">21903632</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref040">
      <label>40</label>
      <mixed-citation publication-type="other">Chen T, Guestrin C. XGBoost: A Scalable Tree Boosting System. Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. New York, NY, USA: ACM; 2016. pp. 785–794. <comment>doi: </comment><pub-id pub-id-type="doi">10.1145/2939672.2939785</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Abbasi</surname><given-names>WA</given-names></name>, <name><surname>Minhas</surname><given-names>FUAA</given-names></name>. <article-title>Issues in performance evaluation for host–pathogen protein interaction prediction.</article-title><source>J Bioinform Comput Biol</source>. <year>2016</year>;<volume>14</volume>: <fpage>1650011</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1142/S0219720016500116</pub-id><?supplied-pmid 26932275?><pub-id pub-id-type="pmid">26932275</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref042">
      <label>42</label>
      <mixed-citation publication-type="other">Davis J, Goadrich M. The Relationship Between Precision-Recall and ROC Curves. Proceedings of the 23rd International Conference on Machine Learning. New York, NY, USA: ACM; 2006. pp. 233–240. <comment>doi: </comment><pub-id pub-id-type="doi">10.1145/1143844.1143874</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Tharwat</surname><given-names>A.</given-names></name><article-title>Classification assessment methods.</article-title><source>Appl Comput Inform</source>. <year>2020</year>; ahead-of-print. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.aci.2018.08.003</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref044">
      <label>44</label>
      <mixed-citation publication-type="journal"><name><surname>Chandra</surname><given-names>TB</given-names></name>, <name><surname>Verma</surname><given-names>K</given-names></name>, <name><surname>Singh</surname><given-names>BK</given-names></name>, <name><surname>Jain</surname><given-names>D</given-names></name>, <name><surname>Netam</surname><given-names>SS</given-names></name>. <article-title>Coronavirus disease (COVID-19) detection in Chest X-Ray images using majority voting based classifier ensemble.</article-title><source>Expert Syst Appl</source>. <year>2021</year>;<volume>165</volume>: <fpage>113909</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.eswa.2020.113909</pub-id><?supplied-pmid 32868966?><pub-id pub-id-type="pmid">32868966</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref045">
      <label>45</label>
      <mixed-citation publication-type="journal"><name><surname>Rodriguez-Fdez</surname><given-names>I</given-names></name>, <name><surname>Canosa</surname><given-names>A</given-names></name>, <name><surname>Mucientes</surname><given-names>M</given-names></name>, <name><surname>Bugarin</surname><given-names>A</given-names></name>. <source>STAC: A web platform for the comparison of algorithms using statistical tests</source>. <year>2015</year> [cited 22 Jan 2021]. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/FUZZ-IEEE.2015.7337889</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0255674.ref046">
      <label>46</label>
      <mixed-citation publication-type="journal"><name><surname>Chandra</surname><given-names>TB</given-names></name>, <name><surname>Verma</surname><given-names>K</given-names></name>, <name><surname>Singh</surname><given-names>BK</given-names></name>, <name><surname>Jain</surname><given-names>D</given-names></name>, <name><surname>Netam</surname><given-names>SS</given-names></name>. <article-title>Coronavirus disease (COVID-19) detection in Chest X-Ray images using majority voting based classifier ensemble.</article-title><source>Expert Syst Appl</source>. <year>2021</year>;<volume>165</volume>: <fpage>113909</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.eswa.2020.113909</pub-id><?supplied-pmid 32868966?><pub-id pub-id-type="pmid">32868966</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article article-type="author-comment" id="pone.0255674.r001" specific-use="rebutted-decision-letter-unavailable">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0255674.r001</article-id>
    <title-group>
      <article-title>Author response to previous submission</article-title>
    </title-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>0</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">29 Apr 2021</named-content>
    </p>
    <supplementary-material id="pone.0255674.s002" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">Revision Summary.docx</named-content></p>
      </caption>
      <media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0255674.s002.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="aggregated-review-documents" id="pone.0255674.r002" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0255674.r002</article-id>
    <title-group>
      <article-title>Decision Letter 0</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Bhadauria</surname>
          <given-names>Tunira</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2021 Tunira Bhadauria</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Tunira Bhadauria</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0255674" id="rel-obj002" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>0</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">30 Jun 2021</named-content>
    </p>
    <p>PONE-D-21-14202</p>
    <p>ESIDE: A computationally intelligent method to identify earthworm species (E. fetida) from digital images: Application in taxonomy</p>
    <p>PLOS ONE</p>
    <p>Dear Dr. Abbasi,</p>
    <p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p>
    <p>Comments</p>
    <p>1.I would like to congratulate the authors for there innovative research related to earthworm taxonomy using digital images. </p>
    <p>2.This paper presents an initial work to classify earthworm species from digital images which is the first study of its kind reported from any where, therefore the paper has the merit for publication in the journal. </p>
    <p>3.the manuscript would become more worthy of publication if the authors would incorporate some information related to details about the tools which have been used.</p>
    <p>4.The authors also need to incorporate the comments put forward by the second reviewer.</p>
    <p>Please submit your revised manuscript by 20 July 2021. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at <email>plosone@plos.org</email>. When you're ready to submit your revision, log on to <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.editorialmanager.com/pone/" ext-link-type="uri">https://www.editorialmanager.com/pone/</ext-link> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p>
    <p>Please include the following items when submitting your revised manuscript:</p>
    <p>
      <list list-type="bullet">
        <list-item>
          <p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p>
        </list-item>
        <list-item>
          <p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p>
        </list-item>
        <list-item>
          <p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p>
        </list-item>
      </list>
    </p>
    <p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p>
    <p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" ext-link-type="uri">http://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</ext-link>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link>.</p>
    <p>We look forward to receiving your revised manuscript.</p>
    <p>Kind regards,</p>
    <p>Tunira Bhadauria, Ph.D.</p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
    <p>Journal requirements:</p>
    <p>When submitting your revision, we need you to address these additional requirements.</p>
    <p>1. Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at</p>
    <p><ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</ext-link> and</p>
    <p>
      <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" ext-link-type="uri">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</ext-link>
    </p>
    <p>2. We suggest you thoroughly copyedit your manuscript for language usage, spelling, and grammar. If you do not know anyone who can help you do this, you may wish to consider employing a professional scientific editing service. </p>
    <p>Whilst you may use any professional scientific editing service of your choice, PLOS has partnered with both American Journal Experts (AJE) and Editage to provide discounted services to PLOS authors. Both organizations have experience helping authors meet PLOS guidelines and can provide language editing, translation, manuscript formatting, and figure formatting to ensure your manuscript meets our submission guidelines. To take advantage of our partnership with AJE, visit the AJE website (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://learn.aje.com/plos/" ext-link-type="uri">http://learn.aje.com/plos/</ext-link>) for a 15% discount off AJE services. To take advantage of our partnership with Editage, visit the Editage website (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.editage.com" ext-link-type="uri">www.editage.com</ext-link>) and enter referral code PLOSEDIT for a 15% discount off Editage services.  If the PLOS editorial team finds any language issues in text that either AJE or Editage has edited, the service provider will re-edit the text for free.</p>
    <p>Upon resubmission, please provide the following:</p>
    <p>● The name of the colleague or the details of the professional service that edited your manuscript</p>
    <p>● A copy of your manuscript showing your changes by either highlighting them or using track changes (uploaded as a *supporting information* file)</p>
    <p>● A clean copy of the edited manuscript (uploaded as the new *manuscript* file)</p>
    <p>3. Thank you for stating the following in the Acknowledgments Section of your manuscript:</p>
    <p>“Dr. Saiqa Andleeb acknowledges the support of the Higher Education Commission (HEC) of Pakistan for granting research projects under the National Research Program for Universities (NRPU) and Technology Development Fund (TDF)(Grant ids: NRPU-2907 &amp; TDF-02006).”</p>
    <p>We note that you have provided funding information that is not currently declared in your Funding Statement. However, funding information should not appear in the Acknowledgments section or other areas of your manuscript. We will only publish funding information present in the Funding Statement section of the online submission form.</p>
    <p>Please remove any funding-related text from the manuscript and let us know how you would like to update your Funding Statement. Currently, your Funding Statement reads as follows:</p>
    <p> “Saiqa Andleeb acknowledges the support of the Higher  the support of the Higher Education Commission (HEC) of Pakistan for granting research projects under the National Research Program for Universities (NRPU) and Technology Development Fund (TDF)(Grant ids: NRPU-2907 &amp; TDF-02006).</p>
    <p>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.”</p>
    <p>Please include your amended statements within your cover letter; we will change the online submission form on your behalf.</p>
    <p>4. We note that you have stated that you will provide repository information for your data at acceptance. Should your manuscript be accepted for publication, we will hold it until you provide the relevant accession numbers or DOIs necessary to access your data. If you wish to make changes to your Data Availability statement, please describe these changes in your cover letter and we will update your Data Availability statement to reflect the information you provide.</p>
    <p>Please review your reference list to ensure that it is complete and correct. If you have cited papers that have been retracted, please include the rationale for doing so in the manuscript text, or remove these references and replace them with relevant current references. Any changes to the reference list should be mentioned in the rebuttal letter that accompanies your revised manuscript. If you need to cite a retracted article, indicate the article’s retracted status in the References list and also include a citation and full reference for the retraction notice.</p>
    <p>Additional Editor Comments (if provided):</p>
    <p>I would like to congratulate the authors for there innovative research related to earthworm taxonomy using digital images. This paper presents an initial work to classify earthworm species from digital images which is the first study of its kind reported from any where, therefore the paper has the merit for publication in the journal ,however the manuscript would become more worthy of publication if the authors would incorporate some information related to details about the tools which have been used. The authors also need to incorporate the comments put forward by the second reviewer.</p>
    <p>[Note: HTML markup is below. Please do not edit.]</p>
    <p>Reviewers' comments:</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <bold>Comments to the Author</bold>
    </p>
    <p>1. Is the manuscript technically sound, and do the data support the conclusions?</p>
    <p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p>2. Has the statistical analysis been performed appropriately and rigorously? </p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p>3. Have the authors made all data underlying the findings in their manuscript fully available?</p>
    <p>The <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.plosone.org/static/policies.action#sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.</p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p>4. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
    <p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p>5. Review Comments to the Author</p>
    <p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p>
    <p>Reviewer #1: This paper presents an initial work to classify earthworm species from digital images.</p>
    <p>The work is simple: a comparison between the combination of a bunch of feature extractors and classifiers.</p>
    <p>However, this seems to be the first work to be done in this specific application.</p>
    <p>The authors have clarified all my points/questions from the previous version/submission.</p>
    <p>Reviewer #2: The title of the manusript is really good and the information in this paper is new and relevant. But, just give the little basic information about the tools which have been used. And in the result and discussion section the 3rd line "In what follows.......is not clear rephrase the sentence.</p>
    <p>**********</p>
    <p>6. PLOS authors have the option to publish the peer review history of their article (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.</p>
    <p>Reviewer #1: No</p>
    <p>Reviewer #2: No</p>
    <p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com/</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at <email>figures@plos.org</email>. Please note that Supporting Information files do not need this step.</p>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pone.0255674.r003">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0255674.r003</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 0</article-title>
    </title-group>
    <related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0255674" id="rel-obj003" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">3 Jul 2021</named-content>
    </p>
    <p>Academic editor: </p>
    <p>I would like to congratulate the authors for there innovative research related to earthworm taxonomy using digital images. This paper presents an initial work to classify earthworm species from digital images which is the first study of its kind reported from any where, therefore the paper has the merit for publication in the journal ,however the manuscript would become more worthy of publication if the authors would incorporate some information related to details about the tools which have been used. The authors also need to incorporate the comments put forward by the second reviewer.</p>
    <p>Response: </p>
    <p>Thank you for these encouraging comments. We have tried to incorporate all the information in the revised manuscript related to the tools used in this study.</p>
    <p>Reviewer#2: </p>
    <p>The title of the manusript is really good and the information in this paper is new and relevant. But, just give the little basic information about the tools which have been used. And in the result and discussion section the 3rd line "In what follows.......is not clear rephrase the sentence.</p>
    <p>Response: </p>
    <p>Thank you for this feeadback. We have tried to incorporate all the information in the revised manuscript related to the tools used in this study. Also, the sentence in the result and discussion section has been rephrased to make it more clear.</p>
    <supplementary-material id="pone.0255674.s003" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">Revision Summary.docx</named-content></p>
      </caption>
      <media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="pone.0255674.s003.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pone.0255674.r004" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0255674.r004</article-id>
    <title-group>
      <article-title>Decision Letter 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Bhadauria</surname>
          <given-names>Tunira</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2021 Tunira Bhadauria</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Tunira Bhadauria</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0255674" id="rel-obj004" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">22 Jul 2021</named-content>
    </p>
    <p>ESIDE: A computationally intelligent method to identify earthworm species (<italic toggle="yes">E. fetida</italic>) from digital images: Application in taxonomy</p>
    <p>PONE-D-21-14202R1</p>
    <p>Dear Dr. Abbasi</p>
    <p>We’re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p>
    <p>Within one week, you’ll receive an e-mail detailing the required amendments. When these have been addressed, you’ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p>
    <p>An invoice for payment will follow shortly after the formal acceptance. To ensure an efficient process, please log into Editorial Manager at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://www.editorialmanager.com/pone/" ext-link-type="uri">http://www.editorialmanager.com/pone/</ext-link>, click the 'Update My Information' link at the top of the page, and double check that your user information is up-to-date. If you have any billing related questions, please contact our Author Billing department directly at <email>authorbilling@plos.org</email>.</p>
    <p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they’ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <email>onepress@plos.org</email>.</p>
    <p>Kind regards,</p>
    <p>Tuneera Bhadauria, Ph.D.</p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
    <p>Additional Editor Comments (optional):</p>
    <p>I would like to congratulate the authors for revising the manuscript well, incorporating the suggestions and comments put forward by me and the reviewers in the revised manuscript making it worthy of publication in the journal. Accordingly, I recommend that the manuscript be accepted for publication in the journal.</p>
    <p>Reviewers' comments:</p>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pone.0255674.r005" specific-use="acceptance-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pone.0255674.r005</article-id>
    <title-group>
      <article-title>Acceptance letter</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Bhadauria</surname>
          <given-names>Tunira</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2021 Tunira Bhadauria</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Tunira Bhadauria</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="doi" xlink:href="10.1371/journal.pone.0255674" id="rel-obj005" related-article-type="reviewed-article"/>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">26 Aug 2021</named-content>
    </p>
    <p>PONE-D-21-14202R1 </p>
    <p>ESIDE: A computationally intelligent method to identify earthworm species (E. fetida) from digital images: Application in taxonomy </p>
    <p>Dear Dr. Abbasi:</p>
    <p>I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now with our production department. </p>
    <p>If your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information please contact <email>onepress@plos.org</email>.</p>
    <p>If we can help with anything else, please email us at <email>plosone@plos.org</email>. </p>
    <p>Thank you for submitting your work to PLOS ONE and supporting open access. </p>
    <p>Kind regards, </p>
    <p>PLOS ONE Editorial Office Staff</p>
    <p>on behalf of</p>
    <p>Dr. Tunira Bhadauria </p>
    <p>Academic Editor</p>
    <p>PLOS ONE</p>
  </body>
</sub-article>
