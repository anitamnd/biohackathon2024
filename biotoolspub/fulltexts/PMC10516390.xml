<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Brief Bioinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Brief Bioinform</journal-id>
    <journal-id journal-id-type="publisher-id">bib</journal-id>
    <journal-title-group>
      <journal-title>Briefings in Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1467-5463</issn>
    <issn pub-type="epub">1477-4054</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10516390</article-id>
    <article-id pub-id-type="pmid">37478379</article-id>
    <article-id pub-id-type="doi">10.1093/bib/bbad263</article-id>
    <article-id pub-id-type="publisher-id">bbad263</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Problem Solving Protocol</subject>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>HiC4D: forecasting spatiotemporal Hi-C data with residual ConvLSTM</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Tong</given-names>
        </name>
        <aff><institution>Department of Computer Science, University of Miami</institution>, <addr-line>1365 Memorial Drive, 33124, FL</addr-line>, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Wang</surname>
          <given-names>Zheng</given-names>
        </name>
        <!--zheng.wang@miami.edu-->
        <aff><institution>Department of Computer Science, University of Miami</institution>, <addr-line>1365 Memorial Drive, 33124, FL</addr-line>, <country country="US">USA</country></aff>
        <xref rid="cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="cor1">Corresponding author. Zheng Wang, E-mail: <email>zheng.wang@miami.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>9</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-07-20">
      <day>20</day>
      <month>7</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>20</day>
      <month>7</month>
      <year>2023</year>
    </pub-date>
    <volume>24</volume>
    <issue>5</issue>
    <elocation-id>bbad263</elocation-id>
    <history>
      <date date-type="received">
        <day>9</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="rev-recd">
        <day>12</day>
        <month>6</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>28</day>
        <month>6</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="bbad263.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>The Hi-C experiments have been extensively used for the studies of genomic structures. In the last few years, spatiotemporal Hi-C has largely contributed to the investigation of genome dynamic reorganization. However, computationally modeling and forecasting spatiotemporal Hi-C data still have not been seen in the literature. We present HiC4D for dealing with the problem of forecasting spatiotemporal Hi-C data. We designed and benchmarked a novel network and named it residual ConvLSTM (ResConvLSTM), which is a combination of residual network and convolutional long short-term memory (ConvLSTM). We evaluated our new ResConvLSTM networks and compared them with the other five methods, including a naïve network (NaiveNet) that we designed as a baseline method and four outstanding video-prediction methods from the literature: ConvLSTM, spatiotemporal LSTM (ST-LSTM), self-attention LSTM (SA-LSTM) and simple video prediction (SimVP). We used eight different spatiotemporal Hi-C datasets for the blind test, including two from mouse embryogenesis, one from somatic cell nuclear transfer (SCNT) embryos, three embryogenesis datasets from different species and two non-embryogenesis datasets. Our evaluation results indicate that our ResConvLSTM networks almost always outperform the other methods on the eight blind-test datasets in terms of accurately predicting the Hi-C contact matrices at future time-steps. Our benchmarks also indicate that all of the methods that we benchmarked can successfully recover the boundaries of topologically associating domains called on the experimental Hi-C contact matrices. Taken together, our benchmarks suggest that HiC4D is an effective tool for predicting spatiotemporal Hi-C data. HiC4D is publicly available at both <ext-link xlink:href="http://dna.cs.miami.edu/HiC4D/" ext-link-type="uri">http://dna.cs.miami.edu/HiC4D/</ext-link> and <ext-link xlink:href="https://github.com/zwang-bioinformatics/HiC4D/" ext-link-type="uri">https://github.com/zwang-bioinformatics/HiC4D/</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>4D genome</kwd>
      <kwd>predicting spatiotemporal Hi-C data</kwd>
      <kwd>deep learning</kwd>
      <kwd>convolutional long short-term memory</kwd>
    </kwd-group>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute of General Medical Sciences</institution>
            <institution-id institution-id-type="DOI">10.13039/100000057</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institutes of Health</institution>
            <institution-id institution-id-type="DOI">10.13039/100000002</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R35GM137974</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="11"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>INTRODUCTION</title>
    <p>Since the Hi-C technique was introduced [<xref rid="ref1" ref-type="bibr">1</xref>], it played a vital role in identifying topologically associating domains (TADs) [<xref rid="ref2" ref-type="bibr">2</xref>], discovering A/B compartments [<xref rid="ref1" ref-type="bibr">1</xref>], and detecting DNA loops [<xref rid="ref3" ref-type="bibr">3</xref>]. The genome-wide high-resolution Hi-C data were widely used in various studies, such as reconstructing chromatin three-dimensional structures [<xref rid="ref4" ref-type="bibr">4</xref>], predicting DNA methylation [<xref rid="ref5" ref-type="bibr">5</xref>], investigating neural development [<xref rid="ref6" ref-type="bibr">6</xref>] and exploring Xist transcript mechanism [<xref rid="ref7" ref-type="bibr">7</xref>].</p>
    <p>In recent years, with the coming of the four-dimensional nucleome project [<xref rid="ref8" ref-type="bibr">8</xref>], the dynamics of chromatin architectures during a specific nuclear or cellular process attracted much attention. Various spatiotemporal Hi-C experiments and its variants were conducted for understanding dynamic chromatin architectures in response to external stimuli [<xref rid="ref9" ref-type="bibr">9–11</xref>] and for investigating nuclear or cellular developments, such as cardiogenesis [<xref rid="ref12" ref-type="bibr">12</xref>], neural differentiation [<xref rid="ref6" ref-type="bibr">6</xref>], B cell differentiation [<xref rid="ref13" ref-type="bibr">13</xref>], B cell reprogramming [<xref rid="ref14" ref-type="bibr">14</xref>] and embryogenesis of mouse [<xref rid="ref15" ref-type="bibr">15–17</xref>], human [<xref rid="ref18" ref-type="bibr">18</xref>], drosophila [<xref rid="ref19" ref-type="bibr">19</xref>], Xenopus tropicalis [<xref rid="ref20" ref-type="bibr">20</xref>], zebrafish [<xref rid="ref21" ref-type="bibr">21</xref>], pig [<xref rid="ref22" ref-type="bibr">22</xref>] and medaka [<xref rid="ref23" ref-type="bibr">23</xref>]. These spatiotemporal Hi-C studies revealed transitions, emergences and reorganizations of chromatin architectures, and the captured spatiotemporal Hi-C data are an excellent source for exploring the relationships between gene expression and dynamics of genome reprogramming or development.</p>
    <p>Long short-term memory (LSTM) [<xref rid="ref24" ref-type="bibr">24</xref>] as a special recurrent neural network (RNN) for capturing long-term dependencies has been well studied and widely used in various areas, and two LSTM-variants: Gated Recurrent Unit (GRU) [<xref rid="ref25" ref-type="bibr">25</xref>] and MUT1 [<xref rid="ref26" ref-type="bibr">26</xref>] are attracting more and more attention in the computer vision field. The Convolutional LSTM (ConvLSTM) [<xref rid="ref27" ref-type="bibr">27</xref>], a combination of convolution and LSTM operations, is capable of considering spatial correlations compared with fully connected LSTM (FC-LSTM). The novel architecture named spatiotemporal long short-term memory (ST-LSTM) [<xref rid="ref28" ref-type="bibr">28</xref>, <xref rid="ref29" ref-type="bibr">29</xref>] included a new spatiotemporal memory state based on ConvLSTM for learning spatial and temporal representations at the same time. Self-attention LSTM (SA-LSTM) [<xref rid="ref30" ref-type="bibr">30</xref>] introduced the popular self-attention mechanisms into ConvLSTM. Alphafold [<xref rid="ref31" ref-type="bibr">31</xref>] used one-dimensional ConvLSTM for predicting protein structures. Hi-C-LSTM [<xref rid="ref32" ref-type="bibr">32</xref>] used LSTM for learning low-dimensional latent representations of a Hi-C contact matrix.</p>
    <p>RNNs based on ConvLSTMs were extensively used in video prediction. The neural networks for video prediction can be roughly split into two big categories [<xref rid="ref33" ref-type="bibr">33</xref>]: (1) RNNs by stacking multiple ConvLSTM-based layers and (2) a spatial encoder and a spatial decoder that are usually implemented as convolutional layers together with a temporal learning part between them. The temporal-learning part in the middle may be RNN, a transformer or convolutional networks (ConvNet).</p>
    <p>One of the newest video-prediction methods that is worth mentioning is the simple video prediction (SimVP) model, which was built completely by convolutional layers [<xref rid="ref33" ref-type="bibr">33</xref>] and achieved state-of-the-art performance over five commonly used datasets for the task of video prediction. However, when it comes to the problem of forecasting spatiotemporal Hi-C data, we can hardly find a tool in the literature. There is a computational method 4DMax [<xref rid="ref34" ref-type="bibr">34</xref>], which takes spatiotemporal Hi-C data as input for predicting chromatin organizations. It can interpolate Hi-C contact maps between two given time points from its predicted 4D models, but it cannot forecast spatiotemporal Hi-C at future time-steps.</p>
    <p>In this paper, we present HiC4D for forecasting spatiotemporal Hi-C data. Since residual ConvNet (ResNet) [<xref rid="ref35" ref-type="bibr">35</xref>] was extremely successful in building deeper networks, we newly designed and implemented a simple residual ConvLSTM and named it ResConvLSTM, which is a novel network making ConvLSTMs have more layers and with better learning abilities. In total, we benchmarked nine different methods, including ConvLSTM, ResConvLSTM and its three variants, ST-LSTM, SA-LSTM, SimVP and a naïve network. Our blind test indicates that our ResConvLSTM together with its variants almost always outperforms the other methods on eight different spatiotemporal Hi-C datasets.</p>
  </sec>
  <sec id="sec2">
    <title>MATERIALS AND METHODS</title>
    <sec id="sec2a">
      <title>Spatiotemporal Hi-C datasets</title>
      <p>We used eight different spatiotemporal Hi-C datasets in this study. These datasets were of a varying number of time-steps and read depths for each time point. The first one [<xref rid="ref15" ref-type="bibr">15</xref>] captured Hi-C data in preimplantation embryos at the following stages: gametes (sperm and MII oocyte), pronuclear stage 5 (PN5) zygotes, early two-cell, late two-cell, eight-cell, inner cell masses (ICM) and mouse embryonic stem cells (mES). We chose the Hi-C data of the last six development stages as our first spatiotemporal Hi-C dataset (<xref rid="f1" ref-type="fig">Figure 1A</xref> and <xref rid="TB1" ref-type="table">Table 1</xref>). We downloaded all the valid Hi-C read pairs in the format of ‘allValidPairs’ from Gene Expression Omnibus (GEO) under accession number GSE82185. To balance sequencing depths among different time-steps, we first obtained long-range (&gt; 20-kb) intra-chromosomal read pairs for each stage, and then downsampled read pairs to 115 million for each stage (<xref rid="sup1" ref-type="supplementary-material">Table S1</xref>).</p>
      <table-wrap position="float" id="TB1">
        <label>Table 1</label>
        <caption>
          <p>Overview of eight spatiotemporal Hi-C datasets.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col span="2" align="left"/>
            <col span="3" align="left"/>
            <col span="5" align="left"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">ID</th>
              <th align="left" rowspan="1" colspan="1">Species</th>
              <th align="left" rowspan="1" colspan="1">NO. of time steps (we used)</th>
              <th align="left" rowspan="1" colspan="1">System</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">1</td>
              <td rowspan="1" colspan="1">Mouse</td>
              <td rowspan="1" colspan="1">8(6)</td>
              <td rowspan="1" colspan="1">Embryogenesis</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">2</td>
              <td rowspan="1" colspan="1">Mouse</td>
              <td rowspan="1" colspan="1">8(6)</td>
              <td rowspan="1" colspan="1">Embryogenesis</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">3</td>
              <td rowspan="1" colspan="1">Mouse</td>
              <td rowspan="1" colspan="1">13(6)</td>
              <td rowspan="1" colspan="1">SCNT embryos</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">4</td>
              <td rowspan="1" colspan="1">Human</td>
              <td rowspan="1" colspan="1">6(5)</td>
              <td rowspan="1" colspan="1">Embryogenesis</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">5</td>
              <td rowspan="1" colspan="1">Medaka</td>
              <td rowspan="1" colspan="1">12(6)</td>
              <td rowspan="1" colspan="1">Embryogenesis</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">6</td>
              <td rowspan="1" colspan="1">X. tropicalis</td>
              <td rowspan="1" colspan="1">9(6)</td>
              <td rowspan="1" colspan="1">Embryogenesis</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">7</td>
              <td rowspan="1" colspan="1">Human</td>
              <td rowspan="1" colspan="1">5(5)</td>
              <td rowspan="1" colspan="1">Cardiogenesis</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">8</td>
              <td rowspan="1" colspan="1">Mouse</td>
              <td rowspan="1" colspan="1">7(6)</td>
              <td rowspan="1" colspan="1">Cell reprogramming</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <fig position="float" id="f1">
        <label>Figure 1</label>
        <caption>
          <p>(<bold>A</bold>) An example of spatiotemporal Hi-C data with six time-steps from dataset 1. (<bold>B</bold>) The unrolled RNN architecture of a typical next-frame prediction method. The dashed blue box highlights the three time-steps as input. The contents of the dashed orange box consist of the five next-frame reconstructions. (<bold>C</bold>) A four-layer ConvLSTM network at time <inline-formula><tex-math notation="LaTeX" id="ImEquation1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t$\end{document}</tex-math></inline-formula>. (<bold>D</bold>) One block of ResConvLSTM containing two ConvLSTM layers. (<bold>E</bold>) The architecture of ResConvLSTM network for next-frame prediction at time <inline-formula><tex-math notation="LaTeX" id="ImEquation2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t$\end{document}</tex-math></inline-formula>. (<bold>F</bold>) A four-layer ST-LSTM network at times <inline-formula><tex-math notation="LaTeX" id="ImEquation3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t-1$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ImEquation4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t+1$\end{document}</tex-math></inline-formula>. The blue arrows denote the flows of spatiotemporal memory states.</p>
        </caption>
        <graphic xlink:href="bbad263f1" position="float"/>
      </fig>
      <p>The second dataset [<xref rid="ref17" ref-type="bibr">17</xref>] is very similar to the first one, and it captured Hi-C data of mouse gametes (sperm and MII oocyte) and early embryos (Table <xref rid="TB1" ref-type="table">1</xref>), including two-cell, four-cell, eight-cell, embryonic day (E)3.5 and E7.5 stages. As in dataset 1, we only used the last six stages in this study. We downloaded raw Hi-C reads from Genome Sequence Archive (GSA) under accession number PRJCA000241. We mapped the raw reads to the reference genome (mm10) using Juicer [<xref rid="ref36" ref-type="bibr">36</xref>], used the read pair file ‘merged_nodups.txt’ to obtain long-range (&gt; 20-kb) intra-chromosomal read pairs, and finally downsampled read pairs to 62 million for each stage (<xref rid="sup1" ref-type="supplementary-material">Table S2</xref>).</p>
      <p>The third dataset [<xref rid="ref16" ref-type="bibr">16</xref>] captured spatiotemporal Hi-C of somatic cell nuclear transfer (SCNT) embryos (Table <xref rid="TB1" ref-type="table">1</xref>). It included 13 different stages of reconstructed embryos. Considering the lower sequencing depths of some stages and being largely consistent with the time-steps of dataset 1, we only used six stages (<xref rid="sup1" ref-type="supplementary-material">Table S3</xref>). We downloaded the Hi-C read pairs in the format of ‘allValidPairs’ from GEO under accession number GSE146001, obtained long-range intra-chromosomal read pairs and downsampled read pairs (33 million) as above (<xref rid="sup1" ref-type="supplementary-material">Table S3</xref>).</p>
      <p>The fourth dataset [<xref rid="ref18" ref-type="bibr">18</xref>] contains six stages of spatiotemporal Hi-C during human embryogenesis, including sperm, two-cell, eight-cell, morula, blastocysts and 6-week-old embryos. We used the last five stages (Table <xref rid="TB1" ref-type="table">1</xref>) in our experiment. We downloaded the raw reads from GSA under accession number CRA000852. We mapped the raw reads to the reference genome (hg19) using Juicer [<xref rid="ref36" ref-type="bibr">36</xref>], filtered the read pair file ‘merged_nodups.txt’ to obtain long-range (&gt; 20-kb) intra-chromosomal read pairs, and finally downsampled read pairs to 14.5 million for each stage (<xref rid="sup1" ref-type="supplementary-material">Table S4</xref>).</p>
      <p>The fifth dataset [<xref rid="ref23" ref-type="bibr">23</xref>] captures medaka Hi-C at 12 time points before, during and after gastrulation. We selected six time points as one of our testing datasets. We downloaded raw reads from the NCBI BioProject database (PRJDB7492) and mapped them to the reference genome (GCA_002234675.1) with Juicer followed by the same filtering and down-sampling procedures (<xref rid="sup1" ref-type="supplementary-material">Table S5</xref>).</p>
      <p>The sixth dataset [<xref rid="ref20" ref-type="bibr">20</xref>] contains nine stages of spatiotemporal Hi-C captured in Xenopus tropicalis embryos. We followed the same pipeline of processing the dataset: downloading raw reads (NCBI BioProject database under accession number PRJNA606649), mapping to the reference genome (xenTro10) with Juicer and finally filtering and down-sampling (<xref rid="sup1" ref-type="supplementary-material">Table S6</xref>).</p>
      <p>The last two datasets (datasets 7 and 8) were selected for benchmarking our methods on non-embryogenesis data. The developments for the two datasets are human cardiogenesis [<xref rid="ref12" ref-type="bibr">12</xref>] and the reprogramming of mouse somatic cells into pluripotent stem cells [<xref rid="ref14" ref-type="bibr">14</xref>], respectively. The ‘allValidPairs’ for dataset 7 were downloaded from GEO, GSE106690, and the details for filtering and down-sampling procedures can be found in <xref rid="sup1" ref-type="supplementary-material">Table S7</xref>. The raw reads for dataset 8 were obtained from GEO GSE96611 and mapped to the reference genome (hg38) with Juicer followed by the same filtering and down-sampling steps (<xref rid="sup1" ref-type="supplementary-material">Table S8</xref>).</p>
      <p>To reduce the effects from different numbers of valid read pairs, we set a parameter (maxHiC) for each dataset based on their total number of read pairs after down-sampling, chromosome numbers and chromosome lengths to rescale Hi-C contacts to the range [0, 1].</p>
    </sec>
    <sec id="sec2b">
      <title>HiC4D overview</title>
      <p>The training data were extracted from dataset 1. From all chromosomes from 1 to X, we extracted validation data on chromosome 19, two chromosomes (i.e. 2 and 6) were left for the blind test and the rest chromosomes were used for generating training data. The other seven datasets were selected for blind testing: we tested datasets 2–3 on two chromosomes (2 and 6) and the rest datasets (4–8) on all chromosomes. Considering read depths, we only focused on the resolution of 40 kb in this study. The samples for each chromosome were generated along the diagonal of its 2D raw contact matrix with a sliding window of size <inline-formula><tex-math notation="LaTeX" id="ImEquation7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$50\times 50$\end{document}</tex-math></inline-formula> and a step of size 3 bins. The samples were concatenated as an <inline-formula><tex-math notation="LaTeX" id="ImEquation8">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$n\times{t}\times 1\times 50\times 50$\end{document}</tex-math></inline-formula> five-dimensional tensor, where n is the total number of samples and t is the number of time-steps. The main purpose of this study is to use the Hi-C data of the first three time-steps (<inline-formula><tex-math notation="LaTeX" id="ImEquation9">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{1}$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ImEquation10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{2}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{3}$\end{document}</tex-math></inline-formula>) as input to predict the corresponding Hi-C data of the last three time-steps (<inline-formula><tex-math notation="LaTeX" id="ImEquation12">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{4}$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ImEquation13">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{5}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation14">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{6}$\end{document}</tex-math></inline-formula>).</p>
      <p>We tested two types of frame prediction methods: next-frame and three-step ahead. The next-frame methods consist of ConvLSTM, our newly designed ResConvLSTM, its variants (ResConvGRU, ResConvMUT and ResConvLSTM2) and two novel ConvLSTM-based methods (ST-LSTM and SA-LSTM). The three-step ahead methods include SimVP and NaiveNet. These nine methods were trained with the same data. The best models for the blind test were the ones that achieved the best performance on validation data. Since one pixel may be predicted more than one time, its final prediction is the average value of all predictions.</p>
      <p>After obtaining predictions for each testing chromosome at the future time-steps, we evaluated each method mainly by quantifying the similarity scores between ground truth and predictions for each time-step.</p>
    </sec>
    <sec id="sec2c">
      <title>Next-frame method</title>
      <p>The input of next-frame methods <inline-formula><tex-math notation="LaTeX" id="ImEquation15">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X_{t}$\end{document}</tex-math></inline-formula> at time <inline-formula><tex-math notation="LaTeX" id="ImEquation16">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t$\end{document}</tex-math></inline-formula> is an <inline-formula><tex-math notation="LaTeX" id="ImEquation17">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$n\times 1\times 50\times 50$\end{document}</tex-math></inline-formula> four-dimensional tensor. After passing through the network, we obtain the output <inline-formula><tex-math notation="LaTeX" id="ImEquation18">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\hat{X}_{t+1}$\end{document}</tex-math></inline-formula>, which is thought of as the reconstruction of <inline-formula><tex-math notation="LaTeX" id="ImEquation19">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X_{t+1}$\end{document}</tex-math></inline-formula> (<xref rid="f1" ref-type="fig">Figure 1B</xref>). Since our input time-steps are <inline-formula><tex-math notation="LaTeX" id="ImEquation20">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{1}$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ImEquation21">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{2}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation22">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{3}$\end{document}</tex-math></inline-formula>, the fourth and the following <inline-formula><tex-math notation="LaTeX" id="ImEquation23">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X_{t}$\end{document}</tex-math></inline-formula> are directly from the output of their previous time-step (<xref rid="f1" ref-type="fig">Figure 1B</xref>). The loss is calculated between <inline-formula><tex-math notation="LaTeX" id="ImEquation24">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X_{t}$\end{document}</tex-math></inline-formula> and reconstructed <inline-formula><tex-math notation="LaTeX" id="ImEquation25">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\hat{X}_{t}$\end{document}</tex-math></inline-formula>, where <inline-formula><tex-math notation="LaTeX" id="ImEquation26">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t$\end{document}</tex-math></inline-formula> is from two to six. Technical details of the next-frame methods (ConvLSTM, ResConvLSTM and ST-LSTM) will be presented in the following three subsections.</p>
      <sec id="sec2c1">
        <title>Convolutional LSTMs</title>
        <p>The first ConvLSTM (ConvLSTM-1) we implemented and benchmarked in this study is the same as the one published in the paper that first applied convolutional operation to LSTM [<xref rid="ref27" ref-type="bibr">27</xref>]. The following equations describe a typical <inline-formula><tex-math notation="LaTeX" id="ImEquation27">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$l$\end{document}</tex-math></inline-formula>-th ConvLSTM-1 layer at time <inline-formula><tex-math notation="LaTeX" id="ImEquation28">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t$\end{document}</tex-math></inline-formula> with the following three inputs: the input data <inline-formula><tex-math notation="LaTeX" id="ImEquation29">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$X_{t}$\end{document}</tex-math></inline-formula>, the last memory cell state <inline-formula><tex-math notation="LaTeX" id="ImEquation30">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$C^{l}_{t-1}$\end{document}</tex-math></inline-formula> and the last hidden state <inline-formula><tex-math notation="LaTeX" id="ImEquation31">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$H_{t-1}^{l}$\end{document}</tex-math></inline-formula>: </p>
        <disp-formula>
          <tex-math notation="LaTeX" id="DmEquation1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{align*} i_{t} &amp;=\sigma\left(W_{xi}\ast X_{t}+W_{hi}\ast H_{t-1}^{l}+W_{ci}\circ C_{t-1}^{l}+b_{i}\right) \nonumber \\ f_{t} &amp;=\sigma\left(W_{xf}\ast X_{t}+W_{hf}\ast H_{t-1}^{l}+W_{cf}\circ C_{t-1}^{l}+b_{f}\right) \nonumber \\ C_{t}^{l} &amp;=f_{t}\circ C_{t-1}^{l}+i_{t}\circ\tanh{\left(W_{xc}\ast X_{t}+W_{hc}\ast H_{t-1}^{l}+b_{c}\right)} \nonumber \\ o_{t} &amp;=\sigma(W_{xo}\ast X_{t}+W_{ho}\ast H_{t-1}^{l}+W_{co}\circ C_{t}^{l}+b_{o}) \nonumber \\ H_{t}^{l} &amp;=o_{t}\circ\tanh(C_{t}^{l}), \nonumber \end{align*}\end{document}</tex-math>
        </disp-formula>
        <p>where <inline-formula><tex-math notation="LaTeX" id="ImEquation32">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\ast $\end{document}</tex-math></inline-formula> denotes the convolution operator, <inline-formula><tex-math notation="LaTeX" id="ImEquation33">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\sigma $\end{document}</tex-math></inline-formula> denotes the sigmoid function, <inline-formula><tex-math notation="LaTeX" id="ImEquation34">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\circ $\end{document}</tex-math></inline-formula> denotes the Hadamard product and <inline-formula><tex-math notation="LaTeX" id="ImEquation35">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$W$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation36">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$b$\end{document}</tex-math></inline-formula> are the weight and bias parameters that need to be learned. Since there are various LSTM variants, we added two more ConvLSTMs (i.e. ConvLSTM-2 and ConvLSTM-3). When calculating <inline-formula><tex-math notation="LaTeX" id="ImEquation37">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$i_{t}$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ImEquation38">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$f_{t}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation39">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$o_{t}$\end{document}</tex-math></inline-formula>, we removed the Hadamard products in ConvLSTM-2 and replaced all the Hadamard products with convolutional operations in ConvLSTM-3 (see <xref rid="sup1" ref-type="supplementary-material">supplementary materials</xref> for details). The other parts for the three ConvLSTMs remain the same. We only used one of them for the blind test, and the evaluation results for the three ConvLSTM variants are shown in the Results section. We built the ConvLSTM networks by simply stacking multiple ConvLSTM layers (<xref rid="f1" ref-type="fig">Figure 1C</xref>).</p>
      </sec>
      <sec id="sec2c2">
        <title>ResConvLSTM and its three variants</title>
        <p>We designed ResConvLSTM, which is a combination of residual ConvNet and ConvLSTM (<xref rid="f1" ref-type="fig">Figure 1D</xref>) and is similar to previous residual LSTMs [<xref rid="ref37" ref-type="bibr">37</xref>, <xref rid="ref38" ref-type="bibr">38</xref>]. The <inline-formula><tex-math notation="LaTeX" id="ImEquation40">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$i$\end{document}</tex-math></inline-formula>-th ResConvLSTM block shown in <xref rid="f1" ref-type="fig">Figure 1D</xref> contains two ConvLSTM-1 layers (i.e. <inline-formula><tex-math notation="LaTeX" id="ImEquation41">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$ConvLSTM_{i_{1}}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation42">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$ConvLSTM_{i_{2}}$\end{document}</tex-math></inline-formula>). The final output <inline-formula><tex-math notation="LaTeX" id="ImEquation43">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$H_{t}^{i}$\end{document}</tex-math></inline-formula> of this block at time <inline-formula><tex-math notation="LaTeX" id="ImEquation44">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t$\end{document}</tex-math></inline-formula> is equal to </p>
        <disp-formula>
          <tex-math notation="LaTeX" id="DmEquation2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{align*}&amp; H_{t}^{i}=H_{t}^{i-1}+H_{t}^{i_{2}}, \end{align*}\end{document}</tex-math>
        </disp-formula>
        <p>where the input <inline-formula><tex-math notation="LaTeX" id="ImEquation45">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$H_{t}^{i-1}$\end{document}</tex-math></inline-formula> is the output of the previous ResConvLSTM block and the updated hidden state <inline-formula><tex-math notation="LaTeX" id="ImEquation46">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$H_{t}^{i_{2}}$\end{document}</tex-math></inline-formula> is the output of <inline-formula><tex-math notation="LaTeX" id="ImEquation47">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$ConvLSTM_{i_{2}}$\end{document}</tex-math></inline-formula>. The skip connection can make the output <inline-formula><tex-math notation="LaTeX" id="ImEquation48">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$H_{t}^{i}$\end{document}</tex-math></inline-formula> directly link to the input <inline-formula><tex-math notation="LaTeX" id="ImEquation49">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$H_{t}^{i-1}$\end{document}</tex-math></inline-formula>. The final ResConvLSTM network we used for the blind test is shown in <xref rid="f1" ref-type="fig">Figure 1E</xref>. It contains two 3<inline-formula><tex-math notation="LaTeX" id="ImEquation50">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\times $\end{document}</tex-math></inline-formula>3 2D convolutional layers for increasing and reducing hidden channels, and the middle part is built by stacking 25 ResConvLSTM blocks.</p>
        <p>We replaced all ConvLSTMs in the ResConvLSTM network with convolutional GRU and MUT1 (see <xref rid="sup1" ref-type="supplementary-material">supplementary materials</xref> for details) and obtained two more Residual RNN networks (ResConvGRU and ResConvMUT). The two RNNs (GRU and MUT) outperform LSTM on some tasks [<xref rid="ref26" ref-type="bibr">26</xref>]. Therefore, we think it is worth benchmarking the two methods together with residual networks. We also extended ResConvLSTM by concatenating outputs from every five ResConvLSTM blocks as the final input of the last output layer (ResConvLSTM2 in <xref rid="sup1" ref-type="supplementary-material">Figure S1</xref>), which was inspired by our previous work [<xref rid="ref39" ref-type="bibr">39</xref>].</p>
      </sec>
      <sec id="sec2c3">
        <title>ST-LSTM and SA-LSTM</title>
        <p>The ST-LSTM introduced a novel spatiotemporal memory state [<xref rid="ref28" ref-type="bibr">28</xref>, <xref rid="ref29" ref-type="bibr">29</xref>]. It can flow in both bottom-up and top-down directions, whereas the memory cell state and the hidden state can only flow in horizontal and bottom-up directions, respectively. The following equations describe an ST-LSTM layer at time <inline-formula><tex-math notation="LaTeX" id="ImEquation51">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t$\end{document}</tex-math></inline-formula>: </p>
        <disp-formula>
          <tex-math notation="LaTeX" id="DmEquation3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
\begin{align*} i_{t} &amp;=\sigma\left(W_{xi}{\ast X}_{t}+W_{hi}\ast H_{t-1}^{l}{+\ b}_{i}\right) \\ f_{t} &amp;=\sigma\left(W_{xf}\ast X_{t}+W_{hf}\ast H_{t-1}^{l}+b_{f}\right) \\ C_{t}^{l} &amp;=f_{t}\circ C_{t-1}^{l}+i_{t}\circ\tanh{\left(W_{xc}{\ast X}_{t}+W_{hc}\ast H_{t-1}^{l}+b_{c}\right)} \\ i_{t}^{\prime} &amp;=\sigma\left(W_{xi}^{\prime}{\ast}{{X}}_{t} +W_{mi}\ast M_{t}^{l-1}+b_{i}^{\prime}\right) \\ f_{t}^{\prime} &amp;=\sigma\left(W_{xf}^{\prime}\ast X_{t}+W_{mf}\ast M_{t}^{l-1}+b_{f}^{\prime}\right) \\ M_{t}^{l} &amp;=f_{t}^{\prime}\circ M_{t}^{l-1}+i_{t}^{\prime}\circ\tanh{\left(W_{xm}{\ast X}_{t}+W_{mm}\ast M_{t}^{l-1}+b_{m}\right)} \\ o_{t} &amp;=\sigma(W_{xo}\ast X_{t}+W_{ho}\ast H_{t-1}^{l}+W_{co}\ast C_{t}^{l}+W_{mo}{\ast M}_{t}^{l}+b_{o}) \\ H_{t}^{l} &amp;=o_{t}\circ\tanh(W_{1}\ast\left[C_{t}^{l},\ M_{t}^{l}\right]), \end{align*}\end{document}</tex-math>
        </disp-formula>
        <p>where <inline-formula><tex-math notation="LaTeX" id="ImEquation52">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$M_{t}^{l}$\end{document}</tex-math></inline-formula> is the spatiotemporal memory state for the <inline-formula><tex-math notation="LaTeX" id="ImEquation53">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$l$\end{document}</tex-math></inline-formula>-th layer at time <inline-formula><tex-math notation="LaTeX" id="ImEquation54">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation55">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$W_{1}$\end{document}</tex-math></inline-formula> is 1<inline-formula><tex-math notation="LaTeX" id="ImEquation56">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$\times $\end{document}</tex-math></inline-formula>1 2D convolutional operation for reducing the hidden dimension. The process of generating <inline-formula><tex-math notation="LaTeX" id="ImEquation57">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$M_{t}^{l}$\end{document}</tex-math></inline-formula> is very similar to deriving <inline-formula><tex-math notation="LaTeX" id="ImEquation58">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$C_{t}^{l}$\end{document}</tex-math></inline-formula>. We implemented the final ST-LSTM networks by stacking multiple ST-LSTM layers (<xref rid="f1" ref-type="fig">Figure 1F</xref>).</p>
        <p>We also implemented an SA-LSTM [<xref rid="ref30" ref-type="bibr">30</xref>], which is very similar to ConvLSTM. The main difference is that it preprocessed the input hidden state in each ConvLSTM with a self-attention module.</p>
      </sec>
    </sec>
    <sec id="sec2g">
      <title>The three-step ahead methods: SimVP and NaiveNet</title>
      <p>As its name suggests, the three-step ahead methods mean that we predict three future frames in one prediction. We used the same network of SimVP as described in [<xref rid="ref33" ref-type="bibr">33</xref>]. The batch size and the hidden dimension were set to 32 and 128, respectively. The other hyperparameters were with defaults. We designed a naïve 3D convolutional neural network (NaiveNet) as a baseline. The NaiveNet (<xref rid="sup1" ref-type="supplementary-material">Figure S2</xref>) contains three 3D convolutional layers. Each of the first two layers is followed by Group normalization (number of groups set to 2) [<xref rid="ref40" ref-type="bibr">40</xref>] and LeakyReLU (negative slope set to 0.2).</p>
      <p>The model of NaiveNet for the blind test was trained with the following hyperparameters: batch size 32, hidden dimension 128 and kernel sizes 7 for the two spatial dimensions (height and width) and 1 for the temporal dimension. The input of three-step ahead methods is an <inline-formula><tex-math notation="LaTeX" id="ImEquation59">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$n\times 3\times 1\times 50\times 50$\end{document}</tex-math></inline-formula> five-dimensional tensor, where 3 denotes the first three time-steps (i.e. <inline-formula><tex-math notation="LaTeX" id="ImEquation60">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{1}$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ImEquation61">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{2}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation62">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{3}$\end{document}</tex-math></inline-formula>). The output is still an <inline-formula><tex-math notation="LaTeX" id="ImEquation63">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$n\times 3\times 1\times 50\times 50$\end{document}</tex-math></inline-formula> five-dimensional tensor, but here 3 denotes the last three time-steps (i.e. <inline-formula><tex-math notation="LaTeX" id="ImEquation64">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{4}$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ImEquation65">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{5}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation66">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{6}$\end{document}</tex-math></inline-formula>). The loss is calculated between the output and the ground truth at the last three time-steps.</p>
    </sec>
    <sec id="sec2h">
      <title>Implementation details</title>
      <p>All models were implemented in PyTorch [<xref rid="ref41" ref-type="bibr">41</xref>]. Unless otherwise stated, the loss function for all the models is mean squared error (MSE), and the optimizer for training all models is Adam [<xref rid="ref42" ref-type="bibr">42</xref>] with a learning rate set to 0.0001. All models were trained on an NVIDIA A100 GPU with 40 GB memory.</p>
    </sec>
    <sec id="sec2i">
      <title>Evaluation metrics</title>
      <p>The main evaluation strategy is by quantifying similarity or reproducibility between ground-truth and predicted Hi-C contact matrices at the future time-steps. The two metrics we used are Pearson correlation coefficients at each genomic distance (10–30 bins) and stratum-adjusted correlation coefficient (SCC) from HiCRep [<xref rid="ref43" ref-type="bibr">43</xref>]. When running HiCRep, we set the smoothing parameter to 5 and the lower and upper bounds of the genomic distance to 400 000 and 1600 000, respectively. We also calculated insulation scores [<xref rid="ref44" ref-type="bibr">44</xref>] (see <xref rid="sup1" ref-type="supplementary-material">supplementary materials</xref> for details) for evaluating the ability to recover TAD boundaries.</p>
    </sec>
  </sec>
  <sec id="sec3">
    <title>RESULTS</title>
    <sec id="sec3a">
      <title>Hyperparameter tuning and model selection</title>
      <p>For training ConvLSTM-based models, we tested various hyperparameter combinations (see <xref rid="sup1" ref-type="supplementary-material">Table S9</xref>). For the three ConvLSTM networks (ConvLSTM-1, ConvLSTM-2 and ConvLSTM-3), the first two achieved a smaller MSE loss (0.0067 and 0.00669) than the last one (0.00684). To select one for the blind test, we further evaluated the three networks using Pearson correlations on chromosome 19 at each genomic distance (<xref rid="sup1" ref-type="supplementary-material">Figure S3</xref>). In general, ConvLSTM-1 performs better than the other two. Therefore, the four-layer ConvLSTM-1 was selected as the representative of ConvLSTM networks for the blind test.</p>
      <p>For tuning ResConvLSTM networks, we found three hyperparameter combinations (see <xref rid="sup1" ref-type="supplementary-material">Table S9</xref>) achieved almost the same best losses (0.00666, 0.00664 and 0.00666). Therefore, we further evaluated the three models using Pearson correlations (<xref rid="sup1" ref-type="supplementary-material">Figure S4</xref>) and observed that deeper ResConvLSTM networks perform better, especially at time <inline-formula><tex-math notation="LaTeX" id="ImEquation67">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{6}$\end{document}</tex-math></inline-formula>. The model with 25 ResConvLSTM blocks (52 layers) was used for the blind test. Its three variants (ResConvGRU, ResConvMUT and ResConvLSTM2) were trained with the same hyperparameters as ResConvLSTM.</p>
      <p>For tuning ST-LSTM networks, we trained two more models with the loss function equal to <inline-formula><tex-math notation="LaTeX" id="ImEquation68">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$MSE+0.1\times decouple$\end{document}</tex-math></inline-formula> [<xref rid="ref29" ref-type="bibr">29</xref>]. The further evaluation results for the model with the smallest MSE loss and the two more models are shown in <xref rid="sup1" ref-type="supplementary-material">Figure S5</xref>, indicating that adding decouple loss during training does not provide better performance. Therefore, the four-layer ST-LSTM model with the smallest MSE loss was selected for the blind test. Since SA-LSTM consumes high memory, we set a relatively small hidden dimension for the self-attention module (<xref rid="sup1" ref-type="supplementary-material">Table S9</xref>). The final SA-LSTM model that we used was the one that achieved the smallest validation loss.</p>
      <p>We also reported the MSE losses of two three-step ahead methods (SimVP and NaiveNet) in <xref rid="sup1" ref-type="supplementary-material">Table S9</xref>. It is obvious that their losses are larger than those of next-frame methods because the latter also consider the reconstruction errors of times <inline-formula><tex-math notation="LaTeX" id="ImEquation69">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{2}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation70">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{3}$\end{document}</tex-math></inline-formula>, which are usually smaller because spatiotemporal Hi-C at times <inline-formula><tex-math notation="LaTeX" id="ImEquation71">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{2}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation72">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{3}$\end{document}</tex-math></inline-formula> are easier to learn. Taken together, all the benchmarking models for the blind test were trained with the same batch size of 32 and the same hidden dimension of 128 (32 for ResConvLSTM and its three variants because of GPU memory limitation). In addition, we also borrowed the wide [<xref rid="ref45" ref-type="bibr">45</xref>] and dense [<xref rid="ref46" ref-type="bibr">46</xref>] concepts from convolutional neural networks onto ConvLSTMs but did not obtain a smaller validation loss (data and details not shown).</p>
    </sec>
    <sec id="sec3b">
      <title>Benchmarks on dataset 1</title>
      <p>The reproducibility results for the blind test on dataset 1 are shown in <xref rid="f2" ref-type="fig">Figure 2</xref>. Our newly designed ResConvLSTM often had significantly higher Pearson correlations in comparison with the other methods. The performance of SimVP became worse at the long-term time point (<inline-formula><tex-math notation="LaTeX" id="ImEquation73">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{6}$\end{document}</tex-math></inline-formula>). Moreover, ResConvLSTM mostly outperformed the other methods when the SCC scores for reproducibility were assessed. One exception is that SimVP achieved a bit higher SCC of 0.851 on chromosome 2 at time <inline-formula><tex-math notation="LaTeX" id="ImEquation74">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{4}$\end{document}</tex-math></inline-formula> compared with 0.849 of ResConvLSTM. As expected, NaiveNet consistently had the lowest correlations and SCCs. Based on the sum of all SCC scores, the top three methods were ResConvLSTM, ResConvLSTM2 and ConvLSTM (<xref rid="sup1" ref-type="supplementary-material">Table S10</xref>). Next, we checked the similarity levels of Hi-C contact matrices between different time-steps. For ground-truth Hi-C, we calculated SCC scores between each pair of all six time-steps (<xref rid="f2" ref-type="fig">Figure 2C</xref>). The small values in the upper left and lower right regions indicate that the three input time-steps are different from the three future time-steps. We also calculated SCC scores between each pair of the three predicted time-steps (<xref rid="f2" ref-type="fig">Figure 2D</xref>), suggesting that the two three-step-ahead methods can forecast more distinct matrices than the other next-frame methods.</p>
      <fig position="float" id="f2">
        <label>Figure 2</label>
        <caption>
          <p>Reproducibility results on dataset 1. (<bold>A</bold>) Boxplots of Pearson correlations between ground truth and predicted Hi-C contact matrices at each genomic distance by pooling data from the two testing chromosomes (2 and 6). For clarity, only the P-values between ResConvLSTM and each of the other four methods (NaiveNet, SimVP, SA-LSTM and ConvLSTM) were shown. P-values were computed using the paired Wilcoxon test. (<bold>B</bold>) SCC scores between ground truth and predicted Hi-C contact matrices from the nine methods. (<bold>C</bold>) SCC scores between ground-truth Hi-C matrices from each pair of the six time-steps for two testing chromosomes. (<bold>D</bold>) SCC scores between predicted Hi-C matrices from each pair of the three predicted time-steps.</p>
        </caption>
        <graphic xlink:href="bbad263f2" position="float"/>
      </fig>
      <p>The TAD-recovering results are shown in <xref rid="f3" ref-type="fig">Figures 3</xref>–<xref rid="f4" ref-type="fig">4</xref> and <xref rid="sup1" ref-type="supplementary-material">Figure S6</xref>. We first found that almost all predicted Hi-C contact matrices had very similar insulation scores with ground truth (<xref rid="sup1" ref-type="supplementary-material">Figure S6</xref>), and even NaiveNet achieved &gt;0.86 correlations at times <inline-formula><tex-math notation="LaTeX" id="ImEquation75">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{4}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation76">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{5}$\end{document}</tex-math></inline-formula>. We then called strong TAD boundaries on ground-truth Hi-C contact matrices using cooltools (<ext-link xlink:href="https://github.com/open2c/cooltools" ext-link-type="uri">https://github.com/open2c/cooltools</ext-link>), plotted average insulation scores around strong TAD boundaries (<xref rid="f3" ref-type="fig">Figure 3</xref>), and observed valleys/minima of average insulation scores calculated on the predicted Hi-C contact matrices from each of the five methods, especially for ResConvLSTM, indicating that these methods can successfully recover the strong TAD boundaries. Moreover, we showed some specific TAD-recovering examples at a genomic region in <xref rid="f4" ref-type="fig">Figure 4</xref> and <xref rid="sup1" ref-type="supplementary-material">Figure S7</xref>, revealing that our newly designed ResConvLSTM and the other methods can successfully recover TAD patterns that have not yet been fully established at the input time-steps.</p>
      <fig position="float" id="f3">
        <label>Figure 3</label>
        <caption>
          <p>TAD-recovering results on dataset 1. Valleys/minima of insulation scores from predicted Hi-C contact matrices around strong TAD boundaries that were called based on ground-truth Hi-C.</p>
        </caption>
        <graphic xlink:href="bbad263f3" position="float"/>
      </fig>
      <fig position="float" id="f4">
        <label>Figure 4</label>
        <caption>
          <p>TAD-recovering results on chromosome 6 for dataset 1. Hi-C heat maps and their insulation-score curves for ground truth and ResConvLSTM predictions at the three future time-steps (<inline-formula><tex-math notation="LaTeX" id="ImEquation77">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{4}$\end{document}</tex-math></inline-formula>, <inline-formula><tex-math notation="LaTeX" id="ImEquation78">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{5}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation79">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{6}$\end{document}</tex-math></inline-formula>).</p>
        </caption>
        <graphic xlink:href="bbad263f4" position="float"/>
      </fig>
      <p>In addition, we tested the effects of different numbers of input time-steps. Three more numbers of input time-steps (1, 2 and 4) are investigated, and the corresponding numbers of predicted time-steps are 5, 4 and 2, respectively. Four methods were retrained based on different numbers of input time-steps (details see <xref rid="sup1" ref-type="supplementary-material">supplementary materials</xref>), including NaiveNet, SimVP, ConvLSTM and ResConvLSTM. The evaluation results are shown in <xref rid="sup1" ref-type="supplementary-material">Figure S8</xref> for chromosome 2 and <xref rid="sup1" ref-type="supplementary-material">Figure S9</xref> for chromosome 6, indicating that for all of the four methods, more time-steps used for training results in better performance. We suggest using the first three time-steps as input if the SCC score of 0.7 is an acceptable accuracy threshold for all predicted Hi-C matrices. These results also indicate that if the SCC of 0.6 is acceptable, the upper limit of the number of the predicted time-steps can reach five when using one time-step as the input.</p>
    </sec>
    <sec id="sec3c">
      <title>Benchmarks on datasets 2 and 3</title>
      <p>It is worth noting that compared with the other datasets dataset 2 is more similar to dataset 1 because of the number of read pairs after downsampling, time-point ranking order and the fact that they are both from mouse embryogenesis. We report the reproducibility benchmarks in <xref rid="f5" ref-type="fig">Figure 5A</xref> and <xref rid="f5" ref-type="fig">B</xref> and TAD-recovering results in <xref rid="sup1" ref-type="supplementary-material">Figures S10–S12</xref>. At the first future time-step <inline-formula><tex-math notation="LaTeX" id="ImEquation80">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{4}$\end{document}</tex-math></inline-formula>, ResConvLSTM2 often had the highest correlations and SCCs. At time <inline-formula><tex-math notation="LaTeX" id="ImEquation81">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{5}$\end{document}</tex-math></inline-formula>, ResConvLSTM significantly outperforms the others. However, ConvLSTM performed best at time <inline-formula><tex-math notation="LaTeX" id="ImEquation82">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{6}$\end{document}</tex-math></inline-formula> and was closely followed by ST-LSTM and ResConvMUT. SimVP somehow performed worse even than NaiveNet at time <inline-formula><tex-math notation="LaTeX" id="ImEquation83">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{6}$\end{document}</tex-math></inline-formula>. The top three methods based on the sum of all SCC scores are ST-LSTM, ConvLSTM and ResConvMUT (<xref rid="sup1" ref-type="supplementary-material">Table S10</xref>). As we concluded for dataset 1, the TAD-recovering results (<xref rid="sup1" ref-type="supplementary-material">Figures S10–S12</xref>) for dataset 2 also indicated that the five methods can successfully recover TAD profiles even though our models were not trained on this dataset. Moreover, we generated SCC heat maps for ground truth (<xref rid="f5" ref-type="fig">Figure 5C</xref>) and predicted Hi-C matrices (<xref rid="f5" ref-type="fig">Figure 5D</xref>), suggesting that the first three time-steps are also markedly different from the last three and that next-frame methods are prone to generating a matrix that looks more like its previous prediction than the three-step ahead methods.</p>
      <fig position="float" id="f5">
        <label>Figure 5</label>
        <caption>
          <p>TAD-recovering results for dataset 2. (<bold>A</bold>) Boxplots of Pearson correlations for the two testing chromosomes (2 and 6). P-values were computed using the paired Wilcoxon test. (<bold>B</bold>) SCC scores between ground truth and predicted Hi-C contact matrices from the nine methods. (<bold>C</bold>) SCC scores between ground-truth Hi-C matrices from each pair of the six time-steps for two testing chromosomes. (<bold>D</bold>) SCC scores between predicted Hi-C matrices from each pair of the three predicted time-steps.</p>
        </caption>
        <graphic xlink:href="bbad263f5" position="float"/>
      </fig>
      <p>The third dataset contains 13 time-points, and we only used six of them for matching the time-steps of dataset 1. The main difference between dataset 3 and the first two datasets is that spatiotemporal Hi-C data were captured during SCNT embryo development in dataset 3, whereas it was mouse embryos for the first two datasets. The reproducibility benchmarks for dataset 3 are shown in <xref rid="sup1" ref-type="supplementary-material">Figure S13</xref>. In general, SA-LSTM and ResConvLSTM perform slightly better than the other methods, and the two three-step ahead methods perform noticeably worse than the next-frame methods. The three methods (SA-LSTM, ResConvLSTM and ResConvLSTM2) achieved the top three SCC scores (<xref rid="sup1" ref-type="supplementary-material">Table S10</xref>). The SCC heat maps (<xref rid="sup1" ref-type="supplementary-material">Figure S13C</xref> and <xref rid="sup1" ref-type="supplementary-material">S13D</xref>) are very similar to what we observed from the first two datasets.</p>
    </sec>
    <sec id="sec3d">
      <title>Performances on embryogenesis datasets from different species</title>
      <p>The spatiotemporal Hi-C data in the fourth dataset were captured during human embryo development, which help us assess our methods in a different species. The reproducibility results for two future time-steps (<inline-formula><tex-math notation="LaTeX" id="ImEquation84">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{4}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation85">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{5}$\end{document}</tex-math></inline-formula>) are shown in <xref rid="f6" ref-type="fig">Figure 6</xref>. At time <inline-formula><tex-math notation="LaTeX" id="ImEquation86">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{4}$\end{document}</tex-math></inline-formula>, the top three methods are the residual networks (ResConvLSTM, ResConvLSTM2 and ResConvGRU). At time <inline-formula><tex-math notation="LaTeX" id="ImEquation87">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{5}$\end{document}</tex-math></inline-formula>, ResConvGRU performs best followed by ResConvLSTM, whereas ConvLSTM and SimVP perform worse even than NaiveNet. The top three methods that achieve the highest sum of all SCCs are the three residual networks (<xref rid="sup1" ref-type="supplementary-material">Table S10</xref>), including ResConvGRU, ResConvLSTM and ResConvMUT. As we observed from the evaluation results for the first three datasets, it seems that SimVP cannot predict long-term Hi-C matrices as well as predicting short-term ones, whereas our method ResConvLSTM does not have this weakness. The SCC heat map for the ground-truth Hi-C is shown in <xref rid="sup1" ref-type="supplementary-material">Figure S14</xref>, indicating that the Hi-C matrices for each time-step are distinct from each other. In addition, we reported the running time and memory consumption for predicting dataset 4 in <xref rid="sup1" ref-type="supplementary-material">Figure S15</xref>. Residual networks usually took more time to make predictions, but still no more than five minutes for predicting one chromosome.</p>
      <fig position="float" id="f6">
        <label>Figure 6</label>
        <caption>
          <p>Reproducibility results for dataset 4. (<bold>A</bold>) Boxplots of Pearson correlations at each genomic distance. P-values were computed using the paired Wilcoxon test. (<bold>B</bold>) SCC scores between ground truth and predicted Hi-C contact matrices. P-values were computed using the paired t-test. Both correlation and SCC values were collected from all chromosomes.</p>
        </caption>
        <graphic xlink:href="bbad263f6" position="float"/>
      </fig>
      <p>Datasets 5 and 6 are from two different species (medaka and X. tropicalis). The SCC heat maps (<xref rid="sup1" ref-type="supplementary-material">Figure S16</xref> for dataset 5 and <xref rid="sup1" ref-type="supplementary-material">Figure S17</xref> for dataset 6) indicate that the three input time-steps are distinct from the last three time-steps, especially for dataset 6. The reproducibility results are shown in <xref rid="f7" ref-type="fig">Figure 7</xref> for dataset 5 and <xref rid="sup1" ref-type="supplementary-material">Figure S18</xref> for dataset 6. For dataset 5, ResConvLSTM performs best at times <inline-formula><tex-math notation="LaTeX" id="ImEquation88">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{4}$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math notation="LaTeX" id="ImEquation89">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{5}$\end{document}</tex-math></inline-formula>, while at time <inline-formula><tex-math notation="LaTeX" id="ImEquation90">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$t_{6}$\end{document}</tex-math></inline-formula> SA-LSTM outperforms the others. The top three methods based on the sum of all SCC values are ResConvLSTM, SA-LSTM and ST-LSTM (<xref rid="sup1" ref-type="supplementary-material">Table S10</xref>). For dataset 6, the best three with the highest sum of SCC scores are ResConvLSTM, ResConvLSTM2,and ConvLSTM (<xref rid="sup1" ref-type="supplementary-material">Table S10</xref>).</p>
      <fig position="float" id="f7">
        <label>Figure 7</label>
        <caption>
          <p>Reproducibility results for dataset 5. (<bold>A</bold>) Boxplots of Pearson correlations at each genomic distance. P-values were computed using the paired Wilcoxon test. (<bold>B</bold>) SCC scores between ground truth and predicted Hi-C contact matrices. P-values were computed using the paired t-test.</p>
        </caption>
        <graphic xlink:href="bbad263f7" position="float"/>
      </fig>
    </sec>
    <sec id="sec3e">
      <title>Performances on non-embryogenesis datasets</title>
      <p>The last two datasets (7 and 8) were selected to benchmark the nine methods on non-embryogenesis data. Since the spatiotemporal Hi-C from datasets 7 and 8 are not related to embryogenesis, we used all chromosomes for blind testing. The SCC heat maps are shown in <xref rid="sup1" ref-type="supplementary-material">Figure S19</xref> for dataset 7 and <xref rid="sup1" ref-type="supplementary-material">Figure S20</xref> for dataset 8, which indicate that the spatiotemporal Hi-C data from non-embryogenesis developments are more indistinguishable than those from embryogenesis. The evaluation results for the two datasets are shown in <xref rid="f8" ref-type="fig">Figure 8</xref> and <xref rid="sup1" ref-type="supplementary-material">Figure S21</xref>, respectively. The top two methods for both datasets are the same (ST-LSTM and ResConvLSTM) and the third method is ResConvMUT for dataset 7 and ResConvLSTM2 for dataset 8 (<xref rid="sup1" ref-type="supplementary-material">Table S10</xref>), suggesting that when predicting non-embryogenesis spatiotemporal Hi-C ST-LSTM and residual networks may be better choices.</p>
      <fig position="float" id="f8">
        <label>Figure 8</label>
        <caption>
          <p>Reproducibility benchmarks for dataset 7. (<bold>A</bold>) Boxplots of Pearson correlations at each genomic distance. P-values were computed using the paired Wilcoxon test. (<bold>B</bold>) SCC scores between ground truth and predicted Hi-C contact matrices. P-values were computed using the paired t-test.</p>
        </caption>
        <graphic xlink:href="bbad263f8" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec id="sec4">
    <title>DISCUSSION AND CONCLUSION</title>
    <p>In this paper, we present HiC4D for exploring the forecasting problem of spatiotemporal Hi-C data. We predicted the future three Hi-C frames from the previous three frames with nine different video-prediction methods. Specifically, we reimplemented three RNN methods (ConvLSTM, ST-LSTM and SA-LSTM), introduced a novel method (ResConvLSTM) together with its three variants (ResConvGRU, ResConvMUT and ResConvLSTM2) and used a state-of-the-art method (SimVP) and a NaiveNet as a baseline. These methods were trained with the same data and blindly tested on eight different spatiotemporal Hi-C datasets. Our benchmarks indicate that our newly designed method ResConvLSTM or its variants almost always outperforms the other methods across the eight datasets by achieving higher reproducibility scores. Our evaluation results also indicate that all methods can successfully recover TAD boundaries. Moreover, we show that models learned from one species can be used to forecasting the spatiotemporal Hi-C of another species. Together, HiC4D is an effective tool for accurately predicting spatiotemporal Hi-C data.</p>
    <boxed-text id="box01" position="float">
      <sec id="sec28a">
        <title>Key Points</title>
        <list list-type="bullet">
          <list-item>
            <p>A novel topic of forecasting spatiotemporal Hi-C with deep learning methods is introduced. To the best of our knowledge, this work is the first computational method to forecast spatiotemoral Hi-C data with deep learning methods.</p>
          </list-item>
          <list-item>
            <p>We present HiC4D, a newly designed method for accurately forecasting spatiotemporal Hi-C data. The method combines residual networks and convolutional long short-term memory (ConvLSTM) that makes ConvLSTM “deeper” (having more layers) and better learn the dependencies from the data.</p>
          </list-item>
          <list-item>
            <p>We benchmarked nine deep networks. Our evaluation results indicate that residual RNN networks almost always outperform the other methods on eight different spatiotemporal Hi-C datasets in terms of recovering Hi-C contacts and boundaries of TADs.</p>
          </list-item>
        </list>
      </sec>
    </boxed-text>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>HiC4D_suppl_2_bbad263</label>
      <media xlink:href="hic4d_suppl_2_bbad263.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec id="sec5a">
    <title>FUNDING</title>
    <p>Research reported in this publication was supported by the National Institute Of General Medical Sciences of the National Institutes of Health under Award Number R35GM137974 to ZW. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. The content does not necessarily represent the official views of the National Institutes of Health.</p>
  </sec>
  <sec sec-type="data-availability" id="sec5b">
    <title>DATA AVAILABILITY STATEMENT</title>
    <p>The source code of HiC4D can be found at both <ext-link xlink:href="http://dna.cs.miami.edu/HiC4D/" ext-link-type="uri">http://dna.cs.miami.edu/HiC4D/</ext-link> and <ext-link xlink:href="https://github.com/zwang-bioinformatics/HiC4D/" ext-link-type="uri">https://github.com/zwang-bioinformatics/HiC4D/</ext-link>. The data sources used in this paper are reported in the section “<xref rid="sec2" ref-type="sec">MATERIALS AND METHODS</xref>”. All of the datasets generated in this study are available upon request.</p>
  </sec>
  <notes id="bio3">
    <title>Author Biographies</title>
    <p><bold>Tong Liu</bold> is an Assistant Scientist in the Department of Computer Science at the University of Miami.</p>
    <sec sec-type="author-bio" id="sec22a">
      <p><bold>Zheng Wang</bold> is an Associate Professor in the Department of Computer Science, Department of Biology and Sylvester Comprehensive Cancer Center at the University of Miami.</p>
    </sec>
  </notes>
  <ref-list id="bib1">
    <title>REFERENCES</title>
    <ref id="ref1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lieberman-Aiden</surname>  <given-names>E</given-names></string-name>, <string-name><surname>van Berkum</surname>  <given-names>NL</given-names></string-name>, <string-name><surname>Williams</surname>  <given-names>L</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Comprehensive mapping of long-range interactions reveals folding principles of the human genome</article-title>. <source>Science</source>  <year>2009</year>;<volume>326</volume>(<issue>5950</issue>):<fpage>289</fpage>–<lpage>93</lpage>.<pub-id pub-id-type="pmid">19815776</pub-id></mixed-citation>
    </ref>
    <ref id="ref2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dixon</surname>  <given-names>JR</given-names></string-name>, <string-name><surname>Selvaraj</surname>  <given-names>S</given-names></string-name>, <string-name><surname>Yue</surname>  <given-names>F</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Topological domains in mammalian genomes identified by analysis of chromatin interactions</article-title>. <source>Nature</source>  <year>2012</year>;<volume>485</volume>(<issue>7398</issue>):<fpage>376</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">22495300</pub-id></mixed-citation>
    </ref>
    <ref id="ref3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rao</surname>  <given-names>SS</given-names></string-name>, <string-name><surname>Huntley</surname>  <given-names>MH</given-names></string-name>, <string-name><surname>Durand</surname>  <given-names>NC</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>A 3d map of the human genome at kilobase resolution reveals principles of chromatin looping</article-title>. <source>Cell</source>  <year>2014</year>;<volume>159</volume>(<issue>7</issue>):<fpage>1665</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">25497547</pub-id></mixed-citation>
    </ref>
    <ref id="ref4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nagano</surname>  <given-names>T</given-names></string-name>, <string-name><surname>Lubling</surname>  <given-names>Y</given-names></string-name>, <string-name><surname>Várnai</surname>  <given-names>C</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Cell-cycle dynamics of chromosomal organization at single-cell resolution</article-title>. <source>Nature</source>  <year>2017</year>;<volume>547</volume>(<issue>7661</issue>):<fpage>61</fpage>–<lpage>7</lpage>.<pub-id pub-id-type="pmid">28682332</pub-id></mixed-citation>
    </ref>
    <ref id="ref5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>  <given-names>YH</given-names></string-name>, <string-name><surname>Liu</surname>  <given-names>T</given-names></string-name>, <string-name><surname>Xu</surname>  <given-names>D</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Predicting dna methylation state of cpg dinucleotide using genome topological features and deep networks</article-title>. <source>Sci Rep</source>  <year>2016</year>;<volume>6</volume>:<fpage>19598</fpage>  <comment>Db7fv Times Cited:16 Cited References Count:65</comment>.<pub-id pub-id-type="pmid">26797014</pub-id></mixed-citation>
    </ref>
    <ref id="ref6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bonev</surname>  <given-names>B</given-names></string-name>, <string-name><surname>Cohen</surname>  <given-names>NM</given-names></string-name>, <string-name><surname>Szabo</surname>  <given-names>Q</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Multiscale 3d genome rewiring during mouse neural development</article-title>. <source>Cell</source>  <year>2017</year>;<volume>171</volume>(<issue>3</issue>): <fpage>557</fpage>, e24–<lpage>72</lpage>.<pub-id pub-id-type="pmid">29053968</pub-id></mixed-citation>
    </ref>
    <ref id="ref7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Engreitz</surname>  <given-names>JM</given-names></string-name>, <string-name><surname>Pandya-Jones</surname>  <given-names>A</given-names></string-name>, <string-name><surname>McDonel</surname>  <given-names>P</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>The xist lncrna exploits three-dimensional genome architecture to spread across the x chromosome</article-title>. <source>Science</source>  <year>2013</year>;<volume>341</volume>(<issue>6147</issue>): <fpage>1237973</fpage>.<pub-id pub-id-type="pmid">23828888</pub-id></mixed-citation>
    </ref>
    <ref id="ref8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dekker</surname>  <given-names>J</given-names></string-name>, <string-name><surname>Belmont</surname>  <given-names>AS</given-names></string-name>, <string-name><surname>Guttman</surname>  <given-names>M</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>The 4d nucleome project</article-title>. <source>Nature</source>  <year>2017</year>;<volume>549</volume>(<issue>7671</issue>): <fpage>219</fpage>.<pub-id pub-id-type="pmid">28905911</pub-id></mixed-citation>
    </ref>
    <ref id="ref9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname>  <given-names>Y</given-names></string-name>, <string-name><surname>Gerrard</surname>  <given-names>DL</given-names></string-name>, <string-name><surname>Wang</surname>  <given-names>J</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Temporal dynamic reorganization of 3d chromatin architecture in hormone-induced breast cancer and endocrine resistance</article-title>. <source>Nat Commun</source>  <year>2019</year>;<volume>10</volume>(<issue>1</issue>): <fpage>1</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">30602773</pub-id></mixed-citation>
    </ref>
    <ref id="ref10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mourad</surname>  <given-names>R</given-names></string-name>, <string-name><surname>Hsu</surname>  <given-names>P-Y</given-names></string-name>, <string-name><surname>Juan</surname>  <given-names>L</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Estrogen induces global reorganization of chromatin structure in human breast cancer cells</article-title>. <source>PloS One</source>  <year>2014</year>;<volume>9</volume>(<issue>12</issue>): <fpage>e113354</fpage>.<pub-id pub-id-type="pmid">25470140</pub-id></mixed-citation>
    </ref>
    <ref id="ref11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reed</surname>  <given-names>KS</given-names></string-name>, <string-name><surname>Davis</surname>  <given-names>ES</given-names></string-name>, <string-name><surname>Bond</surname>  <given-names>ML</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Temporal analysis suggests a reciprocal relationship between 3d chromatin structure and transcription</article-title>. <source>Cell Rep</source>  <year>2022</year>;<volume>41</volume>(<issue>5</issue>): <fpage>111567</fpage>.<pub-id pub-id-type="pmid">36323252</pub-id></mixed-citation>
    </ref>
    <ref id="ref12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bertero</surname>  <given-names>A</given-names></string-name>, <string-name><surname>Fields</surname>  <given-names>PA</given-names></string-name>, <string-name><surname>Ramani</surname>  <given-names>V</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Dynamics of genome reorganization during human cardiogenesis reveal an rbm20-dependent splicing factory</article-title>. <source>Nat Commun</source>  <year>2019</year>;<volume>10</volume>(<issue>1</issue>): <fpage>1</fpage>–<lpage>19</lpage>.<pub-id pub-id-type="pmid">30602773</pub-id></mixed-citation>
    </ref>
    <ref id="ref13">
      <label>13.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vilarrasa-Blasi</surname>  <given-names>R</given-names></string-name>, <string-name><surname>Soler-Vila</surname>  <given-names>P</given-names></string-name>, <string-name><surname>Verdaguer-Dot</surname>  <given-names>N</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Dynamics of genome architecture and chromatin function during human b cell differentiation and neoplastic transformation</article-title>. <source>Nat Commun</source>  <year>2021</year>;<volume>12</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>18</lpage>.<pub-id pub-id-type="pmid">33397941</pub-id></mixed-citation>
    </ref>
    <ref id="ref14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stadhouders</surname>  <given-names>R</given-names></string-name>, <string-name><surname>Vidal</surname>  <given-names>E</given-names></string-name>, <string-name><surname>Serra</surname>  <given-names>F</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Transcription factors orchestrate dynamic interplay between genome topology and gene regulation during cell reprogramming</article-title>. <source>Nat Genet</source>  <year>2018</year>;<volume>50</volume>(<issue>2</issue>):<fpage>238</fpage>–<lpage>49</lpage>.<pub-id pub-id-type="pmid">29335546</pub-id></mixed-citation>
    </ref>
    <ref id="ref15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Du</surname>  <given-names>Z</given-names></string-name>, <string-name><surname>Zheng</surname>  <given-names>H</given-names></string-name>, <string-name><surname>Huang</surname>  <given-names>B</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Allelic reprogramming of 3d chromatin architecture during early mammalian development</article-title>. <source>Nature</source>  <year>2017</year>;<volume>547</volume>(<issue>7662</issue>):<fpage>232</fpage>–<lpage>5</lpage>.<pub-id pub-id-type="pmid">28703188</pub-id></mixed-citation>
    </ref>
    <ref id="ref16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname>  <given-names>M</given-names></string-name>, <string-name><surname>Zhu</surname>  <given-names>Q</given-names></string-name>, <string-name><surname>Li</surname>  <given-names>C</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Chromatin architecture reorganization in murine somatic cell nuclear transfer embryos</article-title>. <source>Nat Commun</source>  <year>2020</year>;<volume>11</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>14</lpage>.<pub-id pub-id-type="pmid">31911652</pub-id></mixed-citation>
    </ref>
    <ref id="ref17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ke</surname>  <given-names>Y</given-names></string-name>, <string-name><surname>Xu</surname>  <given-names>Y</given-names></string-name>, <string-name><surname>Chen</surname>  <given-names>X</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>3d chromatin structures of mature gametes and structural reprogramming during mammalian embryogenesis</article-title>. <source>Cell</source>  <year>2017</year>;<volume>170</volume>(<issue>2</issue>): <fpage>367</fpage>, e20–<lpage>81</lpage>.<pub-id pub-id-type="pmid">28709003</pub-id></mixed-citation>
    </ref>
    <ref id="ref18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname>  <given-names>X</given-names></string-name>, <string-name><surname>Ke</surname>  <given-names>Y</given-names></string-name>, <string-name><surname>Wu</surname>  <given-names>K</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Key role for ctcf in establishing chromatin structure in human embryos</article-title>. <source>Nature</source>  <year>2019</year>;<volume>576</volume>(<issue>7786</issue>):<fpage>306</fpage>–<lpage>10</lpage>.<pub-id pub-id-type="pmid">31801998</pub-id></mixed-citation>
    </ref>
    <ref id="ref19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hug</surname>  <given-names>CB</given-names></string-name>, <string-name><surname>Grimaldi</surname>  <given-names>AG</given-names></string-name>, <string-name><surname>Kruse</surname>  <given-names>K</given-names></string-name>, <string-name><surname>Vaquerizas</surname>  <given-names>JM</given-names></string-name></person-group>. <article-title>Chromatin architecture emerges during zygotic genome activation independent of transcription</article-title>. <source>Cell</source>  <year>2017</year>;<volume>169</volume>(<issue>2</issue>): <fpage>216</fpage>, e19–<lpage>28</lpage>.<pub-id pub-id-type="pmid">28388407</pub-id></mixed-citation>
    </ref>
    <ref id="ref20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niu</surname>  <given-names>L</given-names></string-name>, <string-name><surname>Shen</surname>  <given-names>W</given-names></string-name>, <string-name><surname>Shi</surname>  <given-names>Z</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Three-dimensional folding dynamics of the xenopus tropicalis genome</article-title>. <source>Nat Genet</source>  <year>2021</year>;<volume>53</volume>(<issue>7</issue>): <fpage>1075</fpage>–<lpage>87</lpage>.<pub-id pub-id-type="pmid">34099928</pub-id></mixed-citation>
    </ref>
    <ref id="ref21">
      <label>21.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wike</surname>  <given-names>CL</given-names></string-name>, <string-name><surname>Guo</surname>  <given-names>Y</given-names></string-name>, <string-name><surname>Tan</surname>  <given-names>M</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Chromatin architecture transitions from zebrafish sperm through early embryogenesis</article-title>. <source>Genome Res</source>  <year>2021</year>;<volume>31</volume>(<issue>6</issue>):<fpage>981</fpage>–<lpage>94</lpage>.<pub-id pub-id-type="pmid">34006569</pub-id></mixed-citation>
    </ref>
    <ref id="ref22">
      <label>22.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>  <given-names>F</given-names></string-name>, <string-name><surname>Wang</surname>  <given-names>D</given-names></string-name>, <string-name><surname>Song</surname>  <given-names>R</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>The asynchronous establishment of chromatin 3d architecture between in vitro fertilized and uniparental preimplantation pig embryos</article-title>. <source>Genome Biol</source>  <year>2020</year>;<volume>21</volume>:<fpage>1</fpage>–<lpage>21</lpage>.</mixed-citation>
    </ref>
    <ref id="ref23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nakamura</surname>  <given-names>R</given-names></string-name>, <string-name><surname>Motai</surname>  <given-names>Y</given-names></string-name>, <string-name><surname>Kumagai</surname>  <given-names>M</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Ctcf looping is established during gastrulation in medaka embryos</article-title>. <source>Genome Res</source>  <year>2021</year>;<volume>31</volume>(<issue>6</issue>):<fpage>968</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">34006570</pub-id></mixed-citation>
    </ref>
    <ref id="ref24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hochreiter</surname>  <given-names>S</given-names></string-name>, <string-name><surname>Schmidhuber</surname>  <given-names>J</given-names></string-name></person-group>. <article-title>Long short-term memory</article-title>. <source>Neural Comput</source>  <year>1997</year>;<volume>9</volume>(<issue>8</issue>):<fpage>1735</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="ref25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cho</surname>  <given-names>K</given-names></string-name>, <string-name><surname>Van Merriënboer</surname>  <given-names>B</given-names></string-name>, <string-name><surname>Gulcehre</surname>  <given-names>C</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Learning phrase representations using rnn encoder-decoder for statistical machine translation</article-title>. <source>arXiv preprint arXiv:14061078</source>  <year>2014</year>.</mixed-citation>
    </ref>
    <ref id="ref26">
      <label>26.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>R.</given-names>  <surname>Jozefowicz</surname></string-name>, <string-name><given-names>W.</given-names>  <surname>Zaremba</surname></string-name>, <string-name><given-names>I.</given-names>  <surname>Sutskever</surname></string-name></person-group>. “<article-title>An empirical exploration of recurrent network architectures</article-title>.” In <source>International conference on machine learning</source>, pp. <fpage>2342</fpage>–<lpage>50</lpage>,
<publisher-name>PMLR</publisher-name>.</mixed-citation>
    </ref>
    <ref id="ref27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xingjian</surname>  <given-names>S</given-names></string-name>, <string-name><surname>Chen</surname>  <given-names>Z</given-names></string-name>, <string-name><surname>Wang</surname>  <given-names>H</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Convolutional lstm network: a machine learning approach for precipitation nowcasting</article-title>. <source>Adv Neural Inf Process Syst</source>  <fpage>802</fpage>–<lpage>10</lpage>.</mixed-citation>
    </ref>
    <ref id="ref28">
      <label>28.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>  <given-names>Y</given-names></string-name>, <string-name><surname>Long</surname>  <given-names>M</given-names></string-name>, <string-name><surname>Wang</surname>  <given-names>J</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Predrnn: recurrent neural networks for predictive learning using spatiotemporal lstms</article-title>. <source>Adv Neural Inf Process Syst</source>  <year>2017</year>;<volume>30</volume>.</mixed-citation>
    </ref>
    <ref id="ref29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>  <given-names>Y</given-names></string-name>, <string-name><surname>Wu</surname>  <given-names>H</given-names></string-name>, <string-name><surname>Zhang</surname>  <given-names>J</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Predrnn: a recurrent neural network for spatiotemporal predictive learning</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source>  <year>2022</year>.</mixed-citation>
    </ref>
    <ref id="ref30">
      <label>30.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Z.</given-names>  <surname>Lin</surname></string-name>, <string-name><given-names>M.</given-names>  <surname>Li</surname></string-name>, <string-name><given-names>Z.</given-names>  <surname>Zheng</surname></string-name>, <string-name><given-names>Y.</given-names>  <surname>Cheng</surname></string-name>, <string-name><given-names>C.</given-names>  <surname>Yuan</surname></string-name></person-group>. “<article-title>Self-attention convlstm for spatiotemporal prediction</article-title>.” In <source>Proceedings of the AAAI Conference on Artificial Intelligence</source>, vol. <volume>34</volume>, pp. <fpage>11531</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="ref31">
      <label>31.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Senior</surname>  <given-names>AW</given-names></string-name>, <string-name><surname>Evans</surname>  <given-names>R</given-names></string-name>, <string-name><surname>Jumper</surname>  <given-names>J</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Protein structure prediction using multiple deep neural networks in the 13th critical assessment of protein structure prediction (casp13)</article-title>. <source>Proteins: Structure, Function, and Bioinformatics</source>  <year>2019</year>;<volume>87</volume>(<issue>12</issue>):<fpage>1141</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="ref32">
      <label>32.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dsouza</surname>  <given-names>KB</given-names></string-name>, <string-name><surname>Maslova</surname>  <given-names>A</given-names></string-name>, <string-name><surname>Al-Jibury</surname>  <given-names>E</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Learning representations of chromatin contacts using a recurrent neural network identifies genomic drivers of conformation</article-title>. <source>Nat Commun</source>  <year>2022</year>;<volume>13</volume>(<issue>1</issue>): <fpage>1</fpage>–<lpage>19</lpage>.<pub-id pub-id-type="pmid">34983933</pub-id></mixed-citation>
    </ref>
    <ref id="ref33">
      <label>33.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>Z.</given-names>  <surname>Gao</surname></string-name>, <string-name><given-names>C.</given-names>  <surname>Tan</surname></string-name>, <string-name><given-names>L.</given-names>  <surname>Wu</surname></string-name>, <string-name><given-names>S. Z.</given-names>  <surname>Li</surname></string-name></person-group>. “<article-title>Simvp: Simpler yet better video prediction</article-title>.” In <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, pp. <fpage>3170</fpage>–<lpage>80</lpage>.</mixed-citation>
    </ref>
    <ref id="ref34">
      <label>34.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Highsmith</surname>  <given-names>M</given-names></string-name>, <string-name><surname>Cheng</surname>  <given-names>J</given-names></string-name></person-group>. <article-title>Four-dimensional chromosome structure prediction</article-title>. <source>Int J Mol Sci</source>  <year>2021</year>;<volume>22</volume>(<issue>18</issue>): <fpage>9785</fpage>.<pub-id pub-id-type="pmid">34575948</pub-id></mixed-citation>
    </ref>
    <ref id="ref35">
      <label>35.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>K.</given-names>  <surname>He</surname></string-name>, <string-name><given-names>X.</given-names>  <surname>Zhang</surname></string-name>, <string-name><given-names>S.</given-names>  <surname>Ren</surname></string-name>, <string-name><given-names>J.</given-names>  <surname>Sun</surname></string-name></person-group>. “<article-title>Deep residual learning for image recognition</article-title>.” In <source>Proceedings of the IEEE conference on computer vision and pattern recognition</source>, pp. <fpage>770</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="ref36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Durand</surname>  <given-names>NC</given-names></string-name>, <string-name><surname>Shamim</surname>  <given-names>MS</given-names></string-name>, <string-name><surname>Machol</surname>  <given-names>I</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Juicer provides a one-click system for analyzing loop-resolution hi-c experiments</article-title>. <source>Cell Syst</source>  <year>2016</year>;<volume>3</volume>(<issue>1</issue>):<fpage>95</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">27467249</pub-id></mixed-citation>
    </ref>
    <ref id="ref37">
      <label>37.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname>  <given-names>J</given-names></string-name>, <string-name><surname>El-Khamy</surname>  <given-names>M</given-names></string-name>, <string-name><surname>Lee</surname>  <given-names>J</given-names></string-name></person-group>. <article-title>Residual lstm: design of a deep recurrent architecture for distant speech recognition</article-title>. <source>arXiv preprint arXiv:170103360</source>  <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="ref38">
      <label>38.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>Y.</given-names>  <surname>Zhang</surname></string-name>, <string-name><given-names>W.</given-names>  <surname>Chan</surname></string-name>, <string-name><given-names>N.</given-names>  <surname>Jaitly</surname></string-name></person-group>. “<article-title>Very deep convolutional networks for end-to-end speech recognition</article-title>.” In <source>2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)</source>, pp. <fpage>4845</fpage>–<lpage>9</lpage>,
<publisher-name>IEEE</publisher-name>.</mixed-citation>
    </ref>
    <ref id="ref39">
      <label>39.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>  <given-names>T</given-names></string-name>, <string-name><surname>Wang</surname>  <given-names>Z</given-names></string-name></person-group>. <article-title>Hicnn2: enhancing the resolution of hi-c data using an ensemble of convolutional neural networks</article-title>. <source>Genes</source>  <year>2019</year>;<volume>10</volume>(<issue>11</issue>): <fpage>862</fpage>.<pub-id pub-id-type="pmid">31671634</pub-id></mixed-citation>
    </ref>
    <ref id="ref40">
      <label>40.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>Y.</given-names>  <surname>Wu</surname></string-name>, <string-name><given-names>K.</given-names>  <surname>He</surname></string-name></person-group>. “<article-title>Group normalization</article-title>.” In <source>Proceedings of the European conference on computer vision (ECCV)</source>, pp. <fpage>3</fpage>–<lpage>19</lpage>.</mixed-citation>
    </ref>
    <ref id="ref41">
      <label>41.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>A.</given-names>  <surname>Paszke</surname></string-name>, <string-name><given-names>S.</given-names>  <surname>Gross</surname></string-name>, <string-name><given-names>F.</given-names>  <surname>Massa</surname></string-name>, <string-name><given-names>A.</given-names>  <surname>Lerer</surname></string-name>, <string-name><given-names>J.</given-names>  <surname>Bradbury</surname></string-name>, <string-name><given-names>G.</given-names>  <surname>Chanan</surname></string-name>, <string-name><given-names>T.</given-names>  <surname>Killeen</surname></string-name>, <string-name><given-names>Z.</given-names>  <surname>Lin</surname></string-name>, <string-name><given-names>N.</given-names>  <surname>Gimelshein</surname></string-name>, <string-name><given-names>L.</given-names>  <surname>Antiga</surname></string-name></person-group>. “<article-title>Pytorch: an imperative style, high-performance deep learning library</article-title>,” <source>Adv Neural Inf Process Syst</source>, pp. <fpage>8026</fpage>–<lpage>37</lpage>.</mixed-citation>
    </ref>
    <ref id="ref42">
      <label>42.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kingma</surname>  <given-names>DP</given-names></string-name>, <string-name><surname>Ba</surname>  <given-names>J</given-names></string-name></person-group>. <article-title>Adam: a method for stochastic optimization</article-title>. <source>arXiv preprint arXiv:14126980</source>  <year>2014</year>.</mixed-citation>
    </ref>
    <ref id="ref43">
      <label>43.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname>  <given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname>  <given-names>F</given-names></string-name>, <string-name><surname>Yardimci</surname>  <given-names>GG</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Hicrep: assessing the reproducibility of hi-c data using a stratum-adjusted correlation coefficient</article-title>. <source>Genome Res</source>  <year>2017</year>;<volume>27</volume>(<issue>11</issue>):<fpage>1939</fpage>–<lpage>49</lpage>.<pub-id pub-id-type="pmid">28855260</pub-id></mixed-citation>
    </ref>
    <ref id="ref44">
      <label>44.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Crane</surname>  <given-names>E</given-names></string-name>, <string-name><surname>Bian</surname>  <given-names>Q</given-names></string-name>, <string-name><surname>McCord</surname>  <given-names>RP</given-names></string-name>, <etal>et al</etal>.</person-group>  <article-title>Condensin-driven remodelling of x chromosome topology during dosage compensation</article-title>. <source>Nature</source>  <year>2015</year>;<volume>523</volume>(<issue>7559</issue>): <fpage>240</fpage>.<pub-id pub-id-type="pmid">26030525</pub-id></mixed-citation>
    </ref>
    <ref id="ref45">
      <label>45.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>C.</given-names>  <surname>Szegedy</surname></string-name>, <string-name><given-names>W.</given-names>  <surname>Liu</surname></string-name>, <string-name><given-names>Y.</given-names>  <surname>Jia</surname></string-name>, <string-name><given-names>P.</given-names>  <surname>Sermanet</surname></string-name>, <string-name><given-names>S.</given-names>  <surname>Reed</surname></string-name>, <string-name><given-names>D.</given-names>  <surname>Anguelov</surname></string-name>, <string-name><given-names>D.</given-names>  <surname>Erhan</surname></string-name>, <string-name><given-names>V.</given-names>  <surname>Vanhoucke</surname></string-name>, <string-name><given-names>A.</given-names>  <surname>Rabinovich</surname></string-name></person-group>. “<article-title>Going deeper with convolutions</article-title>.” In <source>Proceedings of the IEEE conference on computer vision and pattern recognition</source>, pp. <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="ref46">
      <label>46.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>G.</given-names>  <surname>Huang</surname></string-name>, <string-name><given-names>Z.</given-names>  <surname>Liu</surname></string-name>, <string-name><given-names>L.</given-names>  <surname>Van Der Maaten</surname></string-name>, <string-name><given-names>K. Q.</given-names>  <surname>Weinberger</surname></string-name></person-group>, “<article-title>Densely connected convolutional networks</article-title>.” In <source>Proceedings of the IEEE conference on computer vision and pattern recognition</source>, pp. <fpage>4700</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
