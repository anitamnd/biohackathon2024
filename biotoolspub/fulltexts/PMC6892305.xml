<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Database (Oxford)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Database (Oxford)</journal-id>
    <journal-id journal-id-type="publisher-id">databa</journal-id>
    <journal-title-group>
      <journal-title>Database: The Journal of Biological Databases and Curation</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-0463</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6892305</article-id>
    <article-id pub-id-type="doi">10.1093/database/baz116</article-id>
    <article-id pub-id-type="publisher-id">baz116</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A general approach for improving deep learning-based medical relation extraction using a pre-trained model and fine-tuning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Tao</given-names>
        </name>
        <xref ref-type="aff" rid="aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Wu</surname>
          <given-names>Mingfen</given-names>
        </name>
        <xref ref-type="aff" rid="aff1"/>
        <xref rid="cor1" ref-type="corresp"/>
        <!--<email>mfwu@sina.com</email>-->
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Li</surname>
          <given-names>Hexi</given-names>
        </name>
        <xref ref-type="aff" rid="aff1"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><institution>Department of Computer Science and Engineering, Faculty of Intelligent Manufacturing, Wuyi University</institution>, No.22, Dongcheng village, Pengjiang district, Jiangmen City,
Guangdong Province, 529020, <country country="CN">China</country></aff>
    <author-notes>
      <corresp id="cor1">Corresponding author: Tel: +86 189 3318 3773; Fax: 086-0750-3299730; Email: <email>mfwu@sina.com</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-12-04">
      <day>04</day>
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>04</day>
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>2019</volume>
    <elocation-id>baz116</elocation-id>
    <history>
      <date date-type="received">
        <day>24</day>
        <month>3</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>16</day>
        <month>7</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>2</day>
        <month>9</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Â© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="baz116.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>The automatic extraction of meaningful relations from biomedical literature or clinical records is crucial in various biomedical applications. Most of the current deep learning approaches for medical relation extraction require large-scale training data to prevent overfitting of the training model. We propose using a pre-trained model and a fine-tuning technique to improve these approaches without additional time-consuming human labeling. Firstly, we show the architecture of Bidirectional Encoder Representations from Transformers (BERT), an approach for pre-training a model on large-scale unstructured text. We then combine BERT with a one-dimensional convolutional neural network (1d-CNN) to fine-tune the pre-trained model for relation extraction. Extensive experiments on three datasets, namely the BioCreative V chemical disease relation corpus, traditional Chinese medicine literature corpus and i2b2 2012 temporal relation challenge corpus, show that the proposed approach achieves state-of-the-art results (giving a relative improvement of 22.2, 7.77, and 38.5% in F1 score, respectively, compared with a traditional 1d-CNN classifier). The source code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/chentao1999/MedicalRelationExtraction">https://github.com/chentao1999/MedicalRelationExtraction</ext-link>.</p>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Guangdong Provincial Education Department</named-content>
        </funding-source>
        <award-id>2014KZDXM055</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Guangdong Natural Science Foundation</named-content>
          <named-content content-type="funder-identifier">10.13039/501100003453</named-content>
        </funding-source>
        <award-id>2016A070708002</award-id>
        <award-id>2016A030313003</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Graduate Education Innovation</named-content>
        </funding-source>
        <award-id>2016SFKC_42</award-id>
        <award-id>YJS-SFKC-14-05</award-id>
        <award-id>YJS-PYJD-17-03</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Integration of cloud computing and big data innovation project</named-content>
        </funding-source>
        <award-id>2017B02101</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Jiangmen foundation and theoretical science research project</named-content>
        </funding-source>
        <award-id>2018JC01003</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="15"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Introduction</title>
    <p>Medical relations, such as chemical disease relations (CDRs) and chemical protein relations in modern medicine, herb-syndrome relations and formula-disease relations in traditional medicine, play a key role in a number of biomedical-related applications, e.g. clinical decision-making, drug discovery and drug side-effect detection. Manually extracting these relations is difficult and time-consuming. With recent rapid increases in the scale of biomedical texts and literature, the automatic extraction of meaningful medical relations has received increasing attention over the past decade (<xref rid="ref1" ref-type="bibr">1)</xref>. Relation extraction is usually considered as a classification problem. Three kinds of approaches have been applied to extract medical relations: rule-based approaches (<xref rid="ref2" ref-type="bibr">2</xref>, <xref rid="ref3" ref-type="bibr">3)</xref>, shallow machine learning approaches (<xref rid="ref4" ref-type="bibr">4</xref>, <xref rid="ref5" ref-type="bibr">5)</xref> and deep learning approaches (<xref rid="ref1" ref-type="bibr">1</xref>, <xref rid="ref6" ref-type="bibr">6)</xref>.</p>
    <p>Rule-based approaches require domain experts to define heuristic rules to target a special task (<xref rid="ref7" ref-type="bibr">7)</xref>. Shallow machine learning approaches consider medical relation extraction as a classification problem and generally use supervised learning and feature engineering to obtain high performance. These approaches require manually constructed features or rules. Deep learning approaches use neural networks to automatically capture the syntactic and semantic features of the text without feature engineering. Among current deep learning approaches, convolutional neural networks (CNNs) are one of the key drivers of improvements (<xref rid="ref8" ref-type="bibr">8)</xref>.</p>
    <p>However, most deep learning approaches for medical relation extraction are supervised and thus require large-scale training data to prevent overfitting of the training model. Typically, at least 5000 labeled data per category are needed for acceptable performance, and more than 10 million are required to match or exceed human performance (<xref rid="ref9" ref-type="bibr">9)</xref>. Although many medical relation extraction corpora have been created over recent years, most of them are too small to train a deep neural network, especially to train the neural networks which have achieved success in the computer vision or natural language processing (NLP) domains. Munkhdalai <italic>etÂ al.</italic> (<xref rid="ref10" ref-type="bibr">10)</xref> compared shallow machine learning approaches with deep learning approaches for clinical relation identification, and found that the shallow form remains advantageous over deep learning for clinical relation identification, although deep learning models demonstrate the potential for significant improvement if more training data were available. Huynh <italic>etÂ al.</italic> (<xref rid="ref11" ref-type="bibr">11)</xref> concluded that more complex CNN variants, such as convolutional recurrent neural networks and CNNs with attention, perform worse than traditional CNNs. We think this is because the corpus they used only contained several thousand labeled training data, and complex models are more likely to cause overfitting with such limited datasets.</p>
    <p>Though it is expensive to collect large amounts of training data for the medical domain, a large number of unstructured clinical records or biomedical texts and literature are created every day. Wang and Fan (<xref rid="ref12" ref-type="bibr">12)</xref> proposed the integration of unlabeled data to help solve the overfitting problems that occur when there are insufficient labeled data. Many methods have been developed to take advantage of unstructured data, such as training domain-specific word embeddings, transfer learning and fine-tuning of pre-trained models. Model pre-training and fine-tuning take a model that has already been trained for a given task and applies it to a second, similar task. This takes advantage of the features extracted on the first task without training from scratch on the second task. Thus, it is a kind of inductive transfer learning (<xref rid="ref13" ref-type="bibr">13)</xref>, which was initially used on a large scale in the field of computer vision (<xref rid="ref14" ref-type="bibr">14â16)</xref>. In text mining or NLP, typical pre-training approaches include Embeddings from Language Models (ELMo) (<xref rid="ref17" ref-type="bibr">17)</xref>, Universal Language Model Fine-tuning (ULMFiT) (<xref rid="ref13" ref-type="bibr">13)</xref>, Bidirectional Encoder Representations from Transformers (BERT) (<xref rid="ref18" ref-type="bibr">18)</xref>, OpenAI Generative Pre-training Transformer (GPT) (<xref rid="ref19" ref-type="bibr">19)</xref> and GPT-2 (<xref rid="ref20" ref-type="bibr">20)</xref>.</p>
    <p>In this paper, we focus on pre-training models from unstructured text and fine-tuning the pre-trained models to improve the performance of existing deep learning-based medical relation extraction approaches with limited training data. First, we show the architecture of BERT, which is a novel and effective approach for pre-training models on large-scale unstructured text. Then, we use a one-dimensional convolutional neural network (1d-CNN) to fine-tune the pre-trained BERT model for medical relation extraction. To evaluate our approach, extensive experiments are conducted on three kinds of real-world medical relation extraction datasets in different languages: the BioCreative V CDR corpus (<xref rid="ref21" ref-type="bibr">21â24)</xref>, traditional Chinese medicine (TCM) literature corpus (<xref rid="ref25" ref-type="bibr">25)</xref>, and i2b2 2012 temporal relations challenge corpus (<xref rid="ref26" ref-type="bibr">26</xref>, <xref rid="ref27" ref-type="bibr">27)</xref>. The proposed approach achieves state-of-the-art results on all three datasets (giving a relative improvement of 22.2, 7.77 and 38.5% in F1 score, respectively, compared with a traditional 1d-CNN classifier). To the best of our knowledge, this is the first general-purpose approach to achieve state-of-the-art performance in all three medical relation extraction tasks. The results can be used in applications including chemical-disease interactions research, poly-pharmacology research and adjuvant clinical treatment. The source code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/chentao1999/MedicalRelationExtraction">https://github.com/chentao1999/MedicalRelationExtraction</ext-link>. We have made a web service of our system available at <ext-link ext-link-type="uri" xlink:href="http://120.78.238.14:8080/cdr">http://120.78.238.14:8080/cdr</ext-link>.</p>
  </sec>
  <sec id="sec2">
    <title>Materials and methods</title>
    <sec id="sec3">
      <title>Data sources</title>
      <p>The proposed method is a general-purpose approach. In this work, we utilize three different kinds of medical relation extraction corpora:
<list list-type="order"><list-item><p>BioCreative V CDR task corpus (in short, BC5CDR corpus) (<xref rid="ref21" ref-type="bibr">21â24)</xref>: this consists of 1500 PubMed articles with 4409 annotated chemicals, 5818 diseases and 3116 chemical-disease interactions. <xref rid="f1" ref-type="fig">Figure 1</xref> shows a PubTator format (tab-delimited format) file for the article (PMID: 19803309) in the training set of the corpus. A summary of this corpus is presented in <xref rid="TB1" ref-type="table">Table 1</xref>. The relation task data are publicly available through BioCreative V at <ext-link ext-link-type="uri" xlink:href="https://biocreative.bioinformatics.udel.edu/resources/corpora/biocreative-v-cdr-corpus/">https://biocreative.bioinformatics.udel.edu/resources/corpora/biocreative-v-cdr-corpus/</ext-link>.</p></list-item><list-item><p>TCM literature corpus (in short, TCM corpus) (<xref rid="ref25" ref-type="bibr">25)</xref>: the abstracts of all 106,150 papers published in the 114 most popular Chinese TCM journals from 2011 to 2016 are collected, including details of 3024 herbs, 4957 formulae, 1126 syndromes and 1650 diseases. Five types of relations are annotated. <xref rid="f2" ref-type="fig">Figure 2</xref> gives an example of TCM literature and relations in the corpus. The statistics of the corpus are summarized in <xref rid="TB2" ref-type="table">Table 2</xref>. The negative relations are for co-occurring entities that do not have an explicit relation. The unlabeled relations are for co-occurring entities that their relations are not annotated by TCM experts. Only 10% of the candidate relations are annotated. The entire dataset is available online at <ext-link ext-link-type="uri" xlink:href="http://arnetminer.org/TCMRelExtr">http://arnetminer.org/TCMRelExtr</ext-link>.</p></list-item><list-item><p>The 2012 informatics for integrating biology and the bedside (i2b2) project temporal relations challenge corpus (in short, i2b2 temporal corpus) (<xref rid="ref26" ref-type="bibr">26</xref>, <xref rid="ref27" ref-type="bibr">27)</xref>: This contains 310 de-identified discharge summaries of over 178,000 tokens, with annotations of clinically significant events, temporal expressions and temporal relations in clinical narratives. On average, each discharge summary in the corpus contains 86.6 events, 12.4 temporal expressions and 176 raw temporal relations. In this corpus, eight kinds of temporal relations between events and temporal expressions are defined: BEFORE, AFTER, SIMULTANEOUS, OVERLAP, BEGUN_BY, ENDED_BY, DURING and BEFORE_OVERLAP. <xref rid="f3" ref-type="fig">Figure 3</xref> shows an excerpt of a patient report and its annotation of events, temporal expressions and temporal relations in the training set of the corpus. We present the details of this corpus in <xref rid="TB3" ref-type="table">Table 3</xref>. The annotations are available at <ext-link ext-link-type="uri" xlink:href="http://i2b2.org/NLP/DataSets">http://i2b2.org/NLP/DataSets</ext-link>.</p></list-item></list></p>
      <fig id="f1" orientation="portrait" position="float">
        <label>Figure 1</label>
        <caption>
          <p>An example of the BC5CDR corpus (PubTator format, PMID:19803309).</p>
        </caption>
        <graphic xlink:href="baz116f1"/>
      </fig>
      <table-wrap id="TB1" orientation="portrait" position="float">
        <label>Table 1</label>
        <caption>
          <p>Summary of the BioCreative V CDR corpus</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="center" span="1"/>
            <col align="center" span="1"/>
            <col align="center" span="1"/>
            <col align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Dataset</th>
              <th align="center" rowspan="1" colspan="1">Articles</th>
              <th align="center" rowspan="1" colspan="1">Chemical mention (ID)</th>
              <th align="center" rowspan="1" colspan="1">Disease mention (ID)</th>
              <th align="center" rowspan="1" colspan="1">CID relation</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Training</td>
              <td rowspan="1" colspan="1">500</td>
              <td rowspan="1" colspan="1">5203 (1467)</td>
              <td rowspan="1" colspan="1">4182 (1965)</td>
              <td rowspan="1" colspan="1">1038</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Dev</td>
              <td rowspan="1" colspan="1">500</td>
              <td rowspan="1" colspan="1">5347 (1507)</td>
              <td rowspan="1" colspan="1">4244 (1865)</td>
              <td rowspan="1" colspan="1">1012</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Test</td>
              <td rowspan="1" colspan="1">500</td>
              <td rowspan="1" colspan="1">5385 (1435)</td>
              <td rowspan="1" colspan="1">4424 (1988)</td>
              <td rowspan="1" colspan="1">1066</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <fig id="f2" orientation="portrait" position="float">
        <label>Figure 2</label>
        <caption>
          <p>An example of the TCM corpus.</p>
        </caption>
        <graphic xlink:href="baz116f2"/>
      </fig>
      <fig id="f3" orientation="portrait" position="float">
        <label>Figure 3</label>
        <caption>
          <p>Sample text excerpt of the i2b2 temporal corpus.</p>
        </caption>
        <graphic xlink:href="baz116f3"/>
      </fig>
      <p>From the above tables, it is clear that BC5CDR and the TCM corpus are annotated with two categories, and there are hundreds of labeled data per category. The i2b2 temporal corpus is much larger. There are 33,635 annotated samples across eight kinds of temporal relations, an average of 4204.4 labeled data per category. None of these corpora is large enough (&lt;5000 labeled data per category) to train a deep neural network for acceptable performance.</p>
    </sec>
    <sec id="sec4">
      <title>Overview of our approach</title>
      <p>An overview of our approach for improving deep learning-based medical relation extraction using a pre-trained model and model fine-tuning is shown in <xref rid="f4" ref-type="fig">Figure 4</xref>. The left sub-figure (<xref rid="f4" ref-type="fig">Figure 4a</xref>) shows the architecture of the traditional approach using a 1d-CNN model to classify medical relations. The word embeddings and pre-processed medical relation extraction corpus are the input of the 1d-CNN model. The word embeddings are real number vector representations of words or phrases from the vocabulary. It is usually trained from large-scale unstructured biomedical text, literature or clinical records for medical relation extraction.</p>
      <fig id="f4" orientation="portrait" position="float">
        <label>Figure 4</label>
        <caption>
          <p>The architecture of the traditional approach and our proposed approach.</p>
        </caption>
        <graphic xlink:href="baz116f4"/>
      </fig>
      <p>The right sub-figure (<xref rid="f4" ref-type="fig">Figure 4b</xref>) is the architecture of our proposed approach. âPre-trained Modelâ refers to binary checkpoint files in which the neural network architecture, weights and variables are stored. âBERTâ refers to a kind of pre-training approach. Before fine-turning begins, âBERTâ restores its variables and neural network parameters by loading the âPre-trained Modelâ files. After BERT loads the pre-trained model, fine-tuning begins. The training error back-propagates to BERT to fine-tune its parameters, which are firstly restored from the pre-trained model. Our approach also uses a 1d-CNN model to classify medical relations. The main differences between our proposed approach and the traditional approach are:
<list list-type="order"><list-item><p>We use a pre-trained model instead of word embeddings as the input of the 1d-CNN model.</p></list-item><list-item><p>We combine the 1d-CNN with BERT and use the 1d-CNN to fine-tune the parameters of the BERT model. The operations in the dashed rectangle, such as pre-processing and post-processing, are optional in our experiments. Our proposed approach is an end-to-end general-purpose. We didnât perform pre-processing and post-processing in all three experiments. Experimental results show that our approach achieves state-of-the-art performance even without pre-processing the corpus and post-processing the results. Other researchers who use our method can add pre-processing and post-processing for a special corpus to further improve performance.</p></list-item><list-item><p>The model fine-tuning process is realized by back-propagating the training error of the 1d-CNN to the BERT model. This is a dynamic model training process. Traditional approaches that concatenate embeddings with the input at different layers still train the main task model from scratch and treat pre-trained embeddings as fixed parameters, limiting their usefulness (<xref rid="ref13" ref-type="bibr">13)</xref>.</p></list-item></list></p>
      <p>The following sections describe the pre-trained model and our approach in detail and explain how to use the 1d-CNN to fine-tune the pre-trained BERT model for medical relation extraction.</p>
      <table-wrap id="TB2" orientation="portrait" position="float">
        <label>Table 2</label>
        <caption>
          <p>Summary of the TCM corpus</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="center" span="1"/>
            <col align="center" span="1"/>
            <col align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="2" align="left" colspan="1">Relation type</th>
              <th colspan="2" align="center" rowspan="1">Labeled relations</th>
              <th rowspan="2" align="center" colspan="1">Unlabeled relations</th>
            </tr>
            <tr>
              <th align="center" rowspan="1" colspan="1">Positive</th>
              <th align="center" rowspan="1" colspan="1">Negative</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Herb-syndrome</td>
              <td rowspan="1" colspan="1">538</td>
              <td rowspan="1" colspan="1">582</td>
              <td rowspan="1" colspan="1">10â077</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Herb-disease</td>
              <td rowspan="1" colspan="1">534</td>
              <td rowspan="1" colspan="1">642</td>
              <td rowspan="1" colspan="1">10â579</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Formula-syndrome</td>
              <td rowspan="1" colspan="1">392</td>
              <td rowspan="1" colspan="1">574</td>
              <td rowspan="1" colspan="1">8693</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Formula-disease</td>
              <td rowspan="1" colspan="1">377</td>
              <td rowspan="1" colspan="1">411</td>
              <td rowspan="1" colspan="1">7094</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Syndrome-disease</td>
              <td rowspan="1" colspan="1">431</td>
              <td rowspan="1" colspan="1">532</td>
              <td rowspan="1" colspan="1">8681</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <sec id="sec5">
      <title>Pre-trained model</title>
      <p>Most supervised learning approaches on task-specific datasets are brittle and sensitive to slight changes in the data distribution (<xref rid="ref28" ref-type="bibr">28)</xref> and task specification (<xref rid="ref29" ref-type="bibr">29)</xref>. Pre-trained models are usually trained by a pre-training approach in an unsupervised way on large-scale unstructured general-domain text (like Wikipedia) on GPU cluster or cloud TPUs for several days. They are general systems that can be used as components in many downstream tasks.</p>
      <table-wrap id="TB3" orientation="portrait" position="float">
        <label>Table 3</label>
        <caption>
          <p>Summary of the i2b2 temporal relation corpus</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="center" span="1"/>
            <col align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th align="center" rowspan="1" colspan="1">Training set</th>
              <th align="center" rowspan="1" colspan="1">Test set</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Discharge summaries</td>
              <td rowspan="1" colspan="1">190</td>
              <td rowspan="1" colspan="1">120</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Events</td>
              <td rowspan="1" colspan="1">16,468</td>
              <td rowspan="1" colspan="1">13,594</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Temporal expressions</td>
              <td rowspan="1" colspan="1">2,366</td>
              <td rowspan="1" colspan="1">1,820</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Temporal relations</td>
              <td rowspan="1" colspan="1">33,635</td>
              <td rowspan="1" colspan="1">27,736</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">âBEFORE</td>
              <td rowspan="1" colspan="1">13,467</td>
              <td rowspan="1" colspan="1">10,789</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">âAFTER</td>
              <td rowspan="1" colspan="1">2,211</td>
              <td rowspan="1" colspan="1">1,941</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">âSIMULTANEOUS</td>
              <td rowspan="1" colspan="1">4,725</td>
              <td rowspan="1" colspan="1">4,142</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">âOVERLAP</td>
              <td rowspan="1" colspan="1">7,061</td>
              <td rowspan="1" colspan="1">4,877</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">âBEGUN_BY</td>
              <td rowspan="1" colspan="1">996</td>
              <td rowspan="1" colspan="1">788</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">âENDED_BY</td>
              <td rowspan="1" colspan="1">797</td>
              <td rowspan="1" colspan="1">688</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">âDURING</td>
              <td rowspan="1" colspan="1">1,037</td>
              <td rowspan="1" colspan="1">875</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">âBEFORE_OVERLAP</td>
              <td rowspan="1" colspan="1">3,249</td>
              <td rowspan="1" colspan="1">3,636</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">âUnlabeled</td>
              <td rowspan="1" colspan="1">92</td>
              <td rowspan="1" colspan="1">0</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>As mentioned above, typical pre-training approaches include ELMo, ULMFiT, GPT, GPT-2 and BERT. ELMo uses a bidirectional long short-term memory (LSTM) to pre-train a bidirectional language model (biLM) on a large text corpus. Once pre-trained, the biLM can compute representations for downstream tasks (<xref rid="ref17" ref-type="bibr">17)</xref>. ULMFiT uses a three-layer LSTM architecture to pre-train an ImageNet-like language model and uses a discriminative fine-tuning technique to allow different layers to capture different types of information (<xref rid="ref13" ref-type="bibr">13)</xref>. GPT (<xref rid="ref19" ref-type="bibr">19)</xref> uses a left-to-right architecture, where every token can only attend to previous tokens in the self-attention layers of the transformer (<xref rid="ref30" ref-type="bibr">30)</xref>. GPT-2 largely follows the details of the GPT model, but has over an order of magnitude more parameters than the original GPT (<xref rid="ref20" ref-type="bibr">20)</xref>. BERT uses a deep bidirectional transformer that is jointly conditioned on both the left and right contexts in all layers to pre-train masked language models (<xref rid="ref18" ref-type="bibr">18)</xref>.</p>
      <p>In this work, we use BERT as our pre-training approach because (i) it achieves better performance than most other pre-training approaches (ELMo, OpenAI GPT, etc.) in many NLP tasks (<xref rid="ref18" ref-type="bibr">18)</xref> and (ii) it is open source. Pre-training is fairly expensive. Several pre-trained BERT models are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/google-research/bert">https://github.com/google-research/bert</ext-link>. We will never need to pre-train our own model from scratch.</p>
      <p>An illustration of the architecture of BERT is shown in Figure 6. BERT uses WordPieces (<xref rid="ref31" ref-type="bibr">31)</xref> as tokens rather than words. Consider the following example sentence pair:</p>
      <p><bold>Example 1:</bold> suxamethonium<sub>[D013390]</sub> masseter spasm<sub>[D014313]</sub> a dose-response study<italic>.</italic></p>
      <p>This is broken down into smaller chunks, as shown in the Token Embeddings line in <xref rid="f5" ref-type="fig">Figure 5</xref>. â##â refers to the split word pieces. For example, suxamethonium is split into five tokens: su, ##xa, ##met, ##hon and ##ium. In the Token Embeddings, [CLS] refers to a special classification embedding. [SEP] refers to the end of a sentence. In the Segment Embeddings, A (in red) refers to the first sentence of the sentence pair and B (in blue) refers to the second sentence of the sentence pair. The Position Embeddings refers to the serial number of tokens in the sentence pair sequence. The input embeddings are constructed by summing the values of the corresponding token, segment and position embeddings (<xref rid="ref18" ref-type="bibr">18)</xref>. The i-th value of the input embedding is computed as follows:<disp-formula id="deqn01"><label>(1)</label><tex-math id="M1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} {v}_{input}^{(i)}={v}_{token}^{(i)}+{v}_{segment}^{(i)}+{v}_{position}^{(i)} \end{equation*}\end{document}</tex-math></disp-formula>where <italic>v</italic><sup>(<italic>i</italic>)</sup> refers to the <italic>i</italic>-th value of an embedding; <italic>v<sub>input</sub></italic>, <italic>v<sub>token</sub></italic> and <italic>v<sub>segment</sub></italic> refer to the input embeddings, token embeddings, segment embeddings and position embeddings, respectively.</p>
      <fig id="f5" orientation="portrait" position="float">
        <label>Figure 5</label>
        <caption>
          <p>An illustration of the architecture of BERT (<xref rid="ref18" ref-type="bibr">18)</xref>.</p>
        </caption>
        <graphic xlink:href="baz116f5"/>
      </fig>
      <p>The architecture of BERT is basically a multi-layer transformer encoder stack. In each layer, the number of transformer encoder nodes is equal to the length of the input embedding. Each node fully connects with every transformer encoder node in the upper layer. The basic BERT model has 12 layers, whereas the large BERT model has 24 layers. Each transformer encoder node has two sub-layers: (i) a self-attention layer, which helps the encoder look at other words in the input sentence as it encodes a specific word and (ii) a position-wise fully connected feed-forward network, which receives the output of the self-attention layer (<xref rid="ref19" ref-type="bibr">19)</xref>.</p>
      <p>To pre-train a language model, BERT uses two novel unsupervised prediction tasks: (i) masked language model, in which several tokens in each sequence are randomly erased and replaced with a special token (âmaskedâ). A model is trained by using the unmasked words to predict the masked word. (ii) Next sentence prediction, where 50% of sentence pairs are labeled with âIsNextâ, and the other 50% sentence pairs have the second sentence randomly replaced and the whole sentence pair labeled with âNotNextâ. A model is trained with both âIsNextâ and âNotNextâ sentence pairs.</p>
      <p>After random dropout regularization, the output of the transformer encoder stack is connected with a linear classifier for sequence classification training. The training error is back-propagated to the first layer of the pre-trained BERT model to realize the model fine-tuning process.</p>
    </sec>
    <sec id="sec6">
      <title>A general approach for medical relation extraction</title>
      <p>We formulated the medical relation extraction task as a classification problem that judges whether a given pair of medical entities (e.g. chemical and disease) was asserted with an induction relation in the article. Our approach is a general-purpose approach. The ârelationâ here depends on the relation defined in the specific corpus. It can refer to the existence of a relation (in BC5CDR corpus and TCM corpus) or a specific type of relation (in i2b2 temporal corpus). In BC5CDR and TCM corpus, the relation is undirected. In i2b2 temporal corpus, it is directed, because time has a direction.</p>
      <p>As a classification problem, the specific input of our model is the two entities in a relation (see sentence 1 in <xref rid="f5" ref-type="fig">Figure 5</xref>) and the context entities co-occurred with (see sentence 2 in <xref rid="f5" ref-type="fig">Figure 5</xref>). The output is the existence of a relation (for BC5CDR corpus and TCM corpus) or the label of a specific type of relation (for i2b2 temporal corpus). Take the following data from the BC5CDR corpus as an example:</p>
      <p><bold>Example 2:</bold> 1601297|a|The electrocardiograms (ECG) of 99 cocaine-abusing patients were compared with the ECGs of 50 schizophrenic controls. Eleven of the cocaine abusers and none of the controls had ECG evidence of significant myocardial injury defined as myocardial infarction, ischemia and bundle branch block.</p>
      <table-wrap id="TB17" orientation="portrait" position="float">
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
          </colgroup>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">1601297 </td>
              <td rowspan="1" colspan="1">33 50</td>
              <td colspan="2" rowspan="1">Myocardial injury</td>
              <td rowspan="1" colspan="1">Disease</td>
              <td rowspan="1" colspan="1">D009202</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1601297</td>
              <td rowspan="1" colspan="1">83</td>
              <td rowspan="1" colspan="1">90</td>
              <td rowspan="1" colspan="1">Cocaine</td>
              <td rowspan="1" colspan="1">Chemical</td>
              <td rowspan="1" colspan="1">D003042</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1601297</td>
              <td rowspan="1" colspan="1">135</td>
              <td rowspan="1" colspan="1">142</td>
              <td rowspan="1" colspan="1">Cocaine</td>
              <td rowspan="1" colspan="1">Chemical</td>
              <td rowspan="1" colspan="1">D003042</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1601297</td>
              <td rowspan="1" colspan="1">194 207</td>
              <td colspan="2" rowspan="1">Schizophrenic</td>
              <td rowspan="1" colspan="1">Disease</td>
              <td rowspan="1" colspan="1">D012559</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1601297</td>
              <td rowspan="1" colspan="1">232</td>
              <td rowspan="1" colspan="1">239</td>
              <td rowspan="1" colspan="1">Cocaine</td>
              <td rowspan="1" colspan="1">Chemical</td>
              <td rowspan="1" colspan="1">D003042</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1601297</td>
              <td rowspan="1" colspan="1">305 322</td>
              <td colspan="2" rowspan="1">Myocardial injury</td>
              <td rowspan="1" colspan="1">Disease</td>
              <td rowspan="1" colspan="1">D009202</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1601297</td>
              <td rowspan="1" colspan="1">334 355</td>
              <td colspan="2" rowspan="1">Myocardial infarction</td>
              <td rowspan="1" colspan="1">Disease</td>
              <td rowspan="1" colspan="1">D009203</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1601297</td>
              <td rowspan="1" colspan="1">357</td>
              <td rowspan="1" colspan="1">365</td>
              <td rowspan="1" colspan="1">Ischemia</td>
              <td rowspan="1" colspan="1">Disease</td>
              <td rowspan="1" colspan="1">D007511</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1601297</td>
              <td rowspan="1" colspan="1">371 390</td>
              <td colspan="2" rowspan="1">Bundle branch block</td>
              <td rowspan="1" colspan="1">Disease</td>
              <td rowspan="1" colspan="1">D002037</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1601297</td>
              <td rowspan="1" colspan="1">CID</td>
              <td rowspan="1" colspan="1">D003042</td>
              <td rowspan="1" colspan="1">D009203</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1601297</td>
              <td rowspan="1" colspan="1">CID</td>
              <td rowspan="1" colspan="1">D003042</td>
              <td rowspan="1" colspan="1">D002037</td>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1"/>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>This is a PubTator format (tab-delimited format) file for the article (PMID: 1601297) in the training set of the BC5CDR corpus. The first two lines are the title and the abstract of the annotated article. There are one chemical (MeSH ID: D003042), five disease (MeSH ID: D009202, D012559, D009203, D007511, and D002037) and two CID relations (&lt;D003042, D009203&gt; and &lt; D003042, D002037&gt;). For CID relation &lt;D003042, D009203&gt;, we concatenate the chemical âcocaineâ and disease âmyocardial infarctionâ as the first sentence and concatenate the title and abstract as the second sentence. The first and second sentences form a sentence pair sequence, which is input into the BERT model.</p>
      <p>Using a sentence pair as the input of a neural network is an effective mechanism to model the relationship between two sentences. It is commonly used in many NLP tasks (e.g. language model (<xref rid="ref32" ref-type="bibr">32)</xref>, machine translation (<xref rid="ref33" ref-type="bibr">33)</xref> and natural language inference (<xref rid="ref34" ref-type="bibr">34)</xref>). Just like the shallow machine learning methods, different features are concatenated into a long vector as the input of the classifier (e.g. SVM, CRF and Naive Bayes). For an end-to-end neural network system, it is easy and intuitive to concatenate different kinds of information provided by the training data into a sequence as the input of the system.</p>
      <p>In our approach, we concatenate the entities as the first sentence input and concatenate the title and abstract as the second sentence input, just because BERT needs a sentence pair as input, and this is an effective mechanism to model the relationship between entities and their context. A âsentenceâ here can be an arbitrary span of contiguous text, rather than an actual linguistic sentence.</p>
      <p>The relations in the BC5CDR dataset are annotated at the abstract level, and only entity pairs which have CID relation are annotated. Following the participating systems of the BioCreative V Chemical Disease Relation (CDR) Task (<xref rid="ref8" ref-type="bibr">8</xref>, <xref rid="ref21" ref-type="bibr">21)</xref>, we label these annotated entity pairs with â1â to generate positive training samples. Then, we randomly select a âchemicalâ entity and a âdiseaseâ entity in a sample document to make an entity pair. If the entity pair is not annotated, we think the two entities in this entity pair have no CID relation. We label this entity pair with â0â to generate a negative sample. Positive and negative samples are generated according to the ratio of 1:1 in order to train a balanced model to predict new relations.</p>
      <p>For entity pair &lt;D003042, D009203&gt;, a positive sample is generated as follows:</p>
      <p>âId_1 cocaine myocardial infarction\tElectrocardiographic evidence of myocardial injury in psychiatrically hospitalized cocaine abusers. The electrocardiograms (ECGs) of 99 cocaine-abusing patients were compared with the ECGs of 50 schizophrenic controls. Eleven of the cocaine abusers and none of the controls had ECG evidence of significant myocardial injury defined as myocardial infarction, ischemia and bundle branch block.â</p>
      <p>For entity pair &lt;D003042, D002037&gt;, another positive sample is generated as follows:</p>
      <p>âId_2 cocaine bundle branch block\tElectrocardiographic evidence of myocardial injury in psychiatrically hospitalized cocaine abusers. The electrocardiograms (ECGs) of 99 cocaine-abusing patients were compared with the ECGs of 50 schizophrenic controls. Eleven of the cocaine abusers and none of the controls had ECG evidence of significant myocardial injury defined as myocardial infarction, ischemia and bundle branch block.â</p>
      <p>We randomly select two diseases in (D009202, D012559 and D007511) to generate two entity pairs that have no CID relation and use them to generate two negative samples. They may be like this:</p>
      <p>âId_3 cocaine myocardial injury block\tElectrocardiographic evidence of myocardial injury in psychiatrically hospitalized cocaine abusers. The electrocardiograms (ECGs) of 99 cocaine-abusing patients were compared with the ECGs of 50 schizophrenic controls. Eleven of the cocaine abusers and none of the controls had ECG evidence of significant myocardial injury defined as myocardial infarction, ischemia and bundle branch block.</p>
      <p>Id_4 cocaine schizophrenic\tElectrocardiographic evidence of myocardial injury in psychiatrically hospitalized cocaine abusers. The electrocardiograms (ECG) of 99 cocaine-abusing patients were compared with the ECGs of 50 schizophrenic controls. Eleven of the cocaine abusers and none of the controls had ECG evidence of significant myocardial injury defined as myocardial infarction, ischemia and bundle branch block.â</p>
      <p>In the TCM corpus, both positive and negative samples are annotated. We use the original data to train a model.</p>
      <p>If there are multiple relation categories, as it is in the i2b2 temporal corpus, each pair of entities (including an event entity and a temporal expression entity) is labeled with one of the eight kinds of temporal relations (BEFORE, AFTER, SIMULTANEOUS, OVERLAP, BEGUN_BY, ENDED_BY, DURING and BEFORE_OVERLAP). We also use the original samples directly to train a multi-class classifier for prediction.</p>
    </sec>
    <sec id="sec7">
      <title>Fine-tuning the BERT model with 1d-CNN</title>
      <p>In the original BERT model, a linear classifier is used to fine-tune the pre-trained model for sequence classification. In this work, to improve the performance of the 1d-CNN in medical relation extraction tasks, we use the multi-filter 1d-CNN classifier (in short, 1d-CNN) proposed by Kim (<xref rid="ref35" ref-type="bibr">35)</xref> to fine-tune the pre-trained BERT model.</p>
      <p>The training object of the 1d-CNN is to minimize the ranking loss below:<disp-formula id="deqn02"><label>(2)</label><tex-math id="M2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \sum_{d\in T}\max \left\{0,1-g(d)+g\left({d}^{\prime}\right)\right\} \end{equation*}\end{document}</tex-math></disp-formula></p>
      <p>where <italic>d</italic> is a medical relation document in training set <italic>T</italic> with a positive label; <inline-formula><tex-math id="M3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${d}^{\prime }$\end{document}</tex-math></inline-formula> is another document in <italic>T</italic> with a negative label; <inline-formula><tex-math id="M4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$g(\cdotp )$\end{document}</tex-math></inline-formula> is the scoring function that represents the 1d-CNN architecture and <inline-formula><tex-math id="M5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$g(d)$\end{document}</tex-math></inline-formula> and <inline-formula><tex-math id="M6">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$g({d}^{\prime})$\end{document}</tex-math></inline-formula> are the scores of positive and negative documents, respectively. The training procession of the 1d-CNN classifier is to make <inline-formula><tex-math id="M7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$g(d)$\end{document}</tex-math></inline-formula> approximately 1 and <inline-formula><tex-math id="M8">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$g({d}^{\prime})$\end{document}</tex-math></inline-formula> approximatelyÂ 0.</p>
      <p>Positive label and negative label documents are the positive and negative samples in a corpus that is used to train a binary classifier. When there are multiple chemicals, diseases and relations in a document, multiple entity pairs are generated, and each pair of entities share the same context document. One entity pair and its context form a positive sample. For the BC5CDR corpus, we randomly select two entities that have no medical relation to generate negative samples. For the TCM and i2b2 temporal corpus, we use the original annotated data to train a model.</p>
      <p>The main architecture of the 1d-CNN consists of (i) an input layer, which converts variable-length medical relation documents into fixed-length vectors; (ii) a convolution layer, in which multiple filters move across the input vectors to extract semantic features through one-dimensional convolution; (iii) a pooling layer, in which the most useful semantic features are selected by a max-overtime pooling operation (<xref rid="ref36" ref-type="bibr">36)</xref> and (iv) an output layer, in which multiple features are concatenated and classified by a fully connected SoftMax classifier. In the training process, the training error is back-propagated to fine-tune the parameters of the BERT, which are firstly restored from the pre-trained model.</p>
      <p>Pre-trained BERT models can also be used in other deep learning methods, such as RNN and LSTM. However, they cannot be used as features in these methods because the pre-trained BERT models are neural networks with pre-trained parameters, not a vector with numerical values. They are usually used as components of other neural networks.</p>
    </sec>
  </sec>
  <sec id="sec8">
    <title>Experiments and results</title>
    <sec id="sec9">
      <title>Measures</title>
      <p>For all three corpora, we use the precision, recall and F1 measure as evaluation metrics for the medical relation extraction performance. The precision, recall, and F1 measure are computed as follows:<disp-formula id="deqn03"><label>(3)</label><tex-math id="M9">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{Precision}\left(\mathrm{P}\right)=\frac{TP}{TP+ FP} \end{equation*}\end{document}</tex-math></disp-formula><disp-formula id="deqn04"><label>(4)</label><tex-math id="M10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{Recall}\left(\mathrm{R}\right)=\frac{TP}{TP+ FN} \end{equation*}\end{document}</tex-math></disp-formula><disp-formula id="deqn05"><label>(5)</label><tex-math id="M11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{equation*} \mathrm{F}1=\frac{2\times P\times R}{P+R} \end{equation*}\end{document}</tex-math></disp-formula></p>
      <p>where <italic>TP</italic> denotes true positive, <italic>FP</italic> denotes false positive and <italic>FN</italic> denotes false negative in the confusion matrix.</p>
      <p>Medical relation extraction in the i2b2 2012 temporal relations challenge is a multi-class classification task. In this work, we use the evaluation scripts (Available at <ext-link ext-link-type="uri" xlink:href="http://i2b2.org/NLP/DataSets">http://i2b2.org/NLP/DataSets</ext-link>) provided by the challenge organizer to evaluate the performance of our approach on the i2b2 temporal corpus.</p>
    </sec>
    <sec id="sec10">
      <title>Experimental settings</title>
      <p>For all three corpora, we use a PyTorch implementation of Kimâs 1d-CNN (Software available at <ext-link ext-link-type="uri" xlink:href="https://github.com/wabyking/TextClassificationBenchmark">https://github.com/wabyking/TextClassificationBenchmark</ext-link>). For the pre-trained word embeddings used in 1d-CNN, we use two English embeddings (Glove embeddings (<xref rid="ref37" ref-type="bibr">37)</xref> and PubMed embeddings (Available at <ext-link ext-link-type="uri" xlink:href="http://bio.nlplab.org/">http://bio.nlplab.org/</ext-link>)) and two Chinese embeddings (general embeddings (<xref rid="ref38" ref-type="bibr">38)</xref> and TCM literature embeddings trained by ourselves) for the English and Chinese corpora, respectively.</p>
      <p>For the Glove embeddings (Available at <ext-link ext-link-type="uri" xlink:href="https://nlp.stanford.edu/projects/glove/">https://nlp.stanford.edu/projects/glove/</ext-link>), we use 300-dimensional vectors trained on 6B tokens from Wikipedia 2014 and Gigaword 5. For general Chinese embeddings (Available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Embedding/Chinese-Word-Vectors">https://github.com/Embedding/Chinese-Word-Vectors</ext-link>), we use the 300-dimensional vectors trained on a mixed corpus including Baidu Encyclopedia, Chinese Wikipedia, Peopleâs Daily News and similar. For TCM literature embeddings, we use the traditional Chinese medicine literature in the TCM corpus. This contains 15M words, and the vocabulary size is 57K. We use word2vec tools (Available at <ext-link ext-link-type="uri" xlink:href="https://code.google.com/archive/p/word2vec/">https://code.google.com/archive/p/word2vec/</ext-link>)to train the vectors. The embeddings have 300 dimensions.</p>
      <p>To train 1d-CNN, we concatenate the two entities in one relation and the text they co-occurred in as a long document and use this document as the input of 1d-CNN. We use rectified linear units for the activation function, filter windows of lengths 3, 4 and 5 with 100 feature maps each, an AdaDelta decay parameter of 0.95 and a dropout rate of 0.5 on all three corpora. The maximum sequence length is set to 400 for the BC5CDR corpus, 300 for the TCM corpus and 1000 for the i2b2 temporal corpus.</p>
      <p>To fine-tune 1d-CNN using the pre-trained BERT model, we concatenate the two entities in one relation as one input sentence and the text in which the two entities co-occurred as the other input sentence. We use the âuncased_L-12_H-768_A-12â model for the English corpus and the âchinese_L-12_H-768_A-12â model for the Chinese corpus. Both models are pre-trained on the BERT-Base network, which has 12 layers, 768 hidden nodes, 12 heads and 110M parameters. As reported by Devlin <italic>etÂ al.</italic> (<xref rid="ref2" ref-type="bibr">2)</xref>, the âuncased_L-12_H-768_A-12â model is trained on BooksCorpus (800M words) (<xref rid="ref39" ref-type="bibr">39)</xref> and English Wikipedia (2500M words). We use a learning rate of 5âÃâ10<sup>â5</sup>.</p>
      <p>We trained our models using a single NVIDIA GeForce GTX 1080Ti GPU with 12 GB of RAM. Fine-tuning the pre-trained BERT model on GPUs with 12â16 GB of RAM may cause out-of-memory issues (<ext-link ext-link-type="uri" xlink:href="https://github.com/google-research/bert#out-of-memory-issues">https://github.com/google-research/bert#out-of-memory-issues</ext-link>). The factors that affect memory usage are the maximum sequence length and the batch size for training. We used maximum sequence lengths of 200, 110 and 170 and training batch sizes of 20, 32 and 8 for the BC5CDR corpus, TCM corpus and i2b2 temporal corpus, respectively. For the other parameters, we use the default settings for 1d-CNN and BERT.</p>
    </sec>
    <sec id="sec11">
      <title>BioCreative V CDR task</title>
      <p><xref rid="TB4" ref-type="table">Table 4</xref> presents the system results achieved on the BC5CDR corpus. The best results are highlighted in boldface. The BioCreative V CDR task has two subtasks: disease named entity recognition (DNER) and chemical-induced disease (CID) relation extraction. In <xref rid="TB4" ref-type="table">Table 4</xref>, the âbest system of BioCreative V CDR extraction challengeâ uses the chemical and disease entities automatically recognized in the DNER subtask, whereas the other four approaches use the gold annotated entities as the input for the CID relation extraction task.</p>
      <table-wrap id="TB4" orientation="portrait" position="float">
        <label>Table 4</label>
        <caption>
          <p>System results on the BC5CDR corpus</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="center" span="1"/>
            <col align="center" span="1"/>
            <col align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Approach</th>
              <th align="center" rowspan="1" colspan="1">Precision</th>
              <th align="center" rowspan="1" colspan="1">Recall</th>
              <th align="center" rowspan="1" colspan="1">F1</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">Best system of BioCreative V CDR extraction challenge (<xref rid="ref34" ref-type="bibr">34)</xref></td>
              <td rowspan="1" colspan="1">0.5567</td>
              <td rowspan="1" colspan="1">0.5844</td>
              <td rowspan="1" colspan="1">0.5703</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1d-CNN with gold entity annotation (Glove Embeddings)</td>
              <td rowspan="1" colspan="1">0.6085</td>
              <td rowspan="1" colspan="1">0.5642</td>
              <td rowspan="1" colspan="1">0.5855</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1d-CNN with gold entity annotation (PubMed embeddings)</td>
              <td rowspan="1" colspan="1">0.7439</td>
              <td rowspan="1" colspan="1">0.5699</td>
              <td rowspan="1" colspan="1">0.6454</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Pons <italic>etÂ al.</italic> (<xref rid="ref37" ref-type="bibr">37)</xref></td>
              <td rowspan="1" colspan="1">0.731</td>
              <td rowspan="1" colspan="1">0.676</td>
              <td rowspan="1" colspan="1">0.7020</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BERT with pre-trained model</td>
              <td rowspan="1" colspan="1">0.7493</td>
              <td rowspan="1" colspan="1">0.6673</td>
              <td rowspan="1" colspan="1">0.7059</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1d-CNN fine-tuning the pre-trained BERT model</td>
              <td rowspan="1" colspan="1">
                <bold>0.7505</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.6838</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.7156</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>The best results for each metric are highlighted in boldface.</p>
        </table-wrap-foot>
      </table-wrap>
      <p>The 1d-CNN approach with general embeddings (Glove embeddings) achieves an F1 score of 0.5855. Using domain-specific embeddings (PubMed embeddings) improves the 1d-CNN F1 score to 0.6454, a relative improvement of 10.2%. Pons <italic>etÂ al.</italic> (<xref rid="ref40" ref-type="bibr">40)</xref> refers to the SVM approach with rich human-engineered features proposed by Pons <italic>etÂ al.</italic> Using the gold annotated entities and post-challenge features, this approach achieves an F1 score of 0.7020. âBERT with pre-trained modelâ refers to the original BERT model in which a linear classifier is used to fine-tune the pre-trained model. The â1d-CNN fine-tuning BERT with pre-trained modelâ refers to our proposed approach. It achieves state-of-the-art performance without any human-engineered features or pre/post-processing operations, giving a relative improvement of 1.9% compared to Pons <italic>etÂ al.</italic> and 10.8% compared to 1d-CNN with PubMed embeddings. These results validate the influences of the pre-trained model and the fine-tuning technique in terms of medical relation extraction.</p>
      <p>There are 14,901 words found in the vocabulary of the BC5CDR corpus. Among these, 11,652 words were found in the Glove embeddings and 13,928 words were found in the PubMed embeddings. BERT split these words into 9175 sub-word units (tokens), with all word pieces included in the vocabulary of the pre-trained BERT model. The experimental results show that higher word coverage can improve the recall of the approach.</p>
    </sec>
    <sec id="sec12">
      <title>Relation extraction task using TCM literature</title>
      <p><xref rid="TB5" ref-type="table">Table 5</xref> presents the system results achieved on the TCM literature corpus. HS, HD, FS, FD and SD refer to the herb-syndrome, herb-disease, formula-syndrome, formula-disease and syndrome-disease relations in TCM, respectively. The top three results of the compared systems, i.e. Basic SVM, Iterative SVM and HFGM, were reported by Wan <italic>etÂ al.</italic> (<xref rid="ref25" ref-type="bibr">25)</xref>. HFGM is the abbreviation of the heterogeneous factor graph model, which is a unified graphical model proposed by Wan <italic>etÂ al.</italic> It is used to simultaneously infer the labels of all the candidate relations by employing the concept of collective inference (<xref rid="ref25" ref-type="bibr">25)</xref>. â1d-CNN general embeddingsâ refers to the 1d-CNN approach using general Chinese embeddings as input, â1d-CNN TCM embeddingsâ refers to the 1d-CNN approach using TCM literature embeddings as input, âBERT with pre-trained modelâ refers to the original BERT model in which a linear classifier is used to fine-tune the pre-trained model and â1d-CNN fine-tuningâ refers to the 1d-CNN approach using the basic BERT network as its component and fine-tuning the pre-trained BERT model with 1d-CNN. Following the work of Wan <italic>etÂ al.</italic> (<xref rid="ref25" ref-type="bibr">25)</xref>, we perform a five-fold cross-validation to evaluate the performance of our model. The best results for each relation type and metric are highlighted in boldface.</p>
      <table-wrap id="TB5" orientation="portrait" position="float">
        <label>Table 5</label>
        <caption>
          <p>System results on the TCM corpus</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="center" span="1"/>
            <col align="center" span="1"/>
            <col align="center" span="1"/>
            <col align="center" span="1"/>
            <col align="center" span="1"/>
            <col align="center" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Approach</th>
              <th align="left" rowspan="1" colspan="1">Metric</th>
              <th align="center" rowspan="1" colspan="1">HS</th>
              <th align="center" rowspan="1" colspan="1">HD</th>
              <th align="center" rowspan="1" colspan="1">FS</th>
              <th align="center" rowspan="1" colspan="1">FD</th>
              <th align="center" rowspan="1" colspan="1">SD</th>
              <th align="center" rowspan="1" colspan="1">Average</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left" rowspan="3" colspan="1">Basic SVM</td>
              <td rowspan="1" colspan="1">Precision</td>
              <td rowspan="1" colspan="1">0.7889</td>
              <td rowspan="1" colspan="1">0.7913</td>
              <td rowspan="1" colspan="1">0.8012</td>
              <td rowspan="1" colspan="1">0.8104</td>
              <td rowspan="1" colspan="1">0.7772</td>
              <td rowspan="1" colspan="1">0.7930</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Recall</td>
              <td rowspan="1" colspan="1">0.7234</td>
              <td rowspan="1" colspan="1">0.7459</td>
              <td rowspan="1" colspan="1">0.7232</td>
              <td rowspan="1" colspan="1">0.7308</td>
              <td rowspan="1" colspan="1">0.7322</td>
              <td rowspan="1" colspan="1">0.7315</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">F1</td>
              <td rowspan="1" colspan="1">0.7547</td>
              <td rowspan="1" colspan="1">0.7679</td>
              <td rowspan="1" colspan="1">0.7602</td>
              <td rowspan="1" colspan="1">0.7685</td>
              <td rowspan="1" colspan="1">0.7540</td>
              <td rowspan="1" colspan="1">0.7609</td>
            </tr>
            <tr>
              <td align="left" rowspan="3" colspan="1">Iterative SVM</td>
              <td rowspan="1" colspan="1">Precision</td>
              <td rowspan="1" colspan="1">0.8335</td>
              <td rowspan="1" colspan="1">0.8310</td>
              <td rowspan="1" colspan="1">0.8433</td>
              <td rowspan="1" colspan="1">0.8555</td>
              <td rowspan="1" colspan="1">0.8188</td>
              <td rowspan="1" colspan="1">0.8354</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Recall</td>
              <td rowspan="1" colspan="1">0.7766</td>
              <td rowspan="1" colspan="1">0.7951</td>
              <td rowspan="1" colspan="1">0.7775</td>
              <td rowspan="1" colspan="1">0.7841</td>
              <td rowspan="1" colspan="1">0.7834</td>
              <td rowspan="1" colspan="1">0.7836</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">F1</td>
              <td rowspan="1" colspan="1">0.8040</td>
              <td rowspan="1" colspan="1">0.8127</td>
              <td rowspan="1" colspan="1">0.8091</td>
              <td rowspan="1" colspan="1">0.8182</td>
              <td rowspan="1" colspan="1">0.8007</td>
              <td rowspan="1" colspan="1">0.8087</td>
            </tr>
            <tr>
              <td align="left" rowspan="3" colspan="1">HFGM</td>
              <td rowspan="1" colspan="1">Precision</td>
              <td rowspan="1" colspan="1">0.9094</td>
              <td rowspan="1" colspan="1">0.8948</td>
              <td rowspan="1" colspan="1">0.9081</td>
              <td rowspan="1" colspan="1">0.9107</td>
              <td rowspan="1" colspan="1">0.8987</td>
              <td rowspan="1" colspan="1">0.9039</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Recall</td>
              <td rowspan="1" colspan="1">
                <bold>0.8693</bold>
              </td>
              <td rowspan="1" colspan="1">0.8734</td>
              <td rowspan="1" colspan="1">
                <bold>0.8569</bold>
              </td>
              <td rowspan="1" colspan="1">0.8825</td>
              <td rowspan="1" colspan="1">0.8687</td>
              <td rowspan="1" colspan="1">0.8698</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">F1</td>
              <td rowspan="1" colspan="1">0.8889</td>
              <td rowspan="1" colspan="1">0.8840</td>
              <td rowspan="1" colspan="1">
                <bold>0.8818</bold>
              </td>
              <td rowspan="1" colspan="1">0.8964</td>
              <td rowspan="1" colspan="1">0.8786</td>
              <td rowspan="1" colspan="1">0.8856</td>
            </tr>
            <tr>
              <td align="left" rowspan="3" colspan="1">1d-CNN general embeddings</td>
              <td rowspan="1" colspan="1">Precision</td>
              <td rowspan="1" colspan="1">
                <bold>0.9670</bold>
              </td>
              <td rowspan="1" colspan="1">0.9264</td>
              <td rowspan="1" colspan="1">
                <bold>0.9572</bold>
              </td>
              <td rowspan="1" colspan="1">0.9041</td>
              <td rowspan="1" colspan="1">
                <bold>0.9982</bold>
              </td>
              <td rowspan="1" colspan="1">0.9505</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Recall</td>
              <td rowspan="1" colspan="1">0.7460</td>
              <td rowspan="1" colspan="1">0.9070</td>
              <td rowspan="1" colspan="1">0.6937</td>
              <td rowspan="1" colspan="1">0.7950</td>
              <td rowspan="1" colspan="1">0.8150</td>
              <td rowspan="1" colspan="1">0.7913</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">F1</td>
              <td rowspan="1" colspan="1">0.8422</td>
              <td rowspan="1" colspan="1">0.9166</td>
              <td rowspan="1" colspan="1">0.8045</td>
              <td rowspan="1" colspan="1">0.8461</td>
              <td rowspan="1" colspan="1">0.8973</td>
              <td rowspan="1" colspan="1">0.8613</td>
            </tr>
            <tr>
              <td align="left" rowspan="3" colspan="1">1d-CNN TCM embeddings</td>
              <td rowspan="1" colspan="1">Precision</td>
              <td rowspan="1" colspan="1">0.9382</td>
              <td rowspan="1" colspan="1">0.9365</td>
              <td rowspan="1" colspan="1">0.8984</td>
              <td rowspan="1" colspan="1">0.9150</td>
              <td rowspan="1" colspan="1">0.9784</td>
              <td rowspan="1" colspan="1">0.9333</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Recall</td>
              <td rowspan="1" colspan="1">0.7451</td>
              <td rowspan="1" colspan="1">0.9044</td>
              <td rowspan="1" colspan="1">0.7059</td>
              <td rowspan="1" colspan="1">0.8249</td>
              <td rowspan="1" colspan="1">0.8463</td>
              <td rowspan="1" colspan="1">0.8053</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">F1</td>
              <td rowspan="1" colspan="1">0.8306</td>
              <td rowspan="1" colspan="1">0.9201</td>
              <td rowspan="1" colspan="1">0.7906</td>
              <td rowspan="1" colspan="1">0.8677</td>
              <td rowspan="1" colspan="1">0.9076</td>
              <td rowspan="1" colspan="1">0.8633</td>
            </tr>
            <tr>
              <td align="left" rowspan="3" colspan="1">BERT with pre-trained model</td>
              <td rowspan="1" colspan="1">Precision</td>
              <td rowspan="1" colspan="1">0.9263</td>
              <td rowspan="1" colspan="1">0.9675</td>
              <td rowspan="1" colspan="1">0.8885</td>
              <td rowspan="1" colspan="1">0.9570</td>
              <td rowspan="1" colspan="1">0.9589</td>
              <td rowspan="1" colspan="1">0.9319</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Recall</td>
              <td rowspan="1" colspan="1">0.8457</td>
              <td rowspan="1" colspan="1">0.9440</td>
              <td rowspan="1" colspan="1">0.8334</td>
              <td rowspan="1" colspan="1">0.9281</td>
              <td rowspan="1" colspan="1">0.9237</td>
              <td rowspan="1" colspan="1">0.8901</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">F1</td>
              <td rowspan="1" colspan="1">0.8842</td>
              <td rowspan="1" colspan="1">0.9556</td>
              <td rowspan="1" colspan="1">0.8601</td>
              <td rowspan="1" colspan="1">0.9423</td>
              <td rowspan="1" colspan="1">0.9410</td>
              <td rowspan="1" colspan="1">0.9105</td>
            </tr>
            <tr>
              <td align="left" rowspan="3" colspan="1">1d-CNN fine-tuning</td>
              <td rowspan="1" colspan="1">Precision</td>
              <td rowspan="1" colspan="1">0.9365</td>
              <td rowspan="1" colspan="1">
                <bold>0.9745</bold>
              </td>
              <td rowspan="1" colspan="1">0.8974</td>
              <td rowspan="1" colspan="1">
                <bold>0.9702</bold>
              </td>
              <td rowspan="1" colspan="1">0.9806</td>
              <td rowspan="1" colspan="1">
                <bold>0.9518</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Recall</td>
              <td rowspan="1" colspan="1">0.8629</td>
              <td rowspan="1" colspan="1">
                <bold>0.9553</bold>
              </td>
              <td rowspan="1" colspan="1">0.8350</td>
              <td rowspan="1" colspan="1">
                <bold>0.9352</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.9420</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.9061</bold>
              </td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">F1</td>
              <td rowspan="1" colspan="1">
                <bold>0.8982</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.9648</bold>
              </td>
              <td rowspan="1" colspan="1">0.8651</td>
              <td rowspan="1" colspan="1">
                <bold>0.9522</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.9609</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.9282</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>The best results for each metric are highlighted in boldface.</p>
        </table-wrap-foot>
      </table-wrap>
      <p>As we can see, almost all the algorithms have very high performance on this corpus. This task is easier than the other two tasks because it is a binary classification problem, and the relations in this corpus are annotated at the instance level.</p>
      <p>The â1d-CNN fine-tuningâ approach achieves the best performance on four of the five relation types, outperforming the others by a good margin on the herb-disease, formula-disease and syndrome-disease relations. Compared with <italic>HFGM</italic>, which is a probability graph model specially designed for TCM relation extraction problems, â1d-CNN fine-tuningâ improves the F1 score by 1.04, 9.14, 6.22 and 9.37% on the herb-syndrome, herb-disease, formula-disease and syndrome-disease relations, respectively. This indicates that our proposed approach is effective for TCM relation extraction.</p>
      <p>In formula-syndrome relations, the â1d-CNN fine-tuningâ approach achieves an F1 score that is 1.67% lower than that of HFGM. This may be because we only find 197 out of the 966 annotated formula-syndrome relations that co-occurred in the literature of the TCM corpus, whereas HFGM uses all 966 annotated formula-syndrome relations (see <xref rid="TB2" ref-type="table">Table 2</xref>). In TCM corpus, the format of annotated relation documents is: âID\tEntityID1\tEntityName1 \tEntityID2\tEntityName2\tLabelâ, and the TCM literature which is used to annotate TCM relations is in a separate document. We need to search for the context of the relations in the literature document. As shown in <xref rid="TB2" ref-type="table">Table 2</xref>, there are 966 annotated formula-syndrome relations, including 392 positive relations and 574 negative relations. When we searched for the context that the entities of a formula-syndrome relation co-occurred in, we only found 197 relations their entities co-occurred in the literature of the TCM corpus.</p>
      <p>For the other four kinds of relations, the numbers are 256/1120 (herb-syndrome relations), 1176/1176 (herb-disease relations), 788/788 (formula disease relations) and 268/964 (syndrome-disease relations). Therefore, only 197 formula-syndrome relations are used in our experiment. Our method achieves comparable or better performance with less training data than the comparative methods. It shows the effectiveness of our method.</p>
      <p>The â1d-CNN with general embeddingâ approach achieves the best precision for the herb-syndrome, formula-syndrome and syndrome-disease relations, but has low recall on most relations. The â1d-CNN with TCM embeddingâ approach has a larger vocabulary coverage than â1d-CNN with general embeddingâ and achieves slightly better performance. By fine-tuning the pre-trained BERT model, our proposed approach achieves F1 scores of 0.8982, 0.9648, 0.8651, 0.9522 and 0.9609 on the five relations. This corresponds to relative improvements of 6.65, 5.26, 7.53, 12.5 and 7.09% compared with the â1d-CNN with general embeddingsâ approach, respectively. These results indicate that using the pre-trained model and fine-tuning technique can improve the performance of the 1d-CNN classifier for TCM relation extraction.</p>
    </sec>
    <sec id="sec13">
      <title>I2b2 2012 challenge clinical temporal relation extraction task</title>
      <p><xref rid="TB6" ref-type="table">Table 6</xref> presents the system results achieved on the i2b2 temporal relation corpus. â1d-CNN with gold entity annotationâ refers to the 1d-CNN approach using annotated gold event and time expressions as entities. âGlove embeddings and PubMed embeddingsâ refer to the 1d-CNN approach using Glove embeddings and PubMed embeddings as initial input, respectively. âThe best system of i2b2 challengeâ refers to the system that obtained the best performance in the TLINK subtask of the i2b2 2012 temporal relations challenge. This is an SVM classifier-based approach that also uses annotated gold events and time expressions. âBERT with pre-trained modelâ refers to the original BERT model in which a linear classifier is used to fine-tune the pre-trained model. â1d-CNN fine-tuning BERT with pre-trained modelâ is our proposed approach.</p>
      <table-wrap id="TB6" orientation="portrait" position="float">
        <label>Table 6</label>
        <caption>
          <p>System results on the i2b2 temporal corpus</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
            <col align="left" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="left" rowspan="1" colspan="1">Approach</th>
              <th align="center" rowspan="1" colspan="1">Precision</th>
              <th align="center" rowspan="1" colspan="1">Recall</th>
              <th align="center" rowspan="1" colspan="1">F1</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">1d-CNN with gold entity annotation (Glove embeddings)</td>
              <td rowspan="1" colspan="1">0.4549</td>
              <td rowspan="1" colspan="1">0.5846</td>
              <td rowspan="1" colspan="1">0.5117</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1d-CNN with gold entity annotation (PubMed embeddings)</td>
              <td rowspan="1" colspan="1">0.5787</td>
              <td rowspan="1" colspan="1">0.5647</td>
              <td rowspan="1" colspan="1">0.5716</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">The best system of i2b2 challenge (<xref rid="ref27" ref-type="bibr">27)</xref></td>
              <td rowspan="1" colspan="1">
                <bold>0.71</bold>
              </td>
              <td rowspan="1" colspan="1">0.67</td>
              <td rowspan="1" colspan="1">0.6932</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">BERT with pre-trained model</td>
              <td rowspan="1" colspan="1">0.6684</td>
              <td rowspan="1" colspan="1">0.7173</td>
              <td rowspan="1" colspan="1">0.6920</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">1d-CNN fine-tuning BERT with pre-trained model</td>
              <td rowspan="1" colspan="1">0.6722</td>
              <td rowspan="1" colspan="1">
                <bold>0.7489</bold>
              </td>
              <td rowspan="1" colspan="1">
                <bold>0.7085</bold>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>The best results for each metric are highlighted in boldface.</p>
        </table-wrap-foot>
      </table-wrap>
      <p>Note that our proposed approach achieves the best performance, with an F1 score of 0.7085. This represents a relative improvement of 2.21% compared with the best system from the i2b2 challenge. By using a pre-trained model on large-scale unstructured text, our approach achieves a recall of 0.7489, a relative improvement of 11.8% compared with the best system of the i2b2 challenge. Note that our method is a general-purpose end-to-end approach without feature engineering for special tasks. We did not even pre-process the corpus or post-process the classification result in this experiment.</p>
      <p>The 1d-CNN approach with general embeddings (Glove embeddings in the table) achieves an F1 score of 0.5117. Using domain-specific embeddings (PubMed embeddings in the table) improves the F1 score of 1d-CNN to 0.5716. This is a relative improvement of 11.7% compared with the 1d-CNN approach with general embeddings. By fine-tuning the pre-trained BERT model, the F1 score of 1d-CNN improves to 0.7085, a relative improvement of 38.4% compared with the 1d-CNN approach with general embeddings and 23.9% compared with the 1d-CNN approach with domain-specific embeddings. These results indicate that our proposed approach can improve the performance of the 1d-CNN for temporal relation extraction tasks.</p>
    </sec>
  </sec>
  <sec id="sec14">
    <title>Discussion</title>
    <p>In this work, we have presented an approach for chemical disease relation extraction, traditional Chinese medicine literature relation extraction and clinical temporal relation extraction. To the best of our knowledge, this is the first general-purpose approach to achieve state-of-the-art performance in all three medical relation extraction tasks. After performing an in-depth analysis of some specific instances, we found that our proposed approach improves the performance of relation extraction for the following reasons: (i) the pre-trained model is more effective than word embeddings for acquiring useful linguistic knowledge for downstream tasks; (ii) compared with the â1d-CNN general embeddingsâ approach, our method achieves higher recall on all three corpora. This indicates that fine-tuning the pre-trained model and back-propagating the training error makes better use of the linguistic knowledge acquired from the unstructured text than using pre-trained embeddings as input and training the main task model from scratch. Treating pre-trained embeddings as fixed parameters limits their usefulness (<xref rid="ref13" ref-type="bibr">13)</xref>. (iii) Using WordPieces as tokens rather than words can improve the coverage of the input embeddings for the 1d-CNN classifier.</p>
    <p>We further analyzed the errors made by our method. One kind of error is that the two entities in a relation are too far away to be identified by our method. For example, our method failed to extract the CID relation of âsystemic sclerosisâ (MeSH: D012595) and âcorticosteroidâ (MeSH: D000305) from the following sentence: âScleroderma renal crisis (SRC) is a rare complication of <bold>systemic sclerosis</bold> (SSc) but can be severe enough to require temporary or permanent renal replacement therapy. Moderate to high dose <bold>corticosteroid</bold> use is recognized as a major risk factor for SRC<italic>.â</italic> (PMID: 22836123), the two entities (in bold) are separated in two sentences with 18 words between them. This may be because the distance between the entities is too far, and there is no trigger word between them.</p>
    <p>Another kind of error is that the category of relations extracted by our method is not the category of relations annotated in the corpus. Take the BC5CDR corpus as an example, in â<bold>Famotidine</bold> is a histamine H2-receptor antagonist used in inpatient settings for prevention of stress <bold>ulcers</bold>...â (PMID: 8701013, words in bold are disease/chemical entities given by the corpus), our method successfully extracted the relation of âFamotidineâ (MeSH: D015738) and âulcersâ (MeSH: D014456) but cannot distinguish the difference between prevention relation and CID relation.</p>
    <p>We trained our models on an NVIDIA GeForce GTX 1080Ti GPU with cuDNN library enabled. For the BC5CDR corpus, the average training speed is 0.126sec/batch, and the total time of model training is about 31 minutes. For the TCM corpus, take herb-disease relation as an example, the average training speed is 0.081sec/batch, and the training time for the model is about 13 minutes. For the i2b2 temporal corpus, the average training speed is 0.505sec/batch, and the total training time is about 50 minutes.</p>
    <p>The results presented in the BioCreative V CDR task can improve the research process of chemical-disease interactions, which is critical in applications including clinical trial screening, clinical decision-making and drug discovery. The relations of herbs, formulae, syndromes and diseases found in TCM literature relation extraction task are useful for assisting clinical treatment, poly-pharmacology and drug-safety research. Understanding the clinical timeline is crucial in determining a patientâs diagnosis and treatment. The results presented in I2b2 2012 challenge clinical temporal relation extraction task can be used in disease progression monitoring, early prediction of chronic disease and adverse event detection.</p>
  </sec>
  <sec id="sec15">
    <title>Conclusions</title>
    <p>This paper has presented a novel approach to improve deep learning-based medical relation extraction via model pre-training on large-scale unstructured text and fine-tuning the pre-trained model. The approach employs BERT to construct a pre-trained model on large-scale unstructured text and uses 1d-CNN to fine-tune the pre-trained model for clinical relation extraction. We have conducted extensive experiments on three clinical relation extraction corpora in comparison with the best existing systems. Empirical results show that our approach achieves state-of-the-art performance on all three corpora. We have found that using the pre-trained model and fine-tuning technique boosts the performance of clinical relation extraction. This general approach can be applied to many disease- and drug-related systems and clinical applications.</p>
  </sec>
</body>
<back>
  <sec id="sec16">
    <title>Funding</title>
    <p>Guangdong Provincial Education Department (grant number 2014KZDXM055); Guangdong Natural Science Foundation project (grant number 2016A070708002, 2016A030313003); Graduate Education Innovation project (grant number 2016SFKC_42, YJS-SFKC-14-05, YJS-PYJD-17-03); Integration of cloud computing and big data innovation project (grant number 2017B02101) and Jiangmen foundation and theoretical science research project (grant number 2018JC01003).</p>
    <p><italic>Conflict of interest</italic>. None declared.</p>
  </sec>
  <notes id="AN1">
    <p><bold>Database URL</bold>: <ext-link ext-link-type="uri" xlink:href="http://120.78.238.14:8080/cdr">http://120.78.238.14:8080/cdr</ext-link></p>
  </notes>
  <ref-list id="bib1">
    <title>References</title>
    <ref id="ref1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Luo</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Cheng</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Uzuner</surname><given-names>Ã.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2018</year>) <article-title>Segment convolutional neural networks (Seg-CNNs) for classifying relations in clinical notes</article-title>. <source>JAMIA</source>, <volume>25</volume>, <fpage>93</fpage>â<lpage>98</lpage>.<pub-id pub-id-type="pmid">29025149</pub-id></mixed-citation>
    </ref>
    <ref id="ref2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Ross</surname><given-names>K.E.</given-names></name>, <name name-style="western"><surname>Arighi</surname><given-names>C.N.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2015</year>) <article-title>miRTex: a text mining system for miRNA-gene relation extraction</article-title>. <source>PLoS Comput. Biol.</source>, <volume>11</volume>, <fpage>1</fpage>â<lpage>24</lpage>. doi: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1004391</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lowe</surname><given-names>D.M.</given-names></name>, <name name-style="western"><surname>OâBoyle</surname><given-names>N.M.</given-names></name> and <name name-style="western"><surname>Sayle</surname><given-names>R.A.</given-names></name></person-group> (<year>2016</year>) <article-title>Efficient chemical-disease identification and relationship extraction using Wikipedia to improve recall</article-title>. <source>Database (Oxford)</source>, <volume>2016</volume>, <fpage>baw039</fpage>. doi: <pub-id pub-id-type="doi">10.1093/database/baw039</pub-id>.<pub-id pub-id-type="pmid">27060160</pub-id></mixed-citation>
    </ref>
    <ref id="ref4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Le</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Tran</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Dang</surname><given-names>T.H.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2016</year>) <article-title>Sieve-based coreference resolution enhances semi-supervised learning model for chemical-induced disease relation extraction</article-title>. <source>Database (Oxford)</source>,
<volume>2016</volume>, <fpage>baw102</fpage>.<pub-id pub-id-type="pmid">27630201</pub-id></mixed-citation>
    </ref>
    <ref id="ref5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Onye</surname><given-names>S.C.</given-names></name>, <name name-style="western"><surname>AkkeleÅ</surname><given-names>A.</given-names></name> and <name name-style="western"><surname>Dimililer</surname><given-names>N.</given-names></name></person-group> (<year>2018</year>) <article-title>RelSCANâa system for extracting chemical-induced disease relation from biomedical literature</article-title>. <source>J. Biomed. Inform.</source>, <volume>87</volume>, <fpage>79</fpage>â<lpage>87</lpage>.<pub-id pub-id-type="pmid">30296491</pub-id></mixed-citation>
    </ref>
    <ref id="ref6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>W.</given-names></name> and <name name-style="western"><surname>Yu</surname><given-names>H.</given-names></name></person-group> (<year>2018</year>) <article-title>Extraction of information related to adverse drug events from electronic health record notes: design of an end-to-end model based on deep learning</article-title>. <source><italic toggle="yes">JMIR Med. Inform.</italic></source>, <volume>6</volume>, <fpage>1</fpage>â<lpage>14</lpage>. doi: <pub-id pub-id-type="doi">10.2196/12159</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zheng</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Lin</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>Z.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2018</year>) <article-title>An effective neural model extracting document level chemical-induced disease relations from biomedical literature</article-title>. <source>J. Biomed. Inform.</source>, <volume>83</volume>, <fpage>1</fpage>â<lpage>9</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jbi.2018.05.001</pub-id>.<pub-id pub-id-type="pmid">29746916</pub-id></mixed-citation>
    </ref>
    <ref id="ref8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gu</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Sun</surname><given-names>F.</given-names></name>, <name name-style="western"><surname>Qian</surname><given-names>L.</given-names></name> and <name name-style="western"><surname>Zhou</surname><given-names>G.</given-names></name></person-group> (<year>2017</year>) <article-title>Chemical-induced disease relation extraction via convolutional neural network</article-title>. <source>Database (Oxford)</source>, <volume>2017</volume>, <fpage>1</fpage>â<lpage>12</lpage>. doi: <pub-id pub-id-type="doi">10.1093/database/bax024</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref9">
      <label>9.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Goodfellow</surname><given-names>I.</given-names></name>, <name name-style="western"><surname>Bengio</surname><given-names>Y.</given-names></name> and <name name-style="western"><surname>Courville</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>) <source>Deep Learning</source>. <publisher-name>MIT Press</publisher-name>, <publisher-loc>Cambridge, MA, USA</publisher-loc><comment><ext-link ext-link-type="uri" xlink:href="http://www.deeplearningbook.org">http://www.deeplearningbook.org</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="ref10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Munkhdalai</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>F.</given-names></name> and <name name-style="western"><surname>Yu</surname><given-names>H.</given-names></name></person-group> (<year>2018</year>) <article-title>Clinical relation extraction toward drug safety surveillance using electronic health record narratives: classical learning versus deep learning</article-title>. <source>JMIR Public Health Surveill.</source>, <volume>4</volume>, <fpage>e29</fpage>. doi: <pub-id pub-id-type="doi">10.2196/publichealth.9361</pub-id>.<pub-id pub-id-type="pmid">29695376</pub-id></mixed-citation>
    </ref>
    <ref id="ref11">
      <label>11.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Huynh</surname><given-names>T.</given-names></name>, <name name-style="western"><surname>He</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Willis</surname><given-names>A.</given-names></name> and <name name-style="western"><surname>Rueger</surname><given-names>S.</given-names></name></person-group> (<year>2016</year>) <chapter-title>Adverse drug reaction classification with deep neural networks</chapter-title> In: <source>Proceedings of COLING 2016</source>.
<publisher-name>The COLING 2016 Organizing Committee</publisher-name>, <publisher-loc>Osaka, Japan</publisher-loc>, pp. <fpage>877</fpage>â<lpage>887</lpage>.</mixed-citation>
    </ref>
    <ref id="ref12">
      <label>12.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>C.</given-names></name> and <name name-style="western"><surname>Fan</surname><given-names>J.</given-names></name></person-group> (<year>2014</year>) <chapter-title>Medical relation extraction with manifold models</chapter-title> In: <source>Proceedings of the 52nd ACL</source>.
<publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Baltimore, Maryland</publisher-loc>, pp. <fpage>828</fpage>â<lpage>838</lpage>.</mixed-citation>
    </ref>
    <ref id="ref13">
      <label>13.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Howard</surname><given-names>J.</given-names></name> and <name name-style="western"><surname>Ruder</surname><given-names>S.</given-names></name></person-group> (<year>2018</year>) <chapter-title>Universal language model fine-tuning for text classification</chapter-title> In: <source>Proceedings of the 56th ACL</source>. <publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Melbourne, Australia</publisher-loc>, pp. <fpage>328</fpage>â<lpage>339</lpage>.</mixed-citation>
    </ref>
    <ref id="ref14">
      <label>14.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Donahue</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Jia</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Vinyals</surname><given-names>O.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2014</year>) <chapter-title>DeCAF: a deep convolutional activation feature for generic visual recognition</chapter-title> In: <source>Proceedings of the 31th ICML</source>.
<publisher-name>JMLR.org</publisher-name>, <publisher-loc>Beijing, China</publisher-loc>, pp. <fpage>647</fpage>â<lpage>655</lpage>.</mixed-citation>
    </ref>
    <ref id="ref15">
      <label>15.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Razavian</surname><given-names>A.S.</given-names></name>, <name name-style="western"><surname>Azizpour</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Sullivan</surname><given-names>J.</given-names></name> and <name name-style="western"><surname>Carlsson</surname><given-names>S.</given-names></name></person-group> (<year>2014</year>) <chapter-title>CNN features off-the-shelf: an astounding baseline for recognition</chapter-title> In: <source>Proceeding of CVPRW '14</source>. <publisher-name>IEEE Computer Society</publisher-name>, <publisher-loc>Washington, DC, USA</publisher-loc>, pp. <fpage>512</fpage>-<lpage>519</lpage>, doi: <pub-id pub-id-type="doi">10.1109/CVPRW.2014.131</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref16">
      <label>16.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Huang</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>Z.</given-names></name>, <name name-style="western"><surname>van der Maaten</surname><given-names>L.</given-names></name> and <name name-style="western"><surname>Weinberger</surname><given-names>K.Q.</given-names></name></person-group> (<year>2017</year>) <chapter-title>Densely connected convolutional networks</chapter-title> In: <source>Proceedings of CVPR</source>. <publisher-name>IEEE Computer Society</publisher-name>, <publisher-loc>Honolulu, HI, USA</publisher-loc>, pp. <fpage>2261</fpage>â<lpage>2269</lpage>, doi: <pub-id pub-id-type="doi">10.1109/CVPR.2017.243</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref17">
      <label>17.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Peters</surname><given-names>M.E.</given-names></name>, <name name-style="western"><surname>Neumann</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Iyyer</surname><given-names>M.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2018</year>) <chapter-title>Deep contextualized word representations</chapter-title> In: <source>Proceedings of NAACL-HLT</source>.
<publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>New Orleans, Louisiana</publisher-loc>, pp. <fpage>2227</fpage>â<lpage>2237</lpage>.</mixed-citation>
    </ref>
    <ref id="ref18">
      <label>18.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Devlin</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Chang</surname><given-names>M.W.</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>K.</given-names></name> and <name name-style="western"><surname>Toutanova</surname><given-names>K.</given-names></name></person-group> (<year>2018</year>) <chapter-title>BERT: pre-training of deep bidirectional transformers for language understanding</chapter-title> In: <source>arXiv preprint arXiv:181004805</source>. </mixed-citation>
    </ref>
    <ref id="ref19">
      <label>19.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Radford</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Narasimhan</surname><given-names>K.</given-names></name>, <name name-style="western"><surname>Salimans</surname><given-names>T.</given-names></name> and <name name-style="western"><surname>Sutskever</surname><given-names>I.</given-names></name></person-group> (<year>2018</year>) <source>Improving Language Understanding by Generative Pre-Training</source>. <ext-link ext-link-type="uri" xlink:href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="ref20">
      <label>20.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Radford</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Wu</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Child</surname><given-names>R.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2019</year>) <source>Language Models are Unsupervised Multitask Learners</source><comment>. <ext-link ext-link-type="uri" xlink:href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf</ext-link></comment>.</mixed-citation>
    </ref>
    <ref id="ref21">
      <label>21.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Wei</surname><given-names>C.</given-names></name>, <name name-style="western"><surname>Peng</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Leaman</surname><given-names>R.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2015</year>) <chapter-title>Overview of the BioCreative V chemical disease relation (CDR) task</chapter-title> In: <source>Proceedings of the Fifth BioCreative Challenge Evaluation Workshop</source>. <publisher-name>The Fifth BioCreative Organizing Committee</publisher-name>, pp. <fpage>154</fpage>â<lpage>166</lpage>.</mixed-citation>
    </ref>
    <ref id="ref22">
      <label>22.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Sun</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>R.J.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2015</year>) <chapter-title>Anotating chemicals, diseases and their interactions in biomedical literature</chapter-title> In: <source>Proceedings of the Fifth BioCreative Challenge Evaluation Workshop</source>. <publisher-name>The Fifth BioCreative Organizing Committee</publisher-name>, pp. <fpage>173</fpage>â<lpage>182</lpage>.</mixed-citation>
    </ref>
    <ref id="ref23">
      <label>23.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Leaman</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Dogan</surname><given-names>R.I.</given-names></name> and <name name-style="western"><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2013</year>) <article-title>DNorm: disease name normalization with pairwise learning to rank</article-title>. <source>Bioinformatics</source>, <volume>29</volume>, <fpage>2909</fpage>â<lpage>2917</lpage>.<pub-id pub-id-type="pmid">23969135</pub-id></mixed-citation>
    </ref>
    <ref id="ref24">
      <label>24.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Leaman</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Wei</surname><given-names>C.</given-names></name> and <name name-style="western"><surname>Lu</surname><given-names>Z.</given-names></name></person-group> (<year>2015</year>) <article-title>tmChem: a high perfor mance approach for chemical named entity recognition and normalization</article-title>. <source>Aust. J. Chem.</source>, <volume>7</volume>, <fpage>1</fpage>â<lpage>10</lpage>.</mixed-citation>
    </ref>
    <ref id="ref25">
      <label>25.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wan</surname><given-names>H.</given-names></name>, <name name-style="western"><surname>Moens</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Luyten</surname><given-names>W.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2016</year>) <article-title>Extracting relations from traditional Chinese medicine literature via heterogeneous entity networks</article-title>. <source>JAMIA</source>, <volume>23</volume>, <fpage>356</fpage>â<lpage>365</lpage>.<pub-id pub-id-type="pmid">26224335</pub-id></mixed-citation>
    </ref>
    <ref id="ref26">
      <label>26.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sun</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Rumshisky</surname><given-names>A.</given-names></name> and <name name-style="western"><surname>Uzuner</surname><given-names>O.</given-names></name></person-group> (<year>2013</year>) <article-title>Annotating temporal information in clinical narratives</article-title>. <source>J. Biomed. Inform.</source>, <volume>46</volume>, <fpage>S5</fpage>â<lpage>S12</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jbi.2013.07.004</pub-id>.<pub-id pub-id-type="pmid">23872518</pub-id></mixed-citation>
    </ref>
    <ref id="ref27">
      <label>27.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sun</surname><given-names>W.</given-names></name>, <name name-style="western"><surname>Rumshisky</surname><given-names>A.</given-names></name> and <name name-style="western"><surname>Uzuner</surname><given-names>O.</given-names></name></person-group> (<year>2013</year>) <article-title>Evaluating temporal relations in clinical text: 2012 i2b2 challenge</article-title>. <source>JAMIA</source>, <volume>20</volume>, <fpage>806</fpage>â<lpage>813</lpage>.<pub-id pub-id-type="pmid">23564629</pub-id></mixed-citation>
    </ref>
    <ref id="ref28">
      <label>28.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Recht</surname><given-names>B.</given-names></name>, <name name-style="western"><surname>Roelofs</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Schmidt</surname><given-names>L.</given-names></name> and <name name-style="western"><surname>Shankar</surname><given-names>V.</given-names></name></person-group> (<year>2018</year>) <chapter-title>Do CIFAR-10 classifiers generalize to CIFAR-10?</chapter-title> In: <source>arXiv preprint arXiv:1806.00451</source>. </mixed-citation>
    </ref>
    <ref id="ref29">
      <label>29.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kirkpatrick</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Pascanu</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Rabinowitz</surname><given-names>N.C.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2017</year>) <article-title>Overcoming catastrophic forgetting in neural networks</article-title>. <source>Proc. Natl. Acad. Sci. U. S. A.</source>, <volume>114</volume>, <fpage>3521</fpage>â<lpage>3526</lpage>.<pub-id pub-id-type="pmid">28292907</pub-id></mixed-citation>
    </ref>
    <ref id="ref30">
      <label>30.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Vaswani</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Shazeer</surname><given-names>N.</given-names></name>, <name name-style="western"><surname>Parmar</surname><given-names>N.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2017</year>) <chapter-title>Attention is all you need</chapter-title> In: <source>Proceedings of NeurIPS</source>. <publisher-name>Curran Associates, Inc.</publisher-name>, <publisher-loc>Long Beach, CA, USA</publisher-loc>, pp. <fpage>6000</fpage>â<lpage>6010</lpage>.</mixed-citation>
    </ref>
    <ref id="ref31">
      <label>31.</label>
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Wu</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Schuster</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>Z.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2016</year>) <chapter-title>Googleâs neural machine translation system: bridging the gap between human and machine translation</chapter-title> In: <source>arXiv preprint arXiv:1609.08144</source>. </mixed-citation>
    </ref>
    <ref id="ref32">
      <label>32.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Lan</surname><given-names>W.</given-names></name> and <name name-style="western"><surname>Xu</surname><given-names>W.</given-names></name></person-group> (<year>2018</year>) <chapter-title>Character-based neural networks for sentence pair modeling</chapter-title> In: <source>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT</source>.
<publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>New Orleans, Louisiana, USA</publisher-loc>, pp. <fpage>157</fpage>â<lpage>163</lpage>.</mixed-citation>
    </ref>
    <ref id="ref33">
      <label>33.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Sutskever</surname><given-names>I.</given-names></name>, <name name-style="western"><surname>Vinyals</surname><given-names>O.</given-names></name> and <name name-style="western"><surname>Le</surname><given-names>Q.V.</given-names></name></person-group> (<year>2014</year>) <chapter-title>Sequence to sequence learning with neural networks</chapter-title> In: <source>Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014</source>. <publisher-name>Curran Associates, Inc.</publisher-name>, <publisher-loc>Montreal, Quebec, Canada</publisher-loc>, pp. <fpage>3104</fpage>â<lpage>3112</lpage>.</mixed-citation>
    </ref>
    <ref id="ref34">
      <label>34.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Bowman</surname><given-names>S.R.</given-names></name>, <name name-style="western"><surname>Gauthier</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Rastogi</surname><given-names>A.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2016</year>) <chapter-title>A fast unified model for parsing and sentence understanding</chapter-title> In: <source>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016</source>.
<publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Berlin, Germany</publisher-loc>, pp. <fpage>1466</fpage>â<lpage>1477</lpage>.</mixed-citation>
    </ref>
    <ref id="ref35">
      <label>35.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Kim</surname><given-names>Y.</given-names></name></person-group> (<year>2014</year>) <chapter-title>Convolutional neural networks for sentence classification</chapter-title> In: <source>Proceedings of EMNLP 2014</source>.
<publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Doha, Qatar</publisher-loc>, pp. <fpage>1746</fpage>â<lpage>1751</lpage>.</mixed-citation>
    </ref>
    <ref id="ref36">
      <label>36.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Collobert</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Weston</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Bottou</surname><given-names>L.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2011</year>) <article-title>Natural language processing (almost) from scratch</article-title>. <source>J. Mach. Learn. Res.</source>, <volume>12</volume>, <fpage>2493</fpage>â<lpage>2537</lpage>.</mixed-citation>
    </ref>
    <ref id="ref37">
      <label>37.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Pennington</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Socher</surname><given-names>R.</given-names></name> and <name name-style="western"><surname>Manning</surname><given-names>C.D.</given-names></name></person-group> (<year>2014</year>) <chapter-title>GloVe: global vectors for word representation</chapter-title> In: <source>Proceedings of EMNLP 2014</source>.
<publisher-name>Association for Computational Linguistics</publisher-name>, pp. <fpage>1532</fpage>â<lpage>1543</lpage>.</mixed-citation>
    </ref>
    <ref id="ref38">
      <label>38.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Zhao</surname><given-names>Z.</given-names></name>, <name name-style="western"><surname>Hu</surname><given-names>R.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2018</year>) <chapter-title>Analogical reasoning on Chinese morphological and semantic relations</chapter-title> In: <source>Proceedings of the 56th ACL</source>.
<publisher-name>Association for Computational Linguistics</publisher-name>, pp. <fpage>138</fpage>â<lpage>143</lpage>.</mixed-citation>
    </ref>
    <ref id="ref39">
      <label>39.</label>
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Zhu</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>Kiros</surname><given-names>R.</given-names></name>, <name name-style="western"><surname>Zemel</surname><given-names>R.S.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2015</year>) <article-title>Aligning books and movies: towards story-like visual explanations by watching movies and reading books</article-title>. In: <source>Proceedings of ICCV 2015</source>. <publisher-name>IEEE Computer Society</publisher-name>, pp. <fpage>19</fpage>-<lpage>27</lpage>, doi: <pub-id pub-id-type="doi">10.1109/ICCV.2015.11</pub-id>.</mixed-citation>
    </ref>
    <ref id="ref40">
      <label>40.</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pons</surname><given-names>E.</given-names></name>, <name name-style="western"><surname>Becker</surname><given-names>B.F.H.</given-names></name>, <name name-style="western"><surname>Akhondi</surname><given-names>S.A.</given-names></name><etal>etÂ al.</etal></person-group> (<year>2016</year>) <article-title>Extraction of chemical-induced diseases using prior knowledge and textual information</article-title>. <source>Database (Oxford)</source>. <volume>2016</volume>, <fpage>1</fpage>â<lpage>8</lpage>.
doi: <pub-id pub-id-type="doi">10.1093/database/baw046</pub-id>.</mixed-citation>
    </ref>
  </ref-list>
</back>
