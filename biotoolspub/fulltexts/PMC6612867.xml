<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6612867</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btz364</article-id>
    <article-id pub-id-type="publisher-id">btz364</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Ismb/Eccb 2019 Conference Proceedings</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Macromolecular Sequence, Structure, and Function</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Adversarial domain adaptation for cross data source macromolecule <italic>in situ</italic> structural classification in cellular electron cryo-tomograms</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Lin</surname>
          <given-names>Ruogu</given-names>
        </name>
        <xref ref-type="aff" rid="btz364-aff1">1</xref>
        <xref ref-type="author-notes" rid="btz364-FM2"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zeng</surname>
          <given-names>Xiangrui</given-names>
        </name>
        <xref ref-type="aff" rid="btz364-aff1">1</xref>
        <xref ref-type="author-notes" rid="btz364-FM2"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kitani</surname>
          <given-names>Kris</given-names>
        </name>
        <xref ref-type="aff" rid="btz364-aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Xu</surname>
          <given-names>Min</given-names>
        </name>
        <xref ref-type="aff" rid="btz364-aff1">1</xref>
        <xref ref-type="corresp" rid="btz364-cor1"/>
        <!--<email>mxu1@cs.cmu.edu</email>-->
      </contrib>
    </contrib-group>
    <aff id="btz364-aff1"><label>1</label>Computational Biology Department, Carnegie Mellon University, Pittsburgh, PA, USA</aff>
    <aff id="btz364-aff2"><label>2</label>Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA</aff>
    <author-notes>
      <corresp id="btz364-cor1">To whom correspondence should be addressed. <email>mxu1@cs.cmu.edu</email></corresp>
      <fn id="btz364-FM2">
        <p>The authors wish it to be known that, in their opinion, the first two authors should be regarded as Joint First Authors.</p>
      </fn>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-07-05">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>35</volume>
    <issue>14</issue>
    <fpage>i260</fpage>
    <lpage>i268</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btz364.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Since 2017, an increasing amount of attention has been paid to the supervised deep learning-based macromolecule <italic>in situ</italic> structural classification (i.e. subtomogram classification) in cellular electron cryo-tomography (CECT) due to the substantially higher scalability of deep learning. However, the success of such supervised approach relies heavily on the availability of large amounts of labeled training data. For CECT, creating valid training data from the same data source as prediction data is usually laborious and computationally intensive. It would be beneficial to have training data from a separate data source where the annotation is readily available or can be performed in a high-throughput fashion. However, the cross data source prediction is often biased due to the different image intensity distributions (a.k.a. domain shift).</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We adapt a deep learning-based adversarial domain adaptation (3D-ADA) method to timely address the domain shift problem in CECT data analysis. 3D-ADA first uses a source domain feature extractor to extract discriminative features from the training data as the input to a classifier. Then it adversarially trains a target domain feature extractor to reduce the distribution differences of the extracted features between training and prediction data. As a result, the same classifier can be directly applied to the prediction data. We tested 3D-ADA on both experimental and realistically simulated subtomogram datasets under different imaging conditions. 3D-ADA stably improved the cross data source prediction, as well as outperformed two popular domain adaptation methods. Furthermore, we demonstrate that 3D-ADA can improve cross data source recovery of novel macromolecular structures.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>
          <ext-link ext-link-type="uri" xlink:href="https://github.com/xulabs/projects">https://github.com/xulabs/projects</ext-link>
        </p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">U.S. National Institutes of Health</named-content>
        </funding-source>
        <award-id>P41 GM103712</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Samuel and Emma Winters Foundation</named-content>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="9"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Nearly every major process in a cell is orchestrated by the interplay of macromolecules, which often coordinate their actions as functional modules in biochemical pathways. Capturing the information on the native macromolecular structures and spatial organizations within single cells is necessary for the accurate interpretation of cellular processes. However, such information has been extremely difficult to acquire due to the lack of suitable techniques. Only recently, the advancement of the cellular electron cryo-tomography (CECT) 3D imaging technique has enabled the visualization of the sub-cellular structural organization in near-native state at sub-molecular resolution (<xref rid="btz364-B22" ref-type="bibr">Lučić <italic>et al.</italic>, 2013</xref>). The advance of automatic image acquisition has made it possible for an electron microscope to capture hundreds of tomograms within several days, containing millions of structurally highly heterogeneous macromolecules (<xref rid="btz364-B28" ref-type="bibr">Oikonomou and Jensen, 2017</xref>). Each macromolecule is represented as a <italic>subtomogram</italic>, which is a cubic sub-volume enclosing the macromolecule extracted from a tomogram.</p>
    <p>Due to the structural complexity of macromolecules and imaging limitations (missing wedge effects) in CECT data, the systematic macromolecule structural recovery is very challenging. Efficient and accurate structural classification of at least millions of highly heterogeneous macromolecules is a key step for such structural recovery. Since 2017, a number of convolutional neural networks (CNN)-based supervised subtomogram classification methods have been proposed (<xref rid="btz364-B6" ref-type="bibr">Che <italic>et al.</italic>, 2018</xref>; <xref rid="btz364-B14" ref-type="bibr">Guo <italic>et al.</italic>, 2018a</xref>; <xref rid="btz364-B38" ref-type="bibr">Xu <italic>et al.</italic>, 2017</xref>). CNN has also been applied to other tomogram analysis tasks such as structural segmentation (<xref rid="btz364-B7" ref-type="bibr">Chen <italic>et al.</italic>, 2017</xref>; <italic>Liu et al.</italic>, <xref rid="btz364-B20" ref-type="bibr">2018a</xref>, <xref rid="btz364-B21" ref-type="bibr">b</xref>), pattern mining (<xref rid="btz364-B41" ref-type="bibr">Zeng <italic>et al.</italic>, 2018</xref>) and organelle detection (<xref rid="btz364-B18" ref-type="bibr">Li <italic>et al.</italic>, 2019</xref>). Although deep learning-based subtomogram classification significantly outperformed existing high-throughput coarse classification methods in terms of speed and accuracy, they rely heavily on large amounts of properly labeled subtomograms.</p>
    <p>In principle, it is feasible to label the training data through techniques such as template search (<xref rid="btz364-B2" ref-type="bibr">Beck <italic>et al.</italic>, 2009</xref>; <xref rid="btz364-B17" ref-type="bibr">Kunz <italic>et al.</italic>, 2015</xref>), unsupervised reference-free subtomogram classification (<xref rid="btz364-B1" ref-type="bibr">Bartesaghi <italic>et al.</italic>, 2008</xref>; <xref rid="btz364-B8" ref-type="bibr">Chen <italic>et al.</italic>, 2014</xref>; <xref rid="btz364-B37" ref-type="bibr">Xu <italic>et al.</italic>, 2012</xref>), correlated super-resolution imaging (<xref rid="btz364-B5" ref-type="bibr">Chang <italic>et al.</italic>, 2014</xref>; <xref rid="btz364-B16" ref-type="bibr">Johnson <italic>et al.</italic>, 2015</xref>) or structural pattern mining (<xref rid="btz364-B39" ref-type="bibr">Xu <italic>et al.</italic>, 2019</xref>). However, there are three main bottlenecks in the labeling process: (i) the aforementioned techniques are often computationally intensive, which may take weeks to complete, (ii) a substantial amount of manual quality control, including visual inspection and selection, is needed and (iii) most importantly, for each prediction dataset, a classification model needs to be trained using a valid training dataset from the <italic>same data source</italic> as the prediction dataset. Instead of preparing training data from the same data source, it would be beneficial to obtain training data from an independent data source preferably with labels readily available or can be prepared in an automatic and high-throughput fashion. Several independent data sources exist: (i) the electron cryo-tomograms of purified macromolecular complexes in which populations of macromolecules are already classified through biochemical means, (ii) simulated datasets, which provide an unlimited amount of data with fully automatic labeling and (iii) previously manually annotated datasets.</p>
    <p>The main issue of using training data from an independent source is that it leads to a distribution difference between training data and prediction data. In other words, subtomograms containing the same structure but captured from separate data sources often have different image intensity distributions, which depends spatially on the relative 3D location on the macromolecular structure. For example, as in <xref ref-type="fig" rid="btz364-F3">Figure 3</xref>, the same GroEL or CPSase under different imaging conditions appear differently. A classification model generally assumes the data distribution of training and prediction data to be identical (<xref rid="btz364-B34" ref-type="bibr">Tommasi <italic>et al.</italic>, 2016</xref>). The differences between training and prediction data distributions can severely bias the model prediction. This phenomenon is termed <italic>domain shift</italic>, and is defined to be differences between training and prediction data in the joint distribution of input and output variables (<xref rid="btz364-B31" ref-type="bibr">Quionero-Candela <italic>et al.</italic>, 2009</xref>).</p>
    <p>Formally, a <italic>domain</italic><inline-formula id="IE1"><mml:math id="IM1"><mml:mi mathvariant="double-struck">D</mml:mi></mml:math></inline-formula> consists of two components, data (a dataset of subtomograms in our case) and a marginal probability distribution that the data follows, denoted as <inline-formula id="IE2"><mml:math id="IM2"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. We refer to the dataset which labeled data are abundant as the <italic>source domain</italic><inline-formula id="IE3"><mml:math id="IM3"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and the dataset which labeled data are not available or very little as the <italic>target domain</italic><inline-formula id="IE4"><mml:math id="IM4"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. For our CECT structural classification, the training subtomograms are sampled from the source domain and the prediction subtomograms are sampled from the target domain.</p>
    <p>In this paper, we focus on a typical case of domain shift called <italic>covariate shift</italic> (<xref rid="btz364-B29" ref-type="bibr">Patel <italic>et al.</italic>, 2015</xref>). Let <italic>x</italic> denote a subtomogram and <italic>y</italic> denote the class label of <italic>x</italic>. <italic>Covariate shift</italic> occurs in prediction problems when <inline-formula id="IE5"><mml:math id="IM5"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>|</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> but <inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≠</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In other words, the conditional distribution of class labels <italic>y</italic> given subtomograms <italic>x</italic> is the same between source and target data, but the image intensity distributions between training and prediction subtomograms differ. This difference is primarily caused by different experimental conditions, such as resolution, defocus, spherical aberration and signal-to-noise ratio (SNR) (<xref ref-type="fig" rid="btz364-F3">Fig. 3</xref>). Covariate shift has to be taken into account for cross data source classification.</p>
    <p>We adapt an adversarial learning approach for domain adaptation (from <xref rid="btz364-B12" ref-type="bibr">Ganin <italic>et al.</italic>, 2016</xref>; <xref rid="btz364-B35" ref-type="bibr">Tzeng <italic>et al.</italic>, 2017</xref>). The method is named adversarial domain adaptation (3D-ADA) and is shown in <xref ref-type="fig" rid="btz364-F1">Figure 1</xref>. First, we train the combination of a source feature extractor <inline-formula id="IE7"><mml:math id="IM7"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and a subtomogram classifier <italic>C</italic> using labeled subtomograms from the source domain <inline-formula id="IE8"><mml:math id="IM8"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Next, we train a target feature extractor <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and map the target domain features into a latent space with the similar distribution as the source domain features, using both labeled subtomograms sampled from the source domain <inline-formula id="IE10"><mml:math id="IM10"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and unlabeled subtomograms sampled from the target domain <inline-formula id="IE11"><mml:math id="IM11"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. The mapping <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is learned using a domain discriminator <italic>D</italic> with an adversarial loss [<xref ref-type="disp-formula" rid="E1">Equations (1)</xref> and <xref ref-type="disp-formula" rid="E2">(2)]</xref>, which minimizes the domain discrepancy. The training is conducted in an <italic>adversarial</italic> fashion: (i) the training of <italic>F<sub>t</sub></italic> aims to fool <italic>D</italic> so that <italic>D</italic> cannot discriminate features produced by <italic>F<sub>t</sub></italic> from features produced by <italic>F<sub>s</sub></italic> (<xref ref-type="disp-formula" rid="E1">Equation (1)</xref>), (ii) the training of <italic>D</italic> aims to maximally discriminate features produced by <italic>F<sub>t</sub></italic> from features produced by <italic>F<sub>s</sub></italic> (<xref ref-type="disp-formula" rid="E2">Equation (2)</xref>). This learning approach is inspired by the Generative Adversarial Network (GAN) (<xref rid="btz364-B13" ref-type="bibr">Goodfellow <italic>et al.</italic>, 2014</xref>), which aims to confuse the discriminator <italic>D</italic> by generating images indistinguishable from the real ones. Different from GAN, 3D-ADA consists of <italic>feature extractors F<sub>s</sub></italic> and <italic>F<sub>t</sub></italic>, which are CNNs that map the input subtomograms into a low-dimensional feature space that are discriminative to the structural classes of the subtomograms. During the final classification, the trained target feature extractor <italic>F<sub>t</sub></italic> is used to extract features from subtomograms in the target domain <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and input the discriminative features into the macromolecule structural classifier <italic>C</italic> to perform prediction.
</p>
    <fig id="btz364-F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <p>An overview of the 3D-ADA framework. Those numbers in small white boxes are labels, including source subtomogram labels <italic>Y<sub>s</sub></italic>, target subtomogram labels <italic>Y<sub>t</sub></italic> and domain labels. Solid line arrays are inputs or outputs according to their directions. Dotted line arrays denote the training process here using the back-propagation algorithm</p>
      </caption>
      <graphic xlink:href="btz364f1"/>
    </fig>
    <p>We tested 3D-ADA on 10 realistically simulated subtomogram datasets and three experimental datasets under different imaging conditions. 3D-ADA stably improved the cross-domain prediction, as well as outperformed two popular domain adaptation methods, Direct Importance Estimation (IE) (<xref rid="btz364-B33" ref-type="bibr">Sugiyama <italic>et al.</italic>, 2008</xref>) and Structural Correspondence Learning (SC) (<xref rid="btz364-B4" ref-type="bibr">Blitzer <italic>et al.</italic>, 2006</xref>). Furthermore, we demonstrate that 3D-ADA can also improve the cross data source structural recovery of novel macromolecules unseen in the training data.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <p>We have source domain subtomograms <inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (i.e. 3D gray scale images of size <inline-formula id="IE15"><mml:math id="IM15"><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>), represented as 3D arrays of <inline-formula id="IE16"><mml:math id="IM16"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi><mml:mo>×</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. The source domain labels <inline-formula id="IE17"><mml:math id="IM17"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are each represented as a binary array <inline-formula id="IE18"><mml:math id="IM18"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mi>l</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, where <italic>l</italic> is the number of macromolecular structure classes in the source domain. We also have target domain subtomograms <inline-formula id="IE19"><mml:math id="IM19"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and their labels <inline-formula id="IE20"><mml:math id="IM20"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, in the same form as the source domain ones, respectively. <italic>Y<sub>t</sub></italic> is unknown and to be predicted after the domain adaptation.</p>
    <p>Source feature extractor <italic>F<sub>s</sub></italic> and classifier <italic>C</italic> are first trained using back-propagation on <italic>X<sub>s</sub></italic> and <italic>Y<sub>s</sub></italic> and using the standard cross-entropy as loss function. Next, we perform domain adaptation through adversarial training. <xref ref-type="fig" rid="btz364-F1">Figure 1</xref> shows our whole ADA method. The neural network models of <italic>F<sub>s</sub></italic>, <italic>F<sub>t</sub></italic>, <italic>C</italic>, <italic>D</italic> are illustrated in <xref ref-type="fig" rid="btz364-F2">Figure 2</xref>. Specifically, we use the domain discriminator <italic>D</italic>, to classify the domain of the input data based on the extracted features. For <italic>D</italic>, the source domain label is set as 0 and target domain label is set as 1. <italic>F<sub>t</sub></italic> is initialized as a copy of the trained <italic>F<sub>s</sub></italic>. We then fix <italic>F<sub>s</sub></italic> and iteratively update <italic>F<sub>t</sub></italic> and <italic>D</italic> alternatively according to:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"/><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>F</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo> </mml:mo><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"/><mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mrow><mml:mi>min</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:munder><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"/><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo> </mml:mo><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo> </mml:mo><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p>
    <fig id="btz364-F2" orientation="portrait" position="float">
      <label>Fig. 2.</label>
      <caption>
        <p>Architectures of neural networks used in 3D-ADA. The networks include multiple layers which are represented by boxes in this figure and all of them are trainable. The type of layer and its critical parameters are shown in boxes. For example, ‘8−5×5×5−1 Conv’ denotes a 3D convolutional layer with eight 5×5×5 filters and stride of 1. It should be noted that ‘FC-L’ denotes a fully connected layer with L units, where L is the number of classes in datasets. These layers are defined similar to <xref rid="btz364-B41" ref-type="bibr">Zeng <italic>et al.</italic> (2018)</xref>. Input and output of each module: for examples: input of <italic>F<sub>s</sub></italic> and <italic>F<sub>t</sub></italic> as subtomogram, input to <italic>C</italic> as features and output of <italic>C</italic> as structural classes, input to <italic>D</italic> as features, output of <italic>D</italic> as domains</p>
      </caption>
      <graphic xlink:href="btz364f2"/>
    </fig>
    <p><italic>D</italic> and <italic>F<sub>t</sub></italic> are trained in an adversarial fashion. Specifically, <xref ref-type="disp-formula" rid="E1">Equation (1)</xref> aims at training <inline-formula id="IE21"><mml:math id="IM21"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> to trick the discriminator <italic>D</italic>. Clearly, <inline-formula id="IE22"><mml:math id="IM22"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>F</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> will decrease when more target domain features are labeled close to 0 by <italic>D</italic>, so that it makes target domain features extracted by <inline-formula id="IE23"><mml:math id="IM23"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> more possible to be regarded as source domain features by <italic>D</italic>. By contrast, <xref ref-type="disp-formula" rid="E2">Equation (2)</xref> aims at training a discriminative <italic>D</italic> to separate from target domain features from source domain features. <inline-formula id="IE24"><mml:math id="IM24"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> will decrease when more source domain features are labeled close to 0 and more target domain features are labeled close to 1 by <italic>D</italic>. The ultimate goal of the adversarial training is to extract features invariant to domain change by the target feature extractor <italic>F<sub>t</sub></italic>. Ideally, in the ADA stage, the target feature extractor <italic>F<sub>t</sub></italic> should be trained to have the domain discriminator <italic>D</italic> has accuracy close to 0.5, meaning <italic>D</italic> is completely fooled by the domain invariant features extracted by <italic>F<sub>t</sub></italic>. 3D-ADA does not directly apply a min–max game in optimization as performed in the standard GANs (<xref rid="btz364-B13" ref-type="bibr">Goodfellow <italic>et al.</italic>, 2014</xref>). The model is optimized by splitting a min–max loss into two independent losses, one for the <italic>F<sub>t</sub></italic> and one for <italic>D</italic>. The 3D-ADA method is shown in Algorithm 1.</p>
    <p>After the ADA using Algorithm 1, the trained <italic>F<sub>t</sub></italic> is used to calculate <inline-formula id="IE25"><mml:math id="IM25"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> for estimating <italic>Y<sub>t</sub></italic>, where <inline-formula id="IE26"><mml:math id="IM26"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is predicted structure class labels <italic>Y<sub>t</sub></italic> of <italic>X<sub>t</sub></italic>. Because after domain adaptation, the distribution difference between <inline-formula id="IE27"><mml:math id="IM27"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE28"><mml:math id="IM28"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is reduced, <italic>C</italic> can be directly applied to <inline-formula id="IE29"><mml:math id="IM29"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to calculate <inline-formula id="IE30"><mml:math id="IM30"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>Y</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, with reduced biases from domain shift.
</p>
    <p>
      <boxed-text id="btz364-BOX1" position="float" orientation="portrait">
        <label>Algorithm 1</label>
        <caption>
          <p> Adversarial domain adaptation training</p>
        </caption>
        <p>
          <bold>Input:</bold>
        </p>
        <p> Set of subtomograms from source domain: <inline-formula id="IE31"><mml:math id="IM31"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></p>
        <p> Set of subtomograms from target domain: <inline-formula id="IE32"><mml:math id="IM32"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></p>
        <p> Domain labels: <inline-formula id="IE33"><mml:math id="IM33"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE34"><mml:math id="IM34"><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula></p>
        <p> Trained source feature extractor: <inline-formula id="IE35"><mml:math id="IM35"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></p>
        <p>
          <bold>Output:</bold>
        </p>
        <p> Trained domain discriminator: <italic>D</italic></p>
        <p> Trained target feature extractor: <inline-formula id="IE36"><mml:math id="IM36"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></p>
        <p> 1:  <bold>for</bold><italic>n</italic> training iterations <bold>do</bold></p>
        <p> 2:   <bold>for</bold><italic>k</italic> steps <bold>do</bold></p>
        <p> 3:    Sample minibatch of <italic>m</italic> samples <inline-formula id="IE37"><mml:math id="IM37"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mi>m</mml:mi></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> from <inline-formula id="IE38"><mml:math id="IM38"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p>
        <p> 4:    Sample minibatch of <italic>m</italic> samples <inline-formula id="IE39"><mml:math id="IM39"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>m</mml:mi></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> from <inline-formula id="IE40"><mml:math id="IM40"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p>
        <p> 5:    Update <italic>D</italic> by ascending stochastic gradient of <italic>L<sub>D</sub></italic>, with <italic>F<sub>t</sub></italic> fixed:
<disp-formula id="E3"><mml:math id="M3"><mml:mrow><mml:msub><mml:mrow><mml:mo>▽</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mi>D</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mrow><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p> 6:   Sample minibatch of <italic>m</italic> target samples <inline-formula id="IE41"><mml:math id="IM41"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>m</mml:mi></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> from <inline-formula id="IE42"><mml:math id="IM42"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p>
        <p> 7:   Update <inline-formula id="IE43"><mml:math id="IM43"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> by descending stochastic gradient of <italic>L<sub>F</sub></italic> with the <italic>D</italic> fixed:
<disp-formula id="E4"><mml:math id="M4"><mml:mrow><mml:msub><mml:mrow><mml:mo>▽</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mfrac><mml:mn>1</mml:mn><mml:mi>m</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:mrow><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mtext>log</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p>
        <p> 8:  <bold>return</bold><italic>D</italic>, <inline-formula id="IE44"><mml:math id="IM44"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></p>
      </boxed-text>
    </p>
    <p>The rationale behind using two training stages, one for extracting source features and the other for extracting target features invariant to domain change, is that we use the first stage to guarantee that features informative for classification is extracted. Intuitively, for subtomogram classification, if the two stages are trained simultaneously, the model could stuck in the local optimum that identical non-informative features are extracted to make the discriminator <italic>D</italic> completely fooled. However, such identical but non-informative features are useless for the classification in the target domain.</p>
    <p>Compared to the original ADA method (<xref rid="btz364-B12" ref-type="bibr">Ganin <italic>et al.</italic>, 2016</xref>), we have several modifications:
<list list-type="bullet"><list-item><p>We extended the 2D CNNs to 3D, and designed new 3D network architectures for CECT data.</p></list-item><list-item><p>We use two feature extractors <italic>F<sub>s</sub></italic> and <italic>F<sub>t</sub></italic> to extract features from <italic>X<sub>s</sub></italic> and <italic>X<sub>t</sub></italic> separately [similar to <xref rid="btz364-B35" ref-type="bibr">Tzeng <italic>et al.</italic> (2017)</xref>] instead of a single one for both <italic>X<sub>s</sub></italic> and <italic>X<sub>t</sub></italic>. The independent <inline-formula id="IE45"><mml:math id="IM45"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for target data enables the target domain feature to be more flexible and robust.</p></list-item><list-item><p>The adversarial loss function [<xref ref-type="disp-formula" rid="E1">Equations (1)</xref> and <xref ref-type="disp-formula" rid="E2">(2)</xref>] is gradient forwarded. The adversarial loss uses the proper domain supervision information for both <italic>D</italic> and <inline-formula id="IE46"><mml:math id="IM46"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> training that avoids gradient vanish in back-propagation, thus the model is less likely to stuck in local minimum.</p></list-item></list></p>
    <p>The details of the two baseline methods, Direct IE (<xref rid="btz364-B33" ref-type="bibr">Sugiyama <italic>et al.</italic>, 2008</xref>) and SC (<xref rid="btz364-B4" ref-type="bibr">Blitzer <italic>et al.</italic>, 2006</xref>), can be found in <xref ref-type="supplementary-material" rid="sup1">Supplementary Data</xref>.</p>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Simulated datasets</title>
      <p>We generated two simulated dataset batches, denoted as dataset batch A and B (<italic>S<sub>A</sub></italic> and <italic>S<sub>B</sub></italic>). The two dataset batches differ in imaging parameters. Each batch contains five datasets of different SNR levels. Within each dataset, we simulated 23 000 subtomograms containing 23 structural classes.</p>
      <p>The subtomogram datasets are realistically simulated by approximating the true CECT image reconstruction process similar to many previous works (<xref rid="btz364-B9" ref-type="bibr">Förster <italic>et al.</italic>, 2008</xref>; <xref rid="btz364-B37" ref-type="bibr">Xu <italic>et al.</italic>, 2012</xref>). Tomographic noise, missing wedges and electron optical factors, including the Contrast Transfer Function (CTF) and Modulation Transfer Function (MTF), were properly included, based on the assumption that macromolecular complexes have an electron optical density in proportion to the electrostatic potential. The PDB2VOL program from the Situs (<xref rid="btz364-B36" ref-type="bibr">Wriggers <italic>et al.</italic>, 1999</xref>) package was used to generate subtomograms of 40<sup>3</sup> voxels. The voxel spacing was defined to be 0.92 nm, the same as in experimental dataset <inline-formula id="IE47"><mml:math id="IM47"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> in Section 3.2 and the resolution was also defined at 0.92 nm. Electron micrographic images were simulated based on the density maps adopted from Protein Data Bank (PBD), through a tilt angle of <inline-formula id="IE48"><mml:math id="IM48"><mml:mrow><mml:mo>±</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>60</mml:mn></mml:mrow></mml:mrow><mml:mo>°</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. Noise was added to electron micrograph images (<xref rid="btz364-B9" ref-type="bibr">Förster <italic>et al.</italic>, 2008</xref>) corresponding to different SNR levels, including the estimated SNRs from experimental data (Section 3.2). Optical effects were simulated by convolving the electron micrograph images the CTF and MTF (<xref rid="btz364-B10" ref-type="bibr">Frank, 2006</xref>; <xref rid="btz364-B26" ref-type="bibr">Nickell <italic>et al.</italic>, 2005</xref>), with acquisition parameters similar to typical experimental tomograms (dataset <inline-formula id="IE49"><mml:math id="IM49"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> in Section 3.2).</p>
      <p>Twenty-two representative macromolecular complexes (details in <xref ref-type="supplementary-material" rid="sup1">Supplementary Data</xref>) are collected from the PDB (<xref rid="btz364-B3" ref-type="bibr">Berman <italic>et al.</italic>, 2000</xref>). Inside each dataset, for each complex, we generated 1000 simulated subtomograms, each containing a randomly rotated and translated macromolecule. Furthermore, we also simulated 1000 subtomograms that contain no macromolecule. As a result, one dataset contains 23 000 simulated subtomograms of 23 structural classes including the NULL class.</p>
      <p>The two dataset batches each containing multiple datasets of different SNR levels (1000, 0.5, 0.1, 0.05, 0.03). The SNR of experimental datasets in Section 3.2 ranged from 0.01 to 0.5. Since we simulated 23 000 subtomograms within each SNR batch, in total there are 115 000 subtomograms in each batch. For <italic>S<sub>A</sub></italic>, we use the spherical aberration of 2 mm, defocus of −5 <italic>μ</italic>m and voltage of 300 kV. For <italic>S<sub>B</sub></italic>, we use the spherical aberration of 2.2 mm, defocus of −10 <italic>μ</italic>m and voltage of 300 kV. These parameters are assigned with typical values used in real CECT imaging (<xref rid="btz364-B39" ref-type="bibr">Xu <italic>et al.</italic>, 2019</xref>; <xref rid="btz364-B40" ref-type="bibr">Zeev-Ben-Mordehai <italic>et al.</italic>, 2016</xref>; <xref rid="btz364-B41" ref-type="bibr">Zeng <italic>et al.</italic>, 2018</xref>). Dataset batch B has a higher contrast than dataset batch A because of its significantly higher defocus in magnitude. The MTF in our simulation is defined as <inline-formula id="IE50"><mml:math id="IM50"><mml:mrow><mml:mi>sinc</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>π</mml:mo><mml:mo>ω</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> where <italic>ω</italic> is the fraction of the Nyquist frequency, a realistic detector (<xref rid="btz364-B25" ref-type="bibr">McMullan <italic>et al.</italic>, 2009</xref>). To construct the final subtomogram, a direct Fourier inversion reconstruction algorithm [implemented in the EMAN2 library (<xref rid="btz364-B11" ref-type="bibr">Galaz-Montoya <italic>et al.</italic>, 2015</xref>)] is used to produce the simulated subtomogram from the tilt series <inline-formula id="IE51"><mml:math id="IM51"><mml:mrow><mml:mo>±</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>60</mml:mn></mml:mrow></mml:mrow><mml:mo>°</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. <xref ref-type="fig" rid="btz364-F3">Figure 3</xref> shows examples of simulated subtomograms of two datasets batched with different SNRs.
</p>
      <fig id="btz364-F3" orientation="portrait" position="float">
        <label>Fig. 3.</label>
        <caption>
          <p>Left: Isosurfaces of GroEL (PDB ID: 1KP8) and carbamoyl phosphate synthetase (PDB ID: 1BXR). Right: Center slices (x–z plane) of subtomograms from dataset batches A and B with different SNR levels</p>
        </caption>
        <graphic xlink:href="btz364f3"/>
      </fig>
      <sec>
        <title>3.1.1 Results on simulated data</title>
        <p>We compared the macromolecule structural classification performance using dataset batch B (<italic>S<sub>B</sub></italic>) as training data and dataset batch A (<italic>S<sub>A</sub></italic>) as prediction data. Without domain adaptation, the prediction is calculated by <inline-formula id="IE52"><mml:math id="IM52"><mml:mrow><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. With domain adaptation, the prediction is calculated by <inline-formula id="IE53"><mml:math id="IM53"><mml:mrow><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> using <italic>F<sub>t</sub></italic> optimized using Algorithm 1.</p>
        <p>The macromolecule structural classification accuracy is shown in <xref rid="btz364-T1" ref-type="table">Table 1</xref>. The accuracy is defined as the ratio of numbers of correctly classified samples to numbers of all samples. We also show the result of baseline methods IE and SC (details in <xref ref-type="supplementary-material" rid="sup1">Supplementary Data</xref>) performing the same tasks. In each cell, from top to bottom, the results displayed are accuracy without domain adaptation, IE accuracy, SC accuracy and 3D-ADA accuracy. The highest one is highlighted. The 3D-ADA framework achieved the highest accuracy in 24 of the 25 experiments. In addition, we discussed the impact of data augmentation on the prediction accuracy in <xref ref-type="supplementary-material" rid="sup1">Supplementary Data</xref>.</p>
        <table-wrap id="btz364-T1" orientation="portrait" position="float">
          <label>Table 1.</label>
          <caption>
            <p>Accuracy on simulated datasets</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="2" colspan="1">Accuracy</th>
                <th colspan="6" rowspan="1">SNR of target domain (<italic>S<sub>A</sub></italic>)<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1">1000</th>
                <th rowspan="1" colspan="1">0.5</th>
                <th rowspan="1" colspan="1">0.1</th>
                <th rowspan="1" colspan="1">0.05</th>
                <th rowspan="1" colspan="1">0.03</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="4" colspan="1">SNR of source domain (<italic>S<sub>B</sub></italic>)</td>
                <td rowspan="4" colspan="1">1000</td>
                <td rowspan="1" colspan="1">0.855</td>
                <td rowspan="1" colspan="1">0.687</td>
                <td rowspan="1" colspan="1">0.385</td>
                <td rowspan="1" colspan="1">0.235</td>
                <td rowspan="1" colspan="1">0.157</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.739</td>
                <td rowspan="1" colspan="1">0.620</td>
                <td rowspan="1" colspan="1">0.287</td>
                <td rowspan="1" colspan="1">0.159</td>
                <td rowspan="1" colspan="1">0.111</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.760</td>
                <td rowspan="1" colspan="1">0.638</td>
                <td rowspan="1" colspan="1">0.289</td>
                <td rowspan="1" colspan="1">0.162</td>
                <td rowspan="1" colspan="1">0.114</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>0.991</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.923</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.737</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.499</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.326</bold>
                </td>
              </tr>
              <tr>
                <td colspan="7" rowspan="1"/>
              </tr>
              <tr>
                <td rowspan="4" colspan="1"/>
                <td rowspan="4" colspan="1">0.5</td>
                <td rowspan="1" colspan="1">0.779</td>
                <td rowspan="1" colspan="1">0.757</td>
                <td rowspan="1" colspan="1">0.547</td>
                <td rowspan="1" colspan="1">0.366</td>
                <td rowspan="1" colspan="1">0.258</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.806</td>
                <td rowspan="1" colspan="1">0.710</td>
                <td rowspan="1" colspan="1">0.479</td>
                <td rowspan="1" colspan="1">0.372</td>
                <td rowspan="1" colspan="1">0.291</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.819</td>
                <td rowspan="1" colspan="1">0.723</td>
                <td rowspan="1" colspan="1">0.486</td>
                <td rowspan="1" colspan="1">0.373</td>
                <td rowspan="1" colspan="1">0.291</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>0.978</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.970</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.835</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.628</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.464</bold>
                </td>
              </tr>
              <tr>
                <td colspan="7" rowspan="1"/>
              </tr>
              <tr>
                <td rowspan="4" colspan="1"/>
                <td rowspan="4" colspan="1">0.1</td>
                <td rowspan="1" colspan="1">0.902</td>
                <td rowspan="1" colspan="1">0.922</td>
                <td rowspan="1" colspan="1">0.894</td>
                <td rowspan="1" colspan="1">0.726</td>
                <td rowspan="1" colspan="1">0.503</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.864</td>
                <td rowspan="1" colspan="1">0.881</td>
                <td rowspan="1" colspan="1">0.776</td>
                <td rowspan="1" colspan="1">0.637</td>
                <td rowspan="1" colspan="1">0.475</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>0.905</bold>
                </td>
                <td rowspan="1" colspan="1">0.920</td>
                <td rowspan="1" colspan="1">0.826</td>
                <td rowspan="1" colspan="1">0.650</td>
                <td rowspan="1" colspan="1">0.479</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.894</td>
                <td rowspan="1" colspan="1">
                  <bold>0.932</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.901</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.760</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.626</bold>
                </td>
              </tr>
              <tr>
                <td colspan="7" rowspan="1"/>
              </tr>
              <tr>
                <td rowspan="4" colspan="1"/>
                <td rowspan="4" colspan="1">0.05</td>
                <td rowspan="1" colspan="1">0.946</td>
                <td rowspan="1" colspan="1">0.950</td>
                <td rowspan="1" colspan="1">0.911</td>
                <td rowspan="1" colspan="1">0.766</td>
                <td rowspan="1" colspan="1">0.563</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.937</td>
                <td rowspan="1" colspan="1">0.929</td>
                <td rowspan="1" colspan="1">0.897</td>
                <td rowspan="1" colspan="1">0.758</td>
                <td rowspan="1" colspan="1">0.575</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.948</td>
                <td rowspan="1" colspan="1">0.951</td>
                <td rowspan="1" colspan="1">0.907</td>
                <td rowspan="1" colspan="1">0.774</td>
                <td rowspan="1" colspan="1">0.583</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>0.967</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.971</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.928</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.825</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.628</bold>
                </td>
              </tr>
              <tr>
                <td colspan="7" rowspan="1"/>
              </tr>
              <tr>
                <td rowspan="3" colspan="1"/>
                <td rowspan="3" colspan="1">0.03</td>
                <td rowspan="1" colspan="1">0.938</td>
                <td rowspan="1" colspan="1">0.924</td>
                <td rowspan="1" colspan="1">0.903</td>
                <td rowspan="1" colspan="1">0.844</td>
                <td rowspan="1" colspan="1">0.704</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.903</td>
                <td rowspan="1" colspan="1">0.891</td>
                <td rowspan="1" colspan="1">0.864</td>
                <td rowspan="1" colspan="1">0.775</td>
                <td rowspan="1" colspan="1">0.609</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.907</td>
                <td rowspan="1" colspan="1">0.893</td>
                <td rowspan="1" colspan="1">0.865</td>
                <td rowspan="1" colspan="1">0.778</td>
                <td rowspan="1" colspan="1">0.613</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1"/>
                <td rowspan="1" colspan="1">
                  <bold>0.976</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.972</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.952</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.891</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.773</bold>
                </td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <p><italic>Note:</italic> In each cell, from top to bottom, the results displayed are accuracy without domain adaptation, IE accuracy, SC accuracy and 3D-ADA accuracy. The highest one is highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <table-wrap id="btz364-T2" orientation="portrait" position="float">
          <label>Table 2.</label>
          <caption>
            <p> Accuracy of experimental subtomograms classification</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Accuracy</th>
                <th colspan="5" rowspan="1">SNR of source domain<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1">Dataset</th>
                <th rowspan="1" colspan="1">1000</th>
                <th rowspan="1" colspan="1">0.5</th>
                <th rowspan="1" colspan="1">0.1</th>
                <th rowspan="1" colspan="1">0.05</th>
                <th rowspan="1" colspan="1">0.03</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="2" colspan="1">
                  <inline-formula id="IE54">
                    <mml:math id="IM54">
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>S</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>e</mml:mi>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </td>
                <td rowspan="1" colspan="1">0.375</td>
                <td rowspan="1" colspan="1">0.313</td>
                <td rowspan="1" colspan="1">0.465</td>
                <td rowspan="1" colspan="1">0.331</td>
                <td rowspan="1" colspan="1">0.566</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>0.578</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.641</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.563</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.584</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.606</bold>
                </td>
              </tr>
              <tr>
                <td colspan="6" rowspan="1"/>
              </tr>
              <tr>
                <td rowspan="2" colspan="1">
                  <inline-formula id="IE55">
                    <mml:math id="IM55">
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>S</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>e</mml:mi>
                            <mml:mn>2</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </td>
                <td rowspan="1" colspan="1">0.400</td>
                <td rowspan="1" colspan="1">0.370</td>
                <td rowspan="1" colspan="1">0.311</td>
                <td rowspan="1" colspan="1">0.308</td>
                <td rowspan="1" colspan="1">0.336</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>0.495</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.469</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.471</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.450</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.377</bold>
                </td>
              </tr>
              <tr>
                <td colspan="6" rowspan="1"/>
              </tr>
              <tr>
                <td rowspan="2" colspan="1">
                  <inline-formula id="IE56">
                    <mml:math id="IM56">
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>S</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>e</mml:mi>
                            <mml:mn>3</mml:mn>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </td>
                <td rowspan="1" colspan="1">0.313</td>
                <td rowspan="1" colspan="1">0.376</td>
                <td rowspan="1" colspan="1">0.375</td>
                <td rowspan="1" colspan="1">0.372</td>
                <td rowspan="1" colspan="1">0.375</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>0.688</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.656</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.625</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.621</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.624</bold>
                </td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn2">
              <p><italic>Note:</italic> In each cell, the upper and lower numbers denote classification before and after 3D-ADA, respectively. The highest one is highlighted in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <title>3.1.2 Result visualization</title>
        <p>We visualize some of the results. Using subtomograms at SNR 0.1 in <italic>S<sub>B</sub></italic> as source and subtomograms at SNR 0.05 in <italic>S<sub>A</sub></italic> as the target, we randomly picked 100 samples in each target domain data class (2300 picked in total) to avoid crowdedness in the visualization. In <xref ref-type="fig" rid="btz364-F4">Figure 4</xref>, we use T-SNE (<xref rid="btz364-B23" ref-type="bibr">Maaten and Hinton, 2008</xref>) to visualize their distribution before and after 3D-ADA. <xref ref-type="fig" rid="btz364-F4">Figure 4</xref> shows that, after 3D-ADA, structural classes become significantly more separable.
</p>
        <fig id="btz364-F4" orientation="portrait" position="float">
          <label>Fig. 4.</label>
          <caption>
            <p>T-SNE embedding: target domain class prediction. Each dot represents a sample and its color represents its true class: (<bold>a</bold>) before 3D-ADA and (<bold>b</bold>) after 3D-ADA</p>
          </caption>
          <graphic xlink:href="btz364f4"/>
        </fig>
        <p>The confusion matrices of the macromolecule structural classification results before and after 3D-ADA are shown in <xref ref-type="fig" rid="btz364-F5">Figure 5</xref>. Clearly, after 3D-ADA, the misclassification rate is significantly reduced as the confusion matrix diagonal becomes darker after domain adaptation.
</p>
        <fig id="btz364-F5" orientation="portrait" position="float">
          <label>Fig. 5.</label>
          <caption>
            <p>Confusion matrices of target domain class predictions: (<bold>a</bold>) before 3D-ADA and (<bold>b</bold>) after 3D-ADA. Each row represents the predicted class of an instance while each column represents the true class. The darker the cells are, the larger proportion of samples are predicted to be the specific class. A perfect classification will show a black diagonal with all cells on it having a value of 1.0</p>
          </caption>
          <graphic xlink:href="btz364f5"/>
        </fig>
      </sec>
    </sec>
    <sec>
      <title>3.2 Experimental datasets</title>
      <p>We further tested the 3D-ADA on three experimental datasets <inline-formula id="IE57"><mml:math id="IM57"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>.</p>
      <p>For <inline-formula id="IE58"><mml:math id="IM58"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, the experimental tomograms contain purified human 20S proteasome and <italic>Escherichia coli</italic> ribosome obtained through similar data generation procedure as in <xref rid="btz364-B40" ref-type="bibr">Zeev-Ben-Mordehai <italic>et al.</italic> (2016)</xref>. To separate structures of trimeric conformations in native membrane-anchored full-length herpes simplex virus 1 glycoprotein B, imaging parameters have been successfully optimized and applied (<xref rid="btz364-B40" ref-type="bibr">Zeev-Ben-Mordehai <italic>et al.</italic>, 2016</xref>). Specifically, Cryo-Electron Microscopy was performed at 300 keV using a TF30 ‘Polara’ electron microscope (FEI). The microscope was operated in zero-loss imaging mode with a 20-eV energy-selecting slit, using a Quantum postcolumn energy filter (Gatan). Images were recorded using a post-filter <inline-formula id="IE59"><mml:math id="IM59"><mml:mo>≈</mml:mo></mml:math></inline-formula>4000 × 4000 K2-summit direct electron detector (Gatan). The detector was operated in counting mode with dose fractionation. A calibrated pixel size of 0.23 nm was adopted at the specimen level. Tilt series data were collected using SerialEM (<xref rid="btz364-B24" ref-type="bibr">Mastronarde, 2005</xref>) at defocus ranges of −6 to −5 <italic>μ</italic>m. To have stable defocus during data collection, the auto-focusing routine was iterated through the tilt series with 100 nm accuracy. Finally, tomograms were reconstructed by the weighted back-projection in IMOD program (<xref rid="btz364-B32" ref-type="bibr">Sandberg <italic>et al.</italic>, 2003</xref>). Then, the reconstructed tomograms were four times binned to result in a voxel spacing of 0.92 nm.</p>
      <p>From three tomograms, we extracted a total of 4019 subtomograms of 36<sup>3</sup> voxels. For each tomogram, we extracted subtomograms by performing template-free particle picking in a similar way to <xref rid="btz364-B30" ref-type="bibr">Pei <italic>et al.</italic> (2016)</xref>. To extract the subtomograms, the tomograms were convolved with the 3D difference of a Gaussian, with scaling factor <inline-formula id="IE60"><mml:math id="IM60"><mml:mrow><mml:mo>σ</mml:mo><mml:mo>=</mml:mo></mml:mrow></mml:math></inline-formula>5 nm and scaling factor ratio <italic>K </italic>=<italic> </italic>1.1. The extracted subtomograms were smoothed by convolving with a Gaussian kernel of <italic>σ</italic> = 2 nm. We manually selected 100 ribosome subtomograms and 100 proteasomes, both with high confidence of their structure identity. In addition, we selected 100 subtomograms of NULL classes by randomly sampling the non-structural area of experimental tomograms. As shown in <xref ref-type="fig" rid="btz364-F6">Figure 6</xref>, the experimental subtomograms has very low SNR (0.01) and thus highly challenging to classify. The templates were obtained from generating 4 nm resolution density maps from the PDB structures using the PDB2VOL program (<xref rid="btz364-B36" ref-type="bibr">Wriggers <italic>et al.</italic>, 1999</xref>). Then, they were properly convolved with the CTF according to the imaging parameters. The templates are used to construct simulation datasets with labels as training datasets (source domain <inline-formula id="IE61"><mml:math id="IM61"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>).
</p>
      <fig id="btz364-F6" orientation="portrait" position="float">
        <label>Fig. 6.</label>
        <caption>
          <p>The 2D slices of example subtomogram in each class in dataset <inline-formula id="IE62"><mml:math id="IM62"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula></p>
        </caption>
        <graphic xlink:href="btz364f6"/>
      </fig>
      <p>Similarly, <inline-formula id="IE63"><mml:math id="IM63"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> contains 240 subtomograms, consisting of 80 ribosome subtomograms, 80 TRiC subtomograms and 80 proteasome subtomograms of size 40<sup>3</sup> voxels with voxel spacing 1.368 nm. The subtomograms are manually extracted from a rat neuron tomogram (<xref rid="btz364-B15" ref-type="bibr">Guo <italic>et al.</italic>, 2018b</xref>). The tilt angle range was <inline-formula id="IE64"><mml:math id="IM64"><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>50</mml:mn></mml:mrow></mml:mrow><mml:mo>°</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> to <inline-formula id="IE65"><mml:math id="IM65"><mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>70</mml:mn></mml:mrow></mml:mrow><mml:mo>°</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. The structural templates were obtained using PDB structures 4GU0 (human 80s ribosome), 4V94 (eukaryotic chaperonin TRiC) and 6EPF (26S proteasome). The templates are used to construct simulation datasets with labels as training datasets (source domain <inline-formula id="IE66"><mml:math id="IM66"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>).</p>
      <p><inline-formula id="IE67"><mml:math id="IM67"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> contains 400 hemagglutinin subtomograms, 400 apoferritin subtomograms and 400 insulin receptor subtomograms of size 28<sup>3</sup> voxels with voxel spacing 0.94 nm from a single particle dataset (<xref rid="btz364-B27" ref-type="bibr">Noble <italic>et al.</italic>, 2018</xref>). The tilt angle range was <inline-formula id="IE68"><mml:math id="IM68"><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>60</mml:mn></mml:mrow></mml:mrow><mml:mo>°</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> to <inline-formula id="IE69"><mml:math id="IM69"><mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>60</mml:mn></mml:mrow></mml:mrow><mml:mo>°</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. The subtomograms are extracted using the difference of Gaussian particle-picking algorithm and manually annotated. The structural templates were obtained using PDB structures 3LZG (virus hemagglutinin), 4V1W (horse spleen apoferritin) and 4ZXB (human insulin receptor). The templates are used to construct simulation datasets with labels as training datasets (source domain <inline-formula id="IE70"><mml:math id="IM70"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">D</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>).</p>
    </sec>
    <sec>
      <title>3.3 3D-ADA classifications on experimental data</title>
      <p>Based on different classes of macromolecules in different experimental dataset, we follow the simulation process mentioned in Section 3.2 to make their own source dataset.</p>
      <p>For each training dataset, we simulated 3000 subtomograms for the source domain. The classification result is shown in <xref rid="btz364-T2" ref-type="table">Table 2</xref>. Since the classification of experimental subtomograms is very hard due to the high noise level and structural complexity, the classification accuracy before domain adaptation is virtually close to random guess (0.33). In all the experiments, 3D-ADA substantially increased the classification accuracy. How to choose the optimal simulation parameters to construct source dataset, especially structural templates and SNR, is still an open problem. Since when classifying an experimental subtomogram dataset, the data acquisition experimental conditions such as spherical aberration and defocus are known, we recommend the users to simulate training dataset with the same experimental condition parameters to reduce the domain shift between simulated source dataset and experimental target dataset. In terms of SNR, the simulated training dataset should have similar or slightly lower SNR as compared to the experimental dataset to be classified. However, the users should be aware that when the SNR of the training dataset is too low such as 0.001, the source dataset classifier training may not converge due to the strong influence of noise.</p>
      <p>We note here that in simulated dataset <italic>S<sub>A</sub></italic> and <italic>S<sub>B</sub></italic>, the number of subtomograms in the source domain and target domain is the same, 23 000. However, in practice, the number of subtomograms in the experimental datasets may be smaller. In our experiments on experimental data, there are 3000 subtomograms in the simulated source domain whereas the number of subtomograms in the experimental datasets varies from 240 to 300 to 1200. Although the number of subtomograms in the experimental target domain is significantly decreased, our 3D-ADA is still effective as shown in <xref rid="btz364-T2" ref-type="table">Table 2</xref>.</p>
      <p>We applied a weighted subtomogram averaging algorithm (<xref rid="btz364-B37" ref-type="bibr">Xu <italic>et al.</italic>, 2012</xref>) to recover the structure in <inline-formula id="IE71"><mml:math id="IM71"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> based on the classification label before and after domain adaptation (<xref ref-type="fig" rid="btz364-F7">Fig. 7</xref>). The ground truth is obtained based on the true subtomogram labels. Although the apoferritin structure is successfully recovered even before using domain adaptation probably due to its strong signal and rotational symmetry, the hemagglutinin structure and the insulin receptor structure do not recover well using the classification label before the domain adaptation. By contrast, after 3D-ADA, we are able better recover the hemagglutinin structure and the insulin receptor structure. We note that the subtomogram number in <inline-formula id="IE72"><mml:math id="IM72"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE73"><mml:math id="IM73"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is too low to recover the structure.
</p>
      <fig id="btz364-F7" orientation="portrait" position="float">
        <label>Fig. 7.</label>
        <caption>
          <p>Recovered structures in S<sub>e3</sub> based on the classification label. Three structures: (<bold>a</bold>) Hemagglutinin, (<bold>b</bold>) Apoferritin, (<bold>c</bold>) Insulin receptor</p>
        </caption>
        <graphic xlink:href="btz364f7"/>
      </fig>
    </sec>
    <sec>
      <title>3.4 Improvement of novel structure detection and recovery</title>
      <p>Since the majority of macromolecular structures are still unknown, detecting novel structures in CECT is a key step to advance our <italic>in situ</italic> structural biology knowledge. Previously, we have demonstrated that even if prediction subtomograms contain unseen structural classes that do not exist in the training data, the unseen classes still tend to form clusters after being projected into the latent feature space using the trained feature extractor (<xref rid="btz364-B38" ref-type="bibr">Xu <italic>et al.</italic>, 2017</xref>). Since the detection of novel structures depends on the extraction of important discriminative structural features, we investigate the novel structure detection when there is a covariate shift between source and target domains. We use subtomograms simulated at SNR 1000 in dataset batch B as <italic>X<sub>s</sub></italic> and subtomograms simulated at SNR 0.5 in dataset batch A as <italic>X<sub>t</sub></italic>. We removed all subtomograms of a particular structural class (RNA polymerase, PDB ID: 2GHO) from the training data. Denote the set of RNA polymerase subtomograms and their corresponding class labels in source and target domains as <inline-formula id="IE75"><mml:math id="IM74"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mtext>RP</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mtext>RP</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mtext>RP</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE76"><mml:math id="IM75"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mtext>RP</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, respectively. We train <italic>F<sub>s</sub></italic> and <italic>C</italic> using <inline-formula id="IE77"><mml:math id="IM76"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>∖</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mtext>RP</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE78"><mml:math id="IM77"><mml:mrow><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>∖</mml:mo><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mtext>RP</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>, then obtain optimized <italic>F<sub>t</sub></italic> by applying the domain adaptation Algorithm 1 to <inline-formula id="IE79"><mml:math id="IM78"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>∖</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mtext>RP</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>∖</mml:mo><mml:msubsup><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mtext>RP</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE80"><mml:math id="IM79"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>∖</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mtext>RP</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula>. Then we used T-SNE to further embed <inline-formula id="IE81"><mml:math id="IM80"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE82"><mml:math id="IM81"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> into <inline-formula id="IE83"><mml:math id="IM82"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> to visualize the projected prediction samples before and after domain adaptation. Denote <inline-formula id="IE84"><mml:math id="IM83"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mo>-</mml:mo><mml:mtext>SNE</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> as the T-SNE embedding. It can be seen from <xref ref-type="fig" rid="btz364-F8">Figure 8</xref> that the after domain adaption case, <inline-formula id="IE85"><mml:math id="IM84"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mo>-</mml:mo><mml:mtext>SNE</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mtext>RP</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, is significantly better clustered than the before domain adaptation case, <inline-formula id="IE86"><mml:math id="IM85"><mml:mrow><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mo>-</mml:mo><mml:mtext>SNE</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mtext>RP</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.
</p>
      <fig id="btz364-F8" orientation="portrait" position="float">
        <label>Fig. 8.</label>
        <caption>
          <p>Subtomograms in the target domain projected to the structural feature space. The RNA polymerase (PDB ID: 2GHO) subtomograms which are removed from training process were highlighted in red: (<bold>a</bold>) before 3D-ADA and (<bold>b</bold>) after 3D-ADA</p>
        </caption>
        <graphic xlink:href="btz364f8"/>
      </fig>
      <p>Moreover, we demonstrate for the cross-domain recovery of novel structures unseen in the training data. The extracted features are clustered into 100 clusters using k-means clustering. Then we applied a weighted subtomogram averaging algorithm (<xref rid="btz364-B37" ref-type="bibr">Xu <italic>et al.</italic>, 2012</xref>) to recover the structure in each cluster. The recovered structures were manually matched to the 22 classes (including the novel one). To measure the structural discrepancy, we use the Fourier Shell Correlation (resolution) with 0.5 cutoff to show the maximal structural factors that are discrepant between the true structure and the recovered structure (<xref rid="btz364-B19" ref-type="bibr">Liao and Frank, 2010</xref>). <xref ref-type="fig" rid="btz364-F9">Figure 9</xref> shows examples of recovered structures and the novel structure RNA polymerase (2GHO) is successfully recovered with structural discrepancy 4.19 nm. To compare, the recovery of RNA polymerase before domain adaptation is 4.84 nm. Overall, the structural discrepancy of recovered structures before domain adaptation has mean value of 5.42 nm with a standard deviation of 1.28 nm. By contrast, the structural discrepancy after 3D-ADA has mean value improved to 5.17 nm with a standard deviation of 1.27 nm.
</p>
      <fig id="btz364-F9" orientation="portrait" position="float">
        <label>Fig. 9.</label>
        <caption>
          <p>Structural recovery results. The underlying true structure is on the left and the recovered structure is on the right. The number in the parentheses denotes the structural discrepancy</p>
        </caption>
        <graphic xlink:href="btz364f9"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>Macromolecules are nano-machines that arguably govern cellular processes. In recent years, CECT has emerged as the most promising technique for the systematic and <italic>in situ</italic> detection of the native structure and spatial organization of macromolecules inside single cells. However, CECT analysis is very difficult due to the large data quantity, high level of structural complexity and imaging limitations in CECT data. High-throughput subtomogram classification is a key step in reducing structural complexity. Nevertheless, existing unsupervised subtomogram classification approaches either have limited accuracy or speed to process millions of structurally highly heterogeneous macromolecules available in a CECT dataset. Deep learning-based supervised subtomogram classification (e.g. <xref rid="btz364-B38" ref-type="bibr">Xu <italic>et al.</italic>, 2017</xref>) potentially makes a powerful technique for the large-scale subtomogram classification with significantly improved speed and accuracy. But the successful training of such methods often require a large amount of structurally annotated subtomograms, which is generally laborious and computationally expensive to obtain from the same tomogram dataset. Therefore, it would be very beneficial to conduct the training using training data collected from a separate data source and annotated in a high-throughput fashion. In order to do so, the domain shift problem must be overcome as it is likely to significantly bias the results in the cross data source prediction setting.</p>
    <p>We adapt an ADA framework for structural classification of macromolecules captured by CECT. Combining 3D CNNs and adversarial learning, 3D-ADA maps subtomograms into a latent space shareable between separate domains to obtain a robust model for cross data source macromolecular structural classification. Moreover, 3D-ADA can be easily extended to utilize multiple CECT training data sources by training multiple source domain feature extractors.</p>
    <p>Most traditional domain adaptation methods aim to minimize some metric of domain shift such as maximum mean discrepancy or correlation distances. Other methods try to reconstruct the target domain from the source representation. Compared with those traditional methods, the ADA has the following advantages for CECT data:
<list list-type="bullet"><list-item><p>Using deep learning techniques, 3D-ADA allows large-scale training with large amounts of prediction data.</p></list-item><list-item><p>Instead of using fixed features, the feature extractor is trainable and the domain adaptation is incorporated into the training process. The final classification is performed on adapted features that tend to be discriminative with respect to structural classes and invariant with respect to domains.</p></list-item><list-item><p>Using the back-propagation algorithm, 3D-ADA is constructed as end-to-end feed-forward networks, improving over the isolated domain adaptation steps.</p></list-item></list></p>
    <p>Our tests showed that our 3D-ADA significantly improved cross data source subtomogram classification, and it outperformed two classical domain adaptation methods. 3D-ADA can also potentially be useful for cross data source detection novel macromolecular structures.</p>
    <p>This work represents an important step towards fully utilizing the power of deep learning for large-scale subtomogram classification. The optimal CNN models and training strategies for more accurate domain adaptation remain to be explored.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btz364_Supplementary_Data</label>
      <media xlink:href="btz364_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We thank Dr Tzviya Zeev-Ben-Mordehai and Dr Qiang Guo for sharing the experimental tomograms. We thank Ziqian Lin for helping with conducting experiments. We thank Kevin Wang for helping with English editing.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported in part by the U.S. National Institutes of Health (NIH) grant P41 GM103712. M.X. acknowledge support from Samuel and Emma Winters Foundation. X.Z. was supported by a fellowship from Carnegie Mellon University's Center for Machine Learning and Health.</p>
      <p><italic>Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btz364-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bartesaghi</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>Classification and 3D averaging with missing wedge correction in biological electron tomography</article-title>. <source>J. Struct. Biol</source>., <volume>162</volume>, <fpage>436</fpage>–<lpage>450</lpage>.<pub-id pub-id-type="pmid">18440828</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Beck</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Visual proteomics of the human pathogen <italic>Leptospira interrogans</italic></article-title>. <source>Nat. Methods</source>, <volume>6</volume>, <fpage>817</fpage>–<lpage>823</lpage>.<pub-id pub-id-type="pmid">19838170</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Berman</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2000</year>) 
<article-title>The protein data bank</article-title>. <source>Nucleic Acids Res</source>., <volume>28</volume>, <fpage>235.</fpage><pub-id pub-id-type="pmid">10592235</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B4">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Blitzer</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) Domain adaptation with structural correspondence learning. In: <italic>Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</italic>, pp. <fpage>120</fpage>–<lpage>128</lpage>. Association for Computational Linguistics, Sydney, Australia.</mixed-citation>
    </ref>
    <ref id="btz364-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chang</surname><given-names>Y.-W.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Correlated cryogenic photoactivated localization microscopy and cryo-electron tomography</article-title>. <source>Nat. Methods</source>, <volume>11</volume>, <fpage>737</fpage>–<lpage>739</lpage>.<pub-id pub-id-type="pmid">24813625</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Che</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Improved deep learning-based macromolecules structure classification from electron cryo-tomograms</article-title>. <source>Mach. Vision Appl</source>., <volume>29</volume>, <fpage>1227</fpage>–<lpage>1236</lpage>.</mixed-citation>
    </ref>
    <ref id="btz364-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Convolutional neural networks for automated annotation of cellular cryo-electron tomograms</article-title>. <source>Nat. Methods</source>, <volume>14</volume>, <fpage>983.</fpage><pub-id pub-id-type="pmid">28846087</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Autofocused 3D classification of cryoelectron subtomograms</article-title>. <source>Structure</source>, <volume>22</volume>, <fpage>1528</fpage>–<lpage>1537</lpage>.<pub-id pub-id-type="pmid">25242455</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Förster</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>Classification of cryo-electron sub-tomograms using constrained correlation</article-title>. <source>J. Struct. Biol</source>., <volume>161</volume>, <fpage>276</fpage>–<lpage>286</lpage>.<pub-id pub-id-type="pmid">17720536</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B10">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Frank</surname><given-names>J.</given-names></name></person-group> (<year>2006</year>) <source>Three-Dimensional Electron Microscopy of Macromolecular Assemblies</source>. 
<publisher-name>Oxford University Press</publisher-name>, 
<publisher-loc>New York</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btz364-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Galaz-Montoya</surname><given-names>J.G.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Single particle tomography in eman2</article-title>. <source>J. Struct. Biol</source>., <volume>190</volume>, <fpage>279</fpage>–<lpage>290</lpage>.<pub-id pub-id-type="pmid">25956334</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ganin</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Domain-adversarial training of neural networks</article-title>. <source>J. Mach. Learn. Res</source>., <volume>17</volume>, <fpage>2096</fpage>–<lpage>2030</lpage>.</mixed-citation>
    </ref>
    <ref id="btz364-B13">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Goodfellow</surname><given-names>I.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) <chapter-title>Generative adversarial nets</chapter-title> In: <source>Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014</source>, December 8–13, 2014. Montreal, Quebec, Canada, pp. <fpage>2672</fpage>–<lpage>2680</lpage>.</mixed-citation>
    </ref>
    <ref id="btz364-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Guo</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2018a</year>) Model compression for faster structural separation of macromolecules captured by cellular electron cryo-tomography. In <italic>International Conference Image Analysis and Recognition</italic>, pp. <fpage>144</fpage>–<lpage>152</lpage>. Springer, Póvoa de Varzim, Portugal.</mixed-citation>
    </ref>
    <ref id="btz364-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Guo</surname><given-names>Q.</given-names></name></person-group><etal>et al</etal> (<year>2018b</year>) 
<article-title>In situ structure of neuronal c9orf72 Poly-Ga aggregates reveals proteasome recruitment</article-title>. <source>Cell</source>, <volume>172</volume>, <fpage>696</fpage>–<lpage>705</lpage>.<pub-id pub-id-type="pmid">29398115</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Johnson</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Correlative in-resin super-resolution and electron microscopy using standard fluorescent proteins</article-title>. <source>Sci. Rep</source>., <volume>5</volume>, <fpage>9583</fpage>.<pub-id pub-id-type="pmid">25823571</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kunz</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>M-free: mask-independent scoring of the reference bias</article-title>. <source>J. Struct. Biol</source>., <volume>192</volume>, <fpage>307</fpage>–<lpage>311</lpage>.<pub-id pub-id-type="pmid">26325584</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>Automatic localization and identification of mitochondria in cellular electron cryo-tomography using faster-RCNN</article-title>. <source>BMC bioinformatics</source>, <volume>20</volume>, <fpage>132</fpage>.<pub-id pub-id-type="pmid">30925860</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liao</surname><given-names>H.Y.</given-names></name>, <name name-style="western"><surname>Frank</surname><given-names>J.</given-names></name></person-group> (<year>2010</year>) 
<article-title>Definition and estimation of resolution in single-particle reconstructions</article-title>. <source>Structure</source>, <volume>18</volume>, <fpage>768</fpage>–<lpage>775</lpage>.<pub-id pub-id-type="pmid">20637413</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B20">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2018a</year>) Deep learning based supervised semantic segmentation of electron cryo-subtomograms. In <italic>IEEE International Conference on Image Processing</italic>, pp. <fpage>1578</fpage>–<lpage>1582</lpage>, ICIP, Athens, Greece.</mixed-citation>
    </ref>
    <ref id="btz364-B21">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2018b</year>) Multi-task learning for macromolecule classification, segmentation and coarse structural recovery in cryo-tomography. In: <italic>British Machine Vision Conference</italic>, BMVC, p. <fpage>271</fpage>, North Umbria University, Newcastle, UK.</mixed-citation>
    </ref>
    <ref id="btz364-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lučić</surname><given-names>V.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>Cryo-electron tomography: the challenge of doing structural biology in situ</article-title>. <source>J. Cell Biol</source>., <volume>202</volume>, <fpage>407</fpage>–<lpage>419</lpage>.<pub-id pub-id-type="pmid">23918936</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Maaten</surname><given-names>L.V.D.</given-names></name>, <name name-style="western"><surname>Hinton</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>) 
<article-title>Visualizing data using T-SNE</article-title>. <source>J. Mach. Learn. Res</source>., <volume>9</volume>, <fpage>2579</fpage>–<lpage>2605</lpage>.</mixed-citation>
    </ref>
    <ref id="btz364-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mastronarde</surname><given-names>D.N.</given-names></name></person-group> (<year>2005</year>) 
<article-title>Automated electron microscope tomography using robust prediction of specimen movements</article-title>. <source>J. Struct. Biol</source>., <volume>152</volume>, <fpage>36</fpage>–<lpage>51</lpage>.<pub-id pub-id-type="pmid">16182563</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>McMullan</surname><given-names>G.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Detective quantum efficiency of electron area detectors in electron microscopy</article-title>. <source>Ultramicroscopy</source>, <volume>109</volume>, <fpage>1126</fpage>–<lpage>1143</lpage>.<pub-id pub-id-type="pmid">19497671</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Nickell</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2005</year>) 
<article-title>TOM software toolbox: acquisition and analysis for electron tomography</article-title>. <source>J. Struct. Biol</source>., <volume>149</volume>, <fpage>227</fpage>–<lpage>234</lpage>.<pub-id pub-id-type="pmid">15721576</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Noble</surname><given-names>A.J.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Reducing effects of particle adsorption to the air–water interface in cryo-em</article-title>. <source>Nat. Methods</source>, <volume>15</volume>, <fpage>793.</fpage><pub-id pub-id-type="pmid">30250056</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Oikonomou</surname><given-names>C.M.</given-names></name>, <name name-style="western"><surname>Jensen</surname><given-names>G.J.</given-names></name></person-group> (<year>2017</year>) 
<article-title>Cellular electron cryotomography: toward structural biology in situ</article-title>. <source>Annu. Rev. Biochem</source>., <volume>86</volume>, <fpage>873</fpage>–<lpage>896</lpage>.<pub-id pub-id-type="pmid">28426242</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Patel</surname><given-names>V.M.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Visual domain adaptation: a survey of recent advances</article-title>. <source>IEEE Signal Process. Mag</source>., <volume>32</volume>, <fpage>53</fpage>–<lpage>69</lpage>.</mixed-citation>
    </ref>
    <ref id="btz364-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pei</surname><given-names>L.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Simulating cryo electron tomograms of crowded cell cytoplasm for assessment of automated particle picking</article-title>. <source>BMC Bioinform</source>., <volume>17</volume>, <fpage>405.</fpage></mixed-citation>
    </ref>
    <ref id="btz364-B31">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Quionero-Candela</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) <source>Dataset Shift in Machine Learning</source>. 
<publisher-name>The MIT Press</publisher-name>, 
<publisher-loc>Cambridge, MA</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btz364-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sandberg</surname><given-names>K.</given-names></name></person-group><etal>et al</etal> (<year>2003</year>) 
<article-title>A fast reconstruction algorithm for electron microscope tomography</article-title>. <source>J. Struct. Biol</source>., <volume>144</volume>, <fpage>61</fpage>–<lpage>72</lpage>.<pub-id pub-id-type="pmid">14643209</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Sugiyama</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) 
<article-title>Direct importance estimation for covariate shift adaptation</article-title>. <source>Ann. Inst. Stat. Math</source>., <volume>60</volume>, <fpage>699</fpage>–<lpage>746</lpage>.</mixed-citation>
    </ref>
    <ref id="btz364-B34">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Tommasi</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) Learning the roots of visual domain shift. In: <italic>European Conference on Computer Vision</italic>, pp. <fpage>475</fpage>–<lpage>482</lpage>. Springer, Amsterdam, The Netherlands.</mixed-citation>
    </ref>
    <ref id="btz364-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tzeng</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) <chapter-title>Adversarial discriminative domain adaptation</chapter-title> In: <source>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2017)</source>, Honolulu, HI, USA, July 21–26, 2017. Vol. <volume>1</volume>, p. <fpage>4</fpage>.</mixed-citation>
    </ref>
    <ref id="btz364-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wriggers</surname><given-names>W.</given-names></name></person-group><etal>et al</etal> (<year>1999</year>) 
<article-title>Situs: a package for docking crystal structures into low-resolution maps from electron microscopy</article-title>. <source>J. Struct. Biol</source>., <volume>125</volume>, <fpage>185</fpage>–<lpage>195</lpage>.<pub-id pub-id-type="pmid">10222274</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xu</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>High-throughput subtomogram alignment and classification by Fourier space constrained fast volumetric matching</article-title>. <source>J. Struct. Biol</source>., <volume>178</volume>, <fpage>152</fpage>–<lpage>164</lpage>.<pub-id pub-id-type="pmid">22420977</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xu</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Deep learning-based subdivision approach for large scale macromolecules structure recovery from electron cryo tomograms</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>i13</fpage>–<lpage>i22</lpage>.<pub-id pub-id-type="pmid">28881965</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Xu</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>De novo structural pattern mining in cellular electron cryo-tomograms</article-title>. <source>Structure</source>, <volume>27</volume>, <fpage>679</fpage>–<lpage>691.e14</lpage>.<pub-id pub-id-type="pmid">30744995</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zeev-Ben-Mordehai</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Two distinct trimeric conformations of natively membrane-anchored full-length herpes simplex virus 1 glycoprotein b</article-title>. <source>Proc. Natl. Acad. Sci. USA</source>, <volume>113</volume>, <fpage>4176</fpage>–<lpage>4181</lpage>.<pub-id pub-id-type="pmid">27035968</pub-id></mixed-citation>
    </ref>
    <ref id="btz364-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zeng</surname><given-names>X.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>A convolutional autoencoder approach for mining features in cellular electron cryo-tomograms and weakly supervised coarse segmentation</article-title>. <source>J. Struct. Biol</source>., <volume>202</volume>, <fpage>150</fpage>–<lpage>160</lpage>.<pub-id pub-id-type="pmid">29289599</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
