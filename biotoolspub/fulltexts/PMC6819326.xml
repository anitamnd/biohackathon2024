<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6819326</article-id>
    <article-id pub-id-type="publisher-id">3157</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-019-3157-y</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Methodology Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>PPR-SSM: personalized PageRank and semantic similarity measures for entity linking</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7965-6536</contrib-id>
        <name>
          <surname>Lamurias</surname>
          <given-names>Andre</given-names>
        </name>
        <address>
          <email>alamurias@lasige.di.fc.ul.pt</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ruas</surname>
          <given-names>Pedro</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Couto</surname>
          <given-names>Francisco M.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2181 4263</institution-id><institution-id institution-id-type="GRID">grid.9983.b</institution-id><institution>LASIGE, Departamento de Informática, Faculdade de Ciências, Universidade de Lisboa, </institution></institution-wrap>Lisboa, 749-016 Portugal </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>29</day>
      <month>10</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>29</day>
      <month>10</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>20</volume>
    <elocation-id>534</elocation-id>
    <history>
      <date date-type="received">
        <day>17</day>
        <month>4</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>10</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2019</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Biomedical literature concerns a wide range of concepts, requiring controlled vocabularies to maintain a consistent terminology across different research groups. However, as new concepts are introduced, biomedical literature is prone to ambiguity, specifically in fields that are advancing more rapidly, for example, drug design and development. Entity linking is a text mining task that aims at linking entities mentioned in the literature to concepts in a knowledge base. For example, entity linking can help finding all documents that mention the same concept and improve relation extraction methods. Existing approaches focus on the local similarity of each entity and the global coherence of all entities in a document, but do not take into account the semantics of the domain.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">We propose a method, PPR-SSM, to link entities found in documents to concepts from domain-specific ontologies. Our method is based on Personalized PageRank (PPR), using the relations of the ontology to generate a graph of candidate concepts for the mentioned entities. We demonstrate how the knowledge encoded in a domain-specific ontology can be used to calculate the coherence of a set of candidate concepts, improving the accuracy of entity linking. Furthermore, we explore weighting the edges between candidate concepts using semantic similarity measures (SSM). We show how PPR-SSM can be used to effectively link named entities to biomedical ontologies, namely chemical compounds, phenotypes, and gene-product localization and processes.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">We demonstrated that PPR-SSM outperforms state-of-the-art entity linking methods in four distinct gold standards, by taking advantage of the semantic information contained in ontologies. Moreover, PPR-SSM is a graph-based method that does not require training data. Our method improved the entity linking accuracy of chemical compounds by 0.1385 when compared to a method that does not use SSMs.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Ontologies</kwd>
      <kwd>Text mining</kwd>
      <kwd>Entity linking</kwd>
      <kwd>Biomedical literature</kwd>
      <kwd>ChEBI</kwd>
      <kwd>HPO</kwd>
      <kwd>GO</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2019</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p>Entity linking matches each entity mention in a document to an entry of a knowledge base (KB) that unequivocally represents that concept [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. This task is a fundamental component of text mining systems, in order to integrate the information described in the literature across multiple documents [<xref ref-type="bibr" rid="CR3">3</xref>]. Entity linking has been applied to accomplish various objectives, for example, to link persons to their family members [<xref ref-type="bibr" rid="CR4">4</xref>], to enrich a domain-specific KBs with information from Wikipedia tables [<xref ref-type="bibr" rid="CR5">5</xref>], or to link events described in tweets [<xref ref-type="bibr" rid="CR6">6</xref>]. Entity linking is fundamental to real-world text mining applications where the same concept may be referred to in different spellings and lexical variations across various documents. Due to the diverse nomenclature of biomedical entities, it is often a challenge to match these to KB entries. While several biomedical Named Entity Recognition (NER) approaches have been developed to recognize, for example, genes, drugs and diseases entities in documents [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>], fewer approaches exist to link these entities to a KB, given its higher complexity.</p>
    <p>Entity linking can be incorporated into a NER system to perform both tasks at once. For example, by directly matching a list of concept names and synonyms from a controlled vocabulary to the text, it is possible to directly obtain the respective identifiers. However, this approach will be restricted to the names and synonyms considered in the KB, even when string matching algorithms can be used to deal with misspellings and other lexical variations. As most state-of-the-art NER systems are based on machine learning algorithms, they focus on recognizing segments of text that refer to entities of interest, requiring an additional method to match each named entity to a KB. Entity linking can also be modeled as a ranking task, where a list of candidate matches of an entity is ordered from highest to lowest confidence level. The input data consists of a graph, where nodes represent associations between named entities and candidate matches obtained from the KB. The edges represent links between concepts found in an external database. The objective of this approach is to select the set of candidate matches that maximizes the global coherence between entities.</p>
    <p>In biomedicine, ontologies are commonly used to organize knowledge about a specific domain, providing a formal representation of concepts and their relations according to the domain. As such, they can be used as reference KBs for text mining tasks such as entity linking [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR10">10</xref>]. For example, an ontology enables us to calculate the semantic similarity between two concepts and compare which concepts have more in common. Therefore, this source of information can be incorporated into entity linking approaches to improve their performance.</p>
    <p>The Human Phenotype Ontology (HPO) [<xref ref-type="bibr" rid="CR11">11</xref>] provides a standardized vocabulary to describe phenotypic variations in human disease which can be used by computational applications. This ontology was first released in 2008, originally composed by 8000 concepts, with the latest version containing 11,000 concepts. Figure <xref rid="Fig1" ref-type="fig">1</xref>a shows an excerpt of this ontology, with focus on the ancestors of the concept “Bilateral vestibular Schwannoma” (HP:0009589). The arrows describe <italic>is-a</italic> relations, providing a detailed classification of each concept. Chemical Entities of Biological Interest (ChEBI) contains over 46,000 molecular entities, with each entity being organized in an ontology structure [<xref ref-type="bibr" rid="CR12">12</xref>]. The ChEBI ontology contains <italic>is-a</italic> relations, but also other types of relations such as <italic>has part</italic>, <italic>has role</italic>, and chemistry specific relations such as <italic>is conjugate base of</italic> and <italic>is tautomer of</italic>. Figure <xref rid="Fig1" ref-type="fig">1</xref>b shows the closest <italic>is-a</italic> ascendants of the ChEBI concept “biliverdin (2-)”.
<fig id="Fig1"><label>Fig. 1</label><caption><p>Excerpts of the ontologies used in this work. Arrows indicate <italic>is-a</italic> relations. Each concept may have more than one ancestor as well as multiple descendants. <bold>a</bold> HPO; <bold>b</bold> ChEBI</p></caption><graphic xlink:href="12859_2019_3157_Fig1_HTML" id="MO1"/></fig>
</p>
    <p>Entity linking is a challenging task for biomedical literature when compared to other domains. For example, while there is no exact match for "iron chloride" in ChEBI, a database of chemical entities with biological interest [<xref ref-type="bibr" rid="CR13">13</xref>], there are 157 abstracts on PubMed that match that exact string at the time we were writing this manuscript. These cases are problematic to automatic approaches because the entity string itself is ambiguous, requiring more advanced approaches to resolve this ambiguity. According to the Human Phenotype Ontology (HPO), dyschromatopsia and color-blindness refer to the same phenotype. Therefore a search for one of those names should retrieve documents that also mention the other one. Another example, a protein may be mentioned by its full name or by an acronym; in this case, the normalization process should assign the same identifier to both occurrences. To properly perform biomedical entity linking, it is necessary to account for these issues, as well as with the constant flow of newly published information.</p>
    <p>PageRank is a graph-based algorithm initially developed to rank web pages for search results [<xref ref-type="bibr" rid="CR14">14</xref>]. An adaptation of this algorithm, Personalized PageRank (PPR) [<xref ref-type="bibr" rid="CR15">15</xref>], has been successfully applied to Word Sense Disambiguation [<xref ref-type="bibr" rid="CR16">16</xref>] and Named Entity Disambiguation [<xref ref-type="bibr" rid="CR17">17</xref>], which are tasks similar to entity linking [<xref ref-type="bibr" rid="CR18">18</xref>]. The PPR algorithm, which we make use of in this work, is based on random walks along the graph, with a given probability of jumping to a specific source node.</p>
    <p>Our main contribution is PPR-SSM, a novel domain-specific entity linking method for documents annotated with named entities that can be applied to various domains. Our method uses the PPR algorithm on a graph obtained from the relations established in the ontology, and explores the semantic similarity between the candidate matches of each entity to maximize the global coherence. We applied this method to three gold standards: i) one annotated with chemical entities; ii) one annotated with human phenotypes; and iii) annotated with gene ontology concepts. We used the ChEBI, HPO, and GO ontologies as our domain-specific KBs in the chemical, phenotype, and gene ontology gold standards, respectively. This method outperformed string matching and other PPR approaches. We also studied the effect of different semantic similarity measures in the results. We provide the code used in the experiments<xref ref-type="fn" rid="Fn1">1</xref>, along with usage examples and a Docker image.</p>
    <sec id="Sec2">
      <title>Related work</title>
      <p>Previous studies follow mainly two types of approaches: local similarity approaches, where the similarity between the entity text and candidate match is explored, and global approaches, which attempt at selecting the set of candidate matches that best represents the entities of a document [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR20">20</xref>]. One of the most commonly used KBs for entity linking is Wikipedia, which contains information about a great variety of topics. For this reason, it can be used to map entities of different domains to a KB. This variety of topics also increases the difficulty of the task, since the same expression can have different meanings according to its context. The disambiguation pages show the diverse meanings that an expression may have. For example, “New York” can refer to the state, the city in the state of New York, cities in other states, works of art, sports teams and ship names.</p>
      <p>Bunesco et al. presented a method based on Support Vector Machines, using a dictionary generated from Wikipedia to detect and link entities [<xref ref-type="bibr" rid="CR21">21</xref>]. Other authors aimed at maximizing the global coherence between the linked entities [<xref ref-type="bibr" rid="CR22">22</xref>–<xref ref-type="bibr" rid="CR24">24</xref>]. Pershina et al. presented a graph-based method based on the Personalized PageRank (PPR) algorithm to this task, incorporating both local and global coherence [<xref ref-type="bibr" rid="CR25">25</xref>]. They assumed that the probability of each node is related to how likely it is to fit with the other highest scoring nodes. More recently, Radhakrishnan et al. presented a method that improved entity similarity by training embedding vectors on a densified KB [<xref ref-type="bibr" rid="CR20">20</xref>]. Since the majority of entity linking gold standards are based on Wikipedia, these systems are developed for general KBs, and rarely focus on domain-specific KBs.</p>
      <sec id="Sec3">
        <title>Graph-based approaches</title>
        <p>Several graph-based approaches have been proposed for entity linking. [<xref ref-type="bibr" rid="CR26">26</xref>] developed a graph-based framework to rank the entries of a database according to their relevance to a query. [<xref ref-type="bibr" rid="CR27">27</xref>] proposed a method to rank the concepts and relations of an ontology according to their importance to the domain. Although this method is helpful to better understand a domain using ontologies, the authors did not explore its utility for other text mining tasks. [<xref ref-type="bibr" rid="CR28">28</xref>] explored Markov networks for entity linking, applied to citation databases. These types of approaches require training data, which is not always available, particularly in some biomedical domains. Unlike other authors that explored graph-based methods for entity linking, we propose a method that takes advantage of the semantic relations described in the KB.</p>
      </sec>
      <sec id="Sec4">
        <title>Biomedical entity linking</title>
        <p>Wikipedia as a KB for entity linking has two properties that are useful for this task: redirect pages, which account for synonyms and lexical variations; and disambiguation pages, which account for strings with multiple meanings. While biomedical ontologies can incorporate synonyms, there is no equivalent to disambiguation pages. When such ambiguity arises, it is necessary to understand the context of the sentence to determine the correct definition.</p>
        <p>The gene normalization task of BioCreative consisted in determining the unique identifiers of genes and proteins mentioned in scientific articles [<xref ref-type="bibr" rid="CR29">29</xref>, <xref ref-type="bibr" rid="CR30">30</xref>]. The objective of this task, as with the other BioCreative tasks, was to promote the development of new text mining methods specifically for biomedical text. The organizers selected and manually annotated articles with gene names, using Entrez Gene as reference. Three editions of this task were organized, each edition increasing the difficulty, with the final edition requiring the full-text annotation and being species non-specific. The gold standards developed for this task were made available and can then be used to benchmark new methods. Tsuruoka et al. [<xref ref-type="bibr" rid="CR31">31</xref>] presented a method to develop heuristic rules for biomedical entity linking automatically. Their method obtained better computational performance than string matching while requiring minimal expert knowledge in the development of the rules.</p>
        <p>A domain-specific ontology can be defined as a directed acyclic graph where each node represents a concept of the domain and the edges represent known relations between these concepts [<xref ref-type="bibr" rid="CR32">32</xref>]. This definition is the traditional representation of existing biomedical ontologies, which are nowadays a mainstream approach to formalize knowledge about entities, such as genes, chemicals, phenotypes, and disorders. Biomedical ontologies are usually publicly available and cover a large variety of topics of Life and Health Sciences. The success of exploring a given biomedical ontology for performing a specific task can be easily extended to other topics due to the standard structure of biomedical ontologies. For example, the same measures of metadata quality have been successfully applied to resources annotated with different biomedical ontologies [<xref ref-type="bibr" rid="CR33">33</xref>]. Zheng et al. [<xref ref-type="bibr" rid="CR34">34</xref>] developed a graph-based approach to biomedical entity linking, by performing collective inference over a text window and using entropy to estimate the importance of each edge. While their method is similar to ours in some ways, we explore the ontology even further by incorporating the information content of each concept and its similarity to the other candidate concepts. Our method combines the advantages of PPR-based methods that do not require training data, with domain knowledge from biomedical ontologies. Therefore, it can be adapted for other domains, as long as there is an exhaustive and domain-specific ontology available.</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec5" sec-type="results">
    <title>Results</title>
    <sec id="Sec6">
      <title>Data</title>
      <p>We evaluated our method on three gold standards, consisting of biomedical documents manually annotated with ontology concepts. Table <xref rid="Tab1" ref-type="table">1</xref> presents a comparison between the gold standards. The ChEBI-patents corpus consists of 40 patent documents annotated with chemical entities, using the ChEBI ontology as reference. This gold standard was developed by a team of curators from ChEBI and the European Patent Office. The documents were selected to be representative of the universe of chemical patent documents. Whenever possible, the curators added the ChEBI concept identifier to the entity annotations. Since we were interested only in linking entity mentions to concept identifiers, we discarded entity mentions that were not assigned an identifier. There were 8407 textual entity mentions annotated with ChEBI identifiers in this corpus, corresponding to 2081 unique entity mentions. The ChEBI team provides an API that can be used to retrieve a list of concepts associated with a text search, which we used to obtain the candidate list for each entity. Since the annotation process was performed in 2009, we also used the ChEBI API to update concept identifiers that have changed since then automatically.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Summary of the gold standards used for evaluation</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Gold standard</th><th align="left">ChEBI-patents</th><th align="left">HPO-GSC</th><th align="left">CRAFT-BP</th><th align="left">CRAFT-CC</th></tr></thead><tbody><tr><td align="left">Documents</td><td align="left">40</td><td align="left">228</td><td align="left">67</td><td align="left">67</td></tr><tr><td align="left">Total entities</td><td align="left">18061</td><td align="left">2773</td><td align="left">9280</td><td align="left">4075</td></tr><tr><td align="left">w/ ID</td><td align="left">8407</td><td align="left">2773</td><td align="left">9280</td><td align="left">4075</td></tr><tr><td align="left">w/ candidates</td><td align="left">6607</td><td align="left">1890</td><td align="left">9280</td><td align="left">4075</td></tr><tr><td align="left">Entities/doc</td><td align="left">210.2</td><td align="left">12.2</td><td align="left">138.5</td><td align="left">60.8</td></tr></tbody></table></table-wrap>
</p>
      <p>Additionally, we evaluated our method on a gold standard corpus of 228 scientific abstracts annotated with human phenotypes, associated with the Human Phenotype Ontology (HPO), which we refer to as HPO-GSC. We used an updated version of this corpus, which aimed at improving the consistency of the annotations [<xref ref-type="bibr" rid="CR35">35</xref>]. A total of 2773 textual named entities were annotated in this corpus, corresponding to 2170 unique entity mentions. We found that phenotype entities were more varied regarding nomenclature due to the existence of more synonyms for the same phenotype when compared to chemical entities. Comparing with the ChEBI-patents corpus, we can see that this corpus has fewer entities per document (ChEBI-patents: 210 entities/document; HPO-GSC: 12 entities/document). This ratio is relevant for our method because it aims at maximizing the coherence between entities, and documents with fewer entities are more prone to errors. We obtain a list of candidates for each entity through fuzzy string matching with the labels and synonyms of the HPO.</p>
      <p>In order to compare our work with the state-of-the-art, we used the Colorado Richly Annotated Full-Text (CRAFT) Corpus with articles annotated with Gene Ontology (GO) concepts [<xref ref-type="bibr" rid="CR36">36</xref>]. The v3.1 release includes 67 articles from PubMed Central Open subset. The articles in this corpus were independently annotated with concepts belonging to the three GO sub-ontologies: Biological Process (BP), Cellular Component (CC) and Molecular Function (MF). The annotations pertaining to MF subset were not used due to the low number of concepts annotated and the high number of concept repetition. The subsections of the corpus containing files annotated with BP and CC concepts are thus referred as CRAFT-BP and CRAFT-CC, respectively. There were 4075 named entities annotated in CRAFT-CC and 9280 in CRAFT-BP.</p>
      <p>Figure <xref rid="Fig2" ref-type="fig">2</xref> shows an excerpt of the ChEBI-patents and HPO-GSC corpora, to demonstrate the type of information that was annotated by the curators. While in some cases the label of the concept matches the textual mention, in other cases there are some differences. Acronyms are common to both phenotypes and chemical entities. The HPO-GSC gold standard contains some overlapping entities, which could be mapped to different ontology concepts. While “neurofibromatosis” and “neurofibromas” were mapped to different concept identifiers, the current version of HPO merged those two concepts. As with the ChEBI-patents gold standard, we retrieved the most recent identifier of each concept annotated on each gold standard. Other challenges consist in dealing with plurals (both the entity text and concept label can be plural or singular) and abbreviations and acronyms (the ontology may have some of these synonyms but not all).
<fig id="Fig2"><label>Fig. 2</label><caption><p>Example of the annotations associated with each of the gold standard used. For each entity mention, surrounded by a rectangle, we show its ontology ID and label. <bold>a</bold> HPO-GSC; <bold>b</bold> ChEBI-patents</p></caption><graphic xlink:href="12859_2019_3157_Fig2_HTML" id="MO2"/></fig>
</p>
      <p>We used the April 2018 release of ChEBI, the March 2018 release of HPO and the February 2019 release of GO. The version of the ChEBI ontology that was used has about 54k manually verified chemical compounds. This ontology is curated by experts and updated monthly, while various sources are used to keep it as complete as possible, including user submissions. The HPO contains about 13k phenotypes and is focused on medically relevant phenotypes, and associating those phenotypes with diseases. This ontology is used in various applications that deal with clinical data. The GO is a structured representation for gene and gene product functions across many different organisms, like humans or bacteria, and is divided in three sub-ontologies as previously referred: Biological Process (BP) includes concepts describing biological pathways, for example, “cell death” (GO:0008219); Molecular Function (MF) includes concepts related with elemental functions such as “catalytic activity” (GO:0003824), being normally the “building blocks” of the biological pathways described by BP concepts; Cellular Component (CC) concepts refer to the place where above events occur, like “cytoplasm” (GO:0005737). The referred GO version includes 45,023 concepts, of which 29,699 belong to BP sub-ontology and 4,211 belong to CC sub-ontology. These ontologies tackle specific and complex areas of knowledge that benefit greatly from text mining methods.</p>
    </sec>
    <sec id="Sec7">
      <title>Evaluation setup</title>
      <p>We evaluated each model considering the entities that were manually mapped to an ontology concept and for which the correct solution was in the set of candidates. Using the matching methods presented in the Methods section, we obtain a list of candidates for each entity. Table <xref rid="Tab1" ref-type="table">1</xref> shows that on the datasets used, most entities had its solution in the respective candidate list. Figure <xref rid="Fig3" ref-type="fig">3</xref> shows an example of how we applied our method to the ChEBI-patents corpus.
<fig id="Fig3"><label>Fig. 3</label><caption><p>Pipeline of the PPR-SSM method to the ChEBI-patents corpus. For each entity, a candidate list <italic>C</italic><italic>L</italic>(<italic>e</italic>) is obtained. The proposed ontology-based scoring function is applied to each element of the list, and the top scoring element is chosen</p></caption><graphic xlink:href="12859_2019_3157_Fig3_HTML" id="MO3"/></fig>
</p>
      <p>We found that many concepts were not directly linked to each other in the ontology, meaning that the graph of each document would not have enough edges to apply PPR. For this reason, we studied the effect of considering the transitivity of subsumption relations, with a maximum distance threshold between 1 and 8. For example, if 5 is the maximum distance allowed, we would consider that there is an edge in the graph between two nodes if the shortest path between the respective concepts in ontology is equal to or less than 5 edges.</p>
      <p>We use the scoring functions described in (<xref rid="Equ3" ref-type="">3</xref>) and (<xref rid="Equ12" ref-type="">12</xref>) to rank the candidate list of each entity mention. In case of a tie, we pick the candidate with more subclasses. We considered only candidates with a matching score higher than 0.7 for CHEBI-patents and HPO-GSC entities and higher than 0.6 for CRAFT-BP and CRAFT-CC entities which were determined empirically to be the best threshold values. We then compared the predicted candidate with the gold standard to calculate the accuracy score.</p>
      <p>The PPR algorithm was computed using the Monte Carlo approach presented by Fogaras and Racz [<xref ref-type="bibr" rid="CR15">15</xref>]. We executed 2,000 iterations for each source node, performing five steps of PPR, with a probability of jumping to source node equal to 0.2. These values were suggested by Pershina et al. [<xref ref-type="bibr" rid="CR25">25</xref>], which we kept since we saw no major improvements with a different number of iterations, steps or jump probability.</p>
    </sec>
    <sec id="Sec8">
      <title>Experiments</title>
      <p>Table <xref rid="Tab2" ref-type="table">2</xref> compares the accuracy of the proposed method with a string matching baseline and two other versions of the PPR algorithm: the first consisting of the PPR-based approach proposed by Pershina et al. adapted to biomedical domain-specific ontologies and the second adding a weight to the contribution of each node based on its Information Content (IC) (<xref rid="Equ1" ref-type="">1</xref>). We performed a baseline evaluation, which consisted in picking the top candidate with highest string matching similarity. Adding semantic similarity as a factor in the contribution of each candidate has a positive effect, obtaining a higher accuracy than the other approaches.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Accuracy of PPR-SSM compared with a baseline and PPR model, on the ChEBI-patents, HPO-GSC, and CRAFT (Biological Process and Cellular Component) gold standards</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Method</th><th align="left">ChEBI-patents</th><th align="left">HPO-GSC</th><th align="left">CRAFT-BP</th><th align="left">CRAFT-CC</th></tr></thead><tbody><tr><td align="left">Top match</td><td align="left">0.5271</td><td align="left">0.6380</td><td align="left">0.7744</td><td align="left">0.6899</td></tr><tr><td align="left">PPR</td><td align="left">0.6654</td><td align="left">0.5544</td><td align="left">0.6923</td><td align="left">0.6166</td></tr><tr><td align="left">PPR-IC</td><td align="left">0.8026</td><td align="left">0.6557</td><td align="left">0.8204</td><td align="left">0.7247</td></tr><tr><td align="left">PPR-SSM</td><td align="left">0.8039</td><td align="left">0.6825</td><td align="left">0.8244</td><td align="left">0.7258</td></tr></tbody></table></table-wrap>
</p>
      <p>Figure <xref rid="Fig4" ref-type="fig">4</xref> shows the effect of different maximum distance thresholds between concepts of the ontology. We compared paths of length 1, which means that there is a direct relationship between two concepts, to length 8, meaning that if there is a path shorter or equal to 8 between the concepts in the ontology, an edge is created in the graph. Each gold standard has a different optimal distance, with ChEBI-patents obtaining its best accuracy with distance 3, HPO-GSC with distance 6 and CRAFT-BP and CRAFT-CC both with distance 1. According to our experiments, the concepts linked by distances greater than those values do not contribute positively to the estimation of coherence within candidates. We used those distance values when comparing different PPR-based approaches (Table <xref rid="Tab2" ref-type="table">2</xref>) and Semantic Similarity Measures (SSM) (Table <xref rid="Tab3" ref-type="table">3</xref>).
<fig id="Fig4"><label>Fig. 4</label><caption><p>Comparison of different maximum distance values using the PPR-IC approach. For the CRAFT corpora (both BP and CC), the maximum accuracy is achieved using only direct links between concepts, while ChEBI and HPO-GSC benefit from including longer links</p></caption><graphic xlink:href="12859_2019_3157_Fig4_HTML" id="MO4"/></fig><table-wrap id="Tab3"><label>Table 3</label><caption><p>Comparison of different semantic similarity measures for PPR-based entity linking</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">SSM</th><th align="left">IC<sub>shared</sub></th><th align="left">ChEBI-patents</th><th align="left">HPO-GSC</th><th align="left">CRAFT-BP</th><th align="left">CRAFT-CC</th></tr></thead><tbody><tr><td align="left">Resnik</td><td align="left">MICA</td><td align="left">0.7916</td><td align="left">0.6306</td><td align="left">0.7444</td><td align="left">0.6439</td></tr><tr><td align="left"/><td align="left">DCA</td><td align="left">0.7916</td><td align="left">0.6340</td><td align="left">0.7545</td><td align="left">0.6439</td></tr><tr><td align="left">Lin</td><td align="left">MICA</td><td align="left">0.7965</td><td align="left">0.6825</td><td align="left">0,8244</td><td align="left">0.7190</td></tr><tr><td align="left"/><td align="left">DCA</td><td align="left">0.7965</td><td align="left">0.6775</td><td align="left">0.8216</td><td align="left">0.7258</td></tr><tr><td align="left">JC</td><td align="left">MICA</td><td align="left">0.8014</td><td align="left">0.6775</td><td align="left">0.8177</td><td align="left">0.6985</td></tr><tr><td align="left"/><td align="left">DCA</td><td align="left">0.8039</td><td align="left">0.6633</td><td align="left">0.8199</td><td align="left">0.6997</td></tr></tbody></table></table-wrap>
</p>
      <p>We used three SSMs for our PPR-SSM model: Resnik, Lin, and Jiang-Conrath (JC). Furthermore, we compare for each SSM the usage of Most Informative Common Ancestors (MICA) and Disjunctive Common Ancestors (DCA) to calculate the shared information content. Table <xref rid="Tab3" ref-type="table">3</xref> shows the results of this comparison.</p>
      <p>Comparing the results obtained with each SSM, we can see that different measures obtain the best results on each gold standard. While JC-DCA obtains the best accuracy on the ChEBI-patents, Lin-MICA obtains the best accuracy on HPO-GSC and on CRAFT-BP and Lin-DCA on CRAFT-CC. In all cases, the Resnik measure obtains lower scores than the PPR-IC model. The main difference between Resnik and the other measures is that it does not take into account the individual IC of the two concepts. On ChEBI-patents, none of the measures had a noticeable effect on the performance, and in most cases, it decreases the accuracy. However, the PPR-IC model leads to considerable improvement, so there would be fewer and more difficult cases for the PPR-SSM model to resolve. A similar situation occurred for both CRAFT-BP and CRAFT-CC, despite the more modest increase in disambiguation accuracy by PPR-IC model comparing to ChEBI-patents. As the effect of the PPR-IC model on HPO-GSC was not as high, both Lin and JC measures improved the results. These findings seem to suggest that SSM can increase the disambiguation accuracy especially in cases where the PPR-IC model does not improve accuracy substantially. If the accuracy is already high, the SSM will have less impact on its improvement.</p>
    </sec>
  </sec>
  <sec id="Sec9" sec-type="discussion">
    <title>Discussion</title>
    <p>We manually analyzed the errors of the PPR-SSM model on each gold standard, in order to understand the limitations of our approach. On the ChEBI-patents corpus, some errors were due to the same words being used to refer to a family of compounds and a type of chemical compound. For example, “polyamine” can refer to CHEBI:51349 (polyamine macromolecule) and CHEBI:88061 (polyamine). Other errors were caused by the lack of edges between candidates, which happened in some documents. In these cases, the PPR algorithm cannot be applied, and the candidate with the highest number of descendants is chosen, which is not always the correct choice and does not take into account the global coherence. Another common error is with chemical compounds that have different charges, for example, biliverdin and biliverdin(2-). These two concepts are linked by <italic>is conjugate acid of</italic> and <italic>is conjugate base of</italic> relations. However, they have a different set of <italic>is-a</italic> ancestors, having only organic molecular entity and its respective ancestors in common. More contextual information from the text could help understand the specific molecule that is being mentioned. Many entities of the gold standard were not annotated with ChEBI identifiers (Table <xref rid="Tab1" ref-type="table">1</xref>). These missing identifiers could improve the results of our method since the graph of each document would be more exhaustive, and the global coherence score would take into account the complete set of entities. As both compounds appear in the same candidate list, the fact that the latter has a relation with the CHEBI:22563 (“anion”), a concept with many descendants, resulted in a higher score. In Fig. <xref rid="Fig1" ref-type="fig">1</xref> we can see that “biliverdin(2-)” is one concept away from “organic anion”, which has 166 descendants.</p>
    <p>On the HPO-GSC corpus, some errors were due to concepts with similar meanings. For example, “microretrognathia” and “micrognathia” are both facial deformations related to the development of the fetal mandible, and their respective HPO concepts have the same edges. Another common error was when dealing with child and parent concepts. For example, HP:0009588 refers to Vestibular Schwannoma and HP:0009589 to Bilateral vestibular Schwannoma and both appear in the candidate list for Bilateral vestibular Schwannoma. The parent concept, Vestibular Schwannoma, obtained a higher score, resulting in an error. Parent concepts are closer to the top concepts, and therefore it will have paths to more concepts. As it can be seen in Fig. <xref rid="Fig1" ref-type="fig">1</xref>a, HPO has several instances where related concepts have similar labels, with a difference of just one word. Even though we try to account for this issue by giving more weight to concepts with higher information content, sometimes this weight is not enough and concepts that have more links are ranked higher than the correct candidate. As the nomenclature of phenotypes is not as systematic as the nomenclature of chemical compounds, it is harder to perform entity linking on this domain, resulting in lower accuracy scores.</p>
    <p>On both CRAFT-BP and CRAFT-CC corpora, some common errors occurred when dealing with child and parent concepts, just like it had been previously described on the HPO-GSC corpus. However, normally the candidate with higher IC was picked, as this is a factor in the calculation of the coherence score (Eq. <xref rid="Equ12" ref-type="">12</xref>). For example, RNA metabolic process (GO:0016070) and metabolic process (GO:0008152) were on the candidate list for metabolic (GO:0008152) and the chosen candidate was the more informative concept RNA metabolic process, which is not the correct candidate. Neither of the concepts had links with other candidates, so it was chosen the concept that had higher IC, RNA metabolic process.</p>
    <p>Another aspect to highlight on the CRAFT-BP and CRAFT-CC corpora, although not the focus of the present study, is the high recall achieved while performing disambiguation: 0.77295 and 0.84315, respectively. Comparing with the values referred in [<xref ref-type="bibr" rid="CR37">37</xref>], where the recall was less than 0.20 for CRAFT-BP and less than 0.70 for CRAFT-CC, the results obtained are a noticeable improvement, even more if we consider that the precision (or accuracy) has not been negatively affected.</p>
  </sec>
  <sec id="Sec10" sec-type="conclusion">
    <title>Conclusion</title>
    <p>Entity linking is an essential task in text mining systems so that the information extracted can be linked to existing resources. However few approaches take advantage of the extensive knowledge encoded in domain-specific ontologies. We proposed a method, PPR-SSM, that combined existing entity linking graph-based approaches with semantic similarity to calculate a global coherence score. Using this score, we select the best candidate matches to a named entity. Our method outperformed string matching and PPR-based methods in four case-studies, obtaining an accuracy of 0.8039 on the ChEBI-patents gold standard, 0.6825 on HPO-GSC, 0.8244 on CRAFT-BP and 0.7258 on CRAFT-CC. These results show the potential of the proposed method to be adapted to other domains where ontologies are available. The code used to implement the method is publicly available<xref ref-type="fn" rid="Fn2">2</xref>.</p>
    <p>As future work, we could take advantage of the similarities between ontologies to develop a joint approach, as suggested by [<xref ref-type="bibr" rid="CR38">38</xref>]. The authors of this paper have shown that considering multiple ontologies together is beneficial to biomedical EL. Other improvements would be to improve the candidate generation process, so that more entities have the correct candidate in their candidate list. One possible approach would be to use word embeddings to find the most similar concepts, instead of matching the characters of the string. Furthermore, the document graph could be improved using relation extracted from the document between entities. This way, if a relation between two entities is stated in the document, but not in the ontology, we could still use that information.</p>
  </sec>
  <sec id="Sec11">
    <title>Methods</title>
    <sec id="Sec12">
      <title>Problem definition</title>
      <p>We now define the concepts necessary to understand the entity linking problem and our proposed solution. We consider the problem setting where a corpus of documents is annotated with entity mentions, and each entity mention has a set of KB candidate matches. The objective of entity linking is to link each entity mention to an entry of a KB. We can define a KB as a tuple &lt;<italic>C</italic>,<italic>R</italic>&gt;, where C is the set of concepts about a particular subject, and R the set of relations between the concepts, where each relation is a pair of concepts (<italic>c</italic><sub>1</sub>,<italic>c</italic><sub>2</sub>) with <italic>c</italic><sub>1</sub>,<italic>c</italic><sub>2</sub>∈<italic>C</italic><xref ref-type="fn" rid="Fn3">3</xref>. We consider a candidate list <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$CL(e) = \{ c_{e}^{1},..., c_{e}^{i} \} $\end{document}</tex-math><mml:math id="M2"><mml:mtext mathvariant="italic">CL</mml:mtext><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mi>...</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>}</mml:mo></mml:math><inline-graphic xlink:href="12859_2019_3157_Article_IEq1.gif"/></alternatives></inline-formula> for each entity <italic>e</italic>∈<italic>E</italic>, where <italic>E</italic> is the set of named entities mentioned in a document. We want to find the <italic>c</italic><sub><italic>e</italic></sub>∈<italic>C</italic><italic>L</italic>(<italic>e</italic>) that best represents each <italic>e</italic>.</p>
      <p>For each document, we can construct a graph <italic>G</italic> consisting of the edges defined by: 
<disp-formula id="Equa"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$G = \{ (e, c_{e}) | e \in E, c_{e} \in CL(e) \} $$ \end{document}</tex-math><mml:math id="M4"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>|</mml:mo><mml:mi>e</mml:mi><mml:mo>∈</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mtext mathvariant="italic">CL</mml:mtext><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2019_3157_Article_Equa.gif" position="anchor"/></alternatives></disp-formula> where <italic>e</italic> corresponds to each named entity of a document and <italic>c</italic><sub><italic>e</italic></sub> to each candidate match of that entity. Hence, each node of <italic>G</italic> represents a candidate to a given entity of the document. The entities themselves are not represented in the graph, only the candidate concepts associated with them. However, different entities may have common candidate concepts, which would be represented as different nodes in the graph.</p>
      <p>Our objective is to define a function <italic>disambiguate</italic> such that 
<disp-formula id="Equb"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$disambiguate(e) = \operatorname*{arg\,max}_{c_{e}}\{ score(e, c_{e})\} $$ \end{document}</tex-math><mml:math id="M6"><mml:mrow><mml:mtext mathvariant="italic">disambiguate</mml:mtext><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mtext>arg max</mml:mtext></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mo>{</mml:mo><mml:mtext mathvariant="italic">score</mml:mtext><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:math><graphic xlink:href="12859_2019_3157_Article_Equb.gif" position="anchor"/></alternatives></disp-formula> where <italic>score</italic> is a scoring function that evaluates how likely the candidate is to be the correct choice for entity <italic>e</italic>.</p>
    </sec>
    <sec id="Sec13">
      <title>Ontology-based personalized pageRank</title>
      <p>We assume that a measure of global coherence among the candidate concepts could be used as a scoring function. The coherence of a candidate concept quantifies how well it fits among a set of concepts, while the global coherence estimates how well a set of candidate concepts fit with each other. This idea has been explored by other authors, who suggest random walks methods such as PPR to rank the importance of each node in a graph. Nodes with greater weight would be more relevant to the results. The weights are determined by simulating random walks on the graph, with a certain probability of jumping to a random node. The PPR algorithm is a variant of PageRank where the jump is always made to the same node. Using the graph previously described, we apply the PPR algorithm to calculate the weights of each node in relation to each other, which we use as a coherence score. While Pershina et al. [<xref ref-type="bibr" rid="CR25">25</xref>] use a general purpose KB to run the PPR algorithm, we use domain-specific ontologies, which usually contain more detailed nodes and edges.</p>
      <p>Note that in our graph model, each node represents a candidate concept associated with a named entity. Therefore, we consider only edges between nodes associated with different entities, since only one element of each candidate list can be correct. Our approach to entity linking explores the structure of the ontology to generate the graph. If a node is within distance <italic>d</italic> of another node, we consider that they are linked. To calculate this distance, we do not take into consideration the directionality of the relations of the ontology. Therefore, any two nodes of the same document can form an edge as long as there is a path with length equal to or shorter than <italic>d</italic> between them, and they are associated with different entities.</p>
      <p>Figure <xref rid="Fig5" ref-type="fig">5</xref> shows an example of the graph generated by a set of named entities from an abstract annotated with HPO concepts. To simplify the figure, we show only three entities and the two highest scoring candidates of each entity. We considered <italic>d</italic>=6 for this example. Due to its spelling similarity, tremor is a candidate match to the entity “tumour”, when in fact the correct match should be neoplasm. Note that neoplasm is a candidate for that entity because HPO has tumour as a synonym of neoplasm. The candidate tremor is linked only to one other candidate, while tumour is linked to candidates from both entities. Hence, neoplasm is more likely to maximize the global coherence. Likewise, Abnormality of the nervous system is linked only to one candidate, so it will have a negative contribution to the global coherence. Both candidates of the entity “neurofibromatosis” are linked to the same concepts. In these cases, we adopt a conservative approach and pick the candidate with more descendants in the ontology, since it represents a more generic concept. Therefore, neurofibromas would be the chosen candidate for that entity.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Example of the graph generated from abstract PMID2888021 using HPO. We show two candidate matches for each entity mention, and the edges obtained from the HPO ontology between each matches. Each candidate match is represented by its ontology ID and its preferred label</p></caption><graphic xlink:href="12859_2019_3157_Fig5_HTML" id="MO5"/></fig>
</p>
      <p>The PPR algorithm is used to calculate the coherence of each node in relation to another node, which can also be interpreted as the PageRank score. To accomplish this, we personalized the graph to each node, referred to as the source node. We estimate the coherence of node <italic>n</italic> to source node <italic>s</italic>, given by <italic>P</italic><italic>P</italic><italic>R</italic>(<italic>s</italic>→<italic>n</italic>), corresponding to the weight of <italic>n</italic> when personalizing to <italic>s</italic>. We multiply the PPR score by the normalized IC value of the concept associated with node <italic>n</italic>, in order to account for the different degrees of specificity of the concepts of an ontology. Therefore we calculate the coherence of node <italic>n</italic> relative to node <italic>s</italic> as 
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$  coherence_{s}(n) = PPR(s \rightarrow n) \cdot IC(n)  $$ \end{document}</tex-math><mml:math id="M8"><mml:mtext mathvariant="italic">coherenc</mml:mtext><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">PPR</mml:mtext><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>→</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo><mml:mo>·</mml:mo><mml:mtext mathvariant="italic">IC</mml:mtext><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:math><graphic xlink:href="12859_2019_3157_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>We estimate IC of a node <italic>n</italic> as: 
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$  IC(n) = -\log(p(n))  $$ \end{document}</tex-math><mml:math id="M10"><mml:mtext mathvariant="italic">IC</mml:mtext><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mo>log</mml:mo><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:math><graphic xlink:href="12859_2019_3157_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <italic>p</italic>(<italic>n</italic>) is the probability of that node appearing on a corpus [<xref ref-type="bibr" rid="CR39">39</xref>].</p>
      <p>Finally, we sum the coherence score of node <italic>n</italic> to each source node <italic>s</italic> to estimate its global coherence: 
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$  coherence(n) = \sum_{s \in G} coherence_{s}(n)  $$ \end{document}</tex-math><mml:math id="M12"><mml:mtext mathvariant="italic">coherence</mml:mtext><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>G</mml:mi></mml:mrow></mml:munder><mml:mtext mathvariant="italic">coherenc</mml:mtext><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:math><graphic xlink:href="12859_2019_3157_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p>
    </sec>
    <sec id="Sec14">
      <title>Semantic similarity</title>
      <p>Semantic similarity measures (SSM) estimate the similarity between concepts using the relations defined by an ontology [<xref ref-type="bibr" rid="CR40">40</xref>]. We explore how taking into account the semantic similarity between concepts can improve the graph model previously described, by adjusting the contribution of each node to another node. If two nodes share more semantics, they should have a greater contribution to each other’s global coherence score.</p>
      <p>SSMs are normally restricted to subsumption relations (<italic>is-a</italic> or <italic>subClassOf</italic>), which are transitive, meaning that if <italic>R</italic> is the set of relations between concepts, (<italic>c</italic><sub>1</sub>,<italic>c</italic><sub>2</sub>)∈<italic>R</italic>, and (<italic>c</italic><sub>2</sub>,<italic>c</italic><sub>3</sub>)∈<italic>R</italic>, then (<italic>c</italic><sub>1</sub>,<italic>c</italic><sub>3</sub>)∈<italic>R</italic>. Therefore, the ancestors of <italic>c</italic> are given by 
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{*{20}l} Anc(c) = \{a : (c,a) \in T\} \end{array} $$ \end{document}</tex-math><mml:math id="M14"><mml:mtable class="align" columnalign="left"><mml:mtr><mml:mtd class="align-1"><mml:mtext mathvariant="italic">Anc</mml:mtext><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>a</mml:mi><mml:mo>:</mml:mo><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo><mml:mo>∈</mml:mo><mml:mi>T</mml:mi><mml:mo>}</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2019_3157_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <italic>T</italic> is the smallest relation set on <italic>C</italic> that contains <italic>R</italic> and is transitive.</p>
      <p>Many SSMs explore the ancestors exclusive to each concept, as well as their common ancestors. We can define the common ancestors <italic>CA</italic> between two concepts as 
<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$\begin{array}{*{20}l} CA(c_{1}, c_{2}) = Anc(c_{1}) \cap Anc(c_{2}) \end{array} $$ \end{document}</tex-math><mml:math id="M16"><mml:mtable class="align" columnalign="left"><mml:mtr><mml:mtd class="align-1"><mml:mtext mathvariant="italic">CA</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">Anc</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>∩</mml:mo><mml:mtext mathvariant="italic">Anc</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math><graphic xlink:href="12859_2019_3157_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>Some SSMs use only the Most Informative Common Ancestors (MICA), which can be considered the most relevant to compare entities: 
<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$  MICA(c_{1}, c_{2}) = \{ a : a \in CA(c_{1}, c_{2}) \wedge IC(a) = \\ \max\{IC(a) : a \in CA(c_{1}, c_{2})\}\}  $$ \end{document}</tex-math><mml:math id="M18"><mml:mtext mathvariant="italic">MICA</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>a</mml:mi><mml:mo>:</mml:mo><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:mtext mathvariant="italic">CA</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>∧</mml:mo><mml:mtext mathvariant="italic">IC</mml:mtext><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>max</mml:mo><mml:mo>{</mml:mo><mml:mtext mathvariant="italic">IC</mml:mtext><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo><mml:mo>:</mml:mo><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:mtext mathvariant="italic">CA</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>}</mml:mo><mml:mo>}</mml:mo></mml:math><graphic xlink:href="12859_2019_3157_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>Alternatively, SSMs can consider multiple inheritance relations, which we refer to Disjunctive Common Ancestors (DCA): 
<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$  DCA(c_{1}, c_{2}) = \{a : a \in CA(c_{1}, c_{2}) \\ \wedge \forall_{a_{x} \in CA(c_{1}, c_{2})}PD(c_{1},c_{2},a) = \\ PD(c_{1}, c_{2}, a_{x}) \Rightarrow IC(a) &gt; IC(a_{x}) \}  $$ \end{document}</tex-math><mml:math id="M20"><mml:mtext mathvariant="italic">DCA</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>a</mml:mi><mml:mo>:</mml:mo><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:mtext mathvariant="italic">CA</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>∧</mml:mo><mml:msub><mml:mrow><mml:mo>∀</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mtext mathvariant="italic">CA</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mtext mathvariant="italic">PD</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">PD</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>⇒</mml:mo><mml:mtext mathvariant="italic">IC</mml:mtext><mml:mo>(</mml:mo><mml:mi>a</mml:mi><mml:mo>)</mml:mo><mml:mo>&gt;</mml:mo><mml:mtext mathvariant="italic">IC</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>}</mml:mo></mml:math><graphic xlink:href="12859_2019_3157_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <italic>PD</italic> is a function that calculates the difference between the number of paths of <italic>c</italic><sub>1</sub> and <italic>c</italic><sub>2</sub> to their common ancestors.</p>
      <p>SSMs can use the IC of the concepts to estimate its similarity. Several measures have been proposed, one of the most commonly used being the measure proposed by Resnik [<xref ref-type="bibr" rid="CR39">39</xref>]: 
<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$  SSM_{Resnik}(c_{1},c_{2}) = IC_{shared}(c_{1}, c_{2})  $$ \end{document}</tex-math><mml:math id="M22"><mml:mtext mathvariant="italic">SS</mml:mtext><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">Resnik</mml:mtext></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">shared</mml:mtext></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><graphic xlink:href="12859_2019_3157_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where <italic>I</italic><italic>C</italic><sub><italic>shared</italic></sub> is the average of the information content of the MICA or DCA.</p>
      <p>Another SSM was proposed by Lin et al. [<xref ref-type="bibr" rid="CR41">41</xref>], which balances the IC of the common ancestors with the IC of the concepts themselves: 
<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$  SSM_{Lin}(c_{1},c_{2}) = \frac{2 \times IC_{shared}(c_{1}, c_{2})}{IC(c_{1}) + IC(c_{2})}  $$ \end{document}</tex-math><mml:math id="M24"><mml:mtext mathvariant="italic">SS</mml:mtext><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">Lin</mml:mtext></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">shared</mml:mtext></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">IC</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mtext mathvariant="italic">IC</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:math><graphic xlink:href="12859_2019_3157_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>Finally, Jiang and Conrath [<xref ref-type="bibr" rid="CR42">42</xref>] proposed a measure of distance between concepts of an ontology, given by 
<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ dist_{jc}(c_{1}, c_{2}) = IC(c_{1}) + IC(c_{2}) - \\ 2 \times IC_{shared}(c_{1}, c_{2})  $$ \end{document}</tex-math><mml:math id="M26"><mml:mtext mathvariant="italic">dis</mml:mtext><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">jc</mml:mtext></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">IC</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mtext mathvariant="italic">IC</mml:mtext><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi>I</mml:mi><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">shared</mml:mtext></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math><graphic xlink:href="12859_2019_3157_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>As an SSM should be inversely proportional to the distance (i.e. less distance, more similar), we can use this distance to calculate a semantic similarity score: 
<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$  SSM_{jc}(c_{1},c_{2}) = \begin{cases} \frac{1}{dist(c1,c2)}, \text{if}\ dist &gt; 0 \\ 1,\text{otherwise} \end{cases}  $$ \end{document}</tex-math><mml:math id="M28"><mml:mtext mathvariant="italic">SS</mml:mtext><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">jc</mml:mtext></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable class="array" columnalign="left"><mml:mtr><mml:mtd><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mtext mathvariant="italic">dist</mml:mtext><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mtext>if</mml:mtext><mml:mspace width="1em"/><mml:mtext mathvariant="italic">dist</mml:mtext><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mspace width="1em"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mtext>otherwise</mml:mtext><mml:mspace width="1em"/></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12859_2019_3157_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>Each of the presented measures uses the IC of the common ancestors between the two concepts. As such, they can use either MICA or DCA to calculate the <italic>I</italic><italic>C</italic><sub><italic>shared</italic></sub> factor. We adapted the coherence score of node <italic>e</italic> according to source node <italic>s</italic> as: 
<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$  coherence_{e} = PPR(s \rightarrow e) \cdot SSM(s, e) \cdot IC(e)  $$ \end{document}</tex-math><mml:math id="M30"><mml:mtext mathvariant="italic">coherenc</mml:mtext><mml:msub><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">PPR</mml:mtext><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>→</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo><mml:mo>·</mml:mo><mml:mtext mathvariant="italic">SSM</mml:mtext><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo><mml:mo>·</mml:mo><mml:mtext mathvariant="italic">IC</mml:mtext><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:math><graphic xlink:href="12859_2019_3157_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula></p>
      <p>where SSM corresponds to one of the three SSM previously described.</p>
    </sec>
    <sec id="Sec15">
      <title>Models</title>
      <p>We studied the effect of SSMs as a factor on the scoring function, and how it affects the accuracy of entity linking results. We first applied a baseline approach that consisted in selecting the ontology concept label most similar to the textual entity mention. This was implemented using the Levenshtein distance to obtain the label with the shortest distance to the text. This approach compares only the lexical form of the label, ignoring any context and semantics.</p>
      <p>Then, we applied the PPR algorithm, using an approach similar to [<xref ref-type="bibr" rid="CR25">25</xref>], but adapted to biomedical ontologies, which we refer to as the PPR model. As shown in (<xref rid="Equ1" ref-type="">1</xref>), we can adjust the PPR score of each node with its IC. We refer to this model as PPR-IC. As previously explained, our adaptation of this approach has a distance parameter, corresponding to the maximum ontology distance between concepts. We studied the effect of this parameter on the PPR algorithm, to find the best value to use for further experiments.</p>
      <p>We can then further adjust the contribution of each node to another node in the graph with the semantic similarity between them. As opposed to the model proposed by Pershina et al., we use all the candidates associated with the other entity mentions and not just the top scoring. This SSM factor will increase the weight of similar concepts, most likely to be coherent with the source node, and reduce the contribution of concepts less related to the source node. We refer to this model as PPR-SSM and study the effect of three SSMs on the accuracy of entity linking. Furthermore, we compare two versions of each SSM: one using the IC of the MICA (<xref rid="Equ6" ref-type="">6</xref>) and another using the DCA (<xref rid="Equ7" ref-type="">7</xref>).</p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>BP</term>
        <def>
          <p>Biological process</p>
        </def>
      </def-item>
      <def-item>
        <term>CC</term>
        <def>
          <p>Cellular component</p>
        </def>
      </def-item>
      <def-item>
        <term>ChEBI</term>
        <def>
          <p>Chemical entities of biological interest</p>
        </def>
      </def-item>
      <def-item>
        <term>DCA</term>
        <def>
          <p>Disjunctive common ancestors</p>
        </def>
      </def-item>
      <def-item>
        <term>GO</term>
        <def>
          <p>Gene ontology</p>
        </def>
      </def-item>
      <def-item>
        <term>HPO</term>
        <def>
          <p>Human phenotype ontology</p>
        </def>
      </def-item>
      <def-item>
        <term>IC</term>
        <def>
          <p>Information content</p>
        </def>
      </def-item>
      <def-item>
        <term>JC</term>
        <def>
          <p>Jiang and conrath</p>
        </def>
      </def-item>
      <def-item>
        <term>KB</term>
        <def>
          <p>Knowledge base</p>
        </def>
      </def-item>
      <def-item>
        <term>MF</term>
        <def>
          <p>Molecular function</p>
        </def>
      </def-item>
      <def-item>
        <term>MICA</term>
        <def>
          <p>Most informative common ancestor</p>
        </def>
      </def-item>
      <def-item>
        <term>NER</term>
        <def>
          <p>Named entity recognition</p>
        </def>
      </def-item>
      <def-item>
        <term>PPR</term>
        <def>
          <p>Personalized pageRank</p>
        </def>
      </def-item>
      <def-item>
        <term>SSM</term>
        <def>
          <p>Semantic similarity measures</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn id="Fn1">
      <label>1</label>
      <p>https://github.com/lasigeBioTM/PPRSSM</p>
    </fn>
    <fn id="Fn2">
      <label>2</label>
      <p>https://github.com/lasigeBioTM/PPRSSM</p>
    </fn>
    <fn id="Fn3">
      <label>3</label>
      <p>We use typewriter to indicate a concept of a KB, italics to indicate relations between concepts, and quotes to indicate entity mentions.</p>
    </fn>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>AL and FMC - conception. AL and PR - creation of new software used in the work. AL, PR, and FMC - design of the work, interpretation of data, drafted the work and substantively revised it. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported by FCT through funding of the DeST: Deep Semantic Tagger project, ref. PTDC/CCI-BIO/28685/2017, LaSIGE Research Unit, ref. UID/CEC/00408/2019. The funding body did not have any roles in the design of the study and collection, analysis, and interpretation of data and in writing the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The data and code used for this study are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/lasigeBioTM/PPRSSM">https://github.com/lasigeBioTM/PPRSSM</ext-link>.</p>
  </notes>
  <notes>
    <title>Ethics approval and consent to participate</title>
    <p>Not applicable.</p>
  </notes>
  <notes>
    <title>Consent for publication</title>
    <p>Not applicable.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Competing interests</title>
    <p>The authors declare that they have no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1</label>
      <mixed-citation publication-type="other">Shen W, Wang J, Han J. Entity linking with a knowledge base: Issues, techniques, and solutions. IEEE Trans Knowl Data Eng. 2015; 27(2):443–60. 10.1109/TKDE.2014.2327028.</mixed-citation>
    </ref>
    <ref id="CR2">
      <label>2</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Rao</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>McNamee</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Dredze</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Entity linking: Finding extracted entities in a knowledge base</article-title>
        <source>Multi-source, Multilingual Information Extraction and Summarization</source>
        <year>2013</year>
        <publisher-loc>London</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Christen</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <source>Data Matching: Concepts and Techniques for Record Linkage, Entity Resolution, and Duplicate Detection</source>
        <year>2012</year>
        <publisher-loc>London</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4</label>
      <mixed-citation publication-type="other">Kouki P, Pujara J, Marcum C, Koehly L, Getoor L. Collective Entity Resolution in Familial Networks. 2017 IEEE Int Conf Data Min (ICDM). 2017:227–236. 10.1109/ICDM.2017.32.</mixed-citation>
    </ref>
    <ref id="CR5">
      <label>5</label>
      <mixed-citation publication-type="other">Ran C, Shen W, Wang J, Zhu X. Domain-specific knowledge base enrichment using wikipedia tables. Proc IEEE Int Conf Data Min ICDM. 2016; 2016-January:349–358. 10.1109/ICDM.2015.124.</mixed-citation>
    </ref>
    <ref id="CR6">
      <label>6</label>
      <mixed-citation publication-type="other">Wang J, Tong W, Yu H, Li M, Ma X, Cai H, Hanratty T, Han J. Mining multi-aspect reflection of news events in twitter: Discovery, linking and presentation. In: 2015 IEEE International Conference on Data Mining: 2015. p. 429–438. 10.1109/ICDM.2015.112.</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7</label>
      <mixed-citation publication-type="other">Chan SK, Lam W, Yu X. A cascaded approach to biomedical named entity recognition using a unified model. In: Seventh IEEE International Conference on Data Mining (ICDM 2007): 2007. p. 93–102. 10.1109/ICDM.2007.20.</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8</label>
      <mixed-citation publication-type="other">Krallinger M, Rabal O, Lourenço A, Oyarzabal J, Valencia A. Information Retrieval and Text Mining Technologies for Chemistry. Chem Rev. 2017:6–00851. 10.1021/acs.chemrev.6b00851.</mixed-citation>
    </ref>
    <ref id="CR9">
      <label>9</label>
      <mixed-citation publication-type="other">Rodriguez-Esteban R. Biomedical text mining and its applications. PLoS Comput Biol. 2009; 5(12):1–5. 10.1371/journal.pcbi.1000597.</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10</label>
      <mixed-citation publication-type="other">Garcia ACB, Ferraz IN, Pinto F. The role of domain ontology in text mining applications: The addminer project. In: Sixth IEEE International Conference on Data Mining - Workshops (ICDMW’06): 2006. p. 34–8. 10.1109/ICDMW.2006.157.</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Köhler</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Vasilevsky</surname>
            <given-names>NA</given-names>
          </name>
          <name>
            <surname>Engelstad</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Foster</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>McMurry</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Aymé</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Baynam</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Bello</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Boerkoel</surname>
            <given-names>CF</given-names>
          </name>
          <name>
            <surname>Boycott</surname>
            <given-names>KM</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The human phenotype ontology in 2017</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>45</volume>
        <issue>D1</issue>
        <fpage>865</fpage>
        <lpage>76</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkw1039</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12</label>
      <mixed-citation publication-type="other">Hastings J, Owen G, Dekker A, Ennis M, Kale N, Muthukrishnan V, Turner S, Swainston N, Mendes P, Steinbeck C. ChEBI in 2016: Improved services and an expanding collection of metabolites. Nucleic Acids Res. 2016; 44(D1):1214–9. 10.1093/nar/gkv1031.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13</label>
      <mixed-citation publication-type="other">Hastings J, De Matos P, Dekker A, Ennis M, Harsha B, Kale N, Muthukrishnan V, Owen G, Turner S, Williams M, Steinbeck C. The ChEBI reference database and ontology for biologically relevant chemistry: Enhancements for 2013. Nucleic Acids Res. 2013; 41(D1):456–63. 10.1093/nar/gks1146.</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brin</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Page</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>The anatomy of a large-scale hypertextual web search engine</article-title>
        <source>Comput Netw ISDN Syst</source>
        <year>1998</year>
        <volume>30</volume>
        <issue>1-7</issue>
        <fpage>107</fpage>
        <lpage>17</lpage>
        <pub-id pub-id-type="doi">10.1016/S0169-7552(98)00110-X</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15</label>
      <mixed-citation publication-type="other">Fogaras D, Rácz B. Towards Scaling Fully Personalized PageRank. Science. 2002:105–17.</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16</label>
      <mixed-citation publication-type="other">Sinha R, Mihalcea R. Unsupervised graph-based word sense disambiguation using measures of word semantic similarity. In: International Conference on Semantic Computing (ICSC 2007). IEEE: 2007. p. 363–9. 10.1109/icsc.2007.87.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <mixed-citation publication-type="other">Alhelbawy A, Gaizauskas R. Graph ranking for collective named entity disambiguation. In: Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers): 2014. p. 75–80.</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <mixed-citation publication-type="other">Lamurias A, Couto F. Text mining for bioinformatics using biomedical literature In: Ranganathan S., Nakai K., Schönbach C., Gribskov M., editors. Encyclopedia of Bioinformatics and Computational Biology vol. 1. Oxford: Oxford: Elsevier: 2019. 10.1016/B978-0-12-809633-8.20409-3.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19</label>
      <mixed-citation publication-type="other">Ratinov L, Roth D, Downey D, Anderson M. Local and global algorithms for disambiguation to wikipedia. In: Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11. Stroudsburg: Association for Computational Linguistics: 2011. p. 1375–1384. <ext-link ext-link-type="uri" xlink:href="http://dl.acm.org/citation.cfm?id=2002472.2002642">http://dl.acm.org/citation.cfm?id=2002472.2002642</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20</label>
      <mixed-citation publication-type="other">Radhakrishnan P, Talukdar P, Varma V. ELDEN: Improved Entity Linking Using Densified Knowledge Graphs; 2018. 10.18653/v1/N18-1167.</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21</label>
      <mixed-citation publication-type="other">Bunescu R, Pasca M. Using Encyclopedic Knowledge for Named Entity Disambiguation. Proc 11th Conf Eur Chapter Assoc Comput Linguist. 2006; April:3–7. <ext-link ext-link-type="uri" xlink:href="https://www.aclweb.org/anthology/E06-1002/">https://www.aclweb.org/anthology/E06-1002/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Ratinov</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Roth</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Downey</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Anderson</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Local and global algorithms for disambiguation to wikipedia</article-title>
        <source>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1</source>
        <year>2011</year>
        <publisher-loc>Portland, Oregon</publisher-loc>
        <publisher-name>Association for Computational Linguistics</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Hoffart</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yosef</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Bordino</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Fürstenau</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Pinkal</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Spaniol</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Taneva</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Thater</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Weikum</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Robust disambiguation of named entities in text</article-title>
        <source>Proceedings of the Conference on Empirical Methods in Natural Language Processing</source>
        <year>2011</year>
        <publisher-loc>Edinburgh</publisher-loc>
        <publisher-name>Association for Computational Linguistics</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Roth</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Relational inference for wikification</article-title>
        <source>Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</source>
        <year>2013</year>
        <publisher-loc>Seattle</publisher-loc>
        <publisher-name>Association for Computational Linguistics</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25</label>
      <mixed-citation publication-type="other">Pershina M, He Y, Grishman R. Personalized page rank for named entity disambiguation. In: Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Denver: Association for Computational Linguistics: 2015. p. 238–43. 10.3115/v1/N15-1026.</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Balmin</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hristidis</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Papakonstantinou</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Objectrank: Authority-based keyword search in databases</article-title>
        <source>Proceedings of the Thirtieth International Conference on Very Large Data bases-Volume 30</source>
        <year>2004</year>
        <publisher-loc>Toronto</publisher-loc>
        <publisher-name>VLDB Endowment</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Identifying potentially important concepts and relations in an ontology</article-title>
        <source>International Semantic Web Conference</source>
        <year>2008</year>
        <publisher-loc>Karlsruhe</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28</label>
      <mixed-citation publication-type="other">Singla P, Domingos P. Entity resolution with markov logic. In: Sixth International Conference on Data Mining (ICDM’06): 2006. p. 572–82. 10.1109/ICDM.2006.65.</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Morgan</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Cohen</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Fluck</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ruch</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Divoli</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Fundel</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Leaman</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Hakenberg</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Overview of BioCreative II gene normalization</article-title>
        <source>Genome Biol</source>
        <year>2008</year>
        <volume>9</volume>
        <issue>Suppl 2</issue>
        <fpage>3</fpage>
        <pub-id pub-id-type="doi">10.1186/gb-2008-9-s2-s3</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Kao</surname>
            <given-names>H-Y</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>C-H</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kuo</surname>
            <given-names>C-J</given-names>
          </name>
          <name>
            <surname>Hsu</surname>
            <given-names>C-N</given-names>
          </name>
          <name>
            <surname>Tsai</surname>
            <given-names>RT-H</given-names>
          </name>
          <name>
            <surname>Dai</surname>
            <given-names>H-J</given-names>
          </name>
          <name>
            <surname>Okazaki</surname>
            <given-names>N</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The gene normalization task in biocreative iii</article-title>
        <source>BMC Bioinformatics</source>
        <year>2011</year>
        <volume>12</volume>
        <issue>8</issue>
        <fpage>2</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-12-S8-S2</pub-id>
        <pub-id pub-id-type="pmid">21205299</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31</label>
      <mixed-citation publication-type="other">Tsuruoka Y, Miwa M, Hamamoto K, Tsujii J, Ananiadou S. Discovering and visualizing indirect associations between biomedical concepts. Bioinformatics. 2011; 27(13):111–9. 10.1093/bioinformatics/btr214.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32</label>
      <mixed-citation publication-type="other">Smith L, Tanabe LK, Ando RJn, Kuo C-jJ, Chung I-fF, Hsu C-NN, Lin Y-sS, Klinger R, Friedrich CM, Ganchev K, Torii M, Liu H, Haddow B, Struble CA, Povinelli RJ, Vlachos A, Baumgartner WA, Hunter L, Carpenter B, Tsai RT-h, Dai H-J, Liu F, Chen Y, Sun C, Katrenko S, Adriaans P, Blaschke C, Torres R, Neves M, Nakov P, Divoli A, Maña-López M, Mata J, Wilbur WJ, et al.Overview of BioCreative II gene mention recognition,. Genome Biol. 2008; 9 Suppl 2(Suppl 2):2. 10.1186/gb-2008-9-s2-s2.</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33</label>
      <mixed-citation publication-type="other">Ferreira JD, Inácio B, Salek RM, Couto FM. Assessing public metabolomics metadata, towards improving quality. J Integr Bioinformatics. 2017; 14(4).</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>JG</given-names>
          </name>
          <name>
            <surname>Howsmon</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Hahn</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>McGuinness</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hendler</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Entity linking for biomedical literature</article-title>
        <source>BMC Med Inform Decis Making</source>
        <year>2015</year>
        <volume>15</volume>
        <issue>1</issue>
        <fpage>4</fpage>
        <pub-id pub-id-type="doi">10.1186/1472-6947-15-S1-S4</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35</label>
      <mixed-citation publication-type="other">Lobo M, Lamurias A, Couto F. Identifying human phenotype terms by combining machine learning and validation rules. BioMed Res Int. 2017; 2017. 10.1155/2017/8565739.</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36</label>
      <mixed-citation publication-type="other">Bada M, Eckert M, Evans D, Garcia K, Shipley K, Sitnikov D, Baumgartner Jr WA, Cohen KB, Verspoor K, Blake JA, Hunter LE. Concept annotation in the CRAFT corpus. BMC Bioinformatics. 2012; 61(Suppl 13). 10.1186/1471-2105-13-161.</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37</label>
      <mixed-citation publication-type="other">Boguslav M, Cohen KB, Jr. WAB, Hunter LE. Improving precision in concept normalization:566–77. 10.1142/9789813235533_0052.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tsai</surname>
            <given-names>C-T</given-names>
          </name>
          <name>
            <surname>Roth</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Concept grounding to multiple knowledge bases via indirect supervision</article-title>
        <source>Trans Assoc Comput Linguist</source>
        <year>2016</year>
        <volume>4</volume>
        <fpage>141</fpage>
        <lpage>54</lpage>
        <pub-id pub-id-type="doi">10.1162/tacl_a_00089</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Resnik</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Using information content to evaluate semantic similarity in a taxonomy</article-title>
        <source>International Joint Conference on Artificial Intelligence</source>
        <year>1995</year>
        <publisher-loc>Montreal</publisher-loc>
        <publisher-name>Citeseer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40</label>
      <mixed-citation publication-type="other">Couto F, Lamurias A. Encyclopedia of Bioinformatics and Computational Biology In: Ranganathan S., Nakai K., Schönbach C., Gribskov M., editors. Oxford: Oxford: Elsevier: 2019. p. 870–6. 10.1016/B978-0-12-809633-8.20401-9.</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>An information-theoretic definition of similarity</article-title>
        <source>ICML</source>
        <year>1998</year>
        <publisher-loc>Madison, Wisconsin</publisher-loc>
        <publisher-name>Citeseer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42</label>
      <mixed-citation publication-type="other">Jiang JJ, Conrath DW. Semantic similarity based on corpus statistics and lexical taxonomy. In: Proceedings of the 10th Research on Computational Linguistics International Conference. Taipei: The Association for Computational Linguistics and Chinese Language Processing (ACLCLP): 1997. p. 19–33. <ext-link ext-link-type="uri" xlink:href="http://www.aclweb.org/anthology/O97-1002">http://www.aclweb.org/anthology/O97-1002</ext-link>.</mixed-citation>
    </ref>
  </ref-list>
</back>
