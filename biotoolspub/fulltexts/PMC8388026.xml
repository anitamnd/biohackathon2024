<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8388026</article-id>
    <article-id pub-id-type="pmid">33244599</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa991</article-id>
    <article-id pub-id-type="publisher-id">btaa991</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Applications Notes</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Data and Text Mining</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>i2d: an R package for simulating data from images and the implications in biomedical research</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-7796-2441</contrib-id>
        <name>
          <surname>Liang</surname>
          <given-names>Xiaoyu</given-names>
        </name>
        <aff><institution>Department of Psychiatry, Yale School of Medicine</institution>, New Haven, CT 06511, <country country="US">USA</country></aff>
        <aff><institution>VA Connecticut Healthcare System</institution>, West Haven, CT 06516, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hu</surname>
          <given-names>Ying</given-names>
        </name>
        <aff><institution>Center for Biomedical Bioinformatics and Information Technology, National Cancer Institute</institution>, Rockville, MD 20852, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yan</surname>
          <given-names>Chunhua</given-names>
        </name>
        <aff><institution>Center for Biomedical Bioinformatics and Information Technology, National Cancer Institute</institution>, Rockville, MD 20852, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Xu</surname>
          <given-names>Ke</given-names>
        </name>
        <xref rid="btaa991-cor1" ref-type="corresp"/>
        <aff><institution>Department of Psychiatry, Yale School of Medicine</institution>, New Haven, CT 06511, <country country="US">USA</country></aff>
        <aff><institution>VA Connecticut Healthcare System</institution>, West Haven, CT 06516, <country country="US">USA</country></aff>
        <!--ke.xu@yale.edu-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Jonathan</surname>
          <given-names>Wren</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btaa991-cor1">To whom correspondence should be addressed. <email>ke.xu@yale.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>15</day>
      <month>8</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-11-27">
      <day>27</day>
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>27</day>
      <month>11</month>
      <year>2020</year>
    </pub-date>
    <volume>37</volume>
    <issue>16</issue>
    <fpage>2497</fpage>
    <lpage>2498</lpage>
    <history>
      <date date-type="received">
        <day>13</day>
        <month>8</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>26</day>
        <month>10</month>
        <year>2020</year>
      </date>
      <date date-type="editorial-decision">
        <day>13</day>
        <month>11</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>16</day>
        <month>11</month>
        <year>2020</year>
      </date>
      <date date-type="corrected-typeset">
        <day>11</day>
        <month>12</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa991.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>High-quality imaging analyses have been proposed to drive innovation in biomedical and biological research. However, the application of images remains underexploited because of the limited capacity of human vision and the challenges in extracting quantitative information from images. Computationally extracting quantitative information from images is critical to overcoming this limitation. Here, we present a novel R package, i2d, to simulate data from an image based on digital convolution.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>The R package i2d allows users to transform an image into a simulated dataset that can be used to extract and analyze complex information in biomedical and biological research. The package also includes three novel and efficient methods for graph clustering based on simulated data, which can be used to dissect complex gene networks into sub-clusters that have similar biological functions.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>The code, the documentation, a tutorial and example data are available on an open source at: github.com/XiaoyuLiang/i2d.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>National Institute on Drug Abuse</institution>
            <institution-id institution-id-type="DOI">10.13039/100000026</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>R01042691</award-id>
        <award-id>R01DA047063</award-id>
        <award-id>R01DA047820</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="2"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Imaging is a powerful tool in biomedical and biological research that allows us to improve or extract valuable information on tissue composition, cellular structure, and fundamental molecular processes. Recent advances in biomedical and biological imaging have resulted in an explosion in the quality and quantity of images obtained in a digital format, such as JPEG, TIF, and RAW. However, these images remain underexploited because of the limited visual capacity of humans to detect precise imaging patterns. Computationally extracting quantitative information from an image is critical to overcoming this limitation.</p>
    <p>Methods for quantifying information from images have been developed. magick (<xref rid="btaa991-B2" ref-type="bibr">Ooms, 2018</xref>) and EBImage (<xref rid="btaa991-B3" ref-type="bibr">Pau et al., 2010</xref>) are well-established image processing toolboxes that provide functions for reading, writing, processing, and analyzing images. magick can process the basic information of an image such as image filtering, kernel convolution, and layer stacking. EBImage includes a range of fast image processing functions and represents images as multidimensional arrays containing pixel intensity values. However, neither of these methods can directly transform spatial information from images. The interpretation and analysis of images based on pixel intensity are challenging and result in misinformation or incomplete data analysis.</p>
    <p>In this article, based on image digitalization and convolution, we aim to develop a tool to simulate data points from an image such that simulated data are closer to real images when the number of simulated points tends to infinity. Here, we present an R package, i2d, depends on two R packages EBImage (<xref rid="btaa991-B3" ref-type="bibr">Pau <italic toggle="yes">et al.</italic>, 2010</xref>) and igraph (<xref rid="btaa991-B1" ref-type="bibr">Csardi and Nepusz, 2006</xref>), and allows users to easily transform an image into a simulated geographic coordinate dataset that can be used to extract and analyze the complex information in biomedical and biological images (<xref rid="btaa991-F1" ref-type="fig">Fig. 1</xref>). This utility allows users to perform graph clustering analysis using clustering algorithms based on distances among coordinates. More importantly, it includes three methods for graph clustering and trajectory analysis.</p>
    <fig position="float" id="btaa991-F1">
      <label>Fig. 1.</label>
      <caption>
        <p>Examples for using i2d. (<bold>a</bold>) Example for converting 2D images into digital coordinates using i2d. The left figure shows the original image. The middle and right figures show 2000 and 10000 simulated data points. (<bold>b</bold>) Example for simulating data points for a 3D image using i2d. The i2d function can also generate 3D digital coordinates by combining two 2D images. (<bold>c</bold>) Example for graph clustering based on 1000 simulated data points. The left figure shows the original image. The middle and right figures show different clusters finding by codeGCluster in i2d package. Different colors represent different clusters.</p>
      </caption>
      <graphic xlink:href="btaa991f1" position="float"/>
    </fig>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Image digitization</title>
      <p>We consider an image as a matrix whose elements are numbers between 0 and 255. The size of this matrix is image height by width by the number of image channels. A grayscale image has 1 channel, while a color image has 3 red–green–blue (RGB) channels. For a color image, the true color image RGB is converted to a grayscale intensity image. A grayscale image that has a one-pixel matrix is used for the subsequent analysis. Here, we summarize the general steps for image digitization:
</p>
      <list list-type="simple">
        <list-item>
          <p>Step 1: Normalize the image pixel value. Normalize the pixel value from <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mi>P</mml:mi><mml:mo>:</mml:mo><mml:mo> </mml:mo></mml:math></inline-formula>[0, 255] to <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>′</mml:mi></mml:mrow></mml:msup><mml:mo>:</mml:mo></mml:math></inline-formula> [0, 1] so that 0 is taken to be black and 1 is taken to be white. Values in between make up the different shades of gray. Since we prefer to select darker points, the pixel values are transferred into <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:msup><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>′</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> so that 0 is taken to be white and 1 is taken to be black.</p>
        </list-item>
        <list-item>
          <p>Step 2: 2D convolution filter. We filter an image such that the brightness value of the output image at a given pixel is a function of the weighted average of the brightness of the surrounding pixels. The aim of this step is to return the binary pixel matrix (containing only 0 and 1) resulting from the convolution filter of the original normalized image pixel matrix, where 0 represents points that cannot be selected and 1 represents points that can be selected. See the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref> for further details.</p>
        </list-item>
        <list-item>
          <p>Step 3: Convert to <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mi>x</mml:mi></mml:math></inline-formula> and <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mi>y</mml:mi></mml:math></inline-formula> coordinates. Based on the binary image matrix, we refer to the row number and column number of entries with value 1 in the binary image matrix as the <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mi>x</mml:mi></mml:math></inline-formula>-coordinate and <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mi>y</mml:mi></mml:math></inline-formula>-coordinate, respectively.</p>
        </list-item>
        <list-item>
          <p>Step 4: Randomly select points as simulated data. The users can decide the sample size (number of points). The data will be sampled with a replacement if the sample size is larger than the image dimension in step 3; otherwise, the data will be sampled without replacement.</p>
        </list-item>
      </list>
    </sec>
    <sec>
      <title>2.2 Graph clustering based on the digital data of the image</title>
      <p>Based on geographic coordinate data obtained from image digitization, the i2d package also includes three graph clustering algorithms depending on igraph package (<xref rid="btaa991-B1" ref-type="bibr">Csardi and Nepusz, 2006</xref>). Users can manually define the number of clusters. The details of the three methods can be found in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>. We treat each point as a vertex and the Euclidean distance between two points as the weight of the edge. Our goal is to find a partition <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mi mathvariant="script">G</mml:mi></mml:math></inline-formula> that partitions <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mi>N</mml:mi></mml:math></inline-formula> vertices <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> into <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mi>K</mml:mi></mml:math></inline-formula> disjoint clusters <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> taking into consideration the edge structure of the graph in such a way that there should be many edges within each cluster and relatively few between the clusters, where <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mi mathvariant="script">G</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> with <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi mathvariant="script">G</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mfenced open="{" close="}" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> and <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="script">k</mml:mi></mml:mrow></mml:msub><mml:mo>∩</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi>ℓ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">∅</mml:mi><mml:mi mathvariant="normal"> </mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="script">k</mml:mi><mml:mo>≠</mml:mo><mml:mi>ℓ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>. In the meanwhile, the outliers should be detected and removed before the clustering procedure.</p>
      <p>The minimum spanning tree (MST)-based graph clustering algorithm (mstGCluster) not only can be used to group the vertices into a specific number of clusters but also can filter the noise in the graph. Prim’s algorithm is used to find an MST of the graph. Then, we utilize the k-means clustering method to detect the noise in the graph. Last, removing <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> edges with the largest weights will group the vertices into <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mi>K</mml:mi></mml:math></inline-formula> disjoint clusters (<xref rid="sup1" ref-type="supplementary-material">Supplementary Figs S1 and S2</xref> in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>).</p>
      <p>The modularity optimization-based community detection method for graph clustering (codeGCluster) treats all the vertices as a big community. We separate the whole community into several small communities by removing the weak connections. The community detection methods, such as the Louvain algorithm, the fast-greedy modularity optimization algorithm, and the near linear time algorithm are used to find communities in graphs. We use iteration to separate the whole community into a specific number (<inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mi>K</mml:mi></mml:math></inline-formula>) of communities (<xref rid="btaa991-F1" ref-type="fig">Fig. 1c</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S3</xref> in <xref rid="sup1" ref-type="supplementary-material">Supplementary Material</xref>).</p>
      <p>The package also includes a function for trajectory analysis, which can be used for gene enrichment analysis and graph clustering. In detail, the longest path through the MST, corresponding to the longest distance of the vertices that were selected from the graph, is referred to as the ‘backbone’ of the tree. We extract the backbone and the long branches on the backbone of MST for trajectory analysis and graph clustering analysis.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Conclusions</title>
    <p>The developed R package i2d is a new tool for digital data simulation from images. The usage of i2d integrated into the R environment provides a flexible and powerful platform for image data handling and analysis. It is user friendly and easy and fast to operate. Furthermore, the simulated dataset can be used for extracting and investigating information in biomedical and biological images.</p>
    <sec>
      <title>Author Contributions</title>
      <p>Y.H. and C.Y. were responsible for the R package preparation, data analysis, and manuscript preparation. K.X. contributed to manuscript preparation. X.L. was responsible for the R package preparation and manuscript preparation. All authors read and approved the final manuscript.</p>
    </sec>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was supported by the National Institute on Drug Abuse [R01042691 (Xu), R01DA047063 (Xu and Aouizerat), R01DA047820 (Xu and Aouizerat)].</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btaa991_Supplementary_Data</label>
      <media xlink:href="btaa991_supplementary_data.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa991-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Csardi</surname><given-names>G.</given-names></string-name>, <string-name><surname>Nepusz</surname><given-names>T.</given-names></string-name></person-group> (<year>2006</year>) <article-title>The igraph software package for complex network research</article-title>. <source>Int. J. Complex Syst</source>., <volume>1695</volume>, <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa991-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ooms</surname><given-names>J.</given-names></string-name></person-group> (<year>2018</year>) Magick: advanced graphics and image-processing in R. <italic toggle="yes">CRAN. R package version, 1</italic>.</mixed-citation>
    </ref>
    <ref id="btaa991-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pau</surname><given-names>G.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2010</year>) <article-title>EBImage—an R package for image processing with applications to cellular phenotypes</article-title>. <source>Bioinformatics</source>, <volume>26</volume>, <fpage>979</fpage>–<lpage>981</lpage>.<pub-id pub-id-type="pmid">20338898</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
