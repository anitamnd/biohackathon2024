<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Physiol</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Physiol</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Physiol.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Physiology</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1664-042X</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9908962</article-id>
    <article-id pub-id-type="publisher-id">1076533</article-id>
    <article-id pub-id-type="doi">10.3389/fphys.2023.1076533</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Physiology</subject>
        <subj-group>
          <subject>Technology and Code</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Virtual Fly Brain—An interactive atlas of the <italic>Drosophila</italic> nervous system</article-title>
      <alt-title alt-title-type="left-running-head">Court et al.</alt-title>
      <alt-title alt-title-type="right-running-head">
        <ext-link xlink:href="https://doi.org/10.3389/fphys.2023.1076533" ext-link-type="uri">10.3389/fphys.2023.1076533</ext-link>
      </alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Court</surname>
          <given-names>Robert</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2114501/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Costa</surname>
          <given-names>Marta</given-names>
        </name>
        <xref rid="aff2" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pilgrim</surname>
          <given-names>Clare</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2076878/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Millburn</surname>
          <given-names>Gillian</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Holmes</surname>
          <given-names>Alex</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <xref rid="fn1" ref-type="author-notes">
          <sup>†</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>McLachlan</surname>
          <given-names>Alex</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2112443/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Larkin</surname>
          <given-names>Aoife</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Matentzoglu</surname>
          <given-names>Nicolas</given-names>
        </name>
        <xref rid="aff5" ref-type="aff">
          <sup>5</sup>
        </xref>
        <xref rid="fn1" ref-type="author-notes">
          <sup>†</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1298857/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Kir</surname>
          <given-names>Huseyin</given-names>
        </name>
        <xref rid="aff5" ref-type="aff">
          <sup>5</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Parkinson</surname>
          <given-names>Helen</given-names>
        </name>
        <xref rid="aff5" ref-type="aff">
          <sup>5</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Brown</surname>
          <given-names>Nicolas H.</given-names>
        </name>
        <xref rid="aff4" ref-type="aff">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>O’Kane</surname>
          <given-names>Cahir J.</given-names>
        </name>
        <xref rid="aff3" ref-type="aff">
          <sup>3</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/24168/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Armstrong</surname>
          <given-names>J. Douglas</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">
          <sup>1</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1858/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jefferis</surname>
          <given-names>Gregory S. X. E.</given-names>
        </name>
        <xref rid="aff6" ref-type="aff">
          <sup>6</sup>
        </xref>
        <uri xlink:href="https://loop.frontiersin.org/people/2783/overview"/>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Osumi-Sutherland</surname>
          <given-names>David</given-names>
        </name>
        <xref rid="aff5" ref-type="aff">
          <sup>5</sup>
        </xref>
        <xref rid="c001" ref-type="corresp">*</xref>
        <uri xlink:href="https://loop.frontiersin.org/people/1990964/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>School of Informatics</institution>, <institution>University of Edinburgh</institution>, <addr-line>Edinburgh</addr-line>, <country>United Kingtom</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Department of Zoology</institution>, <institution>University of Cambridge</institution>, <addr-line>Cambridge</addr-line>, <country>United Kingtom</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Department of Genetics</institution>, <institution>University of Cambridge</institution>, <addr-line>Cambridge</addr-line>, <country>United Kingtom</country></aff>
    <aff id="aff4"><sup>4</sup><institution>Department of Physiology</institution>, <institution>Development and Neuroscience</institution>, <institution>University of Cambridge</institution>, <addr-line>Cambridge</addr-line>, <country>United Kingtom</country></aff>
    <aff id="aff5"><sup>5</sup><institution>European Bioinformatics Institute (EMBL-EBI)</institution>, <addr-line>Hinxton</addr-line>, <country>United Kingtom</country></aff>
    <aff id="aff6"><sup>6</sup><institution>MRC Laboratory for Molecular Biology</institution>, <addr-line>Cambridge</addr-line>, <country>United Kingtom</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p><bold>Edited by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/66122/overview" ext-link-type="uri">Iris Salecker</ext-link>, INSERM U1024 Institut de biologie de l'Ecole Normale Supérieure, France</p>
      </fn>
      <fn fn-type="edited-by">
        <p><bold>Reviewed by:</bold><ext-link xlink:href="https://loop.frontiersin.org/people/1082496/overview" ext-link-type="uri">Aljoscha Nern</ext-link>, Janelia Research Campus, United States</p>
        <p><ext-link xlink:href="https://loop.frontiersin.org/people/999016/overview" ext-link-type="uri">Nikolaos Konstantinides</ext-link>, UMR7592 Institut Jacques Monod (IJM), France</p>
      </fn>
      <corresp id="c001">*Correspondence: David Osumi-Sutherland, <email>davidos@ebi.ac.uk</email>
</corresp>
      <fn fn-type="present-address" id="fn1">
        <p><sup>†</sup><bold>Present Address:</bold> Alex Holmes, Sanger Institute, Hinxton, Cambridgeshire, United Kingdom</p>
        <p>Nicolas Matentzoglu, Semanticly, Athens, Greece</p>
      </fn>
      <fn fn-type="other">
        <p>This article was submitted to Invertebrate Physiology, a section of the journal Frontiers in Physiology</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>26</day>
      <month>1</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>14</volume>
    <elocation-id>1076533</elocation-id>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>10</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>02</day>
        <month>1</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2023 Court, Costa, Pilgrim, Millburn, Holmes, McLachlan, Larkin, Matentzoglu, Kir, Parkinson, Brown, O’Kane, Armstrong, Jefferis and Osumi-Sutherland.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Court, Costa, Pilgrim, Millburn, Holmes, McLachlan, Larkin, Matentzoglu, Kir, Parkinson, Brown, O’Kane, Armstrong, Jefferis and Osumi-Sutherland</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>As a model organism, <italic>Drosophila</italic> is uniquely placed to contribute to our understanding of how brains control complex behavior. Not only does it have complex adaptive behaviors, but also a uniquely powerful genetic toolkit, increasingly complete dense connectomic maps of the central nervous system and a rapidly growing set of transcriptomic profiles of cell types. But this also poses a challenge: Given the massive amounts of available data, how are researchers to Find, Access, Integrate and Reuse (FAIR) relevant data in order to develop an integrated anatomical and molecular picture of circuits, inform hypothesis generation, and find reagents for experiments to test these hypotheses? The Virtual Fly Brain (<ext-link xlink:href="http://virtualflybrain.org" ext-link-type="uri">virtualflybrain.org</ext-link>) web application &amp; API provide a solution to this problem, using FAIR principles to integrate 3D images of neurons and brain regions, connectomics, transcriptomics and reagent expression data covering the whole CNS in both larva and adult. Users can search for neurons, neuroanatomy and reagents by name, location, or connectivity, <italic>via</italic> text search, clicking on 3D images, search-by-image, and queries by type (e.g., dopaminergic neuron) or properties (e.g., synaptic input in the antennal lobe). Returned results include cross-registered 3D images that can be explored in linked 2D and 3D browsers or downloaded under open licenses, and extensive descriptions of cell types and regions curated from the literature. These solutions are potentially extensible to cover similar atlasing and data integration challenges in vertebrates.</p>
    </abstract>
    <kwd-group>
      <kwd>drosophila</kwd>
      <kwd>atlas</kwd>
      <kwd>connectomics</kwd>
      <kwd>transcriptomics</kwd>
      <kwd>neurobiology</kwd>
      <kwd>ontology</kwd>
      <kwd>FAIR</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">
          <institution-wrap>
            <institution>Wellcome Trust
</institution>
            <institution-id institution-id-type="doi">10.13039/100010269</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id award-type="contract" rid="cn001">105023/A/14/Z 208379/Z/17/Z 223741/Z/21/Z</award-id>
      </award-group>
      <funding-statement>This work was supported by the Wellcome Trust grants 105023/A/14/Z, 208379/Z/17/Z, and 223741/Z/21/Z.</funding-statement>
    </funding-group>
  </article-meta>
</front>
<body>
  <sec id="s1">
    <title>1 Introduction</title>
    <p>Understanding the circuit basis of behavior is one of the grand challenges facing the biomedical sciences and has major implications for human society and health. Massive amounts of data that are relevant to this challenge are now available across multiple species. Dense connectomes covering a significant portion of the <italic>Drosophila</italic> central nervous system are available (<xref rid="B53" ref-type="bibr">Scheffer et al., 2020</xref>) and ongoing efforts are increasing coverage (<xref rid="B16" ref-type="bibr">Dorkenwald et al., 2020</xref>). Single-cell transcriptomic profiles, integrated with morphology and functional profiles, are available for a majority of cell types in the optic lobe (<xref rid="B31" ref-type="bibr">Kurmangaliyev et al., 2020</xref>; <xref rid="B47" ref-type="bibr">Özel et al., 2021</xref>) and more sparsely in other nervous system and brain regions (<xref rid="B13" ref-type="bibr">Davie et al., 2018</xref>; <xref rid="B34" ref-type="bibr">Li et al., 2022</xref>). In <italic>Drosophila</italic>, transgenic techniques (<xref rid="B35" ref-type="bibr">Luan et al., 2006</xref>; <xref rid="B48" ref-type="bibr">Pfeiffer et al., 2010</xref>) and libraries of transgenes (<xref rid="B27" ref-type="bibr">Jenett et al., 2012</xref>; <xref rid="B58" ref-type="bibr">Tirian and Dickson, 2017</xref>) allow precise targeting of neuron types to manipulate and measure their activity, enabling the genetic dissection of circuit function.</p>
    <p>While this opens up unprecedented opportunities for understanding the circuit basis of behavior, it also poses new challenges: How can researchers know when they have data about one of the thousands of new cell types being identified and characterized in the literature and as part of large-scale analyses? How can they explore these massive new datasets, in conjunction with the literature, to generate hypotheses and form an integrated picture of the anatomical and molecular nature of circuits? How can researchers share their data in a way that conforms to FAIR standards (<xref rid="B59" ref-type="bibr">Wilkinson et al., 2016</xref>) and easily reuse the data of others?</p>
    <p>Virtual Fly Brain (VFB) (<xref rid="B40" ref-type="bibr">Milyaev et al., 2012</xref>) provides a solution to these problems by integrating massive amounts of data derived from diverse techniques and multiple sources along with curated information from the literature. All this content is available <italic>via</italic> a web application and an API. The web application facilitates finding and integrating information about brain regions, neuron types and individual registered images, <italic>via</italic> sophisticated text search, point and click interaction with 3D images and graph visualizations and <italic>via</italic> semantic queries (e.g., finding neurons by type and location). All data is integrated following FAIR principles and we provide tools to enable users to share and integrate their data on VFB following these principles. VFB integrates images, connectomics and transcriptomics data by using two strategies - semantic and image-based.</p>
    <p>Semantic integration is facilitated by the <italic>Drosophila</italic> Anatomy Ontology (DAO) (<xref rid="B11" ref-type="bibr">Costa et al., 2013</xref>), curated from the literature, and increasingly from data-driven identification of cell types. The DAO serves both as a queryable store of knowledge about <italic>Drosophila</italic> neuroanatomy, cell types and their classifications, and a source of terms for annotating data across modalities including images, connectomics, transcriptomics and expression patterns. Standard parcellation schemes have been developed for all <italic>Drosophila</italic> central nervous system regions and stages including adult brain and ventral nerve cord (<xref rid="B22" ref-type="bibr">Ito et al., 2014</xref>; <xref rid="B12" ref-type="bibr">Court et al., 2020</xref>). These parcellation schemes provide a standard reference for CNS regions defined in the DAO. Following FAIR data standards, all data on VFB is accessible <italic>via</italic> an identifier, in the form of a URL, that is globally unique, persistent, and resolvable.</p>
    <p>Image-based integration makes use of standard templates (see <xref rid="F1" ref-type="fig">Figure 1</xref>) onto which image data is registered (morphed), allowing hundreds of thousands of images from multiple imaging modalities to be co-registered so that they can be viewed and analyzed programmatically in a common coordinate space. Cross-registration has made it possible to design search algorithms to compare neurons, including NBLAST (<xref rid="B10" ref-type="bibr">Costa et al., 2016</xref>), which provides a similarity score for any two cross-registered neuron tracings based on how similar their morphology and location are. These and other alignment-style queries are key to solving another problem—that of defining neuron types in ways that allow them to be identified from data using quantitative criteria rather than, as traditionally, using qualitative criteria and human judgment. A similar problem was solved in genomics by the use of BLAST in combination with versioned genome builds, annotated with gene models. Registered 3D neuron images can be mapped to a type using NBLAST, as long as we have a set of reference images for neuron types. While the concept of a gene is hard to define non-controversially (<xref rid="B50" ref-type="bibr">Portin and Wilkins, 2017</xref>), and gene model annotation can be error prone and controversial (<xref rid="B29" ref-type="bibr">Koonin and Galperin, 2003</xref>), there is enough shared understanding and agreement to use sequence similarity to map genomic and transcriptomic sequence data to specific genes. The concept of cell type is even more controversial (<xref rid="B1" ref-type="bibr">Bates et al., 2019</xref>; <xref rid="B61" ref-type="bibr">Zeng, 2022</xref>), but neurobiologists typically group cells sharing morphological, connectomic, functional and developmental properties together under a common name, and generally refer to such groupings as types. For neurons in the <italic>Drosophila</italic> nervous system, shared location and morphology is highly indicative of shared developmental origin, connectivity and response properties (<xref rid="B1" ref-type="bibr">Bates et al., 2019</xref>). Neurons with shared location and morphology can be consistently identified across individuals and are present in numbers from 1–1000 per brain hemisphere (<xref rid="B1" ref-type="bibr">Bates et al., 2019</xref>). Shared morphology is therefore a strong indicator of cell type.</p>
    <fig position="float" id="F1">
      <label>FIGURE 1</label>
      <caption>
        <p><italic>Templates and content</italic>. VFB has templates that integrate image data into common coordinate spaces and many more that serve as references for datasets in their native space The first four rows of the table provide details of the most up-to-date integrative templates on VFB: the JRC2018 unisex adult brain template (<xref rid="B4" ref-type="bibr">Bogovic et al., 2019</xref>) has the largest number of aligned images, which include over 26,500 EM images from CATMAID FAFB (<xref rid="B62" ref-type="bibr">Zheng et al., 2018</xref>) and the Janelia Hemibrain (<xref rid="B53" ref-type="bibr">Scheffer et al., 2020</xref>) combined, over 70,000 images showing expression patterns or fragments of expression patterns from sources including FlyCircuit (<xref rid="B7" ref-type="bibr">Chiang et al., 2010</xref>; <xref rid="B55" ref-type="bibr">Shih et al., 2015</xref>) and Janelia FlyLight (<xref rid="B39" ref-type="bibr">Meissner et al., 2022</xref>) and 46 painted neuropil domains (painted by Kazunori Shinomiya); The JRC2018 adult ventral nerve cord (VNC) template (<xref rid="B4" ref-type="bibr">Bogovic et al., 2019</xref>) has over 2,000 EM images from CATMAID FANC (<xref rid="B49" ref-type="bibr">Phelps et al., 2021</xref>), over 18,000 images of expression patterns from sources including FlyLight and 21 painted domains (<xref rid="B12" ref-type="bibr">Court et al., 2020</xref>) The Seymour L1 template has nearly 3,500 EM images from CATMAID L1 (<xref rid="B43" ref-type="bibr">Ohyama et al., 2015</xref>); The Wood2018 template has 255 painted domains (David Wood and Volker Hartenstein, unpublished). The rest of the table provides details of three of the available reference templated on VFB: the McKellar2020 adult head template has painted domains showing the adult pharyngeal musculature (<xref rid="B38" ref-type="bibr">McKellar et al., 2020</xref>); the hemibrain has the hemibrain connectome in its native space, along with a more detailed parcellation scheme (<xref rid="B53" ref-type="bibr">Scheffer et al., 2020</xref>); the Ito half-brain is the original reference template and parcellation scheme for the BrainName standard (<xref rid="B22" ref-type="bibr">Ito et al., 2014</xref>).</p>
      </caption>
      <graphic xlink:href="fphys-14-1076533-g001" position="float"/>
    </fig>
    <p>Clustering neurons with similar morphology based on NBLAST score identifies many previously identified types (<xref rid="B10" ref-type="bibr">Costa et al., 2016</xref>) indicating that NBLAST can be used reliably in many cases to identify neuronal type. In the case of sequence data, annotated reference genomes provide a reference standard for gene identity. While we have no equivalent standard reference for cell type morphologies, the availability of large connectomics projects with annotated neuron types, assessed at least in part using morphology <italic>via</italic> NBLAST scores, has provided us with a good <italic>de facto</italic> standard. For example, the largest of these published to date (<xref rid="B53" ref-type="bibr">Scheffer et al., 2020</xref>) is represented on VFB along with mappings to &gt;1,100 known types and assigned a further 3864 provisional types based on NBLAST similarity—all cataloged and classified using DAO neuron type terms. VFB can therefore support cell type identification from data using NBLAST for a large and growing set of neuron types, assigning standard aoverlapping functionality such as NeuronBridge (<xref rid="B9" ref-type="bibr">Clements et al., 2022</xref>) and neuprint (<xref rid="B8" ref-type="bibr">Clements et al., 2020</xref>), are to support data-discovery across many sources, to make first-pass exploration of complex data easy and to link that data to the literature. For further analysis, users can download data, or follow links from data on VFB to the same data on these other resources with their own data downloads, data exploration and search tools.</p>
    <p>We believe that this initial data discovery and exploration step will become increasingly important as more and more single-cell transcriptomics and connectomics datasets become available. Consistent semantic annotation across diverse datasets on VFB is key to achieving this. Not only does this support matching of cell types across datasets, it also allows for sophisticated queries that group data in biologically relevant ways, for example by gross classification, location or connectivity of annotated neurons.</p>
  </sec>
  <sec sec-type="methods" id="s2">
    <title>2 Methods</title>
    <sec id="s2-1">
      <title>2.1 Curation</title>
      <p>VFB curators work closely with FlyBase, the EBI single cell expression atlas curators and data providers to curate information from the literature and annotate data in a timely manner. Literature curation captures information about neuron types and transgene expression and takes advantage of FlyBase curation, including community curation efforts and text-mining pipelines (<xref rid="B5" ref-type="bibr">Bunt et al., 2012</xref>; <xref rid="B19" ref-type="bibr">Halperin et al., 2012</xref>; <xref rid="B32" ref-type="bibr">Larkin et al., 2021</xref>) to easily identify and prioritize papers that contain data of high priority for VFB curation. Data curation standardizes the annotation of neuron types and transgenes in data using the same ontology and feature identifiers as FlyBase.</p>
    </sec>
    <sec id="s2-2">
      <title>2.2 Semantic integration</title>
      <sec id="s2-2-1">
        <title>2.2.1 Ontologies and semantic schemas</title>
        <p>VFB is built around the <italic>Drosophila</italic> Anatomy Ontology (DAO) (<xref rid="B11" ref-type="bibr">Costa et al., 2013</xref>), a manually curated, query-able classification of <italic>Drosophila</italic> anatomical structures and cell types expressed in Web Ontology Language (OWL) (<xref rid="B21" ref-type="bibr">World Wide Web Consortium, 2012</xref>). DAO is built using community standards (<xref rid="B25" ref-type="bibr">Jackson et al., 2021</xref>) and tooling (<xref rid="B36" ref-type="bibr">Matentzoglu et al., 2022</xref>) for sustainable, scalable ontology development. Neuroanatomy is represented in DAO using a standard schema that supports recording neuronal location, connectivity, lineage and function and incorporates basic spatial reasoning (<xref rid="B45" ref-type="bibr">Osumi-Sutherland et al., 2012</xref>). We have extended this schema to incorporate relations for recording brain regions in which a neuron type has its <italic>major</italic> inputs and outputs, for example, that the synaptic input onto DA1 uniglomerular antennal lobe projection neurons is concentrated in the DA1 glomerulus (<xref rid="B56" ref-type="bibr">Stocker et al., 1990</xref>; <xref rid="B3" ref-type="bibr">Bates et al., 2020a</xref>) distinguishing these from small numbers of inputs and outputs that occur on almost all parts of any neuron in connectomics data. Using this schema and information curated from over 1000 papers, the DAO represents 13,000 neuroanatomical structures and cell types, including over 9800 terms for neuron types (e.g. DL1 adPN) and more general neuron classifications (e.g. “cholinergic neuron”, “uniglomerular antennal lobe projection neuron”). The neuron types include over 3800 that are predicted from connectomics data (<xref rid="B53" ref-type="bibr">Scheffer et al., 2020</xref>) and over 2750 types for which we have curated lineage, which is reflected in links to neuroblast (e.g. develops from BAl3p neuroblast), lineage clones (e.g. part of BAl3p lineage clone) and classifications (e.g. BAl3p lineage neuron). This ontology and OWL schema, along with an OWL schema for representing image metadata and image registration (<xref rid="B44" ref-type="bibr">Osumi-Sutherland et al., 2014</xref>), are also used to classify and record the properties of cell types depicted in 3D images, connectomics and transcriptomics data on VFB. This means that the same OWL queries can be used both to query for data about individual neurons, and also to drive searches for neuron types based on their classification and properties (see, for example, the compound query in <xref rid="F4" ref-type="fig">Figure 4</xref>).</p>
        <p>The common OWL schema is also used to drive a system of semantic tags - short, informative pieces of text (e.g., cholinergic, larval, synaptic_neuropil) that appear as badges attached to ontology terms and data on the VFB site (<xref rid="F2" ref-type="fig">Figures 2, 4–8</xref>) and are used to drive filters for text search (<xref rid="F3" ref-type="fig">Figure 3</xref>).</p>
        <fig position="float" id="F2">
          <label>FIGURE 2</label>
          <caption>
            <p><italic>General layout and browsing</italic>. <bold>(A)</bold> The Slice Viewer allows users to view single slices of the Z-stack of the displayed elements. <bold>(B)</bold> The 3D Viewer shows entities in 3D space, allowing zoom and rotation. <bold>(C)</bold> The Template ROI Browser shows the neuropil regions of the current template (arranged hierarchically) and allows these to be added to the display. <bold>(D)</bold> The Layers tool acts as a color key for all the entities currently loaded and features a set of controls allowing content to be removed, hidden or recolored. <bold>(E)</bold> The term info shows details of a selected entity, in this case a cell type. Available images of this cell type are shown as thumbnails and can be added to the viewer by clicking the thumbnail. Split-GAL4 lines that target this cell type are also shown in the Term Info. Cell types also have a description based on published information. Term Info for a different entity can be shown by clicking on something in the Term Info or Layers panes, searching or using the left/right arrows above the Term Info pane. Arrowhead at top right indicates the search tool.</p>
          </caption>
          <graphic xlink:href="fphys-14-1076533-g002" position="float"/>
        </fig>
        <fig position="float" id="F3">
          <label>FIGURE 3</label>
          <caption>
            <p><italic>Search</italic>. Clicking the magnifying glass in the top right of the page will open the Search tool. Searching based on synonyms is supported and semantic tags on the right of each result provide extra information. Filters can be accessed by clicking on the lines on the right. <bold>(A)</bold> With no filters applied, results for “Or49a ORN” are a mixture of images (marked with *) and cell types from adult and larval stages. <bold>(B)</bold> To restrict results to larval neuron types, excluding images, filters can be applied to narrow down the results list, choosing a positive filter (green) for Larva and Neuron, and a negative filter (red) for Image.</p>
          </caption>
          <graphic xlink:href="fphys-14-1076533-g003" position="float"/>
        </fig>
        <p>The DAO is also used to annotate transgene expression patterns and single cell RNAseq data in FlyBase—the latter as part of a collaboration between FlyBase and the EBI single cell expression atlas. We convert all of this into a standard OWL representation for import into VFB. The spatial reasoning built into the DAO allows us to provide a highly enriched set of results when users query for transgenes expressed in an anatomical structure—returning transgenes expressed in neurons that have some part in this structure or any of its substructures (<xref rid="B40" ref-type="bibr">Milyaev et al., 2012</xref>; <xref rid="B45" ref-type="bibr">Osumi-Sutherland et al., 2012</xref>).</p>
        <p>While OWL has many advantages for standardization and querying, it cannot serve all VFB use cases. OWL is not designed for fast, tunable text search with autosuggestion. For this VFB uses an Apache SOLR document store. It is also not ideally suited for automatically generating graph and tree visualizations or for maintaining and updating image annotations. The graph database Neo4J (<xref rid="B41" ref-type="bibr">Neo4j Graph Data Platform, 2020</xref>) is ideal for both of these use cases and provides a parallel system for graph pattern queries (e.g. for image metadata) that is simpler and more flexible than SPARQL (<xref rid="B37" ref-type="bibr">McCarthy et al., 2012</xref>), the standard graph-pattern query language for OWL. We developed a standard translation between OWL and Neo4j, covering a limited subset of OWL, optimized for readability and queryability and supported by a Java Library (<xref rid="B57" ref-type="bibr">Tan et al., 2021</xref>). This allows us to maintain a curation database in Neo4J (VFB-KB) and a front-facing Neo4j server for generating trees (<xref rid="F2" ref-type="fig">Figure 2C</xref>), graphs (<xref rid="F8" ref-type="fig">Figure 8</xref>) and graph queries for the VFB web-app and API.</p>
      </sec>
      <sec id="s2-2-2">
        <title>2.2.2 Data integration pipeline and servers</title>
        <p>The VFB extract transform and load (ETL) pipeline extracts data from diverse sources (FlyBase (<xref rid="B18" ref-type="bibr">Gramates et al., 2022</xref>), CATMAID (<xref rid="B52" ref-type="bibr">Saalfeld et al., 2009</xref>), NeuronBridge (<xref rid="B9" ref-type="bibr">Clements et al., 2022</xref>), NeuPrint (<xref rid="B8" ref-type="bibr">Clements et al., 2020</xref>)) into ROBOT templates (<xref rid="B24" ref-type="bibr">Jackson et al., 2019</xref>) specifying their transformation to OWL following our standard schemas. We then load the resulting OWL files into a triple store, along with the various ontologies used in data annotation (also in OWL) and an OWL version of our curation database (VFB-KB). The triple store integrates all of this content around a common set of persistent URLs that serve as identifiers for ontology terms, data instances etc, merging and deduplicating references to these entities. Downstream of the triplestore, a pipeline adds semantic tags using OWL and SPARQL queries, and loads the front-facing servers.</p>
      </sec>
    </sec>
    <sec id="s2-3">
      <title>2.3 Image integration and NBLAST</title>
      <p>Unregistered images were registered using CMTK with nine degrees of freedom followed by a non-rigid registration (<xref rid="B51" ref-type="bibr">Rohlfing and Maurer, 2003</xref>; <xref rid="B26" ref-type="bibr">Jefferis et al., 2007</xref>). If necessary, data was moved to the left side of the brain by flipping and then applying a mirroring registration (<xref rid="B2" ref-type="bibr">Bates et al., 2020b</xref>). We made use of standard bridging registrations wherever possible to cross-register images from external templates, or between templates on VFB. For images registered to templates not hosted on VFB or where we needed to move between templates on VFB, we made use of bridging registrations wherever possible (<xref rid="B2" ref-type="bibr">Bates et al., 2020b</xref>).</p>
      <p>The NBLAST implementation in Navis (<xref rid="B3" ref-type="bibr">Bates et al., 2020a</xref>) was used to generate a complete NBLAST matrix comparing all single neuron skeletons in VFB, including skeletons from the Janelia hemibrain (<xref rid="B53" ref-type="bibr">Scheffer et al., 2020</xref>), FAFB (<xref rid="B62" ref-type="bibr">Zheng et al., 2018</xref>) and FlyCircuit (<xref rid="B7" ref-type="bibr">Chiang et al., 2010</xref>) datasets) with each other and with all split-GAL4 expression patterns in the VFB database registered to the JRC2018 adult unisex brain template (<xref rid="B4" ref-type="bibr">Bogovic et al., 2019</xref>). Most neuron types are present as bilaterally symmetric pairs. To match the same type on opposite sides of the brain, each neuron-to-neuron NBLAST was performed and then repeated with one of the neurons mirrored along the midline and only the highest of these two scores was retained. Split-GAL4 expression patterns almost always label the same neuron(s) on both sides of the brain, so we used NBLAST to compare a union of each neuron and its mirror image across the midline to each split-GAL4 expression pattern. For NBLAST between neurons and from neurons to split-Gal4 expression patterns, mean scores were calculated so that a single score represents each pairwise comparison, regardless of direction. This biases the results towards sparse expression patterns, minimizing off-target expression and avoids promoting high scoring matches from neuron fragments to whole neurons, as the score for whole neuron to fragment in these cases will be low. In cases where a neuron is known to be truncated at the edge of a sample, the neuron being compared to it is also truncated to the same boundary before the mean NBLAST score is calculated. Queries on VFB (<xref rid="F5" ref-type="fig">Figures 5</xref>–<xref rid="F7" ref-type="fig">7</xref>) use precomputed NBLAST scores for neuron to neuron and neuron to Split-Gal4 as well as color depth MIP scores (<xref rid="B46" ref-type="bibr">Otsuna et al., 2018</xref>) from NeuronBridge (<xref rid="B9" ref-type="bibr">Clements et al., 2022</xref>) for neuron to neuron, neuron to Split-GAL4 and neuron to MultiColor FlpOut (MCFO) images of expression patterns. All scores are stored in the VFB Neo4j database. NBLAST scores are stored as a sparse matrix where scores below 0.25 are removed and the remaining scores are limited to the top 20 for any given neuron or expression pattern.</p>
      <p>To test the efficacy of NBLAST and CDMIP similarity score queries in finding targeting split-GAL4 combinations for neuron types, we used associations between neuron types and split-Gal4 combinations curated from the literature and for which we have images (746 associations). We first found all individual neurons of each type for which a known targeting split Gal4 combination exists. For each type for which a known targeting split-Gal4 combination exists, we found the highest NBLAST or CDMIP score between individual neurons of this type and images of each Split-GAL4 combination in the database. To measure recall for a realistic browsing scenario, we tested whether known targeting split-GAL4 combinations were returned in the first 20 hits. We calculated precision across all returned results. This strategy prevents results from being overwhelmed by false positives in cases where there are many neurons or split-GAL4 combinations of a single type.</p>
      <p>The VFB website is driven by a customized version of the Geppetto web framework (<xref rid="B6" ref-type="bibr">Cantarelli et al., 2018</xref>). The 2D slice viewer improves on the neuron/expression image overlap of the previous (<xref rid="B40" ref-type="bibr">Milyaev et al., 2012</xref>) VFB 1.0 viewer to allow multiple signal overlaps with true color blending. To achieve this, webGL 2D canvas color blending was used in combination with auto-assigned, maximally spread, LAB-space signal colors. This ensures the maximum possible color differentiation with a new feature allowing the user to select any point on the image showing all signals present at that point. This allows VFB to deliver a desktop stack scrolling experience by preemptively buffering neighboring slices for all displayed items and supporting mouse gestures for navigation through the stack.</p>
    </sec>
    <sec id="s2-4">
      <title>2.4 Visualizing circuits and part-trees</title>
      <p>A Neo4j query is used to automatically generate a browsable tree (template ROI browser, <xref rid="F2" ref-type="fig">Figure 2C</xref>) for each template, based on the painted domains associated with it.</p>
      <p>The circuit browser uses an implementation of Yen’s k-Shortest Path algorithm in the Neo4j Graph Data Science package v2.1 (<ext-link xlink:href="https://neo4j.com/docs/graph-data-science/current/algorithms/yens" ext-link-type="uri">https://neo4j.com/docs/graph-data-science/current/algorithms/yens</ext-link>) to find the k shortest, most highly weighted paths between two selected neurons in a connectome, filtering out connections with a weight below a specified threshold. The weight is stored as a Neo4j edge property and corresponds to the number of synaptic connections in a given direction between two neurons, where one presynaptic density to one T-bar corresponds to a single connection. Yen’s algorithm calculates the lowest weighted paths, so we need to invert the weights. In our current implementation we calculate inverted weight by subtracting from 5000, a weight just above the highest weighted synaptic connection (4299 connecting DPM_R (FlyEM-HB:5813105172) to APL_R (FlyEM-HB:425790257). We are likely to adopt a less arbitrary solution in future, but based on expert feedback, this tuning provides useful, intuitive results.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <title>3 Results</title>
    <sec id="s3-1">
      <title>3.1 Organization of data</title>
      <p>Images on Virtual Fly Brain are cross registered to a growing set of standard 3D image templates covering all central nervous system regions and post-embryonic stages (<xref rid="F1" ref-type="fig">Figure 1</xref>). Integrative templates for adult brain, adult ventral nerve cord and larval nervous system at instars 1 and 3, integrate cross-registered image data from many data sources. For example, our main adult brain template has almost 100,000 cross-registered images from 64 datasets, including connectomics data from electron and light microscopy images of neurons, lineage clones and expression patterns. These come from a mixture of small-lab datasets and large datasets imported <italic>via</italic> well-established pipelines from external databases including FlyCircuit (<xref rid="B7" ref-type="bibr">Chiang et al., 2010</xref>; <xref rid="B55" ref-type="bibr">Shih et al., 2015</xref>), Flylight (<xref rid="B39" ref-type="bibr">Meissner et al., 2022</xref>), CATMAID (<xref rid="B52" ref-type="bibr">Saalfeld et al., 2009</xref>) (multiple instances hosted on VFB servers) and neuPrint (<xref rid="B8" ref-type="bibr">Clements et al., 2020</xref>). Where they provide useful reference, VFB also includes templates for single datasets in their native space, including dense connectomes, standard parcellation references and images depicting the relationship of the CNS to musculature. In summary, this cross referencing of data at the image level underpins a central feature of VFB to support the integration and comparison of many disparate datasets from across the <italic>Drosophila</italic> community.</p>
      <p>To support FAIR sharing, in particular, simple and consistent ways to access and reference data, every image on VFB is assigned a globally unique, persistent, resolvable identifier in the form of a URL. This is important not only for hosted data that has no associated identifiers, but also for the large numbers of images that are assigned local identifiers on other resources, as these local identifiers are not globally unique or easily resolvable without further information. For example, the multiple CATMAID instances hosted by VFB have clashing neuron IDs, so these IDs are not sufficient to resolve data on CATMAID without additional information about which CATMAID instance the neuron ID came from. In contrast, the VFB-assigned URL resolves to the relevant, persistent page on VFB, from which data can be downloaded and can also be used to access data <italic>via</italic> our API. Both site and API provide mappings to IDs and links to data on external sites.</p>
    </sec>
    <sec id="s3-2">
      <title>3.2 Exploring neuroanatomy</title>
      <p>The VFB web app consists of a set of widgets for exploring and displaying information about neuroanatomy, which can be arranged as desired, using an internal windowing system. <xref rid="F1" ref-type="fig">Figure 1</xref> shows the default layout and features content related to our running example—the neuron WEDPN2 (adult wedge projection neuron 2). A pair of image browsers displays the same content in 2D (<xref rid="F1" ref-type="fig">Figure 1A</xref>) and 3D (<xref rid="F1" ref-type="fig">Figure 1B</xref>), in this case images of a WEDPN2 neuron (green), the wedge brain region (pale blue/grey) and the expression pattern of a split-GAL4 combination that targets WEDPN2 (pink). A foldable parts tree (<xref rid="F1" ref-type="fig">Figure 1C</xref>) can be used to select and color brain regions, in this case the wedge is selected and coloured. A layers tool (layers, <xref rid="F1" ref-type="fig">Figure 1D</xref>) serves as both a key to displayed content, associating colors with image names and types, and a control panel for selecting, removing, hiding or recoloring content. Finally, a term Information window (<xref rid="F1" ref-type="fig">Figure 1E</xref>) displays detailed information about selected content, as well as a set of queries allowing access to extended information. In this case, the selected content is a neuron type with symbol WEDPN2 (reflecting the typical way this neuron type is referred to), and a longer, more descriptive name that uniquely distinguishes it in the context of all <italic>Drosophila</italic> anatomy. Term information also includes, alternative names (synonyms), classification (e.g., WEDPN2 is classified as a wedge projection neuron, GABA-ergic neuron and a BAlp3 lineage neuron), relationships to other anatomical classes, a referenced description, examples images (2D projection), curated split-GAL4 drivers and queries.</p>
      <p>All selected 3D images can be downloaded separately or in bulk, with downloads incorporating licensing and references, allowing users to use these in their own analysis in combination with local data.</p>
      <p>Virtual Fly Brain makes it easy to find and integrate information about brain regions, neuron types and individual registered images <italic>via</italic> a range of different entry points: text search; point and click selection from images; queries for neurons by their location and properties; and data driven search.</p>
      <sec id="s3-2-1">
        <title>3.2.1 Text search</title>
        <p>Users can search for neuroanatomical structures, driver expression patterns, cell-types or images starting from almost any name found in the literature using an intelligent, autocomplete-based search system (<xref rid="F3" ref-type="fig">Figure 3</xref>) accessed from the header of all VFB pages (<xref rid="F2" ref-type="fig">Figure 2</xref>, yellow arrowhead). Search works irrespective of the order of words used and covers curated synonyms as well as official names and symbols from DAO (<xref rid="F3" ref-type="fig">Figure 3A</xref>). A set of search filters (<xref rid="F3" ref-type="fig">Figure 3B</xref>) allows users to restrict search content positively or negatively by type (e.g., neuron, anatomy, expression pattern), stage (e.g. adult, larva) or data type (e.g. image).</p>
      </sec>
      <sec id="s3-2-2">
        <title>3.2.2 Point-and-click selection from images</title>
        <p>Users can browse and select brain regions by pointing and clicking on the 2D slice browser or the tree browser, triggering display of reference information about the brain region and giving access to queries for neurons by location.</p>
      </sec>
      <sec id="s3-2-3">
        <title>3.2.3 Queries for neurons by their location and properties</title>
        <p>VFB can also be used to explore neuroanatomy and find and select content <italic>via</italic> more sophisticated queries tailored to the content selected and driven by both data and information curated from the literature. For example, starting from a brain region, users can search innervating neuron types or images and can intersect these queries to refine them. <xref rid="F4" ref-type="fig">Figure 4</xref> shows an example of this type of query, finding images of wedge projection neurons that have some part in the lateral horn. Queries for neurons also include queries by lineage, e.g. WEDPN2 can be found from a query for components of ‘adult BAlp3 lineage clone'.</p>
        <fig position="float" id="F4">
          <label>FIGURE 4</label>
          <caption>
            <p>Compound Queries. The Term Info pane <bold>(A)</bold> shows queries available in the TermInfo of “wedge projection neuron”. Clicking on the query for available images of “wedge projection neuron” bring up a results table <bold>(B)</bold> which can be further refined by clicking “Refine Query” underneath. The query interface <bold>(C,D)</bold> shows the original query and allows a second query to be run to find items that fit both sets of criteria, in this case images of neurons that also have some part in the lateral horn. Images in the subsequent results table <bold>(E)</bold> can be added to the viewer by clicking the checkboxes on the right.</p>
          </caption>
          <graphic xlink:href="fphys-14-1076533-g004" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec id="s3-3">
      <title>3.3 Data-driven search</title>
      <p>In addition to semantic search, VFB features neuron structure searches that find images depicting neurons with similar location and morphology to that depicted in an input image. These searches are driven by NBLAST similarity scores (<xref rid="B2" ref-type="bibr">Bates et al., 2020b</xref>), precomputed by VFB, and color-depth Maximum Intensity Projection (color-depth MIP) scores (<xref rid="B46" ref-type="bibr">Otsuna et al., 2018</xref>), provided by NeuronBridge (<xref rid="B9" ref-type="bibr">Clements et al., 2022</xref>). The Janelia hemibrain (<xref rid="B53" ref-type="bibr">Scheffer et al., 2020</xref>) and FAFB (<xref rid="B62" ref-type="bibr">Zheng et al., 2018</xref>) and the many studies that have traced neuronal circuits in these, provide <italic>de facto</italic> reference image datasets for identifying neuron types using NBLAST.</p>
      <p><xref rid="F5" ref-type="fig">Figure 5</xref> shows an NBLAST search for potential types for an untyped neuron (Cha-F-600036) from the FlyCircuit dataset (<xref rid="B7" ref-type="bibr">Chiang et al., 2010</xref>). Multiple high scoring matches to typed neurons support the assignment of this neuron as a type of WEDPN2 neuron. Searches like this will become a critically important tool as we enter an era of comparative connectomics as resources to manually annotate new data cannot keep pace with high throughput data collection. For example, the FlyWire (<xref rid="B16" ref-type="bibr">Dorkenwald et al., 2020</xref>) project is generating a minimally annotated, dense reconstruction of the FAFB brain. Making sense of this data will require cross-sample mapping of neuron types <italic>via</italic> algorithms like NBLAST.</p>
      <fig position="float" id="F5">
        <label>FIGURE 5</label>
        <caption>
          <p><italic>Typing neurons using NBLAST</italic>. <bold>(A)</bold> TermIinfo for a neuron from FlyCircuit (<xref rid="B7" ref-type="bibr">Chiang et al., 2010</xref>) with no curated type other than “neuron”. <bold>(B)</bold> NBLAST query results for neurons similar morphology to the untyped query neuron. The top five results are all typed as “adult wedge projection neuron 2”. <bold>(C)</bold> image comparing the morphology of the query FlyCircuit neuron [“Cha-F-600036 (VFB_00007511)” in green] and the ‘adult wedge projection neuron 2' “WEDPN2B_R (FlyEM-HB:916828438) [VFB_jrchk7yi]" WEDPN2B_R in magenta).</p>
        </caption>
        <graphic xlink:href="fphys-14-1076533-g005" position="float"/>
      </fig>
    </sec>
    <sec id="s3-4">
      <title>3.4 Finding transgenic driver lines</title>
      <p>In order to genetically dissect neural circuit function, <italic>Drosophila</italic> neurobiologists need to precisely target specific types of neurons to experimentally manipulate their activity. This is typically achieved using a split-GAL4 driver system that initiates downstream expression at the intersection of two transgene expression patterns (<xref rid="B35" ref-type="bibr">Luan et al., 2006</xref>). In these types of experiments, the biggest bottleneck is finding combinations of driver lines that precisely target the neuron type of interest.</p>
      <p>VFB features over 99,000 queryable records, curated from the literature, associating transgenes and split combinations, recorded using FlyBase Identifiers, with the anatomical structures and cell types in which they are expressed, curated using the DAO. This includes 1508 split-GAL4 combinations targeting almost 700 types of neuron. These are displayed in the Term Information window for each neuron type, for example, WEDPN2 is targeted by split-GAL4 combination “R66A08 ∩ R85A07” (<xref rid="F2" ref-type="fig">Figure 2E</xref>). Novel combinations of hemidrivers can potentially be found from among the curated records linking full transgene expression patterns to neuron types. However, these results only scratch the surface of untested split-GAL4 driver combinations from among the millions that are possible.</p>
      <p>VFB also features over 43,000 registered 3D images of transgene expression patterns covering 16,876 transgenic driver lines, including over 2700 covering 579 split-GAL4 combinations. As well as full expression pattern images, VFB also hosts almost 50,000 images of stochastically generated subsets of neurons from full GAL4 expression patterns and split-GAL4 combinations, generated by a variety of techniques, including Multi-Color Flip Out (MCFO) (<xref rid="B42" ref-type="bibr">Nern et al., 2015</xref>).</p>
      <p>VFB can be used to query for potential split driver combinations targeting any neuron type for which an image is available, using NBLAST scores (<xref rid="F6" ref-type="fig">Figures 6B–D</xref>) or color-depth maximum intensity projection (CDMIP) similarity scores (<xref rid="B46" ref-type="bibr">Otsuna et al., 2018</xref>) from NeuronBridge (<xref rid="B9" ref-type="bibr">Clements et al., 2022</xref>) (<xref rid="F7" ref-type="fig">Figure 7</xref>). In the example shown in <xref rid="F6" ref-type="fig">Figure 6C</xref>, one of the top three hits from an NBLAST search (R66A08 ∩ R85A07) is confirmed by information curated from the literature. Analysis of the ability of NBLAST queries from neurons to return associations between neuron types and split combinations curated from the literature, shows that 53% of curated matches are returned in the top 20 (aggregating individual images by neuron type and Split-Gal4 combination), with a precision of 26% (calculated using all returned results). The same analysis using CDMIP scores gives much lower recall (16%) in the top 20 hits and precision (19%), calculated using all returned results. Given the high false positive rate, results need to be screened by eye. Each potential driver line can be loaded onto the stack browser together with the query neuron to manually check the quality of the match (<xref rid="F6" ref-type="fig">Figure 6D</xref>). <xref rid="F7" ref-type="fig">Figure 7</xref> shows CDMIP search returning images of subsets of neurons in MCFO images of full driver expression patterns, potentially finding new hemidriver combinations. Where multiple driver lines are identified that have little overlap, this can form the basis for an intersectional approach to target a neuron type more precisely.</p>
      <fig position="float" id="F6">
        <label>FIGURE 6</label>
        <caption>
          <p>Identifying Split-GAL4 combinations that potentially target a query neuron. <bold>(A)</bold> TermInfo for a neuron, “WEDPN2B_R”, type “adult wedge projection neuron 2” (WEDPN2), from the hemibrain dataset. This neuron will be used for an NBLAST search. <bold>(B)</bold> NBLAST query results showing Split-GAL4 driver line results and NBLAST scores. The third result (with the checked tickbox) was selected for further investigation (panels C and D). <bold>(C)</bold> Image of the query neuron skeleton (yellow) and Split-GAL4 expression pattern point cloud (blue) overlap. <bold>(D)</bold> A search for neuron types that this Split-GAL4 combination is known to target, curated from the literature, finds the type of the neuron used for the NBLAST search (WEDPN2), supporting the NBLAST query result in this case.</p>
        </caption>
        <graphic xlink:href="fphys-14-1076533-g006" position="float"/>
      </fig>
      <fig position="float" id="F7">
        <label>FIGURE 7</label>
        <caption>
          <p>Identifying potential GAL4 drivers using color depth MIP scores <bold>(A)</bold> query results for the neuron “WEDPN2B_R”, showing hits to multiple MCFO images of driver line results and color depth MIP scores. The second (sparse MCFO expression) and fourth (dense MCFO expression) results (checked tickboxes) were selected for further investigation (panels (B) and (C), respectively). <bold>(B)</bold> Image of the query neuron (green) and expression pattern point cloud from a sparse line (magenta) overlap. <bold>(C)</bold> The same query neuron (green) also overlaps with the expression pattern point cloud of a dense line (magenta).</p>
        </caption>
        <graphic xlink:href="fphys-14-1076533-g007" position="float"/>
      </fig>
    </sec>
    <sec id="s3-5">
      <title>3.5 Exploring connectomics</title>
      <p>VFB includes connectomics data from multiple sources, encoded as directional pairwise links between individual neurons, with weight recorded as the number of synaptic connections. Where available, we also record directional pairwise links between neurons and the brain regions they innervate, again including weight as number of synapses. These data are used to generate direct reports of connectivity for specific neurons. The latter is also used to drive queries for neuron images by region (<xref rid="F4" ref-type="fig">Figure 4</xref>).</p>
      <p>Our circuit query tool allows users to find the shortest, most highly weighted paths between any two neurons in the same connectome (<xref rid="F8" ref-type="fig">Figure 8</xref>). Users can specify a minimum weight for connections and the number of paths to return. For ease of viewing, the results are arranged in a graph with rows and columns, with the first and last columns being the start and end neurons specified in the query. Neurons in the circuit between these two, are arranged in order of the numbers of hops from the starting neuron. Higher ranking paths (by length and weight) are displayed in lower rows. Edges display weight (forward and reverse). Nodes (neurons) display type and gross classification (e.g. cholinergic, olfactory). All nodes are selectable, for display of term information, classification, images etc.</p>
      <fig position="float" id="F8">
        <label>FIGURE 8</label>
        <caption>
          <p><italic>Circuit browser.</italic> A circuit diagram of paths between “WEDPN2B_R” and “VP2_adPN_R”. Rectangles represent neurons with the symbols of classes at the top, names of individual neurons at the bottom and colors corresponding to gross classifications in the middle. The legend for these gross classifications can be seen in the top-right [note the WDPN2 is classed as both cholinergic and glutamatergic based on antibody staining evidence (<xref rid="B15" ref-type="bibr">Dolan et al., 2019</xref>)]. Pathways are ordered from “strongest” at the bottom to “weakest” at the top. Arrows show the direction of synaptic connectivity and numbers outside of brackets show the number of synapses annotated for each connection. Numbers inside brackets show the number of synapses in the opposite direction.</p>
        </caption>
        <graphic xlink:href="fphys-14-1076533-g008" position="float"/>
      </fig>
    </sec>
    <sec id="s3-6">
      <title>3.6 Exploring single cell transcriptomics</title>
      <p>One of the major strengths of VFB’s semantic approach is the ease with which very different data types can be cross-integrated. VFB is working with FlyBase and the EBI single-cell atlas to annotate neuron types in single-cell transcriptomics data using the DAO. This allows queries for associated transcriptomics data from any cell type term or class in VFB. <xref rid="F9" ref-type="fig">Figure 9A</xref> shows the results of a query for transcriptomics data for olfactory receptor neurons. The results table returns clusters, the datasets they are from and their cell type annotations. <xref rid="F9" ref-type="fig">Figure 9B</xref> shows an example of summary expression data for one of these clusters, from the Fly Cell Atlas dataset (<xref rid="B34" ref-type="bibr">Li et al., 2022</xref>). For each gene these results show the level of expression, the proportion of expressing cells in the annotated cluster and semantic tags summarizing gene function, derived from Gene Ontology Molecular Function and Gene Group annotations in FlyBase (<xref rid="F9" ref-type="fig">Figure 9B</xref>). Links from datasets to the EBI Single Cell Expression Atlas allow further exploration of data and download of cell-by-gene matrices and associated annotations for local analysis.</p>
      <fig position="float" id="F9">
        <label>FIGURE 9</label>
        <caption>
          <p><italic>Single Cell RNAseq</italic> (not yet live) <bold>(A)</bold> Each transcriptional cluster is linked to a cell type in the <italic>Drosophila</italic> Anatomy Ontology (curation done by Single Cell Expression Atlas and FlyBase) facilitating searches based on cell type (typically more general types than we have for connectomics data). <bold>(B)</bold> Each gene expressed in more than half of the cells in a cluster will be viewable in VFB with its expression level and extent (proportion of cells in cluster that transcript was detected in) and semantic tags representing the gene’s function (based on GO and Gene Group annotations from FlyBase).</p>
        </caption>
        <graphic xlink:href="fphys-14-1076533-g009" position="float"/>
      </fig>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>4 Discussion</title>
    <sec id="s4-1">
      <title>4.1 Summary</title>
      <p>VFB helps users build an integrated picture of the anatomical and molecular nature of neurons and the circuits they form by providing access to a wealth of curated information and data <italic>via</italic> multiple search and query systems and reports. A user might start with the name of a neuron type from the literature (<xref rid="F3" ref-type="fig">Figure 3</xref>) and from there find a description, links to further papers (<xref rid="F2" ref-type="fig">Figure 2</xref>), downloadable 3D images (<xref rid="F2" ref-type="fig">Figures 2</xref>, <xref rid="F4" ref-type="fig">4</xref>), a list of known and potential driver combinations to use to target the neuron type (<xref rid="F5" ref-type="fig">Figures 5</xref>–<xref rid="F7" ref-type="fig">7</xref>) connectomics data (<xref rid="F8" ref-type="fig">Figure 8</xref>), transcriptomics data (<xref rid="F9" ref-type="fig">Figure 9</xref>). Or they might start from a phenotype caused by a particular split-GAL4 driver and from there, want to find neurons where this split-GAL4 driver is known, or predicted, to be expressed along with connectomics and transcriptomics reports for these neurons from multiple sources. They might be interested to find circuit paths between two neurons they believe to be targeted by two different split driver combinations that cause similar phenotypes when used to silence target neurons (<xref rid="F8" ref-type="fig">Figure 8</xref>). In all cases, VFB supports rapid data discovery across datasets and provides a fast, accessible starting point for basic data exploration, while also supporting more advanced data exploration and analysis by providing data downloads and links to and identifiers for the same data in other tools and resources. Following FAIR data standards, all hosted data is downloadable under open licenses, with tracked provenance and rich metadata.</p>
    </sec>
    <sec id="s4-2">
      <title>4.2 Relationship to other resources</title>
      <p>Virtual Fly Brain adds unique value through comprehensive semantic and image-based data integration and inclusion of curated information from the literature. Related resources have some overlaps in functionality, but also have their own distinct functionalities and often include data that fall outside the current scope of VFB. VFB facilitates access to these resources <italic>via</italic> an extensive and flexible system of link-outs that link to the same data or entities on external sites. We are tightly integrated with FlyBase, which we link out to for all information on genetic features (genes, alleles, transgenes). We provide direct links from data on VFB to the same data on the sites of major data-providers (FlyCircuit (<xref rid="B7" ref-type="bibr">Chiang et al., 2010</xref>; <xref rid="B55" ref-type="bibr">Shih et al., 2015</xref>), FlyLight (<xref rid="B39" ref-type="bibr">Meissner et al., 2022</xref>), NeuronBridge (<xref rid="B9" ref-type="bibr">Clements et al., 2022</xref>), neuPrint (<xref rid="B8" ref-type="bibr">Clements et al., 2020</xref>) and CATMAID (<xref rid="B52" ref-type="bibr">Saalfeld et al., 2009</xref>)), which, while limited to their own data, each provide distinct query tools and additional meta-data over that captured by VFB. In the case of CATMAID, VFB is also the sole host for official, public facing CATMAID servers for multiple connectomics datasets, providing a vital service to the community by archiving these data sets in their original form as they are released, as well as integrating them into VFB.</p>
      <p>VFB also provides a home for many datasets from independent labs that are not integrated by other resources and so would otherwise be inaccessible. This includes many independently generated Split-GAL4 datasets, registered image data for neuroblast lineage clones covering the adult brain, kindly contributed by the labs of Kei Ito and Tzumin Lee (<xref rid="B23" ref-type="bibr">Ito et al., 2013</xref>; <xref rid="B60" ref-type="bibr">Yu et al., 2013</xref>) and a dataset of 3D images of pharyngeal muscles, innervating motor neurons and split-GAL4 drivers (<xref rid="B38" ref-type="bibr">McKellar et al., 2020</xref>).</p>
      <p>We also link out to related resources including InsectBrain DB (<xref rid="B20" ref-type="bibr">Heinze et al., 2021</xref>), which hosts 3D parcellation schemes and neuron images for brains of many insects and <ext-link xlink:href="http://larvalbrain.org" ext-link-type="uri">larvalbrain.org</ext-link>, which hosts reference information for larval anatomy and expression patterns. We currently do not link to Fruit Fly Brain Observatory/FlyBrainLab (<xref rid="B33" ref-type="bibr">Lazar et al., 2021</xref>), which is focussed on facilitating simulation, because their dynamically generated content pages do not easily support linking.</p>
    </sec>
    <sec id="s4-3">
      <title>4.3 Future plans</title>
      <p>VFB is built around a unique combination of curated knowledge and data, united by a common semantic schema: the same classifications and relationships are used to record the properties of types of neurons and individual instances of neurons; relationships between individuals can be associated directly with data, such as synapse number or NBLAST similarity score. Future extensions to VFB will continue to leverage this combination to provide unique functionality. For example, future versions of the connectomics browser will feature aggregation of synaptic strength to neuron types. We will continue to expand the inclusion of queryable data relevant to curated knowledge in VFB, including incorporating lineage inferred from primary neurite location and neurotransmitter predicted from the application of machine learning to electron microscopy data (<xref rid="B17" ref-type="bibr">Eckstein et al., 2020</xref>).</p>
      <sec id="s4-3-1">
        <title>4.3.1 Leveraging data to improve annotation; leveraging annotation to test algorithms</title>
        <p>VFB increasingly combines curated knowledge claims with data relevant to those claims. For example, we include both curated claims about typing of individual neurons and the Split-Gal4 lines that target them as well as similarity scores that support these claims. This is potentially useful for finding mis-annotated data—e.g., if a neuron annotated as a specific cell type has a very low similarity score to all other neurons annotated to that type, the annotation is likely to be wrong and can be flagged as low reliability. In developing tools that use similarity scores, such as the proposed split finder service (described below), curated information can serve as a reference set to test and tune the tool, as demonstrated in the results described in <xref rid="s3-4" ref-type="sec">Section 3.4</xref>.</p>
      </sec>
      <sec id="s4-3-2">
        <title>4.3.2 Split finder service</title>
        <p>Currently, users wanting to find split-GAL4 drivers for neuron types on VFB can start from a neuron type and search for drivers curated as expressed in that neuron, based on the literature, or navigate down to an individual neuron to search by precomputed NBLAST or color-depth MIP scores. The latter functionality partially overlaps with that of NeuronBridge (<xref rid="B9" ref-type="bibr">Clements et al., 2022</xref>). We will extend NBLAST scores on VFB to include all MCFO images from FlyLight. Taking advantage of VFB semantics, we are working on a unified split-finder tool that supports a one click-search from neuron type for candidate split driver combinations and hemidrivers based on a combination of associations curated from the and similarity scores. Results will be viewable as color depth MIP images as these are faster to screen by eye for matches (<xref rid="B46" ref-type="bibr">Otsuna et al., 2018</xref>)<bold>.</bold>
</p>
      </sec>
      <sec id="s4-3-3">
        <title>4.3.3 Supporting comparative connectomics</title>
        <p>In the near future, VFB will ingest multiple large connectomics datasets with variable coverage and accuracy of neuron type annotation. BLAST-like algorithms, in the short-term NBLAST for morphology, but longer term supplemented by CBLAST (<xref rid="B53" ref-type="bibr">Scheffer et al., 2020</xref>) for connectivity and potentially methods that use subcellular features (<xref rid="B54" ref-type="bibr">Schubert et al., 2019</xref>; <xref rid="B63" ref-type="bibr">Zinchenko et al., 2022</xref>), will be critical to help users to interpret this data by facilitating prediction and assignment of neuron types. For example, a user finding paths between untyped neurons from FlyWire using our circuit browsing tool will be able to use NBLAST to find predicted types for neurons in the circuit, where these exist in other reference data sets. We will also investigate adding precomputed predicted neuron types based on NBLAST scores, with appropriate caveats, as a way of making browsing more efficient.</p>
        <p>We are also about to release a service allowing registered neuron skeletons to be uploaded to the VFB site for viewing in the context of other 3D data and running NBLAST to predict neuron type.</p>
      </sec>
      <sec id="s4-3-4">
        <title>4.3.4 Integrating connectomics with transcriptomics</title>
        <p>The ability to resolve neuronal cell types in <italic>Drosophila</italic> single cell RNAseq data to the same granularity as achieved when typing by morphology and connectomics is improving as larger numbers of cells are profiled (<xref rid="B1" ref-type="bibr">Bates et al., 2019</xref>) as developmental data is integrated, and with the help of bulk scRNAseq data for cells marked with Split-GAL4 drivers and mappings from these to cell types (<xref rid="B14" ref-type="bibr">Davis et al., 2020</xref>; <xref rid="B31" ref-type="bibr">Kurmangaliyev et al., 2020</xref>; <xref rid="B47" ref-type="bibr">Özel et al., 2021</xref>). The fruits of these approaches are most apparent in the optic lobe where we now have transcriptomics profiles of 200 cell types and the first integrated analysis across transcriptomic and connectomic data is now available (<xref rid="B31" ref-type="bibr">Kurmangaliyev et al., 2020</xref>; <xref rid="B47" ref-type="bibr">Özel et al., 2021</xref>).</p>
        <p>While VFB currently only has limited scRNAseq data available (see <xref rid="F9" ref-type="fig">Figure 9</xref>), the number of annotated datasets is growing rapidly thanks to a collaboration with FlyBase and the EBI single cell expression atlas. As the number of datasets and cell types covered by transcriptomics and connectomics data and mapped to split-GAL4 lines increases, mapping between datasets for combined analysis will become increasingly challenging. Providing uniform, standardized annotation of cell types and their classifications across all these data types and datasets puts VFB in a strong position to facilitate these combined analyses. The VFB web application provides mechanisms for browsing connections and finding paths in the connectomics data (<xref rid="F8" ref-type="fig">Figure 8</xref>) and for rapidly navigating from this to transcriptomic profiles. More sophisticated analyses will be facilitated by accessing this data through the VFB_connect API.</p>
      </sec>
      <sec id="s4-3-5">
        <title>4.3.5 Improving 3D image visualizations</title>
        <p>To limit load on user’s laptops, the 3D browser uses maximum projection point-cloud renderings of expression. While enabling multiple expression patterns to be overlaid, this approach is not ideal as it can throw away fine details and can fail to adequately reflect graded expression. We are working to transition the site to a full resolution display of graded expression data, taking advantage of advances in bandwidth and laptop GPUs.</p>
      </sec>
      <sec id="s4-3-6">
        <title>4.3.6 Adding anatomical context</title>
        <p>VFB is in the process of ingesting multiple 3D datasets depicting the relationship of the nervous system to its inputs and outputs, including a complete 3D larva reconstructed from transmission electron microscopy data from serial sections and reconstruction of a fly leg, complete with muscles, sense organs and their innervating neurons from X-ray holographic nano-tomography data (<xref rid="B30" ref-type="bibr">Kuan et al., 2020</xref>).</p>
      </sec>
      <sec id="s4-3-7">
        <title>4.3.7 Improved links to the literature</title>
        <p>While VFB already extensively links neuron types to relevant literature <italic>via</italic> curation, we are improving this using a natural language processing pipeline in order to provide, as far as possible, a complete and accurate coverage of literature links for all neuron types.</p>
      </sec>
      <sec id="s4-3-8">
        <title>4.3.8 User data upload</title>
        <p>An interface allowing users to upload and annotate their own registered image data, receiving a globally unique, persistent, resolvable identifier in return, is currently in beta testing.</p>
      </sec>
    </sec>
  </sec>
  <sec id="s4-4">
    <title>5 Conclusions</title>
    <p>Virtual Fly Brain enables its users to search, browse, view, and download diverse, cross-integrated data relevant to developing and testing hypotheses about the circuit basis of complex behaviors in <italic>Drosophila</italic>. As the volume and diversity of both small and large <italic>Drosophila</italic> neurobiology datasets increases, and these are incorporated into VFB, the role of VFB as a data integrator will become increasingly important, especially for solving the problem of identifying neuron types in poorly annotated datasets and for finding reagents to target these neurons.</p>
    <p>Similar data integration issues are faced in large atlasing projects in other species, including major planned atlases of mouse, human and non-human primates (<xref rid="B28" ref-type="bibr">Kaiser, 2022</xref>). The solutions developed by VFB are likely to prove useful in these cases too.</p>
    <p>The semantic integration pipeline developed for VFB has already been re-used to underpin the Allen Brain Atlas cell type explorer (<ext-link xlink:href="https://knowledge.brain-map.org/celltypes" ext-link-type="uri">https://knowledge.brain-map.org/celltypes</ext-link>) a multi-modal single cell transcriptomics atlas of the mammalian primary motor cortex (<xref rid="B57" ref-type="bibr">Tan et al., 2021</xref>). It is also being re-used to drive autocomplete in the Cell Annotation Platform (<ext-link xlink:href="http://celltype.info" ext-link-type="uri">http://celltype.info</ext-link>).</p>
  </sec>
</body>
<back>
  <ack>
    <p>Data providers: FlyCircuit: CC Lo, AS Chiang; FlyLight: W Korf, G Meissner, R Svirskas; FlyEM: K Shinomiya; T Wolff, L Scheffer, S Takemura; H Otsuna; ,A Cardona, T Lee, Y Aso, S Hampel, S. Cachero, M-J Dolan, K Ito, J Kohl, CE McKellar, T Nojima, D Turner-Evans, M Ho, D Wood. Technical support: MetaCell: D del Piano, G Idili, M Cantarelli. CATMAID:T Kazimiers, A Cardona Advisors: K Ito, D Shepherd; M Landgraf; M Pankratz; G Tavosanis; I Horrocks; CJ Mungall, J. Balhoff, P Schlegel, V Hartenstein.</p>
  </ack>
  <sec sec-type="data-availability" id="s5">
    <title>Data availability statement</title>
    <p>Publicly available datasets were analyzed in this study. All data is available, following FAIR data sharing standards, through the VFB website (<ext-link xlink:href="https://virtualflybrain.org" ext-link-type="uri">https://virtualflybrain.org</ext-link>) and API (<ext-link xlink:href="https://pypi.org/project/vfb-connect/" ext-link-type="uri">https://pypi.org/project/vfb-connect/</ext-link>). The VFB site can be accessed through any computer + browswer with standard WebGL support, which can be tested at <ext-link xlink:href="https://get.webgl.org/" ext-link-type="uri">https://get.webgl.org/</ext-link>. The Drosophila Anatomy Ontology is available under a CC-BY-4.0 license from <ext-link xlink:href="http://purl.obolibrary.org/obo/fbbt.owl" ext-link-type="uri">http://purl.obolibrary.org/obo/fbbt.owl</ext-link>. All code is available under open licenses at <ext-link xlink:href="https://github.com/VirtualFlyBrain" ext-link-type="uri">https://github.com/VirtualFlyBrain</ext-link>. Jupyter notebooks showing anaylsing the success of NBLAST and CDMIP scoresqueries in finding known split combinationsare available at <ext-link xlink:href="https://github.com/VirtualFlyBrain/VFB_similarity_import/tree/vFrontiers/stats" ext-link-type="uri">https://github.com/VirtualFlyBrain/VFB_similarity_import/tree/vFrontiers/stats</ext-link>.</p>
  </sec>
  <sec id="s6">
    <title>Author contributions</title>
    <p>HP, CO, JA, NB, GJ, and DS provided supervision. GJ also provided extensive advice and help with data processing and collection. DS did most of the writing, with contributions from MC, CO, JA, and HP, RC, AM, and CP. Developers: RC (senior developer, pipelines, web development), DS (semantic schema and pipelines) NM (pipeline development), HK (pipeline development), AM (NBLAST), CP (data ingest). Ontology editors: CP, MC, and DS. Curation: AM, AH, GM, MC, CP, and AL.</p>
  </sec>
  <sec sec-type="COI-statement" id="s8">
    <title>Conflict of interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
  <sec sec-type="disclaimer" id="s9">
    <title>Publisher’s note</title>
    <p>All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.</p>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>A. S.</given-names></name><name><surname>Janssens</surname><given-names>J.</given-names></name><name><surname>Jefferis</surname><given-names>G. S.</given-names></name><name><surname>Aerts</surname><given-names>S.</given-names></name></person-group> (<year>2019</year>). <article-title>Neuronal cell types in the fly: Single-cell anatomy meets single-cell genomics</article-title>. <source>Curr. Opin. Neurobiol.</source>
<volume>56</volume>, <fpage>125</fpage>–<lpage>134</lpage>. <pub-id pub-id-type="doi">10.1016/j.conb.2018.12.012</pub-id>
<pub-id pub-id-type="pmid">30703584</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>A. S.</given-names></name><name><surname>Manton</surname><given-names>J. D.</given-names></name><name><surname>Jagannathan</surname><given-names>S. R.</given-names></name><name><surname>Costa</surname><given-names>M.</given-names></name><name><surname>Schlegel</surname><given-names>P.</given-names></name><name><surname>Rohlfing</surname><given-names>T.</given-names></name><etal/></person-group> (<year>2020b</year>). <article-title>The natverse, a versatile toolbox for combining and analysing neuroanatomical data</article-title>. <source>eLife</source>
<volume>9</volume>, <fpage>e53350</fpage>. <pub-id pub-id-type="doi">10.7554/eLife.53350</pub-id>
<pub-id pub-id-type="pmid">32286229</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>A. S.</given-names></name><name><surname>Schlegel</surname><given-names>P.</given-names></name><name><surname>Roberts</surname><given-names>R. J. V.</given-names></name><name><surname>Drummond</surname><given-names>N.</given-names></name><name><surname>Tamimi</surname><given-names>I. F. M.</given-names></name><name><surname>Turnbull</surname><given-names>R.</given-names></name><etal/></person-group> (<year>2020a</year>). <article-title>Complete connectomic reconstruction of olfactory projection neurons in the fly brain</article-title>. <source>Curr. Biol. CB</source>
<volume>30</volume> (<issue>16</issue>), <fpage>3183</fpage>–<lpage>3199</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2020.06.042</pub-id>
<pub-id pub-id-type="pmid">32619485</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogovic</surname><given-names>J. A.</given-names></name><name><surname>Otsuna</surname><given-names>H.</given-names></name><name><surname>Heinrich</surname><given-names>L.</given-names></name><name><surname>Ito</surname><given-names>M.</given-names></name><name><surname>Jeter</surname><given-names>J.</given-names></name><name><surname>Meissner</surname><given-names>G.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>An unbiased template of the Drosophila brain and ventral nerve cord</article-title>. <comment>bioRxiv</comment>. <pub-id pub-id-type="doi">10.1101/376384</pub-id>
</mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bunt</surname><given-names>S. M.</given-names></name><name><surname>Grumbling</surname><given-names>G. B.</given-names></name><name><surname>Field</surname><given-names>H. I.</given-names></name><name><surname>Marygold</surname><given-names>S. J.</given-names></name><name><surname>Brown</surname><given-names>N. H.</given-names></name><name><surname>Millburn</surname><given-names>G. H.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Directly e-mailing authors of newly published papers encourages community curation</article-title>. <source>Database J. Biol. databases curation</source>
<volume>2012</volume>, <fpage>bas024</fpage>. <pub-id pub-id-type="doi">10.1093/database/bas024</pub-id>
</mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cantarelli</surname><given-names>M.</given-names></name><name><surname>Marin</surname><given-names>B.</given-names></name><name><surname>Quintana</surname><given-names>A.</given-names></name><name><surname>Earnshaw</surname><given-names>M.</given-names></name><name><surname>Court</surname><given-names>R.</given-names></name><name><surname>Gleeson</surname><given-names>P.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>Geppetto: A reusable modular open platform for exploring neuroscience data and models</article-title>. <source>Philosophical Trans. R. Soc. B Biol. Sci.</source>
<volume>373</volume>, <fpage>20170380</fpage>. <pub-id pub-id-type="doi">10.1098/rstb.2017.0380</pub-id>
</mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chiang</surname><given-names>A. S.</given-names></name><name><surname>Lin</surname><given-names>C. Y.</given-names></name><name><surname>Chuang</surname><given-names>C. C.</given-names></name><name><surname>Chang</surname><given-names>H. M.</given-names></name><name><surname>Hsieh</surname><given-names>C. H.</given-names></name><name><surname>Yeh</surname><given-names>C. W.</given-names></name><etal/></person-group> (<year>2010</year>). <article-title>Three-dimensional reconstruction of brain-wide wiring networks in Drosophila at single-cell resolution</article-title>. <source>Curr. Biol. CB</source>
<volume>21</volume> (<issue>1</issue>), <fpage>1</fpage>–<lpage>11</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2010.11.056</pub-id>
<pub-id pub-id-type="pmid">21129968</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Clements</surname><given-names>J.</given-names></name><name><surname>Dolafi</surname><given-names>T.</given-names></name><name><surname>Umayam</surname><given-names>L.</given-names></name><name><surname>Neubarth</surname><given-names>N. L.</given-names></name><name><surname>Berg</surname><given-names>S.</given-names></name><name><surname>Scheffer</surname><given-names>L. K.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>neuprint: Analysis tools for em connectomics</article-title>. <comment>BioRxiv [Preprint]. Available at: <ext-link xlink:href="https://www.biorxiv.org/content/10.1101/2020.01.16.909465v1.abstract" ext-link-type="uri">https://www.biorxiv.org/content/10.1101/2020.01.16.909465v1.abstract</ext-link>
</comment>.</mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clements</surname><given-names>J.</given-names></name><name><surname>Goina</surname><given-names>C.</given-names></name><name><surname>Hubbard</surname><given-names>P. M.</given-names></name><name><surname>Kawase</surname><given-names>T.</given-names></name><name><surname>Olbris</surname><given-names>D. J.</given-names></name><name><surname>Otsuna</surname><given-names>H.</given-names></name><etal/></person-group> (<year>2022</year>). <article-title>NeuronBridge: An intuitive web application for neuronal morphology search across large data sets</article-title>. <comment>bioRxiv</comment>. <pub-id pub-id-type="doi">10.1101/2022.07.20.500311</pub-id>
</mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costa</surname><given-names>M.</given-names></name><name><surname>Manton</surname><given-names>J. D.</given-names></name><name><surname>Ostrovsky</surname><given-names>A. D.</given-names></name><name><surname>Prohaska</surname><given-names>S.</given-names></name><name><surname>Jefferis</surname><given-names>G. S. X. E.</given-names></name></person-group> (<year>2016</year>). <article-title>Nblast: Rapid, sensitive comparison of neuronal structure and construction of neuron family databases</article-title>. <source>Neuron</source>
<volume>91</volume> (<issue>2</issue>), <fpage>293</fpage>–<lpage>311</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2016.06.012</pub-id>
<pub-id pub-id-type="pmid">27373836</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Costa</surname><given-names>M.</given-names></name><name><surname>Reeve</surname><given-names>S.</given-names></name><name><surname>Grumbling</surname><given-names>G.</given-names></name><name><surname>Osumi-Sutherland</surname><given-names>D.</given-names></name></person-group> (<year>2013</year>). <article-title>The Drosophila anatomy ontology</article-title>. <source>J. Biomed. Semant.</source>
<volume>4</volume> (<issue>1</issue>), <fpage>32</fpage>. <pub-id pub-id-type="doi">10.1186/2041-1480-4-32</pub-id>
</mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Court</surname><given-names>R.</given-names></name><name><surname>Namiki</surname><given-names>S.</given-names></name><name><surname>Armstrong</surname><given-names>J. D.</given-names></name><name><surname>Borner</surname><given-names>J.</given-names></name><name><surname>Card</surname><given-names>G.</given-names></name><name><surname>Costa</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>A systematic nomenclature for the Drosophila ventral nerve cord</article-title>. <source>Neuron</source>
<volume>107</volume> (<issue>6</issue>), <fpage>1071</fpage>–<lpage>1079</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2020.08.005</pub-id>
<pub-id pub-id-type="pmid">32931755</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davie</surname><given-names>K.</given-names></name><name><surname>Janssens</surname><given-names>J.</given-names></name><name><surname>Koldere</surname><given-names>D.</given-names></name><name><surname>De Waegeneer</surname><given-names>M.</given-names></name><name><surname>Pech</surname><given-names>U.</given-names></name><name><surname>Kreft</surname><given-names>L.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>A single-cell transcriptome atlas of the aging Drosophila brain</article-title>. <source>Cell</source>
<volume>174</volume> (<issue>4</issue>), <fpage>982</fpage>–<lpage>998</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2018.05.057</pub-id>
<pub-id pub-id-type="pmid">29909982</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>F. P.</given-names></name><name><surname>Nern</surname><given-names>A.</given-names></name><name><surname>Picard</surname><given-names>S.</given-names></name><name><surname>Reiser</surname><given-names>M. B.</given-names></name><name><surname>Rubin</surname><given-names>G. M.</given-names></name><name><surname>Eddy</surname><given-names>S. R.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>A genetic, genomic, and computational resource for exploring neural circuit function</article-title>. <source>eLife</source>
<volume>9</volume>, <fpage>e50901</fpage>. <pub-id pub-id-type="doi">10.7554/eLife.50901</pub-id>
<pub-id pub-id-type="pmid">31939737</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dolan</surname><given-names>M.-J.</given-names></name><name><surname>Frechter</surname><given-names>S.</given-names></name><name><surname>Bates</surname><given-names>A. S.</given-names></name><name><surname>Dan</surname><given-names>C.</given-names></name><name><surname>Huoviala</surname><given-names>P.</given-names></name><name><surname>Roberts</surname><given-names>R. J.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Neurogenetic dissection of the Drosophila lateral horn reveals major outputs, diverse behavioural functions, and interactions with the mushroom body</article-title>. <source>eLife</source>
<volume>8</volume>, <fpage>e43079</fpage>. <pub-id pub-id-type="doi">10.7554/eLife.43079</pub-id>
<pub-id pub-id-type="pmid">31112130</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dorkenwald</surname><given-names>S.</given-names></name><name><surname>McKellar</surname><given-names>C.</given-names></name><name><surname>Macrina</surname><given-names>T.</given-names></name><name><surname>Kemnitz</surname><given-names>N.</given-names></name><name><surname>Lee</surname><given-names>K.</given-names></name><name><surname>Lu</surname><given-names>R.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>FlyWire: Online community for whole-brain connectomics</article-title>. <comment>bioRxiv</comment>. <pub-id pub-id-type="doi">10.1101/2020.08.30.274225</pub-id>
</mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eckstein</surname><given-names>N.</given-names></name><name><surname>Bates</surname><given-names>A. S.</given-names></name><name><surname>Du</surname><given-names>M.</given-names></name><name><surname>Hartenstein</surname><given-names>V.</given-names></name><name><surname>Jefferis</surname><given-names>G. S.</given-names></name><name><surname>Funke</surname><given-names>J.</given-names></name></person-group> (<year>2020</year>). <article-title>Neurotransmitter classification from electron microscopy images at synaptic sites in Drosophila</article-title>. <comment>bioRxiv</comment>. <pub-id pub-id-type="doi">10.1101/2020.06.12.148775</pub-id>
</mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramates</surname><given-names>L. S.</given-names></name><name><surname>Agapite</surname><given-names>J.</given-names></name><name><surname>Attrill</surname><given-names>H.</given-names></name><name><surname>Calvi</surname><given-names>B. R.</given-names></name><name><surname>Crosby</surname><given-names>M. A.</given-names></name><name><surname>Dos Santos</surname><given-names>G.</given-names></name><etal/></person-group> (<year>2022</year>). <article-title>FlyBase: A guided tour of highlighted features</article-title>. <source>Genetics</source>
<volume>220</volume> (<issue>4</issue>), <fpage>iyac035</fpage>. <pub-id pub-id-type="doi">10.1093/genetics/iyac035</pub-id>
<pub-id pub-id-type="pmid">35266522</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halperin</surname><given-names>R. F.</given-names></name><name><surname>Stafford</surname><given-names>P.</given-names></name><name><surname>Emery</surname><given-names>J. S.</given-names></name><name><surname>Navalkar</surname><given-names>K. A.</given-names></name><name><surname>Johnston</surname><given-names>S. A.</given-names></name></person-group> (<year>2012</year>). <article-title>GuiTope: An application for mapping random-sequence peptides to protein sequences</article-title>. <source>BMC Bioinforma.</source>
<volume>13</volume>, <fpage>1</fpage>–<lpage>24</lpage>. <pub-id pub-id-type="doi">10.1186/1471-2105-13-s12-a1</pub-id>
</mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heinze</surname><given-names>S.</given-names></name></person-group> (<year>2021</year>). <article-title>Mapping the fly's 'brain in the brain'</article-title>. <source>eLife</source>
<volume>10</volume>, <fpage>e73963</fpage>. <pub-id pub-id-type="doi">10.7554/eLife.73963</pub-id>
<pub-id pub-id-type="pmid">34696825</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname><given-names>K.</given-names></name><name><surname>Shinomiya</surname><given-names>K.</given-names></name><name><surname>Ito</surname><given-names>M.</given-names></name><name><surname>Armstrong</surname><given-names>J. D.</given-names></name><name><surname>Boyan</surname><given-names>G.</given-names></name><name><surname>Hartenstein</surname><given-names>V.</given-names></name><etal/></person-group> (<year>2014</year>). <article-title>A systematic nomenclature for the insect brain</article-title>. <source>Neuron</source>
<volume>81</volume> (<issue>4</issue>), <fpage>755</fpage>–<lpage>765</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2013.12.017</pub-id>
<pub-id pub-id-type="pmid">24559671</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname><given-names>M.</given-names></name><name><surname>Masuda</surname><given-names>N.</given-names></name><name><surname>Shinomiya</surname><given-names>K.</given-names></name><name><surname>Endo</surname><given-names>K.</given-names></name><name><surname>Ito</surname><given-names>K.</given-names></name></person-group> (<year>2013</year>). <article-title>Systematic analysis of neural projections reveals clonal composition of the Drosophila brain</article-title>. <source>Curr. Biol. CB</source>
<volume>23</volume> (<issue>8</issue>), <fpage>644</fpage>–<lpage>655</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2013.03.015</pub-id>
<pub-id pub-id-type="pmid">23541729</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jackson</surname><given-names>R. C.</given-names></name><name><surname>Balhoff</surname><given-names>J. P.</given-names></name><name><surname>Douglass</surname><given-names>E.</given-names></name><name><surname>Harris</surname><given-names>N. L.</given-names></name><name><surname>Mungall</surname><given-names>C. J.</given-names></name><name><surname>Overton</surname><given-names>J. A.</given-names></name></person-group> (<year>2019</year>). <article-title>Robot: A tool for automating ontology workflows</article-title>. <source>BMC Bioinforma.</source>
<volume>20</volume> (<issue>1</issue>), <fpage>407</fpage>. <pub-id pub-id-type="doi">10.1186/s12859-019-3002-3</pub-id>
</mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jackson</surname><given-names>R.</given-names></name><name><surname>Matentzoglu</surname><given-names>N.</given-names></name><name><surname>Overton</surname><given-names>J. A.</given-names></name><name><surname>Vita</surname><given-names>R.</given-names></name><name><surname>Balhoff</surname><given-names>J. P.</given-names></name><name><surname>Buttigieg</surname><given-names>P. L.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>OBO foundry in 2021: Operationalizing open data principles to evaluate ontologies</article-title>. <source>Database J. Biol. databases curation</source>
<volume>2021</volume>, <fpage>baab069</fpage>. <pub-id pub-id-type="doi">10.1093/database/baab069</pub-id>
</mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jefferis</surname><given-names>G. S. X. E.</given-names></name><name><surname>Potter</surname><given-names>C. J.</given-names></name><name><surname>Chan</surname><given-names>A. M.</given-names></name><name><surname>Marin</surname><given-names>E. C.</given-names></name><name><surname>Rohlfing</surname><given-names>T.</given-names></name><name><surname>Maurer</surname><given-names>C. R.</given-names></name><etal/></person-group> (<year>2007</year>). <article-title>Comprehensive maps of Drosophila higher olfactory centers: Spatially segregated fruit and pheromone representation</article-title>. <source>Cell</source>
<volume>128</volume> (<issue>6</issue>), <fpage>1187</fpage>–<lpage>1203</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2007.01.040</pub-id>
<pub-id pub-id-type="pmid">17382886</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenett</surname><given-names>A.</given-names></name><name><surname>Rubin</surname><given-names>G. M.</given-names></name><name><surname>Ngo</surname><given-names>T. T. B.</given-names></name><name><surname>Shepherd</surname><given-names>D.</given-names></name><name><surname>Murphy</surname><given-names>C.</given-names></name><name><surname>Dionne</surname><given-names>H.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>A GAL4-driver line resource for Drosophila neurobiology</article-title>. <source>Cell Rep.</source>
<volume>2</volume> (<issue>4</issue>), <fpage>991</fpage>–<lpage>1001</lpage>. <pub-id pub-id-type="doi">10.1016/j.celrep.2012.09.011</pub-id>
<pub-id pub-id-type="pmid">23063364</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaiser</surname><given-names>J.</given-names></name></person-group> (<year>2022</year>). <article-title>NIH's BRAIN Initiative puts $500 million into creating most detailed ever human brain atlas</article-title>. <source>Science</source>
<volume>377</volume> (<issue>6613</issue>). <pub-id pub-id-type="doi">10.1126/science.ade9983</pub-id>
</mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Koonin</surname><given-names>E. V.</given-names></name><name><surname>Galperin</surname><given-names>M. Y.</given-names></name></person-group> (<year>2003</year>). <source>Genome annotation and analysis</source>. <publisher-name>Boston: Kluwer Academic</publisher-name>. <comment>Available at: <ext-link xlink:href="https://www.ncbi.nlm.nih.gov/books/NBK20253/" ext-link-type="uri">https://www.ncbi.nlm.nih.gov/books/NBK20253/</ext-link>
</comment> (<comment>Accessed September 29, 2022)</comment>.</mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuan</surname><given-names>A. T.</given-names></name><name><surname>Phelps</surname><given-names>J. S.</given-names></name><name><surname>Thomas</surname><given-names>L. A.</given-names></name><name><surname>Nguyen</surname><given-names>T. M.</given-names></name><name><surname>Han</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>C. L.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>Dense neuronal reconstruction through X-ray holographic nano-tomography</article-title>. <source>Nat. Neurosci.</source>
<volume>23</volume> (<issue>12</issue>), <fpage>1637</fpage>–<lpage>1643</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-020-0704-9</pub-id>
<pub-id pub-id-type="pmid">32929244</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurmangaliyev</surname><given-names>Y. Z.</given-names></name><name><surname>Yoo</surname><given-names>J.</given-names></name><name><surname>Valdes-Aleman</surname><given-names>J.</given-names></name><name><surname>Sanfilippo</surname><given-names>P.</given-names></name><name><surname>Zipursky</surname><given-names>S. L.</given-names></name></person-group> (<year>2020</year>). <article-title>Transcriptional programs of circuit assembly in the Drosophila visual system</article-title>. <source>Neuron</source>
<volume>108</volume> (<issue>6</issue>), <fpage>1045</fpage>–<lpage>1057.e6</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2020.10.006</pub-id>
<pub-id pub-id-type="pmid">33125872</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larkin</surname><given-names>A.</given-names></name><name><surname>Marygold</surname><given-names>S. J.</given-names></name><name><surname>Antonazzo</surname><given-names>G.</given-names></name><name><surname>Attrill</surname><given-names>H.</given-names></name><name><surname>Dos Santos</surname><given-names>G.</given-names></name><name><surname>Garapati</surname><given-names>P. V.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>FlyBase: Updates to the <italic>Drosophila melanogaster</italic> knowledge base</article-title>. <source>Nucleic acids Res.</source>
<volume>49</volume> (<issue>D1</issue>), <fpage>D899</fpage>–<lpage>D907</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkaa1026</pub-id>
<pub-id pub-id-type="pmid">33219682</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lazar</surname><given-names>A. A.</given-names></name><name><surname>Liu</surname><given-names>T.</given-names></name><name><surname>Turkcan</surname><given-names>M. K.</given-names></name><name><surname>Zhou</surname><given-names>Y.</given-names></name></person-group> (<year>2021</year>). <article-title>Accelerating with FlyBrainLab the discovery of the functional logic of the Drosophila brain in the connectomic and synaptomic era</article-title>. <source>eLife</source>
<volume>10</volume>, <fpage>e62362</fpage>. <pub-id pub-id-type="doi">10.7554/eLife.62362</pub-id>
<pub-id pub-id-type="pmid">33616035</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H.</given-names></name><name><surname>Janssens</surname><given-names>J.</given-names></name><name><surname>De Waegeneer</surname><given-names>M.</given-names></name><name><surname>Kolluru</surname><given-names>S. S.</given-names></name><name><surname>Davie</surname><given-names>K.</given-names></name><name><surname>Gardeux</surname><given-names>V.</given-names></name><etal/></person-group> (<year>2022</year>). <article-title>Fly cell atlas: A single-nucleus transcriptomic atlas of the adult fruit fly</article-title>. <source>Science</source>
<volume>375</volume> (<issue>6584</issue>), <fpage>eabk2432</fpage>. <pub-id pub-id-type="doi">10.1126/science.abk2432</pub-id>
<pub-id pub-id-type="pmid">35239393</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luan</surname><given-names>H.</given-names></name><name><surname>Peabody</surname><given-names>N. C.</given-names></name><name><surname>Vinson</surname><given-names>C. R.</given-names></name><name><surname>White</surname><given-names>B. H.</given-names></name></person-group> (<year>2006</year>). <article-title>Refined spatial manipulation of neuronal function by combinatorial restriction of transgene expression</article-title>. <source>Neuron</source>
<volume>52</volume> (<issue>3</issue>), <fpage>425</fpage>–<lpage>436</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2006.08.028</pub-id>
<pub-id pub-id-type="pmid">17088209</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Matentzoglu</surname><given-names>N.</given-names></name><name><surname>Goutte-Gattat</surname><given-names>D.</given-names></name><name><surname>Tan</surname><given-names>S. Z. K.</given-names></name><name><surname>Balhoff</surname><given-names>J. P.</given-names></name><name><surname>Carbon</surname><given-names>S.</given-names></name><name><surname>Caron</surname><given-names>A. R.</given-names></name><etal/></person-group> (<year>2022</year>). <article-title>Ontology development kit: A toolkit for building, maintaining, and standardising biomedical ontologies</article-title>. <source>Database (Oxford)</source>
<volume>2022</volume>. <pub-id pub-id-type="doi">10.1093/database/baac087</pub-id>
</mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCarthy</surname><given-names>L.</given-names></name><name><surname>Vandervalk</surname><given-names>B.</given-names></name><name><surname>Wilkinson</surname><given-names>M.</given-names></name></person-group> (<year>2012</year>). <article-title>SPARQL assist language-neutral query composer</article-title>. <source>BMC Bioinforma.</source>
<volume>13</volume> (<issue>1</issue>), <fpage>S2</fpage>. <pub-id pub-id-type="doi">10.1186/1471-2105-13-S1-S2</pub-id>
</mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McKellar</surname><given-names>C. E.</given-names></name><name><surname>Siwanowicz</surname><given-names>I.</given-names></name><name><surname>Dickson</surname><given-names>B. J.</given-names></name><name><surname>Simpson</surname><given-names>J. H.</given-names></name></person-group> (<year>2020</year>). <article-title>Controlling motor neurons of every muscle for fly proboscis reaching</article-title>. <source>eLife</source>
<volume>9</volume>, <fpage>e54978</fpage>. <pub-id pub-id-type="doi">10.7554/eLife.54978</pub-id>
<pub-id pub-id-type="pmid">32584254</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Meissner</surname><given-names>G. W.</given-names></name><name><surname>Nern</surname><given-names>A.</given-names></name><name><surname>Dorman</surname><given-names>Z.</given-names></name><name><surname>DePasquale</surname><given-names>G. M.</given-names></name><name><surname>Forster</surname><given-names>K.</given-names></name><name><surname>Gibney</surname><given-names>T.</given-names></name><etal/></person-group> (<year>2022</year>). <article-title>A searchable image resource of <italic>Drosophila</italic> GAL4-driver expression patterns with single neuron resolution</article-title>. <source>biorXiv</source>. <pub-id pub-id-type="doi">10.1101/2020.05.29.080473</pub-id>
</mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milyaev</surname><given-names>N.</given-names></name><name><surname>Osumi-Sutherland</surname><given-names>D.</given-names></name><name><surname>Reeve</surname><given-names>S.</given-names></name><name><surname>Burton</surname><given-names>N.</given-names></name><name><surname>Baldock</surname><given-names>R. A.</given-names></name><name><surname>Armstrong</surname><given-names>J. D.</given-names></name></person-group> (<year>2012</year>). <article-title>The Virtual Fly Brain browser and query interface</article-title>. <source>Bioinformatics</source>
<volume>28</volume> (<issue>3</issue>), <fpage>411</fpage>–<lpage>415</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btr677</pub-id>
<pub-id pub-id-type="pmid">22180411</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="webpage"><collab>Neo4j Graph Data Platform</collab> (<year>2020</year>). <article-title>Neo4j graph data platform</article-title>. <comment>Neo4j. Available at: <ext-link xlink:href="https://neo4j.com/" ext-link-type="uri">https://neo4j.com/</ext-link>
</comment> (<comment>Accessed: December 5, 2022)</comment>.</mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nern</surname><given-names>A.</given-names></name><name><surname>Pfeiffer</surname><given-names>B. D.</given-names></name><name><surname>Rubin</surname><given-names>G. M.</given-names></name></person-group> (<year>2015</year>). <article-title>Optimized tools for multicolor stochastic labeling reveal diverse stereotyped cell arrangements in the fly visual system</article-title>. <source>Proc. Natl. Acad. Sci. U. S. A.</source>
<volume>112</volume> (<issue>22</issue>), <fpage>E2967</fpage>–<lpage>E2976</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1506763112</pub-id>
<pub-id pub-id-type="pmid">25964354</pub-id></mixed-citation>
    </ref>
    <ref id="B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohyama</surname><given-names>T.</given-names></name><name><surname>Schneider-Mizell</surname><given-names>C. M.</given-names></name><name><surname>Fetter</surname><given-names>R. D.</given-names></name><name><surname>Aleman</surname><given-names>J. V.</given-names></name><name><surname>Franconville</surname><given-names>R.</given-names></name><name><surname>Rivera-Alba</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>A multilevel multimodal circuit enhances action selection in Drosophila</article-title>. <source>Nature</source>
<volume>520</volume> (<issue>7549</issue>), <fpage>633</fpage>–<lpage>639</lpage>. <pub-id pub-id-type="doi">10.1038/nature14297</pub-id>
<pub-id pub-id-type="pmid">25896325</pub-id></mixed-citation>
    </ref>
    <ref id="B44">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Osumi-Sutherland</surname><given-names>D.</given-names></name><name><surname>Costa</surname><given-names>M.</given-names></name><name><surname>Court</surname><given-names>R.</given-names></name><name><surname>O'Kane</surname><given-names>C. J.</given-names></name></person-group> (<year>2014</year>). “<article-title>Virtual Fly Brain-Using OWL to support the mapping and genetic dissection of the Drosophila brain</article-title>,” in <source>Proceedings of OWLED 2014</source>. <comment>OWLED 2014 (CEUR workshop proceedings)</comment> Editor <person-group person-group-type="editor"><name><surname>Maria Keet</surname><given-names>C.</given-names></name></person-group>, <fpage>85</fpage>–<lpage>96</lpage>. <comment>Available at: <ext-link xlink:href="http://ceur-ws.org/Vol-1265/owled2014_submission_12.pdf" ext-link-type="uri">http://ceur-ws.org/Vol-1265/owled2014_submission_12.pdf</ext-link>
</comment>.</mixed-citation>
    </ref>
    <ref id="B45">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Osumi-Sutherland</surname><given-names>D.</given-names></name><name><surname>Reeve</surname><given-names>S.</given-names></name><name><surname>Mungall</surname><given-names>C. J.</given-names></name><name><surname>Neuhaus</surname><given-names>F.</given-names></name><name><surname>Ruttenberg</surname><given-names>A.</given-names></name><name><surname>Jefferis</surname><given-names>G. S. X. E.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>A strategy for building neuroanatomy ontologies</article-title>. <source>Bioinformatics</source>
<volume>28</volume> (<issue>9</issue>), <fpage>1262</fpage>–<lpage>1269</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bts113</pub-id>
<pub-id pub-id-type="pmid">22402613</pub-id></mixed-citation>
    </ref>
    <ref id="B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otsuna</surname><given-names>H.</given-names></name><name><surname>Ito</surname><given-names>M.</given-names></name><name><surname>Kawase</surname><given-names>T.</given-names></name></person-group> (<year>2018</year>). <article-title>Color depth MIP mask search: A new tool to expedite split-GAL4 creation</article-title>. <comment>bioRxiv</comment>. <pub-id pub-id-type="doi">10.1101/318006</pub-id>
</mixed-citation>
    </ref>
    <ref id="B47">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Özel</surname><given-names>M. N.</given-names></name><name><surname>Simon</surname><given-names>F.</given-names></name><name><surname>Jafari</surname><given-names>S.</given-names></name><name><surname>Holguera</surname><given-names>I.</given-names></name><name><surname>Chen</surname><given-names>Y. C.</given-names></name><name><surname>Benhra</surname><given-names>N.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Neuronal diversity and convergence in a visual system developmental atlas</article-title>. <source>Nature</source>
<volume>589</volume> (<issue>7840</issue>), <fpage>88</fpage>–<lpage>95</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-020-2879-3</pub-id>
<pub-id pub-id-type="pmid">33149298</pub-id></mixed-citation>
    </ref>
    <ref id="B48">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeiffer</surname><given-names>B. D.</given-names></name><name><surname>Ngo</surname><given-names>T. T. B.</given-names></name><name><surname>Hibbard</surname><given-names>K. L.</given-names></name><name><surname>Murphy</surname><given-names>C.</given-names></name><name><surname>Jenett</surname><given-names>A.</given-names></name><name><surname>Truman</surname><given-names>J. W.</given-names></name><etal/></person-group> (<year>2010</year>). <article-title>Refinement of tools for targeted gene expression in Drosophila</article-title>. <source>Genetics</source>
<volume>186</volume> (<issue>2</issue>), <fpage>735</fpage>–<lpage>755</lpage>. <pub-id pub-id-type="doi">10.1534/genetics.110.119917</pub-id>
<pub-id pub-id-type="pmid">20697123</pub-id></mixed-citation>
    </ref>
    <ref id="B49">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phelps</surname><given-names>J. S.</given-names></name><name><surname>Hildebrand</surname><given-names>D. G. C.</given-names></name><name><surname>Graham</surname><given-names>B. J.</given-names></name><name><surname>Kuan</surname><given-names>A. T.</given-names></name><name><surname>Thomas</surname><given-names>L. A.</given-names></name><name><surname>Nguyen</surname><given-names>T. M.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Reconstruction of motor control circuits in adult Drosophila using automated transmission electron microscopy</article-title>. <source>Cell</source>
<volume>184</volume> (<issue>3</issue>), <fpage>759</fpage>–<lpage>774.e18</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2020.12.013</pub-id>
<pub-id pub-id-type="pmid">33400916</pub-id></mixed-citation>
    </ref>
    <ref id="B50">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Portin</surname><given-names>P.</given-names></name><name><surname>Wilkins</surname><given-names>A.</given-names></name></person-group> (<year>2017</year>). <article-title>The evolving definition of the term “gene”</article-title>. <source>Genetics</source>
<volume>205</volume> (<issue>4</issue>), <fpage>1353</fpage>–<lpage>1364</lpage>. <pub-id pub-id-type="doi">10.1534/genetics.116.196956</pub-id>
<pub-id pub-id-type="pmid">28360126</pub-id></mixed-citation>
    </ref>
    <ref id="B51">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rohlfing</surname><given-names>T.</given-names></name><name><surname>Maurer</surname><given-names>C. R.</given-names><suffix>Jr</suffix></name></person-group> (<year>2003</year>). <article-title>Nonrigid image registration in shared-memory multiprocessor environments with application to brains, breasts, and bees</article-title>. <source>IEEE Trans. Inf. Technol. Biomed. a Publ. IEEE Eng. Med. Biol. Soc.</source>
<volume>7</volume> (<issue>1</issue>), <fpage>16</fpage>–<lpage>25</lpage>. <pub-id pub-id-type="doi">10.1109/titb.2003.808506</pub-id>
</mixed-citation>
    </ref>
    <ref id="B52">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saalfeld</surname><given-names>S.</given-names></name><name><surname>Cardona</surname><given-names>A.</given-names></name><name><surname>Hartenstein</surname><given-names>V.</given-names></name><name><surname>Tomancak</surname><given-names>P.</given-names></name></person-group> (<year>2009</year>). <article-title>Catmaid: Collaborative annotation toolkit for massive amounts of image data</article-title>. <source>Bioinformatics</source>
<volume>25</volume> (<issue>15</issue>), <fpage>1984</fpage>–<lpage>1986</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btp266</pub-id>
<pub-id pub-id-type="pmid">19376822</pub-id></mixed-citation>
    </ref>
    <ref id="B53">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scheffer</surname><given-names>L. K.</given-names></name><name><surname>Xu</surname><given-names>C. S.</given-names></name><name><surname>Januszewski</surname><given-names>M.</given-names></name><name><surname>Lu</surname><given-names>Z.</given-names></name><name><surname>Takemura</surname><given-names>S. Y.</given-names></name><name><surname>Hayworth</surname><given-names>K. J.</given-names></name><etal/></person-group> (<year>2020</year>). <article-title>A connectome and analysis of the adult Drosophila central brain</article-title>. <source>eLife</source>
<volume>9</volume>. <pub-id pub-id-type="doi">10.7554/eLife.57443</pub-id>
</mixed-citation>
    </ref>
    <ref id="B54">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schubert</surname><given-names>P. J.</given-names></name><name><surname>Dorkenwald</surname><given-names>S.</given-names></name><name><surname>Januszewski</surname><given-names>M.</given-names></name><name><surname>Jain</surname><given-names>V.</given-names></name><name><surname>Kornfeld</surname><given-names>J.</given-names></name></person-group> (<year>2019</year>). <article-title>Learning cellular morphology with neural networks</article-title>. <source>Nat. Commun.</source>
<volume>10</volume> (<issue>1</issue>), <fpage>2736</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-019-10836-3</pub-id>
<pub-id pub-id-type="pmid">31227718</pub-id></mixed-citation>
    </ref>
    <ref id="B55">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shih</surname><given-names>C.-T.</given-names></name><name><surname>Sporns</surname><given-names>O.</given-names></name><name><surname>Yuan</surname><given-names>S. L.</given-names></name><name><surname>Su</surname><given-names>T. S.</given-names></name><name><surname>Lin</surname><given-names>Y. J.</given-names></name><name><surname>Chuang</surname><given-names>C. C.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>Connectomics-based analysis of information flow in the Drosophila brain</article-title>. <source>Curr. Biol. CB</source>
<volume>25</volume> (<issue>10</issue>), <fpage>1249</fpage>–<lpage>1258</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2015.03.021</pub-id>
<pub-id pub-id-type="pmid">25866397</pub-id></mixed-citation>
    </ref>
    <ref id="B56">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stocker</surname><given-names>R. F.</given-names></name><name><surname>Lienhard</surname><given-names>M. C.</given-names></name><name><surname>Borst</surname><given-names>A.</given-names></name><name><surname>Fischbach</surname><given-names>K. F.</given-names></name></person-group> (<year>1990</year>). <article-title>Neuronal architecture of the antennal lobe in <italic>Drosophila melanogaster</italic>
</article-title>. <source>Cell tissue Res.</source>
<volume>262</volume> (<issue>1</issue>), <fpage>9</fpage>–<lpage>34</lpage>. <pub-id pub-id-type="doi">10.1007/BF00327741</pub-id>
<pub-id pub-id-type="pmid">2124174</pub-id></mixed-citation>
    </ref>
    <ref id="B57">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>S.</given-names></name><name><surname>Kir</surname><given-names>H.</given-names></name><name><surname>Aevermann</surname><given-names>B.</given-names></name><name><surname>Gillespie</surname><given-names>T.</given-names></name><name><surname>Hawrylycz</surname><given-names>M.</given-names></name><name><surname>Lein</surname><given-names>E.</given-names></name><etal/></person-group> (<year>2021</year>). <article-title>Brain data standards ontology: A data-driven ontology of transcriptomically defined cell types in the primary motor cortex</article-title>. <comment>bioRxiv</comment>. <pub-id pub-id-type="doi">10.1101/2021.10.10.463703</pub-id>
</mixed-citation>
    </ref>
    <ref id="B58">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tirian</surname><given-names>L.</given-names></name><name><surname>Dickson</surname><given-names>B. J.</given-names></name></person-group> (<year>2017</year>). <article-title>The VT GAL4, LexA, and split-GAL4 driver line collections for targeted expression in the <italic>Drosophila</italic> nervous system</article-title>. <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/198648</pub-id>
</mixed-citation>
    </ref>
    <ref id="B59">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilkinson</surname><given-names>M. D.</given-names></name><name><surname>Dumontier</surname><given-names>M.</given-names></name><name><surname>Aalbersberg</surname><given-names>I. J. J.</given-names></name><name><surname>Appleton</surname><given-names>G.</given-names></name><name><surname>Axton</surname><given-names>M.</given-names></name><name><surname>Baak</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>The FAIR Guiding Principles for scientific data management and stewardship</article-title>. <source>Sci. data</source>
<volume>3</volume>, <fpage>160018</fpage>. <pub-id pub-id-type="doi">10.1038/sdata.2016.18</pub-id>
<pub-id pub-id-type="pmid">26978244</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="webpage"><collab>World Wide Web Consortium</collab> (<year>2012</year>). <article-title>OWL 2 web ontology language—recommendation, w3c.org</article-title>. <comment>Available at: <ext-link xlink:href="https://www.w3.org/TR/2012/REC-owl2-primer-20121211/" ext-link-type="uri">https://www.w3.org/TR/2012/REC-owl2-primer-20121211/</ext-link> (Accessed 16/01/2023)</comment>.</mixed-citation>
    </ref>
    <ref id="B60">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>H.-H.</given-names></name><name><surname>Awasaki</surname><given-names>T.</given-names></name><name><surname>Schroeder</surname><given-names>M. D.</given-names></name><name><surname>Long</surname><given-names>F.</given-names></name><name><surname>Yang</surname><given-names>J. S.</given-names></name><name><surname>He</surname><given-names>Y.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Clonal development and organization of the adult Drosophila central brain</article-title>. <source>Curr. Biol. CB</source>
<volume>23</volume> (<issue>8</issue>), <fpage>633</fpage>–<lpage>643</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2013.02.057</pub-id>
<pub-id pub-id-type="pmid">23541733</pub-id></mixed-citation>
    </ref>
    <ref id="B61">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeng</surname><given-names>H.</given-names></name></person-group> (<year>2022</year>). <article-title>What is a cell type and how to define it?</article-title>
<source>Cell</source>
<volume>185</volume> (<issue>15</issue>), <fpage>2739</fpage>–<lpage>2755</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2022.06.031</pub-id>
<pub-id pub-id-type="pmid">35868277</pub-id></mixed-citation>
    </ref>
    <ref id="B62">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>Z.</given-names></name><name><surname>Lauritzen</surname><given-names>J. S.</given-names></name><name><surname>Perlman</surname><given-names>E.</given-names></name><name><surname>Robinson</surname><given-names>C. G.</given-names></name><name><surname>Nichols</surname><given-names>M.</given-names></name><name><surname>Milkie</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>A complete electron microscopy volume of the brain of adult <italic>Drosophila melanogaster</italic>
</article-title>. <source>Cell</source>
<volume>174</volume> (<issue>3</issue>), <fpage>730</fpage>–<lpage>743</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2018.06.019</pub-id>
<pub-id pub-id-type="pmid">30033368</pub-id></mixed-citation>
    </ref>
    <ref id="B63">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zinchenko</surname><given-names>V.</given-names></name><name><surname>Hugger</surname><given-names>J.</given-names></name><name><surname>Uhlmann</surname><given-names>V.</given-names></name><name><surname>Arendt</surname><given-names>D.</given-names></name><name><surname>Kreshuk</surname><given-names>A.</given-names></name></person-group> (<year>2022</year>). <article-title>MorphoFeatures: Unsupervised exploration of cell types, tissues and organs in volume electron microscopy</article-title>. <comment>bioRxiv</comment>. <pub-id pub-id-type="doi">10.1101/2022.05.07.490949</pub-id>
</mixed-citation>
    </ref>
  </ref-list>
</back>
