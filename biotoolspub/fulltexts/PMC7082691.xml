<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_PACS100168 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEgr5 jpg ?>
<?FILEgr6 jpg ?>
<?FILEgr7 jpg ?>
<?FILEgr8 jpg ?>
<?FILEgr9 jpg ?>
<?FILEgr10 jpg ?>
<?FILEgr11 jpg ?>
<?FILEgr12 jpg ?>
<?FILEgr13 jpg ?>
<?FILEgr14 jpg ?>
<?FILEgr15 jpg ?>
<?FILEgr16 jpg ?>
<?FILEfx1 jpg ?>
<?FILEfx2 jpg ?>
<?FILEfx3 jpg ?>
<?FILEfx4 jpg ?>
<?FILEmmc1 flv ?>
<?FILEmmc1 mp4 ?>
<?FILEmmc2 flv ?>
<?FILEmmc2 mp4 ?>
<?FILEmmc3 flv ?>
<?FILEmmc3 mp4 ?>
<?FILEmmc4 flv ?>
<?FILEmmc4 mp4 ?>
<?FILEmmc5 flv ?>
<?FILEmmc5 mp4 ?>
<?FILEmmc6 flv ?>
<?FILEmmc6 mp4 ?>
<?FILEmmc7 flv ?>
<?FILEmmc7 mp4 ?>
<?FILEmmc8 flv ?>
<?FILEmmc8 mp4 ?>
<?FILEsi1 svg ?>
<?FILEsi2 svg ?>
<?FILEsi3 svg ?>
<?FILEsi4 svg ?>
<?FILEsi5 svg ?>
<?FILEsi6 svg ?>
<?FILEsi7 svg ?>
<?FILEsi8 svg ?>
<?FILEsi9 svg ?>
<?FILEsi10 svg ?>
<?FILEsi11 svg ?>
<?FILEsi12 svg ?>
<?properties open_access?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Photoacoustics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Photoacoustics</journal-id>
    <journal-title-group>
      <journal-title>Photoacoustics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">2213-5979</issn>
    <issn pub-type="epub">2213-5979</issn>
    <publisher>
      <publisher-name>Elsevier</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7082691</article-id>
    <article-id pub-id-type="publisher-id">S2213-5979(20)30008-2</article-id>
    <article-id pub-id-type="doi">10.1016/j.pacs.2020.100168</article-id>
    <article-id pub-id-type="publisher-id">100168</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>3D PHOVIS: 3D photoacoustic visualization studio</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="aut0005">
        <name>
          <surname>Cho</surname>
          <given-names>Seonghee</given-names>
        </name>
        <email>shcho89@postech.ac.kr</email>
        <xref rid="aff0005" ref-type="aff">a</xref>
      </contrib>
      <contrib contrib-type="author" id="aut0010">
        <name>
          <surname>Baik</surname>
          <given-names>Jinwoo</given-names>
        </name>
        <email>bjwpp@postech.ac.kr</email>
        <xref rid="aff0010" ref-type="aff">b</xref>
      </contrib>
      <contrib contrib-type="author" id="aut0015">
        <name>
          <surname>Managuli</surname>
          <given-names>Ravi</given-names>
        </name>
        <email>ravim@uw.edu</email>
        <email>ravim@u.washington.edu</email>
        <xref rid="aff0015" ref-type="aff">c</xref>
        <xref rid="aff0020" ref-type="aff">d</xref>
      </contrib>
      <contrib contrib-type="author" id="aut0020">
        <name>
          <surname>Kim</surname>
          <given-names>Chulhong</given-names>
        </name>
        <email>chulhong@postech.edu</email>
        <xref rid="aff0025" ref-type="aff">e</xref>
        <xref rid="cor0005" ref-type="corresp">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff0005"><label>a</label>School of Interdisciplinary Bioscience and Bioengineering, Pohang University of Science and Technology (POSTECH), Pohang, 37673, Republic of Korea</aff>
    <aff id="aff0010"><label>b</label>Department of Creative IT Engineering, Pohang University of Science and Technology (POSTECH), Pohang, 37673, Republic of Korea</aff>
    <aff id="aff0015"><label>c</label>Department of Bioengineering, University of Washington, Seattle, WA, 98195, USA</aff>
    <aff id="aff0020"><label>d</label>Hitachi Healthcare America, Twinsburg, OH, 44087, USA</aff>
    <aff id="aff0025"><label>e</label>Departments of Creative IT Engineering, Mechanical Engineering, Electrical Engineering, and School of Interdisciplinary Bioscience and Bioengineering, Pohang University of Science and Technology (POSTECH), Pohang, 37673, Republic of Korea</aff>
    <author-notes>
      <corresp id="cor0005"><label>⁎</label>Corresponding author. <email>chulhong@postech.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>10</day>
      <month>3</month>
      <year>2020</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <month>6</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>10</day>
      <month>3</month>
      <year>2020</year>
    </pub-date>
    <volume>18</volume>
    <elocation-id>100168</elocation-id>
    <history>
      <date date-type="received">
        <day>4</day>
        <month>12</month>
        <year>2019</year>
      </date>
      <date date-type="rev-recd">
        <day>30</day>
        <month>1</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>11</day>
        <month>2</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2020 The Author(s)</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license license-type="CC BY" xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="abs0005">
      <p>Photoacoustic (PA) imaging (or optoacoustic imaging) is a novel biomedical imaging method in biological and medical research. This modality performs morphological, functional, and molecular imaging with and without labels in both microscopic and deep tissue imaging domains. A variety of innovations have enhanced 3D PA imaging performance and thus has opened new opportunities in preclinical and clinical imaging. However, the 3D visualization tools for PA images remains a challenge. There are several commercially available software packages to visualize the generated 3D PA images. They are generally expensive, and their features are not optimized for 3D visualization of PA images. Here, we demonstrate a specialized 3D visualization software package, namely 3D Photoacoustic Visualization Studio (3D PHOVIS), specifically targeting photoacoustic data, image, and visualization processes. To support the research environment for visualization and fast processing, we incorporated 3D PHOVIS onto the MATLAB with graphical user interface and developed multi-core graphics processing unit modules for fast processing. The 3D PHOVIS includes following modules: (1) a mosaic volume generator, (2) a scan converter for optical scanning photoacoustic microscopy, (3) a skin profile estimator and depth encoder, (4) a multiplanar viewer with a navigation map, and (5) a volume renderer with a movie maker. This paper discusses the algorithms present in the software package and demonstrates their functions. In addition, the applicability of this software to ultrasound imaging and optical coherence tomography is also investigated. User manuals and application files for 3D PHOVIS are available for free on the website (<ext-link ext-link-type="uri" xlink:href="http://www.boa-lab.com" id="intr0005">www.boa-lab.com</ext-link>). Core functions of 3D PHOVIS are developed as a result of a summer class at POSTECH, “High-Performance Algorithm in CPU/GPU/DSP, and Computer Architecture.” We believe our 3D PHOVIS provides a unique tool to PA imaging researchers, expedites its growth, and attracts broad interests in a wide range of studies.</p>
    </abstract>
    <kwd-group id="kwd0005">
      <title>Keywords</title>
      <kwd>Volume mosaic</kwd>
      <kwd>3D scan-conversion</kwd>
      <kwd>Skin detection</kwd>
      <kwd>Visualization</kwd>
      <kwd>Rendering</kwd>
      <kwd>Volume imaging</kwd>
      <kwd>3D imaging</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="sec0005">
    <label>1</label>
    <title>Introduction</title>
    <p id="par0005">Photoacoustic imaging (PAI, or optoacoustic imaging) is a biomedical imaging technique that detects ultrasound (US) signals generated via light-induced thermal expansion and relaxation of cells within tissues, called the photoacoustic (PA) effect. [<xref rid="bib0005" ref-type="bibr">1</xref>] Based on the fundamental hybrid nature, PAI has two unique competitive differentiators: (1) strong image contrast on the basis of rich intrinsic (e.g., melanin [<xref rid="bib0010" ref-type="bibr">2</xref>], DNA/RNA [<xref rid="bib0015" ref-type="bibr">3</xref>], hemoglobin [<xref rid="bib0020" ref-type="bibr">[4]</xref>, <xref rid="bib0025" ref-type="bibr">[5]</xref>, <xref rid="bib0030" ref-type="bibr">[6]</xref>], lipid [<xref rid="bib0035" ref-type="bibr">7</xref>], water [<xref rid="bib0040" ref-type="bibr">8</xref>], and others [<xref rid="bib0045" ref-type="bibr">9</xref>]) and extrinsic (e.g., various contrast agents) optical properties, and (2) deep tissue imaging capability in an optical diffusion regime providing high spatial resolution [<xref rid="bib0050" ref-type="bibr">10</xref>]. Due to these unique features, not only biological applications but also medical applications have been investigated in the recent decade [<xref rid="bib0055" ref-type="bibr">[11]</xref>, <xref rid="bib0060" ref-type="bibr">[12]</xref>, <xref rid="bib0065" ref-type="bibr">[13]</xref>, <xref rid="bib0070" ref-type="bibr">[14]</xref>, <xref rid="bib0075" ref-type="bibr">[15]</xref>].</p>
    <p id="par0010">Many research activities in the PAI field boost the hardware and software performance, develop various novel PA derivative techniques, and apply to the technology in life science [<xref rid="bib0080" ref-type="bibr">[16]</xref>, <xref rid="bib0085" ref-type="bibr">[17]</xref>, <xref rid="bib0090" ref-type="bibr">[18]</xref>] and medicine [<xref rid="bib0095" ref-type="bibr">[19]</xref>, <xref rid="bib0100" ref-type="bibr">[20]</xref>, <xref rid="bib0105" ref-type="bibr">[21]</xref>, <xref rid="bib0110" ref-type="bibr">[22]</xref>, <xref rid="bib0115" ref-type="bibr">[23]</xref>]. However, research activities benefitting the visualization of the 3D PAI are rarely found. Mainly, few commercial medical data processing and visualization tools such as ImageJ (Wayne Rasband, USA), AMIRA (Thermo Fisher Scientific, USA) and VolView (Kitware, USA) are available, and they do not provide visualization tools specifically targeted for PAI. In addition, they are relatively expensive, do not support incorporating newly available visualization techniques, often have insufficient image qualities, and cannot be integrated with the most popular data processing tool in academia, i.e., MATLAB (MathWorks, USA).</p>
    <p id="par0015">Here, we have developed a novel 3D data/image processing and visualization tool for PAI, called 3D Photoacoustic Visualization Studio (3D PHOVIS). The unique features of 3D PHOVIS are illustrated in <xref rid="fig0005" ref-type="fig">Fig. 1</xref>. We implemented the 3D PHOVIS on the most commonly used MATLAB platform and leveraged parallel processing technology to provide real-time interactive work interface. The MATLAB platform allows researchers to incorporate their own newly developed visualization algorithm to improve the image quality further. The 3D PHOVIS consist of the following applications: (1) a mosaic volume generator, (2) a scan converter for optical scanning photoacoustic microscopy (PAM), (3) a skin profile estimator and depth encoder, (4) a multiplanar reconstruction (MPR) viewer with a navigation map, and (5) a volume renderer with a movie maker. In addition to PAI, we also explored the use of the 3D PHOVIS for other popular biological and medical imaging tools, such as optical coherence tomography (OCT) and US imaging. We expect this free software package available on the website (<ext-link ext-link-type="uri" xlink:href="http://www.boa-lab.com" id="intr0010">www.boa-lab.com</ext-link>) will broadly impact the research of PAI in the field of biological and medical imaging.<fig id="fig0005"><label>Fig. 1</label><caption><p>Main features of 3D Photoacoustic Visualization Studio (3D PHOVIS). FOV, field of view; PAM, photoacoustic microscopy; and MPR: multiplanar reformation.</p></caption><alt-text id="at0005">Fig. 1</alt-text><graphic xlink:href="gr1"/></fig></p>
  </sec>
  <sec id="sec0010">
    <label>2</label>
    <title>Design concept</title>
    <sec id="sec0015">
      <label>2.1</label>
      <title>Goal of development and expected user environments</title>
      <p id="par0020">The goal of our 3D PHOVIS is to provide intuitive volume editing and high-quality volume visualization experiences for all researchers in the field of biomedical imaging. The 3D PHOVIS can handle any data type that can be imported into MATLAB. Detailed data preparation procedures are described in the instruction manual with sample scripts.</p>
    </sec>
    <sec id="sec0020">
      <label>2.2</label>
      <title>Preparation of test data set</title>
      <p id="par0025">Acoustic-resolution (AR) PAM system (MicroPhotoAcoustics, USA) with a water-immersible micro-electro-mechanical systems (MEMS) scanner (OPTICHO, Republic of Korea) was used to acquire 3D PAM volume data for operational testing. The animal experiments were performed as per regulations and protocols approved by the Institutional Animal Care and Use Committee (IACUC) of Pohang University of Science and Technology (POSTECH), and regulations of the National Institutes of Health Guide for the Care and Use of Laboratory Animals. We performed PAI of a healthy mouse to acquire 3D volumetric PAM data (POSTECH Biotech Center; 15−25 g, 6 weeks old) in a back-coronal view. We first anesthetized the mouse with a vaporized isoflurane (1 L/min of oxygen and 0.75 % isoflurane), and then removed its hair with depilatory lotion. The mouse was placed on an imaging table custom-designed for PAI during the <italic>in vivo</italic> imaging experiments and the mouse body temperature was maintained with a heating pad. Ultrasound gel (Ecosonic, SANIPIA, Republic of Korea) was applied to enhance acoustic impedance matching between the mouse body and the water. The optical energy illuminated on the mouse skin surface was 2.3 mJ/cm<sup>2</sup>, which is below the maximum permissible exposure for single laser pulse (MPE<sub>SLP</sub>) safety limits of 20 mJ/cm<sup>2</sup> at 532 nm. For multiple pulse trains, the maximum permissible exposure for pulse train (MPE<sub>train</sub>) is 269 mJ/cm<sup>2</sup>, which is calculated for the scanning range of 2.5 mm, the optical beam size of 1.5 mm, the imaging pixel step size of 16.7 μm, and the exposure time of 3.6 ms. For 90 adjacent overlapped laser pulses, resulting maximum permissible exposure for MPE<sub>SLP</sub> is 3.0 mJ/cm<sup>2</sup>, which is well above the illuminated optical energy of 2.3 mJ/cm<sup>2</sup> in the imaging experiment [<xref rid="bib0120" ref-type="bibr">24</xref>]. The MPE<sub>SLP</sub> and MPE<sub>train</sub> are governed by American National Standards Institute (ANSI).</p>
      <p id="par0030">For demonstrating the use of 3D PHOVIS for OCT image rendering, we used the OCT data published by Golabbakhsh et al. [<xref rid="bib0125" ref-type="bibr">25</xref>]. For the US image rendering demo, we acquired a 3D US volume data of a fetus phantom (Model 065-36, CISR Inc., Norfolk, VA) with a mechanically-swiveling 3D transducer interfaced to the EUB-6500 ultrasound machine (Hitachi Healthcare America, USA).</p>
    </sec>
    <sec id="sec0025">
      <label>2.3</label>
      <title>Design of interactive graphical user interface</title>
      <p id="par0035">All graphical user interface (GUI) applications are developed using the 'GUIDE' toolkit provided by MATLAB 2016a. The GUI controllers are custom-developed to give a more intuitive experience than MATLAB built-in GUI controls. All applications utilized the custom-made slider classes because the default MATLAB slider class could not provide an interactive response when moving the slider. A custom-made color map editor class is implemented in every application and can be embedded in a GUI window. In addition, several custom-made interactive graphics classes are also developed to facilitate data visualization, such as navigation cursor, volume position tool, Gaussian brush tool, window/level tool, transfer function adjustment tool, and rendering direction setting tool.</p>
    </sec>
    <sec id="sec0030">
      <label>2.4</label>
      <title>Software structure</title>
      <p id="par0040">Since the interpreter-based software is slow, the functions based on MATLAB script are only used to determine the sequential processes or the interactive behavior of the GUI. If a function requires a two-dimensional loop process for calculation, we use a MATLAB built-in pre-compiled or custom-developed MATLAB executable (MEX) function. All loops in the MEX function are parallelized by the OpenMP library or streaming single instruction multiple data extensions (SSE). For functions requiring 3D data manipulation, we implemented parallel thread execution (PTX) kernels based on CUDA general-purpose computing for graphics processing unit (GPGPU). A majority of computation is implemented based on single-precision floating-point values for speed. All included functions and class structures are loaded by the main window of 3D PHOVIS. All applications are called in the main window and are associated with their GUIs and built-in features.</p>
    </sec>
  </sec>
  <sec id="sec0035">
    <label>3</label>
    <title>Result</title>
    <sec id="sec0040">
      <label>3.1</label>
      <title>Mosaic volume generator</title>
      <sec id="sec0045">
        <label>3.1.1</label>
        <title>Background</title>
        <p id="par0045">One of the most efficient ways to create wide-field images is to mosaic sequentially acquired multiple images. Many techniques have been developed to create panoramic images in 2D by employing feature extraction algorithms on 2D dense data [<xref rid="bib0130" ref-type="bibr">26</xref>]. However, in many applications, automatic feature extraction and matching algorithms do not always work [<xref rid="bib0135" ref-type="bibr">27</xref>,<xref rid="bib0140" ref-type="bibr">28</xref>]. Thus, commercial 2D viewer usually support manual image alignment interfaces to flexibly position the individual images [<xref rid="bib0135" ref-type="bibr">27</xref>,<xref rid="bib0145" ref-type="bibr">29</xref>,<xref rid="bib0150" ref-type="bibr">30</xref>]. For PAI also, it is difficult to apply feature extraction algorithms because the data is sparse and three dimensional [<xref rid="bib0155" ref-type="bibr">31</xref>]. Thus, convenient user interface is necessary to precisely align the individual images to create a mosaic 3D volume imaging. We have prepared a manual volume positioning interface for the volume mosaic process, allowing users to simultaneously observe and assign 3D positions of volumes in multiple planes.</p>
      </sec>
      <sec id="sec0050">
        <label>3.1.2</label>
        <title>Algorithm</title>
        <p id="par0050">The volume merging algorithm consists of the following three steps: positioning, window weighting, and zero padding &amp; maximum intensity filtering (<xref rid="fig0010" ref-type="fig">Fig. 2</xref>). Note that all these steps are processed in the 3D domain. The first step to create a mosaic image is to identify the relative positions between individual images. In the proposed algorithm, the 3D positioning of each volumetric image set is determined manually. The difference in the PA signals in the overlapped regions are interpolated with window weighting to eliminate motion/ghost artifacts and compensate for uneven signal [<xref rid="bib0140" ref-type="bibr">28</xref>]. In the final step, zero-padding is applied to each volume data to match the size of the final volume, and the final volume is generated via maximum value filtering.<fig id="fig0010"><label>Fig. 2</label><caption><p>Schematic of a 3D volumetric mosaic process.</p></caption><alt-text id="at0010">Fig. 2</alt-text><graphic xlink:href="gr2"/></fig></p>
      </sec>
      <sec id="sec0055">
        <label>3.1.3</label>
        <title>Application</title>
        <p id="par0055">The “Mosaic volume generator” application is shown in <xref rid="fig0015" ref-type="fig">Fig. 3</xref> and Supplementary Movie S1. The basic GUI consists of a data positioner, a merged images preview, a color map editor, a data manager, and window weighting. In this application, it is important to locate the individual volume data accurately. Thus, the interactive data positioner is designed to perform intuitive fine-tuning of the volume position. The data positioner has three different views for each orthogonal coordinate (i.e., x, y, and z axes). The data positioner allows the user to reposition each volume by dragging the PA maximum amplitude projection (MAP) images. The user can also set the volume location manually by entering an absolute location in the location editor. For fine-tuning the position, the user can take advantage of MATLAB's zoom and pan features. In the data positioner, the PA MAP images are displayed as translucent images to visualize overlapped areas. A 2D window weighting function is included in the data manager menu to perform appropriate window weight multiplication. In the merging process, zero padding and maximum intensity filtering are performed automatically, and the resulting MAP image in each orthogonal direction is displayed in the preview menu. After filtering, the merged volume could be exported from the preview menu. <xref rid="fig0020" ref-type="fig">Fig. 4</xref> shows the PA MAP mosaic image. Three individual PA MAP images (<xref rid="fig0020" ref-type="fig">Fig. 4</xref>a) are merged into one seamless PA MAP mosaic image. The cross-sectional PA B-scan images are shown in <xref rid="fig0020" ref-type="fig">Fig. 4</xref>b after seamless mosaic imaging.<fig id="fig0015"><label>Fig. 3</label><caption><p>User interface of the “Mosaic volume generator” application (Supplementary Movie S1).</p></caption><alt-text id="at0015">Fig. 3</alt-text><graphic xlink:href="gr3"/></fig><fig id="fig0020"><label>Fig. 4</label><caption><p>PA MAP mosaic image. (a) Three individual PA MAP input images. (b) PA MAP mosaic image and the depth-resolved PA B-scan images along the lines 1, 2, and 3. PA, photoacoustic and MAP, maximum amplitude projection.</p></caption><alt-text id="at0020">Fig. 4</alt-text><graphic xlink:href="gr4"/></fig></p>
      </sec>
    </sec>
    <sec id="sec0060">
      <label>3.2</label>
      <title>Scan converter for optical scanning photoacoustic microscopy</title>
      <sec id="sec0065">
        <label>3.2.1</label>
        <title>Background</title>
        <p id="par0060">The image distortions depending on various optical systems and scanning schemes and are shown in <xref rid="fig0025" ref-type="fig">Fig. 5</xref>. The PAM images either suffer from linear distortion with linear scanning or linear and nonlinear distortions with sinusoidal scanning. The linear bending distortion is induced by the scanning geometry, and the nonlinear compression distortion is caused by the nonlinear movement of the scanning mirror. A pre-objective system that performs linear scanning shows no distortion in the acquired 3D image (<xref rid="fig0025" ref-type="fig">Fig. 5</xref>a). However, image topology produced by a post-objective system with linear scanning (i.e., usually in optical scanning PAM [<xref rid="bib0160" ref-type="bibr">32</xref>]) is slightly deformed by a spherical (2D) or cylindrical (1D) pattern of light focusing on a target (<xref rid="fig0025" ref-type="fig">Fig. 5</xref>b). The declination of the mirror causes additional distortions such as shear, scaling, and rotational deformation in the acquired images. As the azimuthal scanning geometry causes the linear distortion, this can be corrected through a linear transformation as follows [<xref rid="bib0165" ref-type="bibr">33</xref>]:<disp-formula id="eq0005"><label>(1)</label><mml:math id="M1" altimg="si1.svg"><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula><mml:math id="M2" altimg="si2.svg"><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math></inline-formula> is a position vector in the Cartesian coordinator, T is a coordinator conversion matrix, and <inline-formula><mml:math id="M3" altimg="si3.svg"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math></inline-formula> is a position vector in the cylindrical or spherical coordinator. Furthermore, to remove the image distortion due to mirror declination, an affine transformation is applied as follows:<disp-formula id="eq0010"><label>(2)</label><mml:math id="M4" altimg="si4.svg"><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mi>T</mml:mi><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover><mml:mo>,</mml:mo></mml:math></disp-formula>where A is the affine transformation matrix. The 3D linear distortion can be effectively removed in optical scanning PAM with the linear scanning. More recently, a sinusoidal-driven galvanometer or MEMS mirrors have been applied to optical scanning PAM to achieve rapid scanning speeds via resonance motion [<xref rid="bib0120" ref-type="bibr">24</xref>,<xref rid="bib0170" ref-type="bibr">[34]</xref>, <xref rid="bib0175" ref-type="bibr">[35]</xref>, <xref rid="bib0180" ref-type="bibr">[36]</xref>, <xref rid="bib0185" ref-type="bibr">[37]</xref>, <xref rid="bib0190" ref-type="bibr">[38]</xref>, <xref rid="bib0195" ref-type="bibr">[39]</xref>, <xref rid="bib0200" ref-type="bibr">[40]</xref>]. When using a post-objective system with the sinusoidal scanning motion, the nonlinear distortion is also induced (<xref rid="fig0025" ref-type="fig">Fig. 5</xref>c). In this case, the coordinator conversion and affine transformation cannot correct for distortion because of nonlinear distortion. Thus, the angle profile should be linearized through the following equation before correcting the distortion:<disp-formula id="eq0015"><label>(3)</label><mml:math id="M5" altimg="si5.svg"><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>scan</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mtext>sin</mml:mtext></mml:mrow><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mi>π</mml:mi><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <italic>θ<sub>sampled</sub></italic> is a sampled angle, <italic>θ</italic> is a linearized angle, <italic>θ<sub>scan</sub></italic> is a scanning range of the scanner, and <italic>ϕ</italic> is a phase shift caused by acquisition delay. Without linearization, the images are divided into central and peripheral areas [<xref rid="bib0205" ref-type="bibr">41</xref>,<xref rid="bib0210" ref-type="bibr">42</xref>]. Since the difference between sin<italic>θ</italic> and <italic>θ</italic> are negligible in the central area, the angular interval between sampling axes is considered identical. However, the angular interval becomes dramatically nonlinear in the peripheral regions resulting expansion distortion. In the next section, we present a 3D scan converter for cylindrical coordination scanning with a sinusoidal mirror movement. We designed the 3D image warp transform based on inverse mapping approach to simultaneously remove linear and nonlinear distortions.<fig id="fig0025"><label>Fig. 5</label><caption><p>Image distortion vs various scanning methods.</p></caption><alt-text id="at0025">Fig. 5</alt-text><graphic xlink:href="gr5"/></fig></p>
      </sec>
      <sec id="sec0070">
        <label>3.2.2</label>
        <title>Algorithm</title>
        <p id="par0065">As per the scanning mechanism in optical scanning PAM (<xref rid="fig0030" ref-type="fig">Fig. 6</xref>a), the azimuth scanned data should be converted from the polar to Cartesian coordinator with consideration of declination and nonlinear motion of the mirror to correct the distortion. First, we perform the scan conversion by calculating the inverse representation of Eq. <xref rid="eq0010" ref-type="disp-formula">(2)</xref> as follows:<disp-formula id="eq0020"><label>(4)</label><mml:math id="M6" altimg="si6.svg"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover><mml:mo>.</mml:mo></mml:math></disp-formula><fig id="fig0030"><label>Fig. 6</label><caption><p>Principle of the scan conversion algorithm. (a) Scanning geometry and motion of the mirror. (b) Angular distribution of the acquired scanlines and angle profile linearization. (c) Effects of mirror declination in volumetric imaging.</p></caption><alt-text id="at0030">Fig. 6</alt-text><graphic xlink:href="gr6"/></fig></p>
        <p id="par0070">Since the elevational and zenithal tilting of the mirror induces shear deformation and the azimuthal tilting also brings rotational deformation, the affine matrix is represented as follows:<disp-formula id="eq0025"><label>(5)</label><mml:math id="M7" altimg="si7.svg"><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfenced open="[" close="]"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd><mml:mrow><mml:mtext>cos</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>-</mml:mo><mml:mrow><mml:mtext>sin</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mtext>sin</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mtext>cos</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mfenced open="[" close="]"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd><mml:mrow><mml:mtext>sec</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mtext>tan</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mtext>tan</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mtext>sec</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math></disp-formula></p>
        <p id="par0075">To remove this nonlinear distortion, the nonlinear angular profile between the scan lines are linearized by inverse mapping of the angle data (<xref rid="fig0030" ref-type="fig">Fig. 6</xref>b) via the following Equation:<disp-formula id="eq0030"><label>(6)</label><mml:math id="M8" altimg="si8.svg"><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced open="(" close=")"><mml:mrow><mml:mrow><mml:msup><mml:mtext>sin</mml:mtext><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:mfenced><mml:mfrac><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>π</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>.</mml:mo></mml:math></disp-formula></p>
        <p id="par0080">After the linearization, the 3D warping transformation is performed to remove the distortion in the 3D volume image (<xref rid="fig0030" ref-type="fig">Fig. 6</xref>c). The 3D scan conversion algorithm then reduces both nonlinear and linear distortions, and is based on the following Equations:<disp-formula id="eq0035"><label>(7)</label><mml:math id="M9" altimg="si9.svg"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mfenced open="(" close=")"><mml:mrow><mml:msqrt><mml:msup><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mtext>sec</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mtext>sec</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mfenced></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:msqrt><mml:mo>-</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mtext>o</mml:mtext><mml:mtext>f</mml:mtext><mml:mtext>f</mml:mtext><mml:mtext>s</mml:mtext><mml:mtext>e</mml:mtext><mml:mtext>t</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula id="eq0040"><label>(8)</label><mml:math id="M10" altimg="si10.svg"><mml:msup><mml:mi>θ</mml:mi><mml:mtext>'</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mtext>sin</mml:mtext><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mfenced open="(" close=")"><mml:mrow><mml:mrow><mml:mrow><mml:msup><mml:mtext>tan</mml:mtext><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mtext>cos</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mtext>cos</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mi>z</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mfrac><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>π</mml:mi></mml:mfrac><mml:mo>-</mml:mo><mml:mi>ϕ</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula><disp-formula id="eq0045"><label>(9)</label><mml:math id="M11" altimg="si11.svg"><mml:msup><mml:mi>z</mml:mi><mml:mtext>'</mml:mtext></mml:msup><mml:mo>=</mml:mo><mml:mi>z</mml:mi><mml:mo>+</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mtext>tan</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>z</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mtext>tan</mml:mtext><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>where <italic>x</italic> (horizontal)<italic>, y</italic> (axial), and <italic>z</italic> (elevational) represent the location of the voxel to be restored in the Cartesian coordinator. The obtained data is being represented in the distorted cylindrical coordinate using the inverse sine scale angle instead of the normal angle. <italic>r, θ'</italic> and <italic>z'</italic> are the radial, distorted angle, and elevational positions, respectively. <italic>ϕ</italic> is the phase shift described in <xref rid="fig0030" ref-type="fig">Fig. 6</xref>b. <italic>δ</italic> represent the declination of the mirror in each tilting direction in <xref rid="fig0030" ref-type="fig">Fig. 6</xref>c.</p>
      </sec>
      <sec id="sec0075">
        <label>3.2.3</label>
        <title>Application</title>
        <p id="par0085">For an intuitive and interactive working environment, the volume scan conversions are carried out using CUDA GPGPU technology. The application supports binary files as input data with headers. Details of the file header are described in the user manual. To support binary file preparation, 3D PHOVIS provides class functions for adding headers and exporting binary files. <xref rid="fig0035" ref-type="fig">Fig. 7</xref> shows the screenshot of the “Scan converter” application, and the detailed process is shown in Supplementary Movie S2. The volume scan conversion is performed through two-step process. In the first step, “Reference editor” application chooses one data set as the reference volume to visualize the effects of real-time parameter adjustments, utilizing a GPU assisted scan conversion process. The following six parameters are interactively adjusted: (1) offset data radius, (2) scanning range, (3) azimuth tilt, (4) elevation tilt, (5) zenithal tilt, and (6) phase shift of mirror motion. In the second step, “Mosaic volume generator,” user confirms the adjusted parameters by comparing the relationship between different volume data sets. For these data sets, each image is updated after the mouse button from the parameter slider’s knob is released. Each loaded volume is visualized in “Data positioner” as a semi-transparent MAP image. By observing overlapped areas, the user can accurately optimize the parameters.<fig id="fig0035"><label>Fig. 7</label><caption><p>User interface of the “Scan converter for optical scanning photoacoustic microscopy” application (Supplementary Movie S2).</p></caption><alt-text id="at0035">Fig. 7</alt-text><graphic xlink:href="gr7"/></fig></p>
        <p id="par0090">Without motion estimation, the area where <italic>θ</italic> ≒ sin<sup>−1</sup><italic>θ</italic> is relatively free from distortion. Unlike the simple linear coordinator conversion method, the newly proposed scan conversion method achieves wider FOV and less distortion (<xref rid="fig0040" ref-type="fig">Fig. 8</xref>). As one can see, the effective image length along the lateral direction increases to approximately 5 mm with our non-linear distortion correction, while they are about 2.5 mm in the linear coordinator conversion method and less than 2.5 mm in the unprocessed original image.<fig id="fig0040"><label>Fig. 8</label><caption><p>Comparison of the effective field of views in photoacoustic maximum amplitude projection images.</p></caption><alt-text id="at0040">Fig. 8</alt-text><graphic xlink:href="gr8"/></fig></p>
      </sec>
    </sec>
    <sec id="sec0080">
      <label>3.3</label>
      <title>Skin profile estimator and depth encoder</title>
      <sec id="sec0085">
        <label>3.3.1</label>
        <title>Background</title>
        <p id="par0095">Appropriate segmentation of the biological tissues is very important for 3D rendering. The depth-encoded colored PA MAP image is commonly used to show the 3D volumetric PA data in the 2D projection domains. However, a simple depth-encoded 3D rendered image based on the Cartesian coordinate induces significant errors in the rendered image because of irregular biological skin profiles. To accomplish successful depth encoding process, estimating the correct skin surface is essential [<xref rid="bib0215" ref-type="bibr">[43]</xref>, <xref rid="bib0220" ref-type="bibr">[44]</xref>, <xref rid="bib0225" ref-type="bibr">[45]</xref>, <xref rid="bib0230" ref-type="bibr">[46]</xref>]. In the next sub-section, we build a software application that automatically assesses the skin profiles and creates the true colored depth-encoded images.</p>
      </sec>
      <sec id="sec0090">
        <label>3.3.2</label>
        <title>Algorithm</title>
        <p id="par0100">Since the PA signals on the skin are not continuous, it is challenging to correctly contour the skin profiles in the PA images [<xref rid="bib0225" ref-type="bibr">45</xref>]. To delineate the continuous and smooth boundaries, the Gaussian blurring [<xref rid="bib0230" ref-type="bibr">46</xref>], cloth simulation [<xref rid="bib0225" ref-type="bibr">45</xref>], or random sample consensus (RANSAC) fitting [<xref rid="bib0215" ref-type="bibr">43</xref>] have been explored. While these methods show the convincing estimation of the skin profiles, they still have limitations. The Gaussian blurring and cloth simulation methods are vulnerable to outlier signals caused by artifacts. The RANSAC approach is robust even if the data contain many outliers, but only applicable when the appropriate analytical model exists.</p>
        <p id="par0105">To estimate the skin profiles in the PA images, the rough skin profile is sampled by detecting the first PA signals along time-resolved A-line images. The sampled profile is filtered by median filtering and Gaussian blurring. The reliable skin profile, regardless of outliers, is achieved by manually tweaking the profile estimation process using the Gaussian Brush tool provided with the application. The detailed procedure is illustrated in <xref rid="fig0045" ref-type="fig">Fig. 9</xref>. The white line indicates the estimated skin profile and the green line represents the brush guide. Typically, the outliers with large areas are excluded by the Gaussian Brushing and the smaller areas are removed by 2D median filtering. Finally, we apply the Gaussian filtering to smooth the profile.<fig id="fig0045"><label>Fig. 9</label><caption><p>Skin profile estimation process in a B-mode photoacoustic (PA) image and estimated depth-encoded skin profile in the 3D PA image.</p></caption><alt-text id="at0045">Fig. 9</alt-text><graphic xlink:href="gr9"/></fig></p>
      </sec>
      <sec id="sec0095">
        <label>3.3.3</label>
        <title>Application</title>
        <p id="par0110">The “Skin profile estimator and depth encoder” application estimates the skin profile and generates the colored depth-encoded image. This application is driven by MEX functions, which are parallelized by the OpenMP to interactively process and control the volume data in real-time. The GUI interface for this application is shown in <xref rid="fig0050" ref-type="fig">Fig. 10</xref>, and the detailed process is shown in Supplementary Movie S3. The first panel is the “Skin profile estimator” panel. The profile estimation is controlled by four sliders. These slider control the sampling threshold, 2D square median filter size, Gaussian blur amount (using σ, standard deviation), and the overall offset movement of the estimated surface in the axial direction. The expected skin profile is visualized as a white line in each orthogonal slice image and projection image in the profile monitor. The Gaussian brush tool is provided to avoid any incorrect and noisy estimation. The Gaussian brush guides appear as green lines in each orthogonal slice image. The second panel is the “Depth encoder” panel. In this panel, regular and depth-encoded MAP images are displayed in the preview menu. All parameters for MAP rendering (e.g., a surface peel depth, a short-range MAP rendering range, rendering colors, and image brightness) are controlled by the depth peeling tool and two-color map editors. The depth peeling tool consists of two sliders that determine the depth of the surface peel and the range of rendering. The parameter settings of the peeling tool can be saved and recalled later by the reference manager. The signal brightness and depth encoding colors of MAP images are each controlled by separate color map editors. For additional brightness adjustment of the depth-encoded images, γ correction slider is provided. The generated MAP images, volume data, and depth indices can be exported from the Export menu.<fig id="fig0050"><label>Fig. 10</label><caption><p>User interface of the “Skin profile estimator and depth encoder” application (Supplementary Movie S3).</p></caption><alt-text id="at0050">Fig. 10</alt-text><graphic xlink:href="gr10"/></fig></p>
      </sec>
    </sec>
    <sec id="sec0100">
      <label>3.4</label>
      <title>3D volume viewer</title>
      <sec id="sec0105">
        <label>3.4.1</label>
        <title>Background</title>
        <p id="par0115">Many 3D visualizations techniques have been developed and applied to visualize 3D PA data, and each has its own pros and cons [<xref rid="bib0235" ref-type="bibr">47</xref>]. Among various visualization methods, the multiplanar reconstruction (MPR) and volume rendering are most commonly used. The MPR generates a 2D image slice for any desired trajectory, and this method is easy and fast. The volume rendering generates a 3D-like image by simulating a virtual camera, volume subject, and light source. Since the visibility of the 3D image depends on the rendering algorithm and parameters, it is important to construct a specialized interactive interface to optimize the rendering algorithm and 3D parameter updates. To visualize 3D PA data effectively, we developed the "MPR viewer" and the "Volume renderer" with interactive interfaces in the MATLAB environment.</p>
      </sec>
      <sec id="sec0110">
        <label>3.4.2</label>
        <title>Multiplanar reconstruction (MPR) viewer</title>
        <sec id="sec0115">
          <label>3.4.2.1</label>
          <title>Algorithm</title>
          <p id="par0120">We implement the MPR and projection rendering algorithms. Since each MPR slice is a radial slice in the viewing field, each 2D slice is reconstructed by the next linear transformation:<disp-formula id="eq0050"><label>(10)</label><mml:math id="M12" altimg="si12.svg"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>R</mml:mi><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover><mml:mo>,</mml:mo></mml:math></disp-formula>where <inline-formula><mml:math id="M13" altimg="si3.svg"><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math></inline-formula> is the position vector in the cylindrical coordinator, <inline-formula><mml:math id="M14" altimg="si2.svg"><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math></inline-formula> is the position vector in the Cartesian coordinator, <italic>T</italic> is the coordination transform matrix, and <italic>R</italic> is the viewpoint rotation matrix. To provide navigation, the projection image is provided. The shear warp factorization algorithm [<xref rid="bib0240" ref-type="bibr">48</xref>] based on multi-core CPU and SSE is used to render the projection image in an arbitrary viewing direction. For the projection image, a MAP or average amplitude projection (AAP) image can be used. <xref rid="fig0055" ref-type="fig">Fig. 11</xref> shows one MAP image, one AAP image, and three MPR slices cut along the lines “1”, “2”, and “3” in the MAP image. Note that the navigation map image plays an important role in selecting the appropriate MPR configuration angle. In <xref rid="fig0055" ref-type="fig">Fig. 11</xref>, the MAP image represents the distribution of high amplitude signals, while the AAP implies high-density signals.<fig id="fig0055"><label>Fig. 11</label><caption><p>Maximum amplitude projection (MAP) image, average amplitude projection (AAP) image, and multiplanar reconstruction (MPR) images extracted along the lines “1”, “2”, and “3” in the MAP image.</p></caption><alt-text id="at0055">Fig. 11</alt-text><graphic xlink:href="gr11"/></fig></p>
        </sec>
        <sec id="sec0120">
          <label>3.4.2.2</label>
          <title>Application</title>
          <p id="par0125">The user interface and control method of the MPR viewer application is shown in <xref rid="fig0060" ref-type="fig">Fig. 12</xref> and Supplementary Movie S4. The image reconstruction process is powered by the OpenMP library and by employing multi-core CPU parallelization. The MEX function reconstructs MPR, and projection images based on the input parameters, and imaging results are displayed in the GUI interface. The GUI interface has three parts: a navigation map, two MPR viewers, and a transfer function editor. The navigation cursor is controlled by two orthogonal lines with a center point in the projection map image. The position and angle of the cursor and the orthogonal lines are controlled by mouse movement. When the navigation cursor moves, the two MPR slices are automatically updated. The transfer function editor has interactive controls to instantly adjust the dynamic range and color map. The viewing direction in the navigation map can be rotated by right angle in each axial direction or in arbitrary direction. The arbitrary directional rotation is controlled by computer mouse motion.<fig id="fig0060"><label>Fig. 12</label><caption><p>User interface of the “Multiplanar reformation viewer” application (Supplementary Movie S4). MPR: multiplanar reformation.</p></caption><alt-text id="at0060">Fig. 12</alt-text><graphic xlink:href="gr12"/></fig></p>
        </sec>
      </sec>
      <sec id="sec0125">
        <label>3.4.3</label>
        <title>Volume renderer with a moviemaker</title>
        <sec id="sec0130">
          <label>3.4.3.1</label>
          <title>Algorithm</title>
          <p id="par0130">We use a ray casting algorithm, which can provide the best image quality among volume rendering algorithms [<xref rid="bib0245" ref-type="bibr">49</xref>], for “Volume renderer” application. Because the volume rendering process is more computationally expensive than any other process, CUDA GPGPU acceleration is leveraged to execute the rendering processes in real-time. In volume rendering, it is important to determine the voxel information using opacity and colors [<xref rid="bib0250" ref-type="bibr">50</xref>]. We use colormaps to visualize the PA amplitudes in “Amplitude mode” and the PA depth information in “Depth mode.” To classify visible information, we simultaneously sample the PA amplitude and depth data. The detail rendering process is shown in <xref rid="fig0065" ref-type="fig">Fig. 13</xref> and it consists of a ray traversing, sampling, and accumulation process. The ray traversing process determines the sampling position depending on the traversing direction and sampling depth. We sample the values from the input data based on the calculated sampling position by trilinear interpolation. The accumulation process transfers the sampled values to red, green, blue and opacity values, and accumulates the sampled values to generate the rendered 2D images. In <xref rid="fig0065" ref-type="fig">Fig. 13</xref>, <italic>I<sub>vox</sub></italic>(<italic>i</italic>) is the sampled value that represents the PA signal amplitude, <italic>I<sub>depth</sub></italic>(<italic>i</italic>) is the sampled imaging depth information of the volume, and <italic>α<sub>vox</sub></italic>(<italic>i</italic>) is the opacity of the voxel data in the <italic>i</italic>-th sampling position. <italic>I<sub>vox</sub></italic>(<italic>i</italic>) is the voxel’s color and brightness in the “Amplitude mode” and brightness in the “Depth mode”. <italic>I<sub>depth</sub></italic>(<italic>i</italic>) is the voxel’s color in the “Depth mode”.<fig id="fig0065"><label>Fig. 13</label><caption><p>Principle of the volume ray casting process. <italic>I<sub>vox</sub></italic>, the sampled PA signal amplitude value; <italic>I<sub>depth</sub></italic>, the sampled PA imaging depth value; and <italic>α<sub>vox</sub></italic>, the opacity of the sample.</p></caption><alt-text id="at0065">Fig. 13</alt-text><graphic xlink:href="gr13"/></fig></p>
          <p id="par0135"><xref rid="fig0070" ref-type="fig">Fig. 14</xref> shows the rendering examples and corresponding algorithms in the “Amplitude mode”, and “Depth mode.” For the accumulation process, alpha composition (AC), MAP, and AAP methods are implemented. To render a single pixel, AC accumulates the sampled voxels with partial transparency [<xref rid="bib0255" ref-type="bibr">51</xref>], MAP finds the maximum values among the sampled voxels, and AAP returns the average values among the sample voxels along the corresponding transfer line. We used the depth index information generated from the “Skin profile estimator and depth encoder” application.<fig id="fig0070"><label>Fig. 14</label><caption><p>Photoacoustic amplitude and depth images processed through the AC, MAP, and AAP algorithms. AC: alpha composition, MAP: maximum amplitude projection, AAP: average amplitude projection.</p></caption><alt-text id="at0070">Fig. 14</alt-text><graphic xlink:href="gr14"/></fig></p>
        </sec>
        <sec id="sec0135">
          <label>3.4.3.2</label>
          <title>Application</title>
          <p id="par0140">The volume rendering application specializes in interactive real-time high-quality volume-rendered image and automatic motion frame generation. CUDA GPGPU acceleration technology is utilized for real-time volume rendering. <xref rid="fig0075" ref-type="fig">Fig. 15</xref> and Supplementary Movie S5 show the user interface for the “Volume renderer” application. For visualizing the volume data, the CUDA function generates a volume rendering image corresponding to the input data, and then the resulting image is displayed in the rendering window. The view orientation and perspective of an image can be fully adjusted in the render window with mouse control, while other software systems typically use a fixed distance between the camera and volume, or only supports non-perspective projection. The rendering results can be captured as an image file, or multiple image frames, which is generated by the automatic frame generator, can be recorded as a video file. The example videos created by this application is available in Supplementary Movies S6.<fig id="fig0075"><label>Fig. 15</label><caption><p>User interface of the “Volume renderer” application (Supplementary Movie S5). The example videos created by this application is available in Supplementary Movies S6–11.</p></caption><alt-text id="at0075">Fig. 15</alt-text><graphic xlink:href="gr15"/></fig></p>
          <p id="par0145">We also explored the feasibility of our volume renderer for 3D OCT and US imaging. <xref rid="fig0080" ref-type="fig">Fig. 16</xref> shows the 2D projection, MPR images, and 3D volume-rendered OCT and US images. The volume-rendered movies are shown in Supplementary Movies S7-8. The OCT data published in Golabbakhsh et al. [<xref rid="bib0125" ref-type="bibr">25</xref>] is employed for OCT image rendering, and we acquired the 3D US volume data of a fetus phantom (Model 065-36, CISR Inc., Norfolk, VA) with a mechanically-swiveling 3D transducer interfaced to the EUB-6500 ultrasound machine (Hitachi Healthcare America, USA). The OCT and US maximum intensity projection (MIP, equivalent algorithm with MAP) and average intensity projection (AIP, an equivalent algorithm with AAP) images are based on optical and acoustic scattering, respectively. These examples imply that our volume renderer is flexible for use in various 3D volumetric imaging modalities.<fig id="fig0080"><label>Fig. 16</label><caption><p>OCT and US MIP and AIP images and corresponding MPR images cut along the lines “1”, “2”, and “3” in the MIP images from “MPR viewer” and 3D volume rendered images processed by AC, MIP, and algorithms. The 3D volume rendered OCT and US images are shown in Supplementary Movie S10-11. AC: alpha composition, AIP: average intensity projection, MIP: maximum intensity projection, OCT: optical coherence tomography, US: ultrasound, ILM: inner limiting layer, ONL: outer nuclear layer.</p></caption><alt-text id="at0080">Fig. 16</alt-text><graphic xlink:href="gr16"/></fig></p>
        </sec>
      </sec>
    </sec>
  </sec>
  <sec id="sec0140">
    <label>4</label>
    <title>System requirements</title>
    <p id="par0150">Software kits and user manuals are available on the Bio Optics and Acoustics Laboratory (BOA-Lab) website (<ext-link ext-link-type="uri" xlink:href="http://www.boa-lab.com" id="intr0015">www.boa-lab.com</ext-link>). All features are designed to work on 64-bit Windows platforms. All MEX functions have been compiled with a 64-bit compiler. Note that this software kit does not work with 32-bit MATLAB. MATLAB version 2016a or later is recommended for normal operation. The parallel and image processing toolboxes must be installed with MATLAB. Our software kit requires a resolution of 1920 × 1080 or higher for normal use. Otherwise, the application windows do not display images appropriately on the screen. The scan converter and volume renderer applications require a CUDA-capable video accelerator card. We further recommend using modern multi-core processors. 3D PHOVIS was developed and tested on workstations using Intel i5-4670 processor and NVIDIA GTX 750ti.</p>
  </sec>
  <sec id="sec0145">
    <label>5</label>
    <title>Discussion and conclusion</title>
    <p id="par0155">A variety of innovations have enhanced 3D PA imaging performance but ours is the first effort to enhance visualization of PA image, which is very critical for the analysis of results. Here, we demonstrated a specialized 3D visualization software package, 3D PHOVIS, specifically targeting photoacoustic data, image, and visualization processes. We incorporated 3D PHOVIS onto the MATLAB with graphical user interface and developed multi-core graphics processing unit modules for fast processing. The five main components of 3D PHOVIS are, namely mosaic volume generator, scan converter, skin profile estimator and depth encoder, MPR viewer, and volume renderer, have unique advantages. In the “Mosaic volume generator”, users provide flexibility to the user to intuitively and manually manipulate data volumes for better registration. Our maximum filtering method does not cause any signal loss or distortion, unlike other commonly used blending methods. Precise manual positioning and window weighting further minimizes data discrepancy for mosaic imaging [<xref rid="bib0120" ref-type="bibr">24</xref>]. The scan conversion algorithm proposed here corrects the distortion of nonlinear mirror scanning in PAM. The “Skin profile estimator and depth encoder” application provides a convenient depth peeling feature that allows us to visualize the unique characteristics of biological tissues based on depth information. The Gaussian brush tool in the “Skin profile estimator” can effectively correct false estimates caused by noises or artifacts. The intuitive slicing position control in the “MPR viewer” application is beneficial to analyze PA images and other 3D images like US and OCT images. In the “Volume renderer” application, three-volume rendering algorithms (e.g., AC, MAP, and AAP) shows their unique characteristics of volume data. As shown in <xref rid="fig0070" ref-type="fig">Fig. 14</xref>, AC represents the most stereoscopic image, MAP represents the strong signal with a high contrast ratio, and AAP represents the signal density in the viewing direction. Since, we implemented the 3D PHOVIS on the most commonly used MATLAB platform, it provides researchers to incorporate their own newly developed visualization algorithm to improve the image quality further. 3D PHOVIS can directly import any type of data from the MATLAB workspace. In addition, we also demonstrated the applicability of this software to ultrasound imaging and optical coherence tomography. User manuals and application files for 3D PHOVIS are available for free on the website (<ext-link ext-link-type="uri" xlink:href="http://www.boa-lab.com" id="intr0020">www.boa-lab.com</ext-link>). We believe our 3D PHOVIS provides a unique tool to PAI researchers, expedites its growth, and attracts broad interests in a wide range of studies. In addition, our 3D software has several advantages over other commercially available including it is free, the applications available are optimized for PA imaging, and is based upon most commonly used research platform, i.e., MATLAB.</p>
    <p id="par0160">There are some limitations to 3D PHOVIS, which can be overcome in near future. The proposed scan conversion algorithm only works for 1-axis cylindrical scanning and different algorithms exists for 2-axes mirror scanning [<xref rid="bib0175" ref-type="bibr">35</xref>] or other scanning mechanisms, which can be incorporated into 3D PHOVIS. Some modules are operator dependent, such as “Mosaic volume generator” and “Skin profile estimator and depth encoder” applications. Future research can automate these applications and incorporated into 3D PHOVIS for other researchers to use. In addition, since all the features and class methods of 3D PHOVIS are designed for GUI input, they are not configured properly for script coding without GUI control. More sophistication can be added to the GUI control. Nevertheless, we strongly believe the proposed 3D visualization tool is very valuable for high-quality research activities in the field of biological and biomedical imaging.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Declaration of Competing Interest</title>
    <p id="par0165">Chulhong Kim has financial interests in OPTICHO, which, however, did not support this work.</p>
  </sec>
</body>
<back>
  <ref-list id="bibl0005">
    <title>References</title>
    <ref id="bib0005">
      <label>1</label>
      <element-citation publication-type="journal" id="sbref0005">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>L.V.</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>A practical guide to photoacoustic tomography in the life sciences</article-title>
        <source>Nat. Methods</source>
        <volume>13</volume>
        <issue>8</issue>
        <year>2016</year>
        <fpage>627</fpage>
        <lpage>638</lpage>
        <pub-id pub-id-type="pmid">27467726</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0010">
      <label>2</label>
      <element-citation publication-type="journal" id="sbref0010">
        <person-group person-group-type="author">
          <name>
            <surname>Moore</surname>
            <given-names>M.J.</given-names>
          </name>
          <name>
            <surname>El-Rass</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Wen</surname>
            <given-names>X.-Y.</given-names>
          </name>
          <name>
            <surname>Kolios</surname>
            <given-names>M.C.</given-names>
          </name>
        </person-group>
        <article-title>Simultaneous ultra-high frequency photoacoustic microscopy and photoacoustic radiometry of zebrafish larvae in vivo</article-title>
        <source>Photoacoustics</source>
        <volume>12</volume>
        <year>2018</year>
        <fpage>14</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="pmid">30225194</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0015">
      <label>3</label>
      <element-citation publication-type="journal" id="sbref0015">
        <person-group person-group-type="author">
          <name>
            <surname>Wong</surname>
            <given-names>T.T.W.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Hsu</surname>
            <given-names>H.C.</given-names>
          </name>
          <name>
            <surname>Maslov</surname>
            <given-names>K.I.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Shung</surname>
            <given-names>K.K.</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L.V.</given-names>
          </name>
        </person-group>
        <article-title>Label-free automated three-dimensional imaging of whole organs by microtomy-assisted photoacoustic microscopy</article-title>
        <source>Nat. Commun.</source>
        <volume>8</volume>
        <issue>1</issue>
        <year>2017</year>
        <fpage>1386</fpage>
        <pub-id pub-id-type="pmid">29123109</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0020">
      <label>4</label>
      <element-citation publication-type="journal" id="sbref0020">
        <person-group person-group-type="author">
          <name>
            <surname>Arthuis</surname>
            <given-names>C.J.</given-names>
          </name>
          <name>
            <surname>Novell</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Raes</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Escoffre</surname>
            <given-names>J.M.</given-names>
          </name>
          <name>
            <surname>Lerondel</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Le Pape</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Bouakaz</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Perrotin</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>Real-time monitoring of placental oxygenation during maternal hypoxia and hyperoxygenation using photoacoustic imaging</article-title>
        <source>PLoS One</source>
        <volume>12</volume>
        <issue>1</issue>
        <year>2017</year>
        <object-id pub-id-type="publisher-id">e0169850</object-id>
      </element-citation>
    </ref>
    <ref id="bib0025">
      <label>5</label>
      <element-citation publication-type="journal" id="sbref0025">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.Y.</given-names>
          </name>
          <name>
            <surname>Jeon</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Baik</surname>
            <given-names>J.W.</given-names>
          </name>
          <name>
            <surname>Cho</surname>
            <given-names>S.H.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Super-resolution localization photoacoustic microscopy using intrinsic red blood cells as contrast absorbers</article-title>
        <source>Light Sci. Appl.</source>
        <volume>8</volume>
        <issue>1</issue>
        <year>2019</year>
        <fpage>1</fpage>
        <lpage>11</lpage>
        <pub-id pub-id-type="pmid">30622704</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0030">
      <label>6</label>
      <element-citation publication-type="journal" id="sbref0030">
        <person-group person-group-type="author">
          <name>
            <surname>Park</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Jeon</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Ahn</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>H.H.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Reflection‐mode switchable subwavelength Bessel‐beam and Gaussian‐beam photoacoustic microscopy in vivo</article-title>
        <source>J. Biophotonics</source>
        <volume>12</volume>
        <issue>2</issue>
        <year>2019</year>
        <object-id pub-id-type="publisher-id">e201800215</object-id>
      </element-citation>
    </ref>
    <ref id="bib0035">
      <label>7</label>
      <element-citation publication-type="journal" id="sbref0035">
        <person-group person-group-type="author">
          <name>
            <surname>Liang</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lashkari</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Choi</surname>
            <given-names>S.S.S.</given-names>
          </name>
          <name>
            <surname>Ntziachristos</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Mandelis</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>The application of frequency-domain photoacoustics to temperature-dependent measurements of the Grüneisen parameter in lipids</article-title>
        <source>Photoacoustics</source>
        <volume>11</volume>
        <year>2018</year>
        <fpage>56</fpage>
        <lpage>64</lpage>
        <pub-id pub-id-type="pmid">30112278</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0040">
      <label>8</label>
      <element-citation publication-type="journal" id="sbref0040">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L.V.</given-names>
          </name>
        </person-group>
        <article-title>Photoacoustic tomography of water in phantoms and tissue</article-title>
        <source>J. Biomed. Opt.</source>
        <volume>15</volume>
        <issue>3</issue>
        <year>2010</year>
        <object-id pub-id-type="publisher-id">036019</object-id>
      </element-citation>
    </ref>
    <ref id="bib0045">
      <label>9</label>
      <element-citation publication-type="journal" id="sbref0045">
        <person-group person-group-type="author">
          <name>
            <surname>Shi</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Wong</surname>
            <given-names>T.T.</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Yung</surname>
            <given-names>C.S.</given-names>
          </name>
          <name>
            <surname>Hwang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Maslov</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L.V.</given-names>
          </name>
        </person-group>
        <article-title>High-resolution, high-contrast mid-infrared imaging of fresh biological samples with ultraviolet-localized photoacoustic microscopy</article-title>
        <source>Nat. Photonics</source>
        <year>2019</year>
        <fpage>1</fpage>
      </element-citation>
    </ref>
    <ref id="bib0050">
      <label>10</label>
      <element-citation publication-type="journal" id="sbref0050">
        <person-group person-group-type="author">
          <name>
            <surname>Jeon</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Multiplane spectroscopic whole-body photoacoustic imaging of small animals in vivo</article-title>
        <source>Med. Biol. Eng. Comput.</source>
        <volume>54</volume>
        <issue>2–3</issue>
        <year>2016</year>
        <fpage>283</fpage>
        <lpage>294</lpage>
        <pub-id pub-id-type="pmid">25115270</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0055">
      <label>11</label>
      <element-citation publication-type="journal" id="sbref0055">
        <person-group person-group-type="author">
          <name>
            <surname>Choi</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>E.Y.</given-names>
          </name>
          <name>
            <surname>Jeon</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Clinical photoacoustic imaging platforms</article-title>
        <source>Biomed. Eng. Lett.</source>
        <volume>8</volume>
        <issue>2</issue>
        <year>2018</year>
        <fpage>139</fpage>
        <lpage>155</lpage>
        <pub-id pub-id-type="pmid">30603199</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0060">
      <label>12</label>
      <element-citation publication-type="journal" id="sbref0060">
        <person-group person-group-type="author">
          <name>
            <surname>Shiina</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Toi</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Yagi</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>Development and clinical translation of photoacoustic mammography</article-title>
        <source>Biomed. Eng. Lett.</source>
        <volume>8</volume>
        <issue>2</issue>
        <year>2018</year>
        <fpage>157</fpage>
        <lpage>165</lpage>
        <pub-id pub-id-type="pmid">30603200</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0065">
      <label>13</label>
      <element-citation publication-type="journal" id="sbref0065">
        <person-group person-group-type="author">
          <name>
            <surname>Upputuri</surname>
            <given-names>P.K.</given-names>
          </name>
          <name>
            <surname>Pramanik</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Fast photoacoustic imaging systems using pulsed laser diodes: a review</article-title>
        <source>Biomed. Eng. Lett.</source>
        <volume>8</volume>
        <issue>2</issue>
        <year>2018</year>
        <fpage>167</fpage>
        <lpage>181</lpage>
        <pub-id pub-id-type="pmid">30603201</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0070">
      <label>14</label>
      <element-citation publication-type="journal" id="sbref0070">
        <person-group person-group-type="author">
          <name>
            <surname>Jeon</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>E.-Y.</given-names>
          </name>
          <name>
            <surname>Choi</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Managuli</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Jong Lee</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Real-time delay-multiply-and-sum beamforming with coherence factor for in vivo clinical photoacoustic imaging of humans</article-title>
        <source>Photoacoustics</source>
        <volume>15</volume>
        <year>2019</year>
        <object-id pub-id-type="publisher-id">100136</object-id>
      </element-citation>
    </ref>
    <ref id="bib0075">
      <label>15</label>
      <element-citation publication-type="journal" id="sbref0075">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Liao</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Gong</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Pang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>The integrated high-resolution reflection-mode photoacoustic and fluorescence confocal microscopy</article-title>
        <source>Photoacoustics</source>
        <volume>14</volume>
        <year>2019</year>
        <fpage>12</fpage>
        <lpage>18</lpage>
        <pub-id pub-id-type="pmid">30923675</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0080">
      <label>16</label>
      <element-citation publication-type="journal" id="sbref0080">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Photoacoustic microscopy: principles and biomedical applications</article-title>
        <source>Biomed. Eng. Lett.</source>
        <volume>8</volume>
        <issue>2</issue>
        <year>2018</year>
        <fpage>203</fpage>
        <lpage>213</lpage>
        <pub-id pub-id-type="pmid">30603203</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0085">
      <label>17</label>
      <element-citation publication-type="journal" id="sbref0085">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Kwon</surname>
            <given-names>O.</given-names>
          </name>
          <name>
            <surname>Jeon</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Shin</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Jo</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Rim</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Doh</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Super-resolution visible photoactivated atomic force microscopy</article-title>
        <source>Light Sci. Appl.</source>
        <volume>6</volume>
        <issue>11</issue>
        <year>2017</year>
        <object-id pub-id-type="publisher-id">e17080</object-id>
      </element-citation>
    </ref>
    <ref id="bib0090">
      <label>18</label>
      <element-citation publication-type="journal" id="sbref0090">
        <person-group person-group-type="author">
          <name>
            <surname>Cai</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Choi</surname>
            <given-names>S.-W.</given-names>
          </name>
          <name>
            <surname>MacEwan</surname>
            <given-names>M.R.</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Xia</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L.V.</given-names>
          </name>
        </person-group>
        <article-title>Investigation of neovascularization in three-dimensional porous scaffolds in vivo by a combination of multiscale photoacoustic microscopy and optical coherence tomography</article-title>
        <source>Tissue Eng. Part C: Methods</source>
        <volume>19</volume>
        <issue>3</issue>
        <year>2012</year>
        <fpage>196</fpage>
        <lpage>204</lpage>
        <pub-id pub-id-type="pmid">22838500</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0095">
      <label>19</label>
      <element-citation publication-type="journal" id="sbref0095">
        <person-group person-group-type="author">
          <name>
            <surname>Jung</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Gunassekaran</surname>
            <given-names>G.R.</given-names>
          </name>
          <name>
            <surname>Jeon</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Cho</surname>
            <given-names>Y.-E.</given-names>
          </name>
          <name>
            <surname>Baek</surname>
            <given-names>M.-C.</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>J.Y.</given-names>
          </name>
          <name>
            <surname>Shim</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Oh</surname>
            <given-names>Y.-K.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>I.-S.</given-names>
          </name>
        </person-group>
        <article-title>A peptide probe enables photoacoustic-guided imaging and drug delivery to lung tumors in K-rasLA2 mutant mice</article-title>
        <source>Cancer Res.</source>
        <year>2019</year>
        <comment>canres.3089.2018</comment>
      </element-citation>
    </ref>
    <ref id="bib0100">
      <label>20</label>
      <element-citation publication-type="journal" id="sbref0100">
        <person-group person-group-type="author">
          <name>
            <surname>Choi</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Toward in vivo translation of super-resolution localization photoacoustic computed tomography using liquid-state dyed droplets</article-title>
        <source>Light Sci. Appl.</source>
        <volume>8</volume>
        <year>2019</year>
      </element-citation>
    </ref>
    <ref id="bib0105">
      <label>21</label>
      <element-citation publication-type="journal" id="sbref0105">
        <person-group person-group-type="author">
          <name>
            <surname>Bi</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Dinish</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Goh</surname>
            <given-names>C.C.</given-names>
          </name>
          <name>
            <surname>Imai</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Moothanchery</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.Y.</given-names>
          </name>
          <name>
            <surname>Jeon</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Pu</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>In vivo label‐free functional photoacoustic monitoring of ischemic reperfusion</article-title>
        <source>J. Biophotonics</source>
        <year>2019</year>
        <fpage>e201800454</fpage>
        <pub-id pub-id-type="pmid">30865386</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0110">
      <label>22</label>
      <element-citation publication-type="journal" id="sbref0110">
        <person-group person-group-type="author">
          <name>
            <surname>Shin</surname>
            <given-names>M.H.</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>E.Y.</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Jung</surname>
            <given-names>H.S.</given-names>
          </name>
          <name>
            <surname>Keum</surname>
            <given-names>D.H.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>G.H.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>K.S.</given-names>
          </name>
          <name>
            <surname>Yun</surname>
            <given-names>S.H.</given-names>
          </name>
        </person-group>
        <article-title>Multimodal cancer theranosis using hyaluronate‐conjugated molybdenum disulfide</article-title>
        <source>Adv. Healthc. Mater.</source>
        <volume>8</volume>
        <issue>1</issue>
        <year>2019</year>
        <object-id pub-id-type="publisher-id">1801036</object-id>
      </element-citation>
    </ref>
    <ref id="bib0115">
      <label>23</label>
      <element-citation publication-type="journal" id="sbref0115">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Beack</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Yoo</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>S.K.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Kwon</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Hahn</surname>
            <given-names>S.K.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>In vivo photoacoustic imaging of livers using biodegradable hyaluronic acid‐conjugated silica nanoparticles</article-title>
        <source>Adv. Funct. Mater.</source>
        <volume>28</volume>
        <issue>22</issue>
        <year>2018</year>
        <object-id pub-id-type="publisher-id">1800941</object-id>
      </element-citation>
    </ref>
    <ref id="bib0120">
      <label>24</label>
      <element-citation publication-type="journal" id="sbref0120">
        <person-group person-group-type="author">
          <name>
            <surname>Baik</surname>
            <given-names>J.W.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.Y.</given-names>
          </name>
          <name>
            <surname>Cho</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Choi</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Super wide-field photoacoustic microscopy of animals and humans in vivo</article-title>
        <source>IEEE Trans. Med. Imaging</source>
        <year>2019</year>
      </element-citation>
    </ref>
    <ref id="bib0125">
      <label>25</label>
      <element-citation publication-type="journal" id="sbref0125">
        <person-group person-group-type="author">
          <name>
            <surname>Golabbakhsh</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Rabbani</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <article-title>Vessel-based registration of fundus and optical coherence tomography projection images of retina using a quadratic registration model</article-title>
        <source>IET Image Process.</source>
        <volume>7</volume>
        <issue>8</issue>
        <year>2013</year>
        <fpage>768</fpage>
        <lpage>776</lpage>
      </element-citation>
    </ref>
    <ref id="bib0130">
      <label>26</label>
      <element-citation publication-type="journal" id="sbref0130">
        <person-group person-group-type="author">
          <name>
            <surname>Pravenaa</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Menaka</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <article-title>A methodical review on image stitching and video stitching techniques</article-title>
        <source>Int. J. Appl. Eng. Res. Dev.</source>
        <volume>11</volume>
        <issue>5</issue>
        <year>2016</year>
        <fpage>3442</fpage>
        <lpage>3448</lpage>
      </element-citation>
    </ref>
    <ref id="bib0135">
      <label>27</label>
      <element-citation publication-type="journal" id="sbref0135">
        <person-group person-group-type="author">
          <name>
            <surname>Mills</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Dudek</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Image stitching with dynamic elements</article-title>
        <source>Image Vis. Comput.</source>
        <volume>27</volume>
        <issue>10</issue>
        <year>2009</year>
        <fpage>1593</fpage>
        <lpage>1602</lpage>
      </element-citation>
    </ref>
    <ref id="bib0140">
      <label>28</label>
      <element-citation publication-type="book" id="sbref0140">
        <person-group person-group-type="author">
          <name>
            <surname>Szeliski</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <chapter-title>Computer Vision: Algorithms and Applications</chapter-title>
        <year>2010</year>
        <publisher-name>Springer Science &amp; Business Media</publisher-name>
      </element-citation>
    </ref>
    <ref id="bib0145">
      <label>29</label>
      <element-citation publication-type="journal" id="sbref0145">
        <person-group person-group-type="author">
          <name>
            <surname>Gledhill</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>G.Y.</given-names>
          </name>
          <name>
            <surname>Taylor</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Clarke</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Panoramic imaging—a review</article-title>
        <source>Comput. Graph.</source>
        <volume>27</volume>
        <issue>3</issue>
        <year>2003</year>
        <fpage>435</fpage>
        <lpage>445</lpage>
      </element-citation>
    </ref>
    <ref id="bib0150">
      <label>30</label>
      <element-citation publication-type="journal" id="sbref0150">
        <person-group person-group-type="author">
          <name>
            <surname>Jain</surname>
            <given-names>P.M.</given-names>
          </name>
          <name>
            <surname>Shandliya</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>A review paper on various approaches for image mosaicing</article-title>
        <source>Int. J. Computat. Eng. Res.</source>
        <volume>3</volume>
        <issue>4</issue>
        <year>2013</year>
        <fpage>106</fpage>
        <lpage>109</lpage>
      </element-citation>
    </ref>
    <ref id="bib0155">
      <label>31</label>
      <element-citation publication-type="journal" id="sbref0155">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Retinal image registration via feature-guided Gaussian mixture model</article-title>
        <source>J. Opt. Soc. Am. A Opt. Image Sci. Vis.</source>
        <volume>33</volume>
        <issue>7</issue>
        <year>2016</year>
        <fpage>1267</fpage>
        <lpage>1276</lpage>
        <pub-id pub-id-type="pmid">27409682</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0160">
      <label>32</label>
      <element-citation publication-type="journal" id="sbref0160">
        <person-group person-group-type="author">
          <name>
            <surname>Xie</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Duan</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Wen</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Correction of the image distortion for laser galvanometric scanning system</article-title>
        <source>Opt. Laser Technol.</source>
        <volume>37</volume>
        <issue>4</issue>
        <year>2005</year>
        <fpage>305</fpage>
        <lpage>311</lpage>
      </element-citation>
    </ref>
    <ref id="bib0165">
      <label>33</label>
      <element-citation publication-type="journal" id="sbref0165">
        <person-group person-group-type="author">
          <name>
            <surname>Zhuang</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Shamdasani</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Sikdar</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Managuli</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Real-time 3-d ultrasound scan conversion using a multicore processor</article-title>
        <source>IEEE Trans. Inf. Technol. Biomed.</source>
        <volume>13</volume>
        <issue>4</issue>
        <year>2009</year>
        <fpage>571</fpage>
        <lpage>574</lpage>
        <pub-id pub-id-type="pmid">19171520</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0170">
      <label>34</label>
      <element-citation publication-type="journal" id="sbref0170">
        <person-group person-group-type="author">
          <name>
            <surname>Duma</surname>
            <given-names>V.-F.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>K.-s.</given-names>
          </name>
          <name>
            <surname>Meemon</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Rolland</surname>
            <given-names>J.P.</given-names>
          </name>
        </person-group>
        <article-title>Experimental investigations of the scanning functions of galvanometer-based scanners with applications in OCT</article-title>
        <source>Appl. Opt.</source>
        <volume>50</volume>
        <issue>29</issue>
        <year>2011</year>
        <fpage>5735</fpage>
        <lpage>5749</lpage>
        <pub-id pub-id-type="pmid">22015369</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0175">
      <label>35</label>
      <element-citation publication-type="journal" id="sbref0175">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>J.Y.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Lim</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Fast optical-resolution photoacoustic microscopy using a 2-axis water-proofing MEMS scanner</article-title>
        <source>Sci. Rep.</source>
        <volume>5</volume>
        <year>2015</year>
        <fpage>7932</fpage>
        <pub-id pub-id-type="pmid">25604654</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0180">
      <label>36</label>
      <element-citation publication-type="journal" id="sbref0180">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.Y.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Recent progress on photoacoustic imaging enhanced with microelectromechanical systems (MEMS) technologies</article-title>
        <source>Micromachines (Basel)</source>
        <volume>9</volume>
        <issue>11</issue>
        <year>2018</year>
      </element-citation>
    </ref>
    <ref id="bib0185">
      <label>37</label>
      <element-citation publication-type="journal" id="sbref0185">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.Y.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Lim</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Two-axis polydimethylsiloxane-based electromagnetic microelectromechanical system scanning mirror for optical coherence tomography</article-title>
        <source>J. Biomed. Opt.</source>
        <volume>21</volume>
        <issue>10</issue>
        <year>2016</year>
        <object-id pub-id-type="publisher-id">106001</object-id>
      </element-citation>
    </ref>
    <ref id="bib0190">
      <label>38</label>
      <element-citation publication-type="journal" id="sbref0190">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>J.Y.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>High-speed and high-SNR photoacoustic microscopy based on a galvanometer mirror in non-conducting liquid</article-title>
        <source>Sci. Rep.</source>
        <volume>6</volume>
        <year>2016</year>
        <fpage>34803</fpage>
        <pub-id pub-id-type="pmid">27708379</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0195">
      <label>39</label>
      <element-citation publication-type="journal" id="sbref0195">
        <person-group person-group-type="author">
          <name>
            <surname>Park</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.Y.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Jeon</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lim</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Handheld photoacoustic microscopy probe</article-title>
        <source>Sci. Rep.</source>
        <volume>7</volume>
        <issue>1</issue>
        <year>2017</year>
        <fpage>13359</fpage>
        <pub-id pub-id-type="pmid">29042650</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0200">
      <label>40</label>
      <element-citation publication-type="journal" id="sbref0200">
        <person-group person-group-type="author">
          <name>
            <surname>Jeon</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Woo</surname>
            <given-names>B.J.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Review on practical photoacoustic microscopy</article-title>
        <source>Photoacoustics</source>
        <year>2019</year>
        <object-id pub-id-type="publisher-id">100141</object-id>
      </element-citation>
    </ref>
    <ref id="bib0205">
      <label>41</label>
      <element-citation publication-type="journal" id="sbref0205">
        <person-group person-group-type="author">
          <name>
            <surname>Yoo</surname>
            <given-names>H.W.</given-names>
          </name>
          <name>
            <surname>Ito</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Schitter</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>High speed laser scanning microscopy by iterative learning control of a galvanometer scanner</article-title>
        <source>Control Eng. Pract.</source>
        <volume>50</volume>
        <year>2016</year>
        <fpage>12</fpage>
        <lpage>21</lpage>
      </element-citation>
    </ref>
    <ref id="bib0210">
      <label>42</label>
      <element-citation publication-type="journal" id="sbref0210">
        <person-group person-group-type="author">
          <name>
            <surname>Arrasmith</surname>
            <given-names>C.L.</given-names>
          </name>
          <name>
            <surname>Dickensheets</surname>
            <given-names>D.L.</given-names>
          </name>
          <name>
            <surname>Mahadevan-Jansen</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>MEMS-based handheld confocal microscope for in-vivo skin imaging</article-title>
        <source>Opt. Express</source>
        <volume>18</volume>
        <issue>4</issue>
        <year>2010</year>
        <fpage>3805</fpage>
        <lpage>3819</lpage>
        <pub-id pub-id-type="pmid">20389391</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0215">
      <label>43</label>
      <element-citation publication-type="journal" id="sbref0215">
        <person-group person-group-type="author">
          <name>
            <surname>Jeon</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>H.B.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>B.J.</given-names>
          </name>
          <name>
            <surname>Managuli</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.H.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.H.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>In vivo photoacoustic imaging of anterior ocular vasculature: a random sample consensus approach</article-title>
        <source>Sci. Rep.</source>
        <volume>7</volume>
        <issue>1</issue>
        <year>2017</year>
        <fpage>4318</fpage>
        <pub-id pub-id-type="pmid">28659597</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0220">
      <label>44</label>
      <element-citation publication-type="journal" id="sbref0220">
        <person-group person-group-type="author">
          <name>
            <surname>Sekiguchi</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Yoshikawa</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Matsumoto</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Asao</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Yagi</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Togashi</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Toi</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Body surface detection method for photoacoustic image data using cloth-simulation technique, photons plus ultrasound: imaging and sensing 2018</article-title>
        <source>Int. Soc. Opt. Photonics</source>
        <year>2018</year>
        <fpage>1049459</fpage>
      </element-citation>
    </ref>
    <ref id="bib0225">
      <label>45</label>
      <element-citation publication-type="journal" id="sbref0225">
        <person-group person-group-type="author">
          <name>
            <surname>Matsumoto</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Asao</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Yoshikawa</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Sekiguchi</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Takada</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Furu</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Saito</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Kataoka</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Abe</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Yagi</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>Label-free photoacoustic imaging of human palmar vessels: a structural morphological analysis</article-title>
        <source>Sci. Rep.</source>
        <volume>8</volume>
        <issue>1</issue>
        <year>2018</year>
        <fpage>786</fpage>
        <pub-id pub-id-type="pmid">29335512</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0230">
      <label>46</label>
      <element-citation publication-type="journal" id="sbref0230">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>H.F.</given-names>
          </name>
          <name>
            <surname>Maslov</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L.V.</given-names>
          </name>
        </person-group>
        <article-title>Automatic algorithm for skin profile detection in photoacoustic microscopy</article-title>
        <source>J. Biomed. Opt.</source>
        <volume>14</volume>
        <issue>2</issue>
        <year>2009</year>
        <object-id pub-id-type="publisher-id">024050</object-id>
      </element-citation>
    </ref>
    <ref id="bib0235">
      <label>47</label>
      <element-citation publication-type="journal" id="sbref0235">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Eagleson</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Peters</surname>
            <given-names>T.M.</given-names>
          </name>
        </person-group>
        <article-title>Volume visualization: a technical overview with a focus on medical applications</article-title>
        <source>J. Digit. Imaging</source>
        <volume>24</volume>
        <issue>4</issue>
        <year>2011</year>
        <fpage>640</fpage>
        <lpage>664</lpage>
        <pub-id pub-id-type="pmid">20714917</pub-id>
      </element-citation>
    </ref>
    <ref id="bib0240">
      <label>48</label>
      <element-citation publication-type="book" id="sbref0240">
        <person-group person-group-type="author">
          <name>
            <surname>Lacroute</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Levoy</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <chapter-title>Fast volume rendering using a shear-warp factorization of the viewing transformation</chapter-title>
        <source>Proceedings of the 21st Annual Conference on Computer Graphics and Interactive Techniques</source>
        <conf-name>ACM</conf-name>
        <year>1994</year>
        <fpage>451</fpage>
        <lpage>458</lpage>
      </element-citation>
    </ref>
    <ref id="bib0245">
      <label>49</label>
      <element-citation publication-type="book" id="sbref0245">
        <person-group person-group-type="author">
          <name>
            <surname>Weiskopf</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <chapter-title>GPU-Based Interactive Visualization Techniques</chapter-title>
        <year>2007</year>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="bib0250">
      <label>50</label>
      <element-citation publication-type="journal" id="sbref0250">
        <person-group person-group-type="author">
          <name>
            <surname>Kniss</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Kindlmann</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Hansen</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Multidimensional transfer functions for interactive volume rendering</article-title>
        <source>IEEE Trans. Vis. Comput. Graph.</source>
        <volume>8</volume>
        <issue>3</issue>
        <year>2002</year>
        <fpage>270</fpage>
        <lpage>285</lpage>
      </element-citation>
    </ref>
    <ref id="bib0255">
      <label>51</label>
      <element-citation publication-type="book" id="sbref0255">
        <person-group person-group-type="author">
          <name>
            <surname>Porter</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Duff</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <chapter-title>Compositing digital images</chapter-title>
        <source>ACM Siggraph Computer Graphics</source>
        <conf-name>ACM</conf-name>
        <year>1984</year>
        <fpage>253</fpage>
        <lpage>259</lpage>
      </element-citation>
    </ref>
  </ref-list>
  <bio>
    <graphic xlink:href="fx1"/>
    <p><bold>Seonghee Cho</bold> completed his B.H.S in Dental Laboratory Science and Engineering and B.E in Biomedical Engineering at Korea University. He is now a Ph.D. candidate in the School of Interdisciplinary Bioscience and Bioengineering at POSTECH. His research interests include ultrasound and photoacoustic imaging and high performance computing.</p>
  </bio>
  <bio>
    <graphic xlink:href="fx2"/>
    <p><bold>Jin-woo Baik</bold> completed his B.S in Electrical Engineering at POSTECH, and now he is a Ph.D. candidate in the Creative IT Engineering Department at POSTECH. His research interests include photoacoustic microscopy and deep learning.</p>
  </bio>
  <bio>
    <graphic xlink:href="fx3"/>
    <p><bold>Ravi Managuli</bold> received the Ph.D. degree in electrical engineering from the University of Washington, Seattle, in 2000. He is a Research Scientist at Hitachi Heathcare America, Seattle, WA, and is also an Affiliate Faculty Member at the University of Washington, Seattle. His research interests are in systems, algorithms and application for medical imaging, digital signal processing, image processing, computer architecture, AI, and real-time multimedia applications.</p>
  </bio>
  <bio>
    <graphic xlink:href="fx4"/>
    <p><bold>Dr. Chulhong Kim</bold> studied for his Ph.D. degree and postdoctoral training at Washington University in St. Louis, St. Louis, Missouri. He currently holds Mueunjae Chaired Professorship and an Associate Professor of Creative IT Engineering at Pohang University of Science and Technology in Republic of Korea. He was the recipients of the 2017 IEEE EMBS Early Career Achievement Award, the 2017 Korean Academy of Science and Technology Young Scientist Award, the 2016 Nightingale Award from IFMBE, and the 2017 KOSOMBE Young Investigator Award “Contributions to multi-scale photoacoustic imaging from super-resolution atomic force photoactivated microscopy for research to systems for clinical applications.</p>
  </bio>
  <sec id="sec0155" sec-type="supplementary-material">
    <label>Appendix A</label>
    <title>Supplementary data</title>
    <p id="par0180">The following are Supplementary data to this article:<supplementary-material content-type="local-data" id="upi0005"><media xlink:href="mmc1.mp4"/></supplementary-material><supplementary-material content-type="local-data" id="upi0010"><media xlink:href="mmc2.mp4"/></supplementary-material><supplementary-material content-type="local-data" id="upi0015"><media xlink:href="mmc3.mp4"/></supplementary-material><supplementary-material content-type="local-data" id="upi0020"><media xlink:href="mmc4.mp4"/></supplementary-material><supplementary-material content-type="local-data" id="upi0025"><media xlink:href="mmc5.mp4"/></supplementary-material><supplementary-material content-type="local-data" id="upi0030"><media xlink:href="mmc6.mp4"/></supplementary-material><supplementary-material content-type="local-data" id="upi0035"><media xlink:href="mmc7.mp4"/></supplementary-material><supplementary-material content-type="local-data" id="upi0040"><media xlink:href="mmc8.mp4"/></supplementary-material></p>
  </sec>
  <ack id="ack0005">
    <title>Acknowledgments</title>
    <p>This work was supported by the <funding-source id="gs0005">National Research Foundation of Korea (NRF)</funding-source> grant funded by the <funding-source id="gs0010">Korea government (MSIT)</funding-source> (No. NRF-2019R1A2C2006269).</p>
  </ack>
  <fn-group>
    <fn id="sec0150" fn-type="supplementary-material">
      <label>Appendix A</label>
      <p id="par0175">Supplementary material related to this article can be found, in the online version, at doi:<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.pacs.2020.100168" id="intr0025">https://doi.org/10.1016/j.pacs.2020.100168</ext-link>.</p>
    </fn>
  </fn-group>
</back>
