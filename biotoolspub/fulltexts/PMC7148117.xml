<?all-math-mml yes?>
<?use-mml?>
<?properties open_access?>
<?properties manuscript?>
<?origin nihpa?>
<?iso-abbr Nat. Methods?>
<?submitter-system nihms?>
<?submitter-userid 8068858?>
<?submitter-authority myNCBI?>
<?submitter-login nature-structure?>
<?submitter-name Nature Publishing Group?>
<?domain nihpa?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-journal-id">101215604</journal-id>
    <journal-id journal-id-type="pubmed-jr-id">32338</journal-id>
    <journal-id journal-id-type="nlm-ta">Nat Methods</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nat. Methods</journal-id>
    <journal-title-group>
      <journal-title>Nature methods</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1548-7091</issn>
    <issn pub-type="epub">1548-7105</issn>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7148117</article-id>
    <article-id pub-id-type="pmid">30923381</article-id>
    <article-id pub-id-type="doi">10.1038/s41592-019-0360-8</article-id>
    <article-id pub-id-type="manuscript">nihpa1522285</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Selene: a PyTorch-based deep learning library for sequence data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Kathleen M.</given-names>
        </name>
        <xref ref-type="aff" rid="A1">1</xref>
        <xref rid="FN1" ref-type="author-notes">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cofer</surname>
          <given-names>Evan M.</given-names>
        </name>
        <xref ref-type="aff" rid="A2">2</xref>
        <xref ref-type="aff" rid="A3">3</xref>
        <xref rid="FN1" ref-type="author-notes">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhou</surname>
          <given-names>Jian</given-names>
        </name>
        <xref ref-type="aff" rid="A1">1</xref>
        <xref ref-type="aff" rid="A2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Troyanskaya</surname>
          <given-names>Olga G.</given-names>
        </name>
        <xref ref-type="aff" rid="A1">1</xref>
        <xref ref-type="aff" rid="A2">2</xref>
        <xref ref-type="aff" rid="A4">4</xref>
        <xref rid="CR1" ref-type="corresp">†</xref>
      </contrib>
    </contrib-group>
    <aff id="A1"><label>1</label>Flatiron Institute, Simons Foundation, New York City, New York, United States of America</aff>
    <aff id="A2"><label>2</label>Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, New Jersey, United States of America</aff>
    <aff id="A3"><label>3</label>Graduate Program in Quantitative and Computational Biology, Princeton University, Princeton, New Jersey, United States of America</aff>
    <aff id="A4"><label>4</label>Department of Computer Science, Princeton University, Princeton, New Jersey, United States of America</aff>
    <author-notes>
      <fn fn-type="equal" id="FN1">
        <label>*</label>
        <p id="P1">These authors contributed equally to this work.</p>
      </fn>
      <fn fn-type="con" id="FN2">
        <p id="P2">Contributions</p>
        <p id="P3">K.M.C and J.Z. conceived the Selene library, K.M.C. and E.M.C. designed, implemented, and documented Selene, K.M.C. performed the analyses described in the manuscript, K.M.C., E.M.C., and O.G.T wrote the manuscript.</p>
      </fn>
      <corresp id="CR1"><label>†</label> To whom correspondence should be addressed. <email>ogt@cs.princeton.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="nihms-submitted">
      <day>11</day>
      <month>3</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>28</day>
      <month>3</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <month>4</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>10</day>
      <month>4</month>
      <year>2020</year>
    </pub-date>
    <volume>16</volume>
    <issue>4</issue>
    <fpage>315</fpage>
    <lpage>318</lpage>
    <!--elocation-id from pubmed: 10.1038/s41592-019-0360-8-->
    <permissions>
      <license>
        <license-p>Users may view, print, copy, and download text and data-mine the content in such documents, for the purposes of academic research, subject always to the full Conditions of use:<uri xlink:href="http://www.nature.com/authors/editorial_policies/license.html#terms">http://www.nature.com/authors/editorial_policies/license.html#terms</uri></license-p>
      </license>
    </permissions>
    <abstract id="ABS1">
      <p id="P4">To enable the application of deep learning in biology, we present Selene (<ext-link ext-link-type="uri" xlink:href="https://selene.flatironinstitute.org/">https://selene.flatironinstitute.org/</ext-link>), a PyTorch-based deep learning library for fast and easy development, training, and application of deep learning model architectures for any biological sequences. We demonstrate how Selene allows researchers to easily train a published architecture on new data, develop and evaluate a new architecture, and use a trained model to answer biological questions of interest.</p>
    </abstract>
    <abstract abstract-type="summary" id="ABS2">
      <title>Reporting Summary</title>
      <p id="P5">Further information on research design is available in the Life Sciences Reporting Summary linked to this article.</p>
    </abstract>
  </article-meta>
</front>
<body>
  <p id="P6">Deep learning describes a set of machine learning techniques that use stacked neural networks to extract complicated patterns from high-dimensional data<sup><xref rid="R1" ref-type="bibr">1</xref></sup>. These techniques are widely used for image classification and natural language processing and have led to very promising advances in the biomedical domain, including genomics and chemical synthesis<sup><xref rid="R1" ref-type="bibr">1</xref>–<xref rid="R3" ref-type="bibr">3</xref></sup>. In regulatory genomics, networks trained on high-throughput sequencing data (e.g. ChIP-seq), or “sequence-based models,” have become the <italic>de facto</italic> standard for predicting regulatory and disease impact of mutations<sup><xref rid="R4" ref-type="bibr">4</xref>–<xref rid="R7" ref-type="bibr">7</xref></sup>. While deep-learning related publications are often accompanied by the associated pre-trained model<sup><xref rid="R6" ref-type="bibr">6</xref>,<xref rid="R8" ref-type="bibr">8</xref>,<xref rid="R9" ref-type="bibr">9</xref></sup>, a key challenge in both developing new deep learning architectures and training existing architectures on new data is the lack of a comprehensive, generalizable, and user-friendly deep learning library for biology.</p>
  <p id="P7">Beyond regulatory genomics, sequence-level deep learning models have broad promise in a wide range of research areas, including recent advances on prediction of disease risk of missense mutations in proteins<sup><xref rid="R10" ref-type="bibr">10</xref></sup> and potential applications to, for example, predicting target site accessibility in genome editing. We must enable the adoption and active development of deep learning-based methods in biomedical sciences. For example, a biomedical scientist excited by a publication of a model capable of predicting the disease-associated effect of mutations should be able to train a similar model on their own ChIP-seq data focused on their disease of interest. A bioinformatician interested in developing new model architectures should be able to experiment with different architectures and evaluate all of them on the same data. Currently, this requires advanced knowledge specific to deep learning<sup><xref rid="R2" ref-type="bibr">2</xref>,<xref rid="R11" ref-type="bibr">11</xref></sup>, substantial new code development, and associated time investment far beyond what most biomedical scientists are able to commit.</p>
  <p id="P8">Here we present Selene, a framework for developing <bold>se</bold>quence-level deep <bold>le</bold>arning <bold>ne</bold>tworks, that provides biomedical scientists with comprehensive support for model training, evaluation, and application across a broad range of biological questions. Sequence-level data refers to any type of biological sequence such as DNA, RNA, or protein sequences and their measured properties (e.g. TF binding, DNase sensitivity, RBP binding). Selene contains modules for (1) data sampling and training for model development (<xref rid="F1" ref-type="fig">Fig. 1a</xref>), and (2) prediction and visualization for analyses using the trained model (<xref rid="F1" ref-type="fig">Fig. 1b</xref>, <xref rid="F1" ref-type="fig">c</xref>). With Selene, researchers can run model development and analysis workflows out-of-the-box. For more advanced use cases, Selene provides templates for extending modules within each workflow so that users can adapt the library to their particular research questions.</p>
  <p id="P9">There has been recent work to make deep learning in biology more accessible: DragoNN is a toolkit for teaching deep learning in regulatory genomics; pysster<sup><xref rid="R12" ref-type="bibr">12</xref></sup> is a Python package for training convolutional neural networks on biological sequence data; and Kipoi<sup><xref rid="R13" ref-type="bibr">13</xref></sup> is a framework to archive, use, and build on published predictive models in genomics. These resources constitute the nascent software ecosystem for sequence-level deep learning. Selene is our contribution to this ecosystem. Selene supports general model development not constrained to a particular architecture (in contrast to pysster) or task (in contrast to DragoNN) and is designed for users with different levels of computational experience. Users are supported in tasks ranging from simply applying an existing model, to retraining it on new data (tasks also supported by Kipoi), to developing new model architectures (a task that is challenging to do with any other tool). The models developed using Selene can be shared and used through the Kipoi framework.</p>
  <p id="P10">To demonstrate Selene’s capabilities for developing and evaluating sequence-level deep learning models, we use it to (1) train a published architecture on new data, (2) develop, train, and evaluate a new model (improving a published model) and (3) apply a trained model to data and visualize the resulting predictions.</p>
  <sec disp-level="2" id="S2">
    <title>Case 1: Training an existing (e.g. published) architecture on a different dataset</title>
    <p id="P11">In this case study, a researcher reads a manuscript about a deep learning model and wants to train the model on different data. For illustration, we will use the DeepSEA model architecture as a starting point in our case studies; however, Selene is completely general and a user can easily use or specify any model of their choice using modules in PyTorch.</p>
    <p id="P12">Suppose a cancer researcher is interested in modeling the regulatory elements of the transcription factor GATA1, specifically focusing on proerythroblasts in bone marrow. This is a tissue-specific genomic feature that DeepSEA does not predict. The researcher downloads peaks data from Cistrome<sup><xref rid="R14" ref-type="bibr">14</xref></sup> and a reference genome FASTA file. Once a researcher formats the data to match the documented inputs (<ext-link ext-link-type="uri" xlink:href="https://selene.flatironinstitute.org/overview/cli.html">https://selene.flatironinstitute.org/overview/cli.html</ext-link>) and fills out the necessary training parameters (e.g. batch size, learning rate), they can use Selene to train the DeepSEA architecture on their data with no new lines of Python code. In this example, they find that the model obtains an AUC of 0.942 on this feature (<xref rid="F2" ref-type="fig">Fig. 2a</xref>).</p>
    <p id="P13">Selene automatically generates training, testing, and validation samples from the provided input data. The samples generated for each partition can be saved and used in subsequent model development so that comparisons can be made across models with different architectures and/or parameters. Further, Selene automatically evaluates the model on the test set after training and, in this case, generates figures to visualize the model’s performance as receiver operating characteristic and average precision curves.</p>
    <p id="P14">Now that the researcher has a trained model, they can use Selene to apply <italic>in silico</italic> mutagenesis to a set of GATA1 sequences from the test set. <italic>In silico</italic> mutagenesis involves “mutating” every position in the sequence to every other possible base<sup><xref rid="R4" ref-type="bibr">4</xref></sup> (DNA and RNA) or amino acid (protein sequences) and examining the consequences of these “mutations.” Selene supports visualizing the outputs of <italic>in silico</italic> mutagenesis as a heatmap and/or motif plot. By visualizing the log<sub>2</sub> fold change for these sequences in a heatmap, the researcher can see that the model detects disruptions in binding at the GATA motif (<xref rid="F2" ref-type="fig">Fig. 2b</xref>).</p>
    <p id="P15">We provide the code and results for this example in Selene’s GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/tree/master/manuscript/case1">https://github.com/FunctionLab/selene/tree/master/manuscript/case1</ext-link>). The case study demonstrates that Selene enables researchers to quickly get started with sequence-based deep learning; researchers can train and apply a model to their area of interest with minimal code and deep learning knowledge. Without Selene, a researcher would need to dedicate substantial time to preprocess their datasets and write code for training and evaluating their model.</p>
  </sec>
  <sec disp-level="2" id="S3">
    <title>Case 2: Developing a new architecture and comparing performance across architectures</title>
    <p id="P16">In another use case, a researcher may want to develop and train a new model architecture. For example, a bioinformatician might want to modify a published model architecture to see how that affects performance. First, the researcher uses modules in PyTorch to specify the model architecture they are interested in evaluating; in this case study, they try to enhance the DeepSEA architecture with batch normalization and three additional convolutional layers. The researcher specifies parameters for training and the paths to the model architecture and data in a configuration file and passes this as input to the library’s command-line interface. Training is automatically completed by Selene; afterwards, the researcher can easily use Selene to compare the performance of their new model to the original DeepSEA model on the same chromosomal holdout dataset.</p>
    <p id="P17">In this case study, the researcher finds that the deeper architecture achieves an average AUC of 0.938 (<xref rid="F3" ref-type="fig">Fig. 3a</xref>) and an average AUPRC of 0.362, which is an improvement over the average AUC of 0.933 and AUPRC of 0.342 of the original 3-convolutional-layer model. The researcher can share this model with a collaborator (e.g. a human geneticist, see <xref rid="S4" ref-type="sec">case study 3</xref> below) and upload it to the Kipoi<sup><xref rid="R13" ref-type="bibr">13</xref></sup> model zoo, a repository of trained models for regulatory genomics, with which Selene-trained models are fully compatible (see an example at <ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/tree/master/manuscript/case2/3_kipoi_export">https://github.com/FunctionLab/selene/tree/master/manuscript/case2/3_kipoi_export</ext-link>).</p>
    <p id="P18">Using Selene, researchers can substantially reduce the amount of work needed to develop, train, and compare new models. Researchers are able to focus on experimenting with various model architectures rather than writing all new code for model training and evaluation.</p>
  </sec>
  <sec disp-level="2" id="S4">
    <title>Case 3: Applying a new model to variants</title>
    <p id="P19">In this case study, a human geneticist studying Alzheimer’s wants to apply the model developed in <xref rid="S3" ref-type="sec">case study 2</xref> above, so they first assess its ability to prioritize potential disease-associated variants. Specifically, they use Selene to make variant effect predictions for nominally significant variants (p-value &lt; 0.05) and nonsignificant variants (p-value &gt; 0.50) reported in the International Genomics of Alzheimer’s Project<sup><xref rid="R15" ref-type="bibr">15</xref></sup> Alzheimer’s disease GWAS<sup><xref rid="R16" ref-type="bibr">16</xref></sup>. The researcher finds that the predicted effect is significantly higher for GWAS nominally significant variants versus non-significant variants, indicating that the new model is indeed able to prioritize potential disease-associated variants (one-sided Wilcoxon rank-sum test; the most significant feature, H3K36me3 in K562 cells, has an adjusted p-value, by Benjamini—Hochberg correction, of 3.89 ✕ 10<sup>−67</sup>) (<xref rid="F3" ref-type="fig">Fig. 3b</xref>).</p>
    <p id="P20">Selene’s modeling capability extends far beyond case studies shown above. The library can be applied to not only DNA, but also RNA and protein sequences; and not only chromatin data, but any current genome-, transcriptome-, or even proteome-wide measurements. We developed Selene to increase the accessibility of deep learning in biology and facilitate the creation of reproducible workflows and results. Furthermore, Selene is open-source software that will continue to be updated and expanded based on community and user feedback.</p>
  </sec>
  <sec id="S5">
    <title>Online methods</title>
    <sec id="S6">
      <title>Overview of Selene</title>
      <p id="P21">Selene consists of two components: a Python library for developing sequence-level neural networks, and a command line interface for prototypical use cases of the library (i.e. training a new model, evaluating an existing model, and analyzing sequence data and variants with a trained model). We herein refer to these components as the software development kit (SDK) and the command line interface (CLI) respectively. Importantly, all functionality provided by the CLI is also available to the user through the SDK. Rather than supplanting the SDK, the CLI is intended to maximize code reuse and minimize user time spent learning SDK by heavily reducing the configuration tasks left to the user (e.g. when GPU usage is specified, the CLI ensures all appropriate computations are performed on the GPU). When appropriate, the SDK does deliver functionality beyond that of the CLI. For instance, the SDK includes several data visualization methods that would be too unwieldy as executables run from the command line.</p>
      <p id="P22">Thorough documentation for the SDK is available at <ext-link ext-link-type="uri" xlink:href="https://selene.flatironinstitute.org/">https://selene.flatironinstitute.org</ext-link>, and tutorials for both the CLI and SDK can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/tree/master/tutorials">https://github.com/FunctionLab/selene/tree/master/tutorials</ext-link>. Notably, one tutorial demonstrates how to use Selene to train a deep neural network regression model (<ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/blob/master/tutorials/regression_mpra_example/regression_mpra_example.ipynb">https://github.com/FunctionLab/selene/blob/master/tutorials/regression_mpra_example/regression_mpra_example.ipynb</ext-link>). This tutorial illustrates Selene’s use outside of the models of transcriptional regulation shown in the case studies.</p>
    </sec>
    <sec id="S7">
      <title>Selene software development kit</title>
      <p id="P23">The Selene SDK, formally known as <italic>selene_sdk</italic>, is an extensible Python package intended to ease development of new programs that leverage sequence-level models through code reuse. The Selene CLI is built entirely upon the functionality provided by the SDK, but it is likely that users will use the SDK outside this context. For example, after training a new sequence-level model with the CLI, one could use the SDK in conjunction with a Python-based web application framework (e.g. Flask, Django) to build a web server so that other researchers can submit sequences or variants and get the trained model’s predictions as output.</p>
      <p id="P24">Leveraging the SDK in a user Python project is no different from using any other Python module. That is, one only needs to import the <italic>selene_sdk</italic> module or any of its members, and supply them with the correct parameters. The runtime behavior of each component of <italic>selene_sdk</italic>, as well as the required parameters for all members of <italic>selene_sdk</italic>, is described in detail in the online documentation (<ext-link ext-link-type="uri" xlink:href="https://selene.flatironinstitute.org/overview/overview.html">https://selene.flatironinstitute.org/overview/overview.html</ext-link>).</p>
    </sec>
    <sec id="S8">
      <title>Selene command line interface</title>
      <p id="P25">The Selene CLI is a usable program to be run from the command line by the user. It encapsulates the configuration, execution, and logging of Selene’s most common use cases. Said use cases are embodied by the CLI’s three commands: <italic>train</italic>, <italic>evaluate</italic>, and <italic>analyze</italic>. These commands are used to train new models, evaluate the performance of trained models, and analyze model predictions (perform <italic>in silico</italic> mutagenesis or variant effect prediction) respectively. Each command configures its specific runtime environment with a combination of command line arguments and parameters drawn from user-provided configuration files. The flexibility of these configuration files allows them to leverage user-developed code as well, and further extends the usability of the CLI. We provide a step-by-step tutorial that describes the CLI configuration file format and shows some example configuration keys and values at <ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/blob/master/tutorials/getting_started_with_selene/getting_started_with_selene.ipynb">https://github.com/FunctionLab/selene/blob/master/tutorials/getting_started_with_selene/getting_started_with_selene.ipynb</ext-link>. Additional examples of CLI configuration files are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/tree/master/config_examples">https://github.com/FunctionLab/selene/tree/master/config_examples</ext-link> as well. Finally, comprehensive documentation detailing all possible configurations supported by Selene can be found at <ext-link ext-link-type="uri" xlink:href="https://selene.flatironinstitute.org/overview/cli.html">https://selene.flatironinstitute.org/overview/cli.html</ext-link>. Users can reference any of these resources when creating their own configuration files.</p>
    </sec>
    <sec id="S9">
      <title>Model Architectures</title>
      <p id="P26">DeepSEA architecture used in case 1 (from the supplementary note in the DeepSEA publication<sup><xref rid="R4" ref-type="bibr">4</xref></sup>):</p>
      <list list-type="order" id="L1">
        <list-item>
          <p id="P27">Convolutional layer (320 kernels, window size = 8, step size = 1)</p>
        </list-item>
        <list-item>
          <p id="P28">Pooling layer (window size = 4, step size = 4)</p>
        </list-item>
        <list-item>
          <p id="P29">Convolutional layer (480 kernels, window size = 8, step size = 1)</p>
        </list-item>
        <list-item>
          <p id="P30">Pooling layer (window size = 4, step size = 4)</p>
        </list-item>
        <list-item>
          <p id="P31">Convolutional layer (960 kernels, window size = 8, step size = 1)</p>
        </list-item>
        <list-item>
          <p id="P32">Fully connected layer (919 genomic features)</p>
        </list-item>
        <list-item>
          <p id="P33">Sigmoid output layer</p>
        </list-item>
      </list>
      <p id="P34">Dropout proportion (proportion of outputs randomly set to 0):</p>
      <p id="P35">Layer 2: 20%</p>
      <p id="P36">Layer 4: 20%</p>
      <p id="P37">Layer 5: 50%</p>
      <p id="P38">All other layers: 0%</p>
      <p id="P39">Architecture used in cases 2 and 3:</p>
      <list list-type="order" id="L2">
        <list-item>
          <p id="P40">Convolutional layer (320 kernels, window size = 8, step size = 1)</p>
        </list-item>
        <list-item>
          <p id="P41">Convolutional layer (320 kernels, window size = 8, step size = 1)</p>
        </list-item>
        <list-item>
          <p id="P42">Pooling layer (window size = 4, step size = 4)</p>
        </list-item>
        <list-item>
          <p id="P43">Convolutional layer (480 kernels, window size = 8, step size = 1)</p>
        </list-item>
        <list-item>
          <p id="P44">Convolutional layer (480 kernels, window size = 8, step size = 1)</p>
        </list-item>
        <list-item>
          <p id="P45">Pooling layer (window size = 4, step size = 4)</p>
        </list-item>
        <list-item>
          <p id="P46">Convolutional layer (960 kernels, window size = 8, step size = 1)</p>
        </list-item>
        <list-item>
          <p id="P47">Convolutional layer (960 kernels, window size = 8, step size = 1)</p>
        </list-item>
        <list-item>
          <p id="P48">Fully connected layer (919 genomic features)</p>
        </list-item>
        <list-item>
          <p id="P49">Sigmoid output layer</p>
        </list-item>
      </list>
      <p id="P50">Dropout proportion:</p>
      <p id="P51">Layer 5: 20%</p>
      <p id="P52">Layer 8: 50%</p>
      <p id="P53">Batch normalization applied after layers 2, 5, and 8 and before dropout.</p>
      <p id="P54">Both architectures use the binary cross-entropy loss function and stochastic gradient descent optimizer (momentum = 0.9, weight decay = 10<sup>−6</sup>).</p>
    </sec>
    <sec id="S10">
      <title>Reproducing the case studies</title>
      <p id="P55">Below, we have described the steps taken for each of the case studies. The code required to reproduce each case study is included in the GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/tree/master/manuscript">https://github.com/FunctionLab/selene/tree/master/manuscript</ext-link>). We have also created Zenodo records for each case that contain all the input data, data processing scripts, and outputs files generated from Selene:</p>
      <list list-type="bullet" id="L3">
        <list-item>
          <p id="P56">Case 1. doi: <ext-link ext-link-type="uri" xlink:href="http://10.5281/zenodo.1442433">10.5281/zenodo.1442433</ext-link></p>
        </list-item>
        <list-item>
          <p id="P57">Case 2. doi: <ext-link ext-link-type="uri" xlink:href="http://10.5281/zenodo.1442437">10.5281/zenodo.1442437</ext-link></p>
        </list-item>
        <list-item>
          <p id="P58">Case 3. doi: <ext-link ext-link-type="uri" xlink:href="http://10.5281/zenodo.1445555">10.5281/zenodo.1445555</ext-link></p>
        </list-item>
      </list>
    </sec>
    <sec id="S11">
      <title>Case 1: Training a state-of-the-art architecture on a different dataset</title>
      <sec id="S12">
        <title>Steps to train DeepSEA on new data.</title>
        <list list-type="order" id="L4">
          <list-item>
            <p id="P59">Download the data from Cistrome. In this case, we are only working with 1 dataset for 1 specific genomic feature. Cistrome ID: 33545, measurements from GSM970258 (Xu et al., 2012):</p>
            <p id="P60">
              <ext-link ext-link-type="uri" xlink:href="http://dc2.cistrome.org/api/downloads/eyJpZCI6IjMzNTQ1In0%3A1fujCu%3ArNvWLCNoET6o9SdkL8fEv13uRu4b/">http://dc2.cistrome.org/api/downloads/eyJpZCI6IjMzNTQ1In0%3A1fujCu%3ArNvWLCNoET6o9SdkL8fEv13uRu4b/</ext-link>
            </p>
          </list-item>
          <list-item>
            <p id="P61">Format the data. We use tools from Samtools<sup><xref rid="R17" ref-type="bibr">17</xref></sup> (specifically, tabix<sup><xref rid="R18" ref-type="bibr">18</xref></sup> and bgzip from HTSlib, <ext-link ext-link-type="uri" xlink:href="https://www.htslib.org/">https://www.htslib.org/</ext-link>). Create a .bed file of chromosome, start, end, and the genomic feature name (useful when there is more than 1 feature). Sort this file and compress it into a .gz file. Tabix-index this file. Specific commands:
<list list-type="alpha-lower" id="L6"><list-item><p id="P62">Only use the columns [chr, start, end]:</p><p id="P63">cut -f 1–3 <bold>&lt;peaks-file&gt;</bold> &gt; <bold>&lt;peak-coordinates-file&gt;</bold></p><p id="P64">Note: Eventually, we will add support for parsing BED files with strand specific features and/or continuous values that quantify these features.</p></list-item><list-item><p id="P65">Add the genomic feature name as the 4th column of the file:</p><p id="P66">sed -i “s/$/\t<bold>&lt;feature-name&gt;</bold>/” <bold>&lt;peak-coordinates-file&gt;</bold></p></list-item><list-item><p id="P67">Sort the file by [chr, start, end]:</p><p id="P68">sort -k1V -k2n -k3n <bold>&lt;peak-coordinates-file&gt;</bold> &gt; <bold>&lt;sorted-coordinates-file&gt;</bold></p></list-item><list-item><p id="P69">Compress the file:</p><p id="P70">bgzip <bold>&lt;sorted-coordinates-file&gt;</bold>This compresses the file to a .gz file in-place. To separately generate the .gz file, run</p><p id="P71">bgzip -c <bold>&lt;sorted-coordinates-file&gt; &gt; &lt;sorted-coordinates-file&gt;</bold>.gz</p></list-item><list-item><p id="P72">Tabix index the file:</p><p id="P73">tabix -p bed <bold>&lt;sorted-coordinates-file&gt;</bold>.gz</p></list-item></list></p>
          </list-item>
          <list-item>
            <p id="P74">Create a file of distinct features that the model will predict, where each feature is a single line in the file. This can easily be created from the .bed file in step 2 by running:</p>
            <p id="P75">cut -f 4 <bold>&lt;peak-coordinates-file&gt;</bold> | sort -u &gt; <bold>&lt;distinct-features&gt;</bold></p>
          </list-item>
          <list-item>
            <p id="P76">Download the GRCh38/hg38 FASTA file. We downloaded the reference sequences GRCh37/hg19 and GRCh38/hg38 used in our analyses from ENCODE: <ext-link ext-link-type="uri" xlink:href="https://www.encodeproject.org/data-standards/reference-sequences/">https://www.encodeproject.org/data-standards/reference-sequences/</ext-link>.</p>
          </list-item>
          <list-item>
            <p id="P77">Specify the model architecture, loss, and optimizer as a Python file. <bold>This is done for you in the case of DeepSEA:</bold>
<ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/blob/master/models/deepsea.py">https://github.com/FunctionLab/selene/blob/master/models/deepsea.py</ext-link></p>
          </list-item>
          <list-item>
            <p id="P79">Fill out the configuration file with the appropriate file paths and training parameters. We recommend starting from one of the example training files in the tutorials (e.g. <ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/blob/master/tutorials/getting_started_with_selene/getting_started_with_selene.ipynb">https://github.com/FunctionLab/selene/blob/master/tutorials/getting_started_with_selene/getting_started_with_selene.ipynb</ext-link>) or in the “config_examples” directory (<ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/tree/master/config_examples">https://github.com/FunctionLab/selene/tree/master/config_examples</ext-link>). You can also review the documentation for the configuration parameters on Selene’s website (<ext-link ext-link-type="uri" xlink:href="https://selene.flatironinstitute.org/overview/cli.html">https://selene.flatironinstitute.org/overview/cli.html</ext-link>).</p>
          </list-item>
          <list-item>
            <p id="P80">Run Selene.</p>
          </list-item>
        </list>
      </sec>
      <sec id="S13">
        <title>Steps to apply and visualize the results of <italic>in silico</italic> mutagenesis.</title>
        <list list-type="order" id="L7">
          <list-item>
            <p id="P81">Collect sequences you want to visualize as a FASTA file. <bold>For this particular case, we provide a script to do so</bold> (<ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/2214130/files/data.tar.gz">https://zenodo.org/record/2214130/files/data.tar.gz</ext-link>).</p>
          </list-item>
          <list-item>
            <p id="P82">Fill out the configuration file with the appropriate file paths (path to the FASTA file, information about the trained model).</p>
          </list-item>
          <list-item>
            <p id="P83">Run Selene. You will get the raw predictions and the log<sub>2</sub> fold change scores as output files.</p>
          </list-item>
          <list-item>
            <p id="P84">Follow one of the Jupyter notebook tutorials for <italic>in silico</italic> mutagenesis (<ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/tree/master/tutorials">https://github.com/FunctionLab/selene/tree/master/tutorials</ext-link>) to generate visualizations for the sequences. <bold>We have done this in</bold>
<ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/blob/master/manuscript/case1/3_visualize_ism_outputs.ipynb">https://github.com/FunctionLab/selene/blob/master/manuscript/case1/3_visualize_ism_outputs.ipynb</ext-link>.</p>
          </list-item>
        </list>
      </sec>
    </sec>
    <sec id="S14">
      <title>Case 2: Developing a new architecture and making model comparisons</title>
      <sec id="S15">
        <title>Steps to train “deeper DeepSEA” on the same exact data as DeepSEA.</title>
        <list list-type="order" id="L8">
          <list-item>
            <p id="P85">Download the code and data bundle from the DeepSEA website (<ext-link ext-link-type="uri" xlink:href="http://deepsea.princeton.edu/media/code/deepsea_train_bundle.v0.9.tar.gz">http://deepsea.princeton.edu/media/code/deepsea_train_bundle.v0.9.tar.gz</ext-link>). You only need the .mat files in this directory. We also include a file listing the 919 genomic features that the model predicts. This is from the resources directory in the standalone version of DeepSEA (<ext-link ext-link-type="uri" xlink:href="http://deepsea.princeton.edu/media/code/deepsea.v0.94b.tar.gz">http://deepsea.princeton.edu/media/code/deepsea.v0.94b.tar.gz</ext-link>). <bold>Zenodo record:</bold>
<ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/2214970/files/DeepSEA_data.tar.gz">https://zenodo.org/record/2214970/files/DeepSEA_data.tar.gz</ext-link>.</p>
          </list-item>
          <list-item>
            <p id="P86">Fill out the configuration file for Selene’s MultiFileSampler (<ext-link ext-link-type="uri" xlink:href="https://selene.flatironinstitute.org/overview/cli.html#multiple-file-sampler">https://selene.flatironinstitute.org/overview/cli.html#multiple-file-sampler</ext-link>) and specify the path to each .mat file for training, validation, and testing.</p>
          </list-item>
          <list-item>
            <p id="P87">Run Selene.</p>
          </list-item>
        </list>
        <p id="P88">Please see the DeepSEA publication for details about data processing and training: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/nmeth.3547#methods">https://www.nature.com/articles/nmeth.3547#methods</ext-link>.</p>
        <p id="P89">In the main text, we report test performance for the model trained using the online sampler. When training on the same exact data (the .mat files) as DeepSEA, we achieve an average AUC of 0.934 and an average AUPRC of 0.361.</p>
      </sec>
      <sec id="S16">
        <title>Steps to download and format all the peaks data from ENCODE and Roadmap Epigenomics.</title>
        <list list-type="order" id="L9">
          <list-item>
            <p id="P90">Download all chromatin feature profiles used for training DeepSEA, specified in Supplementary Table 1 of the DeepSEA manuscript (<ext-link ext-link-type="uri" xlink:href="https://media.nature.com/original/nature-assets/nmeth/journal/v12/n10/extref/nmeth.3547-S2.xlsx">https://media.nature.com/original/nature-assets/nmeth/journal/v12/n10/extref/nmeth.3547-S2.xlsx</ext-link>). <bold>We have done this for you</bold> (<ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/2214970/files/chromatin_profiles.tar.gz">https://zenodo.org/record/2214970/files/chromatin_profiles.tar.gz</ext-link>).</p>
          </list-item>
          <list-item>
            <p id="P91">For each file, keep the chromosome, start, and end columns. In addition, create a fourth column with the feature’s name. Concatenate all these files and create the distinct features file. <bold>We provide a Python script for this step</bold> (<ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/blob/master/manuscript/case2/1_train_with_online_sampler/data/process_chromatin_profiles.py">https://github.com/FunctionLab/selene/blob/master/manuscript/case2/1_train_with_online_sampler/data/process_chromatin_profiles.py</ext-link>).</p>
          </list-item>
          <list-item>
            <p id="P92">Format the data according to the instructions in the “Getting started” tutorial:
<list list-type="alpha-lower" id="L10"><list-item><p id="P93">Sort the file by [chr, start, end]:</p><p id="P94">sort -k1V -k2n -k3n <bold>&lt;peak-coordinates-file&gt;</bold> &gt; <bold>&lt;sorted-coordinates-file&gt;</bold></p></list-item><list-item><p id="P95">Compress the file:</p><p id="P96">bgzip <bold>&lt;sorted-coordinates-file&gt;</bold>This compresses the file to a .gz file in-place. To separately generate the .gz file, run bgzip -c <bold>&lt;sorted-coordinates-file&gt; &gt; &lt;sorted-coordinates-file&gt;</bold>.gz</p></list-item><list-item><p id="P97">Tabix index the file:</p><p id="P98">tabix -p bed <bold>&lt;sorted-coordinates-file&gt;</bold>.gz</p></list-item></list></p>
            <p id="P99">
              <ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/blob/master/manuscript/case2/1_train_with_online_sampler/data/process_data.sh">https://github.com/FunctionLab/selene/blob/master/manuscript/case2/1_train_with_online_sampler/data/process_data.sh</ext-link>
            </p>
          </list-item>
          <list-item>
            <p id="P100">Download the hg19 FASTA file (<ext-link ext-link-type="uri" xlink:href="https://www.encodeproject.org/files/male.hg19/@@download/male.hg19.fasta.gz">https://www.encodeproject.org/files/male.hg19/@@download/male.hg19.fasta.gz</ext-link>).</p>
          </list-item>
          <list-item>
            <p id="P101">Specify the model architecture, loss, and optimizer as a Python file: <ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/blob/master/selene_sdk/utils/example_model.py">https://github.com/FunctionLab/selene/blob/master/selene_sdk/utils/example_model.py</ext-link></p>
          </list-item>
          <list-item>
            <p id="P103">Fill out the configuration file with the appropriate file paths and training parameters. We set the training parameters (number of steps, batches, etc.) so that they matched how DeepSEA was originally trained.</p>
          </list-item>
          <list-item>
            <p id="P104">Run Selene.</p>
          </list-item>
        </list>
      </sec>
    </sec>
    <sec id="S17">
      <title>Case 3: Applying a new model to variants</title>
      <list list-type="order" id="L12">
        <list-item>
          <p id="P105">Download the SNPs from the International Genomics of Alzheimer’s Project. (<ext-link ext-link-type="uri" xlink:href="https://www.niagads.org/igap-age-onset-survival-analyses-p-value-only">https://www.niagads.org/igap-age-onset-survival-analyses-p-value-only</ext-link>)</p>
        </list-item>
        <list-item>
          <p id="P106">Group the variants into those with p-values below 0.05 (significant) and those with p-values above 0.50 (nonsignificant).</p>
        </list-item>
        <list-item>
          <p id="P107">Fill out the configuration file with the paths to the two variants files and the trained model weights file from Case 2.</p>
        </list-item>
        <list-item>
          <p id="P108">Run Selene.</p>
        </list-item>
        <list-item>
          <p id="P109">Follow the script provided for this case to analyze the variant predictions (<ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/blob/master/manuscript/case3/2_variant_groups_comparison.sh">https://github.com/FunctionLab/selene/blob/master/manuscript/case3/2_variant_groups_comparison.sh</ext-link>).</p>
        </list-item>
      </list>
      <sec id="S18">
        <title>Statistical analysis</title>
        <p id="P110">Details of the statistical test used for <xref rid="S4" ref-type="sec">case study 3</xref> are specified in the associated text and figure legend (<xref rid="F3" ref-type="fig">Fig. 3b</xref>).</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="supplementary-material" id="SM1">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="SD1">
      <label>1</label>
      <media xlink:href="NIHMS1522285-supplement-1.pdf" orientation="portrait" id="d36e827" position="anchor"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="S19">
    <title>Acknowledgements</title>
    <p id="P111">The authors acknowledge all members of the Troyanskaya lab for helpful discussions. In addition, the authors thank D. Simon for setting up the website and automating updates to the site. The authors are pleased to acknowledge that this work was performed using the high-performance computing resources at Simons Foundation and the TIGRESS computer center at Princeton University. This work was supported by NIH grants R01HG005998, U54HL117798, R01GM071966, and T32HG003284, HHS grant HHSN272201000054C, and Simons Foundation grant 395506. O.G.T. is a CIFAR fellow.</p>
  </ack>
  <fn-group>
    <fn fn-type="COI-statement" id="FN3">
      <p id="P112">Competing Interests</p>
      <p id="P113">The authors declare that no competing interests, financial or otherwise, exist.</p>
    </fn>
    <fn id="FN4">
      <p id="P114">Code Availability</p>
      <p id="P115">Selene is open-source software (license BSD 3-Clause Clear).</p>
      <p id="P116">Project homepage: <ext-link ext-link-type="uri" xlink:href="https://selene.flatironinstitute.org/">https://selene.flatironinstitute.org</ext-link></p>
      <p id="P117">GitHub: <ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene">https://github.com/FunctionLab/selene</ext-link></p>
      <p id="P118">Archived version: <ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/archive/0.2.0.tar.gz">https://github.com/FunctionLab/selene/archive/0.2.0.tar.gz</ext-link></p>
    </fn>
    <fn id="FN5">
      <p id="P119">Data Availability</p>
      <p id="P120">
        <underline>Cistrome</underline>
        <sup>
          <xref rid="R14" ref-type="bibr">14</xref>
        </sup>
      </p>
      <p id="P121">Cistrome file ID: 33545, measurements from GSM970258 (Xu et al., 2012)</p>
      <p id="P122">
        <ext-link ext-link-type="uri" xlink:href="http://dc2.cistrome.org/api/downloads/eyJpZCI6IjMzNTQ1In0%3A1fujCu%3ArNvWLCNoET6o9SdkL8fEv13uRu4b/">http://dc2.cistrome.org/api/downloads/eyJpZCI6IjMzNTQ1In0%3A1fujCu%3ArNvWLCNoET6o9SdkL8fEv13uRu4b/</ext-link>
      </p>
      <p id="P123">
        <underline>ENCODE</underline>
        <sup>
          <xref rid="R19" ref-type="bibr">19</xref>
        </sup>
        <underline>and Roadmap Epigenomics</underline>
        <sup>
          <xref rid="R20" ref-type="bibr">20</xref>
        </sup>
        <underline>chromatin profiles</underline>
      </p>
      <p id="P124">Files listed in <ext-link ext-link-type="uri" xlink:href="https://media.nature.com/original/nature-assets/nmeth/journal/v12/n10/extref/nmeth.3547-S2.xlsx">https://media.nature.com/original/nature-assets/nmeth/journal/v12/n10/extref/nmeth.3547-S2.xlsx</ext-link></p>
      <p id="P125">
        <underline>IGAP age at onset survival</underline>
        <sup><xref rid="R15" ref-type="bibr">15</xref>,<xref rid="R16" ref-type="bibr">16</xref></sup>
      </p>
      <p id="P126"><ext-link ext-link-type="uri" xlink:href="https://www.niagads.org/datasets/ng00058">https://www.niagads.org/datasets/ng00058</ext-link> (p-values only file)</p>
      <p id="P127">The case studies used processed datasets from these sources. They can be downloaded at the following Zenodo links:</p>
      <p id="P128">Cistrome:</p>
      <p id="P129">
        <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/2214130/files/data.tar.gz">https://zenodo.org/record/2214130/files/data.tar.gz</ext-link>
      </p>
      <p id="P130">ENCODE and Roadmap Epigenomics chromatin profiles:</p>
      <p id="P131">
        <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/2214970/files/chromatin_profiles.tar.gz">https://zenodo.org/record/2214970/files/chromatin_profiles.tar.gz</ext-link>
      </p>
      <p id="P132">IGAP age at onset survival:</p>
      <p id="P133">
        <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/1445556/files/variant_effect_prediction_data.tar.gz">https://zenodo.org/record/1445556/files/variant_effect_prediction_data.tar.gz</ext-link>
      </p>
    </fn>
  </fn-group>
  <ref-list>
    <title>References</title>
    <ref id="R1">
      <label>1.</label>
      <mixed-citation publication-type="journal"><name><surname>LeCun</surname><given-names>Y</given-names></name>, <name><surname>Bengio</surname><given-names>Y</given-names></name> &amp; <name><surname>Hinton</surname><given-names>G</given-names></name>
<article-title>Deep learning</article-title>. <source>Nature</source>
<volume>521</volume>, <fpage>436</fpage>–<lpage>444</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">26017442</pub-id></mixed-citation>
    </ref>
    <ref id="R2">
      <label>2.</label>
      <mixed-citation publication-type="journal"><name><surname>Ching</surname><given-names>T</given-names></name>, <etal/><article-title>Opportunities and obstacles for deep learning in biology and medicine</article-title>. <source>J. R. Soc. Interface</source><volume>15</volume>, <fpage>20170387</fpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29618526</pub-id></mixed-citation>
    </ref>
    <ref id="R3">
      <label>3.</label>
      <mixed-citation publication-type="journal"><name><surname>Segler</surname><given-names>MHS</given-names></name>, <name><surname>Preuss</surname><given-names>M</given-names></name> &amp; <name><surname>Waller</surname><given-names>MP</given-names></name>
<article-title>Planning chemical syntheses with deep neural networks and symbolic AI</article-title>. <source>Nature</source>
<volume>555</volume>, <fpage>604</fpage>–<lpage>610</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">29595767</pub-id></mixed-citation>
    </ref>
    <ref id="R4">
      <label>4.</label>
      <mixed-citation publication-type="journal"><name><surname>Zhou</surname><given-names>J</given-names></name> &amp; <name><surname>Troyanskaya</surname><given-names>OG</given-names></name>
<article-title>Predicting effects of noncoding variants with deep learning-based sequence model</article-title>. <source>Nat. Methods</source>
<volume>12</volume>, <fpage>931</fpage>–<lpage>934</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">26301843</pub-id></mixed-citation>
    </ref>
    <ref id="R5">
      <label>5.</label>
      <mixed-citation publication-type="journal"><name><surname>Alipanahi</surname><given-names>B</given-names></name>, <name><surname>Delong</surname><given-names>A</given-names></name>, <name><surname>Weirauch</surname><given-names>MT</given-names></name> &amp; <name><surname>Frey</surname><given-names>BJ</given-names></name>
<article-title>Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning</article-title>. <source>Nat. Biotechnol</source>
<volume>33</volume>, <fpage>831</fpage>–<lpage>838</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">26213851</pub-id></mixed-citation>
    </ref>
    <ref id="R6">
      <label>6.</label>
      <mixed-citation publication-type="journal"><name><surname>Kelley</surname><given-names>DR</given-names></name>, <name><surname>Snoek</surname><given-names>J</given-names></name> &amp; <name><surname>Rinn</surname><given-names>J</given-names></name>
<article-title>Basset: Learning the regulatory code of the accessible genome with deep convolutional neural networks</article-title>. <source>Genome Res</source>. (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.1101/gr.200535.115</pub-id></mixed-citation>
    </ref>
    <ref id="R7">
      <label>7.</label>
      <mixed-citation publication-type="journal"><name><surname>Angermueller</surname><given-names>C</given-names></name>, <name><surname>Lee</surname><given-names>HJ</given-names></name>, <name><surname>Reik</surname><given-names>W</given-names></name> &amp; <name><surname>Stegle</surname><given-names>O</given-names></name>
<article-title>DeepCpG: accurate prediction of single-cell DNA methylation states using deep learning</article-title>. <source>Genome Biol</source>. <volume>18</volume>, <fpage>67</fpage> (<year>2017</year>).<pub-id pub-id-type="pmid">28395661</pub-id></mixed-citation>
    </ref>
    <ref id="R8">
      <label>8.</label>
      <mixed-citation publication-type="journal"><name><surname>Kelley</surname><given-names>DR</given-names></name>, <name><surname>Reshef</surname><given-names>Y</given-names></name>, <name><surname>Bileschi</surname><given-names>M</given-names></name>, <name><surname>Belanger</surname><given-names>D</given-names></name>, <name><surname>McLean</surname><given-names>CY</given-names></name> &amp; <name><surname>Snoek</surname><given-names>J</given-names></name>
<article-title>Sequential regulatory activity prediction across chromosomes with convolutional neural networks</article-title>. <source>Genome Res</source>. (<year>2018</year>). doi:<pub-id pub-id-type="doi">10.1101/gr.227819.117</pub-id></mixed-citation>
    </ref>
    <ref id="R9">
      <label>9.</label>
      <mixed-citation publication-type="journal"><name><surname>Quang</surname><given-names>D</given-names></name> &amp; <name><surname>Xie</surname><given-names>X</given-names></name>
<article-title>DanQ: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences</article-title>. <source>Nucleic Acids Res</source>. <volume>44</volume>, <fpage>e107</fpage> (<year>2016</year>).<pub-id pub-id-type="pmid">27084946</pub-id></mixed-citation>
    </ref>
    <ref id="R10">
      <label>10.</label>
      <mixed-citation publication-type="journal"><name><surname>Sundaram</surname><given-names>L</given-names></name>, <etal/><article-title>Predicting the clinical impact of human mutation with deep neural networks</article-title>. <source>Nat. Genet</source><volume>50</volume>, <fpage>1161</fpage>–<lpage>1170</lpage> (<year>2018</year>).<pub-id pub-id-type="pmid">30038395</pub-id></mixed-citation>
    </ref>
    <ref id="R11">
      <label>11.</label>
      <mixed-citation publication-type="journal"><name><surname>Min</surname><given-names>S</given-names></name>, <name><surname>Lee</surname><given-names>B</given-names></name> &amp; <name><surname>Yoon</surname><given-names>S</given-names></name>
<article-title>Deep learning in bioinformatics</article-title>. <source>Brief. Bioinform</source>
<volume>18</volume>, <fpage>851</fpage>–<lpage>869</lpage> (<year>2017</year>).<pub-id pub-id-type="pmid">27473064</pub-id></mixed-citation>
    </ref>
    <ref id="R12">
      <label>12.</label>
      <mixed-citation publication-type="journal"><name><surname>Budach</surname><given-names>S</given-names></name> &amp; <name><surname>Marsico</surname><given-names>A</given-names></name>
<article-title>pysster: Classification Of Biological Sequences By Learning Sequence And Structure Motifs With Convolutional Neural Networks</article-title>. <source>Bioinformatics</source> (<year>2018</year>). doi:<pub-id pub-id-type="doi">10.1093/bioinformatics/bty222</pub-id></mixed-citation>
    </ref>
    <ref id="R13">
      <label>13.</label>
      <mixed-citation publication-type="web"><name><surname>Avsec</surname><given-names>Z</given-names></name>, <etal/><source>Kipoi: accelerating the community exchange and reuse of predictive models for genomics</source>. Preprint at <pub-id pub-id-type="doi">10.1101/375345</pub-id> (<year>2018</year>).</mixed-citation>
    </ref>
    <ref id="R14">
      <label>14.</label>
      <mixed-citation publication-type="journal"><name><surname>Mei</surname><given-names>S</given-names></name>, <etal/><article-title>Cistrome Data Browser: a data portal for ChIP-Seq and chromatin accessibility data in human and mouse</article-title>. <source>Nucleic Acids Res</source>. <volume>45</volume>, <fpage>D658</fpage>–<lpage>D662</lpage> (<year>2017</year>).<pub-id pub-id-type="pmid">27789702</pub-id></mixed-citation>
    </ref>
    <ref id="R15">
      <label>15.</label>
      <mixed-citation publication-type="journal"><name><surname>Ruiz</surname><given-names>A</given-names></name>, <etal/><article-title>Follow-up of loci from the International Genomics of Alzheimer’s Disease Project identifies TRIP4 as a novel susceptibility gene</article-title>. <source>Transl. Psychiatry</source><volume>4</volume>, <fpage>e358</fpage> (<year>2014</year>).<pub-id pub-id-type="pmid">24495969</pub-id></mixed-citation>
    </ref>
    <ref id="R16">
      <label>16.</label>
      <mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>K-L</given-names></name>, <etal/><article-title>A common haplotype lowers PU.1 expression in myeloid cells and delays onset of Alzheimer’s disease</article-title>. <source>Nat. Neurosci</source><volume>20</volume>, <fpage>1052</fpage>–<lpage>1061</lpage> (<year>2017</year>).<pub-id pub-id-type="pmid">28628103</pub-id></mixed-citation>
    </ref>
  </ref-list>
  <ref-list>
    <title>References</title>
    <ref id="R17">
      <label>17.</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>H</given-names></name>, <name><surname>Handsaker</surname><given-names>B</given-names></name>, <name><surname>Wysoker</surname><given-names>A</given-names></name>, <name><surname>Fennell</surname><given-names>T</given-names></name>, <name><surname>Ruan</surname><given-names>J</given-names></name>, <name><surname>Homer</surname><given-names>N</given-names></name>, <name><surname>Marth</surname><given-names>G</given-names></name>, <name><surname>Abecasis</surname><given-names>G</given-names></name>, <name><surname>Durbin</surname><given-names>R</given-names></name> &amp; <article-title>1000 Genome Project Data Processing Subgroup. The Sequence Alignment/Map format and SAMtools</article-title>. <source>Bioinformatics</source>
<volume>25</volume>, <fpage>2078</fpage>–<lpage>2079</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19505943</pub-id></mixed-citation>
    </ref>
    <ref id="R18">
      <label>18.</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>H</given-names></name><article-title>Tabix: fast retrieval of sequence features from generic TAB-delimited files</article-title>. <source>Bioinformatics</source><volume>27</volume>, <fpage>718</fpage>–<lpage>719</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">21208982</pub-id></mixed-citation>
    </ref>
    <ref id="R19">
      <label>19.</label>
      <mixed-citation publication-type="journal"><collab>ENCODE Project Consortium</collab>. <article-title>An integrated encyclopedia of DNA elements in the human genome</article-title>. <source>Nature</source><volume>489</volume>, <fpage>57</fpage>–<lpage>74</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22955616</pub-id></mixed-citation>
    </ref>
    <ref id="R20">
      <label>20.</label>
      <mixed-citation publication-type="journal"><collab>Roadmap Epigenomics Consortium</collab>, <name><surname>Kundaje</surname><given-names>A</given-names></name>, <etal/><article-title>Integrative analysis of 111 reference human epigenomes</article-title>. <source>Nature</source><volume>518</volume>, <fpage>317</fpage>–<lpage>330</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25693563</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig id="F1" orientation="portrait" position="float">
    <label>Figure 1.</label>
    <caption>
      <title>Overview of Selene.</title>
      <p id="P134"><bold>(a)</bold> Selene enables users to train and evaluate new deep learning models with very few lines of code. As input, the library accepts (left) the model architecture, dataset, and (mid) a configuration file that specifies the necessary input data paths and training parameters; Selene automatically splits the data into training and validation/testing, trains the model, evaluates it, and (right) generates figures from the results. <bold>(b)</bold> Selene also supports the use of trained models to interpret variants. In addition to being able to run variant effect prediction with the same configuration file format, Selene includes a visualization of the variants and their difference scores as a Manhattan plot, where a user can hover over each point to see variant information. <bold>(c)</bold> Users interested in finding informative bases that contribute to the binding of a certain protein can run Selene to get mutation effect scores and visualize the scores as a heatmap.</p>
    </caption>
    <graphic xlink:href="nihms-1522285-f0001"/>
  </fig>
  <fig id="F2" orientation="portrait" position="float">
    <label>Figure 2.</label>
    <caption>
      <title>Visualizations generated by using Selene to train and apply a model to sequences.</title>
      <p id="P135"><bold>(a)</bold> Selene visualization of the performance of the model trained in <xref rid="S2" ref-type="sec">case study 1</xref>. <bold>(b)</bold> Selene visualization of <italic>in silico</italic> mutagenesis on the case-study-trained model for 20 randomly selected GATA1 sequences in the test set (two representative plots displayed here, all heatmaps generated are displayed in the example Jupyter notebook: <ext-link ext-link-type="uri" xlink:href="https://github.com/FunctionLab/selene/blob/master/manuscript/case1/3_visualize_ism_outputs.ipynb">https://github.com/FunctionLab/selene/blob/master/manuscript/case1/3_visualize_ism_outputs.ipynb</ext-link>). Bases in the original sequence are distinguished by the gray stripes in the heatmap cells.</p>
    </caption>
    <graphic xlink:href="nihms-1522285-f0002"/>
  </fig>
  <fig id="F3" orientation="portrait" position="float">
    <label>Figure 3.</label>
    <caption>
      <title>Using Selene to train a model and obtain model predictions for variants in an Alzheimer’s GWAS study.</title>
      <p id="P136"><bold>(a)</bold> Selene visualization of the performance of the trained model from case-study 2. <bold>(b)</bold> The trained model, on average, predicts greater differences for the nominally significant variants (p-value &lt; 0.05, n = 422398) reported in the IGAP early onset Alzheimer’s GWAS study<sup><xref rid="R16" ref-type="bibr">16</xref></sup> compared to those that are nonsignificant (p-value &gt; 0.50, n = 3842725). Here we visualize the mean and 95% confidence intervals of the quantile-normalized (against the Gaussian distribution) predicted effect scores of the two variant groups for the genomic feature H3K36me3 in K562 cells, the feature in the model with the most significant difference (one-sided Wilcoxon rank-sum test, adjusted p-value using Benjamini—Hochberg of 3.89 ✕ 10<sup>−67</sup>). After applying the multiple testing correction, 914 of the 919 features that the model predicts showed a significant difference (ɑ &lt; 0.05) between the groups.</p>
    </caption>
    <graphic xlink:href="nihms-1522285-f0003"/>
  </fig>
</floats-group>
