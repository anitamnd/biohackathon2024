<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-id journal-id-type="pmc">plosone</journal-id>
    <journal-title-group>
      <journal-title>PLoS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">5851551</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-16-46352</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0192829</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Pharmacology</subject>
          <subj-group>
            <subject>Drug Research and Development</subject>
            <subj-group>
              <subject>Drug Design</subject>
              <subj-group>
                <subject>Computer-Aided Drug Design</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Genomic Medicine</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Neural Networks</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Neural Networks</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Structural Genomics</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Computational Biology</subject>
          <subj-group>
            <subject>Genome Analysis</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Genome Analysis</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
              <subj-group>
                <subject>Genetic Algorithms</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
            <subj-group>
              <subject>Genetic Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Computational Biology</subject>
          <subj-group>
            <subject>Genome Analysis</subject>
            <subj-group>
              <subject>Gene Ontologies</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Genome Analysis</subject>
              <subj-group>
                <subject>Gene Ontologies</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Mutation</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Generalising better: Applying deep learning to integrate deleteriousness prediction scores for whole-exome SNV studies</article-title>
      <alt-title alt-title-type="running-head">Generalising better: Applying deep learning to integrate prediction scores for WES variation studies</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9049-1111</contrib-id>
        <name>
          <surname>Korvigo</surname>
          <given-names>Ilia</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Data curation</role>
        <role content-type="http://credit.casrai.org/">Formal analysis</role>
        <role content-type="http://credit.casrai.org/">Investigation</role>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Writing – original draft</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff005">
          <sup>5</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Afanasyev</surname>
          <given-names>Andrey</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Data curation</role>
        <role content-type="http://credit.casrai.org/">Funding acquisition</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff003">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Romashchenko</surname>
          <given-names>Nikolay</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Data curation</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Visualization</role>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Skoblov</surname>
          <given-names>Mikhail</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Funding acquisition</role>
        <role content-type="http://credit.casrai.org/">Project administration</role>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff004">
          <sup>4</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Laboratory of Functional Analysis of the Genome, Moscow Institute of Physics and Technology, Moscow, Russia</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Laboratory of Microbiological Monitoring and Bioremediation of Soils, All-Russia Research Institute for Agricultural Microbiology, St. Petersburg, Russia</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>iBinom Inc., Los Angeles, CA, United States of America</addr-line>
    </aff>
    <aff id="aff004">
      <label>4</label>
      <addr-line>Research Center for Medical Genetics, Moscow, Russia</addr-line>
    </aff>
    <aff id="aff005">
      <label>5</label>
      <addr-line>ITMO University, St. Petersburg, Russia</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Porollo</surname>
          <given-names>Alexey</given-names>
        </name>
        <role>Editor</role>
        <xref ref-type="aff" rid="edit1"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Cincinnati Children’s Hospital Medical Center, UNITED STATES</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>Ilia Korvigo was previously employed by iBinon Inc and worked on this project before leaving the company. The commercial affiliation of Mr. Andrey Afanasyev and previous affiliation for Ilia Korvigo does not alter our adherence to PLOS ONE policies on sharing data and materials. There are no patents, products in development or marketed products to declare.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>ilia.korvigo@gmail.com</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>14</day>
      <month>3</month>
      <year>2018</year>
    </pub-date>
    <volume>13</volume>
    <issue>3</issue>
    <elocation-id>e0192829</elocation-id>
    <history>
      <date date-type="received">
        <day>22</day>
        <month>11</month>
        <year>2016</year>
      </date>
      <date date-type="accepted">
        <day>31</day>
        <month>1</month>
        <year>2018</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2018 Korvigo et al</copyright-statement>
      <copyright-year>2018</copyright-year>
      <copyright-holder>Korvigo et al</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pone.0192829.pdf"/>
    <abstract>
      <p>Many automatic classifiers were introduced to aid inference of phenotypical effects of uncategorised nsSNVs (nonsynonymous Single Nucleotide Variations) in theoretical and medical applications. Lately, several meta-estimators have been proposed that combine different predictors, such as PolyPhen and SIFT, to integrate more information in a single score. Although many advances have been made in feature design and machine learning algorithms used, the shortage of high-quality reference data along with the bias towards intensively studied <italic>in vitro</italic> models call for improved generalisation ability in order to further increase classification accuracy and handle records with insufficient data. Since a meta-estimator basically combines different scoring systems with highly complicated nonlinear relationships, we investigated how deep learning (supervised and unsupervised), which is particularly efficient at discovering hierarchies of features, can improve classification performance. While it is believed that one should only use deep learning for high-dimensional input spaces and other models (logistic regression, support vector machines, Bayesian classifiers, etc) for simpler inputs, we still believe that the ability of neural networks to discover intricate structure in highly heterogenous datasets can aid a meta-estimator. We compare the performance with various popular predictors, many of which are recommended by the American College of Medical Genetics and Genomics (ACMG), as well as available deep learning-based predictors. Thanks to hardware acceleration we were able to use a computationally expensive genetic algorithm to stochastically optimise hyper-parameters over many generations. Overfitting was hindered by noise injection and dropout, limiting coadaptation of hidden units. Although we stress that this work was not conceived as a tool comparison, but rather an exploration of the possibilities of deep learning application in ensemble scores, our results show that even relatively simple modern neural networks can significantly improve both prediction accuracy and coverage. We provide open-access to our finest model via the web-site: <ext-link ext-link-type="uri" xlink:href="http://score.generesearch.ru/services/badmut/">http://score.generesearch.ru/services/badmut/</ext-link>.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100006769</institution-id>
            <institution>Russian Science Foundation</institution>
          </institution-wrap>
        </funding-source>
        <award-id>14-26-00094</award-id>
      </award-group>
      <funding-statement>The study was mainly funded by the 5top100 Russian Academic Excellence program <ext-link ext-link-type="uri" xlink:href="http://5top100.com">http://5top100.com</ext-link>. Additionally, the Russian Science Foundation grant 14-26-00094 was used to fund computational resources at the Laboratory of microbiological monitoring and bioremediation of soils (ARRIAM), which were used in this study. ARRIAM played no role in designing and conducting this study. Ilia Korvigo (the corresponding author), being a former employee of iBinom Inc, has worked on this project before leaving the company. The specific role of this author is articulated in the ‘author contributions’ section. The project was initiated by Mr. Andrey Afanasyev (CEO at iBinom Inc), who provided it with data and computational resources at the early stages. The commercial funder supported the decision to publish the data and making all results openly accessible. The funder had no role in the preparation of this manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="4"/>
      <table-count count="8"/>
      <page-count count="17"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>Our training and testing datasets are acquired from open-access databases (<ext-link ext-link-type="uri" xlink:href="http://www.uniprot.org/">http://www.uniprot.org/</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/clinvar/">https://www.ncbi.nlm.nih.gov/clinvar/</ext-link>), and the data processing procedure is thoroughly described in the materials and methods. We reference the source of the testing datasets. We also provide open access to the training dataset used in this study by adding it to the supplement. The predictions, made by our classifier, are available at <ext-link ext-link-type="uri" xlink:href="http://score.generesearch.ru">http://score.generesearch.ru</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>Our training and testing datasets are acquired from open-access databases (<ext-link ext-link-type="uri" xlink:href="http://www.uniprot.org/">http://www.uniprot.org/</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/clinvar/">https://www.ncbi.nlm.nih.gov/clinvar/</ext-link>), and the data processing procedure is thoroughly described in the materials and methods. We reference the source of the testing datasets. We also provide open access to the training dataset used in this study by adding it to the supplement. The predictions, made by our classifier, are available at <ext-link ext-link-type="uri" xlink:href="http://score.generesearch.ru">http://score.generesearch.ru</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Single amino-acid variation (caused by nonsynonymous single nucleotide substitutions—nsSNVs) is a valuable source of information that can help us understand the fundamental features of protein evolution and function as well as uncover causative variants behind inherent health conditions and develop custom treatment strategies to maximise therapeutic efficiency. The dramatic increase in our capacity to cheaply sequence human exomes (the part of the genome comprised of exons) has brought enormous amounts of information on genetic variation in human populations, which clearly has great potential in both theoretical and medical applications. The later fuels research towards the integration of personal genetic data into medical practice. In fact, various companies are already pushing the technology into consumer market, though the means to simplify and streamline the downstream analyses are still in the infancy, and our ability to interpret variation in a phenotypically-sensible manner leaves a lot to be desired. Untangling the connections between variation and phenotypic traits remains one of the greatest challenges of functional genomics, because only a small fraction of possible variants have been thoroughly investigated and manually reviewed with respect to their fitness impact [<xref rid="pone.0192829.ref001" ref-type="bibr">1</xref>]. Thus, a lot of effort has been put into developing the means to infer possible damage of uncategorised nsSNVs by employing machine-learning. As a result, over the past decade many algorithms have been developed for predicting deleteriousness. In order to make predictions these tools encode variants using multiple quantitative and qualitative features, e.g. sequence homology [<xref rid="pone.0192829.ref002" ref-type="bibr">2</xref>], protein structure [<xref rid="pone.0192829.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0192829.ref004" ref-type="bibr">4</xref>] and evolutionary conservation [<xref rid="pone.0192829.ref005" ref-type="bibr">5</xref>, <xref rid="pone.0192829.ref006" ref-type="bibr">6</xref>]. This diversity of scoring tools has led to the creation of dbNSFP [<xref rid="pone.0192829.ref007" ref-type="bibr">7</xref>–<xref rid="pone.0192829.ref009" ref-type="bibr">9</xref>], a regularly updated specialised database that accumulates predictions of various scores alongside genomic features for most of the possible variants in the human exome.</p>
    <p>Meanwhile, the American College of Medical Genetics and Genomics (ACMG) published a guideline for reporting on clinical exomes [<xref rid="pone.0192829.ref010" ref-type="bibr">10</xref>], listing FATHMM [<xref rid="pone.0192829.ref011" ref-type="bibr">11</xref>], MutationAssessor [<xref rid="pone.0192829.ref012" ref-type="bibr">12</xref>], PANTHER [<xref rid="pone.0192829.ref013" ref-type="bibr">13</xref>], PhD-SNP [<xref rid="pone.0192829.ref014" ref-type="bibr">14</xref>], SIFT [<xref rid="pone.0192829.ref015" ref-type="bibr">15</xref>], SNPs&amp;GO [<xref rid="pone.0192829.ref016" ref-type="bibr">16</xref>], MutationTaster [<xref rid="pone.0192829.ref017" ref-type="bibr">17</xref>], MutPred [<xref rid="pone.0192829.ref018" ref-type="bibr">18</xref>], PolyPhen-2 [<xref rid="pone.0192829.ref019" ref-type="bibr">19</xref>], PROVEAN [<xref rid="pone.0192829.ref020" ref-type="bibr">20</xref>], Condel [<xref rid="pone.0192829.ref012" ref-type="bibr">12</xref>], CADD [<xref rid="pone.0192829.ref021" ref-type="bibr">21</xref>], GERP [<xref rid="pone.0192829.ref022" ref-type="bibr">22</xref>], PhyloP [<xref rid="pone.0192829.ref023" ref-type="bibr">23</xref>] and several other scores as the most trustworthy. While the recommendations prove these scores useful, the guidelines describe them as merely accessory means of annotation, because differences in feature sets, training data and machine-learning algorithms used by the scores lead to inconsistent predictions (<xref ref-type="fig" rid="pone.0192829.g001">Fig 1</xref>), making the choice a matter of personal preference of each analyst [<xref rid="pone.0192829.ref024" ref-type="bibr">24</xref>].</p>
    <fig id="pone.0192829.g001" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0192829.g001</object-id>
      <label>Fig 1</label>
      <caption>
        <title>Prediction inconsistency.</title>
        <p>A heatmap of Spearman correlation between rank-transformed output values of different deleteriousness scoring systems. 1000F—allele frequency according to the 1000 Genomes project. Greater absolute correlation means greater consistency.</p>
      </caption>
      <graphic xlink:href="pone.0192829.g001"/>
    </fig>
    <p>While several extensive comparison studies have been carried out [<xref rid="pone.0192829.ref024" ref-type="bibr">24</xref>–<xref rid="pone.0192829.ref026" ref-type="bibr">26</xref>], the differences in benchmarking datasets, the number of tools and precision assessment methods further complicate the generalisability of their conclusions. Therefore, it is still unclear which tools to use for prioritising variants in exome-based studies of human diseases. To reduce bias, gather more available information and simplify tool selection several meta-estimators have been proposed, based on other scores, such as PolyPhen and Sift. It has been demonstrated that combining individual predictors in ensembles can be both effective and not. For example, KGGSeq (an ensemble of SIFT, PolyPhen-2, LRT, MutationTaster and PhyloP [<xref rid="pone.0192829.ref027" ref-type="bibr">27</xref>]), outperformed all scores it integrated in terms of ROC curve AUC (area under the curve), while CONDEL (another meta-estimator) failed to beat some its components [<xref rid="pone.0192829.ref024" ref-type="bibr">24</xref>]. Following the trend, the curators of dbNSFP have developed their own ensemble scores (MetaLR and MetaSVM), that outperform all widely used standalone scores and meta-scores [<xref rid="pone.0192829.ref024" ref-type="bibr">24</xref>]. Additionally, to overcome the shortage of reference data, crucial in purely supervised training, some authors have proposed unsupervised and semi-supervised learning strategies, with CADD being the most notable implementation of the idea, though it doesn’t peform well in benchmarks [<xref rid="pone.0192829.ref024" ref-type="bibr">24</xref>].</p>
    <p>Missing predictions (missing feature values) pose another serious problem. When one or more of the tools used by a meta-score fails to process a substitution (e.g. due to lacking some information about it) the entry becomes incomplete (<xref ref-type="table" rid="pone.0192829.t001">Table 1</xref>) and thus requires special handling. Some tools handle missing values like an intrinsic property of the data [<xref rid="pone.0192829.ref021" ref-type="bibr">21</xref>], some try to impute them (by basically adding another machine learning task) [<xref rid="pone.0192829.ref024" ref-type="bibr">24</xref>], others are restricted to complete entries.</p>
    <table-wrap id="pone.0192829.t001" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0192829.t001</object-id>
      <label>Table 1</label>
      <caption>
        <title>The fraction of nsSNVs with no predictions made by popular deleteriousness scores and the MetaLR meta-score.</title>
      </caption>
      <alternatives>
        <graphic id="pone.0192829.t001g" xlink:href="pone.0192829.t001"/>
        <table frame="box" rules="all" border="0">
          <colgroup span="1">
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Dataset</th>
              <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">PolyPhen-2</th>
              <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">SIFT</th>
              <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">FATHMM</th>
              <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">MutationTaster</th>
              <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">MetaLR</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" rowspan="1" colspan="1">Exome<xref ref-type="table-fn" rid="t001fn001">*</xref></td>
              <td align="char" char="." rowspan="1" colspan="1">0.09</td>
              <td align="char" char="." rowspan="1" colspan="1">0.1</td>
              <td align="char" char="." rowspan="1" colspan="1">0.14</td>
              <td align="char" char="." rowspan="1" colspan="1">0.02</td>
              <td align="char" char="." rowspan="1" colspan="1">0.08</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Test I<xref ref-type="table-fn" rid="t001fn002">**</xref></td>
              <td align="char" char="." rowspan="1" colspan="1">0.02</td>
              <td align="char" char="." rowspan="1" colspan="1">0.03</td>
              <td align="char" char="." rowspan="1" colspan="1">0.06</td>
              <td align="char" char="." rowspan="1" colspan="1">0.01</td>
              <td align="char" char="." rowspan="1" colspan="1">0.004</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Test II<xref ref-type="table-fn" rid="t001fn002">**</xref></td>
              <td align="char" char="." rowspan="1" colspan="1">0.01</td>
              <td align="char" char="." rowspan="1" colspan="1">0.03</td>
              <td align="char" char="." rowspan="1" colspan="1">0.04</td>
              <td align="char" char="." rowspan="1" colspan="1">0.003</td>
              <td align="char" char="." rowspan="1" colspan="1">0.006</td>
            </tr>
          </tbody>
        </table>
      </alternatives>
      <table-wrap-foot>
        <fn id="t001fn001">
          <p>*The fractions are estimated by querying a random subset of 1 ⋅ 10<sup>6</sup> SNVs from dbNSFP v3.2 [<xref rid="pone.0192829.ref009" ref-type="bibr">9</xref>].</p>
        </fn>
        <fn id="t001fn002">
          <p>**Our testing datasets I and II (described in the <xref ref-type="sec" rid="sec002">Materials and methods</xref>), comprising variations with experimental evidence of phenotype.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <p>All these problems greatly emphasise the importance of better generalisation. Here we explore how deep learning can address the issues. Deep learning (DL) allows computational models learn hierarchies of representations with multiple levels of abstractions by combing several layers of nonlinear transformations. Techniques, such as noise injection and dropout, ultimately fight overfitting and allow adaptive regularisation [<xref rid="pone.0192829.ref028" ref-type="bibr">28</xref>]. Deep neural networks have already been used in DANN [<xref rid="pone.0192829.ref029" ref-type="bibr">29</xref>] and Eigen [<xref rid="pone.0192829.ref030" ref-type="bibr">30</xref>] to improve on the CADD’s original unsupervised approach, which incorporates hundreds of different features. While it is believed that one should only use DL for high-dimensional input spaces and other models (logistic regression, support vector machines, Bayesian classifiers, etc) for simpler inputs, we still believe that the ability of deep neural networks to discover intricate structure in highly heterogenous datasets can benefit a meta-estimator with relatively few input features, because connections and interaction between different scoring systems can be highly complicated and nonlinear [<xref rid="pone.0192829.ref029" ref-type="bibr">29</xref>]. We want to stress that this work was not conceived as a tool comparison, but rather an exploration of the possibilities of deep learning application in ensemble scores.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>Materials and methods</title>
    <sec id="sec003">
      <title>Testing and training data</title>
      <p>Our testing setup is based on the extensive comparative study performed by Dong et al. [<xref rid="pone.0192829.ref024" ref-type="bibr">24</xref>]. Since MetaLR and MetaSVM, introduced in the study, were shown to be state of the art in meta-estimators, it was natural to include them here for the sake of comparison along with other scores evaluated in that study. Thus we had to make sure that our training and testing data did not give our models an unfair advantage, hence we used the testing datasets provided by the authors. Briefly, the authors constructed their first testing dataset out of 120 deleterious mutations (causing 49 different diseases) recently reported in Nature Genetics, and 124 neutral mutations newly discovered from the CHARGE sequencing project [<xref rid="pone.0192829.ref031" ref-type="bibr">31</xref>]. To ensure the quality of the deleterious mutations, they only left variants reported to cause Mendelian diseases with experimental evidence. The quality of the neutral mutations was ensured by removing any record with minor allele frequency &lt; 1% in 2 thousands exomes from the ARIC study via the CHARGE sequencing project [<xref rid="pone.0192829.ref031" ref-type="bibr">31</xref>]. Additionally the authors used a subset of VariBench protein tolerance dataset II [<xref rid="pone.0192829.ref026" ref-type="bibr">26</xref>]. VariBench, comprising high quality records with experimentally verified effects, has become a standard dataset for performance evaluation. The dataset itself contains 14611 positive and 19470 negative variants. The subset included 6279 deleterious curated variants and 13240 common neutral variants (minor allele frequency &gt; 1%).</p>
      <p>UniProtKB/Swiss-Prot was the main source of annotated nsSNVs for our training dataset. We downloaded all amino-acid natural variants (the HUMSAVAR archive from UniProt knowledge base release 03.2016) and mapped UniProt protein IDs to RefSeq nucleotide IDs. We then converted AA substitutions into nsSNVs. Initially there were 28 ⋅ 10<sup>3</sup> causative and 39 ⋅ 10<sup>3</sup> neutral AA polymorphisms. We then downloaded ClinVar variants mapped to loci referenced in OMIM [<xref rid="pone.0192829.ref032" ref-type="bibr">32</xref>]. Based on a dataset of 200 manually annotated records we trained a bag-of-words Naïve Bayesian classifier to automatically identify and remove SNVs associated with any type of cancer or having nothing but <italic>in silico</italic> and/or GWAS-based evidence of impact. This left us with around 120 ⋅ 10<sup>3</sup> variants. We further filtered them to remove any possible splicing-altering substitutions using the annotations from SnpEff 4.1 [<xref rid="pone.0192829.ref033" ref-type="bibr">33</xref>]. Finally, we removed all SNVs yielding amino acid substitutions found in the testing datasets. After all these steps there were 96.5 ⋅ 10<sup>3</sup> variants left: 64.5 ⋅ 10<sup>3</sup> deleterious and 32 ⋅ 10<sup>3</sup> neutral. This was our raw supervised training dataset. For our final supervised training collection we only left true positive records with experimental evidence. The dataset comprised around 19735 neutral and 14480 damaging nsSNVs <xref ref-type="supplementary-material" rid="pone.0192829.s001">S1 File</xref>. For our unsupervised training dataset we randomly sampled 10<sup>6</sup> positions from the UCSC-annotated exonic regions. All data were collected for the hg19 genome assembly.</p>
    </sec>
    <sec id="sec004">
      <title>Deep learning models</title>
      <p>We constructed our classifiers using two basic architectures (<xref ref-type="fig" rid="pone.0192829.g002">Fig 2a</xref>): the deep multilayer perceptron (MLP) and the stacked denoising autoencoder (sdAE). MLPs are well known and widely used models. Although their basic architecture was introduced decades ago, their modern versions differ significantly in many implementation details. Stacked denoising autoencoders are relatively novel models used for unsupervised and semi-supervised learning and data compression. These networks are first trained as individual shallow denoising autoencoders (<xref ref-type="fig" rid="pone.0192829.g002">Fig 2b</xref>) by iteratively stacking one on top of another, which is followed by final training (<xref ref-type="fig" rid="pone.0192829.g002">Fig 2c</xref>). The term “denoising” stands for their ability to reconstruct lousy input records by generalising on training datasets. Stacking several autoencoders on top of each other and training each to reconstruct the output of the previous layer allows to learn a hierarchy of features in the input space in an unsupervised manner. When labeled reference data are scarce, one can combine unsupervised and supervised training to discover great generalisations from unlabelled data and perform fine-tuning using the few available labeled records.</p>
      <fig id="pone.0192829.g002" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0192829.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Network types.</title>
          <p>Schematic representation of basic deep learning models used in this study. (a) A multilayer perceptron (MLP). (b) A shallow denoising autoencoder (dAE). (c) Connecting dAEs into a stacked denoising autoencoder (sdAE); notice that each individual dAE learns to reconstruct the latent representation from the previous one (data stream is represented by arrows). Colours encode layer functions (combinations are possible): blue—input, light-red—latent, dark-red—dropout (noise), purple—output, hollow—discarded.</p>
        </caption>
        <graphic xlink:href="pone.0192829.g002"/>
      </fig>
    </sec>
    <sec id="sec005">
      <title>Implementation details</title>
      <p>Here we will briefly discuss several fundamental implementation details: update functions, regularisation, activation functions. Most neural networks are trained using various modifications of stochastic gradient descent (SGD). Here explored two SGD modifications: SGD with Nesterov momentum [<xref rid="pone.0192829.ref034" ref-type="bibr">34</xref>] and adagrad [<xref rid="pone.0192829.ref035" ref-type="bibr">35</xref>]. To prevent overfitting we used dropout as a simple and extremely effective regularisation tool [<xref rid="pone.0192829.ref028" ref-type="bibr">28</xref>, <xref rid="pone.0192829.ref036" ref-type="bibr">36</xref>]. During training, dropout can be interpreted as sampling a part within the full network, and only updating the parameters of the subsampled units during back-propagation. In our MLPs we applied dropout to all layers, but the output; in sdAEs we only applied dropout to the input layer encouraging the networks to denoise the data. We used sigmoidal and ReLU (rectified linear unit) nonlinearities. Briefly, the standard sigmoid function is defined as <inline-formula id="pone.0192829.e001"><alternatives><graphic xlink:href="pone.0192829.e001.jpg" id="pone.0192829.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mo form="prefix">exp</mml:mo><mml:mo>(</mml:mo><mml:mo>-</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>, hence it maps any real number into (0,1) and saturates at both ends, producing unfeasible gradients [<xref rid="pone.0192829.ref037" ref-type="bibr">37</xref>]. More importantly, repeated application of the sigmoid function (which basically happens in deep networks) leads to the vanishing gradient effect (<xref ref-type="fig" rid="pone.0192829.g003">Fig 3a</xref>) hindering convergence. We also used the hyperbolic tangent (tanh), which is considered a superior sigmoidal function, because it is zero-centered and less prone to the vanishing gradient effect (<xref ref-type="fig" rid="pone.0192829.g003">Fig 3b</xref>). The standard ReLU activation function is given by <italic>ρ</italic>(<italic>x</italic>) = <italic>max</italic>(0, <italic>x</italic>). It is idempotent (i.e. <italic>ρ</italic>°<italic>ρ</italic>°…°<italic>ρ</italic> = <italic>ρ</italic>) and scaling invariant (i.e. <italic>ρ</italic>(<italic>αx</italic>) = <italic>αρ</italic>(<italic>x</italic>)). These properties make it computationally cheap and immune to vanishing gradients [<xref rid="pone.0192829.ref038" ref-type="bibr">38</xref>]. At the same time, it has been shown tricky to use the function in autoencoders, due to knockout effect and overshooting [<xref rid="pone.0192829.ref039" ref-type="bibr">39</xref>], hence it is still more common to use sigmoidal activations in these models.</p>
      <fig id="pone.0192829.g003" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0192829.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>Nonlinearities.</title>
          <p>The sigmoid (a) and hyperbolic tangent (b) iteratively applied 3 times. Observe how repeated application of the sigmoid function quickly makes the gradient vanish completely.</p>
        </caption>
        <graphic xlink:href="pone.0192829.g003"/>
      </fig>
    </sec>
    <sec id="sec006">
      <title>Hyper-parameter optimisation and the training setup</title>
      <p>So far we’ve mentioned various aspects of design and implementation, influencing performance in many different ways [<xref rid="pone.0192829.ref037" ref-type="bibr">37</xref>]. These settings are called hyper-parameters: the number of layers and units per each layer, the compression factor in encoders, learning rate, dropout and noise levels, mini-batch size, momentum applied, nonlinearities. To select these we used genetic algorithms (GA)—stochastic optimisation tools simulating natural selection over many generations of mutation, recombination and selective pressure [<xref rid="pone.0192829.ref040" ref-type="bibr">40</xref>]. This strategy has already been successfully applied to optimise hyper-parameters in other machine-learning models [<xref rid="pone.0192829.ref041" ref-type="bibr">41</xref>]. We performed two independent GA runs: one for the pure MLP model and one for the stacked denoising autoencoder. In both cases a population of 100 individuals had been evolving for 100 generations and each model could chose whether to use the 7-way or 100-way phyloP and phastCons conservation scores, the batch size (500-10000), adagrad or Nesterov momentum (0.00-1.0; step size 0.05) update functions and the learning rate (0.005-1.0).</p>
      <p>During the MLP GA run the number of training epochs was fixed at 1000. All models used the hard ReLU activation function and Glorot uniform weight initialisation. Variable hyper-parameters:</p>
      <list list-type="bullet">
        <list-item>
          <p>the number of hidden layers: 1-4</p>
        </list-item>
        <list-item>
          <p>the number of units per hidden layer: 10-30</p>
        </list-item>
        <list-item>
          <p>dropout probability: 0.00-0.5 (stepsize 0.05)</p>
        </list-item>
      </list>
      <p>Each stacked denoising autoencoder trained in two steps: individual shallow autoencoders trained for 300 epochs prior stacking. Stacked autoencoders trained for additional 1000 epochs. We increased the number of training epochs due to the saturation and vanishing gradient problems inherent to sigmoidal nonlinearities. Hyper-parameter search space:</p>
      <list list-type="bullet">
        <list-item>
          <p>first-layer expansion factor: 1.0-1.5 (stepsize 0.05); represents the relative increase in the number of units in the first hidden layer with respect to the input layer</p>
        </list-item>
        <list-item>
          <p>encoder compression level: 1.0-1.5 (stepsize 0.05)</p>
        </list-item>
        <list-item>
          <p>the number of hidden layers in the encoder (excluding the compressed latent layer): 1-3 (and the decoder by extension, due to symmetric design).</p>
        </list-item>
        <list-item>
          <p>activation function: sigmoid or hyperbolic tangent (in conjunction with appropriate weight initialisation functions).</p>
        </list-item>
      </list>
      <p>We carried out the process on a machine with 8 Nvidia Titan X (Maxwell) GPUs (Graphics Processing Units) using model-based parallelism [<xref rid="pone.0192829.ref042" ref-type="bibr">42</xref>], i.e. each model trained on a separate GPU with its own copy of the data, hence we could train up to 8 models simultaneously. To estimate fitness we used 3-fold cross-validation scores (categorical crossentropy for MLPs, and squared-root reconstruction error for sdAEs). Neural networks were implemented using Theano and lasagne in Python 3.5. We used the genetic algorithm implementation provided by package <italic>genetic</italic>, openly available in PyPI (the Python Package Index).</p>
    </sec>
    <sec id="sec007">
      <title>Data extraction and missing annotations</title>
      <p>We selected the following scores and genomic features as input units: FATHMM, GERP++, LRT, LRT Omega, MetaLR, MetaSVM, MutationAssessor, MutationTaster, PROVEAN, Polyphen2 (both HDIV and HVAR), SIFT, SiPhy log Odds, phastCons vertebrate (both 7-way and 100-way), phyloP vertebrate (both 7-way and 100-way) and the allele frequency (AF) in the 1000 Genomes Project dataset. Since all these scores had different output scales and thus couldn’t be directly compared, we used the rank-transformed values, provided by dbNSFP [<xref rid="pone.0192829.ref007" ref-type="bibr">7</xref>], for both training and comparison like demonstrated by Dong et al. [<xref rid="pone.0192829.ref024" ref-type="bibr">24</xref>]. Although this step was only mandatory to train our autoencoders, other networks should have benefitted from the normalised data as well. For each position in the training and testing datasets we extracted these features from dbNSFP 3.1 and 3.2 [<xref rid="pone.0192829.ref009" ref-type="bibr">9</xref>] (we used the former to obtain values for the 7-way phyloP and phastCons, replaced by updated 100-way scores in the recent versions of dbNSFP). We had no special way of handling missing data: missing values in the training and testing datasets were simply replaced by zeros.</p>
    </sec>
    <sec id="sec008">
      <title>Performance estimations</title>
      <p>To make comparisons between different scores possible we used rank-transformed [<xref rid="pone.0192829.ref007" ref-type="bibr">7</xref>] outputs of CADD, DANN, Eigen, FATHMM, GERP++, LRT, MutationAssessor, MutationTaster, PROVEAN, Polyphen-2 (both HDIV and HVAR), SIFT, SiPhy (29-way), phastCons (100-way), phyloP (100-way). We interpreted these values as positive-class (causative) probabilities and carried out two series of benchmarks. The first one comprised threshold-invariant performance indicators: (1) the area under the receiver operating characteristic curve (ROC-curve AUC) and (2) the area under the precision-recall curve (average precision). The second one comprised cutoff-sensitive statistics: (1) the F1 score, (2) the Matthews correlation coefficient (MCC) and (3) the accuracy score. We optimised the cutoff value for each score individually to find the highest possible performance using empirical bootstrapping (1000 replicates) to approximate the distributions of these statistics and estimate their 95% confidence intervals (i.e. the 2.5 and 97.5 percentiles of the distributions). We benchmarked our classifiers (MLP and sdAE) without removing variations with missing annotations (i.e. incomplete data) from the dataset. In our interpretations we considered the second testing dataset more representative, because of its significantly greater size (∼100 times more records).</p>
    </sec>
    <sec id="sec009">
      <title>Assessing generalisation</title>
      <p>Since available testing data comprise a small subset of the exome, to extrapolate a classifier’s performance from these datasets to the entire exome, it is important to evaluate how representative the datasets are and to examine the classifier’s ability to generalise. We used Gene Ontology (GO) [<xref rid="pone.0192829.ref043" ref-type="bibr">43</xref>] terms to encode various protein properties and to analyse their distribution in the exome and the datasets. Since raw GO annotation was extremely sparse and deep, we mapped it onto the generic GO Slim annotation, reducing the GO term-space to ∼150 terms and making it shallow. This allowed us to include all term levels. We carried out binomial tests for each term to find the number of terms significantly enriched in either misclassified or correctly classified subsets of the datasets. Additionally, using the same procedure we tested term enrichment in the false-positive (FP) and false-negative (FN) subsets of the misclassified variations. We adjusted p-values using the Benjamini-Hochberg procedure, also known as the false discovery rate (FDR). For each predictor we used a probability cutoff-value maximising the F1 score. The FDR level was set to 5%.</p>
    </sec>
  </sec>
  <sec id="sec010">
    <title>Results and discussion</title>
    <sec id="sec011">
      <title>Training logs</title>
      <p>We carried out two independent runs of the genetic algorithm to optimise the hyper-parameters in our deep learning models. The MLP run took 3 days of calculations. We selected five sets of parameters yielding the highest cross-validation scores and trained them for 50 ⋅ 10<sup>3</sup> epochs. We then picked the network with the highest ROC-curve AUC and average precision (area under the precision-recall curve). The network had the following parameters:</p>
      <list list-type="bullet">
        <list-item>
          <p>two latent layers: the first one had 13 hidden units, and the second one had 19</p>
        </list-item>
        <list-item>
          <p>dropout probability: 0.1</p>
        </list-item>
        <list-item>
          <p>batch size: 2000</p>
        </list-item>
        <list-item>
          <p>learning rate: 0.01</p>
        </list-item>
        <list-item>
          <p>update function: Nesterov momentum (0.7)</p>
        </list-item>
        <list-item>
          <p>phyloP and phastCons version: 7-way</p>
        </list-item>
      </list>
      <p>The sdAE run took 54 days of calculations. As with the MLPs, we took 5 best-scoring models, though this time we trained each one for 100 ⋅ 10<sup>3</sup> epochs. After benchmarking the models on one million random nsSNVs from the exome (non-overlapping with the training dataset), we picked one model with the lowest absolute-error of reconstruction. It had the following parameters:</p>
      <list list-type="bullet">
        <list-item>
          <p>three latent layers in the encoder</p>
        </list-item>
        <list-item>
          <p>expansion factor: 1.25</p>
        </list-item>
        <list-item>
          <p>compression factor: 1.3</p>
        </list-item>
        <list-item>
          <p>input-layer dropout (noise) probability: 0.3</p>
        </list-item>
        <list-item>
          <p>batch size: 5000</p>
        </list-item>
        <list-item>
          <p>learning rate: 0.05</p>
        </list-item>
        <list-item>
          <p>update function: Nesterov momentum (0.5)</p>
        </list-item>
        <list-item>
          <p>nonlinearity: hyperbolic tangent</p>
        </list-item>
        <list-item>
          <p>phyloP and phastCons version: 100-way</p>
        </list-item>
      </list>
      <p>This model achieved median absolute reconstruction error of 0.02. We then removed the decoding part of the model, added a softmax output layer with two units and trained the model for 10 ⋅ 10<sup>3</sup> epochs to classify nsSNVs using the supervised training dataset. Training parameters were not altered, except for the batch size, which was reduced to 2000. Surprisingly, the resulting classifier performed poorly with average precision of 0.63 and ROC-curve AUC of 0.82, while having extremely low training errors, which led us to conclude that overfitting was the reason behind these results. To test this assumption, we tried to train the model again (staring with the same unmodified sdAE) while freezing the weights in the encoder and only updating the classifier’s softmax layer, which is basically similar to applying logistic regression on the compressed latent representation of the input space. This significantly increased both measures of performance. We used this final model in our benchmarks.</p>
    </sec>
    <sec id="sec012">
      <title>Performance</title>
      <p>The first round of benchmarks comprised cutoff-invariant performance measures: the ROC curve AUC and average accuracy score (the area under the precision-recall curve. The ROC curve AUC tests supported the results published by Dong et al. [<xref rid="pone.0192829.ref024" ref-type="bibr">24</xref>] in their comparative study (<xref ref-type="table" rid="pone.0192829.t002">Table 2</xref>). The meta-estimators, introduced in that study (MetaLR and MetaSVM), outperformed most of the scores we used in the benchmark. Only our MLP classifier had a slight edge over both these scores in terms of the ROC curve AUC. Though, MLP and MetaLR showed identical performance on the test I, which was second only to MutationTater and sdAE, the MLP outperformed all the other scores on the test II. At the same time the stacked autoencoder outperformed all scores on the test I. Surprisingly enough, the deep learning models that were developed to improve on the CADD’s unsupervised approach (DANN and Eigen) performed worse than CADD itself. We also plotted the curves for better illustration (<xref ref-type="fig" rid="pone.0192829.g004">Fig 4</xref>).</p>
      <fig id="pone.0192829.g004" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0192829.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>ROC-curves.</title>
          <p>MLP, MetaLR, MetaSVM, sDAE and MutationTaster produced the largest area under the curve.</p>
        </caption>
        <graphic xlink:href="pone.0192829.g004"/>
      </fig>
      <table-wrap id="pone.0192829.t002" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0192829.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>ROC curve AUC score with 95% confidence intervals.</title>
        </caption>
        <alternatives>
          <graphic id="pone.0192829.t002g" xlink:href="pone.0192829.t002"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Score</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Test I</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Test II</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="1" colspan="1">CADD</td>
                <td align="center" rowspan="1" colspan="1">0.85 (0.79–0.90)</td>
                <td align="center" rowspan="1" colspan="1">0.78 (0.78–0.79)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">DANN</td>
                <td align="center" rowspan="1" colspan="1">0.84 (0.79–0.89)</td>
                <td align="center" rowspan="1" colspan="1">0.75 (0.74–0.75)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Eigen</td>
                <td align="center" rowspan="1" colspan="1">0.86 (0.81–0.91)</td>
                <td align="center" rowspan="1" colspan="1">0.67 (0.66–0.68)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">FATHMM</td>
                <td align="center" rowspan="1" colspan="1">0.84 (0.78–0.89)</td>
                <td align="center" rowspan="1" colspan="1">0.91 (0.90–0.91)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">GERP++</td>
                <td align="center" rowspan="1" colspan="1">0.79 (0.73–0.84)</td>
                <td align="center" rowspan="1" colspan="1">0.68 (0.67–0.68)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">LRT</td>
                <td align="center" rowspan="1" colspan="1">0.85 (0.80–0.90)</td>
                <td align="center" rowspan="1" colspan="1">0.73 (0.72–0.74)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>MLP</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.90 (0.86–0.94)</td>
                <td align="center" rowspan="1" colspan="1">0.94 (0.94–0.95)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaLR</td>
                <td align="center" rowspan="1" colspan="1">0.90 (0.86–0.94)</td>
                <td align="center" rowspan="1" colspan="1">0.93 (0.93–0.94)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaSVM</td>
                <td align="center" rowspan="1" colspan="1">0.90 (0.86–0.94)</td>
                <td align="center" rowspan="1" colspan="1">0.92 (0.92–0.93)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MutationAssessor</td>
                <td align="center" rowspan="1" colspan="1">0.78 (0.71–0.83)</td>
                <td align="center" rowspan="1" colspan="1">0.77 (0.77–0.78)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MutationTaster</td>
                <td align="center" rowspan="1" colspan="1">0.91 (0.87–0.94)</td>
                <td align="center" rowspan="1" colspan="1">0.76 (0.75–0.77)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PROVEAN</td>
                <td align="center" rowspan="1" colspan="1">0.82 (0.77–0.88)</td>
                <td align="center" rowspan="1" colspan="1">0.77 (0.77–0.78)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HDIV</td>
                <td align="center" rowspan="1" colspan="1">0.79 (0.73–0.85)</td>
                <td align="center" rowspan="1" colspan="1">0.77 (0.76–0.77)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HVAR</td>
                <td align="center" rowspan="1" colspan="1">0.80 (0.74–0.86)</td>
                <td align="center" rowspan="1" colspan="1">0.79 (0.78–0.79)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SIFT</td>
                <td align="center" rowspan="1" colspan="1">0.77 (0.71–0.82)</td>
                <td align="center" rowspan="1" colspan="1">0.78 (0.77–0.78)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SiPhy 29-way</td>
                <td align="center" rowspan="1" colspan="1">0.82 (0.76–0.87)</td>
                <td align="center" rowspan="1" colspan="1">0.70 (0.70–0.71)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">phastCons 100-way</td>
                <td align="center" rowspan="1" colspan="1">0.81 (0.76–0.86)</td>
                <td align="center" rowspan="1" colspan="1">0.69 (0.69–0.70)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">phyloP 100-way</td>
                <td align="center" rowspan="1" colspan="1">0.89 (0.85–0.93)</td>
                <td align="center" rowspan="1" colspan="1">0.75 (0.74–0.76)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>sdAE</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.92 (0.88–0.95)</td>
                <td align="center" rowspan="1" colspan="1">0.92 (0.92–0.93)</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>While ROC curve AUC results gave our MLP a slight edge over the other scores on the test II, the average precision score deemed it even more superior (<xref ref-type="table" rid="pone.0192829.t003">Table 3</xref>), though it was second to sdAE on the test I. In general, most scores fared better on the testing dataset I in case of both performance indicators.</p>
      <table-wrap id="pone.0192829.t003" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0192829.t003</object-id>
        <label>Table 3</label>
        <caption>
          <title>Average precision score with 95% confidence intervals.</title>
        </caption>
        <alternatives>
          <graphic id="pone.0192829.t003g" xlink:href="pone.0192829.t003"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Score</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Test I</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Test II</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="1" colspan="1">CADD</td>
                <td align="center" rowspan="1" colspan="1">0.79 (0.70–0.87)</td>
                <td align="center" rowspan="1" colspan="1">0.60 (0.58–0.61)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">DANN</td>
                <td align="center" rowspan="1" colspan="1">0.84 (0.77–0.90)</td>
                <td align="center" rowspan="1" colspan="1">0.55 (0.53–0.56)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Eigen</td>
                <td align="center" rowspan="1" colspan="1">0.81 (0.73–0.89)</td>
                <td align="center" rowspan="1" colspan="1">0.57 (0.56–0.58)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">FATHMM</td>
                <td align="center" rowspan="1" colspan="1">0.83 (0.75–0.90)</td>
                <td align="center" rowspan="1" colspan="1">0.83 (0.82–0.84)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">GERP++</td>
                <td align="center" rowspan="1" colspan="1">0.77 (0.69–0.85)</td>
                <td align="center" rowspan="1" colspan="1">0.44 (0.43–0.45)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">LRT</td>
                <td align="center" rowspan="1" colspan="1">0.87 (0.82–0.92)</td>
                <td align="center" rowspan="1" colspan="1">0.64 (0.63–0.65)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>MLP</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.91 (0.82–0.94)</td>
                <td align="center" rowspan="1" colspan="1">0.89 (0.88–0.91)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaLR</td>
                <td align="center" rowspan="1" colspan="1">0.88 (0.81–0.94)</td>
                <td align="center" rowspan="1" colspan="1">0.87 (0.87–0.89)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaSVM</td>
                <td align="center" rowspan="1" colspan="1">0.91 (0.87–0.95)</td>
                <td align="center" rowspan="1" colspan="1">0.87 (0.86–0.88)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MutationAssessor</td>
                <td align="center" rowspan="1" colspan="1">0.78 (0.70–0.85)</td>
                <td align="center" rowspan="1" colspan="1">0.67 (0.66–0.68)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MutationTaster</td>
                <td align="center" rowspan="1" colspan="1">0.91 (0.87–0.95)</td>
                <td align="center" rowspan="1" colspan="1">0.67 (0.67–0.68)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PROVEAN</td>
                <td align="center" rowspan="1" colspan="1">0.76 (0.67–0.85)</td>
                <td align="center" rowspan="1" colspan="1">0.61 (0.59–0.62)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HDIV</td>
                <td align="center" rowspan="1" colspan="1">0.80 (0.73–0.86)</td>
                <td align="center" rowspan="1" colspan="1">0.67 (0.66–0.68)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HVAR</td>
                <td align="center" rowspan="1" colspan="1">0.77 (0.69–0.84)</td>
                <td align="center" rowspan="1" colspan="1">0.66 (0.65–0.68)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SIFT</td>
                <td align="center" rowspan="1" colspan="1">0.79 (0.72–0.85)</td>
                <td align="center" rowspan="1" colspan="1">0.67 (0.66–0.68)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SiPhy 29-way</td>
                <td align="center" rowspan="1" colspan="1">0.75 (0.65–0.84)</td>
                <td align="center" rowspan="1" colspan="1">0.47 (0.45–0.48)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">phastCons 100-way</td>
                <td align="center" rowspan="1" colspan="1">0.86 (0.81–0.90)</td>
                <td align="center" rowspan="1" colspan="1">0.66 (0.66–0.67)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">phyloP 100-way</td>
                <td align="center" rowspan="1" colspan="1">0.89 (0.83–0.94)</td>
                <td align="center" rowspan="1" colspan="1">0.56 (0.54–0.57)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>sdAE</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.92 (0.86–0.96)</td>
                <td align="center" rowspan="1" colspan="1">0.87 (0.86–0.87)</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>The second round of benchmarks comprised three threshold-sensitive metrics: the F1-score, MCC and the weighted accuracy score (<xref ref-type="table" rid="pone.0192829.t004">Table 4</xref>). Since we have optimised each score’s cutoff individually for each performance metric these results can be used a guideline for cutoff selection. For the most part all three metrics yield similar performance ranking. Once again, the MLP comes first with a slight edge over the MetaLR, MetaSVM and sdAE. The latter three show almost identical performance.</p>
      <table-wrap id="pone.0192829.t004" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0192829.t004</object-id>
        <label>Table 4</label>
        <caption>
          <title>Maximum average values of threshold-sensitive performance measures, evaluated for test II.</title>
          <p>Numbers in parentheses represent corresponding cutoffs.</p>
        </caption>
        <alternatives>
          <graphic id="pone.0192829.t004g" xlink:href="pone.0192829.t004"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Score</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">F1-score</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">MCC</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Accuracy</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="1" colspan="1">CADD</td>
                <td align="center" rowspan="1" colspan="1">0.64 (0.50)</td>
                <td align="center" rowspan="1" colspan="1">0.43 (0.58)</td>
                <td align="center" rowspan="1" colspan="1">0.74 (0.73)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">DANN</td>
                <td align="center" rowspan="1" colspan="1">0.60 (0.51)</td>
                <td align="center" rowspan="1" colspan="1">0.35 (0.53)</td>
                <td align="center" rowspan="1" colspan="1">0.71 (0.85)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Eigen</td>
                <td align="center" rowspan="1" colspan="1">0.61 (0.55)</td>
                <td align="center" rowspan="1" colspan="1">0.43 (0.66)</td>
                <td align="center" rowspan="1" colspan="1">0.77 (0.80)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">FATHMM</td>
                <td align="center" rowspan="1" colspan="1">0.79 (0.83)</td>
                <td align="center" rowspan="1" colspan="1">0.67 (0.87)</td>
                <td align="center" rowspan="1" colspan="1">0.85 (0.88)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">GERP++</td>
                <td align="center" rowspan="1" colspan="1">0.57 (0.38)</td>
                <td align="center" rowspan="1" colspan="1">0.30 (0.38)</td>
                <td align="center" rowspan="1" colspan="1">0.67 (0.99)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">LRT</td>
                <td align="center" rowspan="1" colspan="1">0.61 (0.49)</td>
                <td align="center" rowspan="1" colspan="1">0.37 (0.51)</td>
                <td align="center" rowspan="1" colspan="1">0.71 (0.68)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>MLP</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.83 (0.68)</td>
                <td align="center" rowspan="1" colspan="1">0.75 (0.69)</td>
                <td align="center" rowspan="1" colspan="1">0.89 (0.70)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaLR</td>
                <td align="center" rowspan="1" colspan="1">0.82 (0.83)</td>
                <td align="center" rowspan="1" colspan="1">0.74 (0.83)</td>
                <td align="center" rowspan="1" colspan="1">0.88 (0.88)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaSVM</td>
                <td align="center" rowspan="1" colspan="1">0.81 (0.81)</td>
                <td align="center" rowspan="1" colspan="1">0.72 (0.86)</td>
                <td align="center" rowspan="1" colspan="1">0.88 (0.87)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MutationAssessor</td>
                <td align="center" rowspan="1" colspan="1">0.64 (0.73)</td>
                <td align="center" rowspan="1" colspan="1">0.47 (0.81)</td>
                <td align="center" rowspan="1" colspan="1">0.78 (0.85)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MutationTaster</td>
                <td align="center" rowspan="1" colspan="1">0.63 (0.45)</td>
                <td align="center" rowspan="1" colspan="1">0.41 (0.47)</td>
                <td align="center" rowspan="1" colspan="1">0.72 (0.80)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PROVEAN</td>
                <td align="center" rowspan="1" colspan="1">0.63 (0.55)</td>
                <td align="center" rowspan="1" colspan="1">0.42 (0.60)</td>
                <td align="center" rowspan="1" colspan="1">0.74 (0.79)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HDIV</td>
                <td align="center" rowspan="1" colspan="1">0.63 (0.55)</td>
                <td align="center" rowspan="1" colspan="1">0.42 (0.74)</td>
                <td align="center" rowspan="1" colspan="1">0.75 (0.88)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HVAR</td>
                <td align="center" rowspan="1" colspan="1">0.64 (0.59)</td>
                <td align="center" rowspan="1" colspan="1">0.44 (0.59)</td>
                <td align="center" rowspan="1" colspan="1">0.75 (0.77)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SIFT</td>
                <td align="center" rowspan="1" colspan="1">0.64 (0.58)</td>
                <td align="center" rowspan="1" colspan="1">0.44 (0.66)</td>
                <td align="center" rowspan="1" colspan="1">0.76 (0.72)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SiPhy 29-way</td>
                <td align="center" rowspan="1" colspan="1">0.59 (0.44)</td>
                <td align="center" rowspan="1" colspan="1">0.33 (0.46)</td>
                <td align="center" rowspan="1" colspan="1">0.67 (0.78)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">phastCons 100-way</td>
                <td align="center" rowspan="1" colspan="1">0.59 (0.39)</td>
                <td align="center" rowspan="1" colspan="1">0.33 (0.68)</td>
                <td align="center" rowspan="1" colspan="1">0.67 (0.78)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">phyloP 100-way</td>
                <td align="center" rowspan="1" colspan="1">0.60 (0.51)</td>
                <td align="center" rowspan="1" colspan="1">0.37 (0.62)</td>
                <td align="center" rowspan="1" colspan="1">0.73 (0.73)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>sdAE</bold>
                </td>
                <td align="center" rowspan="1" colspan="1">0.81 (0.69)</td>
                <td align="center" rowspan="1" colspan="1">0.72 (0.79)</td>
                <td align="center" rowspan="1" colspan="1">0.88 (0.79)</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec id="sec013">
      <title>Coverage and missing data</title>
      <p>Coverage is another measure of performance: the inability of a score to predict the impact of a subset of SNVs seriously limits its usefulness, hence a good score should have as much coverage as possible. Among the tools we examined, CADD, DANN, GERP++, MutationTaster, phyloP, phastCons and SiPhy demonstrate almost complete coverage of the genome, yet fall short in terms of prediction accuracy. At the same time, the high-performing scores demonstrate significantly limited coverage (<xref ref-type="table" rid="pone.0192829.t001">Table 1</xref>). We designed our scores with high-coverage in mind from the beginning and ran a separate round of tests to evaluate how they perform when other scores fail to predict due to incomplete annotations or other reasons. For each predictor we found unprocessed SNVs in the testing dataset II. If there were more than 50 unpredicted variations, we assessed their impact using our models and calculated the ROC curve AUC scores (<xref ref-type="table" rid="pone.0192829.t005">Table 5</xref>) and the average precision scores (<xref ref-type="table" rid="pone.0192829.t006">Table 6</xref>). Quite surprisingly, our semi-supervised model (sdAE), explicitly designed and trained to reconstruct missing information, performed downright poorly in the absence of predictions made by FATHMM, PROVEAN, MetaLR, MetaSVM and PolyPhen. At the same time, the MLP performs well in the absence of most predictions: it is only sensitive to the absence of FATHMM and PROVEAN scores. Interestingly enough, both the MLP and sdAE predict nsSNVs unprocessed by Eigen with nearly absolute precision. These results show that the MLP not only provides technically extended coverage of the exome but also makes high-quality predictions.</p>
      <table-wrap id="pone.0192829.t005" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0192829.t005</object-id>
        <label>Table 5</label>
        <caption>
          <title>MLP’s and sdAE’s ROC curve AUC with 95% confidence intervals evaluated on subsets of SNVs from the training dataset II that could not be processed by other predictors.</title>
        </caption>
        <alternatives>
          <graphic id="pone.0192829.t005g" xlink:href="pone.0192829.t005"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Score</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Missing predictions</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">MLP</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">sdAE</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="1" colspan="1">Eigen</td>
                <td align="center" rowspan="1" colspan="1">1175</td>
                <td align="center" rowspan="1" colspan="1">0.97 (0.94–0.98)</td>
                <td align="center" rowspan="1" colspan="1">0.95 (0.92–0.97)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">FATHMM</td>
                <td align="center" rowspan="1" colspan="1">898</td>
                <td align="center" rowspan="1" colspan="1">0.80 (0.75–0.85)</td>
                <td align="center" rowspan="1" colspan="1">0.34 (0.28–0.42)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">LRT</td>
                <td align="center" rowspan="1" colspan="1">1772</td>
                <td align="center" rowspan="1" colspan="1">0.94 (0.93–0.95)</td>
                <td align="center" rowspan="1" colspan="1">0.80 (0.77–0.84)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaLR</td>
                <td align="center" rowspan="1" colspan="1">118</td>
                <td align="center" rowspan="1" colspan="1">0.76 (0.68–0.85)</td>
                <td align="center" rowspan="1" colspan="1">0.59 (0.49–0.70)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaSVM</td>
                <td align="center" rowspan="1" colspan="1">118</td>
                <td align="center" rowspan="1" colspan="1">0.76 (0.67–0.85)</td>
                <td align="center" rowspan="1" colspan="1">0.59 (0.48–0.69)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MutationAssessor</td>
                <td align="center" rowspan="1" colspan="1">843</td>
                <td align="center" rowspan="1" colspan="1">0.90 (0.88–0.92)</td>
                <td align="center" rowspan="1" colspan="1">0.72 (0.67–0.77)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PROVEAN</td>
                <td align="center" rowspan="1" colspan="1">426</td>
                <td align="center" rowspan="1" colspan="1">0.85 (0.81–0.90)</td>
                <td align="center" rowspan="1" colspan="1">0.47 (0.39–0.55)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HDIV</td>
                <td align="center" rowspan="1" colspan="1">286</td>
                <td align="center" rowspan="1" colspan="1">0.85 (0.80–0.89)</td>
                <td align="center" rowspan="1" colspan="1">0.53 (0.46–0.60)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HVAR</td>
                <td align="center" rowspan="1" colspan="1">286</td>
                <td align="center" rowspan="1" colspan="1">0.84 (0.80–0.89)</td>
                <td align="center" rowspan="1" colspan="1">0.53 (0.45–0.61)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SIFT</td>
                <td align="center" rowspan="1" colspan="1">514</td>
                <td align="center" rowspan="1" colspan="1">0.89 (0.85–0.92)</td>
                <td align="center" rowspan="1" colspan="1">0.59 (0.52–0.66)</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <table-wrap id="pone.0192829.t006" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0192829.t006</object-id>
        <label>Table 6</label>
        <caption>
          <title>MLP’s and sdAE’s average precision with 95% confidence intervals evaluated on subsets of SNVs from the training dataset II that could not be processed by other predictors.</title>
        </caption>
        <alternatives>
          <graphic id="pone.0192829.t006g" xlink:href="pone.0192829.t006"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Score</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Number predictions</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">MLP</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">sdAE</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="1" colspan="1">Eigen</td>
                <td align="center" rowspan="1" colspan="1">1175</td>
                <td align="center" rowspan="1" colspan="1">1.00 (0.99–1.00)</td>
                <td align="center" rowspan="1" colspan="1">0.99 (0.99–1.00)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">FATHMM</td>
                <td align="center" rowspan="1" colspan="1">898</td>
                <td align="center" rowspan="1" colspan="1">0.52 (0.42–0.62)</td>
                <td align="center" rowspan="1" colspan="1">0.18 (0.11–0.25)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">LRT</td>
                <td align="center" rowspan="1" colspan="1">1772</td>
                <td align="center" rowspan="1" colspan="1">0.83 (0.79–0.87)</td>
                <td align="center" rowspan="1" colspan="1">0.74 (0.69–0.78)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaLR</td>
                <td align="center" rowspan="1" colspan="1">118</td>
                <td align="center" rowspan="1" colspan="1">0.81 (0.70–0.90)</td>
                <td align="center" rowspan="1" colspan="1">0.63 (0.51–0.75)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaSVM</td>
                <td align="center" rowspan="1" colspan="1">118</td>
                <td align="center" rowspan="1" colspan="1">0.81 (0.71–0.90)</td>
                <td align="center" rowspan="1" colspan="1">0.63 (0.51–0.75)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MutationAssessor</td>
                <td align="center" rowspan="1" colspan="1">843</td>
                <td align="center" rowspan="1" colspan="1">0.83 (0.78–0.87)</td>
                <td align="center" rowspan="1" colspan="1">0.72 (0.67–0.77)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PROVEAN</td>
                <td align="center" rowspan="1" colspan="1">426</td>
                <td align="center" rowspan="1" colspan="1">0.69 (0.59–0.78)</td>
                <td align="center" rowspan="1" colspan="1">0.41 (0.31–0.50)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HDIV</td>
                <td align="center" rowspan="1" colspan="1">286</td>
                <td align="center" rowspan="1" colspan="1">0.82 (0.75–0.87)</td>
                <td align="center" rowspan="1" colspan="1">0.60 (0.52–0.68)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HVAR</td>
                <td align="center" rowspan="1" colspan="1">286</td>
                <td align="center" rowspan="1" colspan="1">0.81 (0.74–0.87)</td>
                <td align="center" rowspan="1" colspan="1">0.60 (0.52–0.68)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SIFT</td>
                <td align="center" rowspan="1" colspan="1">514</td>
                <td align="center" rowspan="1" colspan="1">0.79 (0.72–0.86)</td>
                <td align="center" rowspan="1" colspan="1">0.59 (0.51–0.66)</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec id="sec014">
      <title>GO term enrichment</title>
      <p>We measured generalisability in terms of the average prediction success rate across all terms and the number of GO terms significantly enriched in either the subset of correctly classified or misclassified variations (<xref ref-type="table" rid="pone.0192829.t007">Table 7</xref>). Once again, the MLP outperformed other predictors, yielding the highest average success rate. The five highest-scoring predictors (MLP, MetaLR, sdAE, MetaSVM and FATHMM) show identical performance in terms of the number of significantly enriched terms −139, none of which were enriched in the misclassified subset (FDR 5%).</p>
      <table-wrap id="pone.0192829.t007" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0192829.t007</object-id>
        <label>Table 7</label>
        <caption>
          <title>Average classification success rate across GO terms and the number of significantly enriched terms.</title>
          <p>The number of terms enriched in the misclassified subset is given in parentheses.</p>
        </caption>
        <alternatives>
          <graphic id="pone.0192829.t007g" xlink:href="pone.0192829.t007"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Score</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Average success rate</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Significantly enriched</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>MLP</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.864</td>
                <td align="center" rowspan="1" colspan="1">139 (0)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaLR</td>
                <td align="char" char="." rowspan="1" colspan="1">0.857</td>
                <td align="center" rowspan="1" colspan="1">139 (0)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>sdAE</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.850</td>
                <td align="center" rowspan="1" colspan="1">139 (0)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaSVM</td>
                <td align="char" char="." rowspan="1" colspan="1">0.849</td>
                <td align="center" rowspan="1" colspan="1">139 (0)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">FATHMM</td>
                <td align="char" char="." rowspan="1" colspan="1">0.828</td>
                <td align="center" rowspan="1" colspan="1">139 (0)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MutationAssessor</td>
                <td align="char" char="." rowspan="1" colspan="1">0.725</td>
                <td align="center" rowspan="1" colspan="1">136 (0)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HVAR</td>
                <td align="char" char="." rowspan="1" colspan="1">0.720</td>
                <td align="center" rowspan="1" colspan="1">134 (0)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Eigen</td>
                <td align="char" char="." rowspan="1" colspan="1">0.720</td>
                <td align="center" rowspan="1" colspan="1">134 (0)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PROVEAN</td>
                <td align="char" char="." rowspan="1" colspan="1">0.714</td>
                <td align="center" rowspan="1" colspan="1">133 (1)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SIFT</td>
                <td align="char" char="." rowspan="1" colspan="1">0.713</td>
                <td align="center" rowspan="1" colspan="1">134 (1)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HDIV</td>
                <td align="char" char="." rowspan="1" colspan="1">0.711</td>
                <td align="center" rowspan="1" colspan="1">135 (0)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">CADD</td>
                <td align="char" char="." rowspan="1" colspan="1">0.707</td>
                <td align="center" rowspan="1" colspan="1">131 (1)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MutationTaster</td>
                <td align="char" char="." rowspan="1" colspan="1">0.681</td>
                <td align="center" rowspan="1" colspan="1">127 (2)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">phyloP 100-way</td>
                <td align="char" char="." rowspan="1" colspan="1">0.671</td>
                <td align="center" rowspan="1" colspan="1">126 (2)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">DANN</td>
                <td align="char" char="." rowspan="1" colspan="1">0.668</td>
                <td align="center" rowspan="1" colspan="1">126 (1)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">LRT</td>
                <td align="char" char="." rowspan="1" colspan="1">0.665</td>
                <td align="center" rowspan="1" colspan="1">122 (3)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SiPhy 29-way</td>
                <td align="char" char="." rowspan="1" colspan="1">0.642</td>
                <td align="center" rowspan="1" colspan="1">120 (6)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">phastCons 100-way</td>
                <td align="char" char="." rowspan="1" colspan="1">0.631</td>
                <td align="center" rowspan="1" colspan="1">115 (10)</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">GERP++</td>
                <td align="char" char="." rowspan="1" colspan="1">0.615</td>
                <td align="center" rowspan="1" colspan="1">111 (14)</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>Diving deeper into the misclassified subset, we examined term enrichment in its false-positive (FP) and false-negative (FN) sections (<xref ref-type="table" rid="pone.0192829.t008">Table 8</xref>). Here the MLP proved to be the most balanced classifier, that is it doesn’t strongly gravitate towards making neither FN nor FP errors.</p>
      <table-wrap id="pone.0192829.t008" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0192829.t008</object-id>
        <label>Table 8</label>
        <caption>
          <title>Average deviation of FP/FN rates from equilibrium (imbalance) across all GO terms in the misclassified subsection of the test dataset II and the number of terms significantly enriched in either the FP or FN subsets of the misclassified variations.</title>
        </caption>
        <alternatives>
          <graphic id="pone.0192829.t008g" xlink:href="pone.0192829.t008"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Score</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Average imbalance</th>
                <th align="center" style="border-bottom:thick" rowspan="1" colspan="1">Significantly enriched</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>MLP</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.130</td>
                <td align="center" rowspan="1" colspan="1">70</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">FATHMM</td>
                <td align="char" char="." rowspan="1" colspan="1">0.131</td>
                <td align="center" rowspan="1" colspan="1">81</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HVAR</td>
                <td align="char" char="." rowspan="1" colspan="1">0.137</td>
                <td align="center" rowspan="1" colspan="1">93</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SIFT</td>
                <td align="char" char="." rowspan="1" colspan="1">0.138</td>
                <td align="center" rowspan="1" colspan="1">87</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">
                  <bold>sdAE</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">0.143</td>
                <td align="center" rowspan="1" colspan="1">82</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaLR</td>
                <td align="char" char="." rowspan="1" colspan="1">0.145</td>
                <td align="center" rowspan="1" colspan="1">78</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MetaSVM</td>
                <td align="char" char="." rowspan="1" colspan="1">0.147</td>
                <td align="center" rowspan="1" colspan="1">85</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PolyPhen HDIV</td>
                <td align="char" char="." rowspan="1" colspan="1">0.153</td>
                <td align="center" rowspan="1" colspan="1">100</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MutationAssessor</td>
                <td align="char" char="." rowspan="1" colspan="1">0.161</td>
                <td align="center" rowspan="1" colspan="1">99</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">Eigen</td>
                <td align="char" char="." rowspan="1" colspan="1">0.169</td>
                <td align="center" rowspan="1" colspan="1">104</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">PROVEAN</td>
                <td align="char" char="." rowspan="1" colspan="1">0.170</td>
                <td align="center" rowspan="1" colspan="1">100</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">phyloP 100-way</td>
                <td align="char" char="." rowspan="1" colspan="1">0.183</td>
                <td align="center" rowspan="1" colspan="1">113</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">LRT</td>
                <td align="char" char="." rowspan="1" colspan="1">0.200</td>
                <td align="center" rowspan="1" colspan="1">116</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">CADD</td>
                <td align="char" char="." rowspan="1" colspan="1">0.213</td>
                <td align="center" rowspan="1" colspan="1">122</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">DANN</td>
                <td align="char" char="." rowspan="1" colspan="1">0.223</td>
                <td align="center" rowspan="1" colspan="1">123</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">SiPhy 29-way</td>
                <td align="char" char="." rowspan="1" colspan="1">0.251</td>
                <td align="center" rowspan="1" colspan="1">128</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">MutationTaster</td>
                <td align="char" char="." rowspan="1" colspan="1">0.266</td>
                <td align="center" rowspan="1" colspan="1">129</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">phastCons 100-way</td>
                <td align="char" char="." rowspan="1" colspan="1">0.291</td>
                <td align="center" rowspan="1" colspan="1">135</td>
              </tr>
              <tr>
                <td align="center" rowspan="1" colspan="1">GERP++</td>
                <td align="char" char="." rowspan="1" colspan="1">0.310</td>
                <td align="center" rowspan="1" colspan="1">136</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec id="sec015">
      <title>Supervised vs. Unsupervised</title>
      <p>Some researchers argue that unsupervised inference can help improve prediction quality, which can be hindered by poor coverage of the variome with reliable information on phenotypic categorisation [<xref rid="pone.0192829.ref021" ref-type="bibr">21</xref>]. CADD is probably the most noticeable implementation of this approach. Since multiple studies, including this one, have shown that CADD performs significantly worse than most of its purely supervised rivals, it becomes unclear, whether there is any actual benefit of unsupervised learning in case of nsSNV classification. Most importantly, more complicated tools, such as DANN and Eigen, based on the combination of CADD’s inference model and deep learning, actually performed worse than CADD itself on our tests. Some may argue that this lack of precision is due to the fact that CADD, DANN and Eigen were developed with more attention paid to the variation in noncoding regions. Yet, that doesn’t explain why our own hybrid semi-supervised model, which was absolutely focused on the exome, didn’t beat its purely supervised sibling (though it did outperform most of the other scores we tested). We believe that a lot more research should be invested into unsupervised learning to uncover its full potential (or the lack thereof).</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec016">
    <title>Conclusion</title>
    <p>Here we successfully explored the possibility to efficiently utilise deep learning models to discriminate neutral and likely pathogenic nsSNVs. We tried to use two distinct architectures, one of which made use of unsupervised learning, and optimised hyper-parameters using a genetic algorithm. Although this work was not conceived as a tool comparison, but rather an exploratory study, our results proved that even relatively simple modern neural networks significantly improve prediction accuracy of a deleteriousness prediction tool. Though our semi-supervised model didn’t outperform its purely supervised sibling, it bested most of the scores we tested in the study. Our supervised model showed superior average accuracy as compared to other scores, especially other deep learning-based tools. We have created an open-access web-server so that others could easily access our MLP classifier: <ext-link ext-link-type="uri" xlink:href="http://score.generesearch.ru/services/badmut/">http://score.generesearch.ru/services/badmut/</ext-link>. Although this model proved to perform better than any other tool we compared it to in terms of various performance indicators, effective coverage and generalisability, we believe a lot more more should be done to uncover the real potential of unsupervised and semi-supervised models.</p>
  </sec>
  <sec sec-type="supplementary-material" id="sec017">
    <title>Supporting information</title>
    <supplementary-material content-type="local-data" id="pone.0192829.s001">
      <label>S1 File</label>
      <caption>
        <title>Supervised training dataset.</title>
        <p>The final supervised dataset used for training and fine-tuning.</p>
        <p>(GZ)</p>
      </caption>
      <media xlink:href="pone.0192829.s001.gz">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pone.0192829.s002">
      <label>S2 File</label>
      <caption>
        <title>Additional benchmarks.</title>
        <p>Multiple additional performance indicators calculated on a range of binary cutoff thresholds.</p>
        <p>(TGZ)</p>
      </caption>
      <media xlink:href="pone.0192829.s002.tgz">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pone.0192829.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Ng</surname><given-names>SB</given-names></name>, <name><surname>Nickerson</surname><given-names>DA</given-names></name>, <name><surname>Bamshad</surname><given-names>MJ</given-names></name>, <name><surname>Shendure</surname><given-names>J</given-names></name>. <article-title>Massively parallel sequencing and rare disease</article-title>. <source>Human Molecular Genetics</source>. <year>2010</year>;<volume>19</volume>(<issue>R2</issue>):<fpage>R119</fpage>–<lpage>R124</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/hmg/ddq390">10.1093/hmg/ddq390</ext-link></comment><?supplied-pmid 20846941?><pub-id pub-id-type="pmid">20846941</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Reva</surname><given-names>B</given-names></name>, <name><surname>Antipin</surname><given-names>Y</given-names></name>, <name><surname>Sander</surname><given-names>C</given-names></name>. <article-title>Predicting the functional impact of protein mutations: Application to cancer genomics</article-title>. <source>Nucleic Acids Research</source>. <year>2011</year>;<volume>39</volume>(<issue>17</issue>):<fpage>37</fpage>–<lpage>43</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkr407">10.1093/nar/gkr407</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Ng</surname><given-names>PC</given-names></name>, <name><surname>Henikoff</surname><given-names>S</given-names></name>. <article-title>Predicting the Effects of Amino Acid Substitutions on Protein Function</article-title>. <source>Annu Rev Genom Hum Genet</source>. <year>2006</year>;<volume>7</volume>(<issue>1</issue>):<fpage>61</fpage>–<lpage>80</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev.genom.7.080505.115630">10.1146/annurev.genom.7.080505.115630</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Thusberg</surname><given-names>J</given-names></name>, <name><surname>Vihinen</surname><given-names>M</given-names></name>. <article-title>Pathogenic or not? And if so, then how? Studying the effects of missense mutations using bioinformatics methods</article-title>. <source>Human Mutation</source>. <year>2009</year>;<volume>30</volume>(<issue>5</issue>):<fpage>703</fpage>–<lpage>714</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/humu.20938">10.1002/humu.20938</ext-link></comment><?supplied-pmid 19267389?><pub-id pub-id-type="pmid">19267389</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Cooper</surname><given-names>GM</given-names></name>, <name><surname>Goode</surname><given-names>DL</given-names></name>, <name><surname>Ng</surname><given-names>SB</given-names></name>, <name><surname>Sidow</surname><given-names>A</given-names></name>, <name><surname>Bamshad</surname><given-names>MJ</given-names></name>, <name><surname>Shendure</surname><given-names>J</given-names></name>, <etal>et al</etal><article-title>Single-nucleotide evolutionary constraint scores highlight disease-causing mutations</article-title>. <source>Nature Methods</source>. <year>2010</year>;<volume>7</volume>(<issue>4</issue>):<fpage>250</fpage>–<lpage>251</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nmeth0410-250">10.1038/nmeth0410-250</ext-link></comment><?supplied-pmid 20354513?><pub-id pub-id-type="pmid">20354513</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Pollard</surname><given-names>KS</given-names></name>, <name><surname>Hubisz</surname><given-names>MJ</given-names></name>, <name><surname>Rosenbloom</surname><given-names>KR</given-names></name>, <name><surname>Siepel</surname><given-names>A</given-names></name>. <article-title>Detection of nonneutral substitution rates on mammalian phylogenies</article-title>. <source>Genome Research</source>. <year>2010</year>;<volume>20</volume>(<issue>1</issue>):<fpage>110</fpage>–<lpage>121</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/gr.097857.109">10.1101/gr.097857.109</ext-link></comment><?supplied-pmid 19858363?><pub-id pub-id-type="pmid">19858363</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>X</given-names></name>, <name><surname>Jian</surname><given-names>X</given-names></name>, <name><surname>Boerwinkle</surname><given-names>E</given-names></name>. <article-title>dbNSFP: A lightweight database of human nonsynonymous SNPs and their functional predictions</article-title>. <source>Human Mutation</source>. <year>2011</year>;<volume>32</volume>(<issue>8</issue>):<fpage>894</fpage>–<lpage>899</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/humu.21517">10.1002/humu.21517</ext-link></comment><?supplied-pmid 21520341?><pub-id pub-id-type="pmid">21520341</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>X</given-names></name>, <name><surname>Jian</surname><given-names>X</given-names></name>, <name><surname>Boerwinkle</surname><given-names>E</given-names></name>. <article-title>dbNSFP v2.0: A database of human non-synonymous SNVs and their functional predictions and annotations</article-title>. <source>Human Mutation</source>. <year>2013</year>;<volume>34</volume>(<issue>9</issue>):<fpage>1</fpage>–<lpage>14</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/humu.22376">10.1002/humu.22376</ext-link></comment><pub-id pub-id-type="pmid">22837109</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>X</given-names></name>, <name><surname>Wu</surname><given-names>C</given-names></name>, <name><surname>Li</surname><given-names>C</given-names></name>, <name><surname>Boerwinkle</surname><given-names>E</given-names></name>. <article-title>dbNSFP v3.0: A One-Stop Database of Functional Predictions and Annotations for Human Nonsynonymous and Splice-Site SNVs</article-title>. <source>Human Mutation</source>. <year>2016</year>;<volume>37</volume>(<issue>3</issue>):<fpage>235</fpage>–<lpage>241</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/humu.22932">10.1002/humu.22932</ext-link></comment><?supplied-pmid 26555599?><pub-id pub-id-type="pmid">26555599</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Green</surname><given-names>RC</given-names></name>, <name><surname>Berg</surname><given-names>JS</given-names></name>, <name><surname>Grody</surname><given-names>WW</given-names></name>, <name><surname>Kalia</surname><given-names>SS</given-names></name>, <name><surname>Korf</surname><given-names>BR</given-names></name>, <name><surname>Martin</surname><given-names>CL</given-names></name>, <etal>et al</etal><article-title>ACMG recommendations for reporting of incidental findings in clinical exome and genome sequencing</article-title>. <source>Genetics in medicine: official journal of the American College of Medical Genetics</source>. <year>2013</year>;<volume>15</volume>(<issue>7</issue>):<fpage>565</fpage>–<lpage>74</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/gim.2013.73">10.1038/gim.2013.73</ext-link></comment><pub-id pub-id-type="pmid">23788249</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Shihab</surname><given-names>Ha</given-names></name>, <name><surname>Gough</surname><given-names>J</given-names></name>, <name><surname>Cooper</surname><given-names>DN</given-names></name>, <name><surname>Stenson</surname><given-names>PD</given-names></name>, <name><surname>Barker</surname><given-names>GLa</given-names></name>, <name><surname>Edwards</surname><given-names>KJ</given-names></name>, <etal>et al</etal><article-title>Predicting the Functional, Molecular, and Phenotypic Consequences of Amino Acid Substitutions using Hidden Markov Models</article-title>. <source>Human Mutation</source>. <year>2013</year>;<volume>34</volume>(<issue>1</issue>):<fpage>57</fpage>–<lpage>65</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/humu.22225">10.1002/humu.22225</ext-link></comment><?supplied-pmid 23033316?><pub-id pub-id-type="pmid">23033316</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>González-Pérez</surname><given-names>A</given-names></name>, <name><surname>López-Bigas</surname><given-names>N</given-names></name>. <article-title>Improving the Assessment of the Outcome of Nonsynonymous SNVs with a Consensus Deleteriousness Score, Condel</article-title>. <source>The American Journal of Human Genetics</source>. <year>2011</year>;<volume>88</volume>(<issue>4</issue>):<fpage>440</fpage>–<lpage>449</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.ajhg.2011.03.004">10.1016/j.ajhg.2011.03.004</ext-link></comment><?supplied-pmid 21457909?><pub-id pub-id-type="pmid">21457909</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Thomas</surname><given-names>PD</given-names></name>, <name><surname>Campbell</surname><given-names>MJ</given-names></name>, <name><surname>Kejariwal</surname><given-names>A</given-names></name>, <name><surname>Mi</surname><given-names>H</given-names></name>, <name><surname>Karlak</surname><given-names>B</given-names></name>, <name><surname>Daverman</surname><given-names>R</given-names></name>, <etal>et al</etal><article-title>PANTHER: A library of protein families and subfamilies indexed by function</article-title>. <source>Genome Research</source>. <year>2003</year>;<volume>13</volume>(<issue>9</issue>):<fpage>2129</fpage>–<lpage>2141</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/gr.772403">10.1101/gr.772403</ext-link></comment><?supplied-pmid 12952881?><pub-id pub-id-type="pmid">12952881</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Capriotti</surname><given-names>E</given-names></name>, <name><surname>Calabrese</surname><given-names>R</given-names></name>, <name><surname>Casadio</surname><given-names>R</given-names></name>. <article-title>Predicting the insurgence of human genetic diseases associated to single point protein mutations with support vector machines and evolutionary information</article-title>. <source>Bioinformatics</source>. <year>2006</year>;<volume>22</volume>(<issue>22</issue>):<fpage>2729</fpage>–<lpage>2734</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btl423">10.1093/bioinformatics/btl423</ext-link></comment><?supplied-pmid 16895930?><pub-id pub-id-type="pmid">16895930</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Ng</surname><given-names>PC</given-names></name>, <name><surname>Henikoff</surname><given-names>S</given-names></name>. <article-title>SIFT: Predicting amino acid changes that affect protein function</article-title>. <source>Nucleic Acids Research</source>. <year>2003</year>;<volume>31</volume>(<issue>13</issue>):<fpage>3812</fpage>–<lpage>3814</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkg509">10.1093/nar/gkg509</ext-link></comment><?supplied-pmid 12824425?><pub-id pub-id-type="pmid">12824425</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Capriotti</surname><given-names>E</given-names></name>, <name><surname>Calabrese</surname><given-names>R</given-names></name>, <name><surname>Fariselli</surname><given-names>P</given-names></name>, <name><surname>Martelli</surname><given-names>PL</given-names></name>, <name><surname>Altman</surname><given-names>RB</given-names></name>, <name><surname>Casadio</surname><given-names>R</given-names></name>. <article-title>WS-SNPs&amp;GO: a web server for predicting the deleterious effect of human protein variants using functional annotation</article-title>. <source>BMC genomics</source>. <year>2013</year>;<volume>14</volume> Suppl 3(<issue>Suppl 3</issue>):<fpage>S6</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/1471-2164-14-S3-S6">10.1186/1471-2164-14-S3-S6</ext-link></comment>
<?supplied-pmid 23819482?><pub-id pub-id-type="pmid">23819482</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Schwarz</surname><given-names>JM</given-names></name>, <name><surname>Rödelsperger</surname><given-names>C</given-names></name>, <name><surname>Schuelke</surname><given-names>M</given-names></name>, <name><surname>Seelow</surname><given-names>D</given-names></name>. <article-title>MutationTaster evaluates disease-causing potential of sequence alterations</article-title>. <source>Nature Publishing Group</source>. <year>2010</year>;<volume>7</volume>(<issue>8</issue>):<fpage>575</fpage>–<lpage>576</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0192829.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>B</given-names></name>, <name><surname>Krishnan</surname><given-names>VG</given-names></name>, <name><surname>Mort</surname><given-names>ME</given-names></name>, <name><surname>Xin</surname><given-names>F</given-names></name>, <name><surname>Kamati</surname><given-names>KK</given-names></name>, <name><surname>Cooper</surname><given-names>DN</given-names></name>, <etal>et al</etal><article-title>Automated inference of molecular mechanisms of disease from amino acid substitutions</article-title>. <source>Bioinformatics</source>. <year>2009</year>;<volume>25</volume>(<issue>21</issue>):<fpage>2744</fpage>–<lpage>2750</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btp528">10.1093/bioinformatics/btp528</ext-link></comment><?supplied-pmid 19734154?><pub-id pub-id-type="pmid">19734154</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Adzhubei</surname><given-names>IA</given-names></name>, <name><surname>Schmidt</surname><given-names>S</given-names></name>, <name><surname>Peshkin</surname><given-names>L</given-names></name>, <name><surname>Ramensky</surname><given-names>VE</given-names></name>, <name><surname>Gerasimova</surname><given-names>A</given-names></name>, <name><surname>Bork</surname><given-names>P</given-names></name>, <etal>et al</etal><article-title>A method and server for predicting damaging missense mutations</article-title>. <source>Nature Methods</source>. <year>2010</year>;<volume>7</volume>(<issue>4</issue>):<fpage>248</fpage>–<lpage>249</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nmeth0410-248">10.1038/nmeth0410-248</ext-link></comment><?supplied-pmid 20354512?><pub-id pub-id-type="pmid">20354512</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Choi</surname><given-names>Y</given-names></name>, <name><surname>Sims</surname><given-names>GE</given-names></name>, <name><surname>Murphy</surname><given-names>S</given-names></name>, <name><surname>Miller</surname><given-names>JR</given-names></name>, <name><surname>Chan</surname><given-names>AP</given-names></name>. <article-title>Predicting the Functional Effect of Amino Acid Substitutions and Indels</article-title>. <source>PLoS ONE</source>. <year>2012</year>;<volume>7</volume>(<issue>10</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0046688">10.1371/journal.pone.0046688</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Kircher</surname><given-names>M</given-names></name>, <name><surname>Witten</surname><given-names>DM</given-names></name>, <name><surname>Jain</surname><given-names>P</given-names></name>, <name><surname>O’Roak</surname><given-names>BJ</given-names></name>, <name><surname>Cooper</surname><given-names>GM</given-names></name>, <name><surname>Shendure</surname><given-names>J</given-names></name>. <article-title>A general framework for estimating the relative pathogenicity of human genetic variants</article-title>. <source>Nature genetics</source>. <year>2014</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/ng.2892">10.1038/ng.2892</ext-link></comment><?supplied-pmid 24487276?><pub-id pub-id-type="pmid">24487276</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Davydov</surname><given-names>EV</given-names></name>, <name><surname>Goode</surname><given-names>DL</given-names></name>, <name><surname>Sirota</surname><given-names>M</given-names></name>, <name><surname>Cooper</surname><given-names>GM</given-names></name>, <name><surname>Sidow</surname><given-names>A</given-names></name>, <name><surname>Batzoglou</surname><given-names>S</given-names></name>. <article-title>Identifying a High Fraction of the Human Genome to be under Selective Constraint Using GERP++</article-title>. <source>PLoS Comput Biol</source>. <year>2010</year>;<volume>6</volume>(<issue>12</issue>):<fpage>e1001025</fpage><comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1001025">10.1371/journal.pcbi.1001025</ext-link></comment><?supplied-pmid 21152010?><pub-id pub-id-type="pmid">21152010</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Cooper</surname><given-names>GM</given-names></name>. <article-title>Distribution and intensity of constraint in mammalian genomic sequence</article-title>. <source>Genome Research</source>. <year>2005</year>;<volume>15</volume>(<issue>7</issue>):<fpage>901</fpage>–<lpage>913</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/gr.3577405">10.1101/gr.3577405</ext-link></comment><?supplied-pmid 15965027?><pub-id pub-id-type="pmid">15965027</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>Dong</surname><given-names>C</given-names></name>, <name><surname>Wei</surname><given-names>P</given-names></name>, <name><surname>Jian</surname><given-names>X</given-names></name>, <name><surname>Gibbs</surname><given-names>R</given-names></name>, <name><surname>Boerwinkle</surname><given-names>E</given-names></name>, <name><surname>Wang</surname><given-names>K</given-names></name>, <etal>et al</etal><article-title>Comparison and integration of deleteriousness prediction methods for nonsynonymous SNVs in whole exome sequencing studies</article-title>. <source>Human Molecular Genetics</source>. <year>2015</year>;<volume>24</volume>(<issue>8</issue>):<fpage>2125</fpage>–<lpage>2137</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/hmg/ddu733">10.1093/hmg/ddu733</ext-link></comment><?supplied-pmid 25552646?><pub-id pub-id-type="pmid">25552646</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Chun</surname><given-names>S</given-names></name>, <name><surname>Fay</surname><given-names>JC</given-names></name>. <article-title>Identification of deleterious mutations within three human genomes</article-title>. <source>Identification of deleterious mutations within three human genomes</source>. <year>2009</year>; p. <fpage>1553</fpage>–<lpage>1561</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0192829.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Thusberg</surname><given-names>J</given-names></name>, <name><surname>Olatubosun</surname><given-names>A</given-names></name>, <name><surname>Vihinen</surname><given-names>M</given-names></name>. <article-title>Performance of mutation pathogenicity prediction methods on missense variants</article-title>. <source>Human Mutation</source>. <year>2011</year>;<volume>32</volume>(<issue>4</issue>):<fpage>358</fpage>–<lpage>368</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/humu.21445">10.1002/humu.21445</ext-link></comment><?supplied-pmid 21412949?><pub-id pub-id-type="pmid">21412949</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>MX</given-names></name>, <name><surname>Gui</surname><given-names>HS</given-names></name>, <name><surname>Kwan</surname><given-names>JSH</given-names></name>, <name><surname>Bao</surname><given-names>SY</given-names></name>, <name><surname>Sham</surname><given-names>PC</given-names></name>. <article-title>A comprehensive framework for prioritizing variants in exome sequencing studies of Mendelian diseases</article-title>. <source>Nucleic Acids Research</source>. <year>2012</year>;<volume>40</volume>(<issue>7</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkr1257">10.1093/nar/gkr1257</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Wager</surname><given-names>S</given-names></name>, <name><surname>Wang</surname><given-names>S</given-names></name>, <name><surname>Liang</surname><given-names>P</given-names></name>. <article-title>Dropout Training as Adaptive Regularization</article-title>. <source>Nips</source>. <year>2013</year>; p. <fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0192829.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Quang</surname><given-names>D</given-names></name>, <name><surname>Chen</surname><given-names>Y</given-names></name>, <name><surname>Xie</surname><given-names>X</given-names></name>. <article-title>DANN: a deep learning approach for annotating the pathogenicity of genetic variants</article-title>. <source>Bioinformatics (Oxford, England)</source>. <year>2014</year>;<volume>31</volume>(<issue>5</issue>):<fpage>761</fpage>–<lpage>763</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btu703">10.1093/bioinformatics/btu703</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Ionita-Laza</surname><given-names>I</given-names></name>, <name><surname>McCallum</surname><given-names>K</given-names></name>, <name><surname>Xu</surname><given-names>B</given-names></name>, <name><surname>Buxbaum</surname><given-names>JD</given-names></name>. <article-title>A spectral approach integrating functional genomic annotations for coding and noncoding variants</article-title>. <source>Nature Genetics</source>. <year>2016</year>;(November 2015). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/ng.3477">10.1038/ng.3477</ext-link></comment><?supplied-pmid 26727659?><pub-id pub-id-type="pmid">26727659</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Morrison</surname><given-names>AC</given-names></name>, <name><surname>Voorman</surname><given-names>A</given-names></name>, <name><surname>Johnson</surname><given-names>AD</given-names></name>, <name><surname>Liu</surname><given-names>X</given-names></name>, <name><surname>Yu</surname><given-names>J</given-names></name>, <name><surname>Li</surname><given-names>A</given-names></name>, <etal>et al</etal><article-title>Whole-genome sequence–based analysis of high-density lipoprotein cholesterol</article-title>. <source>Nature Genetics</source>. <year>2013</year>;<volume>45</volume>(<issue>8</issue>):<fpage>899</fpage>–<lpage>901</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/ng.2671">10.1038/ng.2671</ext-link></comment><?supplied-pmid 23770607?><pub-id pub-id-type="pmid">23770607</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Hamosh</surname><given-names>A</given-names></name>, <name><surname>Scott</surname><given-names>AF</given-names></name>, <name><surname>Amberger</surname><given-names>JS</given-names></name>, <name><surname>Bocchini</surname><given-names>CA</given-names></name>, <name><surname>McKusick</surname><given-names>VA</given-names></name>. <article-title>Online Mendelian Inheritance in Man (OMIM), a knowledgebase of human genes and genetic disorders</article-title>. <source>Nucleic Acids Research</source>. <year>2005</year>;<volume>33</volume>(<issue>DATABASE ISS.</issue>):<fpage>514</fpage>–<lpage>517</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0192829.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Cingolani</surname><given-names>P</given-names></name>, <name><surname>Platts</surname><given-names>A</given-names></name>, <name><surname>Wang</surname><given-names>LL</given-names></name>, <name><surname>Coon</surname><given-names>M</given-names></name>, <name><surname>Nguyen</surname><given-names>T</given-names></name>, <name><surname>Wang</surname><given-names>L</given-names></name>, <etal>et al</etal><article-title>A program for annotating and predicting the effects of single nucleotide polymorphisms, SnpEff: SNPs in the genome of Drosophila melanogaster strain w 1118; iso-2; iso-3</article-title>. <source>Fly</source>. <year>2012</year>;<volume>6</volume>(<issue>2</issue>):<fpage>80</fpage>–<lpage>92</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.4161/fly.19695">10.4161/fly.19695</ext-link></comment><?supplied-pmid 22728672?><pub-id pub-id-type="pmid">22728672</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0192829.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Sutskever</surname><given-names>I</given-names></name>, <name><surname>Martens</surname><given-names>J</given-names></name>, <name><surname>Dahl</surname><given-names>G</given-names></name>, <name><surname>Hinton</surname><given-names>G</given-names></name>. <article-title>On the importance of initialization and momentum in deep learning</article-title>. <source>Journal of Machine Learning Research (JMLR)</source>. <year>2013</year>;<volume>28</volume>(<issue>2010</issue>):<fpage>1139</fpage>–<lpage>1147</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0192829.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Duchi</surname><given-names>J</given-names></name>, <name><surname>Hazan</surname><given-names>E</given-names></name>, <name><surname>Singer</surname><given-names>Y</given-names></name>. <article-title>Adaptive Subgradient Methods for Online Learning and Stochastic Optimization</article-title>. <source>Journal of Machine Learning Research</source>. <year>2011</year>;<volume>12</volume>:<fpage>2121</fpage>–<lpage>2159</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0192829.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Srivastava</surname><given-names>N</given-names></name>, <name><surname>Hinton</surname><given-names>G</given-names></name>, <name><surname>Krizhevsky</surname><given-names>A</given-names></name>, <name><surname>Sutskever</surname><given-names>I</given-names></name>, <name><surname>Salakhutdinov</surname><given-names>R</given-names></name>. <article-title>Dropout: prevent NN from overfitting</article-title>. <source>Journal of Machine Learning Research</source>. <year>2014</year>;<volume>15</volume>:<fpage>1929</fpage>–<lpage>1958</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0192829.ref037">
      <label>37</label>
      <mixed-citation publication-type="other">Glorot X, Bengio Y. Understanding the difficulty of training deep feedforward neural networks. Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS). 2010; 9: 249–256.</mixed-citation>
    </ref>
    <ref id="pone.0192829.ref038">
      <label>38</label>
      <mixed-citation publication-type="journal"><name><surname>Krizhevsky</surname><given-names>A</given-names></name>, <name><surname>Sutskever</surname><given-names>I</given-names></name>, <name><surname>Hinton</surname><given-names>GE</given-names></name>. <article-title>ImageNet Classification with Deep Convolutional Neural Networks</article-title>. <source>Advances In Neural Information Processing Systems</source>. <year>2012</year>; p. <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0192829.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Gülçehre</surname><given-names>Ç</given-names></name>, <name><surname>Bengio</surname><given-names>Y</given-names></name>. <article-title>Knowledge Matters: Importance of Prior Information for Optimization</article-title>. <source>Journal of Machine Learning Research</source>. <year>2016</year>;<volume>17</volume>(<issue>8</issue>):<fpage>1</fpage>–<lpage>32</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0192829.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>Bergstra</surname><given-names>J</given-names></name>, <name><surname>Bardenet</surname><given-names>R</given-names></name>, <name><surname>Bengio</surname><given-names>Y</given-names></name>, <name><surname>Kegl</surname><given-names>B</given-names></name>. <article-title>Algorithms for Hyper-Parameter Optimization</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2011</year>; p. <fpage>2546</fpage>–<lpage>2554</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0192829.ref041">
      <label>41</label>
      <mixed-citation publication-type="other">Lessmann S, Stahlbock R, Crone SF. Optimizing Hyperparameters of Support Vector Machines by Genetic Algorithms. Proceedings of the 2005 International Conference on Artificial Intelligence (ICAI 2005). 2005; p. 74–82.</mixed-citation>
    </ref>
    <ref id="pone.0192829.ref042">
      <label>42</label>
      <mixed-citation publication-type="other">Chetlur S, Woolley C. cuDNN: Efficient Primitives for Deep Learning. arXiv preprint arXiv: …. 2014; p. 1–9.</mixed-citation>
    </ref>
    <ref id="pone.0192829.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Blake</surname><given-names>JA</given-names></name>, <name><surname>Christie</surname><given-names>KR</given-names></name>, <name><surname>Dolan</surname><given-names>ME</given-names></name>, <name><surname>Drabkin</surname><given-names>HJ</given-names></name>, <name><surname>Hill</surname><given-names>DP</given-names></name>, <name><surname>Ni</surname><given-names>L</given-names></name>, <etal>et al</etal><article-title>Gene ontology consortium: Going forward</article-title>. <source>Nucleic Acids Research</source>. <year>2015</year>;<volume>43</volume>(<issue>D1</issue>):<fpage>D1049</fpage>–<lpage>D1056</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gku1179">10.1093/nar/gku1179</ext-link></comment><pub-id pub-id-type="pmid">25428369</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
