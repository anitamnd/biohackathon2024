<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Archiving and Interchange DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName archivearticle.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName nlm2jats3.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Genet</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Genet</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Genet.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Genetics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1664-8021</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8283820</article-id>
    <article-id pub-id-type="doi">10.3389/fgene.2021.691274</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Genetics</subject>
        <subj-group>
          <subject>Methods</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>ImputEHR: A Visualization Tool of Imputation for the Prediction of Biomedical Data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Zhou</surname>
          <given-names>Yi-Hui</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/490556/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Saghapour</surname>
          <given-names>Ehsan</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/963395/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>Department of Biological Science, North Carolina State University</institution>, <addr-line>Raleigh, NC</addr-line>, <country>United States</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Bioinformatics Research Center, North Carolina State University</institution>, <addr-line>Raleigh, NC</addr-line>, <country>United States</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Guangchuang Yu, Southern Medical University, China</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Khanh N. Q. Le, Taipei Medical University, Taiwan; Hao Zhu, Southern Medical University, China</p>
      </fn>
      <corresp id="c001">*Correspondence: Yi-Hui Zhou <email>yihui_zhou@ncsu.edu</email></corresp>
      <fn fn-type="other" id="fn001">
        <p>This article was submitted to Computational Genomics, a section of the journal Frontiers in Genetics</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>02</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2021</year>
    </pub-date>
    <volume>12</volume>
    <elocation-id>691274</elocation-id>
    <history>
      <date date-type="received">
        <day>06</day>
        <month>4</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>25</day>
        <month>5</month>
        <year>2021</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2021 Zhou and Saghapour.</copyright-statement>
      <copyright-year>2021</copyright-year>
      <copyright-holder>Zhou and Saghapour</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Electronic health records (EHRs) have been widely adopted in recent years, but often include a high proportion of missing data, which can create difficulties in implementing machine learning and other tools of personalized medicine. Completed datasets are preferred for a number of analysis methods, and successful imputation of missing EHR data can improve interpretation and increase our power to predict health outcomes. However, use of the most popular imputation methods mainly require scripting skills, and are implemented using various packages and syntax. Thus, the implementation of a full suite of methods is generally out of reach to all except experienced data scientists. Moreover, imputation is often considered as a separate exercise from exploratory data analysis, but should be considered as art of the data exploration process. We have created a new graphical tool, ImputEHR, that is based on a Python base and allows implementation of a range of simple and sophisticated (e.g., gradient-boosted tree-based and neural network) data imputation approaches. In addition to imputation, the tool enables data exploration for informed decision-making, as well as implementing machine learning prediction tools for response data selected by the user. Although the approach works for any missing data problem, the tool is primarily motivated by problems encountered for EHR and other biomedical data. We illustrate the tool using multiple real datasets, providing performance measures of imputation and downstream predictive analysis.</p>
    </abstract>
    <kwd-group>
      <kwd>electronic health records</kwd>
      <kwd>imputation</kwd>
      <kwd>gradient boosting</kwd>
      <kwd>prediction</kwd>
      <kwd>decision trees</kwd>
    </kwd-group>
    <counts>
      <fig-count count="7"/>
      <table-count count="2"/>
      <equation-count count="0"/>
      <ref-count count="40"/>
      <page-count count="9"/>
      <word-count count="4835"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>1. Introduction</title>
    <p>Recently, hospitals in the United States have made a concerted effort to transition their health records from paper to digital, the proportion of which has dramatically increased, from 9.4% in 2008 to 75.5% in 2014 (Charles et al., <xref rid="B5" ref-type="bibr">2013</xref>). Although we are seeing improvements in the overall quality of EHR-derived datasets, data missingness remains a substantial and unavoidable issue (Chan et al., <xref rid="B4" ref-type="bibr">2010</xref>; Weiskopf and Weng, <xref rid="B37" ref-type="bibr">2013</xref>). Missing EHR data could be caused by a lack of collection or a lack of documentation (Wells et al., <xref rid="B38" ref-type="bibr">2013</xref>), and it could be missing at random or not at random (Hu et al., <xref rid="B14" ref-type="bibr">2017</xref>). Researchers have noted the problems posed by missing data and are developing strategies to address it (Haukoos and Newgard, <xref rid="B12" ref-type="bibr">2007</xref>; Newgard and Haukoos, <xref rid="B24" ref-type="bibr">2007</xref>), as EHR systems become more relevant and adopted worldwide.</p>
    <p>The expectation of collecting real-world data without missingness is unrealistic. Even the most detailed protocols for data collection cannot guarantee that every subject will have a record at each observation. Missing data present a challenge for analysts, as it can introduce a substantial amount of bias, makes the handling and analysis of the data more arduous, and creates reductions in efficiency (Barnard and Meng, <xref rid="B1" ref-type="bibr">1999</xref>). Many standard analysis methods, including regression, are defeated by even a single missing value from among many potential predictors. Thus, it is possible that standard analysis may essentially “throw away” large portions of the data, even though a small fraction of the data may actually be missing. Ultimately, data missingness decreases our ability to discern the deeper structures and relationships underlying the observations, causing a significant negative impact on scientific research (McKnight et al., <xref rid="B23" ref-type="bibr">2007</xref>). Many important scientific and business decisions are based on results from data analyses, and so dealing with missing data in an appropriate manner is recognized as a crucial step.</p>
    <p>The process of data <italic>imputation</italic> (artificially replacing missing data with an estimated value) offers a practical work-around so that many downstream data handling steps become feasible. This process preserves all observations by replacing missing data with an estimated value based on other available information. Once all missing values have been imputed, datasets can then be analyzed using standard techniques for complete data (Gelman and Hill, <xref rid="B10" ref-type="bibr">2006</xref>). Many advanced analysis methods, such as machine learning, require a complete dataset, so imputing missing data enables researchers to apply statistical and computational association methods that would otherwise be unavailable. Missing data imputation methods are considered standard in areas such as genetic association (Schurz et al., <xref rid="B29" ref-type="bibr">2019</xref>) and proteomics (Jin et al., <xref rid="B16" ref-type="bibr">2021</xref>), where correlation structures are strong. For electronic health records, the need for imputation methods have more recently realized (Jazayeri et al., <xref rid="B15" ref-type="bibr">2020</xref>), and the use of imputation shown to improve prediction accuracy (Beaulieu-Jones et al., <xref rid="B2" ref-type="bibr">2017</xref>). However, use of many of these methods requires purpose-built scripting pipelines (Hu et al., <xref rid="B14" ref-type="bibr">2017</xref>), while we aim in this paper to provide a variety of tools using a very simple interface.</p>
    <p>When imputation is performed, issues of bias and correct handling of variability/uncertainty arise (Rubin, <xref rid="B28" ref-type="bibr">2003</xref>), depending on the imputation accuracy. Much of the traditional statistical literature on handling missing data has dealt with likelihood inference for low-dimensional problems (Rubin, <xref rid="B27" ref-type="bibr">1976</xref>), or resampling techniques such as multiple imputation, which can mimic and account for imputation uncertainty. However, our focus here is on the practical impact of imputation for downstream analysis, such as EHR-based prediction of important health measures. For such efforts, the emphasis is placed on the success of machine-learning methods, which themselves may involve penalization techniques and estimation known to be biased. Thus, we consider imputation as a possibly essential pre-processing step to serve a larger goal, and it should be judged accordingly. Machine-learning methods have reached a high degree of sophistication in biology and genomics (Le and Huynh, <xref rid="B19" ref-type="bibr">2019</xref>; Le et al., <xref rid="B20" ref-type="bibr">2019</xref>), but for electronic health records, which tend to be less structured, a variety of approaches must be considered. In this work, we evaluate the effectiveness of various imputation methods on EHR and other real-world datasets, and proposed a practical and fast imputation method as a hybrid of existing methods.</p>
  </sec>
  <sec id="s2">
    <title>2. Datasets</title>
    <sec>
      <title>2.1. MIMIC-III</title>
      <p>The Medical Information Mart for Intensive Care III (MIMIC-III) is a large database comprising de-identified health-related data associated with over 40,000 patients who stayed in ICUs at the Beth Israel Deaconess Medical Center between 2001 and 2012 (Johnson et al., <xref rid="B17" ref-type="bibr">2016</xref>). MIMIC-III is freely available on PhysioNet (<ext-link ext-link-type="uri" xlink:href="https://mimic.physionet.org">https://mimic.physionet.org</ext-link>). The database includes information such as demographics, hourly vital sign measurements, laboratory test results, procedures, medications, caregiver notes, imaging reports, and mortality (including post-hospital discharge).</p>
      <p>MIMIC-III is disseminated as a relational database consisting of 26 tables containing many categorical and continuous features. We extracted ICD-9 codes from the “DIAGNOSES_ICD” table, demographics and discharge time or time of death from the “ADMISSIONS” table, and laboratory measurements from the “LABEVENTS” table with &lt;30% missing, totaling 603 features. ICD-9 is the actual code corresponding to the diagnosis assigned to the patient. However, it is often unclear whether a negative value indicates that the patient does not have a specific code, or the code is truly missing. The laboratory measurements are continuous values for 726 unique items. The missing proportion of laboratory tests can be as high as 90%, which significantly impacts any downstream analysis of these data. Therefore, it is important to study the appropriate missing data imputation methods for laboratory tests.</p>
    </sec>
    <sec>
      <title>2.2. Datasets From the UCI Machine Learning Repository</title>
      <p>The UCI Machine Learning Repository is a collection of datasets that are used by researchers for the empirical analysis of machine learning algorithms (Dua and Graff, <xref rid="B8" ref-type="bibr">2017</xref>). Although these datasets are largely complete, we can effectively evaluate our imputation under complete missing at random assumptions by artificially masking individual observations and recording the imputation accuracy. Datasets are maintained on their website (<ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/index.php">https://archive.ics.uci.edu/ml/index.php</ext-link>). We selected the following four datasets for imputation testing: (1) “Boston,” information for predicting the value of house prices (Harrison and Rubinfeld, <xref rid="B11" ref-type="bibr">1978</xref>); (2) “Spam,” attributes to determine whether e-mails were spam (Cranor and LaMacchia, <xref rid="B7" ref-type="bibr">1998</xref>), (3) “Letter,” character image features to identify a letter of the alphabet (Frey and Slate, <xref rid="B9" ref-type="bibr">1991</xref>), and (4) “Breast Cancer,” numerical features of cell images for tumor diagnosis in 357 malignant and 212 benign samples (Street et al., <xref rid="B32" ref-type="bibr">1993</xref>). These datasets have varying numbers of samples and features, with both continuous and categorical data, as summarized in <xref rid="T1" ref-type="table">Table 1</xref>.</p>
      <table-wrap id="T1" position="float">
        <label>Table 1</label>
        <caption>
          <p>The Boston data have information for predicting the value of house prices; the spam data contain the attributes to determine whether e-mails spam; the letter data have character image features to identify a letter of the alphabet; the breast cancer data gathered the numerical features of cell images for tumor diagnosis.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Dataset</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Download link</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold># Sample</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold># Features</bold>
              </th>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Attribute type</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Boston</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/machine-learning-databases/housing">https://archive.ics.uci.edu/ml/machine-learning-databases/housing</ext-link>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">506</td>
              <td valign="top" align="center" rowspan="1" colspan="1">13</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Both</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Spam</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Spambase">https://archive.ics.uci.edu/ml/datasets/Spambase</ext-link>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">4,601</td>
              <td valign="top" align="center" rowspan="1" colspan="1">57</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Continuous</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Letter</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Letter+Recognition">https://archive.ics.uci.edu/ml/datasets/Letter+Recognition</ext-link>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">20,000</td>
              <td valign="top" align="center" rowspan="1" colspan="1">16</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Categorical</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Breast cancer</td>
              <td valign="top" align="left" rowspan="1" colspan="1">
                <ext-link ext-link-type="uri" xlink:href="https://archieve.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29">https://archieve.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29</ext-link>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">569</td>
              <td valign="top" align="center" rowspan="1" colspan="1">30</td>
              <td valign="top" align="left" rowspan="1" colspan="1">Continuous</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
  </sec>
  <sec sec-type="methods" id="s3">
    <title>3. Methods</title>
    <p>ImputEHR is designed to provide several existing imputation methods in easy-to-use interface, as described below. In addition, we have noted that tree-based imputation has been relatively under-represented, and we propose some novel enhancements here in order to provide effective tree-based imputations with reasonable computational burden. Gradient boosted trees are an effective machine learning algorithm that iteratively combines decision trees in order to make predictions. In Python, we modified the MissForest algorithm (Stekhoven and Bühlmann, <xref rid="B31" ref-type="bibr">2012</xref>), which imputes missing values using random forests (Liaw and Wiener, <xref rid="B21" ref-type="bibr">2002</xref>), by applying the <italic>LightGBM</italic> module, a gradient boosting framework known for its light computational burden and better performance than previous decision tree-based algorithms (Ke et al., <xref rid="B18" ref-type="bibr">2017</xref>), in the <italic>missingpy</italic> Python library for missing data imputation. Pseudocode for the ImputeEHR1 algorithm is shown in <xref rid="T2" ref-type="table">Table 2</xref>. The ImputeEHR2 approach is using the <italic>XGBoost</italic> (Extreme Gradient Boosting) module (Chen et al., <xref rid="B6" ref-type="bibr">2015</xref>), a common boosting algorithm, in the <italic>missingpy</italic> library. The performance of ImputeEHR was validated using MIMIC-III and the four repository datasets.</p>
    <table-wrap id="T2" position="float">
      <label>Table 2</label>
      <caption>
        <p>Pseudocode of the ImputeEHR algorithm.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th valign="top" align="left" rowspan="1" colspan="1">
              <bold>Algorithm: ImputeEHR algorithm</bold>
            </th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">Require: X is <italic>n</italic> × <italic>m</italic>-dimensional data matrix, with stopping criterion γ</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">1. Make initial guess using mean or median imputation for missing values;</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">2. <italic>k</italic> ← <italic>A</italic> sorted indices vector according to t he amount of missing values of</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">column <italic>X</italic>;</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">w.r.t. increasing amount of missing values;</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">3. <bold>While</bold> not γ <bold>do</bold></td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">4.   <inline-formula><mml:math id="M1"><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msubsup><mml:mo>←</mml:mo></mml:math></inline-formula> Store previously imputed matrix;</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">5.   <bold>for</bold> s in k <bold>do</bold></td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">6.      Fit a LightGBM or Xgboost : <inline-formula><mml:math id="M2"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>~</mml:mo><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math></inline-formula>;</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">7.      Predict <inline-formula><mml:math id="M3"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math></inline-formula> using <inline-formula><mml:math id="M4"><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math></inline-formula>;</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">8.      <inline-formula><mml:math id="M5"><mml:msubsup><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msubsup><mml:mo>←</mml:mo></mml:math></inline-formula> update imputed matrix from <inline-formula><mml:math id="M6"><mml:msubsup><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math></inline-formula>;</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">9.   <bold>end for</bold></td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">10.   Update γ</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">11.   <bold>end</bold> while</td>
          </tr>
          <tr>
            <td valign="top" align="left" rowspan="1" colspan="1">12. <bold>Return</bold> Matrix <italic>X</italic>;</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <sec>
      <title>3.1. Imputing Missing Data</title>
      <p>We compared our proposed ImputeEHR1, ImputeEHR2, and five state-of-the-art imputation methods in Python: MissForest, MICE (Buuren and Groothuis-Oudshoorn, <xref rid="B3" ref-type="bibr">2010</xref>), KNNImputer (Troyanskaya et al., <xref rid="B35" ref-type="bibr">2001</xref>), SoftImpute (Mazumder et al., <xref rid="B22" ref-type="bibr">2010</xref>), and GAIN (Yoon et al., <xref rid="B39" ref-type="bibr">2018</xref>). In addition, we also performed simple feature-mean and feature-median replacement as the most basic and simple imputation method. KNNImputer is based on k-nearest neighbors algorithm. GAIN adapts the generative adversarial nets framework. The MICE and SoftImpute methods are implemented in the <italic>fancyimpute</italic> Python library. SoftImpute uses an iterative soft-thresholded SVD algorithm and MICE uses chained equations to impute missing values. We used default parameter settings for each method, and parameters for the two ImputeEHR methods are listed in <xref ref-type="supplementary-material" rid="SM1">Supplementary Table 1</xref>.</p>
      <p>In each dataset, we generated missing data (missing completely at random), with rates from 10 to 90% in increments of 10% by randomly removing data and ran the imputation methods. The Root Mean Squared Error (RMSE) was then calculated at each missingness rate in comparison of the values between the real and imputed data. We ran 10 iterations in order to obtain average RMSEs.</p>
      <p><xref ref-type="supplementary-material" rid="SM1">Supplementary Tables 2</xref>–<xref ref-type="supplementary-material" rid="SM1">5</xref> show the average RMSEs for each dataset, with the lowest RMSE at each missingness rate highlighted. Overall, our proposed method significantly outperforms all of the state-of-the-art models. ImputeEHR has the lowest RMSE in 24 out of a possible 36 comparisons, followed by MICE and MissForest methods having 6 and 3, respectively.</p>
    </sec>
    <sec>
      <title>3.2. Testing Runtimes Between Methods</title>
      <p>We evaluated the speeds of ImputeEHR1, ImputeEHR2, and MissForest method, since they are each tree-based learning algorithms, using the <italic>scikit-learn</italic> Python library (Pedregosa et al., <xref rid="B26" ref-type="bibr">2011</xref>). We set the number of trees at 100, and used default values for the remaining parameter settings. <xref ref-type="fig" rid="F1">Figure 1</xref> shows the runtimes by missingness rate in each dataset. Our experiments show that both ImputeEHR1 and ImputeEHR2 can accelerate the imputation process 20–25 times faster than MissForest while achieving lower RMSEs. Moreover, ImputeEHR1 is faster than ImputeEHR2 for the largest dataset. We performed this experiment on a desktop computer with Windows 10, Intel(R) Xenon CPU E5-2687W v4@3.00 GHz CPU, 128 GB RAM and GeForce GTX 1080, 8 GB.</p>
      <fig id="F1" position="float">
        <label>Figure 1</label>
        <caption>
          <p>Running time of ImputeEHR1 (blue), MissForest (orange), and ImputeEHR2 (gray) for each dataset.</p>
        </caption>
        <graphic xlink:href="fgene-12-691274-g0001"/>
      </fig>
    </sec>
    <sec>
      <title>3.3. Evaluating Predictive Performance for a Variable of Interest, After Imputation</title>
      <p>We attempted to predict the mortality for ICU patients in the MIMIC-III database. <xref ref-type="fig" rid="F2">Figure 2</xref> provides an illustration of our pipeline. First, we aggregated the laboratory tests in the “LABEVENTS” table by averaging the values taken within the first 24 h of a patient's first admission to ICU. After removing laboratory tests which are &gt;70% missing, 64 items remained. Then, we selected patients with complete records for the 64 laboratory tests, resulting in 714 patients. So our filtered “LABEVENTS” data have dimension 714 patients × 64 laboratory tests, which we used as input for each imputation method.</p>
      <fig id="F2" position="float">
        <label>Figure 2</label>
        <caption>
          <p>Our pipeline of the MIMIC-III data imputation and prediction.</p>
        </caption>
        <graphic xlink:href="fgene-12-691274-g0002"/>
      </fig>
      <p>Then, we combined the imputed “LABEVENTS” data with the ICD-9 codes from the “DIAGNOSIS_ICD” table and the demographics and mortality outcome from the “ADMISSIONS” table into a model matrix and applied lasso regression (Tibshirani, <xref rid="B34" ref-type="bibr">1996</xref>) with five-fold cross-validation. This process involves randomly splitting the samples into five groups, keeping four groups as a training set, so the model can predict the outcomes for samples in the fifth group. This process was run five times so outcomes are predicted in all samples. The area under the curve (AUC) is the metric we used to compare the predicted vs. the actual outcomes. The ImputeEHR method has the highest AUC 0.91, and the tree-based algorithms perform better than other methods. Our pipeline provides the highest prediction accuracy comparing the historical mortality prediction in the literature (Sharafoddini et al., <xref rid="B30" ref-type="bibr">2019</xref>), which reached the best AUC 0.80 (<xref ref-type="fig" rid="F3">Figure 3</xref>). Both receiver operating characteristic curve and precision recall curve show that our pipeline provides the best prediction of mortality.</p>
      <fig id="F3" position="float">
        <label>Figure 3</label>
        <caption>
          <p><bold>(Left)</bold> Receiver operating characteristic curve (ROC) comparison between our pipeline and the method (Sharafoddini et al., <xref rid="B30" ref-type="bibr">2019</xref>) on the mortality prediction of the MIMIC-III data. <bold>(Right)</bold> Precision recall curve comparison.</p>
        </caption>
        <graphic xlink:href="fgene-12-691274-g0003"/>
      </fig>
    </sec>
  </sec>
  <sec id="s4">
    <title>4. Web Application</title>
    <p>The web application (ImputEHR app), available as a scikit-learn package in Python, allows users to apply our pre-processing, feature engineering, and prediction methods on their dataset, and to visualize the results. Below we briefly describe the six major components of the web app, illustrated in <xref ref-type="fig" rid="F4">Figure 4</xref>, and show its capabilities by presenting results of our implementation, using the “Breast Cancer” dataset from the UC Irvine Machine Learning Repository as an example.</p>
    <fig id="F4" position="float">
      <label>Figure 4</label>
      <caption>
        <p>Illustration of the web app for visualization.</p>
      </caption>
      <graphic xlink:href="fgene-12-691274-g0004"/>
    </fig>
    <sec>
      <title>4.1. Percentage of Missing Rate and Correlation Features Information</title>
      <p>Users can obtain initial information about the missing rates of each feature in their dataset. <xref ref-type="supplementary-material" rid="SM1">Supplementary Figure 1</xref> shows the percentage of missing values in our example. Since the breast cancer dataset in <xref rid="T1" ref-type="table">Table 1</xref> (Street et al., <xref rid="B32" ref-type="bibr">1993</xref>) does not have missing values, we randomly set 35–45% of the values as missing and continue to use it as the toy example for our ImputEHR app.</p>
      <p>In addition, the app has the option for users to plot the correlation between any two features (factors). It also helps the users to decide if they need to include these factors that might be highly correlated with each. If the dataset has missing values, users can show the scatterplot before imputing, removing the missing values. Three parameters to better visualize the scatterplot are the color, size, and clarity of the data points (<xref ref-type="supplementary-material" rid="SM1">Supplementary Figure 2</xref>).</p>
    </sec>
    <sec>
      <title>4.2. Visualization of Missingness Patterns</title>
      <p>As an optional feature in our app, the missingness patterns can be checked by users via the black/white image plot, in which black is for missing values. The user can also hover mouse around the Dendrogram and zoom in to check the information for the grouped factors due to the missingness. <xref ref-type="supplementary-material" rid="SM1">Supplementary Figure 3</xref> includes the visualization of Dendrogram on missingness pattern based on the toy data.</p>
    </sec>
    <sec>
      <title>4.3. Imputation Algorithm</title>
      <p>Within the app, the nine imputation methods listed in section 3.1 are available: ImputeEHR1, ImputeEHR2, MissForest, MICE, KNNImputer, SoftImpute, GAIN, mean, and median. <xref ref-type="supplementary-material" rid="SM1">Supplementary Table 6</xref> provides the important parameters' selection for the toy example via ImputeEHR1 and ImputeEHR2 methods.</p>
      <p>Some methods have their own hyperparameters. For KNNImputer, we set <italic>k</italic> = 5, which is considered the default number of nearest neighbors. Four parameters, “batch_size,” “hint_rate,” “alpha,” and “iteration,” are embedded for the GAIN method. The “batch_size” defines the number of training samples present in a single batch. The “hint_rate” reveals the discriminator partial information about the missingness of the original sample. The “alpha” is a hyperparameter, and “iteration” describes the number of times a batch of data passes through the algorithm to update its parameters.</p>
    </sec>
    <sec>
      <title>4.4. Visualization From Combining Dimensional Reduction Algorithms and K-Means Clustering</title>
      <p>ImputEHR makes it easy for users to visualize patterns in their imputed dataset. Principal component analysis (PCA) Pearson (<xref rid="B25" ref-type="bibr">1901</xref>) and t-distributed stochastic neighbor embedding (t-SNE) (Van der Maaten and Hinton, <xref rid="B36" ref-type="bibr">2008</xref>) methods are embedded for dimension reduction. Users can plot the result of either method, partitioning the observations into k clusters. Our ImputEHR app suggests the number of optimal clusters using the Elbow method (Syakur et al., <xref rid="B33" ref-type="bibr">2018</xref>), which runs k-means clustering on the imputed dataset for a range of values for <italic>k</italic> between 1 and 9. For the visualization purpose, the green line in <xref ref-type="supplementary-material" rid="SM1">Supplementary Figure 4</xref> indicates the best choice of <italic>k</italic> plot on the toy example. Three parameters considered for the t-SNE method are “learning rate,” “n_iter” (number of iterations), and “perplexity.” Perplexity defines the number of close neighbors at each point, and learning rate affects the convergence of the embedding. In <xref ref-type="fig" rid="F5">Figure 5</xref> and <xref ref-type="supplementary-material" rid="SM1">Supplementary Figure 5</xref>, we applied k-means method with different numbers of clusters on the outcome of the PCA and t-SNE methods. In our app, user can also mouse over the point and see which variable it is.</p>
      <fig id="F5" position="float">
        <label>Figure 5</label>
        <caption>
          <p>Visualization of patterns in the imputed dataset. User has the option to use the number of cluster and dimension reduction method.</p>
        </caption>
        <graphic xlink:href="fgene-12-691274-g0005"/>
      </fig>
    </sec>
    <sec>
      <title>4.5. Visualization of the Important Features</title>
      <p>A very useful feature of our app is that it helps users to nail down the most important features for further investigation. We provide the users four methods for feature selection from the imputed dataset: LightGBM (Ke et al., <xref rid="B18" ref-type="bibr">2017</xref>), lasso (Tibshirani, <xref rid="B34" ref-type="bibr">1996</xref>), ridge (Hoerl and Kennard, <xref rid="B13" ref-type="bibr">1970</xref>), and elastic net (Zou and Hastie, <xref rid="B40" ref-type="bibr">2005</xref>) (<xref ref-type="fig" rid="F6">Figure 6</xref>). Users can decide how many important features to visualize.</p>
      <fig id="F6" position="float">
        <label>Figure 6</label>
        <caption>
          <p>Visualization of the important features selected by the four methods.</p>
        </caption>
        <graphic xlink:href="fgene-12-691274-g0006"/>
      </fig>
    </sec>
    <sec>
      <title>4.6. Visualization of the Phenotype Prediction</title>
      <p>When performing imputation, if downstream prediction is intended, then the response variable should be removed from the imputation process to avoid overtraining datasets in which cross-validation for prediction of the response must be used. Accordingly, ImputEHR enables the user to select a response variable to be excluded from the imputation process. We also provide the author the visualization of the correlation between the imputed value and the masked 5% non-missing data for each variable (<xref ref-type="supplementary-material" rid="SM1">Supplementary Figure 4</xref>).</p>
      <p>Important features from an imputed dataset are selected as input to predict the phenotype, illustrated in <xref ref-type="fig" rid="F7">Figure 7</xref>, using five-fold cross-validation to avoid overfitting. Users can select from a suite of prediction methods including random forests, lasso, LightGBM, and KNN.</p>
      <fig id="F7" position="float">
        <label>Figure 7</label>
        <caption>
          <p>Pipeline of the predictive model.</p>
        </caption>
        <graphic xlink:href="fgene-12-691274-g0007"/>
      </fig>
      <p>The running time for a job depends largely on the size of dataset, the missing rate, and the computer hardware. All analyses were performed in Python 3.6.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="s5">
    <title>5. Conclusions</title>
    <p>ImputeEHR can quickly and accurately impute missing data, implementing a variety of methods. The ease of performing imputation can lead to better predictive performance, as many methods are made feasible by imputation. We have created a tool covering a range of imputation options, including novel and fast tree-based methods. We have also included a variety of basic phenotype prediction methods, although the user can easily output the imputed dataset for import into other prediction routines. As with any imputation tools, the accuracy will be limited by the correlation structures, and in general the number of features relative to the sample size. For these and other reasons, this tool is not designed for genomic imputation (Schurz et al., <xref rid="B29" ref-type="bibr">2019</xref>) or for proteomics data (Jin et al., <xref rid="B16" ref-type="bibr">2021</xref>), or other areas with well-understood biological correlation structures. However, the ease of use and seamless interface for using multiple imputation methods makes our approach a useful approach in a variety of analysis pipelines.</p>
  </sec>
  <sec sec-type="data-availability" id="s6">
    <title>Data Availability Statement</title>
    <p>The original contributions presented in the study are included in the article/<xref ref-type="sec" rid="s8">Supplementary Material</xref>. The toydata for the ImputEHR app is located at <ext-link ext-link-type="uri" xlink:href="https://github.com/zhouLabNCSU/ImputEHR/tree/main/Demo%20File">https://github.com/zhouLabNCSU/ImputEHR/tree/main/Demo%20File</ext-link>, further inquiries can be directed to the corresponding author/s.</p>
  </sec>
  <sec id="s7">
    <title>Author Contributions</title>
    <p>Y-HZ is the leader of this project. Her contribution includes writing the manuscript, designing the data analysis, summarizing the results, and software management. ES contributed to the Python code underneath the ImputEHR app. Both authors contributed to the article and approved the submitted version.</p>
  </sec>
  <sec sec-type="COI-statement" id="conf1">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
</body>
<back>
  <ack>
    <p>Thanks to Mr. Gallins' effort in reformatting the manuscript into the Latex format. Thanks for Kuncheng Song's contribution to the new <xref ref-type="fig" rid="F1">Figure 1</xref>, ImputEHR Rshiny app and software maintenance, Yang Sun's contribution to <xref ref-type="fig" rid="F3">Figure 3</xref>, Paul Gallins' contribution to <xref ref-type="fig" rid="F7">Figure 7</xref> and draft reformatting.</p>
  </ack>
  <fn-group>
    <fn fn-type="financial-disclosure">
      <p><bold>Funding.</bold> This work was supported by Y-HZ's startup funding at NCSU and Cystic Fibrosis Foundation KNOWLE18XX0.</p>
    </fn>
  </fn-group>
  <sec sec-type="supplementary-material" id="s8">
    <title>Supplementary Material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fgene.2021.691274/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fgene.2021.691274/full#supplementary-material</ext-link></p>
    <supplementary-material content-type="local-data" id="SM1">
      <media xlink:href="Data_Sheet_1.PDF">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <p><ext-link ext-link-type="uri" xlink:href="https://github.com/zhouLabNCSU/ImputEHR">The Rshiny link</ext-link>, supplementary documents, and breast cancer toy example dataset are available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/zhouLabNCSU/ImputEHR">https://github.com/zhouLabNCSU/ImputEHR</ext-link>.</p>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barnard</surname><given-names>J.</given-names></name><name><surname>Meng</surname><given-names>X. L.</given-names></name></person-group> (<year>1999</year>). <article-title>Applications of multiple imputation in medical studies: from aids to nhanes</article-title>. <source>Stat. Methods Med. Res</source>. <volume>8</volume>, <fpage>17</fpage>–<lpage>36</lpage>. <pub-id pub-id-type="doi">10.1177/096228029900800103</pub-id><?supplied-pmid 10347858?><pub-id pub-id-type="pmid">10347858</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beaulieu-Jones</surname><given-names>B. K.</given-names></name><name><surname>Moore</surname><given-names>J. H.</given-names></name></person-group> (<year>2017</year>). <article-title>CONSORTIUM PROAACT. Missing data imputation in the electronic health record using deeply learned autoencoders</article-title>. <source>Pac. Symp. Biocomput</source>. <volume>2017</volume>, <fpage>207</fpage>–<lpage>218</lpage>. <pub-id pub-id-type="doi">10.1142/9789813207813_0021</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buuren</surname><given-names>S.</given-names></name><name><surname>Groothuis-Oudshoorn</surname><given-names>K.</given-names></name></person-group> (<year>2010</year>). <article-title>mice: Multivariate imputation by chained equations in R</article-title>. <source>J. Stat. Softw</source>. <volume>45</volume>, <fpage>1</fpage>–<lpage>68</lpage>. <pub-id pub-id-type="doi">10.18637/jss.v045.i03</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>K. S.</given-names></name><name><surname>Fowles</surname><given-names>J. B.</given-names></name><name><surname>Weiner</surname><given-names>J. P.</given-names></name></person-group> (<year>2010</year>). <article-title>Electronic health records and the reliability and validity of quality measures: a review of the literature</article-title>. <source>Med. Care Res. Rev</source>. <volume>67</volume>, <fpage>503</fpage>–<lpage>527</lpage>. <pub-id pub-id-type="doi">10.1177/1077558709359007</pub-id><?supplied-pmid 20150441?><pub-id pub-id-type="pmid">20150441</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Charles</surname><given-names>D.</given-names></name><name><surname>Gabriel</surname><given-names>M.</given-names></name><name><surname>Furukawa</surname><given-names>M. F.</given-names></name></person-group> (<year>2013</year>). <article-title>Adoption of electronic health record systems among us non-federal acute care hospitals: 2008-2012</article-title>. <source>ONC Data Brief</source>
<volume>9</volume>, <fpage>1</fpage>–<lpage>9</lpage>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://www.healthit.gov/sites/default/files/oncdatabrief16.pdf">https://www.healthit.gov/sites/default/files/oncdatabrief16.pdf</ext-link></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>T.</given-names></name><name><surname>He</surname><given-names>T.</given-names></name><name><surname>Benesty</surname><given-names>M.</given-names></name><name><surname>Khotilovich</surname><given-names>V.</given-names></name><name><surname>Tang</surname><given-names>Y.</given-names></name><name><surname>Cho</surname><given-names>H.</given-names></name><etal/></person-group>. (<year>2015</year>). <source>Xgboost: Extreme Gradient Boosting. R Package Version 0.4-2 1</source>.</mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cranor</surname><given-names>L. F.</given-names></name><name><surname>LaMacchia</surname><given-names>B. A.</given-names></name></person-group> (<year>1998</year>). <article-title>Spam!</article-title>
<source>Commun. ACM</source>
<volume>41</volume>, <fpage>74</fpage>–<lpage>83</lpage>. <pub-id pub-id-type="doi">10.1145/280324.280336</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dua</surname><given-names>D.</given-names></name><name><surname>Graff</surname><given-names>C.</given-names></name></person-group> (<year>2017</year>). <source>UCI machine learning repository</source>. <publisher-loc>Irvine</publisher-loc>: <publisher-name>University of California</publisher-name>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/citation_policy.html">https://archive.ics.uci.edu/ml/citation_policy.html</ext-link></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frey</surname><given-names>P. W.</given-names></name><name><surname>Slate</surname><given-names>D. J.</given-names></name></person-group> (<year>1991</year>). <article-title>Letter recognition using holland-style adaptive classifiers</article-title>. <source>Mach. Learn</source>. <volume>6</volume>, <fpage>161</fpage>–<lpage>182</lpage>. <pub-id pub-id-type="doi">10.1007/BF00114162</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gelman</surname><given-names>A.</given-names></name><name><surname>Hill</surname><given-names>J.</given-names></name></person-group> (<year>2006</year>). <source>Data Analysis Using Regression and Multilevel/Hierarchical Models</source>. <publisher-name>Cambridge University Press</publisher-name>. <pub-id pub-id-type="doi">10.1017/CBO9780511790942</pub-id><?supplied-pmid 17608921?></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harrison</surname><given-names>D.</given-names><suffix>Jr.</suffix></name><name><surname>Rubinfeld</surname><given-names>D. L.</given-names></name></person-group> (<year>1978</year>). <article-title>Hedonic housing prices and the demand for clean air</article-title>. <source>J. Environ. Econ. Manage</source>. <volume>5</volume>, <fpage>81</fpage>–<lpage>102</lpage>. <pub-id pub-id-type="doi">10.1016/0095-0696(78)90006-2</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haukoos</surname><given-names>J. S.</given-names></name><name><surname>Newgard</surname><given-names>C. D.</given-names></name></person-group> (<year>2007</year>). <article-title>Advanced statistics: missing data in clinical research?part 1: an introduction and conceptual framework</article-title>. <source>Acad. Emerg. Med</source>. <volume>14</volume>, <fpage>662</fpage>–<lpage>668</lpage>. <pub-id pub-id-type="doi">10.1197/j.aem.2006.11.037</pub-id><?supplied-pmid 17538078?><pub-id pub-id-type="pmid">17538078</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoerl</surname><given-names>A. E.</given-names></name><name><surname>Kennard</surname><given-names>R. W.</given-names></name></person-group> (<year>1970</year>). <article-title>Ridge regression: biased estimation for nonorthogonal problems</article-title>. <source>Technometrics</source>
<volume>12</volume>, <fpage>55</fpage>–<lpage>67</lpage>. <pub-id pub-id-type="doi">10.1080/00401706.1970.10488634</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname><given-names>Z.</given-names></name><name><surname>Melton</surname><given-names>G. B.</given-names></name><name><surname>Arsoniadis</surname><given-names>E. G.</given-names></name><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Kwaan</surname><given-names>M. R.</given-names></name><name><surname>Simon</surname><given-names>G. J.</given-names></name></person-group> (<year>2017</year>). <article-title>Strategies for handling missing clinical data for automated surgical site infection detection from the electronic health record</article-title>. <source>J. Biomed. Informatics</source>
<volume>68</volume>, <fpage>112</fpage>–<lpage>120</lpage>. <pub-id pub-id-type="doi">10.1016/j.jbi.2017.03.009</pub-id><?supplied-pmid 28323112?><pub-id pub-id-type="pmid">28323112</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jazayeri</surname><given-names>A.</given-names></name><name><surname>Liang</surname><given-names>O. S.</given-names></name><name><surname>Yang</surname><given-names>C. C.</given-names></name></person-group> (<year>2020</year>). <article-title>Imputation of missing data in electronic health records based on patients? similarities</article-title>. <source>J. Healthc. Informatics Res</source>. <volume>4</volume>, <fpage>295</fpage>–<lpage>307</lpage>. <pub-id pub-id-type="doi">10.1007/s41666-020-00073-5</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jin</surname><given-names>L.</given-names></name><name><surname>Bi</surname><given-names>Y.</given-names></name><name><surname>Hu</surname><given-names>C.</given-names></name><name><surname>Qu</surname><given-names>J.</given-names></name><name><surname>Shen</surname><given-names>S.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><etal/></person-group>. (<year>2021</year>). <article-title>A comparative study of evaluating missing value imputation methods in label-free proteomics</article-title>. <source>Sci. Rep</source>. <volume>11</volume>, <fpage>1</fpage>–<lpage>11</lpage>. <pub-id pub-id-type="doi">10.1038/s41598-021-81279-4</pub-id><?supplied-pmid 33469060?><pub-id pub-id-type="pmid">33414495</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>A. E.</given-names></name><name><surname>Pollard</surname><given-names>T. J.</given-names></name><name><surname>Shen</surname><given-names>L.</given-names></name><name><surname>Li-Wei</surname><given-names>H. L.</given-names></name><name><surname>Feng</surname><given-names>M.</given-names></name><name><surname>Ghassemi</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>MIMIC-III, a freely accessible critical care database</article-title>. <source>Sci. Data</source><volume>3</volume>, <fpage>1</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1038/sdata.2016.35</pub-id><?supplied-pmid 27219127?><pub-id pub-id-type="pmid">27219127</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Ke</surname><given-names>G.</given-names></name><name><surname>Meng</surname><given-names>Q.</given-names></name><name><surname>Finley</surname><given-names>T.</given-names></name><name><surname>Wang</surname><given-names>T.</given-names></name><name><surname>Chen</surname><given-names>W.</given-names></name><name><surname>Ma</surname><given-names>W.</given-names></name><etal/></person-group> (<year>2017</year>). <article-title>LightGBM: A highly efficient gradient boosting decision tree</article-title>. <source>Adv. Neural Inform. Process. Syst</source>. <fpage>3146</fpage>–<lpage>3154</lpage>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html">https://proceedings.neurips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html</ext-link></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le</surname><given-names>N. Q. K.</given-names></name><name><surname>Huynh</surname><given-names>T. T.</given-names></name></person-group> (<year>2019</year>). <article-title>Identifying snares by incorporating deep learning architecture and amino acid embedding representation</article-title>. <source>Front. Physiol</source>. <volume>10</volume>:<fpage>1501</fpage>. <pub-id pub-id-type="doi">10.3389/fphys.2019.01501</pub-id><?supplied-pmid 31920706?><pub-id pub-id-type="pmid">31920706</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le</surname><given-names>N. Q. K.</given-names></name><name><surname>Yapp</surname><given-names>E. K. Y.</given-names></name><name><surname>Nagasundaram</surname><given-names>N.</given-names></name><name><surname>Yeh</surname><given-names>H. Y.</given-names></name></person-group> (<year>2019</year>). <article-title>Classifying promoters by interpreting the hidden information of DNA sequences via deep learning and combination of continuous fasttext n-grams</article-title>. <source>Front. Bioeng. Biotechnol</source>. <volume>7</volume>:<fpage>305</fpage>. <pub-id pub-id-type="doi">10.3389/fbioe.2019.00305</pub-id><?supplied-pmid 31750297?><pub-id pub-id-type="pmid">31750297</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liaw</surname><given-names>A.</given-names></name><name><surname>Wiener</surname><given-names>M.</given-names></name></person-group> (<year>2002</year>). <article-title>Classification and regression by randomforest</article-title>. <source>R News</source>
<volume>2</volume>, <fpage>18</fpage>–<lpage>22</lpage>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://cogns.northwestern.edu/cbmg/LiawAndWiener2002.pdf">https://cogns.northwestern.edu/cbmg/LiawAndWiener2002.pdf</ext-link></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazumder</surname><given-names>R.</given-names></name><name><surname>Hastie</surname><given-names>T.</given-names></name><name><surname>Tibshirani</surname><given-names>R.</given-names></name></person-group> (<year>2010</year>). <article-title>Spectral regularization algorithms for learning large incomplete matrices</article-title>. <source>J. Mach. Learn. Res</source>. <volume>11</volume>, <fpage>2287</fpage>–<lpage>2322</lpage>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://jmlr.csail.mit.edu/papers/volume11/mazumder10a/mazumder10a.pdf">https://jmlr.csail.mit.edu/papers/volume11/mazumder10a/mazumder10a.pdf</ext-link><?supplied-pmid 21552465?><pub-id pub-id-type="pmid">21552465</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>McKnight</surname><given-names>P. E.</given-names></name><name><surname>McKnight</surname><given-names>K. M.</given-names></name><name><surname>Sidani</surname><given-names>S.</given-names></name><name><surname>Figueredo</surname><given-names>A. J.</given-names></name></person-group> (<year>2007</year>). <source>Missing Data: A Gentle Introduction</source>. <publisher-name>Guilford Press</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newgard</surname><given-names>C. D.</given-names></name><name><surname>Haukoos</surname><given-names>J. S.</given-names></name></person-group> (<year>2007</year>). <article-title>Advanced statistics: missing data in clinical research?part 2: multiple imputation</article-title>. <source>Acad. Emerg. Med</source>. <volume>14</volume>, <fpage>669</fpage>–<lpage>678</lpage>. <pub-id pub-id-type="doi">10.1111/j.1553-2712.2007.tb01856.x</pub-id><?supplied-pmid 17595237?><pub-id pub-id-type="pmid">17595237</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pearson</surname><given-names>K.</given-names></name></person-group> (<year>1901</year>). <article-title>LIII. On lines and planes of closest fit to systems of points in space</article-title>. <source>London Edinburgh Dublin Philos. Mag. J. Sci</source>. <volume>2</volume>, <fpage>559</fpage>–<lpage>572</lpage>. <pub-id pub-id-type="doi">10.1080/14786440109462720</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F.</given-names></name><name><surname>Varoquaux</surname><given-names>G.</given-names></name><name><surname>Gramfort</surname><given-names>A.</given-names></name><name><surname>Michel</surname><given-names>V.</given-names></name><name><surname>Thirion</surname><given-names>B.</given-names></name><name><surname>Grisel</surname><given-names>O.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Scikit-learn: Machine learning in python</article-title>. <source>J. Mach. Learn. Res</source>. <volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf">https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf</ext-link></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname><given-names>D. B.</given-names></name></person-group> (<year>1976</year>). <article-title>Inference and missing data</article-title>. <source>Biometrika</source>
<volume>63</volume>, <fpage>581</fpage>–<lpage>592</lpage>. <pub-id pub-id-type="doi">10.1093/biomet/63.3.581</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubin</surname><given-names>D. B.</given-names></name></person-group> (<year>2003</year>). <article-title>Discussion on multiple imputation</article-title>. <source>Int. Stat. Rev</source>. <volume>71</volume>, <fpage>619</fpage>–<lpage>625</lpage>. <pub-id pub-id-type="doi">10.1111/j.1751-5823.2003.tb00216.x</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schurz</surname><given-names>H.</given-names></name><name><surname>Müller</surname><given-names>SJ</given-names></name><name><surname>Van Helden</surname><given-names>P. D.</given-names></name><name><surname>Tromp</surname><given-names>G.</given-names></name><name><surname>Hoal</surname><given-names>E. G.</given-names></name><name><surname>Kinnear</surname><given-names>C. J.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Evaluating the accuracy of imputation methods in a five-way admixed population</article-title>. <source>Front. Genet</source>. <volume>10</volume>:<fpage>34</fpage>. <pub-id pub-id-type="doi">10.3389/fgene.2019.00034</pub-id><?supplied-pmid 30804980?><pub-id pub-id-type="pmid">30804980</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharafoddini</surname><given-names>A.</given-names></name><name><surname>Dubin</surname><given-names>J. A.</given-names></name><name><surname>Maslove</surname><given-names>D. M.</given-names></name><name><surname>Lee</surname><given-names>J.</given-names></name></person-group> (<year>2019</year>). <article-title>A new insight into missing data in intensive care unit patient profiles: observational study</article-title>. <source>JMIR Med. Informatics</source>
<volume>7</volume>:<fpage>e11605</fpage>. <pub-id pub-id-type="doi">10.2196/11605</pub-id><?supplied-pmid 30622091?><pub-id pub-id-type="pmid">30622091</pub-id></mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stekhoven</surname><given-names>D. J.</given-names></name><name><surname>Bühlmann</surname><given-names>P.</given-names></name></person-group> (<year>2012</year>). <article-title>Missforest?non-parametric missing value imputation for mixed-type data</article-title>. <source>Bioinformatics</source>
<volume>28</volume>, <fpage>112</fpage>–<lpage>118</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btr597</pub-id><?supplied-pmid 22039212?><pub-id pub-id-type="pmid">22039212</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Street</surname><given-names>W. N.</given-names></name><name><surname>Wolberg</surname><given-names>W. H.</given-names></name><name><surname>Mangasarian</surname><given-names>O. L.</given-names></name></person-group> (<year>1993</year>). <article-title>Nuclear feature extraction for breast tumor diagnosis</article-title>. <source>Biomed. Image Process. Biomed. Visual</source>. <volume>1905</volume>, <fpage>861</fpage>–<lpage>870</lpage>. <pub-id pub-id-type="doi">10.1117/12.148698</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Syakur</surname><given-names>M.</given-names></name><name><surname>Khotimah</surname><given-names>B.</given-names></name><name><surname>Rochman</surname><given-names>E.</given-names></name><name><surname>Satoto</surname><given-names>B.</given-names></name></person-group> (<year>2018</year>). <article-title>Integration k-means clustering method and elbow method for identification of the best customer profile cluster</article-title>. <source>IOP Conf. Ser</source>. <volume>336</volume>:<fpage>012017</fpage>. <pub-id pub-id-type="doi">10.1088/1757-899X/336/1/012017</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tibshirani</surname><given-names>R.</given-names></name></person-group> (<year>1996</year>). <article-title>Regression shrinkage and selection via the lasso</article-title>. <source>J. R. Stat. Soc. Ser. B</source>
<volume>58</volume>, <fpage>267</fpage>–<lpage>288</lpage>. <pub-id pub-id-type="doi">10.1111/j.2517-6161.1996.tb02080.x</pub-id></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Troyanskaya</surname><given-names>O.</given-names></name><name><surname>Cantor</surname><given-names>M.</given-names></name><name><surname>Sherlock</surname><given-names>G.</given-names></name><name><surname>Brown</surname><given-names>P.</given-names></name><name><surname>Hastie</surname><given-names>T.</given-names></name><name><surname>Tibshirani</surname><given-names>R.</given-names></name><etal/></person-group>. (<year>2001</year>). <article-title>Missing value estimation methods for dna microarrays</article-title>. <source>Bioinformatics</source><volume>17</volume>, <fpage>520</fpage>–<lpage>525</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/17.6.520</pub-id><?supplied-pmid 11395428?><pub-id pub-id-type="pmid">11395428</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van der Maaten</surname><given-names>L.</given-names></name><name><surname>Hinton</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>). <article-title>Visualizing data using t-SNE</article-title>. <source>J. Mach. Learn. Res</source>. <volume>9</volume>, <fpage>2579</fpage>–<lpage>2605</lpage>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf">https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf</ext-link></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weiskopf</surname><given-names>N. G.</given-names></name><name><surname>Weng</surname><given-names>C.</given-names></name></person-group> (<year>2013</year>). <article-title>Methods and dimensions of electronic health record data quality assessment: enabling reuse for clinical research</article-title>. <source>J. Am. Med. Informatics Assoc</source>. <volume>20</volume>, <fpage>144</fpage>–<lpage>151</lpage>. <pub-id pub-id-type="doi">10.1136/amiajnl-2011-000681</pub-id><?supplied-pmid 22733976?><pub-id pub-id-type="pmid">22733976</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wells</surname><given-names>B. J.</given-names></name><name><surname>Chagin</surname><given-names>K. M.</given-names></name><name><surname>Nowacki</surname><given-names>A. S.</given-names></name><name><surname>Kattan</surname><given-names>M. W.</given-names></name></person-group> (<year>2013</year>). <article-title>Strategies for handling missing data in electronic health record derived data</article-title>. <source>Egems</source>
<volume>1</volume>:<fpage>1035</fpage>. <pub-id pub-id-type="doi">10.13063/2327-9214.1035</pub-id><?supplied-pmid 25848578?><pub-id pub-id-type="pmid">25848578</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><name><surname>Yoon</surname><given-names>J.</given-names></name><name><surname>Jordon</surname><given-names>J.</given-names></name><name><surname>Van Der Schaar</surname><given-names>M.</given-names></name></person-group> (<year>2018</year>). <article-title>Gain: Missing data imputation using generative adversarial nets</article-title>. <source>arXiv preprint arXiv:1806.02920</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1806.02920">https://arxiv.org/abs/1806.02920</ext-link></mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname><given-names>H.</given-names></name><name><surname>Hastie</surname><given-names>T.</given-names></name></person-group> (<year>2005</year>). <article-title>Regularization and variable selection via the elastic net</article-title>. <source>J. R. Stat. Soc. Ser. B</source>
<volume>67</volume>, <fpage>301</fpage>–<lpage>320</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9868.2005.00503.x</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
