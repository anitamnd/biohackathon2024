<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Neuroinform</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Neuroinform</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Neuroinform.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Neuroinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1662-5196</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7270712</article-id>
    <article-id pub-id-type="doi">10.3389/fninf.2020.00024</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Neuroscience</subject>
        <subj-group>
          <subject>Technology and Code</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Sammba-MRI: A Library for Processing SmAll-MaMmal BrAin MRI Data in Python</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Celestine</surname>
          <given-names>Marina</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="author-notes" rid="fn001">
          <sup>†</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/857825/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Nadkarni</surname>
          <given-names>Nachiket A.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="author-notes" rid="fn001">
          <sup>†</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/855444/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Garin</surname>
          <given-names>Clément M.</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Bougacha</surname>
          <given-names>Salma</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
        <xref ref-type="author-notes" rid="fn001">
          <sup>†</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/590884/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dhenain</surname>
          <given-names>Marc</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/9562/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>UMR9199 Laboratory of Neurodegenerative Diseases, Centre National de la Recherche Scientifique (CNRS)</institution>, <addr-line>Fontenay-aux-Roses</addr-line>, <country>France</country></aff>
    <aff id="aff2"><sup>2</sup><institution>MIRCen, Institut de Biologie François Jacob, Commissariat à l'Energie Atomique et aux Energies Alternatives (CEA)</institution>, <addr-line>Fontenay-aux-Roses</addr-line>, <country>France</country></aff>
    <aff id="aff3"><sup>3</sup><institution>UMR-S U1237 Physiopathologie et imagerie des troubles Neurologiques (PhIND), INSERM, Université de Caen-Normandie, GIP Cyceron</institution>, <addr-line>Caen</addr-line>, <country>France</country></aff>
    <aff id="aff4"><sup>4</sup><institution>Normandie Université, UNICAEN, PSL Research University, EPHE, Inserm, U1077, CHU de Caen, Neuropsychologie et Imagerie de la Mémoire Humaine</institution>, <addr-line>Caen</addr-line>, <country>France</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Jan G. Bjaalie, University of Oslo, Norway</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Luz Maria Alonso-Valerdi, Monterrey Institute of Technology and Higher Education (ITESM), Mexico; Eszter Agnes Papp, University of Oslo, Norway</p>
      </fn>
      <corresp id="c001">*Correspondence: Marc Dhenain <email>marc.dhenain@cea.fr</email></corresp>
      <fn fn-type="other" id="fn001">
        <p>†These authors have contributed equally to this work</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>28</day>
      <month>5</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>14</volume>
    <elocation-id>24</elocation-id>
    <history>
      <date date-type="received">
        <day>31</day>
        <month>5</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>23</day>
        <month>4</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2020 Celestine, Nadkarni, Garin, Bougacha and Dhenain.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Celestine, Nadkarni, Garin, Bougacha and Dhenain</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Small-mammal neuroimaging offers incredible opportunities to investigate structural and functional aspects of the brain. Many tools have been developed in the last decade to analyse small animal data, but current softwares are less mature than the available tools that process human brain data. The Python package Sammba-MRI (SmAll-MaMmal BrAin MRI in Python; <ext-link ext-link-type="uri" xlink:href="http://sammba-mri.github.io">http://sammba-mri.github.io</ext-link>) allows flexible and efficient use of existing methods and enables fluent scriptable analysis workflows, from raw data conversion to multimodal processing.</p>
    </abstract>
    <kwd-group>
      <kwd>processing pipeline</kwd>
      <kwd>MRI</kwd>
      <kwd>registration</kwd>
      <kwd>small animal neuroimaging</kwd>
      <kwd>Python</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">Association France Alzheimer<named-content content-type="fundref-id">10.13039/501100003750</named-content></funding-source>
      </award-group>
      <award-group>
        <funding-source id="cn002">Fondation Plan Alzheimer<named-content content-type="fundref-id">10.13039/501100007494</named-content></funding-source>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="7"/>
      <table-count count="0"/>
      <equation-count count="0"/>
      <ref-count count="42"/>
      <page-count count="9"/>
      <word-count count="5000"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>1. Introduction</title>
    <p>The use of magnetic resonance imaging (MRI) methods in animals provides considerable benefits for improving our understanding of brain structure and function in health and diseases. The greatest advantages of preclinical MRI include group homogeneity and the opportunity to acquire a high amount of information repeated as needed. This added value, together with practical and ethical considerations, resulted in an increase of the use of small-mammal MRI in research. In human brain imaging, a large variety of high level software solutions is available for MRI preprocessing and analysis (e.g., SPM<xref ref-type="fn" rid="fn0001"><sup>1</sup></xref>, FSL<xref ref-type="fn" rid="fn0002"><sup>2</sup></xref>, or AFNI<xref ref-type="fn" rid="fn0003"><sup>3</sup></xref>). Less Free and Open Source Software (FOSS) are already available to analyse animal MRI. Atlas-based Imaging Data Analysis of structural and functional mouse brain MRI (AIDAmri) (Pallast et al., <xref rid="B31" ref-type="bibr">2019</xref>) package allows registration of functional and diffusion mouse brain MRI with the Allen Mouse Brain Atlas (Allen Institute for Brain Science, <xref rid="B2" ref-type="bibr">2004</xref>; Lein et al., <xref rid="B25" ref-type="bibr">2007</xref>). The SAMRI (Small Animal Magnetic Resonance Imaging) package provides fMRI preprocessing, metadata parsing, and data analysis functions optimized for mouse brains (Ioanas et al., <xref rid="B20" ref-type="bibr">2020</xref>). Today, there is still a need for other efficient and collaborative tools that would facilitate the adoption and dissemination of standardized pre-processing strategies for small animal MRI. Sammba-MRI was designed to process MR images, including anatomical, functional, and perfusion images. It allows to preprocess image dataset (conversion to NIfTI, bias correction), register images to templates or atlases, and perform perfusion measures.</p>
  </sec>
  <sec id="s2">
    <title>2. Workflow</title>
    <sec>
      <title>2.1. Tools: Python Ecosystem and Neuroimaging Software Packages</title>
      <p>With its FOSS dependency stack and its growing neuroimaging community Python has been naturally the language of choice for our package. The scientific Python libraries used in Sammba-MRI are NumPy (Oliphant, <xref rid="B30" ref-type="bibr">2006</xref>), SciPy (Millman and Aivazis, <xref rid="B26" ref-type="bibr">2011</xref>), the neuroimaging data analysis tools nibabel<xref ref-type="fn" rid="fn0004"><sup>4</sup></xref>, Nilearn (Abraham et al., <xref rid="B1" ref-type="bibr">2014</xref>) and Nipype (Gorgolewski et al., <xref rid="B15" ref-type="bibr">2011</xref>). Visualization functionality depends on Matplotlib (Hunter, <xref rid="B19" ref-type="bibr">2007</xref>) or Graphviz (Gansner and North, <xref rid="B11" ref-type="bibr">2000</xref>), but neither is required to perform MRI data processing.</p>
      <p>Via Nipype, we utilize basic MRI preprocessing functions from AFNI (Cox, <xref rid="B8" ref-type="bibr">1996</xref>), FSL (Jenkinson et al., <xref rid="B21" ref-type="bibr">2012</xref>) and ANTs (Avants et al., <xref rid="B5" ref-type="bibr">2009</xref>) packages. The dependency on the efficient but non open-source brain segmentation RATs tool (Oguz et al., <xref rid="B29" ref-type="bibr">2014</xref>) is optional.</p>
      <p>More specifically, Sammba-MRI and the examples provided in its manual depends on the following libraries: Nipype ≥ 1.0.4; Nilearn ≥ 0.4.0; Numpy ≥ 1.14; SciPy ≥ 0.19; Nibabel ≥ 2.0.2; Sklearn ≥ 0.19; matplotlib ≥ 1.5.1; nose ≥ 1.2.1; doctest-ignore-unicode; DICOM ToolKit package as well as FSL (version 5.0), AFNI, ANTs, and RATS.</p>
    </sec>
    <sec>
      <title>2.2. Code Design</title>
      <p>Sammba-MRI is developed within GitHub development platform<xref ref-type="fn" rid="fn0005"><sup>5</sup></xref>. Coding guidelines follow the model of Nilearn and other successfully adopted packages (e.g., Scikit-learn Pedregosa et al., <xref rid="B32" ref-type="bibr">2011</xref>) to make the codebase understandable and easily maintainable<xref ref-type="fn" rid="fn0006"><sup>6</sup></xref>. Objects are used with parsimony: the different registration classes share all the same interface, and the brain extraction classes comply to the Nipype <monospace>BaseInterface</monospace>.</p>
      <p>Effort is made to keep the code uniformly formatted and to use consistent naming for the functions and parameters following the coding conventions of Nilearn. Preprocessing building blocks and pipelines are automatically tested on light MRI data samples to ensure code quality. Finally, the user is guided through Sammba-MRI with extensive documentation including installation instructions, application programming interface (API) reference, pipeline graphs, and practical examples based on publicly available small animal neuroimaging datasets.</p>
      <p>An overview of the modules used to manipulate images is presented in <xref ref-type="fig" rid="F1">Figure 1</xref>. These modules are implemented either as “stand-alone” (i.e., <monospace>bias_correction</monospace>) or as ready-to-use pipelines (i.e., <monospace>TemplateRegistrator</monospace>).</p>
      <fig id="F1" position="float">
        <label>Figure 1</label>
        <caption>
          <p>Sammba-MRI workflow. Anatomical, functional, or perfusion images are imported from MRI local scanners or databases. They are analyzed using different preprocessing, segmentation and registration modules. Each function (green) and python-scripts (red) of Sammba-MRI are presented. Library dependencies are specified with color codes.</p>
        </caption>
        <graphic xlink:href="fninf-14-00024-g0001"/>
      </fig>
    </sec>
    <sec>
      <title>2.3. DICOM to NIfTI Conversion</title>
      <p>Sammba-MRI allows to convert Bruker DICOM (digital imaging and communications in medicine) files to the standard Neuroimaging Informatics Technology Initiative format (NIfTI-1) and extracts extensive information using DCMTK package (Eichelberg et al., <xref rid="B10" ref-type="bibr">2004</xref>). Bruker files conversion is an active development field, with various available tools handling DICOM (e.g., dicomifier<xref ref-type="fn" rid="fn0007"><sup>7</sup></xref>) or not (e.g., bru2nii<xref ref-type="fn" rid="fn0008"><sup>8</sup></xref>, Bruker2nifti<xref ref-type="fn" rid="fn0009"><sup>9</sup></xref>, bruker2nifti<xref ref-type="fn" rid="fn0010"><sup>10</sup></xref>). Finally, ParaVision 360 with the latest patch 1.1 can export the NIFTI format since February 2019. Our implementation is meant to be a light helper function, allowing to handle the conversion on the fly. It has been tested only for Paravision 6 and a limited number of imaging sequences.</p>
    </sec>
    <sec>
      <title>2.4. Bias Field Correction</title>
      <p>Intensity non-uniformity modeling is essential in preclinical studies because the intensity gradient corrupting MR images becomes particularly pronounced at high field strengths (Boyes et al., <xref rid="B6" ref-type="bibr">2008</xref>). Sammba-MRI relies on AFNI's <monospace>3dUnifize</monospace> to correct for intensity bias in anatomical images, and on <monospace>N4BiasFieldCorrection</monospace> function of the ANTs package (Tustison et al., <xref rid="B37" ref-type="bibr">2010</xref>) for the other modalities. <monospace>3dUnifize</monospace> is also used to aid brain extraction, as detailed in the following paragraph.</p>
    </sec>
    <sec>
      <title>2.5. Skull-Stripping</title>
      <p>Skull-stripping is a critical early step in processing MR images from small animals. Various automatic rodent-specific softwares (Chou et al., <xref rid="B7" ref-type="bibr">2011</xref>; Oguz et al., <xref rid="B29" ref-type="bibr">2014</xref>) or adaptations of human algorithms (Wood et al., <xref rid="B39" ref-type="bibr">2013</xref>; AFNI's 3dskullstrip -rat) are freely available for research purposes. We choose to rely on the LOGISMOS-based graph segmentation (Yin et al., <xref rid="B40" ref-type="bibr">2010</xref>) based on grayscale mathematical morphology RATS software (Oguz et al., <xref rid="B29" ref-type="bibr">2014</xref>) because of its good performance across a wide range of datasets (Sargolzaei et al., <xref rid="B34" ref-type="bibr">2018</xref>). An alternative to the free but non-open source RATS tool is also available, based on an adaptation of the human histogram-based brain extraction method of Nilearn. This method can be used in any pipeline by setting the parameter <monospace>use_rats_tool</monospace> to <monospace>False</monospace>. Because intensity inhomogeneity can hamper the performance of automatic skull-stripping, prior bias field correction is usually recommended (Sled et al., <xref rid="B36" ref-type="bibr">1998</xref>) and is performed by default with <monospace>3dUnifize</monospace>. The helper function <monospace>brain_segmentation_report</monospace> from Sammba-MRI <monospace>segmentation</monospace> module allows to efficiently tune the initial intensity threshold used in bias correction by producing for a given set of thresholds 5 informative measures characterizing the extracted mask to bypass time consuming repetitive visual checks. The returned features consist of the total volume of the extracted mask, its anteroposterior length, its right-left width, and its inferior-superior height as well as the sample Pearson's product-moment correlation coefficient between the brain mask image and its reflection with respect to the estimated mid-sagittal plane (Powell et al., <xref rid="B33" ref-type="bibr">2016</xref>).</p>
    </sec>
    <sec>
      <title>2.6. Registrations</title>
      <p>Several registration algorithms are implemented within Sammba-MRI. First, rigid-body registration can be performed to roughly align individual images from the same modality or from different modalities. It minimizes normalized mutual information between brain extracted images. This registration is finally estimated and applied to the whole head images. Second, linear registration estimates linear transforms between a source image and a reference image. It relies on AFNI's 3dAllineate function. Linear registration is more efficient when performed on brain-extracted rather than on whole head images. Third, non-linear registration (piecewise polynomial <italic>C</italic><sup>1</sup> diffeomorphism) between a source image and a reference image can also performed. It relies on AFNI's 3dQwarp and iterations toward patch size reduction until a maximum refinement “level” is reached. Unlike linear registration, it is more efficient when computed using whole head images.</p>
      <sec>
        <title>2.6.1. Group-Wise Registration and Study-Template</title>
        <p>Group-wise registration aims to align all images from different animals within a common space, resulting in an average brain (study template) that represents the commonalities among individual brain anatomies of a particular population. Using a study template eliminates possible bias toward external features and improves subsequent analyses (De Feo and Giove, <xref rid="B9" ref-type="bibr">2019</xref>). Sammba-MRI implements the multi-level, iterative scheme proposed by Kovačević et al. (<xref rid="B23" ref-type="bibr">2005</xref>) to create a fine anatomical template from individual anatomical MRI scans. A first rough template is obtained by averaging bias corrected head images centered on their respective brain mask centroids. Then the individual images are registered to this template. This process of successive averaging/registration is iterated while increasing the number of degrees of freedom of the estimated transform and updating the target template (see Nadkarni et al., <xref rid="B28" ref-type="bibr">2019</xref> for a detailed description of the pipeline).</p>
      </sec>
      <sec>
        <title>2.6.2. Inter-Modality Registration</title>
        <p>Several multimodal images can be recorded from a single animal, including structural imaging with different contrasts, blood-oxygenation-level-dependent (BOLD) and arterial spin labeling (ASL) MRI. BOLD imaging is largely used to investigate brain function in response to specific tasks or in the absence of explicit tasks (i.e., in resting state conditions) (Glover, <xref rid="B14" ref-type="bibr">2011</xref>). ASL is an attractive method to image the vascular system by directly measuring blood flow (Kober et al., <xref rid="B22" ref-type="bibr">2008</xref>).</p>
        <p>In addition to the inherent difficulties in intermodality registration (Ashburner and Friston, <xref rid="B4" ref-type="bibr">1997</xref>), severe image artifacts can corrupt BOLD or ASL scans resulting in a low signal-to-noise ratio (SNR). For instance, the echo planar imaging (EPI) technique widely used in functional and perfusion imaging suffers from non-linear geometric and intensity distortions caused by static magnetic field inhomogeneity that worsen at higher field strengths (Hong et al., <xref rid="B18" ref-type="bibr">2015</xref>).</p>
        <p>Thus a specific module called <monospace>_coregister_epi</monospace> was developed to register anatomical and EPI scans from individual animals. Anatomical images are first reoriented to match EPI images. Next, the reoriented anatomical images and the EPI scans are split into 2D slices along the z-direction (according to the slice geometry of EPI). Each EPI slice then undergoes a non-linear registration to match the corresponding anatomical slice. This per-slice registration corrects for EPI distortion while being more conservative than a global 3D non-linear registration.</p>
      </sec>
    </sec>
  </sec>
  <sec id="s3">
    <title>3. Pipelines</title>
    <p>Sammba-MRI proposes two ready-to-use pipelines to perform spatial registrations to a population or standard reference template as well as inter-modalities registration between anatomical, functional, or perfusion images. These pipelines have been tested throughout the different stages of their development process on various datasets from mice, rats and mouse lemurs and used in several publications from our lab (Garin et al., <xref rid="B12" ref-type="bibr">2018</xref>, <xref rid="B13" ref-type="bibr">2019</xref>; Nadkarni et al., <xref rid="B28" ref-type="bibr">2019</xref>). The two pipelines are called <monospace>Coregistrator</monospace> and <monospace>TemplateRegistrator</monospace>.</p>
    <p>All pipelines start with bias field correction for the individual images, involve skull-stripping and specific registration algorithms depending on image modality.</p>
    <sec>
      <title>3.1. Registration Between Anatomical Images and Another Modality:<monospace>Coregistrator</monospace></title>
      <p>Intra-subject registration between an anatomical scan and another modality (BOLD or ASL) is handled in the individual space through the <monospace>Coregistrator</monospace> class from the <monospace>registration</monospace> module (<xref ref-type="fig" rid="F2">Figure 2</xref>).</p>
      <p>
        <inline-graphic xlink:href="fninf-14-00024-i0001.jpg"/>
      </p>
      <fig id="F2" position="float">
        <label>Figure 2</label>
        <caption>
          <p>Sammba-MRI pipelines. Color box represents spaces in which individual images are registered. Registration between individual modalities is performed by Coregistrator class (green arrow). Registration of individual modality images to a reference standard template space is performed by TemplateRegistrator class (blue arrow).</p>
        </caption>
        <graphic xlink:href="fninf-14-00024-g0002"/>
      </fig>
      <p>Multimodal processing slightly differs between modality. Thus, user can choose modality of interest and the critical parameters that lead to the best registration.</p>
      <p>BOLD scans are preprocessed using the same usual steps for human data with optional slice timing correction, bias field correction, realignment to the first volume and computation of the temporal mean of all the volumes. The corresponding structural scan is then registered to the average BOLD scan. Since this is a critical step, the user can choose either to pursue with human-like pipeline by estimating a rigid body functional-to-structural transform and applying its inverse to the structural image, or to assume that the head motion between the two scans is negligible. In all cases, it is better to only reorient the anatomical image to match the modality of interest. Finally, per-slice-based registration is performed as described in <italic>section 2.6.2</italic>.</p>
      <p>
        <inline-graphic xlink:href="fninf-14-00024-i0002.jpg"/>
      </p>
      <p>Sammba-MRI was also designed to analyse ASL scans to perform perfusion measures. This analysis relies on Bruker-FAIR (Flow-sensitive Alternating Inversion Recovery) EPI sequences. Quantitative CBF maps are first estimated using <monospace>perf_fair_nii_proc</monospace> function from the <monospace>modality_processor</monospace> module. Then Sammba-MRI allows to preprocess functional ASL scans with the equilibrium magnetization maps (M0) used as the representative volume for registration. The M0 volume is aligned to the anatomical, first with a rigid body registration and then on a per-slice basis.</p>
      <p>
        <inline-graphic xlink:href="fninf-14-00024-i0003.jpg"/>
      </p>
    </sec>
    <sec>
      <title>3.2. Template-Based Multi-Modal Processing: <monospace>TemplateRegistrator</monospace></title>
      <p>Multimodal images (anatomical, functional, or perfusion MRI) can be handled in the template space through the <monospace>TemplateRegistrator</monospace> class. This pipeline matches individual images to a reference template, a necessary step for group studies (<xref ref-type="fig" rid="F2">Figure 2</xref>).</p>
      <sec>
        <title>3.2.1. Template Matching</title>
        <p>Sammba-MRI proposes to download reference templates both for mouse and rat brains. The user needs to specify the path to the template of his choice to the <monospace>TemplateRegistrator</monospace> class from the <monospace>registration</monospace> module.</p>
        <p>
          <inline-graphic xlink:href="fninf-14-00024-i0004.jpg"/>
        </p>
      </sec>
      <sec>
        <title>3.2.2. BOLD and ASL Preprocessing</title>
        <p>BOLD and ASL preprocessing can also be performed in template space with <monospace>TemplateRegistrator</monospace>. The structural-to-template warp, the functional-to-structural rigid body transform and the perslice functional-to-structural warps are combined and applied in a one-big-step transformation to the functional data to minimize interpolation errors. The <monospace>TemplateRegistrator</monospace> class encompasses an <monospace>inverse_transform_towards_modality</monospace> method to bring an image from the reference space to the individual's space.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results" id="s4">
    <title>4. Results</title>
    <p>Sammba-MRI is available through the GitHub platform<xref ref-type="fn" rid="fn0011"><sup>11</sup></xref> and was tested using different image datasets.</p>
    <sec>
      <title>4.1. Group-Wise Registration, Registration of Anatomical Images to a Common Space, and Template Creation</title>
      <p>First, we evaluated group-wise registration and template creation using a dataset of <italic>in vivo</italic> T2-weighted images of 10 Sprague-Dawley rat brains (Lancelot et al., <xref rid="B24" ref-type="bibr">2014</xref>). The scans were acquired using a 7.0 T Bruker scanner at 100 × 100 × 500 μm resolution using 30 different slices. We used <monospace>anats_to_common</monospace> to register images from the different animals and create a group average template (<xref ref-type="fig" rid="F3">Figure 3</xref>).</p>
      <fig id="F3" position="float">
        <label>Figure 3</label>
        <caption>
          <p>Rat templates issued from Sammba-MRI <bold>(A)</bold> or SPM-based <bold>(B)</bold> registrations. These templates were calculated from anatomical images of 10 animals. Visual observation suggests similar quality of the two templates.</p>
        </caption>
        <graphic xlink:href="fninf-14-00024-g0003"/>
      </fig>
      <p>For comparison purposes, the registration between images from each animal was also performed using algorithms from SPM8<xref ref-type="fn" rid="fn0012"><sup>12</sup></xref> with the SPMMouse toolbox<xref ref-type="fn" rid="fn0013"><sup>13</sup></xref> (Sawiak et al., <xref rid="B35" ref-type="bibr">2009</xref>), a reference method for image-registrations. The brain images were segmented into gray (GM) and white matter (WM) tissue probability maps using locally developed priors, then spatially transformed to a standard space. Priors were based on 100 × 100 × 100 μm resolution images and 134 slices. Affine regularization was set for an average-sized template, with a bias non-uniformity FWHM cut off of 10mm, a 5mm basis-function cut off and sampling distance of 0.3 mm. The resulting GM and WM portions were output in rigid template space, and <monospace>DARTEL</monospace> (Ashburner, <xref rid="B3" ref-type="bibr">2007</xref>) was used to create non-linearly registered maps for each animal and common templates for the cohort of animals. The deformation fields were applied to the MR images of each animal and the resulting images were averaged to create a template. <xref ref-type="fig" rid="F3">Figure 3</xref> shows the template obtained with SPM/Dartel. No obvious difference could be identified between the two templates.</p>
      <p>Sammba-MRI adapts to different small animal species. <xref ref-type="fig" rid="F4">Figure 4</xref> shows a template of mouse lemurs as another example (Nadkarni et al., <xref rid="B27" ref-type="bibr">2018</xref>).</p>
      <fig id="F4" position="float">
        <label>Figure 4</label>
        <caption>
          <p>Mouse lemur template from 34 animals. Coronal section of the mouse lemur MRI template (level of hippocampus).</p>
        </caption>
        <graphic xlink:href="fninf-14-00024-g0004"/>
      </fig>
    </sec>
    <sec>
      <title>4.2. Validation of Template Matching</title>
      <p>The Sprague-Dawley dataset is associated to brain segmentations into 28 regions for each animal (Lancelot et al., <xref rid="B24" ref-type="bibr">2014</xref>). It also includes a study-template and an atlas based on segmentation of this template into 28 regions. Each image of the 12 individual animal was registered to the template using Sammba-MRI and the deformation fields were applied to the segmented images of each animal. We then measured the regional overlap between each region of the transformed atlases of each animal and the template-segmentation using Dice similarity coefficient (<inline-formula><mml:math id="M1"><mml:mn>2</mml:mn><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mo>∩</mml:mo><mml:mi>B</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mo>|</mml:mo><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mi>B</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mfrac></mml:math></inline-formula>).</p>
      <p>The deformation fields calculated with SPM were also applied to the MR and segmented images of each animal. We also measured the regional overlap between each region of the SPM-transformed segmentations of each animal and the template-segmentation also using Dice similarity coefficient.</p>
      <p><xref ref-type="fig" rid="F5">Figure 5</xref> shows that Dice coefficients obtained with Sammba-MRI were highly correlated with those obtained using SPM mouse and outperformed those of SPM in several cases (points above the line). Regions with lower Dice values correspond to ventricles.</p>
      <fig id="F5" position="float">
        <label>Figure 5</label>
        <caption>
          <p>Dice coefficients obtained after registering individual images to a rat brain templates with Sammba-MRI and SPM/Dartel. <bold>(Top)</bold> Comparisons showing 27 brains regions. Bars represents standard error of the mean. <bold>(Bottom)</bold> Individual measures for four different brain regions.</p>
        </caption>
        <graphic xlink:href="fninf-14-00024-g0005"/>
      </fig>
    </sec>
    <sec>
      <title>4.3. fMRI and Perfusion Modalities</title>
      <p>Resting state fMRI allows to study temporally synchronized BOLD oscillations reflecting functionally connected brain networks. As in human resting state fMRI, spatial networks can be extracted using Independent Components Analysis (ICA) (Zerbi et al., <xref rid="B41" ref-type="bibr">2015</xref>; Grandjean et al., <xref rid="B16" ref-type="bibr">2020</xref>). We preprocessed the publicly shared functional data from 15 mice (2–3 months old) from (Zerbi et al., <xref rid="B41" ref-type="bibr">2015</xref>) paper with Sammba-MRI and performed a group ICA (Varoquaux et al., <xref rid="B38" ref-type="bibr">2010</xref>) with 30 components. Relevant bilateral regions related to somatosensory, hippocampal, visual, basal ganglia, and sensorimotor networks were obtained without additional data post-processing (<xref ref-type="fig" rid="F6">Figure 6</xref>).</p>
      <fig id="F6" position="float">
        <label>Figure 6</label>
        <caption>
          <p>ICA bilateral components. IC 1: Barrel field (i) cortex, IC 5: Lateral striatum, IC 9: Dorsal striatum (i), IC 10: Visual cortex, IC1 3: Hippocampus, IC 16: Dorsal striatum (ii), IC 17: Barrel field (ii) cortex, IC 21: Ventral striatum, IC 26: Supplementary cortex.</p>
        </caption>
        <graphic xlink:href="fninf-14-00024-g0006"/>
      </fig>
      <p>To illustrate the perfusion processing pipeline, we used perfusion FAIR images from 30 C57BL/6J mice (6–8 months) to quantify CBF. <xref ref-type="fig" rid="F7">Figure 7</xref> shows regional absolute CBF values. Perfusion values of 152±22 and 143±26 ml/100g/min in the hippocampus and temporal cortex, respectively. These values are lower than those reported by Kober et al. (208±20 and 243±35 ml/100g/min in the hippocampus and cortex) with FAIR method (Kober et al., <xref rid="B22" ref-type="bibr">2008</xref>). They are higher than those (118±6 ml/100g/min in the cortex) reported with the same method by (Zheng et al., <xref rid="B42" ref-type="bibr">2010</xref>).</p>
      <fig id="F7" position="float">
        <label>Figure 7</label>
        <caption>
          <p>CBF from 30 C57BL/6J mice. Boxplot shows median, interquartile range, upper and lower adjacent values for six brain region. Each dot represents regional CBF in ml/100g/min from one animal.</p>
        </caption>
        <graphic xlink:href="fninf-14-00024-g0007"/>
      </fig>
    </sec>
  </sec>
  <sec id="s5">
    <title>5. Big Data, Reproducibility, Collaboration</title>
    <p>The package design facilitates big data exploration: the user is able to run an entire analysis in a single Python script. Rerunning pipelines are optimized through Nipype caching mechanism and long lasting steps (non-linear warping, perfusion fitting) are executed in parallel. We believe that reproducibility in the neuroimaging field is not possible without making the acquired images and the preprocessing code available to the community. For this reason, Sammba-MRI promotes the sharing of MRI data by providing utility functions to download public small animal brain MRI datasets and relies on it for demonstrating the package capabilities. In order to encourage external contributions, our library source code is hosted on the open collaborative GitHub platform and distributed under the CeCILL v2.1 license, a FOSS license adapted to both international and French legal matters allowing anyone to make changes and redistribute it. Sammba-MRI supports GNU/Linux and Mac OS X operating systems (OS), used by over 70% of neuroimagers (Hanke and Halchenko, <xref rid="B17" ref-type="bibr">2011</xref>). So far, Sammba-MRI is designed for advanced users but documentation is provided to help novices.</p>
  </sec>
  <sec sec-type="conclusions" id="s6">
    <title>6. Conclusion</title>
    <p>By efficiently combining different existing human and animal neuroimaging tools, Sammba-MRI allows to tackle common processing issues in a fully automated fashion. High quality spatial registration can be easily performed, including template matching, between modalities registration as well as the creation of cohort-specific templates. Sammba-MRI also implements functional and perfusion MRI preprocessing methods and cerebral blood flow estimation for FAIR perfusion images. Emphasis is put on code readability and ease of use to favor contributions from the community.</p>
  </sec>
  <sec sec-type="data-availability" id="s7">
    <title>Data Availability Statement</title>
    <p>The mouse lemur dataset can be automatically loaded through Sammba-MRI or directly from <ext-link ext-link-type="uri" xlink:href="https://nitrc.org/projects/mouselemuratlas">https://nitrc.org/projects/mouselemuratlas</ext-link> for the template and <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds001945">https://openneuro.org/datasets/ds001945</ext-link> for the original anatomical images. The perfusion dataset will be made publicly available following publication.</p>
  </sec>
  <sec id="s8">
    <title>Ethics Statement</title>
    <p>The animal study was reviewed and approved by local ethics committees CEtEA-CEA DSV IdF.</p>
  </sec>
  <sec id="s9">
    <title>Author Contributions</title>
    <p>SB designed the Sammba-architecture and its implementation on Github. SB, NN, and MC contributed code to the project. NN, CG, and MD contributed to data acquisition. SB wrote the first version of the manuscript with input from CG and NN. MC and MD wrote the final version of the manuscript.</p>
  </sec>
  <sec id="s10">
    <title>Conflict of Interest</title>
    <p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
</body>
<back>
  <ack>
    <p>We thank the France-Alzheimer Association, Plan Alzheimer Foundation, the Foundation Vaincre-Alzheimer, and the French Public Investment Bank's ROMANE program for funding this study.</p>
  </ack>
  <fn-group>
    <fn id="fn0001">
      <p>
        <sup>1</sup>
        <ext-link ext-link-type="uri" xlink:href="https://www.fil.ion.ucl.ac.uk/spm/software/">https://www.fil.ion.ucl.ac.uk/spm/software/</ext-link>
      </p>
    </fn>
    <fn id="fn0002">
      <p>
        <sup>2</sup>
        <ext-link ext-link-type="uri" xlink:href="http://freesurfer.net/">http://freesurfer.net/</ext-link>
      </p>
    </fn>
    <fn id="fn0003">
      <p>
        <sup>3</sup>
        <ext-link ext-link-type="uri" xlink:href="https://afni.nimh.nih.gov/">https://afni.nimh.nih.gov/</ext-link>
      </p>
    </fn>
    <fn id="fn0004">
      <p>
        <sup>4</sup>
        <ext-link ext-link-type="uri" xlink:href="https://nipy.org/nibabel/">https://nipy.org/nibabel/</ext-link>
      </p>
    </fn>
    <fn id="fn0005">
      <p>
        <sup>5</sup>
        <ext-link ext-link-type="uri" xlink:href="https://github.com/sammba-mri/sammba-mri">https://github.com/sammba-mri/sammba-mri</ext-link>
      </p>
    </fn>
    <fn id="fn0006">
      <p>
        <sup>6</sup>
        <ext-link ext-link-type="uri" xlink:href="http://gael-varoquaux.info/programming/software-design-for-maintainability.html">http://gael-varoquaux.info/programming/software-design-for-maintainability.html</ext-link>
      </p>
    </fn>
    <fn id="fn0007">
      <p>
        <sup>7</sup>
        <ext-link ext-link-type="uri" xlink:href="https://github.com/lamyj/dicomifier">https://github.com/lamyj/dicomifier</ext-link>
      </p>
    </fn>
    <fn id="fn0008">
      <p>
        <sup>8</sup>
        <ext-link ext-link-type="uri" xlink:href="https://github.com/neurolabusc/Bru2Nii">https://github.com/neurolabusc/Bru2Nii</ext-link>
      </p>
    </fn>
    <fn id="fn0009">
      <p>
        <sup>9</sup>
        <ext-link ext-link-type="uri" xlink:href="https://github.com/CristinaChavarrias/Bruker2nifti">https://github.com/CristinaChavarrias/Bruker2nifti</ext-link>
      </p>
    </fn>
    <fn id="fn0010">
      <p>
        <sup>10</sup>
        <ext-link ext-link-type="uri" xlink:href="https://github.com/SebastianoF/bruker2nifti">https://github.com/SebastianoF/bruker2nifti</ext-link>
      </p>
    </fn>
    <fn id="fn0011">
      <p>
        <sup>11</sup>
        <ext-link ext-link-type="uri" xlink:href="https://sammba-mri.github.io/introduction.html#installation">https://sammba-mri.github.io/introduction.html#installation</ext-link>
      </p>
    </fn>
    <fn id="fn0012">
      <p>
        <sup>12</sup>
        <ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm">www.fil.ion.ucl.ac.uk/spm</ext-link>
      </p>
    </fn>
    <fn id="fn0013">
      <p>
        <sup>13</sup>
        <ext-link ext-link-type="uri" xlink:href="http://spmmouse.org">http://spmmouse.org</ext-link>
      </p>
    </fn>
  </fn-group>
  <fn-group>
    <fn fn-type="financial-disclosure">
      <p><bold>Funding.</bold> This work was funding by French Public Investment Bank's ROMANE program.</p>
    </fn>
  </fn-group>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname><given-names>A.</given-names></name><name><surname>Pedregosa</surname><given-names>F.</given-names></name><name><surname>Eickenberg</surname><given-names>M.</given-names></name><name><surname>Gervais</surname><given-names>P.</given-names></name><name><surname>Mueller</surname><given-names>A.</given-names></name><name><surname>Kossaifi</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Machine learning for neuroimaging with scikit-learn</article-title>. <source>Front. Neuroinform</source>. <volume>8</volume>:<fpage>14</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2014.00014</pub-id><?supplied-pmid 24600388?><pub-id pub-id-type="pmid">24600388</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="webpage"><person-group person-group-type="author"><collab>Allen Institute for Brain Science</collab></person-group> (<year>2004</year>). <source>Allen Mouse Brain Atlas</source>. Available online at: <ext-link ext-link-type="uri" xlink:href="http://mouse.brain-map.org">http://mouse.brain-map.org</ext-link></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J.</given-names></name></person-group> (<year>2007</year>). <article-title>A fast diffeomorphic image registration algorithm</article-title>. <source>Neuroimage</source>
<volume>38</volume>, <fpage>95</fpage>–<lpage>113</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.07.007</pub-id><?supplied-pmid 17761438?><pub-id pub-id-type="pmid">17761438</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashburner</surname><given-names>J.</given-names></name><name><surname>Friston</surname><given-names>K.</given-names></name></person-group> (<year>1997</year>). <article-title>Multimodal image coregistration and partitioning-a unified framework</article-title>. <source>Neuroimage</source>
<volume>6</volume>, <fpage>209</fpage>–<lpage>217</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.1997.0290</pub-id><?supplied-pmid 9344825?><pub-id pub-id-type="pmid">9344825</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avants</surname><given-names>B. B.</given-names></name><name><surname>Tustison</surname><given-names>N.</given-names></name><name><surname>Song</surname><given-names>G.</given-names></name></person-group> (<year>2009</year>). <article-title>Advanced normalization tools (ANTS)</article-title>. <source>Insight J</source>. <volume>2</volume>, <fpage>1</fpage>–<lpage>35</lpage>.</mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boyes</surname><given-names>R. G.</given-names></name><name><surname>Gunter</surname><given-names>J. L.</given-names></name><name><surname>Frost</surname><given-names>C.</given-names></name><name><surname>Janke</surname><given-names>A. L.</given-names></name><name><surname>Yeatman</surname><given-names>T.</given-names></name><name><surname>Hill</surname><given-names>D. L.</given-names></name><etal/></person-group>. (<year>2008</year>). <article-title>Intensity non-uniformity correction using N3 on 3-T scanners with multichannel phased array coils</article-title>. <source>Neuroimage</source><volume>39</volume>, <fpage>1752</fpage>–<lpage>1762</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.10.026</pub-id><?supplied-pmid 18063391?><pub-id pub-id-type="pmid">18063391</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chou</surname><given-names>N.</given-names></name><name><surname>Wu</surname><given-names>J.</given-names></name><name><surname>Bingren</surname><given-names>J. B.</given-names></name><name><surname>Qiu</surname><given-names>A.</given-names></name><name><surname>Chuang</surname><given-names>K.-H.</given-names></name></person-group> (<year>2011</year>). <article-title>Robust automatic rodent brain extraction using 3-D pulse-coupled neural networks (PCNN)</article-title>. <source>IEEE Trans. Image Process</source>. <volume>20</volume>, <fpage>2554</fpage>–<lpage>2564</lpage>. <pub-id pub-id-type="doi">10.1109/TIP.2011.2126587</pub-id><?supplied-pmid 21411404?><pub-id pub-id-type="pmid">21411404</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>R. W.</given-names></name></person-group> (<year>1996</year>). <article-title>AFNI: software for analysis and visualization of functional magnetic resonance neuroimages</article-title>. <source>Comput. Biomed. Res</source>. <volume>29</volume>, <fpage>162</fpage>–<lpage>173</lpage>. <pub-id pub-id-type="doi">10.1006/cbmr.1996.0014</pub-id><?supplied-pmid 8812068?><pub-id pub-id-type="pmid">8812068</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Feo</surname><given-names>R.</given-names></name><name><surname>Giove</surname><given-names>F.</given-names></name></person-group> (<year>2019</year>). <article-title>Towards an efficient segmentation of small rodents brain: a short critical review</article-title>. <source>J. Neurosci. Methods</source>
<volume>323</volume>, <fpage>82</fpage>–<lpage>89</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2019.05.003</pub-id><?supplied-pmid 31102669?><pub-id pub-id-type="pmid">31102669</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Eichelberg</surname><given-names>M.</given-names></name><name><surname>Riesmeier</surname><given-names>J.</given-names></name><name><surname>Wilkens</surname><given-names>T.</given-names></name><name><surname>Hewett</surname><given-names>A. J.</given-names></name><name><surname>Barth</surname><given-names>A.</given-names></name><name><surname>Jensch</surname><given-names>P.</given-names></name></person-group> (<year>2004</year>). <article-title>“Ten years of medical imaging standardization and prototypical implementation: the DICOM standard and the OFFIS DICOM toolkit (DCMTK),”</article-title> in <source>Medical Imaging 2004: PACS and Imaging Informatics</source>, <volume>Vol. 5371</volume> (<publisher-name>International Society for Optics and Photonics</publisher-name>), <fpage>57</fpage>–<lpage>69</lpage>. <pub-id pub-id-type="doi">10.1117/12.534853</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gansner</surname><given-names>E. R.</given-names></name><name><surname>North</surname><given-names>S. C.</given-names></name></person-group> (<year>2000</year>). <article-title>An open graph visualization system and its applications to software engineering</article-title>. <source>Softw. Pract. Exp</source>. <volume>30</volume>, <fpage>1203</fpage>–<lpage>1233</lpage>. <pub-id pub-id-type="doi">10.1002/1097-024X(200009)30:11&lt;1203::AID-SPE338&gt;3.0.CO;2-N</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Garin</surname><given-names>C. M.</given-names></name><name><surname>Nadkarni</surname><given-names>N. A.</given-names></name><name><surname>Bougacha</surname><given-names>S.</given-names></name><name><surname>Picq</surname><given-names>J.-L.</given-names></name><name><surname>Pepin</surname><given-names>J.</given-names></name><name><surname>Flament</surname><given-names>J.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>“Resting state, gluCEST and anatomical MRI approaches at 11.7T for brain aging studies in a non-human primate,”</article-title> in <source>Proceedings of the Joint Annual Meeting of the International Society for Magnetic Resonance in Medicine and European Society for Magnetic Resonance in Medicine and Biology</source> (<publisher-loc>Paris</publisher-loc>).</mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garin</surname><given-names>C. M.</given-names></name><name><surname>Nadkarni</surname><given-names>N. A.</given-names></name><name><surname>Landeau</surname><given-names>B.</given-names></name><name><surname>Chetelat</surname><given-names>G.</given-names></name><name><surname>Picq</surname><given-names>J.-L.</given-names></name><name><surname>Bougacha</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>Resting state cerebral networks in mouse lemur primates: from multilevel validation to comparison with humans</article-title>. <source>bioRixv</source>. <pub-id pub-id-type="doi">10.1101/599423</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glover</surname><given-names>G. H.</given-names></name></person-group> (<year>2011</year>). <article-title>Overview of functional magnetic resonance imaging</article-title>. <source>Neurosurg. Clin. N. Am</source>. <volume>22</volume>, <fpage>133</fpage>–<lpage>139</lpage>. <pub-id pub-id-type="doi">10.1016/j.nec.2010.11.001</pub-id><?supplied-pmid 21435566?><pub-id pub-id-type="pmid">21435566</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>K.</given-names></name><name><surname>Burns</surname><given-names>C. D.</given-names></name><name><surname>Madison</surname><given-names>C.</given-names></name><name><surname>Clark</surname><given-names>D.</given-names></name><name><surname>Halchenko</surname><given-names>Y. O.</given-names></name><name><surname>Waskom</surname><given-names>M. L.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in python</article-title>. <source>Front. Neuroinform</source>. <volume>5</volume>:<fpage>13</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2011.00013</pub-id><?supplied-pmid 21897815?><pub-id pub-id-type="pmid">21897815</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grandjean</surname><given-names>J.</given-names></name><name><surname>Canella</surname><given-names>C.</given-names></name><name><surname>Anckaerts</surname><given-names>C.</given-names></name><name><surname>Ayranci</surname><given-names>G.</given-names></name><name><surname>Bougacha</surname><given-names>S.</given-names></name><name><surname>Bienert</surname><given-names>T.</given-names></name><etal/></person-group>. (<year>2020</year>). <article-title>Common functional networks in the mouse brain revealed by multi-centre resting-state fMRI analysis</article-title>. <source>Neuroimage</source>, <volume>205</volume>:<fpage>116278</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116278</pub-id><?supplied-pmid 31614221?><pub-id pub-id-type="pmid">31614221</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanke</surname><given-names>M.</given-names></name><name><surname>Halchenko</surname><given-names>Y. O.</given-names></name></person-group> (<year>2011</year>). <article-title>Neuroscience runs on GNU/Linux</article-title>. <source>Front. Neuroinform</source>. <volume>5</volume>:<fpage>8</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2011.00008</pub-id><?supplied-pmid 21779243?><pub-id pub-id-type="pmid">21779243</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>X.</given-names></name><name><surname>To</surname><given-names>X. V.</given-names></name><name><surname>Teh</surname><given-names>I.</given-names></name><name><surname>Soh</surname><given-names>J. R.</given-names></name><name><surname>Chuang</surname><given-names>K.-H.</given-names></name></person-group> (<year>2015</year>). <article-title>Evaluation of EPI distortion correction methods for quantitative MRI of the brain at high magnetic field</article-title>. <source>Mag. Reson. Imaging</source>
<volume>33</volume>, <fpage>1098</fpage>–<lpage>1105</lpage>. <pub-id pub-id-type="doi">10.1016/j.mri.2015.06.010</pub-id><?supplied-pmid 26117700?><pub-id pub-id-type="pmid">26117700</pub-id></mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname><given-names>J. D.</given-names></name></person-group> (<year>2007</year>). <article-title>Matplotlib: A 2D graphics environment</article-title>. <source>Comput. Sci. Eng</source>. <volume>9</volume>:<fpage>90</fpage>
<pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ioanas</surname><given-names>H.-I.</given-names></name><name><surname>Marks</surname><given-names>M.</given-names></name><name><surname>Garin</surname><given-names>C.</given-names></name><name><surname>Dhenain</surname><given-names>M.</given-names></name><name><surname>Yanik</surname><given-names>M. F.</given-names></name><name><surname>Rudin</surname><given-names>M.</given-names></name></person-group> (<year>2020</year>). <article-title>An automated open-source workflow for standards-compliant integration of small animal magnetic resonance imaging data</article-title>. <source>Front. Neuroinform</source>. <volume>14</volume>:<fpage>5</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2020.00005</pub-id><?supplied-pmid 32116629?><pub-id pub-id-type="pmid">32116629</pub-id></mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M.</given-names></name><name><surname>Beckmann</surname><given-names>C. F.</given-names></name><name><surname>Behrens</surname><given-names>T. E.</given-names></name><name><surname>Woolrich</surname><given-names>M. W.</given-names></name><name><surname>Smith</surname><given-names>S. M.</given-names></name></person-group> (<year>2012</year>). <article-title>Fsl</article-title>. <source>Neuroimage</source>
<volume>62</volume>, <fpage>782</fpage>–<lpage>790</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.09.015</pub-id><?supplied-pmid 21979382?><pub-id pub-id-type="pmid">21979382</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kober</surname><given-names>F.</given-names></name><name><surname>Duhamel</surname><given-names>G.</given-names></name><name><surname>Cozzone</surname><given-names>P. J.</given-names></name></person-group> (<year>2008</year>). <article-title>Experimental comparison of four FAIR arterial spin labeling techniques for quantification of mouse cerebral blood flow at 4.7 T</article-title>. <source>NMR Biomed</source>. <volume>21</volume>, <fpage>781</fpage>–<lpage>792</lpage>. <pub-id pub-id-type="doi">10.1002/nbm.1253</pub-id><?supplied-pmid 18384177?><pub-id pub-id-type="pmid">18384177</pub-id></mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kovačević</surname><given-names>N.</given-names></name><name><surname>Henderson</surname><given-names>J.</given-names></name><name><surname>Chan</surname><given-names>E.</given-names></name><name><surname>Lifshitz</surname><given-names>N.</given-names></name><name><surname>Bishop</surname><given-names>J.</given-names></name><name><surname>Evans</surname><given-names>A.</given-names></name><etal/></person-group>. (<year>2005</year>). <article-title>A three-dimensional MRI atlas of the mouse brain with estimates of the average and variability</article-title>. <source>Cereb. Cortex</source><volume>15</volume>, <fpage>639</fpage>–<lpage>645</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhh165</pub-id><?supplied-pmid 15342433?><pub-id pub-id-type="pmid">15342433</pub-id></mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lancelot</surname><given-names>S.</given-names></name><name><surname>Roche</surname><given-names>R.</given-names></name><name><surname>Slimen</surname><given-names>A.</given-names></name><name><surname>Bouillot</surname><given-names>C.</given-names></name><name><surname>Levigoureux</surname><given-names>E.</given-names></name><name><surname>Langlois</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>A multi-atlas based method for automated anatomical rat brain MRI segmentation and extraction of PET activity</article-title>. <source>PLoS ONE</source><volume>9</volume>:<fpage>e109113</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0109113</pub-id><?supplied-pmid 25330005?><pub-id pub-id-type="pmid">25330005</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lein</surname><given-names>E. S.</given-names></name><name><surname>Hawrylycz</surname><given-names>M. J.</given-names></name><name><surname>Ao</surname><given-names>N.</given-names></name><name><surname>Ayres</surname><given-names>M.</given-names></name><name><surname>Bensinger</surname><given-names>A.</given-names></name><name><surname>Bernard</surname><given-names>A.</given-names></name><etal/></person-group>. (<year>2007</year>). <article-title>Genome-wide atlas of gene expression in the adult mouse brain</article-title>. <source>Nature</source><volume>445</volume>, <fpage>168</fpage>–<lpage>176</lpage>. <pub-id pub-id-type="doi">10.1038/nature05453</pub-id><?supplied-pmid 17151600?><pub-id pub-id-type="pmid">17151600</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Millman</surname><given-names>K. J.</given-names></name><name><surname>Aivazis</surname><given-names>M.</given-names></name></person-group> (<year>2011</year>). <article-title>Python for scientists and engineers</article-title>. <source>Comput. Sci. Eng</source>. <volume>13</volume>, <fpage>9</fpage>–<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1109/MCSE.2011.36</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nadkarni</surname><given-names>N. A.</given-names></name><name><surname>Bougacha</surname><given-names>S.</given-names></name><name><surname>Garin</surname><given-names>C.</given-names></name><name><surname>Dhenain</surname><given-names>M.</given-names></name><name><surname>Picq</surname><given-names>J.-L.</given-names></name></person-group> (<year>2018</year>). <article-title>Digital templates and brain atlas dataset for the mouse lemur primate</article-title>. <source>Data Brief</source>
<volume>21</volume>, <fpage>1178</fpage>–<lpage>1185</lpage>. <pub-id pub-id-type="doi">10.1016/j.dib.2018.10.067</pub-id><?supplied-pmid 30456231?><pub-id pub-id-type="pmid">30456231</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nadkarni</surname><given-names>N. A.</given-names></name><name><surname>Bougacha</surname><given-names>S.</given-names></name><name><surname>Garin</surname><given-names>C.</given-names></name><name><surname>Dhenain</surname><given-names>M.</given-names></name><name><surname>Picq</surname><given-names>J.-L.</given-names></name></person-group> (<year>2019</year>). <article-title>A 3D population-based brain atlas of the mouse lemur primate with examples of applications in aging studies and comparative anatomy</article-title>. <source>Neuroimage</source>
<volume>185</volume>, <fpage>85</fpage>–<lpage>95</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.10.010</pub-id><?supplied-pmid 30326295?><pub-id pub-id-type="pmid">30326295</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oguz</surname><given-names>I.</given-names></name><name><surname>Zhang</surname><given-names>H.</given-names></name><name><surname>Rumple</surname><given-names>A.</given-names></name><name><surname>Sonka</surname><given-names>M.</given-names></name></person-group> (<year>2014</year>). <article-title>RATS: rapid automatic tissue segmentation in rodent brain MRI</article-title>. <source>J. Neurosci. Methods</source>
<volume>221</volume>, <fpage>175</fpage>–<lpage>182</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2013.09.021</pub-id><?supplied-pmid 24140478?><pub-id pub-id-type="pmid">24140478</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Oliphant</surname><given-names>T. E.</given-names></name></person-group> (<year>2006</year>). <source>A Guide to NumPy</source>. <volume>Vol. 1</volume>
<publisher-name>Trelgol Publishing</publisher-name>.</mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pallast</surname><given-names>N.</given-names></name><name><surname>Diedenhofen</surname><given-names>M.</given-names></name><name><surname>Blaschke</surname><given-names>S.</given-names></name><name><surname>Wieters</surname><given-names>F.</given-names></name><name><surname>Wiedermann</surname><given-names>D.</given-names></name><name><surname>Hoehn</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Processing pipeline for atlas-based imaging data analysis of structural and functional mouse brain MRI (AIDAmri)</article-title>. <source>Front. Neuroinform</source>. <volume>13</volume>:<fpage>42</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2019.00042</pub-id><?supplied-pmid 31231202?><pub-id pub-id-type="pmid">31231202</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F.</given-names></name><name><surname>Varoquaux</surname><given-names>G.</given-names></name><name><surname>Gramfort</surname><given-names>A.</given-names></name><name><surname>Michel</surname><given-names>V.</given-names></name><name><surname>Thirion</surname><given-names>B.</given-names></name><name><surname>Grisel</surname><given-names>O.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Scikit-learn: Machine learning in Python</article-title>. <source>J. Mach. Learn. Res</source>. <volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Powell</surname><given-names>N. M.</given-names></name><name><surname>Modat</surname><given-names>M.</given-names></name><name><surname>Cardoso</surname><given-names>M. J.</given-names></name><name><surname>Ma</surname><given-names>D.</given-names></name><name><surname>Holmes</surname><given-names>H. E.</given-names></name><name><surname>Yu</surname><given-names>Y.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>Fully-automated μMRI morphometric phenotyping of the Tc1 mouse model of Down syndrome</article-title>. <source>PLoS ONE</source><volume>11</volume>:<fpage>e0162974</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0162974</pub-id><?supplied-pmid 27658297?><pub-id pub-id-type="pmid">27658297</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sargolzaei</surname><given-names>S.</given-names></name><name><surname>Cai</surname><given-names>Y.</given-names></name><name><surname>Wolahan</surname><given-names>S. M.</given-names></name><name><surname>Gaonkar</surname><given-names>B.</given-names></name><name><surname>Sargolzaei</surname><given-names>A.</given-names></name><name><surname>Giza</surname><given-names>C. C.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>“A comparative study of automatic approaches for preclinical MRI-based brain segmentation in the developing rat,”</article-title> in <source>2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</source> (<publisher-loc>Honolulu, HI</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>652</fpage>–<lpage>655</lpage>. <pub-id pub-id-type="doi">10.1109/EMBC.2018.8512402</pub-id><?supplied-pmid 30440481?></mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sawiak</surname><given-names>S.</given-names></name><name><surname>Wood</surname><given-names>N.</given-names></name><name><surname>Williams</surname><given-names>G.</given-names></name><name><surname>Morton</surname><given-names>A.</given-names></name><name><surname>Carpenter</surname><given-names>T.</given-names></name></person-group> (<year>2009</year>). <article-title>Voxel-based morphometry in the R6/2 transgenic mouse reveals differences between genotypes not seen with manual 2D morphometry</article-title>. <source>Neurobiol. Dis</source>. <volume>33</volume>, <fpage>20</fpage>–<lpage>27</lpage>. <pub-id pub-id-type="doi">10.1016/j.nbd.2008.09.016</pub-id><?supplied-pmid 18930824?><pub-id pub-id-type="pmid">18930824</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sled</surname><given-names>J. G.</given-names></name><name><surname>Zijdenbos</surname><given-names>A. P.</given-names></name><name><surname>Evans</surname><given-names>A. C.</given-names></name></person-group> (<year>1998</year>). <article-title>A nonparametric method for automatic correction of intensity nonuniformity in MRI data</article-title>. <source>IEEE Trans. Med. Imaging</source>
<volume>17</volume>, <fpage>87</fpage>–<lpage>97</lpage>. <pub-id pub-id-type="doi">10.1109/42.668698</pub-id><?supplied-pmid 9617910?><pub-id pub-id-type="pmid">9617910</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tustison</surname><given-names>N. J.</given-names></name><name><surname>Avants</surname><given-names>B. B.</given-names></name><name><surname>Cook</surname><given-names>P. A.</given-names></name><name><surname>Zheng</surname><given-names>Y.</given-names></name><name><surname>Egan</surname><given-names>A.</given-names></name><name><surname>Yushkevich</surname><given-names>P. A.</given-names></name><etal/></person-group>. (<year>2010</year>). <article-title>N4ITK: improved N3 bias correction</article-title>. <source>IEEE Trans. Med. Imaging</source><volume>29</volume>:<fpage>1310</fpage>. <pub-id pub-id-type="doi">10.1109/TMI.2010.2046908</pub-id><?supplied-pmid 20378467?><pub-id pub-id-type="pmid">20378467</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varoquaux</surname><given-names>G.</given-names></name><name><surname>Sadaghiani</surname><given-names>S.</given-names></name><name><surname>Pinel</surname><given-names>P.</given-names></name><name><surname>Kleinschmidt</surname><given-names>A.</given-names></name><name><surname>Poline</surname><given-names>J.-B.</given-names></name><name><surname>Thirion</surname><given-names>B.</given-names></name></person-group> (<year>2010</year>). <article-title>A group model for stable multi-subject ICA on fMRI datasets</article-title>. <source>Neuroimage</source>
<volume>51</volume>, <fpage>288</fpage>–<lpage>299</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.02.010</pub-id><?supplied-pmid 20153834?><pub-id pub-id-type="pmid">20153834</pub-id></mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wood</surname><given-names>T. C.</given-names></name><name><surname>Lythgoe</surname><given-names>D. J.</given-names></name><name><surname>Williams</surname><given-names>S. C.</given-names></name></person-group> (<year>2013</year>). <article-title>“rBET: making BET work for rodent brains,”</article-title> in <source>Proceedings of the 21th Meeting of the International Society for Magnetic Resonance in Medicine</source> (<publisher-loc>Salt Lake City, UT</publisher-loc>), <volume>Vol. 21</volume>, <fpage>2706</fpage>.</mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yin</surname><given-names>Y.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Williams</surname><given-names>R.</given-names></name><name><surname>Wu</surname><given-names>X.</given-names></name><name><surname>Anderson</surname><given-names>D. D.</given-names></name><name><surname>Sonka</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>). <article-title>LOGISMOS - Layered Optimal Graph Image Segmentation of Multiple Objects and Surfaces: cartilage segmentation in the knee joint</article-title>. <source>IEEE Trans. Med. Imaging</source>
<volume>29</volume>, <fpage>2023</fpage>–<lpage>2037</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2010.2058861</pub-id><?supplied-pmid 20643602?><pub-id pub-id-type="pmid">20643602</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zerbi</surname><given-names>V.</given-names></name><name><surname>Grandjean</surname><given-names>J.</given-names></name><name><surname>Rudin</surname><given-names>M.</given-names></name><name><surname>Wenderoth</surname><given-names>N.</given-names></name></person-group> (<year>2015</year>). <article-title>Mapping the mouse brain with Rs-fMRI: an optimized pipeline for functional network identification</article-title>. <source>Neuroimage</source>
<volume>123</volume>, <fpage>11</fpage>–<lpage>21</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.07.090</pub-id><?supplied-pmid 26296501?><pub-id pub-id-type="pmid">26296501</pub-id></mixed-citation>
    </ref>
    <ref id="B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>B. W.</given-names></name><name><surname>Lee</surname><given-names>P. T. H.</given-names></name><name><surname>Golay</surname><given-names>X.</given-names></name></person-group> (<year>2010</year>). <article-title>High-sensitivity cerebral perfusion mapping in mice by kbGRASE-fair at 9.4 t</article-title>. <source>NMR Biomed</source>. <volume>23</volume>, <fpage>1061</fpage>–<lpage>1070</lpage>. <pub-id pub-id-type="doi">10.1002/nbm.1533</pub-id><?supplied-pmid 20665907?><pub-id pub-id-type="pmid">20665907</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
