<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?subarticle pcbi.1011240.r001?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLOS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10343141</article-id>
    <article-id pub-id-type="pmid">37390111</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-23-00094</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
              <subj-group>
                <subject>Kernel Methods</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
            <subj-group>
              <subject>Kernel Methods</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Microbiology</subject>
          <subj-group>
            <subject>Medical Microbiology</subject>
            <subj-group>
              <subject>Microbiome</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Microbial Genomics</subject>
              <subj-group>
                <subject>Microbiome</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Microbiology</subject>
          <subj-group>
            <subject>Microbial Genomics</subject>
            <subj-group>
              <subject>Microbiome</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Operator Theory</subject>
            <subj-group>
              <subject>Kernel Functions</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Statistical Methods</subject>
            <subj-group>
              <subject>Forecasting</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical Methods</subject>
              <subj-group>
                <subject>Forecasting</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Gastroenterology and Hepatology</subject>
          <subj-group>
            <subject>Liver Diseases</subject>
            <subj-group>
              <subject>Cirrhosis</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Probability Theory</subject>
            <subj-group>
              <subject>Probability Distribution</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Topology</subject>
            <subj-group>
              <subject>Manifolds</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Supervised learning and model analysis with compositional data</article-title>
      <alt-title alt-title-type="running-head">
        <monospace specific-use="no-wrap">KernelBiome</monospace>
      </alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6919-821X</contrib-id>
        <name>
          <surname>Huang</surname>
          <given-names>Shimeng</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0008-6358-699X</contrib-id>
        <name>
          <surname>Ailer</surname>
          <given-names>Elisabeth</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8718-4305</contrib-id>
        <name>
          <surname>Kilbertus</surname>
          <given-names>Niki</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff003" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6203-9777</contrib-id>
        <name>
          <surname>Pfister</surname>
          <given-names>Niklas</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Department of Mathematical Sciences, University of Copenhagen, Copenhagen, Denmark</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Helmholtz Munich, Munich, Germany</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Technical University of Munich, Munich, Germany</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Coelho</surname>
          <given-names>Luis Pedro</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Fudan University, CHINA</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>shimeng@math.ku.dk</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>30</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <volume>19</volume>
    <issue>6</issue>
    <elocation-id>e1011240</elocation-id>
    <history>
      <date date-type="received">
        <day>19</day>
        <month>1</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>3</day>
        <month>6</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 Huang et al</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Huang et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1011240.pdf"/>
    <abstract>
      <p>Supervised learning, such as regression and classification, is an essential tool for analyzing modern high-throughput sequencing data, for example in microbiome research. However, due to the compositionality and sparsity, existing techniques are often inadequate. Either they rely on extensions of the linear log-contrast model (which adjust for compositionality but cannot account for complex signals or sparsity) or they are based on black-box machine learning methods (which may capture useful signals, but lack interpretability due to the compositionality). We propose <monospace specific-use="no-wrap">KernelBiome</monospace>, a kernel-based nonparametric regression and classification framework for compositional data. It is tailored to sparse compositional data and is able to incorporate prior knowledge, such as phylogenetic structure. <monospace specific-use="no-wrap">KernelBiome</monospace> captures complex signals, including in the zero-structure, while automatically adapting model complexity. We demonstrate on par or improved predictive performance compared with state-of-the-art machine learning methods on 33 publicly available microbiome datasets. Additionally, our framework provides two key advantages: (i) We propose two novel quantities to interpret contributions of individual components and prove that they consistently estimate average perturbation effects of the conditional mean, extending the interpretability of linear log-contrast coefficients to nonparametric models. (ii) We show that the connection between kernels and distances aids interpretability and provides a data-driven embedding that can augment further analysis. <monospace specific-use="no-wrap">KernelBiome</monospace> is available as an open-source Python package on PyPI and at <ext-link xlink:href="https://github.com/shimenghuang/KernelBiome" ext-link-type="uri">https://github.com/shimenghuang/KernelBiome</ext-link>.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>In recent years, advances in gene sequencing technology have allowed scientists to examine entire microbial communities within genetic samples. These communities interact with their surroundings in complex ways, potentially benefiting or harming the host they inhabit. However, analyzing the microbiome—the measured microbial community—is challenging due to the compositionality and sparsity of the data.</p>
      <p>In this study, we developed a statistical framework called <monospace specific-use="no-wrap">KernelBiome</monospace> to model the relationship between the microbiome and a target of interest, such as the host’s disease status. We utilized a type of machine learning model called kernel methods and adapted them to handle the compositional and sparse nature of the data, while also incorporating prior expert knowledge.</p>
      <p>Additionally, we introduced two new measures to help interpret the contributions of individual compositional components. Our approach also demonstrated that kernel methods increase interpretability in analyzing microbiome data. To make <monospace specific-use="no-wrap">KernelBiome</monospace> as accessible as possible, we have created an easy-to-use software package for researchers and practitioners to apply in their work.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100009708</institution-id>
            <institution>Novo Nordisk Fonden</institution>
          </institution-wrap>
        </funding-source>
        <award-id>0069071</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6919-821X</contrib-id>
          <name>
            <surname>Huang</surname>
            <given-names>Shimeng</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100009708</institution-id>
            <institution>Novo Nordisk Fonden</institution>
          </institution-wrap>
        </funding-source>
        <award-id>0069071</award-id>
        <principal-award-recipient>
          <name>
            <surname>Pfister</surname>
            <given-names>Niklas</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award003">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100009318</institution-id>
            <institution>Helmholtz Association</institution>
          </institution-wrap>
        </funding-source>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0008-6358-699X</contrib-id>
          <name>
            <surname>Ailer</surname>
            <given-names>Elisabeth</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>SH and NP are supported by a research grant (0069071) from Novo Nordisk Fonden. EA is supported by the Helmholtz Association under the joint research school "Munich School for Data Science - MUDS". The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="0"/>
      <page-count count="19"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>PLOS Publication Stage</meta-name>
        <meta-value>vor-update-to-uncorrected-proof</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>Publication Update</meta-name>
        <meta-value>2023-07-13</meta-value>
      </custom-meta>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All data analyzed in this paper has been previously published and is publicly available online. Details of data sources and preprocessing steps can be found in the appendix. All experiments are reproducible using the code in <ext-link xlink:href="https://github.com/shimenghuang/KernelBiome" ext-link-type="uri">https://github.com/shimenghuang/KernelBiome</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All data analyzed in this paper has been previously published and is publicly available online. Details of data sources and preprocessing steps can be found in the appendix. All experiments are reproducible using the code in <ext-link xlink:href="https://github.com/shimenghuang/KernelBiome" ext-link-type="uri">https://github.com/shimenghuang/KernelBiome</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>1 Introduction</title>
    <p>Compositional data, that is, measurements of parts of a whole, are common in many scientific disciplines. For example, mineral compositions in geology [<xref rid="pcbi.1011240.ref001" ref-type="bibr">1</xref>], element concentrations in chemistry [<xref rid="pcbi.1011240.ref002" ref-type="bibr">2</xref>], species compositions in ecology [<xref rid="pcbi.1011240.ref003" ref-type="bibr">3</xref>] and more recently high-throughput sequencing reads in microbiome science [<xref rid="pcbi.1011240.ref004" ref-type="bibr">4</xref>].</p>
    <p>Mathematically, any <italic toggle="yes">p</italic>-dimensional composition—by appropriate normalization—can be represented as a point on the simplex
<disp-formula id="pcbi.1011240.e001"><alternatives><graphic xlink:href="pcbi.1011240.e001.jpg" id="pcbi.1011240.e001g" position="anchor"/><mml:math id="M1" display="block" overflow="scroll"><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>≔</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:msup><mml:mo>∣</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msup><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></alternatives></disp-formula></p>
    <p>This complicates the statistical analysis, because the sum-to-one constraint of the simplex induces non-trivial dependencies between the components that may lead to false conclusions, if not appropriately taken into account.</p>
    <p>The statistics community has developed a substantial collection of parametric analysis techniques to account for the simplex structure. The most basic is the family of Dirichlet distributions. However, as pointed out already by [<xref rid="pcbi.1011240.ref005" ref-type="bibr">5</xref>], Dirichlet distributions cannot capture non-trivial dependence structures between the composition components and are thus too restrictive. [<xref rid="pcbi.1011240.ref005" ref-type="bibr">5</xref>] therefore introduced the <italic toggle="yes">log-ratio</italic> approach. It generates a family of distributions by projecting multivariate normal distributions into <inline-formula id="pcbi.1011240.e002"><alternatives><graphic xlink:href="pcbi.1011240.e002.jpg" id="pcbi.1011240.e002g" position="anchor"/><mml:math id="M2" display="inline" overflow="scroll"><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> via an appropriate log-ratio transformation (e.g., the additive log-ratio, centered log-ratio [<xref rid="pcbi.1011240.ref005" ref-type="bibr">5</xref>], or isometric log-ratio [<xref rid="pcbi.1011240.ref006" ref-type="bibr">6</xref>]). The resulting family of distributions results in parametric models on the simplex that are rich enough to capture non-trivial dependencies between the components (i.e., beyond those induced by the sum-to-one constraint). The log-ratio approach has been extended and adapted to a range of statistical problems [e.g., <xref rid="pcbi.1011240.ref007" ref-type="bibr">7</xref>–<xref rid="pcbi.1011240.ref011" ref-type="bibr">11</xref>].</p>
    <p>For supervised learning tasks the log-ratio approach leads to the <italic toggle="yes">log-contrast model</italic> [<xref rid="pcbi.1011240.ref012" ref-type="bibr">12</xref>]. An attractive property of the log-contrast model is that its coefficients quantify the effect of a multiplicative perturbation (i.e., fractionally increasing one component while adjusting the others) on the response. While several extensions of the log-contrast model exist [e.g., <xref rid="pcbi.1011240.ref013" ref-type="bibr">13</xref>–<xref rid="pcbi.1011240.ref017" ref-type="bibr">17</xref>], its parametric approach to supervised learning has two major shortcomings that become particularly severe when applied to high-dimensional and zero-inflated high-throughput sequencing data [<xref rid="pcbi.1011240.ref018" ref-type="bibr">18</xref>, <xref rid="pcbi.1011240.ref019" ref-type="bibr">19</xref>]. Firstly, since the logarithm is not defined at zero, the log-contrast model cannot be directly applied. A common fix is to add so-called pseudo-counts, a small non-zero constant, to all (zero) entries [<xref rid="pcbi.1011240.ref020" ref-type="bibr">20</xref>, <xref rid="pcbi.1011240.ref021" ref-type="bibr">21</xref>]. More sophisticated replacements exist as well [e.g., <xref rid="pcbi.1011240.ref022" ref-type="bibr">22</xref>–<xref rid="pcbi.1011240.ref024" ref-type="bibr">24</xref>], however, they often rely on knowing the nature of the zeros (e.g., whether they are structural or random), which is typically not available in practice and difficult to estimate. In any case, the downstream analysis will strongly depend on the selected zero imputation scheme [<xref rid="pcbi.1011240.ref025" ref-type="bibr">25</xref>]. Secondly, the relationships between individual components (e.g., species) and the response are generally complex. For example, in human microbiome settings, a health outcome may depend on interactions or on the presence or absence of species. Both cannot be captured by the linear structure of the log-contrast model.</p>
    <p>We propose to solve the supervised learning task using a nonparametric kernel approach, which is able to handle complex signals and avoid arbitrary zero-imputation. To be of use in biological applications, there are two components to a supervised analysis: (i) estimating a predictive model that accurately captures signals in the data and (ii) extracting meaningful and interpretable information from the estimated model. For (i), it has been shown that modern machine learning methods are capable of creating highly predictive models by using microbiome data as covariates and phenotypes as responses [e.g., <xref rid="pcbi.1011240.ref026" ref-type="bibr">26</xref>–<xref rid="pcbi.1011240.ref029" ref-type="bibr">29</xref>]. In particular, several approaches have been proposed where kernels are used to incorporate prior information [<xref rid="pcbi.1011240.ref030" ref-type="bibr">30</xref>, <xref rid="pcbi.1011240.ref031" ref-type="bibr">31</xref>], as a way to utilize the compositional structure [<xref rid="pcbi.1011240.ref032" ref-type="bibr">32</xref>–<xref rid="pcbi.1011240.ref034" ref-type="bibr">34</xref>] and to construct association tests [<xref rid="pcbi.1011240.ref035" ref-type="bibr">35</xref>–<xref rid="pcbi.1011240.ref037" ref-type="bibr">37</xref>]. Our proposed framework extends these works by providing new post-analysis techniques (e.g., the compositional feature influence) that respect the compositional structure. Recently, [<xref rid="pcbi.1011240.ref025" ref-type="bibr">25</xref>, <xref rid="pcbi.1011240.ref038" ref-type="bibr">38</xref>] used the radial transformation to argue that kernels on the sphere provide a natural way of analyzing compositions with zeros and similar to our work suggest using the kernel embeddings in a subsequent analysis. Part (ii) is related to the fields of explainable artificial intelligence [<xref rid="pcbi.1011240.ref039" ref-type="bibr">39</xref>] and interpretable machine learning [<xref rid="pcbi.1011240.ref040" ref-type="bibr">40</xref>], which focus on extracting information from predictive models. These types of approaches have also received growing attention in the context of microbiome data [<xref rid="pcbi.1011240.ref041" ref-type="bibr">41</xref>–<xref rid="pcbi.1011240.ref043" ref-type="bibr">43</xref>]. However, to the best of our knowledge, none of these procedures have been adjusted to account for the compositional structure. As we show in Sec. 2.1, not accounting for the compositionality may invalidate the results.</p>
    <p><monospace specific-use="no-wrap">KernelBiome</monospace>, see <xref rid="pcbi.1011240.g001" ref-type="fig">Fig 1</xref>, addresses both (i) by providing a regression and classification procedure based on kernels targeted to the simplex and (ii) by providing a principled way of analyzing the estimated models. Our contributions are fourfold: (1) We develop a theoretical framework for using kernels on compositional data. While using kernels to analyze various aspects of compositional data is not a new idea, a comprehensive analysis and its connection to existing approaches has been missing. In this work, we provide a range of kernels that each capture different aspects of the simplex structure, many of which have not been previously applied to compositional data. For all kernels, we derive novel, positive-definite weighted versions that allow incorporating prior information between the components. Additionally, we show that the distance associated with each kernel can be used to define a kernel-based scalar summary statistic. (2) We propose a theoretically justified analysis of kernel-based models that accounts for compositionality. Firstly, we introduce two novel quantities for measuring the effects of individual features that explicitly take the compositionality into account and prove that these can be consistently estimated. Secondly, we build on known connections between kernels and distance measures to advocate for using the kernel embedding from the estimated model to create visualizations and perform follow-up distance-based analyses that respect the compositionality. (3) We draw connections between <monospace specific-use="no-wrap">KernelBiome</monospace> and log-contrast-based analysis techniques. More specifically, we connect the Aitchison kernel to the log-contrast model, prove that the proposed compositional feature influence in this case reduces to the log-contrast coefficients, and show that our proposed weighted Aitchison kernel is related to the recently proposed tree-aggregation method of log-contrast coefficients [<xref rid="pcbi.1011240.ref044" ref-type="bibr">44</xref>]. Importantly, these connections ensure that <monospace specific-use="no-wrap">KernelBiome</monospace> reduces to standard log-contrast analysis techniques whenever simple log-contrast models are capable of capturing most of the signal. This is also illustrated by our experimental results. (4) We propose a data-adaptive selection framework that allows to compare different kernels in a principled fashion.</p>
    <fig position="float" id="pcbi.1011240.g001">
      <object-id pub-id-type="doi">10.1371/journal.pcbi.1011240.g001</object-id>
      <label>Fig 1</label>
      <caption>
        <title>Overview of <monospace specific-use="no-wrap">KernelBiome</monospace>.</title>
        <p>We start from a paired dataset with a compositional predictor <italic toggle="yes">X</italic> and a response <italic toggle="yes">Y</italic> and optional prior knowledge on the relation between components in the compositions (e.g., via a phylogenetic tree). We then select a model among a large class of kernels which best fits the data. This results in an estimated model <inline-formula id="pcbi.1011240.e003"><alternatives><graphic xlink:href="pcbi.1011240.e003" id="pcbi.1011240.e003g" position="anchor"/><mml:math id="M3" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and embedding <inline-formula id="pcbi.1011240.e004"><alternatives><graphic xlink:href="pcbi.1011240.e004" id="pcbi.1011240.e004g" position="anchor"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. Finally, these can be analyzed while accounting for the compositional structure.</p>
      </caption>
      <graphic xlink:href="pcbi.1011240.g001" position="float"/>
    </fig>
    <p>The paper is structured as follows. In Sec. 2, we introduce the supervised learning task, define two quantities for analyzing individual components (Sec. 2.1), give a short introduction to kernel methods and how to apply our methodology (Sec. 2.2), and present the full <monospace specific-use="no-wrap">KernelBiome</monospace> framework (Sec. 2.3). Finally, we illustrate the advantages of <monospace specific-use="no-wrap">KernelBiome</monospace> in the experiments in Sec. 3.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>2 Methods</title>
    <p>We consider the setting in which we observe <italic toggle="yes">n</italic> independent and identically distributed (i.i.d.) observations (<italic toggle="yes">X</italic><sub>1</sub>, <italic toggle="yes">Y</italic><sub>1</sub>), …, (<italic toggle="yes">X</italic><sub><italic toggle="yes">n</italic></sub>, <italic toggle="yes">Y</italic><sub><italic toggle="yes">n</italic></sub>) of a random variable (<italic toggle="yes">X</italic>, <italic toggle="yes">Y</italic>) with <inline-formula id="pcbi.1011240.e005"><alternatives><graphic xlink:href="pcbi.1011240.e005.jpg" id="pcbi.1011240.e005g" position="anchor"/><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> a compositional predictor and <inline-formula id="pcbi.1011240.e006"><alternatives><graphic xlink:href="pcbi.1011240.e006.jpg" id="pcbi.1011240.e006g" position="anchor"/><mml:math id="M6" display="inline" overflow="scroll"><mml:mrow><mml:mi>Y</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> a real-valued response variable (by which we include categorical responses). Supervised learning attempts to learn a relationship between the response <italic toggle="yes">Y</italic> and the dependent predictors <italic toggle="yes">X</italic>. In this work, we focus on conditional mean relationships. More specifically, we are interested in estimating the conditional mean of <italic toggle="yes">Y</italic>, that is, the function
<disp-formula id="pcbi.1011240.e007"><alternatives><graphic xlink:href="pcbi.1011240.e007.jpg" id="pcbi.1011240.e007g" position="anchor"/><mml:math id="M7" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>:</mml:mo><mml:mi>x</mml:mi><mml:mo>↦</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>Y</mml:mi><mml:mo>∣</mml:mo><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula>
We assume that <inline-formula id="pcbi.1011240.e008"><alternatives><graphic xlink:href="pcbi.1011240.e008.jpg" id="pcbi.1011240.e008g" position="anchor"/><mml:math id="M8" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:mi mathvariant="script">F</mml:mi><mml:mo>⊆</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi>f</mml:mi><mml:mo>∣</mml:mo><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>→</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1011240.e009"><alternatives><graphic xlink:href="pcbi.1011240.e009.jpg" id="pcbi.1011240.e009g" position="anchor"/><mml:math id="M9" display="inline" overflow="scroll"><mml:mi mathvariant="script">F</mml:mi></mml:math></alternatives></inline-formula> is a function class determined by the regression (or classification) procedure.</p>
    <p>While estimating and analyzing the conditional mean is well established for predictors in Euclidean space, there are two factors that complicate the analysis when the predictors are compositional. (i) While it is possible to directly apply most standard regression procedures designed for <inline-formula id="pcbi.1011240.e010"><alternatives><graphic xlink:href="pcbi.1011240.e010.jpg" id="pcbi.1011240.e010g" position="anchor"/><mml:math id="M10" display="inline" overflow="scroll"><mml:mrow><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> also for <inline-formula id="pcbi.1011240.e011"><alternatives><graphic xlink:href="pcbi.1011240.e011.jpg" id="pcbi.1011240.e011g" position="anchor"/><mml:math id="M11" display="inline" overflow="scroll"><mml:mrow><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, it turns out that many approaches are ill-suited to approximate functions on the simplex. (ii) Even if one accurately estimates the conditional mean function <italic toggle="yes">f</italic>*, the simplex constraint complicates any direct assessment of the influence and importance of individual components of the compositional predictor. In this work, we address both issues and propose a nonparametric framework for regression and classification analysis for compositional data.</p>
    <sec id="sec003">
      <title>2.1 Interpreting individual features</title>
      <p>Our goal when estimating the conditional mean <italic toggle="yes">f</italic>* given in <xref rid="pcbi.1011240.e007" ref-type="disp-formula">(1)</xref> is to gain insight into the relationship between the response <italic toggle="yes">Y</italic> and predictors <italic toggle="yes">X</italic>. For example, when fitting a log-contrast model (see Example 2.1), the estimated coefficients provide a useful tool to generate hypotheses about which features affect the response and thereby inform follow-up experiments. For more complex models, such as the nonparametric methods proposed in this work, direct interpretation of a fitted model <inline-formula id="pcbi.1011240.e012"><alternatives><graphic xlink:href="pcbi.1011240.e012.jpg" id="pcbi.1011240.e012g" position="anchor"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is difficult. Two widely applicable measures due to [<xref rid="pcbi.1011240.ref045" ref-type="bibr">45</xref>] are the following: (i) Relative influence, which assigns each coordinate <italic toggle="yes">j</italic> a scalar influence value given by the expected partial derivative <inline-formula id="pcbi.1011240.e013"><alternatives><graphic xlink:href="pcbi.1011240.e013.jpg" id="pcbi.1011240.e013g" position="anchor"/><mml:math id="M13" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mo>[</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mi>d</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msup></mml:mrow></mml:mfrac></mml:mstyle><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and (ii) partial dependence plots, which are constructed by plotting, for each coordinate <italic toggle="yes">j</italic>, the function <inline-formula id="pcbi.1011240.e014"><alternatives><graphic xlink:href="pcbi.1011240.e014.jpg" id="pcbi.1011240.e014g" position="anchor"/><mml:math id="M14" display="inline" overflow="scroll"><mml:mrow><mml:mi>z</mml:mi><mml:mo>↦</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mo>[</mml:mo><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mi>p</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. However, directly applying these measures on the simplex is not possible as we illustrate in Fig B in <xref rid="pcbi.1011240.s004" ref-type="supplementary-material">S4 Appendix</xref>. The intuition is that both measures evaluate the function <inline-formula id="pcbi.1011240.e015"><alternatives><graphic xlink:href="pcbi.1011240.e015.jpg" id="pcbi.1011240.e015g" position="anchor"/><mml:math id="M15" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> outside the simplex. An adaptation of the relative influence (or elasticity in the econometrics literature) to compositions based on the Aitchison geometry has recently been proposed by [<xref rid="pcbi.1011240.ref046" ref-type="bibr">46</xref>]. We adapt the relative influence without relying on the log-ratio transform and hence allow for more general function classes.</p>
      <p>Our approach is based on two coordinate-wise perturbations on the simplex. For any <italic toggle="yes">j</italic> ∈ {1, …, <italic toggle="yes">p</italic>} and <inline-formula id="pcbi.1011240.e016"><alternatives><graphic xlink:href="pcbi.1011240.e016.jpg" id="pcbi.1011240.e016g" position="anchor"/><mml:math id="M16" display="inline" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, define (i) for <italic toggle="yes">c</italic> ∈ [0, ∞) the function <inline-formula id="pcbi.1011240.e017"><alternatives><graphic xlink:href="pcbi.1011240.e017.jpg" id="pcbi.1011240.e017g" position="anchor"/><mml:math id="M17" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> to be the composition resulting from multiplying the <italic toggle="yes">j</italic>-th component by <italic toggle="yes">c</italic> and then scaling the entire vector back into the simplex, and (ii) for <italic toggle="yes">c</italic> ∈ [0, 1] the function <inline-formula id="pcbi.1011240.e018"><alternatives><graphic xlink:href="pcbi.1011240.e018.jpg" id="pcbi.1011240.e018g" position="anchor"/><mml:math id="M18" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> to be the composition that consists of fixing the <italic toggle="yes">j</italic>-th coordinate to <italic toggle="yes">c</italic> and then rescaling all remaining coordinates such that the resulting vector lies in the simplex. Each perturbation can be seen as a different way of intervening on a single coordinate while preserving the simplex structure. More details are given in <xref rid="pcbi.1011240.s001" ref-type="supplementary-material">S1 Appendix</xref>. Based on the first perturbation, we define the <italic toggle="yes">compositional feature influence</italic> (CFI) of component <italic toggle="yes">j</italic> ∈ {1, …, <italic toggle="yes">p</italic>} for any differentiable function <inline-formula id="pcbi.1011240.e019"><alternatives><graphic xlink:href="pcbi.1011240.e019.jpg" id="pcbi.1011240.e019g" position="anchor"/><mml:math id="M19" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>→</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> by
<disp-formula id="pcbi.1011240.e020"><alternatives><graphic xlink:href="pcbi.1011240.e020.jpg" id="pcbi.1011240.e020g" position="anchor"/><mml:math id="M20" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mtext mathcolor="gray">(CFI)</mml:mtext></mml:mrow><mml:mspace width="2em"/><mml:msubsup><mml:mi>I</mml:mi><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>≔</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mo>[</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mi>d</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ψ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>]</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(2)</label></disp-formula>
Similarly, we adapt partial dependence plots using the second perturbation. Define the <italic toggle="yes">compositional feature dependence</italic> (CPD) of component <italic toggle="yes">j</italic> ∈ {1, …, <italic toggle="yes">p</italic>} for any function <inline-formula id="pcbi.1011240.e021"><alternatives><graphic xlink:href="pcbi.1011240.e021.jpg" id="pcbi.1011240.e021g" position="anchor"/><mml:math id="M21" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>→</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> by
<disp-formula id="pcbi.1011240.e022"><alternatives><graphic xlink:href="pcbi.1011240.e022.jpg" id="pcbi.1011240.e022g" position="anchor"/><mml:math id="M22" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mtext mathcolor="gray">(CPD)</mml:mtext></mml:mrow><mml:mspace width="2em"/><mml:msubsup><mml:mi>S</mml:mi><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>:</mml:mo><mml:mi>z</mml:mi><mml:mo>↦</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(3)</label></disp-formula>
In practice, we can compute Monte Carlo estimates of both quantities by replacing expectations with empirical means. We denote the corresponding estimators by <inline-formula id="pcbi.1011240.e023"><alternatives><graphic xlink:href="pcbi.1011240.e023.jpg" id="pcbi.1011240.e023g" position="anchor"/><mml:math id="M23" display="inline" overflow="scroll"><mml:msubsup><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1011240.e024"><alternatives><graphic xlink:href="pcbi.1011240.e024.jpg" id="pcbi.1011240.e024g" position="anchor"/><mml:math id="M24" display="inline" overflow="scroll"><mml:msubsup><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, respectively (see <xref rid="pcbi.1011240.s001" ref-type="supplementary-material">S1 Appendix</xref> for details).</p>
      <p>The following proposition connects the CFI and CPD to the coefficients in a log-contrast function.</p>
      <p><bold>Proposition 2.1</bold> (CFI and CPD in the log-contrast model). Let <italic toggle="yes">f</italic> : <italic toggle="yes">x</italic> ↦ <italic toggle="yes">β</italic><sup><italic toggle="yes">T</italic></sup> log(<italic toggle="yes">x</italic>) with <inline-formula id="pcbi.1011240.e025"><alternatives><graphic xlink:href="pcbi.1011240.e025.jpg" id="pcbi.1011240.e025g" position="anchor"/><mml:math id="M25" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msub><mml:mi>β</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, then the CFI and CPD are given by
<disp-formula id="pcbi.1011240.e026"><alternatives><graphic xlink:href="pcbi.1011240.e026.jpg" id="pcbi.1011240.e026g" position="anchor"/><mml:math id="M26" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mspace width="1em"/><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:msubsup><mml:mi>S</mml:mi><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>:</mml:mo><mml:mi>z</mml:mi><mml:mo>↦</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mspace width="2pt"/><mml:mtext>log</mml:mtext><mml:mspace width="2pt"/><mml:mo>(</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:msup><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msup><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msup></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
respectively, where <inline-formula id="pcbi.1011240.e027"><alternatives><graphic xlink:href="pcbi.1011240.e027.jpg" id="pcbi.1011240.e027g" position="anchor"/><mml:math id="M27" display="inline" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> is a constant depending on the distribution of <italic toggle="yes">X</italic> but not on <italic toggle="yes">z</italic> and satisfies <italic toggle="yes">c</italic> = 0 if <italic toggle="yes">β</italic><sub><italic toggle="yes">j</italic></sub> = 0.</p>
      <p>A proof is given in <xref rid="pcbi.1011240.s006" ref-type="supplementary-material">S6 Appendix</xref>. The proposition shows that the CFI and CPD are generalizations of the <italic toggle="yes">β</italic>-coefficients in the log-contrast model. The following example provides further intuition.</p>
      <p><bold>Example 2.1</bold> (CFI and CPD in a log-contrast model). Consider a log-contrast model <italic toggle="yes">Y</italic> = <italic toggle="yes">f</italic>(<italic toggle="yes">X</italic>) + <italic toggle="yes">ϵ</italic> with <italic toggle="yes">f</italic> : <italic toggle="yes">x</italic> ↦ 2 log(<italic toggle="yes">x</italic><sup>1</sup>) − log(<italic toggle="yes">x</italic><sup>2</sup>) − log(<italic toggle="yes">x</italic><sup>3</sup>).</p>
      <p>The CFI and CPD for the true function <italic toggle="yes">f</italic>—estimated based on <italic toggle="yes">n</italic> = 100 i.i.d. samples (<italic toggle="yes">X</italic><sub>1</sub>, <italic toggle="yes">Y</italic><sub>1</sub>), …, (<italic toggle="yes">X</italic><sub><italic toggle="yes">n</italic></sub>, <italic toggle="yes">Y</italic><sub><italic toggle="yes">n</italic></sub>) with <italic toggle="yes">X</italic><sub><italic toggle="yes">i</italic></sub> compositional log-normal—are shown in <xref rid="pcbi.1011240.g002" ref-type="fig">Fig 2</xref>.</p>
      <fig position="float" id="pcbi.1011240.g002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011240.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Visualization of the CPD (left) and CFI (right) based on <italic toggle="yes">n</italic> = 100 samples and the true function <italic toggle="yes">f</italic>.</title>
          <p>Since <italic toggle="yes">β</italic><sub>4</sub> = 0 in this example the 4-th component has no effect on the value of <italic toggle="yes">f</italic> resulting in a CFI of zero and a flat CPD. Since we are not estimating <italic toggle="yes">f</italic>, the CFI values exactly correspond to the <italic toggle="yes">β</italic>-coefficients in this example.</p>
        </caption>
        <graphic xlink:href="pcbi.1011240.g002" position="float"/>
      </fig>
      <p>The following theorem highlights the usefulness of the CFI and CPD by establishing when they can be consistently estimated from data.</p>
      <p><bold>Theorem 2.1</bold> (Consistency). Assume <inline-formula id="pcbi.1011240.e028"><alternatives><graphic xlink:href="pcbi.1011240.e028.jpg" id="pcbi.1011240.e028g" position="anchor"/><mml:math id="M28" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula> is an estimator of the conditional mean <italic toggle="yes">f</italic>* given in <xref rid="pcbi.1011240.e007" ref-type="disp-formula">(1)</xref> based on (<italic toggle="yes">X</italic><sub>1</sub>, <italic toggle="yes">Y</italic><sub>1</sub>), …, (<italic toggle="yes">X</italic><sub><italic toggle="yes">n</italic></sub>, <italic toggle="yes">Y</italic><sub><italic toggle="yes">n</italic></sub>) i.i.d.</p>
      <list list-type="simple">
        <list-item>
          <p>(i) If <inline-formula id="pcbi.1011240.e029"><alternatives><graphic xlink:href="pcbi.1011240.e029.jpg" id="pcbi.1011240.e029g" position="anchor"/><mml:math id="M29" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>‖</mml:mo><mml:mi mathvariant="normal">∇</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">∇</mml:mi><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mo>‖</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mover><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mover><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> as <italic toggle="yes">n</italic> → ∞ and <inline-formula id="pcbi.1011240.e030"><alternatives><graphic xlink:href="pcbi.1011240.e030.jpg" id="pcbi.1011240.e030g" position="anchor"/><mml:math id="M30" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mo>[</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">∇</mml:mi><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>]</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, then it holds for all <italic toggle="yes">j</italic> ∈ {1, …, <italic toggle="yes">p</italic>} that
<disp-formula id="pcbi.1011240.e031"><alternatives><graphic xlink:href="pcbi.1011240.e031.jpg" id="pcbi.1011240.e031g" position="anchor"/><mml:math id="M31" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mover><mml:mo>⟶</mml:mo><mml:mi>P</mml:mi></mml:mover><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mspace width="1em"/><mml:mtext>as</mml:mtext><mml:mspace width="4pt"/><mml:mi>n</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></p>
        </list-item>
        <list-item>
          <p>(ii) If <inline-formula id="pcbi.1011240.e032"><alternatives><graphic xlink:href="pcbi.1011240.e032.jpg" id="pcbi.1011240.e032g" position="anchor"/><mml:math id="M32" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mtext>sup</mml:mtext><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mtext>supp</mml:mtext><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mover><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mover><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> as <italic toggle="yes">n</italic> → ∞ and supp(<italic toggle="yes">X</italic>) = {<italic toggle="yes">w</italic>/(∑<sub><italic toggle="yes">j</italic></sub>
<italic toggle="yes">w</italic><sup><italic toggle="yes">j</italic></sup>)∣<italic toggle="yes">w</italic> ∈ supp(<italic toggle="yes">X</italic><sup>1</sup>) × ⋯ × supp(<italic toggle="yes">X</italic><sup><italic toggle="yes">p</italic></sup>)}, then it holds for all <italic toggle="yes">j</italic> ∈ {1, …, <italic toggle="yes">p</italic>} and all <italic toggle="yes">z</italic> ∈ [0, 1] with <italic toggle="yes">z</italic>/(1 − <italic toggle="yes">z</italic>) ∈ supp(<italic toggle="yes">X</italic><sup><italic toggle="yes">j</italic></sup>/∑<sub><italic toggle="yes">ℓ</italic>≠<italic toggle="yes">j</italic></sub>
<italic toggle="yes">X</italic><sup><italic toggle="yes">ℓ</italic></sup>) that
<disp-formula id="pcbi.1011240.e033"><alternatives><graphic xlink:href="pcbi.1011240.e033.jpg" id="pcbi.1011240.e033g" position="anchor"/><mml:math id="M33" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mover><mml:mo>⟶</mml:mo><mml:mi>P</mml:mi></mml:mover><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="1em"/><mml:mtext>as</mml:mtext><mml:mspace width="4pt"/><mml:mi>n</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></p>
        </list-item>
      </list>
      <p>A proof is given in <xref rid="pcbi.1011240.s006" ref-type="supplementary-material">S6 Appendix</xref> and the result is demonstrated on simulated data in Fig A in <xref rid="pcbi.1011240.s004" ref-type="supplementary-material">S4 Appendix</xref>. The theorem shows that the CFI is consistently estimated as long as the derivative of <italic toggle="yes">f</italic>* is consistently estimated, which can be ensured for example for the kernel methods discussed in Sec. 2.2. In contrast, the CPD only requires the function <italic toggle="yes">f</italic>* itself to be consistently estimated. The additional assumption on the support ensures that the perturbation <italic toggle="yes">ϕ</italic><sub><italic toggle="yes">j</italic></sub> used in the CPD remains within the support. If this assumption is not satisfied one needs to ensure that the estimated function extrapolates beyond the sample support. Interpreting the CPD therefore requires caution.</p>
    </sec>
    <sec id="sec004">
      <title>2.2 Kernel methods for compositional data analysis</title>
      <p>Before presenting our proposed weighted and unweighted kernels, we briefly review the necessary background on kernels and their connection to distances. Kernel methods are a powerful class of nonparametric statistical methods that are particularly useful for data from non-standard (i.e., non-Euclidean) domains <inline-formula id="pcbi.1011240.e034"><alternatives><graphic xlink:href="pcbi.1011240.e034.jpg" id="pcbi.1011240.e034g" position="anchor"/><mml:math id="M34" display="inline" overflow="scroll"><mml:mi mathvariant="script">X</mml:mi></mml:math></alternatives></inline-formula>. The starting point is a symmetric, positive definite function <inline-formula id="pcbi.1011240.e035"><alternatives><graphic xlink:href="pcbi.1011240.e035.jpg" id="pcbi.1011240.e035g" position="anchor"/><mml:math id="M35" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi><mml:mo>:</mml:mo><mml:mi mathvariant="script">X</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="script">X</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, called kernel. Kernels encode similarities between points in <inline-formula id="pcbi.1011240.e036"><alternatives><graphic xlink:href="pcbi.1011240.e036.jpg" id="pcbi.1011240.e036g" position="anchor"/><mml:math id="M36" display="inline" overflow="scroll"><mml:mi mathvariant="script">X</mml:mi></mml:math></alternatives></inline-formula>, i.e., large values of <italic toggle="yes">k</italic> correspond to points that are similar and small values to points that are less similar. Instead of directly analyzing the data on <inline-formula id="pcbi.1011240.e037"><alternatives><graphic xlink:href="pcbi.1011240.e037.jpg" id="pcbi.1011240.e037g" position="anchor"/><mml:math id="M37" display="inline" overflow="scroll"><mml:mi mathvariant="script">X</mml:mi></mml:math></alternatives></inline-formula>, kernel methods map it into a well-behaved feature space <inline-formula id="pcbi.1011240.e038"><alternatives><graphic xlink:href="pcbi.1011240.e038.jpg" id="pcbi.1011240.e038g" position="anchor"/><mml:math id="M38" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⊆</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi>f</mml:mi><mml:mo>∣</mml:mo><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:mi mathvariant="script">X</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> called reproducing kernel Hilbert space (RKHS), whose inner product preserves the kernel induced similarity.</p>
      <p>Here, we consider kernels on the simplex, that is, <inline-formula id="pcbi.1011240.e039"><alternatives><graphic xlink:href="pcbi.1011240.e039.jpg" id="pcbi.1011240.e039g" position="anchor"/><mml:math id="M39" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">X</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. The conditional mean function <italic toggle="yes">f</italic>* given in <xref rid="pcbi.1011240.e007" ref-type="disp-formula">(1)</xref> can then be estimated by optimizing a loss over <inline-formula id="pcbi.1011240.e040"><alternatives><graphic xlink:href="pcbi.1011240.e040.jpg" id="pcbi.1011240.e040g" position="anchor"/><mml:math id="M40" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, for an appropriate kernel <italic toggle="yes">k</italic> for which <inline-formula id="pcbi.1011240.e041"><alternatives><graphic xlink:href="pcbi.1011240.e041.jpg" id="pcbi.1011240.e041g" position="anchor"/><mml:math id="M41" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula> is sufficiently rich, i.e., <inline-formula id="pcbi.1011240.e042"><alternatives><graphic xlink:href="pcbi.1011240.e042.jpg" id="pcbi.1011240.e042g" position="anchor"/><mml:math id="M42" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. The representer theorem [e.g., <xref rid="pcbi.1011240.ref047" ref-type="bibr">47</xref>] states that such an optimization over <inline-formula id="pcbi.1011240.e043"><alternatives><graphic xlink:href="pcbi.1011240.e043.jpg" id="pcbi.1011240.e043g" position="anchor"/><mml:math id="M43" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula> can be performed efficiently. Formally, it states that the minimizer of an arbitrary convex loss function <inline-formula id="pcbi.1011240.e044"><alternatives><graphic xlink:href="pcbi.1011240.e044.jpg" id="pcbi.1011240.e044g" position="anchor"/><mml:math id="M44" display="inline" overflow="scroll"><mml:mrow><mml:mi>L</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>×</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>→</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>∞</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> of the form
<disp-formula id="pcbi.1011240.e045"><alternatives><graphic xlink:href="pcbi.1011240.e045.jpg" id="pcbi.1011240.e045g" position="anchor"/><mml:math id="M45" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mtext>arg</mml:mtext><mml:mspace width="2pt"/><mml:mtext>min</mml:mtext></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mi>L</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">λ</mml:mi><mml:mo>‖</mml:mo><mml:mi>f</mml:mi><mml:mo>‖</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
with λ &gt; 0 a penalty parameter, has the form <inline-formula id="pcbi.1011240.e046"><alternatives><graphic xlink:href="pcbi.1011240.e046.jpg" id="pcbi.1011240.e046g" position="anchor"/><mml:math id="M46" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mover accent="true"><mml:mi>α</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> for some <inline-formula id="pcbi.1011240.e047"><alternatives><graphic xlink:href="pcbi.1011240.e047.jpg" id="pcbi.1011240.e047g" position="anchor"/><mml:math id="M47" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>α</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. This means that instead of optimizing over a potentially infinite-dimensional space <inline-formula id="pcbi.1011240.e048"><alternatives><graphic xlink:href="pcbi.1011240.e048.jpg" id="pcbi.1011240.e048g" position="anchor"/><mml:math id="M48" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, it is sufficient to optimize over the <italic toggle="yes">n</italic>-dimensional parameter <inline-formula id="pcbi.1011240.e049"><alternatives><graphic xlink:href="pcbi.1011240.e049.jpg" id="pcbi.1011240.e049g" position="anchor"/><mml:math id="M49" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>α</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. Depending on the loss function, this allows to construct efficient regression and classification procedures, such as kernel ridge regression and support vector machines [e.g., <xref rid="pcbi.1011240.ref047" ref-type="bibr">47</xref>].</p>
      <p>The performance of the resulting prediction model depends on the choice of kernel as this determines the function space <inline-formula id="pcbi.1011240.e050"><alternatives><graphic xlink:href="pcbi.1011240.e050.jpg" id="pcbi.1011240.e050g" position="anchor"/><mml:math id="M50" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula>. A useful way of thinking about kernels is via their connection to distances. In short, any kernel <italic toggle="yes">k</italic> induces a unique semi-metric <italic toggle="yes">d</italic><sub><italic toggle="yes">k</italic></sub> and vice versa. More details are given in <xref rid="pcbi.1011240.s005" ref-type="supplementary-material">S5 Appendix</xref>. This connection has two important implications. Firstly, it provides a natural way for constructing kernels based on established distances on the simplex. The intuition being that a distance, which is large for observations with vastly different responses and small otherwise, leads to an informative feature space <inline-formula id="pcbi.1011240.e051"><alternatives><graphic xlink:href="pcbi.1011240.e051.jpg" id="pcbi.1011240.e051g" position="anchor"/><mml:math id="M51" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula>. Secondly, it motivates using the kernel-induced distance, see Sec. 2.3.2.</p>
      <sec id="sec005">
        <title>2.2.1 Kernels on the simplex</title>
        <p>We consider four types of kernels on the simplex, each related to different types of distances. A full list with all kernels and induced distances is provided in <xref rid="pcbi.1011240.s007" ref-type="supplementary-material">S7 Appendix</xref>. While most kernels have previously appeared in the literature, we have adapted many of the kernels to fit into the framework provided here, e.g., added zero-imputation for Aitchison kernels and updated the parametrization for the probability distribution kernels.</p>
        <p><bold>Euclidean</bold>. These are kernels that are constructed by restricting kernels on <inline-formula id="pcbi.1011240.e052"><alternatives><graphic xlink:href="pcbi.1011240.e052.jpg" id="pcbi.1011240.e052g" position="anchor"/><mml:math id="M52" display="inline" overflow="scroll"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:math></alternatives></inline-formula> to the simplex. Any such restriction immediately guarantees that the restricted kernel is again a kernel. However, the induced distances are not targeted to the simplex and therefore can be unnatural choices. In <monospace specific-use="no-wrap">KernelBiome</monospace>, we have included the linear kernel and the radial basis function (RBF) kernel. The RBF kernel is <italic toggle="yes">L</italic><sup><italic toggle="yes">p</italic></sup>-universal [e.g., <xref rid="pcbi.1011240.ref048" ref-type="bibr">48</xref>] which means that it can approximate any integrable function (in the large sample limit). However, this does not necessarily imply good performance for finite sample sizes.</p>
        <p><bold>Aitchison geometry</bold>. One way of incorporating the simplex structure is to use the Aitchison geometry. Essentially, this corresponds to mapping points from the interior of the simplex via the centered log-ratio transform into <inline-formula id="pcbi.1011240.e053"><alternatives><graphic xlink:href="pcbi.1011240.e053.jpg" id="pcbi.1011240.e053g" position="anchor"/><mml:math id="M53" display="inline" overflow="scroll"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:math></alternatives></inline-formula> and then using the Euclidean geometry. This results in the Aitchison kernel for which the induced RKHS is equal to the log-contrast functions. In particular, applying kernel ridge regression with an Aitchison kernel corresponds to fitting a log-contrast model with a penalty on the coefficients. As the centered log-ratio transform is only defined for interior points in the simplex, we add a hyperparameter to the kernels that shift them away from zero. From this perspective, the commonly added pseudo-count constant added to all components becomes a tuneable hyperparameter of our method, rather than a fixed ad-hoc choice during data pre-processing. Thereby, our modified Aitchison kernel respects the fact that current approaches to zero-replacement or imputation are often not biologically justified, yet may impact predictive performance. Our proposed zero-imputed Aitchison kernel comes with two advantages over standard log-contrast modelling: (1) A principled adjustment for zeros and (2) an efficient form of high-dimensional regularization that performs well across a large range of our experiments. In <monospace specific-use="no-wrap">KernelBiome</monospace>, we include the Aitchison kernel and the Aitchison-RBF kernel which combines the Aitchison and RBF kernels.</p>
        <p><bold>Probability distributions</bold>. Another approach to incorporate the simplex structure into the kernel is to view points in the simplex as discrete probability distributions. This allows us to make use of the extensive literature on distances between probability distributions to construct kernels. In <monospace specific-use="no-wrap">KernelBiome</monospace>, we have adapted two classes of such kernels: (1) A parametric class based on generalized Jensen-Shannon distances due to [<xref rid="pcbi.1011240.ref049" ref-type="bibr">49</xref>], which we call generalized-JS, and (2) a parametric class based on the work by [<xref rid="pcbi.1011240.ref050" ref-type="bibr">50</xref>], which we call Hilbertian. Together they contain many well-established distances such as the total variation, Hellinger, Chi-squared, and Jensen-Shannon distance. All resulting kernels allow for zeros in the components of compositions.</p>
        <p><bold>Riemannian manifold</bold>. Finally, the simplex structure can be incorporated by using a multinomial distribution which has a parameter in the simplex. [<xref rid="pcbi.1011240.ref051" ref-type="bibr">51</xref>] show that the geometry of multinomial statistical models can be exploited by using kernels based on the heat equation on a Riemannian manifold. The resulting kernel is known as the heat-diffusion kernel and has been observed to work well with sparse data.</p>
      </sec>
      <sec id="sec006">
        <title>2.2.2 Including prior information into kernels</title>
        <p>All kernels introduced in the previous section (and described in detail in <xref rid="pcbi.1011240.s007" ref-type="supplementary-material">S7 Appendix</xref>) are invariant under permutations of the compositional components. They therefore do not take into account any relation between the components. In many applications, one may however have prior knowledge about the relation between the components. For example, if the compositional predictor consists of relative abundances of microbial species, information about the genetic relation between different species encoded in a phylogenetic tree may be available. Therefore, we provide the following way to incorporate such relations. Assume the prior information has been expressed as a positive semi-definite weight matrix <inline-formula id="pcbi.1011240.e054"><alternatives><graphic xlink:href="pcbi.1011240.e054.jpg" id="pcbi.1011240.e054g" position="anchor"/><mml:math id="M54" display="inline" overflow="scroll"><mml:mrow><mml:mi>W</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> with non-negative entries (e.g., using the UniFrac-Distance [<xref rid="pcbi.1011240.ref052" ref-type="bibr">52</xref>] as shown in Sec. C of <xref rid="pcbi.1011240.s002" ref-type="supplementary-material">S2 Appendix</xref>), where the <italic toggle="yes">ij</italic>-th entry corresponds to the strength of the relation between components <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic>. We can then incorporate <italic toggle="yes">W</italic> directly into our kernels. To see how this works, consider the special case where the kernel <italic toggle="yes">k</italic> can be written as <inline-formula id="pcbi.1011240.e055"><alternatives><graphic xlink:href="pcbi.1011240.e055.jpg" id="pcbi.1011240.e055g" position="anchor"/><mml:math id="M55" display="inline" overflow="scroll"><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></alternatives></inline-formula> for a positive definite kernel <inline-formula id="pcbi.1011240.e056"><alternatives><graphic xlink:href="pcbi.1011240.e056.jpg" id="pcbi.1011240.e056g" position="anchor"/><mml:math id="M56" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>→</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. Then, the weighted kernel
<disp-formula id="pcbi.1011240.e057"><alternatives><graphic xlink:href="pcbi.1011240.e057.jpg" id="pcbi.1011240.e057g" position="anchor"/><mml:math id="M57" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≔</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(4)</label></disp-formula>
is positive definite and incorporates the prior information in a natural way. If two components <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic> are known to be related (corresponding to large values of <italic toggle="yes">W</italic><sub><italic toggle="yes">i</italic>,<italic toggle="yes">j</italic></sub>), the kernel <italic toggle="yes">k</italic><sub><italic toggle="yes">W</italic></sub> takes the similarity across these components into account. In Sec. B of <xref rid="pcbi.1011240.s002" ref-type="supplementary-material">S2 Appendix</xref>, we show that the probability distribution kernels and the linear kernel can be expressed in this way and propose similar weighted versions for the remaining kernels.</p>
        <p>An advantage of our framework is that it defaults to the log-contrast model when more complex models fail to improve the prediction (due to the zero-shift in our proposed Aitchison kernel and the kernel-based regularization, this correspondence is however not exact). We now show that for the weighted Aitchison kernel, the RKHS consists of log-contrast functions with equal coefficients across the weighted blocks, this is similar to how [<xref rid="pcbi.1011240.ref044" ref-type="bibr">44</xref>] incorporate prior information into log-contrast models.</p>
        <p><bold>Proposition 2.2</bold> (weighted Aitchison kernel RKHS). Let <italic toggle="yes">P</italic><sub>1</sub>, …, <italic toggle="yes">P</italic><sub><italic toggle="yes">m</italic></sub> ⊆ {1, …, <italic toggle="yes">p</italic>} be a disjoint partition and <inline-formula id="pcbi.1011240.e058"><alternatives><graphic xlink:href="pcbi.1011240.e058.jpg" id="pcbi.1011240.e058g" position="anchor"/><mml:math id="M58" display="inline" overflow="scroll"><mml:mrow><mml:mi>W</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> the weight matrix defined for all <italic toggle="yes">i</italic>, <italic toggle="yes">j</italic> ∈ {1, …, <italic toggle="yes">p</italic>} by <inline-formula id="pcbi.1011240.e059"><alternatives><graphic xlink:href="pcbi.1011240.e059.jpg" id="pcbi.1011240.e059g" position="anchor"/><mml:math id="M59" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≔</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msub><mml:mn mathvariant="double-struck">1</mml:mn><mml:mrow><mml:mo>{</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Let <italic toggle="yes">k</italic><sub><italic toggle="yes">W</italic></sub> be the weighted Aitchison kernel given in <xref rid="pcbi.1011240.s007" ref-type="supplementary-material">S7 Appendix</xref> (but without zero imputation and on the open simplex). Then, it holds that
<disp-formula id="pcbi.1011240.e060"><alternatives><graphic xlink:href="pcbi.1011240.e060.jpg" id="pcbi.1011240.e060g" position="anchor"/><mml:math id="M60" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>W</mml:mi></mml:msub></mml:msub><mml:mspace width="1em"/><mml:mo>⇔</mml:mo><mml:mspace width="1em"/><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mspace width="2pt"/><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(7)</label></disp-formula>
for some <inline-formula id="pcbi.1011240.e061"><alternatives><graphic xlink:href="pcbi.1011240.e061.jpg" id="pcbi.1011240.e061g" position="anchor"/><mml:math id="M61" display="inline" overflow="scroll"><mml:mrow><mml:mi>β</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> satisfying (1) <inline-formula id="pcbi.1011240.e062"><alternatives><graphic xlink:href="pcbi.1011240.e062.jpg" id="pcbi.1011240.e062g" position="anchor"/><mml:math id="M62" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msub><mml:mi>β</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and (2) for all <italic toggle="yes">ℓ</italic> ∈ {1, …, <italic toggle="yes">m</italic>} and <italic toggle="yes">i</italic>, <italic toggle="yes">j</italic> ∈ <italic toggle="yes">P</italic><sub><italic toggle="yes">ℓ</italic></sub> it holds <italic toggle="yes">β</italic><sub><italic toggle="yes">i</italic></sub> = <italic toggle="yes">β</italic><sub><italic toggle="yes">j</italic></sub></p>
        <p>A proof is given in <xref rid="pcbi.1011240.s006" ref-type="supplementary-material">S6 Appendix</xref>. Combined with Proposition 2.1, this implies that the CFI values are equal across the equally weighted blocks <italic toggle="yes">P</italic><sub>1</sub>, …, <italic toggle="yes">P</italic><sub><italic toggle="yes">m</italic></sub>, which is demonstrated empirically in Sec. 3.2 and Sec. 3.4.</p>
      </sec>
    </sec>
    <sec id="sec007">
      <title>2.3 KernelBiome framework</title>
      <p>For a given i.i.d. dataset (<italic toggle="yes">X</italic><sub>1</sub>, <italic toggle="yes">Y</italic><sub>1</sub>), …, (<italic toggle="yes">X</italic><sub><italic toggle="yes">n</italic></sub>, <italic toggle="yes">Y</italic><sub><italic toggle="yes">n</italic></sub>), <monospace specific-use="no-wrap">KernelBiome</monospace> first runs a data-driven model selection, resulting in an estimated regression function <inline-formula id="pcbi.1011240.e063"><alternatives><graphic xlink:href="pcbi.1011240.e063.jpg" id="pcbi.1011240.e063g" position="anchor"/><mml:math id="M63" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and a specific kernel <inline-formula id="pcbi.1011240.e064"><alternatives><graphic xlink:href="pcbi.1011240.e064.jpg" id="pcbi.1011240.e064g" position="anchor"/><mml:math id="M64" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> (see <xref rid="pcbi.1011240.g001" ref-type="fig">Fig 1</xref>). Then, the feature influence properties (CFI, CPD) and embedding induced by <inline-formula id="pcbi.1011240.e065"><alternatives><graphic xlink:href="pcbi.1011240.e065.jpg" id="pcbi.1011240.e065g" position="anchor"/><mml:math id="M65" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> are analyzed in a way that respects compositionality.</p>
      <sec id="sec008">
        <title>2.3.1 Model selection</title>
        <p>We propose the following two step data-driven selection procedure.</p>
        <list list-type="order">
          <list-item>
            <p>Select the best kernel <inline-formula id="pcbi.1011240.e066"><alternatives><graphic xlink:href="pcbi.1011240.e066.jpg" id="pcbi.1011240.e066g" position="anchor"/><mml:math id="M66" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> with the following hierarchical CV:
<list list-type="bullet"><list-item><p>Fix a kernel <inline-formula id="pcbi.1011240.e067"><alternatives><graphic xlink:href="pcbi.1011240.e067.jpg" id="pcbi.1011240.e067g" position="anchor"/><mml:math id="M67" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, i.e., a type of kernel and its kernel parameters.</p></list-item><list-item><p>Split the sample into <italic toggle="yes">N</italic><sub>out</sub> random (or stratified) folds.</p></list-item><list-item><p>For each fold, use all other folds to perform a <italic toggle="yes">N</italic><sub>in</sub>-fold CV to select the best hyperparameter <inline-formula id="pcbi.1011240.e068"><alternatives><graphic xlink:href="pcbi.1011240.e068.jpg" id="pcbi.1011240.e068g" position="anchor"/><mml:math id="M68" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi mathvariant="normal">λ</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and compute a CV score based on <inline-formula id="pcbi.1011240.e069"><alternatives><graphic xlink:href="pcbi.1011240.e069.jpg" id="pcbi.1011240.e069g" position="anchor"/><mml:math id="M69" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1011240.e070"><alternatives><graphic xlink:href="pcbi.1011240.e070.jpg" id="pcbi.1011240.e070g" position="anchor"/><mml:math id="M70" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi mathvariant="normal">λ</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> on the left-out fold.</p></list-item><list-item><p>Select the kernel <inline-formula id="pcbi.1011240.e071"><alternatives><graphic xlink:href="pcbi.1011240.e071.jpg" id="pcbi.1011240.e071g" position="anchor"/><mml:math id="M71" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> with the best average CV score.</p></list-item></list></p>
          </list-item>
          <list-item>
            <p>Select the best hyperparameter <inline-formula id="pcbi.1011240.e072"><alternatives><graphic xlink:href="pcbi.1011240.e072.jpg" id="pcbi.1011240.e072g" position="anchor"/><mml:math id="M72" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi mathvariant="normal">λ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> for <inline-formula id="pcbi.1011240.e073"><alternatives><graphic xlink:href="pcbi.1011240.e073.jpg" id="pcbi.1011240.e073g" position="anchor"/><mml:math id="M73" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> using a <italic toggle="yes">N</italic><sub>in</sub>-fold CV on the full data. The final estimator <inline-formula id="pcbi.1011240.e074"><alternatives><graphic xlink:href="pcbi.1011240.e074.jpg" id="pcbi.1011240.e074g" position="anchor"/><mml:math id="M74" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is then given by the kernel predictor based on <inline-formula id="pcbi.1011240.e075"><alternatives><graphic xlink:href="pcbi.1011240.e075.jpg" id="pcbi.1011240.e075g" position="anchor"/><mml:math id="M75" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1011240.e076"><alternatives><graphic xlink:href="pcbi.1011240.e076.jpg" id="pcbi.1011240.e076g" position="anchor"/><mml:math id="M76" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi mathvariant="normal">λ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>.</p>
          </list-item>
        </list>
        <p>This CV scheme ensures that all parameters are selected in a data adaptive way. Up to a point, including more parameter settings into the CV makes the method more robust at the cost of additional run time. We provide sensible default choices for all parameters (see e.g., Table A in Sec. A of <xref rid="pcbi.1011240.s002" ref-type="supplementary-material">S2 Appendix</xref> for the default kernels), allowing practitioners to directly apply the method. In the <monospace specific-use="no-wrap">KernelBiome</monospace> implementation, the parameter grids for the kernel parameters and hyperparameters, as well as parameters of the CV including the type of CV, number of CV folds, and scoring can also be be adjusted manually, for example to reduce the run time.</p>
      </sec>
      <sec id="sec009">
        <title>2.3.2 Model analysis</title>
        <p>Firstly, as discussed in Sec. 2.1, we propose to analyze the fitted model <inline-formula id="pcbi.1011240.e077"><alternatives><graphic xlink:href="pcbi.1011240.e077.jpg" id="pcbi.1011240.e077g" position="anchor"/><mml:math id="M77" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> with the CPD and CFI. Other methods developed for functions on <inline-formula id="pcbi.1011240.e078"><alternatives><graphic xlink:href="pcbi.1011240.e078.jpg" id="pcbi.1011240.e078g" position="anchor"/><mml:math id="M78" display="inline" overflow="scroll"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:math></alternatives></inline-formula> do not account for compositionality and can be misleading. Secondly, the kernel embedding <inline-formula id="pcbi.1011240.e079"><alternatives><graphic xlink:href="pcbi.1011240.e079.jpg" id="pcbi.1011240.e079g" position="anchor"/><mml:math id="M79" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> can be used for the following two types of analyses.</p>
        <p><bold>Distance-based analysis</bold>. A key advantage of using kernels is that the fitted kernel <inline-formula id="pcbi.1011240.e080"><alternatives><graphic xlink:href="pcbi.1011240.e080.jpg" id="pcbi.1011240.e080g" position="anchor"/><mml:math id="M80" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is itself helpful in the analysis. As discussed in Sec. 2.2, <inline-formula id="pcbi.1011240.e081"><alternatives><graphic xlink:href="pcbi.1011240.e081.jpg" id="pcbi.1011240.e081g" position="anchor"/><mml:math id="M81" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> induces a distance on the simplex that is well-suited to separate observations with different response values. We therefore suggest to utilize this distance to investigate the data further. Essentially, any statistical method based on distances can be applied. We specifically suggest using kernel PCA to project the samples into a two-dimensional space. As we illustrate in Sec. 3.3, such a projection can be used to detect specific groups or outliers in the samples and can also help understand how the predictors are used by the prediction model <inline-formula id="pcbi.1011240.e082"><alternatives><graphic xlink:href="pcbi.1011240.e082.jpg" id="pcbi.1011240.e082g" position="anchor"/><mml:math id="M82" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. As we are working with compositional data we need to be careful when looking at how individual components contribute to each principle component. Fortunately, the perturbation <italic toggle="yes">ψ</italic> defined in Sec. 2.1 can again be used to construct informative component-wise measures. All details on kernel PCA and how to compute component-wise contributions for each principle component are provided in Sec. B of <xref rid="pcbi.1011240.s005" ref-type="supplementary-material">S5 Appendix</xref>.</p>
        <p><bold>Data-driven scalar summary statistics</bold>. Practitioners often work with scalar summaries of the data as these are easy to communicate. A commonly used summary statistic in ecology is <italic toggle="yes">α</italic>-diversity which measures the variation within a community. The connection between kernels and distances provides a useful tool to construct informative scalar summary statistics by considering distances to a reference point <italic toggle="yes">u</italic> in the simplex. Formally, for a fixed reference point <inline-formula id="pcbi.1011240.e083"><alternatives><graphic xlink:href="pcbi.1011240.e083.jpg" id="pcbi.1011240.e083g" position="anchor"/><mml:math id="M83" display="inline" overflow="scroll"><mml:mrow><mml:mi>u</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> define for all <inline-formula id="pcbi.1011240.e084"><alternatives><graphic xlink:href="pcbi.1011240.e084.jpg" id="pcbi.1011240.e084g" position="anchor"/><mml:math id="M84" display="inline" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> a corresponding closeness measure by <inline-formula id="pcbi.1011240.e085"><alternatives><graphic xlink:href="pcbi.1011240.e085.jpg" id="pcbi.1011240.e085g" position="anchor"/><mml:math id="M85" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≔</mml:mo><mml:mo>-</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <italic toggle="yes">d</italic><sub><italic toggle="yes">k</italic></sub> is the distance induced by the kernel <italic toggle="yes">k</italic>. This provides an easily interpretable scalar quantity. For example, if <italic toggle="yes">Y</italic> is a binary indicator taking values <italic toggle="yes">healthy</italic> and <italic toggle="yes">sick</italic>, we could select <italic toggle="yes">u</italic> to be the geometric median (the observation that has the smallest total distance to all the other observations based on the pairwise kernel distance) of all <italic toggle="yes">X</italic><sub><italic toggle="yes">i</italic></sub> with <italic toggle="yes">Y</italic><sup><italic toggle="yes">i</italic></sup> = <italic toggle="yes">healthy</italic>. Then, <italic toggle="yes">D</italic><sup><italic toggle="yes">k</italic></sup> corresponds to a very simple health score (see Sec. 3.3 for a concrete example). A further example is given by selecting <italic toggle="yes">u</italic> = (1/<italic toggle="yes">p</italic>, …, 1/<italic toggle="yes">p</italic>) and considering points on the simplex as communities. Then, <italic toggle="yes">u</italic> can be interpreted as the most diverse point in the simplex and <italic toggle="yes">D</italic><sup><italic toggle="yes">k</italic></sup> corresponds to a data-adaptive <italic toggle="yes">α</italic>-diversity measure. While such a definition of diversity does not necessarily satisfy all desirable properties for diversities [see e.g., <xref rid="pcbi.1011240.ref053" ref-type="bibr">53</xref>], it is (1) symmetric with respect to switching of coordinates, (2) has an intuitive interpretation and (3) is well-behaved when combined with weighted kernels. Connections to established diversities also exist, for example, the linear kernel corresponds to a shifted version of the Gini-Simpson diversity (i.e., <inline-formula id="pcbi.1011240.e086"><alternatives><graphic xlink:href="pcbi.1011240.e086.jpg" id="pcbi.1011240.e086g" position="anchor"/><mml:math id="M86" display="inline" overflow="scroll"><mml:mrow><mml:mtext>Gini-Simpson</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≔</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:mfrac></mml:mstyle></mml:mrow></mml:math></alternatives></inline-formula>).</p>
      </sec>
      <sec id="sec010">
        <title>2.3.3 Run time complexity</title>
        <p>The run time complexity of <monospace specific-use="no-wrap">KernelBiome</monospace> depends on the number of kernels <italic toggle="yes">K</italic>, the size of the hyperparameter grid <italic toggle="yes">H</italic>, and the number of inner CV folds <italic toggle="yes">N</italic><sub>in</sub> and outer CV folds <italic toggle="yes">N</italic><sub>out</sub>. Since the run time complexity of kernel ridge regression and support vector machines is <italic toggle="yes">O</italic>(<italic toggle="yes">n</italic><sup>3</sup>) (based on a straightforward implementation, actual implementation in available software libraries can achieve a more optimized run time), the total run time complexity of <monospace specific-use="no-wrap">KernelBiome</monospace> is <italic toggle="yes">O</italic>(<italic toggle="yes">KHN</italic><sub>in</sub><italic toggle="yes">N</italic><sub>out</sub><italic toggle="yes">n</italic><sup>3</sup>). For example, the default parameter settings use 55 kernels, with 5-fold inner CV and 10-fold outer CV with a hyperparameter grid of size 10, resulting in 27,500 model fits, each of complexity <italic toggle="yes">O</italic>(<italic toggle="yes">n</italic><sup>3</sup>). To reduce the run time we recommend reducing the number of kernels <italic toggle="yes">K</italic>, this can be particularly useful for prototyping. However, if possible, we recommend using the full list of kernels for a final analysis to avoid a decrease in predictive performance.</p>
      </sec>
      <sec id="sec011">
        <title>2.3.4 Implementation</title>
        <p><monospace specific-use="no-wrap">KernelBiome</monospace> is implemented as a Python [<xref rid="pcbi.1011240.ref054" ref-type="bibr">54</xref>] package that takes advantage of the high-performance <monospace specific-use="no-wrap">JAX</monospace> [<xref rid="pcbi.1011240.ref055" ref-type="bibr">55</xref>] and <monospace specific-use="no-wrap">scikit-learn</monospace> [<xref rid="pcbi.1011240.ref056" ref-type="bibr">56</xref>] libraries. All kernels introduced are implemented with <monospace specific-use="no-wrap">JAX</monospace>’s just-in-time compilation and automatically leverage accelerators such as GPU and TPU whenever available. <monospace specific-use="no-wrap">KernelBiome</monospace> provides fast computation of all kernels and distance metrics as well as easy-to-use procedures for model selection and comparison and procedures to estimate CPD and CFI, compute kernel PCA, and estimate scalar summary statistics. An illustration script for the package’s usage can be found in the package repository.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results" id="sec012">
    <title>3 Results</title>
    <p>We evaluated <monospace specific-use="no-wrap">KernelBiome</monospace> on a total of 33 microbiome datasets. All datasets have been previously published and final datasets used in our experiments can be fully reproduced following the description in the GitHub repo <ext-link xlink:href="https://github.com/shimenghuang/KernelBiome" ext-link-type="uri">https://github.com/shimenghuang/KernelBiome</ext-link>. A summary of the datasets including on the pre-processing steps, prediction task and references is provided in Table A in <xref rid="pcbi.1011240.s003" ref-type="supplementary-material">S3 Appendix</xref>. First, in Sec. 3.1, we show that <monospace specific-use="no-wrap">KernelBiome</monospace> performs on par or better than existing supervised learning procedures for compositional data, while reducing to a powerfully regularized version of the log-contrast model if the prediction task is simple. In Sec. 3.2, we show on a semi-artificial dataset that including prior information can either improve or harm the predictive performance depending on whether or not it is relevant for the prediction. In Sec. 3.3, we illustrate the advantages of a full analysis with <monospace specific-use="no-wrap">KernelBiome</monospace>. Finally, in Sec. 3.4, we demonstrate how <monospace specific-use="no-wrap">KernelBiome</monospace> can incorporate prior knowledge, while preserving a theoretically justified interpretation.</p>
    <sec id="sec013">
      <title>3.1 State-of-the-art prediction performance</title>
      <p>We compare the predictive performance of <monospace specific-use="no-wrap">KernelBiome</monospace> on all datasets with the following competitors: (i) <monospace specific-use="no-wrap">Baseline</monospace>, a naive predictor that uses the training majority class for classification and the training mean for regression as its prediction, (ii) <monospace specific-use="no-wrap">SVM-RBF</monospace>, a support vector machine with the RBF kernel, (iii) <monospace specific-use="no-wrap">Lin/Log-L1</monospace>, a linear/logistic regression with <italic toggle="yes">ℓ</italic><sup>1</sup>-penalty (iv) <monospace specific-use="no-wrap">LogCont-L1</monospace>, a log-contrast regression with <italic toggle="yes">ℓ</italic><sup>1</sup> penalty with a half of the minimum non-zero relative abundance added as pseudo-count to remove zeros, and (v) <monospace specific-use="no-wrap">RF</monospace>, a random forest with 500 trees. For <monospace specific-use="no-wrap">SVM-RBF</monospace>, <monospace specific-use="no-wrap">Lin/Log-L1</monospace> and <monospace specific-use="no-wrap">RF</monospace> we use the <monospace specific-use="no-wrap">scikit-learn</monospace> implementations [<xref rid="pcbi.1011240.ref056" ref-type="bibr">56</xref>] and choose the hyperparameters (bandwidth, max depth and all penalty parameters) based on a 5-fold CV. For <monospace specific-use="no-wrap">LogCont-L1</monospace>, we use the <monospace specific-use="no-wrap">c-lasso</monospace> package [<xref rid="pcbi.1011240.ref016" ref-type="bibr">16</xref>] and the default CV scheme to chose the penalty parameter. We apply two versions of <monospace specific-use="no-wrap">KernelBiome</monospace>: (1) The standard version that adaptively chooses the kernel using <italic toggle="yes">N</italic><sub>in</sub> = 5, <italic toggle="yes">N</italic><sub>out</sub> = 10 (denoted <monospace specific-use="no-wrap">KernelBiome</monospace>), and (2) a version with fixed Aitchison kernel with <italic toggle="yes">c</italic> equal to half of the minimum non-zero relative abundance (denoted <monospace specific-use="no-wrap">KB-Aitchison</monospace>). Both methods use a default hyperparameter grid of size 40, and we use kernel ridge regression as the estimator. We compared with using support vector regression instead of kernel ridge regression and the results are similar.</p>
      <p>For the comparison we perform 20 random (stratified) 10-fold train/test splits and record the predictive performance (balanced accuracy for classification and root-mean-squared error (RMSE) for regression) on each test set. <xref rid="pcbi.1011240.g003" ref-type="fig">Fig 3</xref> contains the summary results for the 33 datasets. <xref rid="pcbi.1011240.g003" ref-type="fig">Fig 3A</xref> gives an overview of the predictive performance. To make the comparison easier, the median test scores are normalized to between 0 and 1 based on the minimum and maximum scores of each dataset. More details of the predictive performance results including boxplots of scores for all tasks and precision-recall curves for all classification tasks are provided in Figs B and C in <xref rid="pcbi.1011240.s003" ref-type="supplementary-material">S3 Appendix</xref>. Moreover, we perform a Wilcoxon signed-rank test [<xref rid="pcbi.1011240.ref057" ref-type="bibr">57</xref>] on the test scores and the percentage of times a method is significantly outperformed by another is given in <xref rid="pcbi.1011240.g003" ref-type="fig">Fig 3B</xref>. Lastly, run times of each method on the 33 datasets are shown in <xref rid="pcbi.1011240.g003" ref-type="fig">Fig 3C</xref>.</p>
      <fig position="float" id="pcbi.1011240.g003">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011240.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <p>(A) Comparison of predictive performance on 33 public datasets (9 regression and 24 classification tasks, separated by the grey vertical line in the figure) based on 20 random 10-fold CV. On the two datasets with grey tick labels no method significantly outperforms the baseline based on the Wilcoxon signed-rank test, meaning that there is little signal in the data. The ones in green are the datasets where <monospace specific-use="no-wrap">KernelBiome</monospace> significantly outperforms the baseline, while it does not on the single dataset with the black label. The corresponding p-values are provided in brackets. (B) Percentage of time a method is significantly outperformed by another based on the Wilcoxon signed-rank test. (C) Average run time of each method on each dataset. A significance level of 0.05 is used.</p>
        </caption>
        <graphic xlink:href="pcbi.1011240.g003" position="float"/>
      </fig>
      <p>On all datasets <monospace specific-use="no-wrap">KernelBiome</monospace> achieves the best or close to best performance and (almost) always captures useful information (green labels in <xref rid="pcbi.1011240.g003" ref-type="fig">Fig 3A</xref>), indicating that the proposed procedure is well-adapted to microbiome data. The kernel which was selected most often by <monospace specific-use="no-wrap">KernelBiome</monospace> and the frequency with which it was selected are shown in Table B in <xref rid="pcbi.1011240.s003" ref-type="supplementary-material">S3 Appendix</xref>. There are several interesting observations: (1) Even though <monospace specific-use="no-wrap">KernelBiome</monospace> selects mostly the Aitchison kernel on rmp, it outperforms <monospace specific-use="no-wrap">KB-Aitchison</monospace>, we attribute this to the advantage of the data-driven zero-imputation. (2) On datasets were the top kernel is selected consistently (e.g., uk, hiv and tara) <monospace specific-use="no-wrap">KernelBiome</monospace> generally performs very well and in these cases strongly outperformed both log-contrast based methods <monospace specific-use="no-wrap">KB-Aitchison</monospace> and <monospace specific-use="no-wrap">LogCont-L1</monospace>. (3) The predictive performance is substantially different between <monospace specific-use="no-wrap">KB-Aitchison</monospace> and <monospace specific-use="no-wrap">LogCont-L1</monospace> which we see as an indication that the type of regularization (kernel-based vs <italic toggle="yes">ℓ</italic><sup>1</sup>-regularization, respectively) is crucial in microbiome datasets.</p>
    </sec>
    <sec id="sec014">
      <title>3.2 Predictive performance given prior information</title>
      <p>In many applications, in particular in biology, prior information about a system is available and should be incorporated into the data analysis. As we show in Sec. 2.2.2, <monospace specific-use="no-wrap">KernelBiome</monospace> allows for incorporating prior knowledge on the relation between individual components (e.g., taxa). We will illustrate in this section that given informative prior knowledge, the predictive performance of <monospace specific-use="no-wrap">KernelBiome</monospace> can be improved, while if the prior knowledge is uninformative or incorrect, the predictive performance can be harmed. We conduct a semi-synthetic experiment based on the uk dataset. The dataset has 327 species and <italic toggle="yes">n</italic> = 882 samples. We generate the response <italic toggle="yes">Y</italic> based on two processes: (DGP1) a linear log-contrast model where species under phylum Bacteroidetes all have coefficient <italic toggle="yes">β</italic><sub><italic toggle="yes">B</italic></sub>, species under phylum Proteobacteria all have coefficient <italic toggle="yes">β</italic><sub><italic toggle="yes">P</italic></sub>, and all coefficients corresponding to other species are set to 0; (DGP2) a linear log-contrast model where the first half of the species under Bacteroidetes are given coefficient −<italic toggle="yes">β</italic><sub><italic toggle="yes">B</italic></sub> while the second half are given coefficient <italic toggle="yes">β</italic><sub><italic toggle="yes">B</italic></sub>, similarly for Proteobacteria.</p>
      <p>We construct a weight matrix based on the phylum each species belongs to (similar as in Prop. 2.2). By construction these weights are informative if the data are generated from DGP1, but not if the data are generated from DGP2. For each DGP, we sample 100 data points for training and another 100 data points for testing, repeated for 200 times. We compare the predictive performance of all methods mentioned in Sec. 3.1 and weighted <monospace specific-use="no-wrap">KernelBiome</monospace> (KB-Weighted) in <xref rid="pcbi.1011240.g004" ref-type="fig">Fig 4</xref>. The results show that when the weights are indeed informative, KB-Weighted achieves the best performance and is significantly better than the unweighted version (p-value 2.34 × 10<sup>−18</sup> based on Wilcoxon signed-rank test). On the other hand, when the weights do not align with the underlying generating mechanism, the predictive performance of KB-Weighted can be significantly worse than the unweighted one (p-value 1.25 × 10<sup>−9</sup> based on Wilcoxon signed-rank test). A table containing the number of other methods a method is significantly outperformed by under the two DGPs is also provided in <xref rid="pcbi.1011240.g004" ref-type="fig">Fig 4</xref>. All methods significantly outperform the baseline in this example, and the corresponding p-values are all below 2 × 10<sup>−17</sup>.</p>
      <fig position="float" id="pcbi.1011240.g004">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011240.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <p>Left and middle: Predictive performance of weighted <monospace specific-use="no-wrap">KernelBiome</monospace> when the given weights are informative (DGP1) and adversarial (DGP2) based on 200 repetitions. Right: the number of other methods each method is significantly outperformed by based on Wilcoxon signed-rank test (siginificance level 0.05), under DGP1 and DGP2.</p>
        </caption>
        <graphic xlink:href="pcbi.1011240.g004" position="float"/>
      </fig>
    </sec>
    <sec id="sec015">
      <title>3.3 Model analysis with KernelBiome</title>
      <p>As shown in the previous section, <monospace specific-use="no-wrap">KernelBiome</monospace> results in fitted models with state-of-the-art prediction performance. This is useful because supervised learning procedures can be used in two types of applications: (1) To learn a prediction model that has a direct application, e.g., as a diagnostic tool, or (2) to learn a predictive model as an intermediate step of an exploratory analysis to find out what factors could be driving the response. As discussed above (2) requires us to take the compositional nature of the predictors into account to avoid misleading conclusions. We show how the <monospace specific-use="no-wrap">KernelBiome</monospace> framework can be used to achieve this based on two datasets: (i) <italic toggle="yes">cirrhosis</italic>, based on a study analyzing the differences in microbial compositions between <italic toggle="yes">n</italic> = 130 healthy and cirrhotic patients [<xref rid="pcbi.1011240.ref058" ref-type="bibr">58</xref>] and (ii) <italic toggle="yes">centralparksoil</italic>, based on a study analyzing the pH concentration using microbial compositions from <italic toggle="yes">n</italic> = 580 soil samples [<xref rid="pcbi.1011240.ref059" ref-type="bibr">59</xref>]. Our aim is not do draw novel biological conclusions, but rather to showcase how <monospace specific-use="no-wrap">KernelBiome</monospace> can be used in this type of analysis.</p>
      <p>To reduce the complexity, we screen the data using <monospace specific-use="no-wrap">KernelBiome</monospace> with the Aitchison kernel and only keep the 50 taxa with the highest absolute CFIs. (As the analysis described here is only an illustration and we are not trying to compare methods, overfitting in this screening step is not a concern. In practice, however, it may be relevant to validate the sensitivity of the results using for example subsampling). We then fit <monospace specific-use="no-wrap">KernelBiome</monospace> with default parameter grid. For cirrhosis this results in the Aitchison kernel and for centralparksoil in the Aitchison-RBF kernel. As outlined in Sec. 2.3.2, we can then apply a kernel PCA with a compositionally adjusted component influence. The result for centralparksoil is given in <xref rid="pcbi.1011240.g005" ref-type="fig">Fig 5A</xref> (for cirrhosis see Fig D in <xref rid="pcbi.1011240.s003" ref-type="supplementary-material">S3 Appendix</xref>). This provides some direct information on which perturbations affects each principle component (e.g., “[g]DA101[s]98” affects the first component the most positively and “Sphingobacterium[s]multivorum” affects the second component the most negatively). Moreover, it also directly provides a tool to detect groupings or outliers of the samples. For example, the samples in the top middle (i.e., center of the U-shape) in <xref rid="pcbi.1011240.g005" ref-type="fig">Fig 5A</xref> could be investigated further as they behave different to the rest.</p>
      <fig position="float" id="pcbi.1011240.g005">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011240.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <p>(A) shows a kernel PCA for the centralparksoil dataset with 2 principle components. On the right, the contribution of the species to each of the two components is given (see Sec. B of <xref rid="pcbi.1011240.s005" ref-type="supplementary-material">S5 Appendix</xref> for details). (B) and (C) are both based on the cirrhosis dataset. In (B) the CFI values are shown on the left and the right plot compares the proposed kernel health score with Simpson diversity. In (C) the scaled CFI values for are illustrated for different weightings. A darker color shade of the (shortened) name of the microbiota signifies a stronger (positive resp. negative) CFI.</p>
        </caption>
        <graphic xlink:href="pcbi.1011240.g005" position="float"/>
      </fig>
      <p>A further useful quantity is the CFI, which for cirrhosis is given in <xref rid="pcbi.1011240.g005" ref-type="fig">Fig 5B</xref> (left) (for centralparksoil see Fig E in <xref rid="pcbi.1011240.s003" ref-type="supplementary-material">S3 Appendix</xref>). They explicitly take the compositional structure into account and have an easy interpretation. For example, “Prevotella_timonensis” has a CFI of 0.07 which implies that on average solely increasing “Prevotella_timonensis” will lead to a larger predicted response. We therefore believe that CFIs are more trustworthy than relying on for example Gini-importance for random forests, which does not have a clear interpretation due to the compositional constraint.</p>
      <p>Lastly, one can also use the connection between kernels and distances to construct useful scalar summary statistics. In <xref rid="pcbi.1011240.g005" ref-type="fig">Fig 5B</xref> (right), we use the kernel-distance to the geometric median in the healthy subpopulation as a scalar indicator for the healthiness of the microbiome. In comparison with more standard scalar summary statistics such as the Simpson diversity, it is targeted to distinguish the two groups.</p>
    </sec>
    <sec id="sec016">
      <title>3.4 Model analysis given prior information</title>
      <p>Including prior information in <monospace specific-use="no-wrap">KernelBiome</monospace> can be used to improve the interpretation of the model analysis step. To illustrate how this works in practice, we again consider the screened cirrhosis dataset. We apply <monospace specific-use="no-wrap">KernelBiome</monospace> with an Aitchison-kernel and <italic toggle="yes">c</italic> equal to half the minimum non-zero relative abundance without weighting, with a phylum-weighting and with a UniFrac-weighting. The resulting scaled CFI values for each are visualized in <xref rid="pcbi.1011240.g005" ref-type="fig">Fig 5C</xref>. The phylum-weighting corresponds to giving all taxa within the same phylum the same weights and the UniFrac-weighting is a weighting that incorporates the phylogenetic structure based on the UniFrac-distance and is described in Sec. C of <xref rid="pcbi.1011240.s002" ref-type="supplementary-material">S2 Appendix</xref>. As can bee seen in <xref rid="pcbi.1011240.g005" ref-type="fig">Fig 5C</xref>, the phylum weighting assigns approximately the same CFI to each variable in the same phylum, this is expected given that the phylum weighting has exactly the structure given in Proposition 2.2. Moreover, the UniFrac-weighting leads to CFI values that lie in-between the unweighted and phylum-weighted versions. Similar effects are seen for different kernels as well. The same plots for the generalized-JS kernel are provided in Fig G in <xref rid="pcbi.1011240.s003" ref-type="supplementary-material">S3 Appendix</xref>.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec017">
    <title>4 Discussion and conclusions</title>
    <p>In this work, we propose the <monospace specific-use="no-wrap">KernelBiome</monospace> framework for supervised learning with compositional covariates consisting of two main ingredients: data-driven model selection and model interpretation. Our approach is based on a flexible family of kernels targeting the structure of microbiome data, and is able to work with different kernel-based algorithms such as SVM and kernel ridge regression. One can also incorporate prior knowledge, which is crucial in microbiome data analysis. We compare <monospace specific-use="no-wrap">KernelBiome</monospace> with other state-of-the-art approaches on 33 microbiome datasets and show that <monospace specific-use="no-wrap">KernelBiome</monospace> achieves improved or comparable results. Moreover, <monospace specific-use="no-wrap">KernelBiome</monospace> provides multiple ways to extract interpretable information from the fitted model. Two novel measures, CFI and CPD, can be used to analyze how each component affects the response. We prove the consistency of these two measures and illustrate them on simulated and real datasets. <monospace specific-use="no-wrap">KernelBiome</monospace> also leverages the connection between kernels and distances to conduct distance-based analysis in a lower-dimensional space.</p>
  </sec>
  <sec id="sec018" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pcbi.1011240.s001" position="float" content-type="local-data">
      <label>S1 Appendix</label>
      <caption>
        <title>Details on CFI and CPD.</title>
        <p>Formal definitions of perturbations and estimators related to CFI and CPD.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011240.s002" position="float" content-type="local-data">
      <label>S2 Appendix</label>
      <caption>
        <title>Details on kernels included in <monospace specific-use="no-wrap">KernelBiome</monospace>.</title>
        <p>Overview of different kernel types, details on how they connect to distances and description of weighted kernels.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011240.s003" position="float" content-type="local-data">
      <label>S3 Appendix</label>
      <caption>
        <title>Details and additional results for experiments in Sec. 3.</title>
        <p>Datasets pre-processing, parameter setup, construction of the weighting matrices with UniFrac-distance and further experiment results based on the cirrhosis and centralparksoil datasets.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s003.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011240.s004" position="float" content-type="local-data">
      <label>S4 Appendix</label>
      <caption>
        <title>Additional experiments with simulated data.</title>
        <p>Consistency of CFI and CPD and comparison of CFI and CPD with their non-simplex counterparts.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s004.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011240.s005" position="float" content-type="local-data">
      <label>S5 Appendix</label>
      <caption>
        <title>Background on kernels.</title>
        <p>Mathematical background on kernels and details on dimensionality and visualization with kernels.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s005.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011240.s006" position="float" content-type="local-data">
      <label>S6 Appendix</label>
      <caption>
        <title>Proofs.</title>
        <p>Proof of theorems and propositions.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s006.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011240.s007" position="float" content-type="local-data">
      <label>S7 Appendix</label>
      <caption>
        <title>List of kernels implemented in <monospace specific-use="no-wrap">KernelBiome</monospace>.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s007.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>The authors would like to thank Christian Müller for detailed feedback and suggestions on this work, Johannes Ostner for help creating the circle plots, Jeroen Raes and Doris Vandeputte for making their raw data available.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1011240.ref001">
      <label>1</label>
      <mixed-citation publication-type="book"><name><surname>Buccianti</surname><given-names>A</given-names></name>, <name><surname>Mateu-Figueras</surname><given-names>G</given-names></name>, <name><surname>Pawlowsky-Glahn</surname><given-names>V</given-names></name>. <part-title>Compositional data analysis in the geosciences: from theory to practice</part-title>. In: <source>GSL Special Publications</source>. <publisher-name>Geological Society of London</publisher-name>; <year>2006</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Pesenson</surname><given-names>MZ</given-names></name>, <name><surname>Suram</surname><given-names>SK</given-names></name>, <name><surname>Gregoire</surname><given-names>JM</given-names></name>. <article-title>Statistical analysis and interpolation of compositional data in materials science</article-title>. <source>ACS combinatorial science</source>. <year>2015</year>;<volume>17</volume>(<issue>2</issue>):<fpage>130</fpage>–<lpage>136</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1021/co5001458</pub-id><?supplied-pmid 25547365?><pub-id pub-id-type="pmid">25547365</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Jackson</surname><given-names>DA</given-names></name>. <article-title>Compositional data in community ecology: the paradigm or peril of proportions?</article-title><source>Ecology</source>. <year>1997</year>;<volume>78</volume>(<issue>3</issue>):<fpage>929</fpage>–<lpage>940</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1890/0012-9658(1997)078[0929:CDICET]2.0.CO;2</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>H</given-names></name>. <article-title>Microbiome, metagenomics, and high-dimensional compositional data analysis</article-title>. <source>Annual Review of Statistics and Its Application</source>. <year>2015</year>;<volume>2</volume>:<fpage>73</fpage>–<lpage>94</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1146/annurev-statistics-010814-020351</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Aitchison</surname><given-names>J</given-names></name>. <article-title>The statistical analysis of compositional data</article-title>. <source>Journal of the Royal Statistical Society: Series B (Methodological)</source>. <year>1982</year>;<volume>44</volume>(<issue>2</issue>):<fpage>139</fpage>–<lpage>160</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Egozcue</surname><given-names>JJ</given-names></name>, <name><surname>Pawlowsky-Glahn</surname><given-names>V</given-names></name>, <name><surname>Mateu-Figueras</surname><given-names>G</given-names></name>, <name><surname>Barcelo-Vidal</surname><given-names>C</given-names></name>. <article-title>Isometric logratio transformations for compositional data analysis</article-title>. <source>Mathematical Geology</source>. <year>2003</year>;<volume>35</volume>(<issue>3</issue>):<fpage>279</fpage>–<lpage>300</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1023/A:1023818214614</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Aitchison</surname><given-names>J</given-names></name>. <article-title>A general class of distributions on the simplex</article-title>. <source>Journal of the Royal Statistical Society: Series B (Methodological)</source>. <year>1985</year>;<volume>47</volume>(<issue>1</issue>):<fpage>136</fpage>–<lpage>146</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref008">
      <label>8</label>
      <mixed-citation publication-type="other">Tsagris MT, Preston S, Wood AT. A data-based power transformation for compositional data; arXiv:1106.1451 [Preprint]. 2011. Available from: <ext-link xlink:href="https://arxiv.org/abs/1106.1451" ext-link-type="uri">https://arxiv.org/abs/1106.1451</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Aitchison</surname><given-names>J</given-names></name>. <article-title>Principal component analysis of compositional data</article-title>. <source>Biometrika</source>. <year>1983</year>;<volume>70</volume>(<issue>1</issue>):<fpage>57</fpage>–<lpage>65</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/biomet/70.1.57</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Aitchison</surname><given-names>J</given-names></name>, <name><surname>Greenacre</surname><given-names>M</given-names></name>. <article-title>Biplots of compositional data</article-title>. <source>Journal of the Royal Statistical Society: Series C (Applied Statistics)</source>. <year>2002</year>;<volume>51</volume>(<issue>4</issue>):<fpage>375</fpage>–<lpage>392</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Friedman</surname><given-names>J</given-names></name>, <name><surname>Alm</surname><given-names>EJ</given-names></name>. <article-title>Inferring correlation networks from genomic survey data</article-title>. <source>Computational Biology</source>. <year>2012</year>;. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002687</pub-id><?supplied-pmid 23028285?><pub-id pub-id-type="pmid">23028285</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Aitchison</surname><given-names>J</given-names></name>, <name><surname>Bacon-Shone</surname><given-names>J</given-names></name>. <article-title>Log contrast models for experiments with mixtures</article-title>. <source>Biometrika</source>. <year>1984</year>;<volume>71</volume>(<issue>2</issue>):<fpage>323</fpage>–<lpage>330</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/biomet/71.2.323</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>W</given-names></name>, <name><surname>Shi</surname><given-names>P</given-names></name>, <name><surname>Feng</surname><given-names>R</given-names></name>, <name><surname>Li</surname><given-names>H</given-names></name>. <article-title>Variable selection in regression with compositional covariates</article-title>. <source>Biometrika</source>. <year>2014</year>;<volume>101</volume>(<issue>4</issue>):<fpage>785</fpage>–<lpage>797</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/biomet/asu031</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Shi</surname><given-names>P</given-names></name>, <name><surname>Zhang</surname><given-names>A</given-names></name>, <name><surname>Li</surname><given-names>H</given-names></name>. <article-title>Regression analysis for microbiome compositional data</article-title>. <source>The Annals of Applied Statistics</source>. <year>2016</year>;<volume>10</volume>(<issue>2</issue>):<fpage>1019</fpage>–<lpage>1040</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1214/16-AOAS928</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Combettes</surname><given-names>PL</given-names></name>, <name><surname>Müller</surname><given-names>CL</given-names></name>. <article-title>Regression models for compositional data: General log-contrast formulations, proximal optimization, and microbiome data applications</article-title>. <source>Statistics in Biosciences</source>. <year>2020</year>; p. <fpage>1</fpage>–<lpage>26</lpage>.<pub-id pub-id-type="pmid">32292527</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Simpson</surname><given-names>L</given-names></name>, <name><surname>Combettes</surname><given-names>P</given-names></name>, <name><surname>Müller</surname><given-names>C</given-names></name>. <article-title>c-lasso—a Python package for constrained sparse and robust regression and classification</article-title>. <source>Journal of Open Source Software</source>. <year>2021</year>;<volume>6</volume>:<fpage>2844</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.21105/joss.02844</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref017">
      <label>17</label>
      <mixed-citation publication-type="other">Ailer E, Müller CL, Kilbertus N. A causal view on compositional data; arXiv:2106.11234 [Preprint]. 2021. Available from: <ext-link xlink:href="https://arxiv.org/abs/2106.11234" ext-link-type="uri">https://arxiv.org/abs/2106.11234</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Tsilimigras</surname><given-names>MC</given-names></name>, <name><surname>Fodor</surname><given-names>AA</given-names></name>. <article-title>Compositional data analysis of the microbiome: fundamentals, tools, and challenges</article-title>. <source>Annals of Epidemiology</source>. <year>2016</year>;<volume>26</volume>(<issue>5</issue>):<fpage>330</fpage>–<lpage>335</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.annepidem.2016.03.002</pub-id><?supplied-pmid 27255738?><pub-id pub-id-type="pmid">27255738</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Gloor</surname><given-names>GB</given-names></name>, <name><surname>Macklaim</surname><given-names>JM</given-names></name>, <name><surname>Pawlowsky-Glahn</surname><given-names>V</given-names></name>, <name><surname>Egozcue</surname><given-names>JJ</given-names></name>. <article-title>Microbiome datasets are compositional: and this is not optional</article-title>. <source>Frontiers in Microbiology</source>. <year>2017</year>;<volume>8</volume>:<fpage>2224</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fmicb.2017.02224</pub-id><?supplied-pmid 29187837?><pub-id pub-id-type="pmid">29187837</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Kaul</surname><given-names>A</given-names></name>, <name><surname>Mandal</surname><given-names>S</given-names></name>, <name><surname>Davidov</surname><given-names>O</given-names></name>, <name><surname>Peddada</surname><given-names>SD</given-names></name>. <article-title>Analysis of microbiome data in the presence of excess zeros</article-title>. <source>Frontiers in Microbiology</source>. <year>2017</year>;<volume>8</volume>:<fpage>2114</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fmicb.2017.02114</pub-id><?supplied-pmid 29163406?><pub-id pub-id-type="pmid">29163406</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>H</given-names></name>, <name><surname>Peddada</surname><given-names>SD</given-names></name>. <article-title>Analysis of microbial compositions: a review of normalization and differential abundance analysis</article-title>. <source>NPJ biofilms and microbiomes</source>. <year>2020</year>;<volume>6</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>13</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41522-020-00160-w</pub-id><?supplied-pmid 33268781?><pub-id pub-id-type="pmid">31908831</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Martín-Fernández</surname><given-names>JA</given-names></name>, <name><surname>Barceló-Vidal</surname><given-names>C</given-names></name>, <name><surname>Pawlowsky-Glahn</surname><given-names>V</given-names></name>. <article-title>Dealing with zeros and missing values in compositional data sets using nonparametric imputation</article-title>. <source>Mathematical Geology</source>. <year>2003</year>;<volume>35</volume>(<issue>3</issue>):<fpage>253</fpage>–<lpage>278</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1023/A:1023866030544</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Fernandes</surname><given-names>AD</given-names></name>, <name><surname>Macklaim</surname><given-names>JM</given-names></name>, <name><surname>Linn</surname><given-names>TG</given-names></name>, <name><surname>Reid</surname><given-names>G</given-names></name>, <name><surname>Gloor</surname><given-names>GB</given-names></name>. <article-title>ANOVA-like differential expression (ALDEx) analysis for mixed population RNA-Seq</article-title>. <source>PloS one</source>. <year>2013</year>;<volume>8</volume>(<issue>7</issue>):<fpage>e67019</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0067019</pub-id><?supplied-pmid 23843979?><pub-id pub-id-type="pmid">23843979</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref024">
      <label>24</label>
      <mixed-citation publication-type="other">De La Cruz R, Kreft JU. Geometric mean extension for data sets with zeros; arXiv:1806.06403 [Preprint]. 2018. Available from: <ext-link xlink:href="https://arxiv.org/abs/1806.06403" ext-link-type="uri">https://arxiv.org/abs/1806.06403</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref025">
      <label>25</label>
      <mixed-citation publication-type="other">Park J, Yoon C, Park C, Ahn J. Kernel Methods for Radial Transformed Compositional Data with Many Zeros. In: International Conference on Machine Learning. PMLR; 2022. p. 17458–17472.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Pasolli</surname><given-names>E</given-names></name>, <name><surname>Truong</surname><given-names>DT</given-names></name>, <name><surname>Malik</surname><given-names>F</given-names></name>, <name><surname>Waldron</surname><given-names>L</given-names></name>, <name><surname>Segata</surname><given-names>N</given-names></name>. <article-title>Machine learning meta-analysis of large metagenomic datasets: tools and biological insights</article-title>. <source>PLoS computational biology</source>. <year>2016</year>;<volume>12</volume>(<issue>7</issue>):<fpage>e1004977</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004977</pub-id><?supplied-pmid 27400279?><pub-id pub-id-type="pmid">27400279</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Knight</surname><given-names>R</given-names></name>, <name><surname>Vrbanac</surname><given-names>A</given-names></name>, <name><surname>Taylor</surname><given-names>BC</given-names></name>, <name><surname>Aksenov</surname><given-names>A</given-names></name>, <name><surname>Callewaert</surname><given-names>C</given-names></name>, <name><surname>Debelius</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Best practices for analysing microbiomes</article-title>. <source>Nature Reviews Microbiology</source>. <year>2018</year>;<volume>16</volume>(<issue>7</issue>):<fpage>410</fpage>–<lpage>422</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41579-018-0029-9</pub-id><?supplied-pmid 29795328?><pub-id pub-id-type="pmid">29795328</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Zhou</surname><given-names>YH</given-names></name>, <name><surname>Gallins</surname><given-names>P</given-names></name>. <article-title>A review and tutorial of machine learning methods for microbiome host trait prediction</article-title>. <source>Frontiers in Genetics</source>. <year>2019</year>; p. <fpage>579</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fgene.2019.00579</pub-id><?supplied-pmid 31293616?><pub-id pub-id-type="pmid">31293616</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Cammarota</surname><given-names>G</given-names></name>, <name><surname>Ianiro</surname><given-names>G</given-names></name>, <name><surname>Ahern</surname><given-names>A</given-names></name>, <name><surname>Carbone</surname><given-names>C</given-names></name>, <name><surname>Temko</surname><given-names>A</given-names></name>, <name><surname>Claesson</surname><given-names>MJ</given-names></name>, <etal>et al</etal>. <article-title>Gut microbiome, big data and machine learning to promote precision medicine for cancer</article-title>. <source>Nature Reviews Gastroenterology &amp; Hepatology</source>. <year>2020</year>;<volume>17</volume>(<issue>10</issue>):<fpage>635</fpage>–<lpage>648</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41575-020-0327-3</pub-id><?supplied-pmid 32647386?><pub-id pub-id-type="pmid">32647386</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref030">
      <label>30</label>
      <mixed-citation publication-type="book"><name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Li</surname><given-names>H</given-names></name>. <part-title>Kernel methods for regression analysis of microbiome compositional data</part-title>. In: <source>Topics in Applied Statistics</source>. <publisher-name>Springer</publisher-name>; <year>2013</year>. p. <fpage>191</fpage>–<lpage>201</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Randolph</surname><given-names>TW</given-names></name>, <name><surname>Zhao</surname><given-names>S</given-names></name>, <name><surname>Copeland</surname><given-names>W</given-names></name>, <name><surname>Hullar</surname><given-names>M</given-names></name>, <name><surname>Shojaie</surname><given-names>A</given-names></name>. <article-title>Kernel-penalized regression for analysis of microbiome data</article-title>. <source>The Annals of Applied Statistics</source>. <year>2018</year>;<volume>12</volume>(<issue>1</issue>):<fpage>540</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1214/17-AOAS1102</pub-id><?supplied-pmid 30224943?><pub-id pub-id-type="pmid">30224943</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Ramon</surname><given-names>E</given-names></name>, <name><surname>Belanche-Muñoz</surname><given-names>L</given-names></name>, <name><surname>Molist</surname><given-names>F</given-names></name>, <name><surname>Quintanilla</surname><given-names>R</given-names></name>, <name><surname>Perez-Enciso</surname><given-names>M</given-names></name>, <name><surname>Ramayo-Caldas</surname><given-names>Y</given-names></name>. <article-title>kernInt: A Kernel Framework for Integrating Supervised and Unsupervised Analyses in Spatio-Temporal Metagenomic Datasets</article-title>. <source>Frontiers in Microbiology</source>. <year>2021</year>;<volume>12</volume>:<fpage>60</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fmicb.2021.609048</pub-id><?supplied-pmid 33584612?><pub-id pub-id-type="pmid">33584612</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Di Marzio</surname><given-names>M</given-names></name>, <name><surname>Panzera</surname><given-names>A</given-names></name>, <name><surname>Venieri</surname><given-names>C</given-names></name>. <article-title>Non-parametric regression for compositional data</article-title>. <source>Statistical Modelling</source>. <year>2015</year>;<volume>15</volume>(<issue>2</issue>):<fpage>113</fpage>–<lpage>133</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1177/1471082X14535522</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref034">
      <label>34</label>
      <mixed-citation publication-type="other">Tsagris M, Athineou G. Compositional: Compositional Data Analysis; 2021. Available from: <ext-link xlink:href="https://CRAN.R-project.org/package=Compositional" ext-link-type="uri">https://CRAN.R-project.org/package=Compositional</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Zhao</surname><given-names>N</given-names></name>, <name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Carroll</surname><given-names>IM</given-names></name>, <name><surname>Ringel-Kulka</surname><given-names>T</given-names></name>, <name><surname>Epstein</surname><given-names>MP</given-names></name>, <name><surname>Zhou</surname><given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Testing in microbiome-profiling studies with MiRKAT, the microbiome regression-based kernel association test</article-title>. <source>The American Journal of Human Genetics</source>. <year>2015</year>;<volume>96</volume>(<issue>5</issue>):<fpage>797</fpage>–<lpage>807</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ajhg.2015.04.003</pub-id><?supplied-pmid 25957468?><pub-id pub-id-type="pmid">25957468</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Wilson</surname><given-names>N</given-names></name>, <name><surname>Zhao</surname><given-names>N</given-names></name>, <name><surname>Zhan</surname><given-names>X</given-names></name>, <name><surname>Koh</surname><given-names>H</given-names></name>, <name><surname>Fu</surname><given-names>W</given-names></name>, <name><surname>Chen</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>MiRKAT: kernel machine regression-based global association tests for the microbiome</article-title>. <source>Bioinformatics</source>. <year>2021</year>;<volume>37</volume>(<issue>11</issue>):<fpage>1595</fpage>–<lpage>1597</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btaa951</pub-id><?supplied-pmid 33225342?><pub-id pub-id-type="pmid">33225342</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>C</given-names></name>, <name><surname>Callahan</surname><given-names>BJ</given-names></name>, <name><surname>Wu</surname><given-names>MC</given-names></name>, <name><surname>Holloway</surname><given-names>ST</given-names></name>, <name><surname>Brochu</surname><given-names>H</given-names></name>, <name><surname>Lu</surname><given-names>W</given-names></name>, <etal>et al</etal>. <article-title>Phylogeny-guided microbiome OTU-specific association test (POST)</article-title>. <source>Microbiome</source>. <year>2022</year>;<volume>10</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>15</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s40168-022-01266-3</pub-id><?supplied-pmid 35668471?><pub-id pub-id-type="pmid">34980280</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref038">
      <label>38</label>
      <mixed-citation publication-type="other">Li B, Ahn J. Reproducing Kernels and New Approaches in Compositional Data Analysis; arXiv:2205.01158 [Preprint]. 2022. Available from: <ext-link xlink:href="https://arxiv.org/abs/2205.01158" ext-link-type="uri">https://arxiv.org/abs/2205.01158</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref039">
      <label>39</label>
      <mixed-citation publication-type="book"><name><surname>Samek</surname><given-names>W</given-names></name>, <name><surname>Montavon</surname><given-names>G</given-names></name>, <name><surname>Vedaldi</surname><given-names>A</given-names></name>, <name><surname>Hansen</surname><given-names>LK</given-names></name>, <name><surname>Müller</surname><given-names>KR</given-names></name>. <source>Explainable AI: interpreting, explaining and visualizing deep learning</source>. vol. <volume>11700</volume>. <publisher-name>Springer Nature</publisher-name>; <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref040">
      <label>40</label>
      <mixed-citation publication-type="other">Molnar C. Interpretable machine learning. Lulu.com; 2020.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Topçuoğlu</surname><given-names>BD</given-names></name>, <name><surname>Lesniak</surname><given-names>NA</given-names></name>, <name><surname>Ruffin</surname><given-names>M</given-names><suffix>IV</suffix></name>, <name><surname>Wiens</surname><given-names>J</given-names></name>, <name><surname>Schloss</surname><given-names>PD</given-names></name>. <article-title>A framework for effective application of machine learning to microbiome-based classification problems</article-title>. <source>MBio</source>. <year>2020</year>;<volume>11</volume>(<issue>3</issue>):<fpage>e00434</fpage>–<lpage>20</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1128/mBio.00434-20</pub-id><?supplied-pmid 32518182?><pub-id pub-id-type="pmid">32518182</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref042">
      <label>42</label>
      <mixed-citation publication-type="journal"><name><surname>Gou</surname><given-names>W</given-names></name>, <name><surname>Ling</surname><given-names>CW</given-names></name>, <name><surname>He</surname><given-names>Y</given-names></name>, <name><surname>Jiang</surname><given-names>Z</given-names></name>, <name><surname>Fu</surname><given-names>Y</given-names></name>, <name><surname>Xu</surname><given-names>F</given-names></name>, <etal>et al</etal>. <article-title>Interpretable machine learning framework reveals robust gut microbiome features associated with type 2 diabetes</article-title>. <source>Diabetes Care</source>. <year>2021</year>;<volume>44</volume>(<issue>2</issue>):<fpage>358</fpage>–<lpage>366</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2337/dc20-1536</pub-id><?supplied-pmid 33288652?><pub-id pub-id-type="pmid">33288652</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Ruaud</surname><given-names>A</given-names></name>, <name><surname>Pfister</surname><given-names>N</given-names></name>, <name><surname>Ley</surname><given-names>RE</given-names></name>, <name><surname>Youngblut</surname><given-names>ND</given-names></name>. <article-title>Interpreting tree ensemble machine learning models with endoR</article-title>. <source>PLOS Computational Biology</source>. <year>2022</year>;<volume>18</volume>(<issue>12</issue>):<fpage>e1010714</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pcbi.1010714</pub-id><?supplied-pmid 36516158?><pub-id pub-id-type="pmid">36516158</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref044">
      <label>44</label>
      <mixed-citation publication-type="journal"><name><surname>Bien</surname><given-names>J</given-names></name>, <name><surname>Yan</surname><given-names>X</given-names></name>, <name><surname>Simpson</surname><given-names>L</given-names></name>, <name><surname>Müller</surname><given-names>CL</given-names></name>. <article-title>Tree-aggregated predictive modeling of microbiome data</article-title>. <source>Scientific Reports</source>. <year>2021</year>;<volume>11</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>13</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-021-93645-3</pub-id><?supplied-pmid 34267244?><pub-id pub-id-type="pmid">33414495</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref045">
      <label>45</label>
      <mixed-citation publication-type="journal"><name><surname>Friedman</surname><given-names>JH</given-names></name>. <article-title>Greedy function approximation: a gradient boosting machine</article-title>. <source>Annals of Statistics</source>. <year>2001</year>; p. <fpage>1189</fpage>–<lpage>1232</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref046">
      <label>46</label>
      <mixed-citation publication-type="journal"><name><surname>Morais</surname><given-names>J</given-names></name>, <name><surname>Thomas-Agnan</surname><given-names>C</given-names></name>. <article-title>Impact of covariates in compositional models and simplicial derivatives</article-title>. <source>Austrian Journal of Statistics</source>. <year>2021</year>;<volume>50</volume>(<issue>2</issue>):<fpage>1</fpage>–<lpage>15</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.17713/ajs.v50i2.1069</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref047">
      <label>47</label>
      <mixed-citation publication-type="book"><name><surname>Schölkopf</surname><given-names>B</given-names></name>, <name><surname>Smola</surname><given-names>AJ</given-names></name>, <name><surname>Bach</surname><given-names>F</given-names></name>. <source>Learning with kernels: support vector machines, regularization, optimization, and beyond</source>. <publisher-name>MIT press</publisher-name>; <year>2002</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref048">
      <label>48</label>
      <mixed-citation publication-type="journal"><name><surname>Sriperumbudur</surname><given-names>BK</given-names></name>, <name><surname>Fukumizu</surname><given-names>K</given-names></name>, <name><surname>Lanckriet</surname><given-names>G</given-names></name>. <article-title>Universality, Characteristic Kernels and RKHS Embedding of Measures</article-title>. <source>Journal of Machine Learning Research</source>. <year>2011</year>;<volume>12</volume>(<issue>7</issue>).</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref049">
      <label>49</label>
      <mixed-citation publication-type="other">Topsøe F. Jenson-Shannon divergence and norm-based measures of discrimination and variation; 2003. Available from: <ext-link xlink:href="https://web.math.ku.dk/~topsoe/sh.ps" ext-link-type="uri">https://web.math.ku.dk/~topsoe/sh.ps</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref050">
      <label>50</label>
      <mixed-citation publication-type="book"><name><surname>Hein</surname><given-names>M</given-names></name>, <name><surname>Bousquet</surname><given-names>O</given-names></name>. <part-title>Hilbertian metrics and positive definite kernels on probability measures</part-title>. In: <source>International Workshop on Artificial Intelligence and Statistics</source>. <publisher-name>PMLR</publisher-name>; <year>2005</year>. p. <fpage>136</fpage>–<lpage>143</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref051">
      <label>51</label>
      <mixed-citation publication-type="journal"><name><surname>Lafferty</surname><given-names>J</given-names></name>, <name><surname>Lebanon</surname><given-names>G</given-names></name>, <name><surname>Jaakkola</surname><given-names>T</given-names></name>. <article-title>Diffusion kernels on statistical manifolds</article-title>. <source>Journal of Machine Learning Research</source>. <year>2005</year>;<volume>6</volume>(<issue>1</issue>):<fpage>129</fpage>–<lpage>163</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref052">
      <label>52</label>
      <mixed-citation publication-type="journal"><name><surname>Lozupone</surname><given-names>C</given-names></name>, <name><surname>Knight</surname><given-names>R</given-names></name>. <article-title>UniFrac: a new phylogenetic method for comparing microbial communities</article-title>. <source>Applied and Environmental Microbiology</source>. <year>2005</year>;<volume>71</volume>(<issue>12</issue>):<fpage>8228</fpage>–<lpage>8235</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1128/AEM.71.12.8228-8235.2005</pub-id><?supplied-pmid 16332807?><pub-id pub-id-type="pmid">16332807</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref053">
      <label>53</label>
      <mixed-citation publication-type="journal"><name><surname>Leinster</surname><given-names>T</given-names></name>, <name><surname>Cobbold</surname><given-names>C</given-names></name>. <article-title>Measuring diversity: The importance of species similarity</article-title>. <source>Ecology</source>. <year>2012</year>;<volume>93</volume>:<fpage>477</fpage>–<lpage>89</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1890/10-2402.1</pub-id><?supplied-pmid 22624203?><pub-id pub-id-type="pmid">22624203</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref054">
      <label>54</label>
      <mixed-citation publication-type="journal"><name><surname>van Rossum</surname><given-names>G</given-names></name>, <name><surname>Drake</surname><given-names>FL</given-names></name>. <article-title>Python 3 Reference Manual</article-title>. <source>CreateSpace</source>; <year>2009</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref055">
      <label>55</label>
      <mixed-citation publication-type="journal"><name><surname>Bradbury</surname><given-names>J</given-names></name>, <name><surname>Frostig</surname><given-names>R</given-names></name>, <name><surname>Hawkins</surname><given-names>P</given-names></name>, <name><surname>Johnson</surname><given-names>MJ</given-names></name>, <name><surname>Leary</surname><given-names>C</given-names></name>, <name><surname>Maclaurin</surname><given-names>D</given-names></name>, <etal>et al</etal>. <source>JAX: composable transformations of Python+NumPy programs</source>; <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref056">
      <label>56</label>
      <mixed-citation publication-type="journal"><name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Gramfort</surname><given-names>A</given-names></name>, <name><surname>Michel</surname><given-names>V</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <name><surname>Grisel</surname><given-names>O</given-names></name>, <etal>et al</etal>. <article-title>Scikit-learn: Machine Learning in Python</article-title>. <source>Journal of Machine Learning Research</source>. <year>2011</year>;<volume>12</volume>:<fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref057">
      <label>57</label>
      <mixed-citation publication-type="book"><name><surname>Wilcoxon</surname><given-names>F</given-names></name>. <source>Individual comparisons by ranking methods</source>. <publisher-name>Springer</publisher-name>; <year>1992</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref058">
      <label>58</label>
      <mixed-citation publication-type="journal"><name><surname>Qin</surname><given-names>N</given-names></name>, <name><surname>Yang</surname><given-names>F</given-names></name>, <name><surname>Li</surname><given-names>A</given-names></name>, <name><surname>Prifti</surname><given-names>E</given-names></name>, <name><surname>Chen</surname><given-names>Y</given-names></name>, <name><surname>Shao</surname><given-names>L</given-names></name>, <etal>et al</etal>. <article-title>Alterations of the human gut microbiome in liver cirrhosis</article-title>. <source>Nature</source>. <year>2014</year>;<volume>513</volume>(<issue>7516</issue>):<fpage>59</fpage>–<lpage>64</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nature13568</pub-id><?supplied-pmid 25079328?><pub-id pub-id-type="pmid">25079328</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref059">
      <label>59</label>
      <mixed-citation publication-type="journal"><name><surname>Ramirez</surname><given-names>KS</given-names></name>, <name><surname>Leff</surname><given-names>JW</given-names></name>, <name><surname>Barberán</surname><given-names>A</given-names></name>, <name><surname>Bates</surname><given-names>ST</given-names></name>, <name><surname>Betley</surname><given-names>J</given-names></name>, <name><surname>Crowther</surname><given-names>TW</given-names></name>, <etal>et al</etal>. <article-title>Biogeographic patterns in below-ground diversity in New York City’s Central Park are similar to those observed globally</article-title>. <source>Proceedings of the Royal Society B: Biological Sciences</source>. <year>2014</year>;<volume>281</volume>(<issue>1795</issue>):<fpage>20141988</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1098/rspb.2014.1988</pub-id><?supplied-pmid 25274366?><pub-id pub-id-type="pmid">25274366</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article article-type="aggregated-review-documents" id="pcbi.1011240.r001" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240.r001</article-id>
    <title-group>
      <article-title>Decision Letter 0</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Patil</surname>
          <given-names>Kiran Raosaheb</given-names>
        </name>
        <role>Section Editor</role>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Coelho</surname>
          <given-names>Luis Pedro</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Patil, Coelho</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Patil, Coelho</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1011240" id="rel-obj001" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>0</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">29 Mar 2023</named-content>
    </p>
    <p>Dear Ms. Huang,</p>
    <p>Thank you very much for submitting your manuscript "Supervised learning and model analysis with compositional data" for consideration at PLOS Computational Biology.</p>
    <p>As with all papers reviewed by the journal, your manuscript was reviewed by members of the editorial board and by several independent reviewers. In light of the reviews (below this email), we would like to invite the resubmission of a significantly-revised version that takes into account the reviewers' comments.</p>
    <p>The reviewers both agree on the value of the study, an opinion we share, but request additional clarifications. We note that a common theme is both reviewers wish to see a clearer statement of how the proposed methods compared to others, which we agree is important. As an additional editorial request, we ask that the authors rework the figures to avoid the use of very small fonts (particularly Fig 1 [bottom right] and Fig 4).</p>
    <p>We cannot make any decision about publication until we have seen the revised manuscript and your response to the reviewers' comments. Your revised manuscript is also likely to be sent to reviewers for further evaluation.</p>
    <p>When you are ready to resubmit, please upload the following:</p>
    <p>[1] A letter containing a detailed list of your responses to the review comments and a description of the changes you have made in the manuscript. Please note while forming your response, if your article is accepted, you may have the opportunity to make the peer review history publicly available. The record will include editor decision letters (with reviews) and your responses to reviewer comments. If eligible, we will contact you to opt in or out.</p>
    <p>[2] Two versions of the revised manuscript: one with either highlights or tracked changes denoting where the text has been changed; the other a clean version (uploaded as the manuscript file).</p>
    <p>Important additional instructions are given below your reviewer comments.</p>
    <p>Please prepare and submit your revised manuscript within 60 days. If you anticipate any delay, please let us know the expected resubmission date by replying to this email. Please note that revised manuscripts received after the 60-day due date may require evaluation and peer review similar to newly submitted manuscripts.</p>
    <p>Thank you again for your submission. We hope that our editorial process has been constructive so far, and we welcome your feedback at any time. Please don't hesitate to contact us if you have any questions or comments.</p>
    <p>Sincerely,</p>
    <p>Luis Pedro Coelho</p>
    <p>Academic Editor</p>
    <p>PLOS Computational Biology</p>
    <p>Kiran Patil</p>
    <p>Section Editor</p>
    <p>PLOS Computational Biology</p>
    <p>***********************</p>
    <p>The reviewers both agree on the value of the study, an opinion we share, but request additional clarifications. We note that a common theme is both reviewers wish to see a clearer statement of how the proposed methods compared to others, which we agree is important. As an additional editorial request, we ask that the authors rework the figures to avoid the use of very small fonts (particularly Fig 1 [bottom right] and Fig 4).</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <bold>Comments to the Authors:</bold>
    </p>
    <p>
      <bold>Please note here if the review is uploaded as an attachment.</bold>
    </p>
    <p>Reviewer #1: The manuscript by Shimeng Huang et al. proposes KernelBiome, a kernel-based nonparametric regression and classification framework for compositional data. The method is specifically developed to deal with sparse compositional data and can incorporate prior knowledge in terms of phylogenetic structure. The algorithm is validated experimentally on 33 publicly available microbiome datasets and compared with state-of-the-art solutions. The code is available as an open-source python package.</p>
    <p>The topic involved in the paper is suitable for publication in PLOS Computational Biology.</p>
    <p>I find the methodological solution quite interesting. It is described in detail in both the main paper and the Supplementary Material. I have more comments about the experimental validation of the proposed solution:</p>
    <p>1. As a general comment, the manuscript has a quite extensive supplementary material in terms of Appendix, while the main text is more limited, especially in terms of main Figures. I feel that some of the more important results/figures may be moved from the supplementary to the main text.</p>
    <p>2. Following the previous point, the comparison among different classifiers is summarized in Figure 3 for only a fraction of the considered datasets (8 among 33 if I understand correctly). I think it would be important to have a figure here that summarizes the results for all considered datasets.</p>
    <p>3. Despite the extensive validation, I still don't get to which extent the proposed solution outperforms the existing ones. For example, in how many cases/datasets the proposed method outperforms the other ones? Can you suggest (or not) your solution based on some data characteristics?</p>
    <p>4. Could you add a statistical test to evaluate if differences in terms of accuracies are statistically significant?</p>
    <p>5. I find interesting that the method can deal with prior information. Which is the added value of this information in terms of classification accuracies? I think it would be relevant performing a comparison in this direction (i.e., comparing results by incorporating or not the prior information).</p>
    <p>6. It is not very clear to me which are the free parameters that should be set for the proposed solution. In case, a sensitivity analysis to them should be performed.</p>
    <p>7. What in terms of computational complexity of the proposed solution with respect to the compared ones? Please add some empirical evaluations.</p>
    <p>Reviewer #2: In this manuscript, Huang et al., propose a kernel-based nonparametric regression and classification framework to address the challenges of compositionality and sparsity in analyzing compositional data. The authors compared the proposed framework with existing methods on publicly available microbiome datasets. Overall, I found the paper to be well-written and well-organized. I have some comments for the authors.</p>
    <p>1. Accuracy and MSE are applied in the classification and regression tasks, respectively. In classification tasks with unbalanced data, I don't think accuracy and AUROC are appropriate metrics. Therefore, I am highly concerned with the performance presented in the manuscript. Moreover, MSE and RMSE are both commonly used metrics for evaluating the performance of regression models. MSE is in square units of the target variable, which can make it difficult to interpret the results.</p>
    <p>2. Line 357; Please consider add more details on the baseline.</p>
    <p>3. Line 373-375: The authors claimed that "On all datasets KernelBiome achieves the best or close to best performance, indicating that the proposed procedure is well-adapted to microbiome data." However, this is not true at all when you look at Figure 6. In some case, the performance of KernelBiome is almost the worst.</p>
    <p>**********</p>
    <p>
      <bold>Have the authors made all data and (if applicable) computational code underlying the findings in their manuscript fully available?</bold>
    </p>
    <p>The <ext-link xlink:href="https://journals.plos.org/ploscompbiol/s/materials-and-software-sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data and code underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data and code should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data or code —e.g. participant privacy or use of data from a third party—those must be specified.</p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p>PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/ploscompbiol/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.</p>
    <p>Reviewer #1: No</p>
    <p>Reviewer #2: No</p>
    <p>
      <underline>Figure Files:</underline>
    </p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <underline><ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com</ext-link></underline>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email us at <underline><email>figures@plos.org</email></underline>.</p>
    <p>
      <underline>Data Requirements:</underline>
    </p>
    <p>Please note that, as a condition of publication, PLOS' data policy requires that you make available all data used to draw the conclusions outlined in your manuscript. Data must be deposited in an appropriate repository, included within the body of the manuscript, or uploaded as supporting information. This includes all numerical values that were used to generate graphs, histograms etc.. For an example in PLOS Biology see here: <ext-link xlink:href="http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5" ext-link-type="uri">http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5</ext-link>.</p>
    <p>
      <underline>Reproducibility:</underline>
    </p>
    <p>To enhance the reproducibility of your results, we recommend that you deposit your laboratory protocols in protocols.io, where a protocol can be assigned its own identifier (DOI) such that it can be cited independently in the future. Additionally, PLOS ONE offers an option to publish peer-reviewed clinical study protocols. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link></p>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pcbi.1011240.r002">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240.r002</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 0</article-title>
    </title-group>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1011240" id="rel-obj002" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">27 Apr 2023</named-content>
    </p>
    <supplementary-material id="pcbi.1011240.s008" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">response_to_reviewers.pdf</named-content></p>
      </caption>
      <media xlink:href="pcbi.1011240.s008.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="aggregated-review-documents" id="pcbi.1011240.r003" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240.r003</article-id>
    <title-group>
      <article-title>Decision Letter 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Patil</surname>
          <given-names>Kiran Raosaheb</given-names>
        </name>
        <role>Section Editor</role>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Coelho</surname>
          <given-names>Luis Pedro</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Patil, Coelho</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Patil, Coelho</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1011240" id="rel-obj003" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">24 May 2023</named-content>
    </p>
    <p>Dear Dr. Huang,</p>
    <p>Thank you very much for submitting your manuscript "Supervised learning and model analysis with compositional data" for consideration at PLOS Computational Biology. As with all papers reviewed by the journal, your manuscript was reviewed by members of the editorial board and by several independent reviewers. The reviewers appreciated the attention to an important topic. Based on the reviews, we are likely to accept this manuscript for publication, providing that you modify the manuscript according to the review recommendations.</p>
    <p>All scientific questions have been address. We agree with reviewer #2 that adding the p-value to the figures is best practices.</p>
    <p>Please prepare and submit your revised manuscript within 30 days. If you anticipate any delay, please let us know the expected resubmission date by replying to this email.</p>
    <p>When you are ready to resubmit, please upload the following:</p>
    <p>[1] A letter containing a detailed list of your responses to all review comments, and a description of the changes you have made in the manuscript. Please note while forming your response, if your article is accepted, you may have the opportunity to make the peer review history publicly available. The record will include editor decision letters (with reviews) and your responses to reviewer comments. If eligible, we will contact you to opt in or out</p>
    <p>[2] Two versions of the revised manuscript: one with either highlights or tracked changes denoting where the text has been changed; the other a clean version (uploaded as the manuscript file).</p>
    <p>Important additional instructions are given below your reviewer comments.</p>
    <p>Thank you again for your submission to our journal. We hope that our editorial process has been constructive so far, and we welcome your feedback at any time. Please don't hesitate to contact us if you have any questions or comments.</p>
    <p>Sincerely,</p>
    <p>Luis Pedro Coelho</p>
    <p>Academic Editor</p>
    <p>PLOS Computational Biology</p>
    <p>Kiran Patil</p>
    <p>Section Editor</p>
    <p>PLOS Computational Biology</p>
    <p>***********************</p>
    <p>A link appears below if there are any accompanying review attachments. If you believe any reviews to be missing, please contact <email>ploscompbiol@plos.org</email> immediately:</p>
    <p>All scientific questions have been address. We agree with reviewer #2 that adding the p-value to the figures is best practices.</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <bold>Comments to the Authors:</bold>
    </p>
    <p>
      <bold>Please note here if the review is uploaded as an attachment.</bold>
    </p>
    <p>Reviewer #1: I feel the authors have answered positively to my previous comments and modified the manuscript according to them.</p>
    <p>Reviewer #2: All my comments have been adequately addressed. On another note, the statistical P value should present with all the figures when comparing different methods. By including P-values, readers can better assess the significance of the findings and make informed interpretations.</p>
    <p>**********</p>
    <p>
      <bold>Have the authors made all data and (if applicable) computational code underlying the findings in their manuscript fully available?</bold>
    </p>
    <p>The <ext-link xlink:href="https://journals.plos.org/ploscompbiol/s/materials-and-software-sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data and code underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data and code should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data or code —e.g. participant privacy or use of data from a third party—those must be specified.</p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p>PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/ploscompbiol/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.</p>
    <p>Reviewer #1: No</p>
    <p>Reviewer #2: No</p>
    <p>Figure Files:</p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link xlink:href="https://pacev2.apexcovantage.com" ext-link-type="uri">https://pacev2.apexcovantage.com</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email us at <email>figures@plos.org</email>.</p>
    <p>Data Requirements:</p>
    <p>Please note that, as a condition of publication, PLOS' data policy requires that you make available all data used to draw the conclusions outlined in your manuscript. Data must be deposited in an appropriate repository, included within the body of the manuscript, or uploaded as supporting information. This includes all numerical values that were used to generate graphs, histograms etc.. For an example in PLOS Biology see here: <ext-link xlink:href="http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5" ext-link-type="uri">http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5</ext-link>.</p>
    <p>Reproducibility:</p>
    <p>To enhance the reproducibility of your results, we recommend that you deposit your laboratory protocols in protocols.io, where a protocol can be assigned its own identifier (DOI) such that it can be cited independently in the future. Additionally, PLOS ONE offers an option to publish peer-reviewed clinical study protocols. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link></p>
    <p>References:</p>
    <p>Review your reference list to ensure that it is complete and correct. If you have cited papers that have been retracted, please include the rationale for doing so in the manuscript text, or remove these references and replace them with relevant current references. Any changes to the reference list should be mentioned in the rebuttal letter that accompanies your revised manuscript.</p>
    <p>
      <italic toggle="yes">If you need to cite a retracted article, indicate the article’s retracted status in the References list and also include a citation and full reference for the retraction notice.</italic>
    </p>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pcbi.1011240.r004">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240.r004</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 1</article-title>
    </title-group>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1011240" id="rel-obj004" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>2</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">27 May 2023</named-content>
    </p>
    <supplementary-material id="pcbi.1011240.s009" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">point_by_point_response.pdf</named-content></p>
      </caption>
      <media xlink:href="pcbi.1011240.s009.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pcbi.1011240.r005" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240.r005</article-id>
    <title-group>
      <article-title>Decision Letter 2</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Patil</surname>
          <given-names>Kiran Raosaheb</given-names>
        </name>
        <role>Section Editor</role>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Coelho</surname>
          <given-names>Luis Pedro</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Patil, Coelho</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Patil, Coelho</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1011240" id="rel-obj005" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>2</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">3 Jun 2023</named-content>
    </p>
    <p>Dear Dr. Huang,</p>
    <p>We are pleased to inform you that your manuscript 'Supervised learning and model analysis with compositional data' has been provisionally accepted for publication in PLOS Computational Biology.</p>
    <p>Before your manuscript can be formally accepted you will need to complete some formatting changes, which you will receive in a follow up email. A member of our team will be in touch with a set of requests.</p>
    <p>Please note that your manuscript will not be scheduled for publication until you have made the required changes, so a swift response is appreciated.</p>
    <p>IMPORTANT: The editorial review process is now complete. PLOS will only permit corrections to spelling, formatting or significant scientific errors from this point onwards. Requests for major changes, or any which affect the scientific understanding of your work, will cause delays to the publication date of your manuscript.</p>
    <p>Should you, your institution's press office or the journal office choose to press release your paper, you will automatically be opted out of early publication. We ask that you notify us now if you or your institution is planning to press release the article. All press must be co-ordinated with PLOS.</p>
    <p>Thank you again for supporting Open Access publishing; we are looking forward to publishing your work in PLOS Computational Biology. </p>
    <p>Best regards,</p>
    <p>Luis Pedro Coelho</p>
    <p>Academic Editor</p>
    <p>PLOS Computational Biology</p>
    <p>Kiran Patil</p>
    <p>Section Editor</p>
    <p>PLOS Computational Biology</p>
    <p>***********************************************************</p>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pcbi.1011240.r006" specific-use="acceptance-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240.r006</article-id>
    <title-group>
      <article-title>Acceptance letter</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Patil</surname>
          <given-names>Kiran Raosaheb</given-names>
        </name>
        <role>Section Editor</role>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Coelho</surname>
          <given-names>Luis Pedro</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Patil, Coelho</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Patil, Coelho</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1011240" id="rel-obj006" related-article-type="reviewed-article"/>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">27 Jun 2023</named-content>
    </p>
    <p>PCOMPBIOL-D-23-00094R2 </p>
    <p>Supervised learning and model analysis with compositional data</p>
    <p>Dear Dr Huang,</p>
    <p>I am pleased to inform you that your manuscript has been formally accepted for publication in PLOS Computational Biology. Your manuscript is now with our production department and you will be notified of the publication date in due course.</p>
    <p>The corresponding author will soon be receiving a typeset proof for review, to ensure errors have not been introduced during production. Please review the PDF proof of your manuscript carefully, as this is the last chance to correct any errors. Please note that major changes, or those which affect the scientific understanding of the work, will likely cause delays to the publication date of your manuscript. </p>
    <p>Soon after your final files are uploaded, unless you have opted out, the early version of your manuscript will be published online. The date of the early version will be your article's publication date. The final article will be published to the same URL, and all versions of the paper will be accessible to readers.</p>
    <p>Thank you again for supporting PLOS Computational Biology and open-access publishing. We are looking forward to publishing your work! </p>
    <p>With kind regards,</p>
    <p>Zsuzsanna Gémesi</p>
    <p>PLOS Computational Biology | Carlyle House, Carlyle Road, Cambridge CB4 3DN | United Kingdom <email>ploscompbiol@plos.org</email> | Phone +44 (0) 1223-442824 | <ext-link xlink:href="http://ploscompbiol.org" ext-link-type="uri">ploscompbiol.org</ext-link> | @PLOSCompBiol</p>
  </body>
</sub-article>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?subarticle pcbi.1011240.r001?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLOS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10343141</article-id>
    <article-id pub-id-type="pmid">37390111</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-23-00094</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
              <subj-group>
                <subject>Kernel Methods</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
            <subj-group>
              <subject>Kernel Methods</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Microbiology</subject>
          <subj-group>
            <subject>Medical Microbiology</subject>
            <subj-group>
              <subject>Microbiome</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Microbial Genomics</subject>
              <subj-group>
                <subject>Microbiome</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Microbiology</subject>
          <subj-group>
            <subject>Microbial Genomics</subject>
            <subj-group>
              <subject>Microbiome</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Operator Theory</subject>
            <subj-group>
              <subject>Kernel Functions</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Statistical Methods</subject>
            <subj-group>
              <subject>Forecasting</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical Methods</subject>
              <subj-group>
                <subject>Forecasting</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Gastroenterology and Hepatology</subject>
          <subj-group>
            <subject>Liver Diseases</subject>
            <subj-group>
              <subject>Cirrhosis</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Probability Theory</subject>
            <subj-group>
              <subject>Probability Distribution</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Topology</subject>
            <subj-group>
              <subject>Manifolds</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Supervised learning and model analysis with compositional data</article-title>
      <alt-title alt-title-type="running-head">
        <monospace specific-use="no-wrap">KernelBiome</monospace>
      </alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6919-821X</contrib-id>
        <name>
          <surname>Huang</surname>
          <given-names>Shimeng</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0008-6358-699X</contrib-id>
        <name>
          <surname>Ailer</surname>
          <given-names>Elisabeth</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8718-4305</contrib-id>
        <name>
          <surname>Kilbertus</surname>
          <given-names>Niki</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff003" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6203-9777</contrib-id>
        <name>
          <surname>Pfister</surname>
          <given-names>Niklas</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Department of Mathematical Sciences, University of Copenhagen, Copenhagen, Denmark</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Helmholtz Munich, Munich, Germany</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Technical University of Munich, Munich, Germany</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Coelho</surname>
          <given-names>Luis Pedro</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Fudan University, CHINA</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>shimeng@math.ku.dk</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>30</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <volume>19</volume>
    <issue>6</issue>
    <elocation-id>e1011240</elocation-id>
    <history>
      <date date-type="received">
        <day>19</day>
        <month>1</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>3</day>
        <month>6</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 Huang et al</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Huang et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1011240.pdf"/>
    <abstract>
      <p>Supervised learning, such as regression and classification, is an essential tool for analyzing modern high-throughput sequencing data, for example in microbiome research. However, due to the compositionality and sparsity, existing techniques are often inadequate. Either they rely on extensions of the linear log-contrast model (which adjust for compositionality but cannot account for complex signals or sparsity) or they are based on black-box machine learning methods (which may capture useful signals, but lack interpretability due to the compositionality). We propose <monospace specific-use="no-wrap">KernelBiome</monospace>, a kernel-based nonparametric regression and classification framework for compositional data. It is tailored to sparse compositional data and is able to incorporate prior knowledge, such as phylogenetic structure. <monospace specific-use="no-wrap">KernelBiome</monospace> captures complex signals, including in the zero-structure, while automatically adapting model complexity. We demonstrate on par or improved predictive performance compared with state-of-the-art machine learning methods on 33 publicly available microbiome datasets. Additionally, our framework provides two key advantages: (i) We propose two novel quantities to interpret contributions of individual components and prove that they consistently estimate average perturbation effects of the conditional mean, extending the interpretability of linear log-contrast coefficients to nonparametric models. (ii) We show that the connection between kernels and distances aids interpretability and provides a data-driven embedding that can augment further analysis. <monospace specific-use="no-wrap">KernelBiome</monospace> is available as an open-source Python package on PyPI and at <ext-link xlink:href="https://github.com/shimenghuang/KernelBiome" ext-link-type="uri">https://github.com/shimenghuang/KernelBiome</ext-link>.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>In recent years, advances in gene sequencing technology have allowed scientists to examine entire microbial communities within genetic samples. These communities interact with their surroundings in complex ways, potentially benefiting or harming the host they inhabit. However, analyzing the microbiome—the measured microbial community—is challenging due to the compositionality and sparsity of the data.</p>
      <p>In this study, we developed a statistical framework called <monospace specific-use="no-wrap">KernelBiome</monospace> to model the relationship between the microbiome and a target of interest, such as the host’s disease status. We utilized a type of machine learning model called kernel methods and adapted them to handle the compositional and sparse nature of the data, while also incorporating prior expert knowledge.</p>
      <p>Additionally, we introduced two new measures to help interpret the contributions of individual compositional components. Our approach also demonstrated that kernel methods increase interpretability in analyzing microbiome data. To make <monospace specific-use="no-wrap">KernelBiome</monospace> as accessible as possible, we have created an easy-to-use software package for researchers and practitioners to apply in their work.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100009708</institution-id>
            <institution>Novo Nordisk Fonden</institution>
          </institution-wrap>
        </funding-source>
        <award-id>0069071</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6919-821X</contrib-id>
          <name>
            <surname>Huang</surname>
            <given-names>Shimeng</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100009708</institution-id>
            <institution>Novo Nordisk Fonden</institution>
          </institution-wrap>
        </funding-source>
        <award-id>0069071</award-id>
        <principal-award-recipient>
          <name>
            <surname>Pfister</surname>
            <given-names>Niklas</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award003">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100009318</institution-id>
            <institution>Helmholtz Association</institution>
          </institution-wrap>
        </funding-source>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0008-6358-699X</contrib-id>
          <name>
            <surname>Ailer</surname>
            <given-names>Elisabeth</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>SH and NP are supported by a research grant (0069071) from Novo Nordisk Fonden. EA is supported by the Helmholtz Association under the joint research school "Munich School for Data Science - MUDS". The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="0"/>
      <page-count count="19"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>PLOS Publication Stage</meta-name>
        <meta-value>vor-update-to-uncorrected-proof</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>Publication Update</meta-name>
        <meta-value>2023-07-13</meta-value>
      </custom-meta>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All data analyzed in this paper has been previously published and is publicly available online. Details of data sources and preprocessing steps can be found in the appendix. All experiments are reproducible using the code in <ext-link xlink:href="https://github.com/shimenghuang/KernelBiome" ext-link-type="uri">https://github.com/shimenghuang/KernelBiome</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All data analyzed in this paper has been previously published and is publicly available online. Details of data sources and preprocessing steps can be found in the appendix. All experiments are reproducible using the code in <ext-link xlink:href="https://github.com/shimenghuang/KernelBiome" ext-link-type="uri">https://github.com/shimenghuang/KernelBiome</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>1 Introduction</title>
    <p>Compositional data, that is, measurements of parts of a whole, are common in many scientific disciplines. For example, mineral compositions in geology [<xref rid="pcbi.1011240.ref001" ref-type="bibr">1</xref>], element concentrations in chemistry [<xref rid="pcbi.1011240.ref002" ref-type="bibr">2</xref>], species compositions in ecology [<xref rid="pcbi.1011240.ref003" ref-type="bibr">3</xref>] and more recently high-throughput sequencing reads in microbiome science [<xref rid="pcbi.1011240.ref004" ref-type="bibr">4</xref>].</p>
    <p>Mathematically, any <italic toggle="yes">p</italic>-dimensional composition—by appropriate normalization—can be represented as a point on the simplex
<disp-formula id="pcbi.1011240.e001"><alternatives><graphic xlink:href="pcbi.1011240.e001.jpg" id="pcbi.1011240.e001g" position="anchor"/><mml:math id="M1" display="block" overflow="scroll"><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mrow><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>≔</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:msup><mml:mo>∣</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msup><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></alternatives></disp-formula></p>
    <p>This complicates the statistical analysis, because the sum-to-one constraint of the simplex induces non-trivial dependencies between the components that may lead to false conclusions, if not appropriately taken into account.</p>
    <p>The statistics community has developed a substantial collection of parametric analysis techniques to account for the simplex structure. The most basic is the family of Dirichlet distributions. However, as pointed out already by [<xref rid="pcbi.1011240.ref005" ref-type="bibr">5</xref>], Dirichlet distributions cannot capture non-trivial dependence structures between the composition components and are thus too restrictive. [<xref rid="pcbi.1011240.ref005" ref-type="bibr">5</xref>] therefore introduced the <italic toggle="yes">log-ratio</italic> approach. It generates a family of distributions by projecting multivariate normal distributions into <inline-formula id="pcbi.1011240.e002"><alternatives><graphic xlink:href="pcbi.1011240.e002.jpg" id="pcbi.1011240.e002g" position="anchor"/><mml:math id="M2" display="inline" overflow="scroll"><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> via an appropriate log-ratio transformation (e.g., the additive log-ratio, centered log-ratio [<xref rid="pcbi.1011240.ref005" ref-type="bibr">5</xref>], or isometric log-ratio [<xref rid="pcbi.1011240.ref006" ref-type="bibr">6</xref>]). The resulting family of distributions results in parametric models on the simplex that are rich enough to capture non-trivial dependencies between the components (i.e., beyond those induced by the sum-to-one constraint). The log-ratio approach has been extended and adapted to a range of statistical problems [e.g., <xref rid="pcbi.1011240.ref007" ref-type="bibr">7</xref>–<xref rid="pcbi.1011240.ref011" ref-type="bibr">11</xref>].</p>
    <p>For supervised learning tasks the log-ratio approach leads to the <italic toggle="yes">log-contrast model</italic> [<xref rid="pcbi.1011240.ref012" ref-type="bibr">12</xref>]. An attractive property of the log-contrast model is that its coefficients quantify the effect of a multiplicative perturbation (i.e., fractionally increasing one component while adjusting the others) on the response. While several extensions of the log-contrast model exist [e.g., <xref rid="pcbi.1011240.ref013" ref-type="bibr">13</xref>–<xref rid="pcbi.1011240.ref017" ref-type="bibr">17</xref>], its parametric approach to supervised learning has two major shortcomings that become particularly severe when applied to high-dimensional and zero-inflated high-throughput sequencing data [<xref rid="pcbi.1011240.ref018" ref-type="bibr">18</xref>, <xref rid="pcbi.1011240.ref019" ref-type="bibr">19</xref>]. Firstly, since the logarithm is not defined at zero, the log-contrast model cannot be directly applied. A common fix is to add so-called pseudo-counts, a small non-zero constant, to all (zero) entries [<xref rid="pcbi.1011240.ref020" ref-type="bibr">20</xref>, <xref rid="pcbi.1011240.ref021" ref-type="bibr">21</xref>]. More sophisticated replacements exist as well [e.g., <xref rid="pcbi.1011240.ref022" ref-type="bibr">22</xref>–<xref rid="pcbi.1011240.ref024" ref-type="bibr">24</xref>], however, they often rely on knowing the nature of the zeros (e.g., whether they are structural or random), which is typically not available in practice and difficult to estimate. In any case, the downstream analysis will strongly depend on the selected zero imputation scheme [<xref rid="pcbi.1011240.ref025" ref-type="bibr">25</xref>]. Secondly, the relationships between individual components (e.g., species) and the response are generally complex. For example, in human microbiome settings, a health outcome may depend on interactions or on the presence or absence of species. Both cannot be captured by the linear structure of the log-contrast model.</p>
    <p>We propose to solve the supervised learning task using a nonparametric kernel approach, which is able to handle complex signals and avoid arbitrary zero-imputation. To be of use in biological applications, there are two components to a supervised analysis: (i) estimating a predictive model that accurately captures signals in the data and (ii) extracting meaningful and interpretable information from the estimated model. For (i), it has been shown that modern machine learning methods are capable of creating highly predictive models by using microbiome data as covariates and phenotypes as responses [e.g., <xref rid="pcbi.1011240.ref026" ref-type="bibr">26</xref>–<xref rid="pcbi.1011240.ref029" ref-type="bibr">29</xref>]. In particular, several approaches have been proposed where kernels are used to incorporate prior information [<xref rid="pcbi.1011240.ref030" ref-type="bibr">30</xref>, <xref rid="pcbi.1011240.ref031" ref-type="bibr">31</xref>], as a way to utilize the compositional structure [<xref rid="pcbi.1011240.ref032" ref-type="bibr">32</xref>–<xref rid="pcbi.1011240.ref034" ref-type="bibr">34</xref>] and to construct association tests [<xref rid="pcbi.1011240.ref035" ref-type="bibr">35</xref>–<xref rid="pcbi.1011240.ref037" ref-type="bibr">37</xref>]. Our proposed framework extends these works by providing new post-analysis techniques (e.g., the compositional feature influence) that respect the compositional structure. Recently, [<xref rid="pcbi.1011240.ref025" ref-type="bibr">25</xref>, <xref rid="pcbi.1011240.ref038" ref-type="bibr">38</xref>] used the radial transformation to argue that kernels on the sphere provide a natural way of analyzing compositions with zeros and similar to our work suggest using the kernel embeddings in a subsequent analysis. Part (ii) is related to the fields of explainable artificial intelligence [<xref rid="pcbi.1011240.ref039" ref-type="bibr">39</xref>] and interpretable machine learning [<xref rid="pcbi.1011240.ref040" ref-type="bibr">40</xref>], which focus on extracting information from predictive models. These types of approaches have also received growing attention in the context of microbiome data [<xref rid="pcbi.1011240.ref041" ref-type="bibr">41</xref>–<xref rid="pcbi.1011240.ref043" ref-type="bibr">43</xref>]. However, to the best of our knowledge, none of these procedures have been adjusted to account for the compositional structure. As we show in Sec. 2.1, not accounting for the compositionality may invalidate the results.</p>
    <p><monospace specific-use="no-wrap">KernelBiome</monospace>, see <xref rid="pcbi.1011240.g001" ref-type="fig">Fig 1</xref>, addresses both (i) by providing a regression and classification procedure based on kernels targeted to the simplex and (ii) by providing a principled way of analyzing the estimated models. Our contributions are fourfold: (1) We develop a theoretical framework for using kernels on compositional data. While using kernels to analyze various aspects of compositional data is not a new idea, a comprehensive analysis and its connection to existing approaches has been missing. In this work, we provide a range of kernels that each capture different aspects of the simplex structure, many of which have not been previously applied to compositional data. For all kernels, we derive novel, positive-definite weighted versions that allow incorporating prior information between the components. Additionally, we show that the distance associated with each kernel can be used to define a kernel-based scalar summary statistic. (2) We propose a theoretically justified analysis of kernel-based models that accounts for compositionality. Firstly, we introduce two novel quantities for measuring the effects of individual features that explicitly take the compositionality into account and prove that these can be consistently estimated. Secondly, we build on known connections between kernels and distance measures to advocate for using the kernel embedding from the estimated model to create visualizations and perform follow-up distance-based analyses that respect the compositionality. (3) We draw connections between <monospace specific-use="no-wrap">KernelBiome</monospace> and log-contrast-based analysis techniques. More specifically, we connect the Aitchison kernel to the log-contrast model, prove that the proposed compositional feature influence in this case reduces to the log-contrast coefficients, and show that our proposed weighted Aitchison kernel is related to the recently proposed tree-aggregation method of log-contrast coefficients [<xref rid="pcbi.1011240.ref044" ref-type="bibr">44</xref>]. Importantly, these connections ensure that <monospace specific-use="no-wrap">KernelBiome</monospace> reduces to standard log-contrast analysis techniques whenever simple log-contrast models are capable of capturing most of the signal. This is also illustrated by our experimental results. (4) We propose a data-adaptive selection framework that allows to compare different kernels in a principled fashion.</p>
    <fig position="float" id="pcbi.1011240.g001">
      <object-id pub-id-type="doi">10.1371/journal.pcbi.1011240.g001</object-id>
      <label>Fig 1</label>
      <caption>
        <title>Overview of <monospace specific-use="no-wrap">KernelBiome</monospace>.</title>
        <p>We start from a paired dataset with a compositional predictor <italic toggle="yes">X</italic> and a response <italic toggle="yes">Y</italic> and optional prior knowledge on the relation between components in the compositions (e.g., via a phylogenetic tree). We then select a model among a large class of kernels which best fits the data. This results in an estimated model <inline-formula id="pcbi.1011240.e003"><alternatives><graphic xlink:href="pcbi.1011240.e003" id="pcbi.1011240.e003g" position="anchor"/><mml:math id="M3" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and embedding <inline-formula id="pcbi.1011240.e004"><alternatives><graphic xlink:href="pcbi.1011240.e004" id="pcbi.1011240.e004g" position="anchor"/><mml:math id="M4" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. Finally, these can be analyzed while accounting for the compositional structure.</p>
      </caption>
      <graphic xlink:href="pcbi.1011240.g001" position="float"/>
    </fig>
    <p>The paper is structured as follows. In Sec. 2, we introduce the supervised learning task, define two quantities for analyzing individual components (Sec. 2.1), give a short introduction to kernel methods and how to apply our methodology (Sec. 2.2), and present the full <monospace specific-use="no-wrap">KernelBiome</monospace> framework (Sec. 2.3). Finally, we illustrate the advantages of <monospace specific-use="no-wrap">KernelBiome</monospace> in the experiments in Sec. 3.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>2 Methods</title>
    <p>We consider the setting in which we observe <italic toggle="yes">n</italic> independent and identically distributed (i.i.d.) observations (<italic toggle="yes">X</italic><sub>1</sub>, <italic toggle="yes">Y</italic><sub>1</sub>), …, (<italic toggle="yes">X</italic><sub><italic toggle="yes">n</italic></sub>, <italic toggle="yes">Y</italic><sub><italic toggle="yes">n</italic></sub>) of a random variable (<italic toggle="yes">X</italic>, <italic toggle="yes">Y</italic>) with <inline-formula id="pcbi.1011240.e005"><alternatives><graphic xlink:href="pcbi.1011240.e005.jpg" id="pcbi.1011240.e005g" position="anchor"/><mml:math id="M5" display="inline" overflow="scroll"><mml:mrow><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> a compositional predictor and <inline-formula id="pcbi.1011240.e006"><alternatives><graphic xlink:href="pcbi.1011240.e006.jpg" id="pcbi.1011240.e006g" position="anchor"/><mml:math id="M6" display="inline" overflow="scroll"><mml:mrow><mml:mi>Y</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> a real-valued response variable (by which we include categorical responses). Supervised learning attempts to learn a relationship between the response <italic toggle="yes">Y</italic> and the dependent predictors <italic toggle="yes">X</italic>. In this work, we focus on conditional mean relationships. More specifically, we are interested in estimating the conditional mean of <italic toggle="yes">Y</italic>, that is, the function
<disp-formula id="pcbi.1011240.e007"><alternatives><graphic xlink:href="pcbi.1011240.e007.jpg" id="pcbi.1011240.e007g" position="anchor"/><mml:math id="M7" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>:</mml:mo><mml:mi>x</mml:mi><mml:mo>↦</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>Y</mml:mi><mml:mo>∣</mml:mo><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula>
We assume that <inline-formula id="pcbi.1011240.e008"><alternatives><graphic xlink:href="pcbi.1011240.e008.jpg" id="pcbi.1011240.e008g" position="anchor"/><mml:math id="M8" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:mi mathvariant="script">F</mml:mi><mml:mo>⊆</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi>f</mml:mi><mml:mo>∣</mml:mo><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>→</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1011240.e009"><alternatives><graphic xlink:href="pcbi.1011240.e009.jpg" id="pcbi.1011240.e009g" position="anchor"/><mml:math id="M9" display="inline" overflow="scroll"><mml:mi mathvariant="script">F</mml:mi></mml:math></alternatives></inline-formula> is a function class determined by the regression (or classification) procedure.</p>
    <p>While estimating and analyzing the conditional mean is well established for predictors in Euclidean space, there are two factors that complicate the analysis when the predictors are compositional. (i) While it is possible to directly apply most standard regression procedures designed for <inline-formula id="pcbi.1011240.e010"><alternatives><graphic xlink:href="pcbi.1011240.e010.jpg" id="pcbi.1011240.e010g" position="anchor"/><mml:math id="M10" display="inline" overflow="scroll"><mml:mrow><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> also for <inline-formula id="pcbi.1011240.e011"><alternatives><graphic xlink:href="pcbi.1011240.e011.jpg" id="pcbi.1011240.e011g" position="anchor"/><mml:math id="M11" display="inline" overflow="scroll"><mml:mrow><mml:mi>X</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, it turns out that many approaches are ill-suited to approximate functions on the simplex. (ii) Even if one accurately estimates the conditional mean function <italic toggle="yes">f</italic>*, the simplex constraint complicates any direct assessment of the influence and importance of individual components of the compositional predictor. In this work, we address both issues and propose a nonparametric framework for regression and classification analysis for compositional data.</p>
    <sec id="sec003">
      <title>2.1 Interpreting individual features</title>
      <p>Our goal when estimating the conditional mean <italic toggle="yes">f</italic>* given in <xref rid="pcbi.1011240.e007" ref-type="disp-formula">(1)</xref> is to gain insight into the relationship between the response <italic toggle="yes">Y</italic> and predictors <italic toggle="yes">X</italic>. For example, when fitting a log-contrast model (see Example 2.1), the estimated coefficients provide a useful tool to generate hypotheses about which features affect the response and thereby inform follow-up experiments. For more complex models, such as the nonparametric methods proposed in this work, direct interpretation of a fitted model <inline-formula id="pcbi.1011240.e012"><alternatives><graphic xlink:href="pcbi.1011240.e012.jpg" id="pcbi.1011240.e012g" position="anchor"/><mml:math id="M12" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is difficult. Two widely applicable measures due to [<xref rid="pcbi.1011240.ref045" ref-type="bibr">45</xref>] are the following: (i) Relative influence, which assigns each coordinate <italic toggle="yes">j</italic> a scalar influence value given by the expected partial derivative <inline-formula id="pcbi.1011240.e013"><alternatives><graphic xlink:href="pcbi.1011240.e013.jpg" id="pcbi.1011240.e013g" position="anchor"/><mml:math id="M13" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mo>[</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mi>d</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msup></mml:mrow></mml:mfrac></mml:mstyle><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and (ii) partial dependence plots, which are constructed by plotting, for each coordinate <italic toggle="yes">j</italic>, the function <inline-formula id="pcbi.1011240.e014"><alternatives><graphic xlink:href="pcbi.1011240.e014.jpg" id="pcbi.1011240.e014g" position="anchor"/><mml:math id="M14" display="inline" overflow="scroll"><mml:mrow><mml:mi>z</mml:mi><mml:mo>↦</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mo>[</mml:mo><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mi>p</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. However, directly applying these measures on the simplex is not possible as we illustrate in Fig B in <xref rid="pcbi.1011240.s004" ref-type="supplementary-material">S4 Appendix</xref>. The intuition is that both measures evaluate the function <inline-formula id="pcbi.1011240.e015"><alternatives><graphic xlink:href="pcbi.1011240.e015.jpg" id="pcbi.1011240.e015g" position="anchor"/><mml:math id="M15" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> outside the simplex. An adaptation of the relative influence (or elasticity in the econometrics literature) to compositions based on the Aitchison geometry has recently been proposed by [<xref rid="pcbi.1011240.ref046" ref-type="bibr">46</xref>]. We adapt the relative influence without relying on the log-ratio transform and hence allow for more general function classes.</p>
      <p>Our approach is based on two coordinate-wise perturbations on the simplex. For any <italic toggle="yes">j</italic> ∈ {1, …, <italic toggle="yes">p</italic>} and <inline-formula id="pcbi.1011240.e016"><alternatives><graphic xlink:href="pcbi.1011240.e016.jpg" id="pcbi.1011240.e016g" position="anchor"/><mml:math id="M16" display="inline" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, define (i) for <italic toggle="yes">c</italic> ∈ [0, ∞) the function <inline-formula id="pcbi.1011240.e017"><alternatives><graphic xlink:href="pcbi.1011240.e017.jpg" id="pcbi.1011240.e017g" position="anchor"/><mml:math id="M17" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> to be the composition resulting from multiplying the <italic toggle="yes">j</italic>-th component by <italic toggle="yes">c</italic> and then scaling the entire vector back into the simplex, and (ii) for <italic toggle="yes">c</italic> ∈ [0, 1] the function <inline-formula id="pcbi.1011240.e018"><alternatives><graphic xlink:href="pcbi.1011240.e018.jpg" id="pcbi.1011240.e018g" position="anchor"/><mml:math id="M18" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> to be the composition that consists of fixing the <italic toggle="yes">j</italic>-th coordinate to <italic toggle="yes">c</italic> and then rescaling all remaining coordinates such that the resulting vector lies in the simplex. Each perturbation can be seen as a different way of intervening on a single coordinate while preserving the simplex structure. More details are given in <xref rid="pcbi.1011240.s001" ref-type="supplementary-material">S1 Appendix</xref>. Based on the first perturbation, we define the <italic toggle="yes">compositional feature influence</italic> (CFI) of component <italic toggle="yes">j</italic> ∈ {1, …, <italic toggle="yes">p</italic>} for any differentiable function <inline-formula id="pcbi.1011240.e019"><alternatives><graphic xlink:href="pcbi.1011240.e019.jpg" id="pcbi.1011240.e019g" position="anchor"/><mml:math id="M19" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>→</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> by
<disp-formula id="pcbi.1011240.e020"><alternatives><graphic xlink:href="pcbi.1011240.e020.jpg" id="pcbi.1011240.e020g" position="anchor"/><mml:math id="M20" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mtext mathcolor="gray">(CFI)</mml:mtext></mml:mrow><mml:mspace width="2em"/><mml:msubsup><mml:mi>I</mml:mi><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>≔</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mo>[</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mi>d</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ψ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>]</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(2)</label></disp-formula>
Similarly, we adapt partial dependence plots using the second perturbation. Define the <italic toggle="yes">compositional feature dependence</italic> (CPD) of component <italic toggle="yes">j</italic> ∈ {1, …, <italic toggle="yes">p</italic>} for any function <inline-formula id="pcbi.1011240.e021"><alternatives><graphic xlink:href="pcbi.1011240.e021.jpg" id="pcbi.1011240.e021g" position="anchor"/><mml:math id="M21" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>→</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> by
<disp-formula id="pcbi.1011240.e022"><alternatives><graphic xlink:href="pcbi.1011240.e022.jpg" id="pcbi.1011240.e022g" position="anchor"/><mml:math id="M22" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mtext mathcolor="gray">(CPD)</mml:mtext></mml:mrow><mml:mspace width="2em"/><mml:msubsup><mml:mi>S</mml:mi><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>:</mml:mo><mml:mi>z</mml:mi><mml:mo>↦</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(3)</label></disp-formula>
In practice, we can compute Monte Carlo estimates of both quantities by replacing expectations with empirical means. We denote the corresponding estimators by <inline-formula id="pcbi.1011240.e023"><alternatives><graphic xlink:href="pcbi.1011240.e023.jpg" id="pcbi.1011240.e023g" position="anchor"/><mml:math id="M23" display="inline" overflow="scroll"><mml:msubsup><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1011240.e024"><alternatives><graphic xlink:href="pcbi.1011240.e024.jpg" id="pcbi.1011240.e024g" position="anchor"/><mml:math id="M24" display="inline" overflow="scroll"><mml:msubsup><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, respectively (see <xref rid="pcbi.1011240.s001" ref-type="supplementary-material">S1 Appendix</xref> for details).</p>
      <p>The following proposition connects the CFI and CPD to the coefficients in a log-contrast function.</p>
      <p><bold>Proposition 2.1</bold> (CFI and CPD in the log-contrast model). Let <italic toggle="yes">f</italic> : <italic toggle="yes">x</italic> ↦ <italic toggle="yes">β</italic><sup><italic toggle="yes">T</italic></sup> log(<italic toggle="yes">x</italic>) with <inline-formula id="pcbi.1011240.e025"><alternatives><graphic xlink:href="pcbi.1011240.e025.jpg" id="pcbi.1011240.e025g" position="anchor"/><mml:math id="M25" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msub><mml:mi>β</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, then the CFI and CPD are given by
<disp-formula id="pcbi.1011240.e026"><alternatives><graphic xlink:href="pcbi.1011240.e026.jpg" id="pcbi.1011240.e026g" position="anchor"/><mml:math id="M26" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mspace width="1em"/><mml:mtext>and</mml:mtext><mml:mspace width="1em"/><mml:msubsup><mml:mi>S</mml:mi><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msubsup><mml:mo>:</mml:mo><mml:mi>z</mml:mi><mml:mo>↦</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mspace width="2pt"/><mml:mtext>log</mml:mtext><mml:mspace width="2pt"/><mml:mo>(</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:msup><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msup><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mi>j</mml:mi></mml:msup></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
respectively, where <inline-formula id="pcbi.1011240.e027"><alternatives><graphic xlink:href="pcbi.1011240.e027.jpg" id="pcbi.1011240.e027g" position="anchor"/><mml:math id="M27" display="inline" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> is a constant depending on the distribution of <italic toggle="yes">X</italic> but not on <italic toggle="yes">z</italic> and satisfies <italic toggle="yes">c</italic> = 0 if <italic toggle="yes">β</italic><sub><italic toggle="yes">j</italic></sub> = 0.</p>
      <p>A proof is given in <xref rid="pcbi.1011240.s006" ref-type="supplementary-material">S6 Appendix</xref>. The proposition shows that the CFI and CPD are generalizations of the <italic toggle="yes">β</italic>-coefficients in the log-contrast model. The following example provides further intuition.</p>
      <p><bold>Example 2.1</bold> (CFI and CPD in a log-contrast model). Consider a log-contrast model <italic toggle="yes">Y</italic> = <italic toggle="yes">f</italic>(<italic toggle="yes">X</italic>) + <italic toggle="yes">ϵ</italic> with <italic toggle="yes">f</italic> : <italic toggle="yes">x</italic> ↦ 2 log(<italic toggle="yes">x</italic><sup>1</sup>) − log(<italic toggle="yes">x</italic><sup>2</sup>) − log(<italic toggle="yes">x</italic><sup>3</sup>).</p>
      <p>The CFI and CPD for the true function <italic toggle="yes">f</italic>—estimated based on <italic toggle="yes">n</italic> = 100 i.i.d. samples (<italic toggle="yes">X</italic><sub>1</sub>, <italic toggle="yes">Y</italic><sub>1</sub>), …, (<italic toggle="yes">X</italic><sub><italic toggle="yes">n</italic></sub>, <italic toggle="yes">Y</italic><sub><italic toggle="yes">n</italic></sub>) with <italic toggle="yes">X</italic><sub><italic toggle="yes">i</italic></sub> compositional log-normal—are shown in <xref rid="pcbi.1011240.g002" ref-type="fig">Fig 2</xref>.</p>
      <fig position="float" id="pcbi.1011240.g002">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011240.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Visualization of the CPD (left) and CFI (right) based on <italic toggle="yes">n</italic> = 100 samples and the true function <italic toggle="yes">f</italic>.</title>
          <p>Since <italic toggle="yes">β</italic><sub>4</sub> = 0 in this example the 4-th component has no effect on the value of <italic toggle="yes">f</italic> resulting in a CFI of zero and a flat CPD. Since we are not estimating <italic toggle="yes">f</italic>, the CFI values exactly correspond to the <italic toggle="yes">β</italic>-coefficients in this example.</p>
        </caption>
        <graphic xlink:href="pcbi.1011240.g002" position="float"/>
      </fig>
      <p>The following theorem highlights the usefulness of the CFI and CPD by establishing when they can be consistently estimated from data.</p>
      <p><bold>Theorem 2.1</bold> (Consistency). Assume <inline-formula id="pcbi.1011240.e028"><alternatives><graphic xlink:href="pcbi.1011240.e028.jpg" id="pcbi.1011240.e028g" position="anchor"/><mml:math id="M28" display="inline" overflow="scroll"><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula> is an estimator of the conditional mean <italic toggle="yes">f</italic>* given in <xref rid="pcbi.1011240.e007" ref-type="disp-formula">(1)</xref> based on (<italic toggle="yes">X</italic><sub>1</sub>, <italic toggle="yes">Y</italic><sub>1</sub>), …, (<italic toggle="yes">X</italic><sub><italic toggle="yes">n</italic></sub>, <italic toggle="yes">Y</italic><sub><italic toggle="yes">n</italic></sub>) i.i.d.</p>
      <list list-type="simple">
        <list-item>
          <p>(i) If <inline-formula id="pcbi.1011240.e029"><alternatives><graphic xlink:href="pcbi.1011240.e029.jpg" id="pcbi.1011240.e029g" position="anchor"/><mml:math id="M29" display="inline" overflow="scroll"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mo>‖</mml:mo><mml:mi mathvariant="normal">∇</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">∇</mml:mi><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mo>‖</mml:mo><mml:mn>2</mml:mn></mml:msub><mml:mover><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mover><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> as <italic toggle="yes">n</italic> → ∞ and <inline-formula id="pcbi.1011240.e030"><alternatives><graphic xlink:href="pcbi.1011240.e030.jpg" id="pcbi.1011240.e030g" position="anchor"/><mml:math id="M30" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mo>[</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="normal">∇</mml:mi><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>]</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>∞</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, then it holds for all <italic toggle="yes">j</italic> ∈ {1, …, <italic toggle="yes">p</italic>} that
<disp-formula id="pcbi.1011240.e031"><alternatives><graphic xlink:href="pcbi.1011240.e031.jpg" id="pcbi.1011240.e031g" position="anchor"/><mml:math id="M31" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mover><mml:mo>⟶</mml:mo><mml:mi>P</mml:mi></mml:mover><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mspace width="1em"/><mml:mtext>as</mml:mtext><mml:mspace width="4pt"/><mml:mi>n</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></p>
        </list-item>
        <list-item>
          <p>(ii) If <inline-formula id="pcbi.1011240.e032"><alternatives><graphic xlink:href="pcbi.1011240.e032.jpg" id="pcbi.1011240.e032g" position="anchor"/><mml:math id="M32" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mtext>sup</mml:mtext><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mtext>supp</mml:mtext><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mover><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mover><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> as <italic toggle="yes">n</italic> → ∞ and supp(<italic toggle="yes">X</italic>) = {<italic toggle="yes">w</italic>/(∑<sub><italic toggle="yes">j</italic></sub>
<italic toggle="yes">w</italic><sup><italic toggle="yes">j</italic></sup>)∣<italic toggle="yes">w</italic> ∈ supp(<italic toggle="yes">X</italic><sup>1</sup>) × ⋯ × supp(<italic toggle="yes">X</italic><sup><italic toggle="yes">p</italic></sup>)}, then it holds for all <italic toggle="yes">j</italic> ∈ {1, …, <italic toggle="yes">p</italic>} and all <italic toggle="yes">z</italic> ∈ [0, 1] with <italic toggle="yes">z</italic>/(1 − <italic toggle="yes">z</italic>) ∈ supp(<italic toggle="yes">X</italic><sup><italic toggle="yes">j</italic></sup>/∑<sub><italic toggle="yes">ℓ</italic>≠<italic toggle="yes">j</italic></sub>
<italic toggle="yes">X</italic><sup><italic toggle="yes">ℓ</italic></sup>) that
<disp-formula id="pcbi.1011240.e033"><alternatives><graphic xlink:href="pcbi.1011240.e033.jpg" id="pcbi.1011240.e033g" position="anchor"/><mml:math id="M33" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mover><mml:mo>⟶</mml:mo><mml:mi>P</mml:mi></mml:mover><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow><mml:mi>j</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="1em"/><mml:mtext>as</mml:mtext><mml:mspace width="4pt"/><mml:mi>n</mml:mi><mml:mo>→</mml:mo><mml:mi>∞</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></p>
        </list-item>
      </list>
      <p>A proof is given in <xref rid="pcbi.1011240.s006" ref-type="supplementary-material">S6 Appendix</xref> and the result is demonstrated on simulated data in Fig A in <xref rid="pcbi.1011240.s004" ref-type="supplementary-material">S4 Appendix</xref>. The theorem shows that the CFI is consistently estimated as long as the derivative of <italic toggle="yes">f</italic>* is consistently estimated, which can be ensured for example for the kernel methods discussed in Sec. 2.2. In contrast, the CPD only requires the function <italic toggle="yes">f</italic>* itself to be consistently estimated. The additional assumption on the support ensures that the perturbation <italic toggle="yes">ϕ</italic><sub><italic toggle="yes">j</italic></sub> used in the CPD remains within the support. If this assumption is not satisfied one needs to ensure that the estimated function extrapolates beyond the sample support. Interpreting the CPD therefore requires caution.</p>
    </sec>
    <sec id="sec004">
      <title>2.2 Kernel methods for compositional data analysis</title>
      <p>Before presenting our proposed weighted and unweighted kernels, we briefly review the necessary background on kernels and their connection to distances. Kernel methods are a powerful class of nonparametric statistical methods that are particularly useful for data from non-standard (i.e., non-Euclidean) domains <inline-formula id="pcbi.1011240.e034"><alternatives><graphic xlink:href="pcbi.1011240.e034.jpg" id="pcbi.1011240.e034g" position="anchor"/><mml:math id="M34" display="inline" overflow="scroll"><mml:mi mathvariant="script">X</mml:mi></mml:math></alternatives></inline-formula>. The starting point is a symmetric, positive definite function <inline-formula id="pcbi.1011240.e035"><alternatives><graphic xlink:href="pcbi.1011240.e035.jpg" id="pcbi.1011240.e035g" position="anchor"/><mml:math id="M35" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi><mml:mo>:</mml:mo><mml:mi mathvariant="script">X</mml:mi><mml:mo>×</mml:mo><mml:mi mathvariant="script">X</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, called kernel. Kernels encode similarities between points in <inline-formula id="pcbi.1011240.e036"><alternatives><graphic xlink:href="pcbi.1011240.e036.jpg" id="pcbi.1011240.e036g" position="anchor"/><mml:math id="M36" display="inline" overflow="scroll"><mml:mi mathvariant="script">X</mml:mi></mml:math></alternatives></inline-formula>, i.e., large values of <italic toggle="yes">k</italic> correspond to points that are similar and small values to points that are less similar. Instead of directly analyzing the data on <inline-formula id="pcbi.1011240.e037"><alternatives><graphic xlink:href="pcbi.1011240.e037.jpg" id="pcbi.1011240.e037g" position="anchor"/><mml:math id="M37" display="inline" overflow="scroll"><mml:mi mathvariant="script">X</mml:mi></mml:math></alternatives></inline-formula>, kernel methods map it into a well-behaved feature space <inline-formula id="pcbi.1011240.e038"><alternatives><graphic xlink:href="pcbi.1011240.e038.jpg" id="pcbi.1011240.e038g" position="anchor"/><mml:math id="M38" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⊆</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mi>f</mml:mi><mml:mo>∣</mml:mo><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:mi mathvariant="script">X</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> called reproducing kernel Hilbert space (RKHS), whose inner product preserves the kernel induced similarity.</p>
      <p>Here, we consider kernels on the simplex, that is, <inline-formula id="pcbi.1011240.e039"><alternatives><graphic xlink:href="pcbi.1011240.e039.jpg" id="pcbi.1011240.e039g" position="anchor"/><mml:math id="M39" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">X</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. The conditional mean function <italic toggle="yes">f</italic>* given in <xref rid="pcbi.1011240.e007" ref-type="disp-formula">(1)</xref> can then be estimated by optimizing a loss over <inline-formula id="pcbi.1011240.e040"><alternatives><graphic xlink:href="pcbi.1011240.e040.jpg" id="pcbi.1011240.e040g" position="anchor"/><mml:math id="M40" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, for an appropriate kernel <italic toggle="yes">k</italic> for which <inline-formula id="pcbi.1011240.e041"><alternatives><graphic xlink:href="pcbi.1011240.e041.jpg" id="pcbi.1011240.e041g" position="anchor"/><mml:math id="M41" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula> is sufficiently rich, i.e., <inline-formula id="pcbi.1011240.e042"><alternatives><graphic xlink:href="pcbi.1011240.e042.jpg" id="pcbi.1011240.e042g" position="anchor"/><mml:math id="M42" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. The representer theorem [e.g., <xref rid="pcbi.1011240.ref047" ref-type="bibr">47</xref>] states that such an optimization over <inline-formula id="pcbi.1011240.e043"><alternatives><graphic xlink:href="pcbi.1011240.e043.jpg" id="pcbi.1011240.e043g" position="anchor"/><mml:math id="M43" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula> can be performed efficiently. Formally, it states that the minimizer of an arbitrary convex loss function <inline-formula id="pcbi.1011240.e044"><alternatives><graphic xlink:href="pcbi.1011240.e044.jpg" id="pcbi.1011240.e044g" position="anchor"/><mml:math id="M44" display="inline" overflow="scroll"><mml:mrow><mml:mi>L</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>×</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>→</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>∞</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> of the form
<disp-formula id="pcbi.1011240.e045"><alternatives><graphic xlink:href="pcbi.1011240.e045.jpg" id="pcbi.1011240.e045g" position="anchor"/><mml:math id="M45" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mtext>arg</mml:mtext><mml:mspace width="2pt"/><mml:mtext>min</mml:mtext></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mi>L</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="normal">λ</mml:mi><mml:mo>‖</mml:mo><mml:mi>f</mml:mi><mml:mo>‖</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
with λ &gt; 0 a penalty parameter, has the form <inline-formula id="pcbi.1011240.e046"><alternatives><graphic xlink:href="pcbi.1011240.e046.jpg" id="pcbi.1011240.e046g" position="anchor"/><mml:math id="M46" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mover accent="true"><mml:mi>α</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> for some <inline-formula id="pcbi.1011240.e047"><alternatives><graphic xlink:href="pcbi.1011240.e047.jpg" id="pcbi.1011240.e047g" position="anchor"/><mml:math id="M47" display="inline" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>α</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. This means that instead of optimizing over a potentially infinite-dimensional space <inline-formula id="pcbi.1011240.e048"><alternatives><graphic xlink:href="pcbi.1011240.e048.jpg" id="pcbi.1011240.e048g" position="anchor"/><mml:math id="M48" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, it is sufficient to optimize over the <italic toggle="yes">n</italic>-dimensional parameter <inline-formula id="pcbi.1011240.e049"><alternatives><graphic xlink:href="pcbi.1011240.e049.jpg" id="pcbi.1011240.e049g" position="anchor"/><mml:math id="M49" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>α</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. Depending on the loss function, this allows to construct efficient regression and classification procedures, such as kernel ridge regression and support vector machines [e.g., <xref rid="pcbi.1011240.ref047" ref-type="bibr">47</xref>].</p>
      <p>The performance of the resulting prediction model depends on the choice of kernel as this determines the function space <inline-formula id="pcbi.1011240.e050"><alternatives><graphic xlink:href="pcbi.1011240.e050.jpg" id="pcbi.1011240.e050g" position="anchor"/><mml:math id="M50" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula>. A useful way of thinking about kernels is via their connection to distances. In short, any kernel <italic toggle="yes">k</italic> induces a unique semi-metric <italic toggle="yes">d</italic><sub><italic toggle="yes">k</italic></sub> and vice versa. More details are given in <xref rid="pcbi.1011240.s005" ref-type="supplementary-material">S5 Appendix</xref>. This connection has two important implications. Firstly, it provides a natural way for constructing kernels based on established distances on the simplex. The intuition being that a distance, which is large for observations with vastly different responses and small otherwise, leads to an informative feature space <inline-formula id="pcbi.1011240.e051"><alternatives><graphic xlink:href="pcbi.1011240.e051.jpg" id="pcbi.1011240.e051g" position="anchor"/><mml:math id="M51" display="inline" overflow="scroll"><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></alternatives></inline-formula>. Secondly, it motivates using the kernel-induced distance, see Sec. 2.3.2.</p>
      <sec id="sec005">
        <title>2.2.1 Kernels on the simplex</title>
        <p>We consider four types of kernels on the simplex, each related to different types of distances. A full list with all kernels and induced distances is provided in <xref rid="pcbi.1011240.s007" ref-type="supplementary-material">S7 Appendix</xref>. While most kernels have previously appeared in the literature, we have adapted many of the kernels to fit into the framework provided here, e.g., added zero-imputation for Aitchison kernels and updated the parametrization for the probability distribution kernels.</p>
        <p><bold>Euclidean</bold>. These are kernels that are constructed by restricting kernels on <inline-formula id="pcbi.1011240.e052"><alternatives><graphic xlink:href="pcbi.1011240.e052.jpg" id="pcbi.1011240.e052g" position="anchor"/><mml:math id="M52" display="inline" overflow="scroll"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:math></alternatives></inline-formula> to the simplex. Any such restriction immediately guarantees that the restricted kernel is again a kernel. However, the induced distances are not targeted to the simplex and therefore can be unnatural choices. In <monospace specific-use="no-wrap">KernelBiome</monospace>, we have included the linear kernel and the radial basis function (RBF) kernel. The RBF kernel is <italic toggle="yes">L</italic><sup><italic toggle="yes">p</italic></sup>-universal [e.g., <xref rid="pcbi.1011240.ref048" ref-type="bibr">48</xref>] which means that it can approximate any integrable function (in the large sample limit). However, this does not necessarily imply good performance for finite sample sizes.</p>
        <p><bold>Aitchison geometry</bold>. One way of incorporating the simplex structure is to use the Aitchison geometry. Essentially, this corresponds to mapping points from the interior of the simplex via the centered log-ratio transform into <inline-formula id="pcbi.1011240.e053"><alternatives><graphic xlink:href="pcbi.1011240.e053.jpg" id="pcbi.1011240.e053g" position="anchor"/><mml:math id="M53" display="inline" overflow="scroll"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:math></alternatives></inline-formula> and then using the Euclidean geometry. This results in the Aitchison kernel for which the induced RKHS is equal to the log-contrast functions. In particular, applying kernel ridge regression with an Aitchison kernel corresponds to fitting a log-contrast model with a penalty on the coefficients. As the centered log-ratio transform is only defined for interior points in the simplex, we add a hyperparameter to the kernels that shift them away from zero. From this perspective, the commonly added pseudo-count constant added to all components becomes a tuneable hyperparameter of our method, rather than a fixed ad-hoc choice during data pre-processing. Thereby, our modified Aitchison kernel respects the fact that current approaches to zero-replacement or imputation are often not biologically justified, yet may impact predictive performance. Our proposed zero-imputed Aitchison kernel comes with two advantages over standard log-contrast modelling: (1) A principled adjustment for zeros and (2) an efficient form of high-dimensional regularization that performs well across a large range of our experiments. In <monospace specific-use="no-wrap">KernelBiome</monospace>, we include the Aitchison kernel and the Aitchison-RBF kernel which combines the Aitchison and RBF kernels.</p>
        <p><bold>Probability distributions</bold>. Another approach to incorporate the simplex structure into the kernel is to view points in the simplex as discrete probability distributions. This allows us to make use of the extensive literature on distances between probability distributions to construct kernels. In <monospace specific-use="no-wrap">KernelBiome</monospace>, we have adapted two classes of such kernels: (1) A parametric class based on generalized Jensen-Shannon distances due to [<xref rid="pcbi.1011240.ref049" ref-type="bibr">49</xref>], which we call generalized-JS, and (2) a parametric class based on the work by [<xref rid="pcbi.1011240.ref050" ref-type="bibr">50</xref>], which we call Hilbertian. Together they contain many well-established distances such as the total variation, Hellinger, Chi-squared, and Jensen-Shannon distance. All resulting kernels allow for zeros in the components of compositions.</p>
        <p><bold>Riemannian manifold</bold>. Finally, the simplex structure can be incorporated by using a multinomial distribution which has a parameter in the simplex. [<xref rid="pcbi.1011240.ref051" ref-type="bibr">51</xref>] show that the geometry of multinomial statistical models can be exploited by using kernels based on the heat equation on a Riemannian manifold. The resulting kernel is known as the heat-diffusion kernel and has been observed to work well with sparse data.</p>
      </sec>
      <sec id="sec006">
        <title>2.2.2 Including prior information into kernels</title>
        <p>All kernels introduced in the previous section (and described in detail in <xref rid="pcbi.1011240.s007" ref-type="supplementary-material">S7 Appendix</xref>) are invariant under permutations of the compositional components. They therefore do not take into account any relation between the components. In many applications, one may however have prior knowledge about the relation between the components. For example, if the compositional predictor consists of relative abundances of microbial species, information about the genetic relation between different species encoded in a phylogenetic tree may be available. Therefore, we provide the following way to incorporate such relations. Assume the prior information has been expressed as a positive semi-definite weight matrix <inline-formula id="pcbi.1011240.e054"><alternatives><graphic xlink:href="pcbi.1011240.e054.jpg" id="pcbi.1011240.e054g" position="anchor"/><mml:math id="M54" display="inline" overflow="scroll"><mml:mrow><mml:mi>W</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> with non-negative entries (e.g., using the UniFrac-Distance [<xref rid="pcbi.1011240.ref052" ref-type="bibr">52</xref>] as shown in Sec. C of <xref rid="pcbi.1011240.s002" ref-type="supplementary-material">S2 Appendix</xref>), where the <italic toggle="yes">ij</italic>-th entry corresponds to the strength of the relation between components <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic>. We can then incorporate <italic toggle="yes">W</italic> directly into our kernels. To see how this works, consider the special case where the kernel <italic toggle="yes">k</italic> can be written as <inline-formula id="pcbi.1011240.e055"><alternatives><graphic xlink:href="pcbi.1011240.e055.jpg" id="pcbi.1011240.e055g" position="anchor"/><mml:math id="M55" display="inline" overflow="scroll"><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></alternatives></inline-formula> for a positive definite kernel <inline-formula id="pcbi.1011240.e056"><alternatives><graphic xlink:href="pcbi.1011240.e056.jpg" id="pcbi.1011240.e056g" position="anchor"/><mml:math id="M56" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow><mml:mo>→</mml:mo><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. Then, the weighted kernel
<disp-formula id="pcbi.1011240.e057"><alternatives><graphic xlink:href="pcbi.1011240.e057.jpg" id="pcbi.1011240.e057g" position="anchor"/><mml:math id="M57" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>W</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≔</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(4)</label></disp-formula>
is positive definite and incorporates the prior information in a natural way. If two components <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic> are known to be related (corresponding to large values of <italic toggle="yes">W</italic><sub><italic toggle="yes">i</italic>,<italic toggle="yes">j</italic></sub>), the kernel <italic toggle="yes">k</italic><sub><italic toggle="yes">W</italic></sub> takes the similarity across these components into account. In Sec. B of <xref rid="pcbi.1011240.s002" ref-type="supplementary-material">S2 Appendix</xref>, we show that the probability distribution kernels and the linear kernel can be expressed in this way and propose similar weighted versions for the remaining kernels.</p>
        <p>An advantage of our framework is that it defaults to the log-contrast model when more complex models fail to improve the prediction (due to the zero-shift in our proposed Aitchison kernel and the kernel-based regularization, this correspondence is however not exact). We now show that for the weighted Aitchison kernel, the RKHS consists of log-contrast functions with equal coefficients across the weighted blocks, this is similar to how [<xref rid="pcbi.1011240.ref044" ref-type="bibr">44</xref>] incorporate prior information into log-contrast models.</p>
        <p><bold>Proposition 2.2</bold> (weighted Aitchison kernel RKHS). Let <italic toggle="yes">P</italic><sub>1</sub>, …, <italic toggle="yes">P</italic><sub><italic toggle="yes">m</italic></sub> ⊆ {1, …, <italic toggle="yes">p</italic>} be a disjoint partition and <inline-formula id="pcbi.1011240.e058"><alternatives><graphic xlink:href="pcbi.1011240.e058.jpg" id="pcbi.1011240.e058g" position="anchor"/><mml:math id="M58" display="inline" overflow="scroll"><mml:mrow><mml:mi>W</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>×</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> the weight matrix defined for all <italic toggle="yes">i</italic>, <italic toggle="yes">j</italic> ∈ {1, …, <italic toggle="yes">p</italic>} by <inline-formula id="pcbi.1011240.e059"><alternatives><graphic xlink:href="pcbi.1011240.e059.jpg" id="pcbi.1011240.e059g" position="anchor"/><mml:math id="M59" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≔</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>ℓ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msub><mml:mn mathvariant="double-struck">1</mml:mn><mml:mrow><mml:mo>{</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>ℓ</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Let <italic toggle="yes">k</italic><sub><italic toggle="yes">W</italic></sub> be the weighted Aitchison kernel given in <xref rid="pcbi.1011240.s007" ref-type="supplementary-material">S7 Appendix</xref> (but without zero imputation and on the open simplex). Then, it holds that
<disp-formula id="pcbi.1011240.e060"><alternatives><graphic xlink:href="pcbi.1011240.e060.jpg" id="pcbi.1011240.e060g" position="anchor"/><mml:math id="M60" display="block" overflow="scroll"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="script">H</mml:mi><mml:msub><mml:mi>k</mml:mi><mml:mi>W</mml:mi></mml:msub></mml:msub><mml:mspace width="1em"/><mml:mo>⇔</mml:mo><mml:mspace width="1em"/><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mi>⊤</mml:mi></mml:msup><mml:mspace width="2pt"/><mml:mtext>log</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(7)</label></disp-formula>
for some <inline-formula id="pcbi.1011240.e061"><alternatives><graphic xlink:href="pcbi.1011240.e061.jpg" id="pcbi.1011240.e061g" position="anchor"/><mml:math id="M61" display="inline" overflow="scroll"><mml:mrow><mml:mi>β</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> satisfying (1) <inline-formula id="pcbi.1011240.e062"><alternatives><graphic xlink:href="pcbi.1011240.e062.jpg" id="pcbi.1011240.e062g" position="anchor"/><mml:math id="M62" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msub><mml:mi>β</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and (2) for all <italic toggle="yes">ℓ</italic> ∈ {1, …, <italic toggle="yes">m</italic>} and <italic toggle="yes">i</italic>, <italic toggle="yes">j</italic> ∈ <italic toggle="yes">P</italic><sub><italic toggle="yes">ℓ</italic></sub> it holds <italic toggle="yes">β</italic><sub><italic toggle="yes">i</italic></sub> = <italic toggle="yes">β</italic><sub><italic toggle="yes">j</italic></sub></p>
        <p>A proof is given in <xref rid="pcbi.1011240.s006" ref-type="supplementary-material">S6 Appendix</xref>. Combined with Proposition 2.1, this implies that the CFI values are equal across the equally weighted blocks <italic toggle="yes">P</italic><sub>1</sub>, …, <italic toggle="yes">P</italic><sub><italic toggle="yes">m</italic></sub>, which is demonstrated empirically in Sec. 3.2 and Sec. 3.4.</p>
      </sec>
    </sec>
    <sec id="sec007">
      <title>2.3 KernelBiome framework</title>
      <p>For a given i.i.d. dataset (<italic toggle="yes">X</italic><sub>1</sub>, <italic toggle="yes">Y</italic><sub>1</sub>), …, (<italic toggle="yes">X</italic><sub><italic toggle="yes">n</italic></sub>, <italic toggle="yes">Y</italic><sub><italic toggle="yes">n</italic></sub>), <monospace specific-use="no-wrap">KernelBiome</monospace> first runs a data-driven model selection, resulting in an estimated regression function <inline-formula id="pcbi.1011240.e063"><alternatives><graphic xlink:href="pcbi.1011240.e063.jpg" id="pcbi.1011240.e063g" position="anchor"/><mml:math id="M63" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and a specific kernel <inline-formula id="pcbi.1011240.e064"><alternatives><graphic xlink:href="pcbi.1011240.e064.jpg" id="pcbi.1011240.e064g" position="anchor"/><mml:math id="M64" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> (see <xref rid="pcbi.1011240.g001" ref-type="fig">Fig 1</xref>). Then, the feature influence properties (CFI, CPD) and embedding induced by <inline-formula id="pcbi.1011240.e065"><alternatives><graphic xlink:href="pcbi.1011240.e065.jpg" id="pcbi.1011240.e065g" position="anchor"/><mml:math id="M65" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> are analyzed in a way that respects compositionality.</p>
      <sec id="sec008">
        <title>2.3.1 Model selection</title>
        <p>We propose the following two step data-driven selection procedure.</p>
        <list list-type="order">
          <list-item>
            <p>Select the best kernel <inline-formula id="pcbi.1011240.e066"><alternatives><graphic xlink:href="pcbi.1011240.e066.jpg" id="pcbi.1011240.e066g" position="anchor"/><mml:math id="M66" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> with the following hierarchical CV:
<list list-type="bullet"><list-item><p>Fix a kernel <inline-formula id="pcbi.1011240.e067"><alternatives><graphic xlink:href="pcbi.1011240.e067.jpg" id="pcbi.1011240.e067g" position="anchor"/><mml:math id="M67" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, i.e., a type of kernel and its kernel parameters.</p></list-item><list-item><p>Split the sample into <italic toggle="yes">N</italic><sub>out</sub> random (or stratified) folds.</p></list-item><list-item><p>For each fold, use all other folds to perform a <italic toggle="yes">N</italic><sub>in</sub>-fold CV to select the best hyperparameter <inline-formula id="pcbi.1011240.e068"><alternatives><graphic xlink:href="pcbi.1011240.e068.jpg" id="pcbi.1011240.e068g" position="anchor"/><mml:math id="M68" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi mathvariant="normal">λ</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and compute a CV score based on <inline-formula id="pcbi.1011240.e069"><alternatives><graphic xlink:href="pcbi.1011240.e069.jpg" id="pcbi.1011240.e069g" position="anchor"/><mml:math id="M69" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1011240.e070"><alternatives><graphic xlink:href="pcbi.1011240.e070.jpg" id="pcbi.1011240.e070g" position="anchor"/><mml:math id="M70" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi mathvariant="normal">λ</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> on the left-out fold.</p></list-item><list-item><p>Select the kernel <inline-formula id="pcbi.1011240.e071"><alternatives><graphic xlink:href="pcbi.1011240.e071.jpg" id="pcbi.1011240.e071g" position="anchor"/><mml:math id="M71" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> with the best average CV score.</p></list-item></list></p>
          </list-item>
          <list-item>
            <p>Select the best hyperparameter <inline-formula id="pcbi.1011240.e072"><alternatives><graphic xlink:href="pcbi.1011240.e072.jpg" id="pcbi.1011240.e072g" position="anchor"/><mml:math id="M72" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi mathvariant="normal">λ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> for <inline-formula id="pcbi.1011240.e073"><alternatives><graphic xlink:href="pcbi.1011240.e073.jpg" id="pcbi.1011240.e073g" position="anchor"/><mml:math id="M73" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> using a <italic toggle="yes">N</italic><sub>in</sub>-fold CV on the full data. The final estimator <inline-formula id="pcbi.1011240.e074"><alternatives><graphic xlink:href="pcbi.1011240.e074.jpg" id="pcbi.1011240.e074g" position="anchor"/><mml:math id="M74" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is then given by the kernel predictor based on <inline-formula id="pcbi.1011240.e075"><alternatives><graphic xlink:href="pcbi.1011240.e075.jpg" id="pcbi.1011240.e075g" position="anchor"/><mml:math id="M75" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1011240.e076"><alternatives><graphic xlink:href="pcbi.1011240.e076.jpg" id="pcbi.1011240.e076g" position="anchor"/><mml:math id="M76" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi mathvariant="normal">λ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>.</p>
          </list-item>
        </list>
        <p>This CV scheme ensures that all parameters are selected in a data adaptive way. Up to a point, including more parameter settings into the CV makes the method more robust at the cost of additional run time. We provide sensible default choices for all parameters (see e.g., Table A in Sec. A of <xref rid="pcbi.1011240.s002" ref-type="supplementary-material">S2 Appendix</xref> for the default kernels), allowing practitioners to directly apply the method. In the <monospace specific-use="no-wrap">KernelBiome</monospace> implementation, the parameter grids for the kernel parameters and hyperparameters, as well as parameters of the CV including the type of CV, number of CV folds, and scoring can also be be adjusted manually, for example to reduce the run time.</p>
      </sec>
      <sec id="sec009">
        <title>2.3.2 Model analysis</title>
        <p>Firstly, as discussed in Sec. 2.1, we propose to analyze the fitted model <inline-formula id="pcbi.1011240.e077"><alternatives><graphic xlink:href="pcbi.1011240.e077.jpg" id="pcbi.1011240.e077g" position="anchor"/><mml:math id="M77" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> with the CPD and CFI. Other methods developed for functions on <inline-formula id="pcbi.1011240.e078"><alternatives><graphic xlink:href="pcbi.1011240.e078.jpg" id="pcbi.1011240.e078g" position="anchor"/><mml:math id="M78" display="inline" overflow="scroll"><mml:msup><mml:mi mathvariant="double-struck">R</mml:mi><mml:mi>p</mml:mi></mml:msup></mml:math></alternatives></inline-formula> do not account for compositionality and can be misleading. Secondly, the kernel embedding <inline-formula id="pcbi.1011240.e079"><alternatives><graphic xlink:href="pcbi.1011240.e079.jpg" id="pcbi.1011240.e079g" position="anchor"/><mml:math id="M79" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> can be used for the following two types of analyses.</p>
        <p><bold>Distance-based analysis</bold>. A key advantage of using kernels is that the fitted kernel <inline-formula id="pcbi.1011240.e080"><alternatives><graphic xlink:href="pcbi.1011240.e080.jpg" id="pcbi.1011240.e080g" position="anchor"/><mml:math id="M80" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is itself helpful in the analysis. As discussed in Sec. 2.2, <inline-formula id="pcbi.1011240.e081"><alternatives><graphic xlink:href="pcbi.1011240.e081.jpg" id="pcbi.1011240.e081g" position="anchor"/><mml:math id="M81" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> induces a distance on the simplex that is well-suited to separate observations with different response values. We therefore suggest to utilize this distance to investigate the data further. Essentially, any statistical method based on distances can be applied. We specifically suggest using kernel PCA to project the samples into a two-dimensional space. As we illustrate in Sec. 3.3, such a projection can be used to detect specific groups or outliers in the samples and can also help understand how the predictors are used by the prediction model <inline-formula id="pcbi.1011240.e082"><alternatives><graphic xlink:href="pcbi.1011240.e082.jpg" id="pcbi.1011240.e082g" position="anchor"/><mml:math id="M82" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. As we are working with compositional data we need to be careful when looking at how individual components contribute to each principle component. Fortunately, the perturbation <italic toggle="yes">ψ</italic> defined in Sec. 2.1 can again be used to construct informative component-wise measures. All details on kernel PCA and how to compute component-wise contributions for each principle component are provided in Sec. B of <xref rid="pcbi.1011240.s005" ref-type="supplementary-material">S5 Appendix</xref>.</p>
        <p><bold>Data-driven scalar summary statistics</bold>. Practitioners often work with scalar summaries of the data as these are easy to communicate. A commonly used summary statistic in ecology is <italic toggle="yes">α</italic>-diversity which measures the variation within a community. The connection between kernels and distances provides a useful tool to construct informative scalar summary statistics by considering distances to a reference point <italic toggle="yes">u</italic> in the simplex. Formally, for a fixed reference point <inline-formula id="pcbi.1011240.e083"><alternatives><graphic xlink:href="pcbi.1011240.e083.jpg" id="pcbi.1011240.e083g" position="anchor"/><mml:math id="M83" display="inline" overflow="scroll"><mml:mrow><mml:mi>u</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> define for all <inline-formula id="pcbi.1011240.e084"><alternatives><graphic xlink:href="pcbi.1011240.e084.jpg" id="pcbi.1011240.e084g" position="anchor"/><mml:math id="M84" display="inline" overflow="scroll"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant="double-struck">S</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> a corresponding closeness measure by <inline-formula id="pcbi.1011240.e085"><alternatives><graphic xlink:href="pcbi.1011240.e085.jpg" id="pcbi.1011240.e085g" position="anchor"/><mml:math id="M85" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mi>D</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≔</mml:mo><mml:mo>-</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <italic toggle="yes">d</italic><sub><italic toggle="yes">k</italic></sub> is the distance induced by the kernel <italic toggle="yes">k</italic>. This provides an easily interpretable scalar quantity. For example, if <italic toggle="yes">Y</italic> is a binary indicator taking values <italic toggle="yes">healthy</italic> and <italic toggle="yes">sick</italic>, we could select <italic toggle="yes">u</italic> to be the geometric median (the observation that has the smallest total distance to all the other observations based on the pairwise kernel distance) of all <italic toggle="yes">X</italic><sub><italic toggle="yes">i</italic></sub> with <italic toggle="yes">Y</italic><sup><italic toggle="yes">i</italic></sup> = <italic toggle="yes">healthy</italic>. Then, <italic toggle="yes">D</italic><sup><italic toggle="yes">k</italic></sup> corresponds to a very simple health score (see Sec. 3.3 for a concrete example). A further example is given by selecting <italic toggle="yes">u</italic> = (1/<italic toggle="yes">p</italic>, …, 1/<italic toggle="yes">p</italic>) and considering points on the simplex as communities. Then, <italic toggle="yes">u</italic> can be interpreted as the most diverse point in the simplex and <italic toggle="yes">D</italic><sup><italic toggle="yes">k</italic></sup> corresponds to a data-adaptive <italic toggle="yes">α</italic>-diversity measure. While such a definition of diversity does not necessarily satisfy all desirable properties for diversities [see e.g., <xref rid="pcbi.1011240.ref053" ref-type="bibr">53</xref>], it is (1) symmetric with respect to switching of coordinates, (2) has an intuitive interpretation and (3) is well-behaved when combined with weighted kernels. Connections to established diversities also exist, for example, the linear kernel corresponds to a shifted version of the Gini-Simpson diversity (i.e., <inline-formula id="pcbi.1011240.e086"><alternatives><graphic xlink:href="pcbi.1011240.e086.jpg" id="pcbi.1011240.e086g" position="anchor"/><mml:math id="M86" display="inline" overflow="scroll"><mml:mrow><mml:mtext>Gini-Simpson</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≔</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:mfrac></mml:mstyle></mml:mrow></mml:math></alternatives></inline-formula>).</p>
      </sec>
      <sec id="sec010">
        <title>2.3.3 Run time complexity</title>
        <p>The run time complexity of <monospace specific-use="no-wrap">KernelBiome</monospace> depends on the number of kernels <italic toggle="yes">K</italic>, the size of the hyperparameter grid <italic toggle="yes">H</italic>, and the number of inner CV folds <italic toggle="yes">N</italic><sub>in</sub> and outer CV folds <italic toggle="yes">N</italic><sub>out</sub>. Since the run time complexity of kernel ridge regression and support vector machines is <italic toggle="yes">O</italic>(<italic toggle="yes">n</italic><sup>3</sup>) (based on a straightforward implementation, actual implementation in available software libraries can achieve a more optimized run time), the total run time complexity of <monospace specific-use="no-wrap">KernelBiome</monospace> is <italic toggle="yes">O</italic>(<italic toggle="yes">KHN</italic><sub>in</sub><italic toggle="yes">N</italic><sub>out</sub><italic toggle="yes">n</italic><sup>3</sup>). For example, the default parameter settings use 55 kernels, with 5-fold inner CV and 10-fold outer CV with a hyperparameter grid of size 10, resulting in 27,500 model fits, each of complexity <italic toggle="yes">O</italic>(<italic toggle="yes">n</italic><sup>3</sup>). To reduce the run time we recommend reducing the number of kernels <italic toggle="yes">K</italic>, this can be particularly useful for prototyping. However, if possible, we recommend using the full list of kernels for a final analysis to avoid a decrease in predictive performance.</p>
      </sec>
      <sec id="sec011">
        <title>2.3.4 Implementation</title>
        <p><monospace specific-use="no-wrap">KernelBiome</monospace> is implemented as a Python [<xref rid="pcbi.1011240.ref054" ref-type="bibr">54</xref>] package that takes advantage of the high-performance <monospace specific-use="no-wrap">JAX</monospace> [<xref rid="pcbi.1011240.ref055" ref-type="bibr">55</xref>] and <monospace specific-use="no-wrap">scikit-learn</monospace> [<xref rid="pcbi.1011240.ref056" ref-type="bibr">56</xref>] libraries. All kernels introduced are implemented with <monospace specific-use="no-wrap">JAX</monospace>’s just-in-time compilation and automatically leverage accelerators such as GPU and TPU whenever available. <monospace specific-use="no-wrap">KernelBiome</monospace> provides fast computation of all kernels and distance metrics as well as easy-to-use procedures for model selection and comparison and procedures to estimate CPD and CFI, compute kernel PCA, and estimate scalar summary statistics. An illustration script for the package’s usage can be found in the package repository.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results" id="sec012">
    <title>3 Results</title>
    <p>We evaluated <monospace specific-use="no-wrap">KernelBiome</monospace> on a total of 33 microbiome datasets. All datasets have been previously published and final datasets used in our experiments can be fully reproduced following the description in the GitHub repo <ext-link xlink:href="https://github.com/shimenghuang/KernelBiome" ext-link-type="uri">https://github.com/shimenghuang/KernelBiome</ext-link>. A summary of the datasets including on the pre-processing steps, prediction task and references is provided in Table A in <xref rid="pcbi.1011240.s003" ref-type="supplementary-material">S3 Appendix</xref>. First, in Sec. 3.1, we show that <monospace specific-use="no-wrap">KernelBiome</monospace> performs on par or better than existing supervised learning procedures for compositional data, while reducing to a powerfully regularized version of the log-contrast model if the prediction task is simple. In Sec. 3.2, we show on a semi-artificial dataset that including prior information can either improve or harm the predictive performance depending on whether or not it is relevant for the prediction. In Sec. 3.3, we illustrate the advantages of a full analysis with <monospace specific-use="no-wrap">KernelBiome</monospace>. Finally, in Sec. 3.4, we demonstrate how <monospace specific-use="no-wrap">KernelBiome</monospace> can incorporate prior knowledge, while preserving a theoretically justified interpretation.</p>
    <sec id="sec013">
      <title>3.1 State-of-the-art prediction performance</title>
      <p>We compare the predictive performance of <monospace specific-use="no-wrap">KernelBiome</monospace> on all datasets with the following competitors: (i) <monospace specific-use="no-wrap">Baseline</monospace>, a naive predictor that uses the training majority class for classification and the training mean for regression as its prediction, (ii) <monospace specific-use="no-wrap">SVM-RBF</monospace>, a support vector machine with the RBF kernel, (iii) <monospace specific-use="no-wrap">Lin/Log-L1</monospace>, a linear/logistic regression with <italic toggle="yes">ℓ</italic><sup>1</sup>-penalty (iv) <monospace specific-use="no-wrap">LogCont-L1</monospace>, a log-contrast regression with <italic toggle="yes">ℓ</italic><sup>1</sup> penalty with a half of the minimum non-zero relative abundance added as pseudo-count to remove zeros, and (v) <monospace specific-use="no-wrap">RF</monospace>, a random forest with 500 trees. For <monospace specific-use="no-wrap">SVM-RBF</monospace>, <monospace specific-use="no-wrap">Lin/Log-L1</monospace> and <monospace specific-use="no-wrap">RF</monospace> we use the <monospace specific-use="no-wrap">scikit-learn</monospace> implementations [<xref rid="pcbi.1011240.ref056" ref-type="bibr">56</xref>] and choose the hyperparameters (bandwidth, max depth and all penalty parameters) based on a 5-fold CV. For <monospace specific-use="no-wrap">LogCont-L1</monospace>, we use the <monospace specific-use="no-wrap">c-lasso</monospace> package [<xref rid="pcbi.1011240.ref016" ref-type="bibr">16</xref>] and the default CV scheme to chose the penalty parameter. We apply two versions of <monospace specific-use="no-wrap">KernelBiome</monospace>: (1) The standard version that adaptively chooses the kernel using <italic toggle="yes">N</italic><sub>in</sub> = 5, <italic toggle="yes">N</italic><sub>out</sub> = 10 (denoted <monospace specific-use="no-wrap">KernelBiome</monospace>), and (2) a version with fixed Aitchison kernel with <italic toggle="yes">c</italic> equal to half of the minimum non-zero relative abundance (denoted <monospace specific-use="no-wrap">KB-Aitchison</monospace>). Both methods use a default hyperparameter grid of size 40, and we use kernel ridge regression as the estimator. We compared with using support vector regression instead of kernel ridge regression and the results are similar.</p>
      <p>For the comparison we perform 20 random (stratified) 10-fold train/test splits and record the predictive performance (balanced accuracy for classification and root-mean-squared error (RMSE) for regression) on each test set. <xref rid="pcbi.1011240.g003" ref-type="fig">Fig 3</xref> contains the summary results for the 33 datasets. <xref rid="pcbi.1011240.g003" ref-type="fig">Fig 3A</xref> gives an overview of the predictive performance. To make the comparison easier, the median test scores are normalized to between 0 and 1 based on the minimum and maximum scores of each dataset. More details of the predictive performance results including boxplots of scores for all tasks and precision-recall curves for all classification tasks are provided in Figs B and C in <xref rid="pcbi.1011240.s003" ref-type="supplementary-material">S3 Appendix</xref>. Moreover, we perform a Wilcoxon signed-rank test [<xref rid="pcbi.1011240.ref057" ref-type="bibr">57</xref>] on the test scores and the percentage of times a method is significantly outperformed by another is given in <xref rid="pcbi.1011240.g003" ref-type="fig">Fig 3B</xref>. Lastly, run times of each method on the 33 datasets are shown in <xref rid="pcbi.1011240.g003" ref-type="fig">Fig 3C</xref>.</p>
      <fig position="float" id="pcbi.1011240.g003">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011240.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <p>(A) Comparison of predictive performance on 33 public datasets (9 regression and 24 classification tasks, separated by the grey vertical line in the figure) based on 20 random 10-fold CV. On the two datasets with grey tick labels no method significantly outperforms the baseline based on the Wilcoxon signed-rank test, meaning that there is little signal in the data. The ones in green are the datasets where <monospace specific-use="no-wrap">KernelBiome</monospace> significantly outperforms the baseline, while it does not on the single dataset with the black label. The corresponding p-values are provided in brackets. (B) Percentage of time a method is significantly outperformed by another based on the Wilcoxon signed-rank test. (C) Average run time of each method on each dataset. A significance level of 0.05 is used.</p>
        </caption>
        <graphic xlink:href="pcbi.1011240.g003" position="float"/>
      </fig>
      <p>On all datasets <monospace specific-use="no-wrap">KernelBiome</monospace> achieves the best or close to best performance and (almost) always captures useful information (green labels in <xref rid="pcbi.1011240.g003" ref-type="fig">Fig 3A</xref>), indicating that the proposed procedure is well-adapted to microbiome data. The kernel which was selected most often by <monospace specific-use="no-wrap">KernelBiome</monospace> and the frequency with which it was selected are shown in Table B in <xref rid="pcbi.1011240.s003" ref-type="supplementary-material">S3 Appendix</xref>. There are several interesting observations: (1) Even though <monospace specific-use="no-wrap">KernelBiome</monospace> selects mostly the Aitchison kernel on rmp, it outperforms <monospace specific-use="no-wrap">KB-Aitchison</monospace>, we attribute this to the advantage of the data-driven zero-imputation. (2) On datasets were the top kernel is selected consistently (e.g., uk, hiv and tara) <monospace specific-use="no-wrap">KernelBiome</monospace> generally performs very well and in these cases strongly outperformed both log-contrast based methods <monospace specific-use="no-wrap">KB-Aitchison</monospace> and <monospace specific-use="no-wrap">LogCont-L1</monospace>. (3) The predictive performance is substantially different between <monospace specific-use="no-wrap">KB-Aitchison</monospace> and <monospace specific-use="no-wrap">LogCont-L1</monospace> which we see as an indication that the type of regularization (kernel-based vs <italic toggle="yes">ℓ</italic><sup>1</sup>-regularization, respectively) is crucial in microbiome datasets.</p>
    </sec>
    <sec id="sec014">
      <title>3.2 Predictive performance given prior information</title>
      <p>In many applications, in particular in biology, prior information about a system is available and should be incorporated into the data analysis. As we show in Sec. 2.2.2, <monospace specific-use="no-wrap">KernelBiome</monospace> allows for incorporating prior knowledge on the relation between individual components (e.g., taxa). We will illustrate in this section that given informative prior knowledge, the predictive performance of <monospace specific-use="no-wrap">KernelBiome</monospace> can be improved, while if the prior knowledge is uninformative or incorrect, the predictive performance can be harmed. We conduct a semi-synthetic experiment based on the uk dataset. The dataset has 327 species and <italic toggle="yes">n</italic> = 882 samples. We generate the response <italic toggle="yes">Y</italic> based on two processes: (DGP1) a linear log-contrast model where species under phylum Bacteroidetes all have coefficient <italic toggle="yes">β</italic><sub><italic toggle="yes">B</italic></sub>, species under phylum Proteobacteria all have coefficient <italic toggle="yes">β</italic><sub><italic toggle="yes">P</italic></sub>, and all coefficients corresponding to other species are set to 0; (DGP2) a linear log-contrast model where the first half of the species under Bacteroidetes are given coefficient −<italic toggle="yes">β</italic><sub><italic toggle="yes">B</italic></sub> while the second half are given coefficient <italic toggle="yes">β</italic><sub><italic toggle="yes">B</italic></sub>, similarly for Proteobacteria.</p>
      <p>We construct a weight matrix based on the phylum each species belongs to (similar as in Prop. 2.2). By construction these weights are informative if the data are generated from DGP1, but not if the data are generated from DGP2. For each DGP, we sample 100 data points for training and another 100 data points for testing, repeated for 200 times. We compare the predictive performance of all methods mentioned in Sec. 3.1 and weighted <monospace specific-use="no-wrap">KernelBiome</monospace> (KB-Weighted) in <xref rid="pcbi.1011240.g004" ref-type="fig">Fig 4</xref>. The results show that when the weights are indeed informative, KB-Weighted achieves the best performance and is significantly better than the unweighted version (p-value 2.34 × 10<sup>−18</sup> based on Wilcoxon signed-rank test). On the other hand, when the weights do not align with the underlying generating mechanism, the predictive performance of KB-Weighted can be significantly worse than the unweighted one (p-value 1.25 × 10<sup>−9</sup> based on Wilcoxon signed-rank test). A table containing the number of other methods a method is significantly outperformed by under the two DGPs is also provided in <xref rid="pcbi.1011240.g004" ref-type="fig">Fig 4</xref>. All methods significantly outperform the baseline in this example, and the corresponding p-values are all below 2 × 10<sup>−17</sup>.</p>
      <fig position="float" id="pcbi.1011240.g004">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011240.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <p>Left and middle: Predictive performance of weighted <monospace specific-use="no-wrap">KernelBiome</monospace> when the given weights are informative (DGP1) and adversarial (DGP2) based on 200 repetitions. Right: the number of other methods each method is significantly outperformed by based on Wilcoxon signed-rank test (siginificance level 0.05), under DGP1 and DGP2.</p>
        </caption>
        <graphic xlink:href="pcbi.1011240.g004" position="float"/>
      </fig>
    </sec>
    <sec id="sec015">
      <title>3.3 Model analysis with KernelBiome</title>
      <p>As shown in the previous section, <monospace specific-use="no-wrap">KernelBiome</monospace> results in fitted models with state-of-the-art prediction performance. This is useful because supervised learning procedures can be used in two types of applications: (1) To learn a prediction model that has a direct application, e.g., as a diagnostic tool, or (2) to learn a predictive model as an intermediate step of an exploratory analysis to find out what factors could be driving the response. As discussed above (2) requires us to take the compositional nature of the predictors into account to avoid misleading conclusions. We show how the <monospace specific-use="no-wrap">KernelBiome</monospace> framework can be used to achieve this based on two datasets: (i) <italic toggle="yes">cirrhosis</italic>, based on a study analyzing the differences in microbial compositions between <italic toggle="yes">n</italic> = 130 healthy and cirrhotic patients [<xref rid="pcbi.1011240.ref058" ref-type="bibr">58</xref>] and (ii) <italic toggle="yes">centralparksoil</italic>, based on a study analyzing the pH concentration using microbial compositions from <italic toggle="yes">n</italic> = 580 soil samples [<xref rid="pcbi.1011240.ref059" ref-type="bibr">59</xref>]. Our aim is not do draw novel biological conclusions, but rather to showcase how <monospace specific-use="no-wrap">KernelBiome</monospace> can be used in this type of analysis.</p>
      <p>To reduce the complexity, we screen the data using <monospace specific-use="no-wrap">KernelBiome</monospace> with the Aitchison kernel and only keep the 50 taxa with the highest absolute CFIs. (As the analysis described here is only an illustration and we are not trying to compare methods, overfitting in this screening step is not a concern. In practice, however, it may be relevant to validate the sensitivity of the results using for example subsampling). We then fit <monospace specific-use="no-wrap">KernelBiome</monospace> with default parameter grid. For cirrhosis this results in the Aitchison kernel and for centralparksoil in the Aitchison-RBF kernel. As outlined in Sec. 2.3.2, we can then apply a kernel PCA with a compositionally adjusted component influence. The result for centralparksoil is given in <xref rid="pcbi.1011240.g005" ref-type="fig">Fig 5A</xref> (for cirrhosis see Fig D in <xref rid="pcbi.1011240.s003" ref-type="supplementary-material">S3 Appendix</xref>). This provides some direct information on which perturbations affects each principle component (e.g., “[g]DA101[s]98” affects the first component the most positively and “Sphingobacterium[s]multivorum” affects the second component the most negatively). Moreover, it also directly provides a tool to detect groupings or outliers of the samples. For example, the samples in the top middle (i.e., center of the U-shape) in <xref rid="pcbi.1011240.g005" ref-type="fig">Fig 5A</xref> could be investigated further as they behave different to the rest.</p>
      <fig position="float" id="pcbi.1011240.g005">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1011240.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <p>(A) shows a kernel PCA for the centralparksoil dataset with 2 principle components. On the right, the contribution of the species to each of the two components is given (see Sec. B of <xref rid="pcbi.1011240.s005" ref-type="supplementary-material">S5 Appendix</xref> for details). (B) and (C) are both based on the cirrhosis dataset. In (B) the CFI values are shown on the left and the right plot compares the proposed kernel health score with Simpson diversity. In (C) the scaled CFI values for are illustrated for different weightings. A darker color shade of the (shortened) name of the microbiota signifies a stronger (positive resp. negative) CFI.</p>
        </caption>
        <graphic xlink:href="pcbi.1011240.g005" position="float"/>
      </fig>
      <p>A further useful quantity is the CFI, which for cirrhosis is given in <xref rid="pcbi.1011240.g005" ref-type="fig">Fig 5B</xref> (left) (for centralparksoil see Fig E in <xref rid="pcbi.1011240.s003" ref-type="supplementary-material">S3 Appendix</xref>). They explicitly take the compositional structure into account and have an easy interpretation. For example, “Prevotella_timonensis” has a CFI of 0.07 which implies that on average solely increasing “Prevotella_timonensis” will lead to a larger predicted response. We therefore believe that CFIs are more trustworthy than relying on for example Gini-importance for random forests, which does not have a clear interpretation due to the compositional constraint.</p>
      <p>Lastly, one can also use the connection between kernels and distances to construct useful scalar summary statistics. In <xref rid="pcbi.1011240.g005" ref-type="fig">Fig 5B</xref> (right), we use the kernel-distance to the geometric median in the healthy subpopulation as a scalar indicator for the healthiness of the microbiome. In comparison with more standard scalar summary statistics such as the Simpson diversity, it is targeted to distinguish the two groups.</p>
    </sec>
    <sec id="sec016">
      <title>3.4 Model analysis given prior information</title>
      <p>Including prior information in <monospace specific-use="no-wrap">KernelBiome</monospace> can be used to improve the interpretation of the model analysis step. To illustrate how this works in practice, we again consider the screened cirrhosis dataset. We apply <monospace specific-use="no-wrap">KernelBiome</monospace> with an Aitchison-kernel and <italic toggle="yes">c</italic> equal to half the minimum non-zero relative abundance without weighting, with a phylum-weighting and with a UniFrac-weighting. The resulting scaled CFI values for each are visualized in <xref rid="pcbi.1011240.g005" ref-type="fig">Fig 5C</xref>. The phylum-weighting corresponds to giving all taxa within the same phylum the same weights and the UniFrac-weighting is a weighting that incorporates the phylogenetic structure based on the UniFrac-distance and is described in Sec. C of <xref rid="pcbi.1011240.s002" ref-type="supplementary-material">S2 Appendix</xref>. As can bee seen in <xref rid="pcbi.1011240.g005" ref-type="fig">Fig 5C</xref>, the phylum weighting assigns approximately the same CFI to each variable in the same phylum, this is expected given that the phylum weighting has exactly the structure given in Proposition 2.2. Moreover, the UniFrac-weighting leads to CFI values that lie in-between the unweighted and phylum-weighted versions. Similar effects are seen for different kernels as well. The same plots for the generalized-JS kernel are provided in Fig G in <xref rid="pcbi.1011240.s003" ref-type="supplementary-material">S3 Appendix</xref>.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec017">
    <title>4 Discussion and conclusions</title>
    <p>In this work, we propose the <monospace specific-use="no-wrap">KernelBiome</monospace> framework for supervised learning with compositional covariates consisting of two main ingredients: data-driven model selection and model interpretation. Our approach is based on a flexible family of kernels targeting the structure of microbiome data, and is able to work with different kernel-based algorithms such as SVM and kernel ridge regression. One can also incorporate prior knowledge, which is crucial in microbiome data analysis. We compare <monospace specific-use="no-wrap">KernelBiome</monospace> with other state-of-the-art approaches on 33 microbiome datasets and show that <monospace specific-use="no-wrap">KernelBiome</monospace> achieves improved or comparable results. Moreover, <monospace specific-use="no-wrap">KernelBiome</monospace> provides multiple ways to extract interpretable information from the fitted model. Two novel measures, CFI and CPD, can be used to analyze how each component affects the response. We prove the consistency of these two measures and illustrate them on simulated and real datasets. <monospace specific-use="no-wrap">KernelBiome</monospace> also leverages the connection between kernels and distances to conduct distance-based analysis in a lower-dimensional space.</p>
  </sec>
  <sec id="sec018" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pcbi.1011240.s001" position="float" content-type="local-data">
      <label>S1 Appendix</label>
      <caption>
        <title>Details on CFI and CPD.</title>
        <p>Formal definitions of perturbations and estimators related to CFI and CPD.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011240.s002" position="float" content-type="local-data">
      <label>S2 Appendix</label>
      <caption>
        <title>Details on kernels included in <monospace specific-use="no-wrap">KernelBiome</monospace>.</title>
        <p>Overview of different kernel types, details on how they connect to distances and description of weighted kernels.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011240.s003" position="float" content-type="local-data">
      <label>S3 Appendix</label>
      <caption>
        <title>Details and additional results for experiments in Sec. 3.</title>
        <p>Datasets pre-processing, parameter setup, construction of the weighting matrices with UniFrac-distance and further experiment results based on the cirrhosis and centralparksoil datasets.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s003.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011240.s004" position="float" content-type="local-data">
      <label>S4 Appendix</label>
      <caption>
        <title>Additional experiments with simulated data.</title>
        <p>Consistency of CFI and CPD and comparison of CFI and CPD with their non-simplex counterparts.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s004.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011240.s005" position="float" content-type="local-data">
      <label>S5 Appendix</label>
      <caption>
        <title>Background on kernels.</title>
        <p>Mathematical background on kernels and details on dimensionality and visualization with kernels.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s005.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011240.s006" position="float" content-type="local-data">
      <label>S6 Appendix</label>
      <caption>
        <title>Proofs.</title>
        <p>Proof of theorems and propositions.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s006.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pcbi.1011240.s007" position="float" content-type="local-data">
      <label>S7 Appendix</label>
      <caption>
        <title>List of kernels implemented in <monospace specific-use="no-wrap">KernelBiome</monospace>.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1011240.s007.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>The authors would like to thank Christian Müller for detailed feedback and suggestions on this work, Johannes Ostner for help creating the circle plots, Jeroen Raes and Doris Vandeputte for making their raw data available.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1011240.ref001">
      <label>1</label>
      <mixed-citation publication-type="book"><name><surname>Buccianti</surname><given-names>A</given-names></name>, <name><surname>Mateu-Figueras</surname><given-names>G</given-names></name>, <name><surname>Pawlowsky-Glahn</surname><given-names>V</given-names></name>. <part-title>Compositional data analysis in the geosciences: from theory to practice</part-title>. In: <source>GSL Special Publications</source>. <publisher-name>Geological Society of London</publisher-name>; <year>2006</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Pesenson</surname><given-names>MZ</given-names></name>, <name><surname>Suram</surname><given-names>SK</given-names></name>, <name><surname>Gregoire</surname><given-names>JM</given-names></name>. <article-title>Statistical analysis and interpolation of compositional data in materials science</article-title>. <source>ACS combinatorial science</source>. <year>2015</year>;<volume>17</volume>(<issue>2</issue>):<fpage>130</fpage>–<lpage>136</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1021/co5001458</pub-id><?supplied-pmid 25547365?><pub-id pub-id-type="pmid">25547365</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Jackson</surname><given-names>DA</given-names></name>. <article-title>Compositional data in community ecology: the paradigm or peril of proportions?</article-title><source>Ecology</source>. <year>1997</year>;<volume>78</volume>(<issue>3</issue>):<fpage>929</fpage>–<lpage>940</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1890/0012-9658(1997)078[0929:CDICET]2.0.CO;2</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>H</given-names></name>. <article-title>Microbiome, metagenomics, and high-dimensional compositional data analysis</article-title>. <source>Annual Review of Statistics and Its Application</source>. <year>2015</year>;<volume>2</volume>:<fpage>73</fpage>–<lpage>94</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1146/annurev-statistics-010814-020351</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Aitchison</surname><given-names>J</given-names></name>. <article-title>The statistical analysis of compositional data</article-title>. <source>Journal of the Royal Statistical Society: Series B (Methodological)</source>. <year>1982</year>;<volume>44</volume>(<issue>2</issue>):<fpage>139</fpage>–<lpage>160</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Egozcue</surname><given-names>JJ</given-names></name>, <name><surname>Pawlowsky-Glahn</surname><given-names>V</given-names></name>, <name><surname>Mateu-Figueras</surname><given-names>G</given-names></name>, <name><surname>Barcelo-Vidal</surname><given-names>C</given-names></name>. <article-title>Isometric logratio transformations for compositional data analysis</article-title>. <source>Mathematical Geology</source>. <year>2003</year>;<volume>35</volume>(<issue>3</issue>):<fpage>279</fpage>–<lpage>300</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1023/A:1023818214614</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Aitchison</surname><given-names>J</given-names></name>. <article-title>A general class of distributions on the simplex</article-title>. <source>Journal of the Royal Statistical Society: Series B (Methodological)</source>. <year>1985</year>;<volume>47</volume>(<issue>1</issue>):<fpage>136</fpage>–<lpage>146</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref008">
      <label>8</label>
      <mixed-citation publication-type="other">Tsagris MT, Preston S, Wood AT. A data-based power transformation for compositional data; arXiv:1106.1451 [Preprint]. 2011. Available from: <ext-link xlink:href="https://arxiv.org/abs/1106.1451" ext-link-type="uri">https://arxiv.org/abs/1106.1451</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Aitchison</surname><given-names>J</given-names></name>. <article-title>Principal component analysis of compositional data</article-title>. <source>Biometrika</source>. <year>1983</year>;<volume>70</volume>(<issue>1</issue>):<fpage>57</fpage>–<lpage>65</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/biomet/70.1.57</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Aitchison</surname><given-names>J</given-names></name>, <name><surname>Greenacre</surname><given-names>M</given-names></name>. <article-title>Biplots of compositional data</article-title>. <source>Journal of the Royal Statistical Society: Series C (Applied Statistics)</source>. <year>2002</year>;<volume>51</volume>(<issue>4</issue>):<fpage>375</fpage>–<lpage>392</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Friedman</surname><given-names>J</given-names></name>, <name><surname>Alm</surname><given-names>EJ</given-names></name>. <article-title>Inferring correlation networks from genomic survey data</article-title>. <source>Computational Biology</source>. <year>2012</year>;. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002687</pub-id><?supplied-pmid 23028285?><pub-id pub-id-type="pmid">23028285</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Aitchison</surname><given-names>J</given-names></name>, <name><surname>Bacon-Shone</surname><given-names>J</given-names></name>. <article-title>Log contrast models for experiments with mixtures</article-title>. <source>Biometrika</source>. <year>1984</year>;<volume>71</volume>(<issue>2</issue>):<fpage>323</fpage>–<lpage>330</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/biomet/71.2.323</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>W</given-names></name>, <name><surname>Shi</surname><given-names>P</given-names></name>, <name><surname>Feng</surname><given-names>R</given-names></name>, <name><surname>Li</surname><given-names>H</given-names></name>. <article-title>Variable selection in regression with compositional covariates</article-title>. <source>Biometrika</source>. <year>2014</year>;<volume>101</volume>(<issue>4</issue>):<fpage>785</fpage>–<lpage>797</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/biomet/asu031</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Shi</surname><given-names>P</given-names></name>, <name><surname>Zhang</surname><given-names>A</given-names></name>, <name><surname>Li</surname><given-names>H</given-names></name>. <article-title>Regression analysis for microbiome compositional data</article-title>. <source>The Annals of Applied Statistics</source>. <year>2016</year>;<volume>10</volume>(<issue>2</issue>):<fpage>1019</fpage>–<lpage>1040</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1214/16-AOAS928</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Combettes</surname><given-names>PL</given-names></name>, <name><surname>Müller</surname><given-names>CL</given-names></name>. <article-title>Regression models for compositional data: General log-contrast formulations, proximal optimization, and microbiome data applications</article-title>. <source>Statistics in Biosciences</source>. <year>2020</year>; p. <fpage>1</fpage>–<lpage>26</lpage>.<pub-id pub-id-type="pmid">32292527</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Simpson</surname><given-names>L</given-names></name>, <name><surname>Combettes</surname><given-names>P</given-names></name>, <name><surname>Müller</surname><given-names>C</given-names></name>. <article-title>c-lasso—a Python package for constrained sparse and robust regression and classification</article-title>. <source>Journal of Open Source Software</source>. <year>2021</year>;<volume>6</volume>:<fpage>2844</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.21105/joss.02844</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref017">
      <label>17</label>
      <mixed-citation publication-type="other">Ailer E, Müller CL, Kilbertus N. A causal view on compositional data; arXiv:2106.11234 [Preprint]. 2021. Available from: <ext-link xlink:href="https://arxiv.org/abs/2106.11234" ext-link-type="uri">https://arxiv.org/abs/2106.11234</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Tsilimigras</surname><given-names>MC</given-names></name>, <name><surname>Fodor</surname><given-names>AA</given-names></name>. <article-title>Compositional data analysis of the microbiome: fundamentals, tools, and challenges</article-title>. <source>Annals of Epidemiology</source>. <year>2016</year>;<volume>26</volume>(<issue>5</issue>):<fpage>330</fpage>–<lpage>335</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.annepidem.2016.03.002</pub-id><?supplied-pmid 27255738?><pub-id pub-id-type="pmid">27255738</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Gloor</surname><given-names>GB</given-names></name>, <name><surname>Macklaim</surname><given-names>JM</given-names></name>, <name><surname>Pawlowsky-Glahn</surname><given-names>V</given-names></name>, <name><surname>Egozcue</surname><given-names>JJ</given-names></name>. <article-title>Microbiome datasets are compositional: and this is not optional</article-title>. <source>Frontiers in Microbiology</source>. <year>2017</year>;<volume>8</volume>:<fpage>2224</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fmicb.2017.02224</pub-id><?supplied-pmid 29187837?><pub-id pub-id-type="pmid">29187837</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Kaul</surname><given-names>A</given-names></name>, <name><surname>Mandal</surname><given-names>S</given-names></name>, <name><surname>Davidov</surname><given-names>O</given-names></name>, <name><surname>Peddada</surname><given-names>SD</given-names></name>. <article-title>Analysis of microbiome data in the presence of excess zeros</article-title>. <source>Frontiers in Microbiology</source>. <year>2017</year>;<volume>8</volume>:<fpage>2114</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fmicb.2017.02114</pub-id><?supplied-pmid 29163406?><pub-id pub-id-type="pmid">29163406</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Lin</surname><given-names>H</given-names></name>, <name><surname>Peddada</surname><given-names>SD</given-names></name>. <article-title>Analysis of microbial compositions: a review of normalization and differential abundance analysis</article-title>. <source>NPJ biofilms and microbiomes</source>. <year>2020</year>;<volume>6</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>13</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41522-020-00160-w</pub-id><?supplied-pmid 33268781?><pub-id pub-id-type="pmid">31908831</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Martín-Fernández</surname><given-names>JA</given-names></name>, <name><surname>Barceló-Vidal</surname><given-names>C</given-names></name>, <name><surname>Pawlowsky-Glahn</surname><given-names>V</given-names></name>. <article-title>Dealing with zeros and missing values in compositional data sets using nonparametric imputation</article-title>. <source>Mathematical Geology</source>. <year>2003</year>;<volume>35</volume>(<issue>3</issue>):<fpage>253</fpage>–<lpage>278</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1023/A:1023866030544</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Fernandes</surname><given-names>AD</given-names></name>, <name><surname>Macklaim</surname><given-names>JM</given-names></name>, <name><surname>Linn</surname><given-names>TG</given-names></name>, <name><surname>Reid</surname><given-names>G</given-names></name>, <name><surname>Gloor</surname><given-names>GB</given-names></name>. <article-title>ANOVA-like differential expression (ALDEx) analysis for mixed population RNA-Seq</article-title>. <source>PloS one</source>. <year>2013</year>;<volume>8</volume>(<issue>7</issue>):<fpage>e67019</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0067019</pub-id><?supplied-pmid 23843979?><pub-id pub-id-type="pmid">23843979</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref024">
      <label>24</label>
      <mixed-citation publication-type="other">De La Cruz R, Kreft JU. Geometric mean extension for data sets with zeros; arXiv:1806.06403 [Preprint]. 2018. Available from: <ext-link xlink:href="https://arxiv.org/abs/1806.06403" ext-link-type="uri">https://arxiv.org/abs/1806.06403</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref025">
      <label>25</label>
      <mixed-citation publication-type="other">Park J, Yoon C, Park C, Ahn J. Kernel Methods for Radial Transformed Compositional Data with Many Zeros. In: International Conference on Machine Learning. PMLR; 2022. p. 17458–17472.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Pasolli</surname><given-names>E</given-names></name>, <name><surname>Truong</surname><given-names>DT</given-names></name>, <name><surname>Malik</surname><given-names>F</given-names></name>, <name><surname>Waldron</surname><given-names>L</given-names></name>, <name><surname>Segata</surname><given-names>N</given-names></name>. <article-title>Machine learning meta-analysis of large metagenomic datasets: tools and biological insights</article-title>. <source>PLoS computational biology</source>. <year>2016</year>;<volume>12</volume>(<issue>7</issue>):<fpage>e1004977</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004977</pub-id><?supplied-pmid 27400279?><pub-id pub-id-type="pmid">27400279</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Knight</surname><given-names>R</given-names></name>, <name><surname>Vrbanac</surname><given-names>A</given-names></name>, <name><surname>Taylor</surname><given-names>BC</given-names></name>, <name><surname>Aksenov</surname><given-names>A</given-names></name>, <name><surname>Callewaert</surname><given-names>C</given-names></name>, <name><surname>Debelius</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Best practices for analysing microbiomes</article-title>. <source>Nature Reviews Microbiology</source>. <year>2018</year>;<volume>16</volume>(<issue>7</issue>):<fpage>410</fpage>–<lpage>422</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41579-018-0029-9</pub-id><?supplied-pmid 29795328?><pub-id pub-id-type="pmid">29795328</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Zhou</surname><given-names>YH</given-names></name>, <name><surname>Gallins</surname><given-names>P</given-names></name>. <article-title>A review and tutorial of machine learning methods for microbiome host trait prediction</article-title>. <source>Frontiers in Genetics</source>. <year>2019</year>; p. <fpage>579</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fgene.2019.00579</pub-id><?supplied-pmid 31293616?><pub-id pub-id-type="pmid">31293616</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Cammarota</surname><given-names>G</given-names></name>, <name><surname>Ianiro</surname><given-names>G</given-names></name>, <name><surname>Ahern</surname><given-names>A</given-names></name>, <name><surname>Carbone</surname><given-names>C</given-names></name>, <name><surname>Temko</surname><given-names>A</given-names></name>, <name><surname>Claesson</surname><given-names>MJ</given-names></name>, <etal>et al</etal>. <article-title>Gut microbiome, big data and machine learning to promote precision medicine for cancer</article-title>. <source>Nature Reviews Gastroenterology &amp; Hepatology</source>. <year>2020</year>;<volume>17</volume>(<issue>10</issue>):<fpage>635</fpage>–<lpage>648</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41575-020-0327-3</pub-id><?supplied-pmid 32647386?><pub-id pub-id-type="pmid">32647386</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref030">
      <label>30</label>
      <mixed-citation publication-type="book"><name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Li</surname><given-names>H</given-names></name>. <part-title>Kernel methods for regression analysis of microbiome compositional data</part-title>. In: <source>Topics in Applied Statistics</source>. <publisher-name>Springer</publisher-name>; <year>2013</year>. p. <fpage>191</fpage>–<lpage>201</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Randolph</surname><given-names>TW</given-names></name>, <name><surname>Zhao</surname><given-names>S</given-names></name>, <name><surname>Copeland</surname><given-names>W</given-names></name>, <name><surname>Hullar</surname><given-names>M</given-names></name>, <name><surname>Shojaie</surname><given-names>A</given-names></name>. <article-title>Kernel-penalized regression for analysis of microbiome data</article-title>. <source>The Annals of Applied Statistics</source>. <year>2018</year>;<volume>12</volume>(<issue>1</issue>):<fpage>540</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1214/17-AOAS1102</pub-id><?supplied-pmid 30224943?><pub-id pub-id-type="pmid">30224943</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Ramon</surname><given-names>E</given-names></name>, <name><surname>Belanche-Muñoz</surname><given-names>L</given-names></name>, <name><surname>Molist</surname><given-names>F</given-names></name>, <name><surname>Quintanilla</surname><given-names>R</given-names></name>, <name><surname>Perez-Enciso</surname><given-names>M</given-names></name>, <name><surname>Ramayo-Caldas</surname><given-names>Y</given-names></name>. <article-title>kernInt: A Kernel Framework for Integrating Supervised and Unsupervised Analyses in Spatio-Temporal Metagenomic Datasets</article-title>. <source>Frontiers in Microbiology</source>. <year>2021</year>;<volume>12</volume>:<fpage>60</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3389/fmicb.2021.609048</pub-id><?supplied-pmid 33584612?><pub-id pub-id-type="pmid">33584612</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Di Marzio</surname><given-names>M</given-names></name>, <name><surname>Panzera</surname><given-names>A</given-names></name>, <name><surname>Venieri</surname><given-names>C</given-names></name>. <article-title>Non-parametric regression for compositional data</article-title>. <source>Statistical Modelling</source>. <year>2015</year>;<volume>15</volume>(<issue>2</issue>):<fpage>113</fpage>–<lpage>133</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1177/1471082X14535522</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref034">
      <label>34</label>
      <mixed-citation publication-type="other">Tsagris M, Athineou G. Compositional: Compositional Data Analysis; 2021. Available from: <ext-link xlink:href="https://CRAN.R-project.org/package=Compositional" ext-link-type="uri">https://CRAN.R-project.org/package=Compositional</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Zhao</surname><given-names>N</given-names></name>, <name><surname>Chen</surname><given-names>J</given-names></name>, <name><surname>Carroll</surname><given-names>IM</given-names></name>, <name><surname>Ringel-Kulka</surname><given-names>T</given-names></name>, <name><surname>Epstein</surname><given-names>MP</given-names></name>, <name><surname>Zhou</surname><given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Testing in microbiome-profiling studies with MiRKAT, the microbiome regression-based kernel association test</article-title>. <source>The American Journal of Human Genetics</source>. <year>2015</year>;<volume>96</volume>(<issue>5</issue>):<fpage>797</fpage>–<lpage>807</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ajhg.2015.04.003</pub-id><?supplied-pmid 25957468?><pub-id pub-id-type="pmid">25957468</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Wilson</surname><given-names>N</given-names></name>, <name><surname>Zhao</surname><given-names>N</given-names></name>, <name><surname>Zhan</surname><given-names>X</given-names></name>, <name><surname>Koh</surname><given-names>H</given-names></name>, <name><surname>Fu</surname><given-names>W</given-names></name>, <name><surname>Chen</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>MiRKAT: kernel machine regression-based global association tests for the microbiome</article-title>. <source>Bioinformatics</source>. <year>2021</year>;<volume>37</volume>(<issue>11</issue>):<fpage>1595</fpage>–<lpage>1597</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btaa951</pub-id><?supplied-pmid 33225342?><pub-id pub-id-type="pmid">33225342</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>C</given-names></name>, <name><surname>Callahan</surname><given-names>BJ</given-names></name>, <name><surname>Wu</surname><given-names>MC</given-names></name>, <name><surname>Holloway</surname><given-names>ST</given-names></name>, <name><surname>Brochu</surname><given-names>H</given-names></name>, <name><surname>Lu</surname><given-names>W</given-names></name>, <etal>et al</etal>. <article-title>Phylogeny-guided microbiome OTU-specific association test (POST)</article-title>. <source>Microbiome</source>. <year>2022</year>;<volume>10</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>15</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s40168-022-01266-3</pub-id><?supplied-pmid 35668471?><pub-id pub-id-type="pmid">34980280</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref038">
      <label>38</label>
      <mixed-citation publication-type="other">Li B, Ahn J. Reproducing Kernels and New Approaches in Compositional Data Analysis; arXiv:2205.01158 [Preprint]. 2022. Available from: <ext-link xlink:href="https://arxiv.org/abs/2205.01158" ext-link-type="uri">https://arxiv.org/abs/2205.01158</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref039">
      <label>39</label>
      <mixed-citation publication-type="book"><name><surname>Samek</surname><given-names>W</given-names></name>, <name><surname>Montavon</surname><given-names>G</given-names></name>, <name><surname>Vedaldi</surname><given-names>A</given-names></name>, <name><surname>Hansen</surname><given-names>LK</given-names></name>, <name><surname>Müller</surname><given-names>KR</given-names></name>. <source>Explainable AI: interpreting, explaining and visualizing deep learning</source>. vol. <volume>11700</volume>. <publisher-name>Springer Nature</publisher-name>; <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref040">
      <label>40</label>
      <mixed-citation publication-type="other">Molnar C. Interpretable machine learning. Lulu.com; 2020.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Topçuoğlu</surname><given-names>BD</given-names></name>, <name><surname>Lesniak</surname><given-names>NA</given-names></name>, <name><surname>Ruffin</surname><given-names>M</given-names><suffix>IV</suffix></name>, <name><surname>Wiens</surname><given-names>J</given-names></name>, <name><surname>Schloss</surname><given-names>PD</given-names></name>. <article-title>A framework for effective application of machine learning to microbiome-based classification problems</article-title>. <source>MBio</source>. <year>2020</year>;<volume>11</volume>(<issue>3</issue>):<fpage>e00434</fpage>–<lpage>20</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1128/mBio.00434-20</pub-id><?supplied-pmid 32518182?><pub-id pub-id-type="pmid">32518182</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref042">
      <label>42</label>
      <mixed-citation publication-type="journal"><name><surname>Gou</surname><given-names>W</given-names></name>, <name><surname>Ling</surname><given-names>CW</given-names></name>, <name><surname>He</surname><given-names>Y</given-names></name>, <name><surname>Jiang</surname><given-names>Z</given-names></name>, <name><surname>Fu</surname><given-names>Y</given-names></name>, <name><surname>Xu</surname><given-names>F</given-names></name>, <etal>et al</etal>. <article-title>Interpretable machine learning framework reveals robust gut microbiome features associated with type 2 diabetes</article-title>. <source>Diabetes Care</source>. <year>2021</year>;<volume>44</volume>(<issue>2</issue>):<fpage>358</fpage>–<lpage>366</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2337/dc20-1536</pub-id><?supplied-pmid 33288652?><pub-id pub-id-type="pmid">33288652</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Ruaud</surname><given-names>A</given-names></name>, <name><surname>Pfister</surname><given-names>N</given-names></name>, <name><surname>Ley</surname><given-names>RE</given-names></name>, <name><surname>Youngblut</surname><given-names>ND</given-names></name>. <article-title>Interpreting tree ensemble machine learning models with endoR</article-title>. <source>PLOS Computational Biology</source>. <year>2022</year>;<volume>18</volume>(<issue>12</issue>):<fpage>e1010714</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pcbi.1010714</pub-id><?supplied-pmid 36516158?><pub-id pub-id-type="pmid">36516158</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref044">
      <label>44</label>
      <mixed-citation publication-type="journal"><name><surname>Bien</surname><given-names>J</given-names></name>, <name><surname>Yan</surname><given-names>X</given-names></name>, <name><surname>Simpson</surname><given-names>L</given-names></name>, <name><surname>Müller</surname><given-names>CL</given-names></name>. <article-title>Tree-aggregated predictive modeling of microbiome data</article-title>. <source>Scientific Reports</source>. <year>2021</year>;<volume>11</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>13</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-021-93645-3</pub-id><?supplied-pmid 34267244?><pub-id pub-id-type="pmid">33414495</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref045">
      <label>45</label>
      <mixed-citation publication-type="journal"><name><surname>Friedman</surname><given-names>JH</given-names></name>. <article-title>Greedy function approximation: a gradient boosting machine</article-title>. <source>Annals of Statistics</source>. <year>2001</year>; p. <fpage>1189</fpage>–<lpage>1232</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref046">
      <label>46</label>
      <mixed-citation publication-type="journal"><name><surname>Morais</surname><given-names>J</given-names></name>, <name><surname>Thomas-Agnan</surname><given-names>C</given-names></name>. <article-title>Impact of covariates in compositional models and simplicial derivatives</article-title>. <source>Austrian Journal of Statistics</source>. <year>2021</year>;<volume>50</volume>(<issue>2</issue>):<fpage>1</fpage>–<lpage>15</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.17713/ajs.v50i2.1069</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref047">
      <label>47</label>
      <mixed-citation publication-type="book"><name><surname>Schölkopf</surname><given-names>B</given-names></name>, <name><surname>Smola</surname><given-names>AJ</given-names></name>, <name><surname>Bach</surname><given-names>F</given-names></name>. <source>Learning with kernels: support vector machines, regularization, optimization, and beyond</source>. <publisher-name>MIT press</publisher-name>; <year>2002</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref048">
      <label>48</label>
      <mixed-citation publication-type="journal"><name><surname>Sriperumbudur</surname><given-names>BK</given-names></name>, <name><surname>Fukumizu</surname><given-names>K</given-names></name>, <name><surname>Lanckriet</surname><given-names>G</given-names></name>. <article-title>Universality, Characteristic Kernels and RKHS Embedding of Measures</article-title>. <source>Journal of Machine Learning Research</source>. <year>2011</year>;<volume>12</volume>(<issue>7</issue>).</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref049">
      <label>49</label>
      <mixed-citation publication-type="other">Topsøe F. Jenson-Shannon divergence and norm-based measures of discrimination and variation; 2003. Available from: <ext-link xlink:href="https://web.math.ku.dk/~topsoe/sh.ps" ext-link-type="uri">https://web.math.ku.dk/~topsoe/sh.ps</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref050">
      <label>50</label>
      <mixed-citation publication-type="book"><name><surname>Hein</surname><given-names>M</given-names></name>, <name><surname>Bousquet</surname><given-names>O</given-names></name>. <part-title>Hilbertian metrics and positive definite kernels on probability measures</part-title>. In: <source>International Workshop on Artificial Intelligence and Statistics</source>. <publisher-name>PMLR</publisher-name>; <year>2005</year>. p. <fpage>136</fpage>–<lpage>143</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref051">
      <label>51</label>
      <mixed-citation publication-type="journal"><name><surname>Lafferty</surname><given-names>J</given-names></name>, <name><surname>Lebanon</surname><given-names>G</given-names></name>, <name><surname>Jaakkola</surname><given-names>T</given-names></name>. <article-title>Diffusion kernels on statistical manifolds</article-title>. <source>Journal of Machine Learning Research</source>. <year>2005</year>;<volume>6</volume>(<issue>1</issue>):<fpage>129</fpage>–<lpage>163</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref052">
      <label>52</label>
      <mixed-citation publication-type="journal"><name><surname>Lozupone</surname><given-names>C</given-names></name>, <name><surname>Knight</surname><given-names>R</given-names></name>. <article-title>UniFrac: a new phylogenetic method for comparing microbial communities</article-title>. <source>Applied and Environmental Microbiology</source>. <year>2005</year>;<volume>71</volume>(<issue>12</issue>):<fpage>8228</fpage>–<lpage>8235</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1128/AEM.71.12.8228-8235.2005</pub-id><?supplied-pmid 16332807?><pub-id pub-id-type="pmid">16332807</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref053">
      <label>53</label>
      <mixed-citation publication-type="journal"><name><surname>Leinster</surname><given-names>T</given-names></name>, <name><surname>Cobbold</surname><given-names>C</given-names></name>. <article-title>Measuring diversity: The importance of species similarity</article-title>. <source>Ecology</source>. <year>2012</year>;<volume>93</volume>:<fpage>477</fpage>–<lpage>89</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1890/10-2402.1</pub-id><?supplied-pmid 22624203?><pub-id pub-id-type="pmid">22624203</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref054">
      <label>54</label>
      <mixed-citation publication-type="journal"><name><surname>van Rossum</surname><given-names>G</given-names></name>, <name><surname>Drake</surname><given-names>FL</given-names></name>. <article-title>Python 3 Reference Manual</article-title>. <source>CreateSpace</source>; <year>2009</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref055">
      <label>55</label>
      <mixed-citation publication-type="journal"><name><surname>Bradbury</surname><given-names>J</given-names></name>, <name><surname>Frostig</surname><given-names>R</given-names></name>, <name><surname>Hawkins</surname><given-names>P</given-names></name>, <name><surname>Johnson</surname><given-names>MJ</given-names></name>, <name><surname>Leary</surname><given-names>C</given-names></name>, <name><surname>Maclaurin</surname><given-names>D</given-names></name>, <etal>et al</etal>. <source>JAX: composable transformations of Python+NumPy programs</source>; <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref056">
      <label>56</label>
      <mixed-citation publication-type="journal"><name><surname>Pedregosa</surname><given-names>F</given-names></name>, <name><surname>Varoquaux</surname><given-names>G</given-names></name>, <name><surname>Gramfort</surname><given-names>A</given-names></name>, <name><surname>Michel</surname><given-names>V</given-names></name>, <name><surname>Thirion</surname><given-names>B</given-names></name>, <name><surname>Grisel</surname><given-names>O</given-names></name>, <etal>et al</etal>. <article-title>Scikit-learn: Machine Learning in Python</article-title>. <source>Journal of Machine Learning Research</source>. <year>2011</year>;<volume>12</volume>:<fpage>2825</fpage>–<lpage>2830</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref057">
      <label>57</label>
      <mixed-citation publication-type="book"><name><surname>Wilcoxon</surname><given-names>F</given-names></name>. <source>Individual comparisons by ranking methods</source>. <publisher-name>Springer</publisher-name>; <year>1992</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref058">
      <label>58</label>
      <mixed-citation publication-type="journal"><name><surname>Qin</surname><given-names>N</given-names></name>, <name><surname>Yang</surname><given-names>F</given-names></name>, <name><surname>Li</surname><given-names>A</given-names></name>, <name><surname>Prifti</surname><given-names>E</given-names></name>, <name><surname>Chen</surname><given-names>Y</given-names></name>, <name><surname>Shao</surname><given-names>L</given-names></name>, <etal>et al</etal>. <article-title>Alterations of the human gut microbiome in liver cirrhosis</article-title>. <source>Nature</source>. <year>2014</year>;<volume>513</volume>(<issue>7516</issue>):<fpage>59</fpage>–<lpage>64</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/nature13568</pub-id><?supplied-pmid 25079328?><pub-id pub-id-type="pmid">25079328</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1011240.ref059">
      <label>59</label>
      <mixed-citation publication-type="journal"><name><surname>Ramirez</surname><given-names>KS</given-names></name>, <name><surname>Leff</surname><given-names>JW</given-names></name>, <name><surname>Barberán</surname><given-names>A</given-names></name>, <name><surname>Bates</surname><given-names>ST</given-names></name>, <name><surname>Betley</surname><given-names>J</given-names></name>, <name><surname>Crowther</surname><given-names>TW</given-names></name>, <etal>et al</etal>. <article-title>Biogeographic patterns in below-ground diversity in New York City’s Central Park are similar to those observed globally</article-title>. <source>Proceedings of the Royal Society B: Biological Sciences</source>. <year>2014</year>;<volume>281</volume>(<issue>1795</issue>):<fpage>20141988</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1098/rspb.2014.1988</pub-id><?supplied-pmid 25274366?><pub-id pub-id-type="pmid">25274366</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
<sub-article article-type="aggregated-review-documents" id="pcbi.1011240.r001" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240.r001</article-id>
    <title-group>
      <article-title>Decision Letter 0</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Patil</surname>
          <given-names>Kiran Raosaheb</given-names>
        </name>
        <role>Section Editor</role>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Coelho</surname>
          <given-names>Luis Pedro</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Patil, Coelho</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Patil, Coelho</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1011240" id="rel-obj001" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>0</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">29 Mar 2023</named-content>
    </p>
    <p>Dear Ms. Huang,</p>
    <p>Thank you very much for submitting your manuscript "Supervised learning and model analysis with compositional data" for consideration at PLOS Computational Biology.</p>
    <p>As with all papers reviewed by the journal, your manuscript was reviewed by members of the editorial board and by several independent reviewers. In light of the reviews (below this email), we would like to invite the resubmission of a significantly-revised version that takes into account the reviewers' comments.</p>
    <p>The reviewers both agree on the value of the study, an opinion we share, but request additional clarifications. We note that a common theme is both reviewers wish to see a clearer statement of how the proposed methods compared to others, which we agree is important. As an additional editorial request, we ask that the authors rework the figures to avoid the use of very small fonts (particularly Fig 1 [bottom right] and Fig 4).</p>
    <p>We cannot make any decision about publication until we have seen the revised manuscript and your response to the reviewers' comments. Your revised manuscript is also likely to be sent to reviewers for further evaluation.</p>
    <p>When you are ready to resubmit, please upload the following:</p>
    <p>[1] A letter containing a detailed list of your responses to the review comments and a description of the changes you have made in the manuscript. Please note while forming your response, if your article is accepted, you may have the opportunity to make the peer review history publicly available. The record will include editor decision letters (with reviews) and your responses to reviewer comments. If eligible, we will contact you to opt in or out.</p>
    <p>[2] Two versions of the revised manuscript: one with either highlights or tracked changes denoting where the text has been changed; the other a clean version (uploaded as the manuscript file).</p>
    <p>Important additional instructions are given below your reviewer comments.</p>
    <p>Please prepare and submit your revised manuscript within 60 days. If you anticipate any delay, please let us know the expected resubmission date by replying to this email. Please note that revised manuscripts received after the 60-day due date may require evaluation and peer review similar to newly submitted manuscripts.</p>
    <p>Thank you again for your submission. We hope that our editorial process has been constructive so far, and we welcome your feedback at any time. Please don't hesitate to contact us if you have any questions or comments.</p>
    <p>Sincerely,</p>
    <p>Luis Pedro Coelho</p>
    <p>Academic Editor</p>
    <p>PLOS Computational Biology</p>
    <p>Kiran Patil</p>
    <p>Section Editor</p>
    <p>PLOS Computational Biology</p>
    <p>***********************</p>
    <p>The reviewers both agree on the value of the study, an opinion we share, but request additional clarifications. We note that a common theme is both reviewers wish to see a clearer statement of how the proposed methods compared to others, which we agree is important. As an additional editorial request, we ask that the authors rework the figures to avoid the use of very small fonts (particularly Fig 1 [bottom right] and Fig 4).</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <bold>Comments to the Authors:</bold>
    </p>
    <p>
      <bold>Please note here if the review is uploaded as an attachment.</bold>
    </p>
    <p>Reviewer #1: The manuscript by Shimeng Huang et al. proposes KernelBiome, a kernel-based nonparametric regression and classification framework for compositional data. The method is specifically developed to deal with sparse compositional data and can incorporate prior knowledge in terms of phylogenetic structure. The algorithm is validated experimentally on 33 publicly available microbiome datasets and compared with state-of-the-art solutions. The code is available as an open-source python package.</p>
    <p>The topic involved in the paper is suitable for publication in PLOS Computational Biology.</p>
    <p>I find the methodological solution quite interesting. It is described in detail in both the main paper and the Supplementary Material. I have more comments about the experimental validation of the proposed solution:</p>
    <p>1. As a general comment, the manuscript has a quite extensive supplementary material in terms of Appendix, while the main text is more limited, especially in terms of main Figures. I feel that some of the more important results/figures may be moved from the supplementary to the main text.</p>
    <p>2. Following the previous point, the comparison among different classifiers is summarized in Figure 3 for only a fraction of the considered datasets (8 among 33 if I understand correctly). I think it would be important to have a figure here that summarizes the results for all considered datasets.</p>
    <p>3. Despite the extensive validation, I still don't get to which extent the proposed solution outperforms the existing ones. For example, in how many cases/datasets the proposed method outperforms the other ones? Can you suggest (or not) your solution based on some data characteristics?</p>
    <p>4. Could you add a statistical test to evaluate if differences in terms of accuracies are statistically significant?</p>
    <p>5. I find interesting that the method can deal with prior information. Which is the added value of this information in terms of classification accuracies? I think it would be relevant performing a comparison in this direction (i.e., comparing results by incorporating or not the prior information).</p>
    <p>6. It is not very clear to me which are the free parameters that should be set for the proposed solution. In case, a sensitivity analysis to them should be performed.</p>
    <p>7. What in terms of computational complexity of the proposed solution with respect to the compared ones? Please add some empirical evaluations.</p>
    <p>Reviewer #2: In this manuscript, Huang et al., propose a kernel-based nonparametric regression and classification framework to address the challenges of compositionality and sparsity in analyzing compositional data. The authors compared the proposed framework with existing methods on publicly available microbiome datasets. Overall, I found the paper to be well-written and well-organized. I have some comments for the authors.</p>
    <p>1. Accuracy and MSE are applied in the classification and regression tasks, respectively. In classification tasks with unbalanced data, I don't think accuracy and AUROC are appropriate metrics. Therefore, I am highly concerned with the performance presented in the manuscript. Moreover, MSE and RMSE are both commonly used metrics for evaluating the performance of regression models. MSE is in square units of the target variable, which can make it difficult to interpret the results.</p>
    <p>2. Line 357; Please consider add more details on the baseline.</p>
    <p>3. Line 373-375: The authors claimed that "On all datasets KernelBiome achieves the best or close to best performance, indicating that the proposed procedure is well-adapted to microbiome data." However, this is not true at all when you look at Figure 6. In some case, the performance of KernelBiome is almost the worst.</p>
    <p>**********</p>
    <p>
      <bold>Have the authors made all data and (if applicable) computational code underlying the findings in their manuscript fully available?</bold>
    </p>
    <p>The <ext-link xlink:href="https://journals.plos.org/ploscompbiol/s/materials-and-software-sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data and code underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data and code should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data or code —e.g. participant privacy or use of data from a third party—those must be specified.</p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p>PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/ploscompbiol/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.</p>
    <p>Reviewer #1: No</p>
    <p>Reviewer #2: No</p>
    <p>
      <underline>Figure Files:</underline>
    </p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <underline><ext-link xlink:href="https://pacev2.apexcovantage.com/" ext-link-type="uri">https://pacev2.apexcovantage.com</ext-link></underline>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email us at <underline><email>figures@plos.org</email></underline>.</p>
    <p>
      <underline>Data Requirements:</underline>
    </p>
    <p>Please note that, as a condition of publication, PLOS' data policy requires that you make available all data used to draw the conclusions outlined in your manuscript. Data must be deposited in an appropriate repository, included within the body of the manuscript, or uploaded as supporting information. This includes all numerical values that were used to generate graphs, histograms etc.. For an example in PLOS Biology see here: <ext-link xlink:href="http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5" ext-link-type="uri">http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5</ext-link>.</p>
    <p>
      <underline>Reproducibility:</underline>
    </p>
    <p>To enhance the reproducibility of your results, we recommend that you deposit your laboratory protocols in protocols.io, where a protocol can be assigned its own identifier (DOI) such that it can be cited independently in the future. Additionally, PLOS ONE offers an option to publish peer-reviewed clinical study protocols. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link></p>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pcbi.1011240.r002">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240.r002</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 0</article-title>
    </title-group>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1011240" id="rel-obj002" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">27 Apr 2023</named-content>
    </p>
    <supplementary-material id="pcbi.1011240.s008" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">response_to_reviewers.pdf</named-content></p>
      </caption>
      <media xlink:href="pcbi.1011240.s008.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="aggregated-review-documents" id="pcbi.1011240.r003" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240.r003</article-id>
    <title-group>
      <article-title>Decision Letter 1</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Patil</surname>
          <given-names>Kiran Raosaheb</given-names>
        </name>
        <role>Section Editor</role>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Coelho</surname>
          <given-names>Luis Pedro</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Patil, Coelho</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Patil, Coelho</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1011240" id="rel-obj003" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>1</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">24 May 2023</named-content>
    </p>
    <p>Dear Dr. Huang,</p>
    <p>Thank you very much for submitting your manuscript "Supervised learning and model analysis with compositional data" for consideration at PLOS Computational Biology. As with all papers reviewed by the journal, your manuscript was reviewed by members of the editorial board and by several independent reviewers. The reviewers appreciated the attention to an important topic. Based on the reviews, we are likely to accept this manuscript for publication, providing that you modify the manuscript according to the review recommendations.</p>
    <p>All scientific questions have been address. We agree with reviewer #2 that adding the p-value to the figures is best practices.</p>
    <p>Please prepare and submit your revised manuscript within 30 days. If you anticipate any delay, please let us know the expected resubmission date by replying to this email.</p>
    <p>When you are ready to resubmit, please upload the following:</p>
    <p>[1] A letter containing a detailed list of your responses to all review comments, and a description of the changes you have made in the manuscript. Please note while forming your response, if your article is accepted, you may have the opportunity to make the peer review history publicly available. The record will include editor decision letters (with reviews) and your responses to reviewer comments. If eligible, we will contact you to opt in or out</p>
    <p>[2] Two versions of the revised manuscript: one with either highlights or tracked changes denoting where the text has been changed; the other a clean version (uploaded as the manuscript file).</p>
    <p>Important additional instructions are given below your reviewer comments.</p>
    <p>Thank you again for your submission to our journal. We hope that our editorial process has been constructive so far, and we welcome your feedback at any time. Please don't hesitate to contact us if you have any questions or comments.</p>
    <p>Sincerely,</p>
    <p>Luis Pedro Coelho</p>
    <p>Academic Editor</p>
    <p>PLOS Computational Biology</p>
    <p>Kiran Patil</p>
    <p>Section Editor</p>
    <p>PLOS Computational Biology</p>
    <p>***********************</p>
    <p>A link appears below if there are any accompanying review attachments. If you believe any reviews to be missing, please contact <email>ploscompbiol@plos.org</email> immediately:</p>
    <p>All scientific questions have been address. We agree with reviewer #2 that adding the p-value to the figures is best practices.</p>
    <p>Reviewer's Responses to Questions</p>
    <p>
      <bold>Comments to the Authors:</bold>
    </p>
    <p>
      <bold>Please note here if the review is uploaded as an attachment.</bold>
    </p>
    <p>Reviewer #1: I feel the authors have answered positively to my previous comments and modified the manuscript according to them.</p>
    <p>Reviewer #2: All my comments have been adequately addressed. On another note, the statistical P value should present with all the figures when comparing different methods. By including P-values, readers can better assess the significance of the findings and make informed interpretations.</p>
    <p>**********</p>
    <p>
      <bold>Have the authors made all data and (if applicable) computational code underlying the findings in their manuscript fully available?</bold>
    </p>
    <p>The <ext-link xlink:href="https://journals.plos.org/ploscompbiol/s/materials-and-software-sharing" ext-link-type="uri">PLOS Data policy</ext-link> requires authors to make all data and code underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data and code should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data or code —e.g. participant privacy or use of data from a third party—those must be specified.</p>
    <p>Reviewer #1: Yes</p>
    <p>Reviewer #2: Yes</p>
    <p>**********</p>
    <p>PLOS authors have the option to publish the peer review history of their article (<ext-link xlink:href="https://journals.plos.org/ploscompbiol/s/editorial-and-peer-review-process#loc-peer-review-history" ext-link-type="uri">what does this mean?</ext-link>). If published, this will include your full peer review and any attached files.</p>
    <p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
    <p><bold>Do you want your identity to be public for this peer review?</bold> For information about this choice, including consent withdrawal, please see our <ext-link xlink:href="https://www.plos.org/privacy-policy" ext-link-type="uri">Privacy Policy</ext-link>.</p>
    <p>Reviewer #1: No</p>
    <p>Reviewer #2: No</p>
    <p>Figure Files:</p>
    <p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <ext-link xlink:href="https://pacev2.apexcovantage.com" ext-link-type="uri">https://pacev2.apexcovantage.com</ext-link>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email us at <email>figures@plos.org</email>.</p>
    <p>Data Requirements:</p>
    <p>Please note that, as a condition of publication, PLOS' data policy requires that you make available all data used to draw the conclusions outlined in your manuscript. Data must be deposited in an appropriate repository, included within the body of the manuscript, or uploaded as supporting information. This includes all numerical values that were used to generate graphs, histograms etc.. For an example in PLOS Biology see here: <ext-link xlink:href="http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5" ext-link-type="uri">http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001908#s5</ext-link>.</p>
    <p>Reproducibility:</p>
    <p>To enhance the reproducibility of your results, we recommend that you deposit your laboratory protocols in protocols.io, where a protocol can be assigned its own identifier (DOI) such that it can be cited independently in the future. Additionally, PLOS ONE offers an option to publish peer-reviewed clinical study protocols. Read more information on sharing protocols at <ext-link xlink:href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" ext-link-type="uri">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</ext-link></p>
    <p>References:</p>
    <p>Review your reference list to ensure that it is complete and correct. If you have cited papers that have been retracted, please include the rationale for doing so in the manuscript text, or remove these references and replace them with relevant current references. Any changes to the reference list should be mentioned in the rebuttal letter that accompanies your revised manuscript.</p>
    <p>
      <italic toggle="yes">If you need to cite a retracted article, indicate the article’s retracted status in the References list and also include a citation and full reference for the retraction notice.</italic>
    </p>
  </body>
</sub-article>
<sub-article article-type="author-comment" id="pcbi.1011240.r004">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240.r004</article-id>
    <title-group>
      <article-title>Author response to Decision Letter 1</article-title>
    </title-group>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1011240" id="rel-obj004" related-article-type="editor-report"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>2</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="author-response-date">27 May 2023</named-content>
    </p>
    <supplementary-material id="pcbi.1011240.s009" position="float" content-type="local-data">
      <label>Attachment</label>
      <caption>
        <p>Submitted filename: <named-content content-type="submitted-filename">point_by_point_response.pdf</named-content></p>
      </caption>
      <media xlink:href="pcbi.1011240.s009.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pcbi.1011240.r005" specific-use="decision-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240.r005</article-id>
    <title-group>
      <article-title>Decision Letter 2</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Patil</surname>
          <given-names>Kiran Raosaheb</given-names>
        </name>
        <role>Section Editor</role>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Coelho</surname>
          <given-names>Luis Pedro</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Patil, Coelho</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Patil, Coelho</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1011240" id="rel-obj005" related-article-type="reviewed-article"/>
    <custom-meta-group>
      <custom-meta>
        <meta-name>Submission Version</meta-name>
        <meta-value>2</meta-value>
      </custom-meta>
    </custom-meta-group>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">3 Jun 2023</named-content>
    </p>
    <p>Dear Dr. Huang,</p>
    <p>We are pleased to inform you that your manuscript 'Supervised learning and model analysis with compositional data' has been provisionally accepted for publication in PLOS Computational Biology.</p>
    <p>Before your manuscript can be formally accepted you will need to complete some formatting changes, which you will receive in a follow up email. A member of our team will be in touch with a set of requests.</p>
    <p>Please note that your manuscript will not be scheduled for publication until you have made the required changes, so a swift response is appreciated.</p>
    <p>IMPORTANT: The editorial review process is now complete. PLOS will only permit corrections to spelling, formatting or significant scientific errors from this point onwards. Requests for major changes, or any which affect the scientific understanding of your work, will cause delays to the publication date of your manuscript.</p>
    <p>Should you, your institution's press office or the journal office choose to press release your paper, you will automatically be opted out of early publication. We ask that you notify us now if you or your institution is planning to press release the article. All press must be co-ordinated with PLOS.</p>
    <p>Thank you again for supporting Open Access publishing; we are looking forward to publishing your work in PLOS Computational Biology. </p>
    <p>Best regards,</p>
    <p>Luis Pedro Coelho</p>
    <p>Academic Editor</p>
    <p>PLOS Computational Biology</p>
    <p>Kiran Patil</p>
    <p>Section Editor</p>
    <p>PLOS Computational Biology</p>
    <p>***********************************************************</p>
  </body>
</sub-article>
<sub-article article-type="editor-report" id="pcbi.1011240.r006" specific-use="acceptance-letter">
  <front-stub>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1011240.r006</article-id>
    <title-group>
      <article-title>Acceptance letter</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Patil</surname>
          <given-names>Kiran Raosaheb</given-names>
        </name>
        <role>Section Editor</role>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Coelho</surname>
          <given-names>Luis Pedro</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <permissions>
      <copyright-statement>© 2023 Patil, Coelho</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Patil, Coelho</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <related-article ext-link-type="doi" xlink:href="10.1371/journal.pcbi.1011240" id="rel-obj006" related-article-type="reviewed-article"/>
  </front-stub>
  <body>
    <p>
      <named-content content-type="letter-date">27 Jun 2023</named-content>
    </p>
    <p>PCOMPBIOL-D-23-00094R2 </p>
    <p>Supervised learning and model analysis with compositional data</p>
    <p>Dear Dr Huang,</p>
    <p>I am pleased to inform you that your manuscript has been formally accepted for publication in PLOS Computational Biology. Your manuscript is now with our production department and you will be notified of the publication date in due course.</p>
    <p>The corresponding author will soon be receiving a typeset proof for review, to ensure errors have not been introduced during production. Please review the PDF proof of your manuscript carefully, as this is the last chance to correct any errors. Please note that major changes, or those which affect the scientific understanding of the work, will likely cause delays to the publication date of your manuscript. </p>
    <p>Soon after your final files are uploaded, unless you have opted out, the early version of your manuscript will be published online. The date of the early version will be your article's publication date. The final article will be published to the same URL, and all versions of the paper will be accessible to readers.</p>
    <p>Thank you again for supporting PLOS Computational Biology and open-access publishing. We are looking forward to publishing your work! </p>
    <p>With kind regards,</p>
    <p>Zsuzsanna Gémesi</p>
    <p>PLOS Computational Biology | Carlyle House, Carlyle Road, Cambridge CB4 3DN | United Kingdom <email>ploscompbiol@plos.org</email> | Phone +44 (0) 1223-442824 | <ext-link xlink:href="http://ploscompbiol.org" ext-link-type="uri">ploscompbiol.org</ext-link> | @PLOSCompBiol</p>
  </body>
</sub-article>
