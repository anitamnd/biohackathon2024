<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6612824</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btz337</article-id>
    <article-id pub-id-type="publisher-id">btz337</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Ismb/Eccb 2019 Conference Proceedings</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Macromolecular Sequence, Structure, and Function</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Prediction of mRNA subcellular localization using deep recurrent neural networks</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Yan</surname>
          <given-names>Zichao</given-names>
        </name>
        <xref ref-type="aff" rid="btz337-aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Lécuyer</surname>
          <given-names>Eric</given-names>
        </name>
        <xref ref-type="aff" rid="btz337-aff2">2</xref>
        <xref ref-type="aff" rid="btz337-aff3">3</xref>
        <xref ref-type="aff" rid="btz337-aff4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Blanchette</surname>
          <given-names>Mathieu</given-names>
        </name>
        <xref ref-type="aff" rid="btz337-aff1">1</xref>
        <xref ref-type="corresp" rid="btz337-cor1"/>
        <!--<email>blanchem@cs.mcgill.ca</email>-->
      </contrib>
    </contrib-group>
    <aff id="btz337-aff1"><label>1</label>School of Computer Science, McGill University, Montreal, QC, Canada</aff>
    <aff id="btz337-aff2"><label>2</label>Department of Biochemistry, University of Montreal, Montreal, QC, Canada</aff>
    <aff id="btz337-aff3"><label>3</label>Institut de Recherches Clinique de Montréal (IRCM), Montreal, QC, Canada</aff>
    <aff id="btz337-aff4"><label>4</label>Division of Experimental Medicine, McGill University, Montreal, QC, Canada</aff>
    <author-notes>
      <corresp id="btz337-cor1">To whom correspondence should be addressed. <email>blanchem@cs.mcgill.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-07-05">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>35</volume>
    <issue>14</issue>
    <fpage>i333</fpage>
    <lpage>i342</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btz337.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Messenger RNA subcellular localization mechanisms play a crucial role in post-transcriptional gene regulation. This trafficking is mediated by <italic>trans</italic>-acting RNA-binding proteins interacting with <italic>cis</italic>-regulatory elements called zipcodes. While new sequencing-based technologies allow the high-throughput identification of RNAs localized to specific subcellular compartments, the precise mechanisms at play, and their dependency on specific sequence elements, remain poorly understood.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We introduce RNATracker, a novel deep neural network built to predict, from their sequence alone, the distributions of mRNA transcripts over a predefined set of subcellular compartments. RNATracker integrates several state-of-the-art deep learning techniques (e.g. CNN, LSTM and attention layers) and can make use of both sequence and secondary structure information. We report on a variety of evaluations showing RNATracker’s strong predictive power, which is significantly superior to a variety of baseline predictors. Despite its complexity, several aspects of the model can be isolated to yield valuable, testable mechanistic hypotheses, and to locate candidate zipcode sequences within transcripts.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>Code and data can be accessed at <ext-link ext-link-type="uri" xlink:href="https://www.github.com/HarveyYan/RNATracker">https://www.github.com/HarveyYan/RNATracker</ext-link>.</p>
      </sec>
      <sec id="s4">
        <title>Supplementary information</title>
        <p><xref ref-type="supplementary-material" rid="sup1">Supplementary data</xref> are available at <italic>Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Institut de Valorisation des Données</named-content>
        </funding-source>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="10"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>RNA subcellular localization constitutes a key but underappreciated aspect of gene regulation (<xref rid="btz337-B9" ref-type="bibr">Chin and Lecuyer, 2017</xref>). Once transcribed, capped, spliced, polyadenylated, mRNA can be shuttled to different parts of the nucleus, or exported to the cytoplasm, where it can further be transported to specific sites, or even excreted in extracellular vesicles (<xref ref-type="fig" rid="btz337-F1">Fig. 1</xref>). In the case of messenger RNA (mRNA), subcellular localization can control how much will be available for translation by ribosomes and where translation will occur, thereby allowing both a quantitative and spatial control over protein production. In particular, this mechanism represents an economical mean of protein localization, by transporting the messenger to the site where the protein is needed and performing on-site translation. While the importance of RNA subcellular localization is best characterized in embryonic development (<xref rid="btz337-B29" ref-type="bibr">Lécuyer <italic>et al.</italic>, 2007</xref>) and neuronal dendrites (<xref rid="btz337-B8" ref-type="bibr">Bramham and Wells, 2007</xref>), it is also highly prevalent in other cell types, with more than 80% of human transcripts showing asymmetrical localization in human and insect-cultured cells (<xref rid="btz337-B5" ref-type="bibr">Benoit Bouvrette <italic>et al.</italic>, 2018</xref>). Defective RNA trafficking, due to mutations either in the <italic>cis</italic>- or <italic>trans</italic>-acting molecules, are linked to a number of muscular and neurodegenerative diseases, as well as cancer (<xref rid="btz337-B13" ref-type="bibr">Cooper <italic>et al.</italic>, 2009</xref>). Improving our understanding of the mechanisms of mRNA localization, and its dependency on transcript sequence or structure, is thus important for the fundamental understanding of molecular biology and has profound biomedical implications.
</p>
    <fig id="btz337-F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <p>Schematic representation of RNA trafficking mechanisms and outcomes in eukaryotes </p>
      </caption>
      <graphic xlink:href="btz337f1"/>
    </fig>
    <p>The RNA trafficking process is mainly driven by a diverse population of <italic>trans</italic>-regulatory factors called RNA-binding proteins (RBPs) (<xref rid="btz337-B16" ref-type="bibr">Dominguez <italic>et al.</italic>, 2018</xref>; <xref rid="btz337-B18" ref-type="bibr">Ferrè <italic>et al.</italic>, 2016</xref>; <xref rid="btz337-B19" ref-type="bibr">Gerstberger <italic>et al.</italic>, 2014</xref>; <xref rid="btz337-B38" ref-type="bibr">Ray <italic>et al.</italic>, 2013</xref>), which stochastically, cooperatively and dynamically bind to specific RNA sequence/structure patterns. While nonspecific protein–RNA interactions are common and help stabilize mRNAs, sequence-specific binding to short sequence/structure patterns allows transcript-specific regulation (<xref rid="btz337-B6" ref-type="bibr">Bergalet and Lécuyer, 2014</xref>). Indeed, sequence motifs have been mapped for a large set of RBPs (<xref rid="btz337-B11" ref-type="bibr">Cook <italic>et al.</italic>, 2011</xref>; <xref rid="btz337-B33" ref-type="bibr">Liu <italic>et al.</italic>, 2017</xref>). mRNA localization <italic>cis</italic>-regulatory elements (also known as zipcodes) are short (20–200 nt) RNA regions that harbor binding sites for one or more RBP that help mediate the transport mRNAs to their intended destination, either actively along the cytoskeleton, diffusion or compartment-specific degradation. Although the number of well-characterized zipcodes remains very limited (only about a dozen in human), most are observed to be located in the 3′ UTR (but many exceptions exist) <xref rid="btz337-B6" ref-type="bibr">Bergalet and Lécuyer (2014)</xref>.</p>
    <p>While the importance and prevalence of mRNA subcellular localization has been known for a long time based on experiments such as fluorescent <italic>in-situ</italic> hybridization (FISH) (<xref rid="btz337-B29" ref-type="bibr">Lécuyer <italic>et al</italic>. 2007</xref>), it is only more recently that high-throughput sequencing-based assays emerged. APEX-RIP is a technique that takes advantage of protein proximity-based biotinylation, mediated by a compartment-specific APEX2 fusion protein, to identify localized transcriptomes (<xref rid="btz337-B26" ref-type="bibr">Kaewsapsak <italic>et al.</italic>, 2017</xref>). The organelle-localized APEX2 fusion protein will biotinylate proximal interacting proteins and, following crosslinking and streptavidin pull-down, co-localizing mRNAs can be identified by deep sequencing. This technology was recently used to map the transcriptome of the nucleus, cytoplasm, endoplasmic reticulum (ER) and mitochondria. CeFra-seq is an alternate technology relying on biochemical separation of subcellular components, followed by RNA-seq (<xref rid="btz337-B5" ref-type="bibr">Benoit Bouvrette <italic>et al.</italic>, 2018</xref>; <xref rid="btz337-B30" ref-type="bibr">Lefebvre <italic>et al.</italic>, 2017</xref>). It was used to map transcript abundance in the nucleus and cytosol, as well as those associated to endomembranes (ER, Golgi, etc.) and those left in the insoluble fraction, consisting of mRNAs associated to cytoskeletal and mitotic apparatus-associated proteins. Both technologies yield reproducible assessments of relative mRNA abundance in the subcellular component they probe and demonstrate the breadth of localization patterns observed in a variety of human cell types.</p>
    <p>In this paper, we aim to build a predictive model of mRNA localization that will quantitatively determine the relative expression of a given transcript among a predetermined set of cellular compartments, based only on sequence information. Such a model is essential to generate testable mechanistic hypotheses about the <italic>cis</italic>- and <italic>trans</italic>-regulatory molecules at hand and predict the impact of mutations on this key step of gene regulation.</p>
    <p>The computational identification of functional regulatory elements within biological sequences is one of the key problems addressed by bioinformatics approaches. Recently, new types of machine learning approaches emerged for sequence function prediction. Those are based on deep neural networks, and often combined convolutional (<xref rid="btz337-B28" ref-type="bibr">LeCun <italic>et al.</italic>, 1989</xref>) and recurrent neural networks [e.g. long short-term memory (LSTM) (<xref rid="btz337-B24" ref-type="bibr">Hochreiter and Schmidhuber, 1997</xref>)]. These approaches were shown to be highly effective at deciphering complex regulatory mechanisms, such as alternative splicing (<xref rid="btz337-B31" ref-type="bibr">Leung <italic>et al.</italic>, 2014</xref>), transcriptional regulation (<xref rid="btz337-B2" ref-type="bibr">Alipanahi <italic>et al.</italic>, 2015</xref>; <xref rid="btz337-B37" ref-type="bibr">Quang and Xie, 2016</xref>; <xref rid="btz337-B44" ref-type="bibr">Zhou and Troyanskaya, 2015</xref>), RBP binding (<xref rid="btz337-B32" ref-type="bibr">Li <italic>et al.</italic>, 2017</xref>; <xref rid="btz337-B35" ref-type="bibr">Pan and Shen, 2017</xref>) and RNA polyadenylation (<xref rid="btz337-B15" ref-type="bibr">Delong <italic>et al.</italic>, 2018</xref>). In those approaches, feature extraction and learning are combined in an end-to-end fashion that often yields better performance compared to conventional feature engineering approaches. The advantage of CNNs lies in their capability of performing automatic and parallel feature extraction by learning parameterized sequence motifs analogous to the position weight matrices (PWM) commonly used in classical sequence analysis algorithms. LSTMs, on the other hand, are more suitable for analyzing sequential data to discover correlations between different positions, allowing to capture sequence context and cooperative binding.</p>
    <p>To our knowledge, no computational predictor of mRNA subcellular localization exists to date. This is the challenge we tackle in this paper. We introduce, evaluate and interpret RNATracker, a deep neural network predictor of subcellular localization combining two convolutional layers, a bidirectional LSTM layer and an attention module. Although the architecture of our model has some similarities with previously proposed approaches (<xref rid="btz337-B32" ref-type="bibr">Li <italic>et al.</italic>, 2017</xref>; <xref rid="btz337-B35" ref-type="bibr">Pan and Shen, 2017</xref>; <xref rid="btz337-B37" ref-type="bibr">Quang and Xie, 2016</xref>), mRNA subcellular localization differs from most previous applications of deep learning to biological sequence function prediction in several aspects that make it particularly challenging. First, the process of subcellular localization is a long chain of complex events mediated by a large number of protein–RNA and RNA–RNA interactions, and may depend on both primary sequence and secondary structure. Second, our goal is to learn a multi-output function that predicts the expression distribution of a given transcript across several cellular fractions, instead of a single positive/negative label. Third, most mRNAs exhibit only a moderate degree of subcellular asymmetry, and experimental measurements are somewhat noisy and potentially biased. Finally, transcripts have greatly variable lengths, an issue generally not encountered in previous applications.</p>
    <p>In this paper, we introduce the RNATracker model and demonstrate its superior ability to predict subcellular localization on two recently published datasets obtained by CeFra-seq (<xref rid="btz337-B5" ref-type="bibr">Benoit Bouvrette <italic>et al.</italic>, 2018</xref>) and APEX-RIP (<xref rid="btz337-B26" ref-type="bibr">Kaewsapsak <italic>et al.</italic>, 2017</xref>). We then dissect the trained models to learn new biology about the mechanisms involved. Finally, we use a sliding window masking strategy to identify the regions most likely to be conferring the observed localization pattern, and present evidence in support of the regulatory function of those regions.</p>
  </sec>
  <sec>
    <title>2 Materials and Methods</title>
    <p>The goal of RNATracker is to predict an mRNA’s subcellular localization profile from its sequence alone (including possibly its secondary structure inferred from the sequence). To this end, we designed a convolutional bidirectional LSTM neural network with attention mechanism, inspired from previous work on the prediction of protein–mRNA interactions (<xref rid="btz337-B2" ref-type="bibr">Alipanahi <italic>et al.</italic>, 2015</xref>; <xref rid="btz337-B32" ref-type="bibr">Li <italic>et al.</italic>, 2017</xref>; <xref rid="btz337-B35" ref-type="bibr">Pan and Shen, 2017</xref>) and DNA function (<xref rid="btz337-B37" ref-type="bibr">Quang and Xie, 2016</xref>). Here, we introduce the methodological aspects of training data, feature encoding, model architecture, training and evaluation.</p>
    <sec>
      <title>2.1 Subcellular localization data</title>
      <p>mRNA subcellular localization data were obtained from CeFra-Seq (<xref rid="btz337-B5" ref-type="bibr">Benoit Bouvrette <italic>et al.</italic>, 2018</xref>) and APEX-RIP (<xref rid="btz337-B26" ref-type="bibr">Kaewsapsak <italic>et al.</italic>, 2017</xref>) experimental data, in the form of normalized expression values (FPKM) for each annotated human protein-coding gene. The first dataset covers four subcellular fractions (<inline-formula id="IE1"><mml:math id="IM1"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mtext>cytosol</mml:mtext><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mtext>nuclear</mml:mtext><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mtext>membranes</mml:mtext><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mtext>insoluble</mml:mtext><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>), whereas the second one identified transcripts enriched in a different set of compartments (<inline-formula id="IE2"><mml:math id="IM2"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mo>=</mml:mo></mml:mrow></mml:math></inline-formula> {ER, mitochondrial, cytosol, nuclear}). Although FPKM normalization can sometimes distort relative expression values across samples, this was not a major concerned here because most genes had similar expression across fractions.</p>
      <p>We averaged replicates and excluded genes with low total expression, keeping only those whose total FPKM expression across all fractions exceeds 1. This resulted in a set of 11 373 localization-annotated transcripts in the CeFra-Seq dataset and 13 860 in the APEX-RIP dataset. Let <italic>e</italic>(<italic>g</italic>, <italic>f</italic>) denote the expression level of gene <italic>g</italic> in fraction <inline-formula id="IE3"><mml:math id="IM3"><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">F</mml:mi></mml:mrow></mml:math></inline-formula>, expressed in FPKM. The normalized localization value for gene <italic>g</italic> in fraction <inline-formula id="IE4"><mml:math id="IM4"><mml:mrow><mml:mi>f</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">F</mml:mi></mml:mrow></mml:math></inline-formula> was defined as <inline-formula id="IE5"><mml:math id="IM5"><mml:mrow><mml:mi mathvariant="italic">loc</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>′</mml:mo><mml:mo>∈</mml:mo><mml:mi mathvariant="script">F</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>′</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>, which measures the relative abundance of <italic>g</italic> in each fraction.</p>
    </sec>
    <sec>
      <title>2.2 Sequences and RNA secondary structure</title>
      <p>mRNA sequences were downloaded from the Ensembl database (<xref rid="btz337-B1" ref-type="bibr">Aken <italic>et al.</italic>, 2017</xref>), keeping only the longest protein-coding isoform. We inferred RNA secondary structure information for each transcript using RNAplfold (<xref rid="btz337-B7" ref-type="bibr">Bernhart <italic>et al.</italic>, 2006</xref>) (window size = 150, span = 100). The output of RNAplfold, which is a list of base pairing probabilities, are converted to an intermediate dot-bracket annotation by greedily creating as many nested basepairs as possible. The resulting predicted structure was parsed using the forgi library (<xref rid="btz337-B27" ref-type="bibr">Kerpedjiev <italic>et al.</italic>, 2015</xref>), part of the Vienna RNA package (<xref rid="btz337-B34" ref-type="bibr">Lorenz <italic>et al.</italic>, 2011</xref>), to annotate each position as belonging to an internal loop (I), hairpin loop (H), multiloop (M), dangling start (F), dangling end (T) or stem (S).</p>
    </sec>
    <sec>
      <title>2.3 Feature encoding</title>
      <p>RNA nucleotides are represented using 1-hot encoding over 4 bits. When RNA secondary structure is considered, a 6-bit encoding of the structural state is used, or a 24-bit encoding of the joint representation of sequence and structural states.</p>
      <p>Input sequence length varies from ∼200 nt to more than 30 000 nt. RNATracker can either operate on individual input sequence of arbitrary lengths, or on fixed length inputs, the latter allowing a variety of mini-batch optimizations and normalizations. In the fixed-length mode, sequences longer than 4000 nt are truncated at the 5’ end [working under the assumption that localization signals are more often found in a transcript’s 3′ end (<xref rid="btz337-B6" ref-type="bibr">Bergalet and Lécuyer, 2014</xref>)]. Sequences shorter than 4000 nt are left padded with empty nucleotides encoded as 0000. We also investigated fixing the length at 1000, 2000 and 8000 nt, but obtained reduced prediction accuracy at 1000 and 2000 nt, and little accuracy benefits at 8000 nt.</p>
    </sec>
    <sec>
      <title>2.4 Model architecture</title>
      <p>RNATracker is a convolutional neural network (CNN) coupled with a LSTM recurrent neural network with attention mechanism. The overall structure of our model structure is shown in <xref ref-type="fig" rid="btz337-F2">Figure 2</xref>. Each component is described in detail below.
</p>
      <fig id="btz337-F2" orientation="portrait" position="float">
        <label>Fig. 2.</label>
        <caption>
          <p>Structure of the RNATracker deep neural network. (<bold>A</bold>) Top-down model architecture from the feature encoding, convolution and LSTM layers to the attention module. (<bold>B</bold>) Details of a LSTM cell. (<bold>C</bold>) Details of the attention module employed in this study</p>
        </caption>
        <graphic xlink:href="btz337f2"/>
      </fig>
      <p>Our network includes two sets of CNN+pooling layers (<xref ref-type="fig" rid="btz337-F2">Fig. 2A</xref>). Each CNN layer consists of 32 convolutional filters of length 10 with ReLU activation, initialized with Xavier uniform. Each pooling layer takes a window of size 3 and a stride of 3, to aggregate local information along the sequence as well as to effectively downsample the sequence by a factor of roughly 9 before passing it on to the subsequent LSTM layers. A network with a single convolutional layer was also evaluated but proved less accurate.</p>
      <p>The output of CNN+pooling layers is fed into the subsequent LSTM layer (<xref ref-type="fig" rid="btz337-F2">Fig. 2B</xref>), which is a recurrent neural network that allows information to flow from position to position, while being updated based on the data at the current position, according to the following equations:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mrow><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mo>σ</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>σ</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>σ</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>tanh</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>⊚</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula><disp-formula id="E3"><label>(3)</label><mml:math id="M3"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>tanh</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>
where <italic>i<sub>t</sub></italic>, <italic>f<sub>t</sub></italic> and <italic>o<sub>t</sub></italic> denote the input, forget and output gate respectively, each as an independent function of previous cell output <inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and input to the current cell <italic>x<sub>t</sub></italic>. <italic>C<sub>t</sub></italic> is the cell memory, composed in part of <inline-formula id="IE7"><mml:math id="IM7"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> which is the candidate cell memory for time step <italic>t</italic>, whose element-wise multiplication with the input gate <italic>i<sub>t</sub></italic> determines how much information to update into the current cell memory <italic>C<sub>t</sub></italic>. Similarly <italic>f<sub>t</sub></italic> controls how much information to forget from previous cell memory <inline-formula id="IE8"><mml:math id="IM8"><mml:mrow><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, therefore <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> makes up the other part of <italic>C<sub>t</sub></italic>. Finally <italic>o<sub>t</sub></italic> controls the information of the current cell output <italic>h<sub>t</sub></italic>. <inline-formula id="IE10"><mml:math id="IM10"><mml:mo>⊚</mml:mo></mml:math></inline-formula> stands for component-wise function composition.</p>
      <p>The use of bidirectional LSTM has previously been shown to be advantageous compared to ordinary unidirectional LSTM, since they are able to aggregate information from both directions (<xref rid="btz337-B41" ref-type="bibr">Schuster and Paliwal, 1997</xref>). Our network includes both a forward (5′ to 3′) and a reverse (3′ to 5′) direction LSTM. For each time step, the output of the bidirectional LSTM is the concatenation of the outputs of the two directional LSTMs.</p>
    </sec>
    <sec>
      <title>2.5 Attention mechanism</title>
      <p>Based on previous studies (<xref rid="btz337-B9" ref-type="bibr">Chin and Lecuyer, 2017</xref>), we expect the localization signals contained within most mRNAs to be confined to a relatively short contiguous portion of the sequence, often (but not always) located in the 3′ UTR. To take advantage of this, RNATracker integrates the notion of attention mechanism (<xref rid="btz337-B3" ref-type="bibr">Bahdanau <italic>et al.</italic>, 2015</xref>), which is a popular add-on technique for multiple tasks in fields, such as document classification (<xref rid="btz337-B43" ref-type="bibr">Yang <italic>et al.</italic>, 2016</xref>) and relation classification (<xref rid="btz337-B45" ref-type="bibr">Zhou <italic>et al.</italic>, 2016</xref>). This allows RNATracker to learn to pay more attention to regions of the sequence that convey more relevant information about localization. The details of the attention module are shown in <xref ref-type="fig" rid="btz337-F2">Figure 2C</xref>. Let us denote output of the bidirectional LSTM layer at time step <italic>t</italic> as <inline-formula id="IE11"><mml:math id="IM11"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mover accent="false"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">←</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. The attention layer performs the following computation:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>tanh</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="E5"><label>(5)</label><mml:math id="M5"><mml:mrow><mml:msub><mml:mrow><mml:mo>α</mml:mo></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>l</mml:mi></mml:msubsup><mml:mrow><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="E6"><label>(6)</label><mml:math id="M6"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>l</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mo>α</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula>
where <italic>w</italic> is a trainable weight vector in lieu of a context vector, <italic>l</italic> denotes the length of the output from the biLSTM layer and <italic>c</italic> is the vector that summarizes the output at different time steps in <italic>h</italic> weighted by α<sub><italic>t</italic></sub>.</p>
      <p>Finally, we attach a fully connected layer with softmax activation after the attention module, to form a four-categorical output.</p>
    </sec>
    <sec>
      <title>2.6 Loss function and regularization</title>
      <p>The entire network is trained to minimize the Kullback–Leibler divergence between the predicted and true subcellular distributions <italic>p</italic> and <italic>q</italic>:
<disp-formula id="E7"><mml:math id="M7"><mml:mrow><mml:mi mathvariant="italic">KL</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mi>i</mml:mi><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">F</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle><mml:mtext> </mml:mtext><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>
where <italic>N</italic> is the size of batch, and <italic>p</italic> is the observed distribution of normalized localization values across the subcellular fractions. Regularization is achieved using dropout units after convolutional layers, with a ratio empirically determined at 0.2.</p>
      <p>When using fixed-length input sequences, we use a mini-batch of size 256, which significantly speeds up training. We have investigated the use of batch normalization (<xref rid="btz337-B25" ref-type="bibr">Ioffe and Szegedy, 2015</xref>), in which other contexts have been shown to speed up convergence. However, we observe that with our 5′ zero-padding of short sequences, this leads to extra input variability being introduced at the 5′ end when the sequences in the batch have unequal lengths, resulting in slightly decreased prediction accuracy. Therefore in practice we choose not to use batch normalization, which however would be worth considering if training efficiency is more of a concern, or in situations where input sequences are of equal lengths.</p>
      <p>The set of hyperparameters reported in this study are selected based on the previous literature (<xref rid="btz337-B32" ref-type="bibr">Li <italic>et al.</italic>, 2017</xref>; <xref rid="btz337-B35" ref-type="bibr">Pan and Shen, 2017</xref>) and subject to a small amount of manual tuning. Overall, we found our model robust to the choice of reasonable hyperparameters.</p>
    </sec>
    <sec>
      <title>2.7 Use of RNA secondary structure</title>
      <p>To assess the extent to which RNA secondary structure can be used to inform subcellular localization prediction, we trained three variants of RNATracker: (i) RNATracker<sub>seq</sub> uses only primary sequence information; (ii) <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>RNATracker</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mtext>seq</mml:mtext><mml:mo>×</mml:mo><mml:mtext>struct</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> represents sequence and structure information jointly using 1-hot encoding over 4 × 6 = 24 bits/nt; and (iii) RNATracker<sub>seq+struct,</sub> which uses different encodings for the sequence and secondary structure, and processes them via different convolutional layers, whose outputs are concatenated before going through the LSTMs.</p>
    </sec>
    <sec>
      <title>2.8 Training and evaluation</title>
      <p>Our model is implemented using Keras (<xref rid="btz337-B10" ref-type="bibr">Chollet <italic>et al.</italic>, 2015</xref>). Training uses the Adam optimizer with Nesterov momentum (<xref rid="btz337-B17" ref-type="bibr">Dozat, 2016</xref>). For all experiments we used 10-fold cross-validation to evaluate our models. A maximum of 100 epochs is used for training each fold, and a validation set consisting of 10% of the training data is used to monitor the loss in the training process to detect overfitting.</p>
      <p>The variable length of mRNA transcripts poses a unique challenge to this study in terms of training time, as this prevents the use of mini-batches. Training examples thus need to be presented one at a time, which results in slow training (7 days for 10-fold cross-validation on a single GTX1080Ti graphic card, using a learning rate of <inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>). Skipping the LSTM layers allows somewhat faster training (2 days), but at a small cost in terms of accuracy (see Section 3). Sequence truncation/padding to 4 kb allows batch training, which yields significant gains in training time (8 h for 10-fold cross-validation, with a learning rate of <inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>).</p>
    </sec>
    <sec>
      <title>2.9 Baseline predictors</title>
      <p>Since we are not aware of any previous work on the prediction of mRNA subcellular localization, we chose to compare the different versions of RNATracker to two baseline predictors based on the popular k-mer representation. The simplicity of k-mer-based approach stems from the fact that the ordering information is lost in this representation. However, it has proved effective for related types of sequence function prediction, such as transcription factor binding (<xref rid="btz337-B20" ref-type="bibr">Ghandi <italic>et al.</italic>, 2014</xref>). Here, we use a feature vector of k-mer counts that combines features from 1-mer to 5-mer extracted from the full RNA sequence, resulting in a 1367-dimensional input vector. We actually investigated going up to 7-mers, but obtained no benefit in terms of accuracy. Two types of predictors were trained: a fully connected neural network (DNN-5Mer) with two hidden layers of size equal to the input dimension, each followed by ReLU activation and dropout, and a smaller neural network (NN-5Mer) with no hidden layer.</p>
    </sec>
    <sec>
      <title>2.10 Locating zipcodes within individual transcripts</title>
      <p>RNATracker can be used to quantify the extent to which specific subsequences of a given transcript contribute to the localization prediction, thereby identifying candidate zipcode elements. This is achieved by temporarily masking (zeroing-out) the sequence of a given portion of the transcript, and computing the Kullback–Leibler distance between RNATracker’s localization predictions on the original and masked sequences. We use a mask of 100 nt and slide it (with 1 nt stride) along the transcript’s sequence to obtain a relative importance vector. Because all the masked sequences have the same length, they can be evaluated in batch, which considerably speeds up the execution. We also experimented with another masking scheme where the masked portion is randomized rather than zeroed out (100 repetitions), but this did not significantly change the results, while taking significantly longer. Therefore, the results presented here are for the zero-masking approach.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <p>The different versions of RNATracker were evaluated on two mRNA subcellular localization datasets. The first was obtained by CeFra-seq in HepG2 cells, and contains 11 373 transcripts analyzed in the nuclear, cytosolic, membranes and insoluble fractions (<xref rid="btz337-B5" ref-type="bibr">Benoit Bouvrette <italic>et al.</italic>, 2018</xref>). The second was produced using APEX-RIP on HEK 293 T cells, and contains 13 860 analyzed in the ER, mitochondrial, cytosolic and nuclear fractions (<xref rid="btz337-B26" ref-type="bibr">Kaewsapsak <italic>et al.</italic>, 2017</xref>). <xref ref-type="fig" rid="btz337-F3">Figure 3</xref> shows the distribution of normalized localization values for each of the four CeFra-seq subcellular fractions, confirming the previously made observation that the cytoplasmic, nuclear and insoluble fractions contain a larger number of strongly localized transcripts, compared to the membrane fraction. Normalized localization values of different fractions are generally negatively correlated, except for the cytosolic and membrane fractions, which are unsurprisingly positively correlated due to physical colocation (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S2</xref>). This will have important consequences on the results presented later. Furthermore, transcripts localized to the cytosol tend to be shorter. See also <xref ref-type="supplementary-material" rid="sup1">Supplementary Figures S3 and S4</xref> for analogous analyses of APEX-RIP data.
</p>
    <fig id="btz337-F3" orientation="portrait" position="float">
      <label>Fig. 3.</label>
      <caption>
        <p>Summary statistics for the CeFra-Seq dataset. (<bold>A</bold>) Distribution of the normalized localization values for each subcellular fraction. (<bold>B</bold>) Number and average length of transcripts whose predominant localization is in each of the four fractions</p>
      </caption>
      <graphic xlink:href="btz337f3"/>
    </fig>
    <sec>
      <title>3.1 Performance of RNATracker</title>
      <p>We used 10-fold cross-validation to evaluate the performance of the different versions of RNATracker and the two baseline k-mer profile predictors, on both the CeFra-seq and APEX-RIP datasets. To limit computational burden, more detailed analyses of some key model components such as the attention weights and the learned sequence motifs were performed exclusively on the CeFra-Seq dataset.</p>
      <p><xref ref-type="fig" rid="btz337-F4">Figure 4</xref> compares the true localization values to those predicted by RNATracker on the ceFra-seq dataset (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S5</xref> for analysis of the APEX-RIP dataset). Correlation coefficients obtained vary from 0.54 for the nuclear and membrane fractions to 0.705 for the cytoplasm faction, and all are significantly different from zero (<italic>P</italic>-value <inline-formula id="IE15"><mml:math id="IM15"><mml:mo>≈</mml:mo></mml:math></inline-formula> 0). In APEX-RIP data, the accuracy is slightly lower, ranging from 0.456 (nuclear fraction) to 0.626 (ER), but again all are highly significant (<italic>P</italic>-value <inline-formula id="IE16"><mml:math id="IM16"><mml:mo>≈</mml:mo></mml:math></inline-formula> 0).
</p>
      <fig id="btz337-F4" orientation="portrait" position="float">
        <label>Fig. 4.</label>
        <caption>
          <p>RNATracker<sub>seq</sub> predictions for the CeFra-Seq dataset by fractions, trained with full-length transcripts. Each point is a transcript with its true localization value shown on the <italic>x</italic>-axis and the predicted value shown on the <italic>y</italic>-axis. (<bold>A</bold>) Cytosolic fraction (<bold>B</bold>) Insolution fraction (<bold>C</bold>) Membrane fraction (<bold>D</bold>) Nuclear fraction</p>
        </caption>
        <graphic xlink:href="btz337f4"/>
      </fig>
      <p><xref rid="btz337-T1" ref-type="table">Table 1</xref> compares the Pearson correlation coefficients between the experimental and predicted localization values of the combined folds, obtained by different predictors. This reveals several observations. First, for both datasets and across all fractions, the best results are obtained using RNATracker applied to full-length sequences (i.e. no trimming/padding) and without RNA secondary structure information. These correlation coefficients are consistently 10–25% higher than those obtained by the k-mer-based neural network, and 2–14% higher than those obtained by RNATracker operating on fixed-length sequences. Gains compared to fixed-length sequences are particularly significant for the membrane fraction (CeFra-seq) and ER (APEX-RIP), suggesting that localization to those fractions may often be mediated by sequences located in the 5′ end of the transcript. This makes sense since targeting to the ER membrane is known to be mediated by the signal sequence that can be found in mRNAs encoding secreted proteins (<xref rid="btz337-B23" ref-type="bibr">Hermesh and Jansen, 2013</xref>). We also observe that the two variants using RNA secondary structure information consistently perform 1–3% worse than the version using sequence information alone (analysis only performed in the fixed-length setting, for running time reasons).</p>
      <table-wrap id="btz337-T1" orientation="portrait" position="float">
        <label>Table 1.</label>
        <caption>
          <p>Pearson correlation coefficients by subcellular fraction of various model and input settings. Numbers in bold are the maximum of their row</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1"/>
              <th colspan="2" rowspan="1">Full-length RNA Inputs<hr/></th>
              <th colspan="4" rowspan="1">Fixed-length Inputs (4 kb)<hr/></th>
              <th colspan="2" rowspan="1">5Mer Inputs<hr/></th>
            </tr>
            <tr>
              <th rowspan="1" colspan="1">Dataset</th>
              <th rowspan="1" colspan="1">Compartment</th>
              <th rowspan="1" colspan="1">RNATracker<sub>seq</sub></th>
              <th rowspan="1" colspan="1">NoLSTM</th>
              <th rowspan="1" colspan="1">RNATracker<sub>seq</sub></th>
              <th rowspan="1" colspan="1">NoAttention</th>
              <th rowspan="1" colspan="1">Seq+Struct</th>
              <th rowspan="1" colspan="1">Seq×Struct</th>
              <th rowspan="1" colspan="1">DNN-5Mer</th>
              <th rowspan="1" colspan="1">NN-5Mer</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">CeFra-Seq</td>
              <td rowspan="1" colspan="1">Cytosol</td>
              <td rowspan="1" colspan="1">
                <bold>0.705</bold>
              </td>
              <td rowspan="1" colspan="1">0.676</td>
              <td rowspan="1" colspan="1">0.685</td>
              <td rowspan="1" colspan="1">0.625</td>
              <td rowspan="1" colspan="1">0.666</td>
              <td rowspan="1" colspan="1">0.652</td>
              <td rowspan="1" colspan="1">0.637</td>
              <td rowspan="1" colspan="1">0.558</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Insoluble</td>
              <td rowspan="1" colspan="1">
                <bold>0.641</bold>
              </td>
              <td rowspan="1" colspan="1">0.626</td>
              <td rowspan="1" colspan="1">0.619</td>
              <td rowspan="1" colspan="1">0.557</td>
              <td rowspan="1" colspan="1">0.604</td>
              <td rowspan="1" colspan="1">0.591</td>
              <td rowspan="1" colspan="1">0.552</td>
              <td rowspan="1" colspan="1">0.478</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Membrane</td>
              <td rowspan="1" colspan="1">
                <bold>0.540</bold>
              </td>
              <td rowspan="1" colspan="1">0.509</td>
              <td rowspan="1" colspan="1">0.469</td>
              <td rowspan="1" colspan="1">0.306</td>
              <td rowspan="1" colspan="1">0.451</td>
              <td rowspan="1" colspan="1">0.409</td>
              <td rowspan="1" colspan="1">0.421</td>
              <td rowspan="1" colspan="1">0.384</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Nuclear</td>
              <td rowspan="1" colspan="1">
                <bold>0.542</bold>
              </td>
              <td rowspan="1" colspan="1">0.515</td>
              <td rowspan="1" colspan="1">0.502</td>
              <td rowspan="1" colspan="1">0.379</td>
              <td rowspan="1" colspan="1">0.475</td>
              <td rowspan="1" colspan="1">0.449</td>
              <td rowspan="1" colspan="1">0.485</td>
              <td rowspan="1" colspan="1">0.432</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">APEX-RIP</td>
              <td rowspan="1" colspan="1">ER</td>
              <td rowspan="1" colspan="1">
                <bold>0.626</bold>
              </td>
              <td rowspan="1" colspan="1">0.554</td>
              <td rowspan="1" colspan="1">0.485</td>
              <td rowspan="1" colspan="1">0.150</td>
              <td rowspan="1" colspan="1">0.469</td>
              <td rowspan="1" colspan="1">0.394</td>
              <td rowspan="1" colspan="1">0.407</td>
              <td rowspan="1" colspan="1">0.368</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Mitocondria</td>
              <td rowspan="1" colspan="1">
                <bold>0.482</bold>
              </td>
              <td rowspan="1" colspan="1">0.449</td>
              <td rowspan="1" colspan="1">0.423</td>
              <td rowspan="1" colspan="1">0.139</td>
              <td rowspan="1" colspan="1">0.376</td>
              <td rowspan="1" colspan="1">0.320</td>
              <td rowspan="1" colspan="1">0.292</td>
              <td rowspan="1" colspan="1">0.224</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Cytosol</td>
              <td rowspan="1" colspan="1">
                <bold>0.561</bold>
              </td>
              <td rowspan="1" colspan="1">0.522</td>
              <td rowspan="1" colspan="1">0.501</td>
              <td rowspan="1" colspan="1">0.259</td>
              <td rowspan="1" colspan="1">0.493</td>
              <td rowspan="1" colspan="1">0.423</td>
              <td rowspan="1" colspan="1">0.446</td>
              <td rowspan="1" colspan="1">0.363</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"/>
              <td rowspan="1" colspan="1">Nuclear</td>
              <td rowspan="1" colspan="1">
                <bold>0.456</bold>
              </td>
              <td rowspan="1" colspan="1">0.402</td>
              <td rowspan="1" colspan="1">0.397</td>
              <td rowspan="1" colspan="1">0.235</td>
              <td rowspan="1" colspan="1">0.384</td>
              <td rowspan="1" colspan="1">0.338</td>
              <td rowspan="1" colspan="1">0.332</td>
              <td rowspan="1" colspan="1">0.238</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic>Note</italic>: NoLSTM and NoAttention are the two ablation tests without the bidirectional LSTM or the attention module.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>Our LSTM-based RNATracker was also compared to a pure CNN model (NoLSTM), revealing a consistent 3–7% increase in correlation coefficients due to the LSTM component. Similarly, a version of RNATracker without the attention module was evaluated but performed significantly worse than its attention-based counterpart (esp. on APEX-RIP data, where the difference ranges from 25% to 30%). These results show that both the LSTM and attention layers are essential for good prediction accuracy. However, the significantly shorter training time makes the fixed-length training a viable alternative when resources are limited.</p>
      <p>We next assessed the ability of RNATracker to identify the predominant localization of a given transcript, defined as the fraction where the transcript’s expression is the highest. Instead of retraining RNATracker for this new classification task, we simply turned this regressor into a classifier by making it output the fraction with the highest predicted localization value. <xref ref-type="supplementary-material" rid="sup1">Supplementary</xref> Figure S6 reports the receiver operating characteristic (ROC) and precision–recall (PR) curves for each predictor, micro-averaged across the four fractions. Consistent with the results on the regression task, RNATracker trained with full-length sequences slightly outperforms all other models, although by a narrow margin compared to the fixed-length version. These results also confirm the strong benefit of the attention module, and the slightly deleterious impact of including RNA secondary structure information. Similar observations can made for the APEX-RIP dataset (<xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S7</xref>).</p>
      <p>To better illustrate the difference between various models, we used Delong’s test from the R package pROC (<xref rid="btz337-B40" ref-type="bibr">Robin <italic>et al.</italic>, 2011</xref>) to compare the ROC curves, confirming that the performance gain from fixed-length to full-length version is statistically significant (<italic>P</italic>-value = <inline-formula id="IE17"><mml:math id="IM17"><mml:mrow><mml:mn>6.1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>), and so are the benefits of the LSTM and the attention module (both <italic>P</italic>-values <inline-formula id="IE18"><mml:math id="IM18"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>2.2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>).</p>
      <p>Given its slightly superior performance, for the rest of this section, we focus analyzing RNATracker with full-length input sequences but no RNA secondary structure, and with LSTM and attention layers. <xref ref-type="supplementary-material" rid="sup1">Supplementary Figure S6</xref>C and D dissects the prediction performance per subcellular fraction. Consistent with correlation results previously shown in <xref ref-type="fig" rid="btz337-F4">Figure 4</xref>, RNATracker has the best performance for the cytosolic fraction (ROC AUC = 0.851, PR AUC = 0.716), slightly better than results on the insoluble and nuclear factions, and much better than those on the membrane fraction. Several factors may explain these differences. First, very few transcripts (∼1000) are predominantly found in the membrane fraction, and almost none have membrane localization value greater than 0.5 (see <xref ref-type="fig" rid="btz337-F3">Figure 3A</xref>). Second, transcripts predominantly localized to the cytoplasmic fraction tend to be significantly shorter than others (see <xref ref-type="fig" rid="btz337-F3">Figure 3B</xref>), which is a clue our predictor takes advantage of.</p>
    </sec>
    <sec>
      <title>3.2 Dissecting the attention module</title>
      <p>As demonstrated earlier, the attention mechanism is beneficial to predicting localization profiles. To better understand its role, we studied how the attention weights α<sub><italic>i</italic></sub> vary along the sequence, under the fixed-length setting. <xref ref-type="fig" rid="btz337-F5">Figure 5</xref> shows that most of the attention weight concentrates at the ∼400 nt at the 3′ end of the transcript. This is likely caused by two factors. First, the few well-characterized <italic>cis</italic>-acting localization regulatory elements tend to be located in the 3′ UTR (<xref rid="btz337-B9" ref-type="bibr">Chin and Lecuyer, 2017</xref>), so it is likely that this is where the most meaningful signal is located. Second, the zero padding introduced in transcripts shorter than 4 kb is always introduced at the 5′ end, making this region generally less informative. It is worth noting, however, that RNATracker is fully able to identify zipcodes located outside that region (see <xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S1</xref>).
</p>
      <fig id="btz337-F5" orientation="portrait" position="float">
        <label>Fig. 5.</label>
        <caption>
          <p>Attention weights α<sub><italic>i</italic></sub>, for RNATracker with fixed-length inputs, averaged over the transcripts predominantly localized to each of the four fractions, as a function of position in transcript</p>
        </caption>
        <graphic xlink:href="btz337f5"/>
      </fig>
    </sec>
    <sec>
      <title>3.3 Analysis of sequence motifs</title>
      <p>The weights learned by the 32 filters from the first CNN layer are akin to position-weight matrices used in classical sequence analysis. We used weblogo (<xref rid="btz337-B14" ref-type="bibr">Crooks <italic>et al.</italic>, 2004</xref>) to visualized the learned motifs, and Tomtom (<xref rid="btz337-B4" ref-type="bibr">Bailey <italic>et al.</italic>, 2009</xref>) to map learned motifs to binding preferences of known RBPs (<xref rid="btz337-B38" ref-type="bibr">Ray <italic>et al.</italic>, 2013</xref>) (keeping in mind the caveat that this is an incomplete catalog and that matching motifs to RBPs is error-prone). A total of 9 of the 30 convolutional filters were found to match the binding profile of a known RBP (Tomtom <italic>P</italic>-value &lt; 0.05). Representative examples are shown in <xref ref-type="fig" rid="btz337-F6">Figure 6A</xref>, with strong matches to RBPs TIA1 (<italic>P</italic>-value = <inline-formula id="IE19"><mml:math id="IM19"><mml:mrow><mml:mn>7.63</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) and BRUNOL5 (<italic>P</italic>-value = <inline-formula id="IE20"><mml:math id="IM20"><mml:mrow><mml:mn>1.64</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>).
</p>
      <fig id="btz337-F6" orientation="portrait" position="float">
        <label>Fig. 6.</label>
        <caption>
          <p>(<bold>A</bold>) Visualization of selected learned sequence motifs (above) mapped to those of known RBPs (below) from <xref rid="btz337-B38" ref-type="bibr">Ray <italic>et al.</italic> (2013)</xref> that are TIA1 (up) and BRUNOL5 (down). (<bold>B</bold>) Hierarchical clustering of 32 filters with 1024 strongly localized transcripts (256 transcripts per fraction), using the cosine distance between the 1024-dimensional vectors of average activation values, averaged across the transcript length</p>
        </caption>
        <graphic xlink:href="btz337f6"/>
      </fig>
      <p>To better understand the role of the 32 motifs learned by RNATracker, and the way in which it combines them to obtain predictions, we clustered them based on their co-occurrences across a subset of 1024 transcripts consisting of the 256 transcripts most strongly localized to each of the four fractions. Two broad sets of motifs emerge. The first (top half of heatmap), contains several C/G-rich motifs as well as more complex motifs, which are strongly associated to cytoplasmic transcripts. The second (bottom half of heatmap), is characterized by A/U-rich motifs, as well as A-G or U-G dinucleotide repeats, which are mostly found in transcripts from the nuclear and insoluble fractions.</p>
      <p>To study how RNATracker uses individual sequence motifs to obtain its localization predictions, we iteratively zeroed out the output of all but one of the filters, and computed the Pearson correlation coefficient between the predicted localization values in the full and zeroed-out model, separately for each fraction. In this way, we are able to crudely isolate the contribution of each single convolution filter to the final prediction.</p>
    </sec>
    <sec>
      <title>3.4 Locating zipcodes within transcripts</title>
      <p>RNA subcellular localization is generally believed to be linked to the presence of discrete contiguous regulatory elements called localization zipcodes. By iteratively masking small portions of a transcript and studying how the predicted localization changes, one can identify candidate zipcodes, defined as regions whose masking significantly alters the localization prediction (see Section 2 and <xref ref-type="supplementary-material" rid="sup1">Supplementary Fig. S1</xref> for examples on specific transcripts). A candidate zipcode can further be assigned an enhancing or repressive label for a given fraction, depending on whether its masking results in a reduction or increase in the predicted localization score for that fraction. <xref ref-type="fig" rid="btz337-F7">Figure 7</xref> shows the number of positive and negative zipcode regions identified at different stringency levels (KL cut-off). At the KL cut-off of 0.0075, we identify 374 unique positive zipcodes, but only 167 unique negative zipcodes.
</p>
      <fig id="btz337-F7" orientation="portrait" position="float">
        <label>Fig. 7.</label>
        <caption>
          <p>Number (left) and interspecies conservation [measured using the KS statistics (right) of enhancing and repressive candidate zipcode regions identified at increasingly strict KL cut-offs]</p>
        </caption>
        <graphic xlink:href="btz337f7"/>
      </fig>
      <p>Because the number of experimentally characterized zipcodes is very small (less than a dozen in human), we had to rely on indirect measures to assess the validity of the predicted zipcode elements. Due to their important role in regulating proper gene expression, we would expect most zipcodes to be under negative selection, and thus to be more highly conserved across species than their neighboring regions. We thus used PhyloP conservation score (<xref rid="btz337-B36" ref-type="bibr">Pollard <italic>et al.</italic>, 2010</xref>), calculated from the multiple genome alignments of 100 vertebrates and available from the UCSC Genome Browser (<xref rid="btz337-B22" ref-type="bibr">Haeussler <italic>et al.</italic>, 2019</xref>). Focusing on the 2392 transcripts exhibiting strong subcellular localization (maximum localization value &gt;0.5), we compared the distribution of average PhyloP scores within the top 541 predicted zipcodes to the PhyloP score distribution of regions of 3′ UTRs not predicted to be zipcodes (<xref ref-type="fig" rid="btz337-F8">Fig. 8</xref>). While the two distributions largely overlap, large conservation scores (&gt;1) are roughly two times more frequent in candidate zipcodes than elsewhere, and the two distributions have means that are significantly different [<italic>P</italic>-value close to 0 using a Kolmogorov–Smirnov (KS) test]. This shows that predicted zipcodes are under stronger negative selection than the rest of the 3′ UTRs, although this may be caused by functions other than localization. Varying the KL threshold used to identify zipcodes, we observe that higher KS statistics (i.e. higher interspecies conservation values) are obtained for our most confidence predictions (<xref ref-type="fig" rid="btz337-F7">Fig. 7</xref>). With the caveat mentioned above, this suggests that RNATracker’s KL score can be used as indicators of zipcode prediction reliability.
</p>
      <fig id="btz337-F8" orientation="portrait" position="float">
        <label>Fig. 8.</label>
        <caption>
          <p>Distribution of average PhyloP scores for 541 regions predicted to be zipcode elements (KL score <inline-formula id="IE21"><mml:math id="IM21"><mml:mo>≤</mml:mo></mml:math></inline-formula> 0.0076, in blue) and 3688436 regions predicted not to be (KL score <inline-formula id="IE22"><mml:math id="IM22"><mml:mo>≤</mml:mo></mml:math></inline-formula> 0.0076, in red). Dotted vertical lines indicate the means of the two distributions</p>
        </caption>
        <graphic xlink:href="btz337f8"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion and conclusion</title>
    <p>Along with two recently published approaches by <xref rid="btz337-B46" ref-type="bibr">Zuckerman and Ulitsky (2019)</xref> and <xref rid="btz337-B21" ref-type="bibr">Gudenas and Wang (2018)</xref>, RNATracker is among the first computational predictors of mRNA subcellular localization. It achieves satisfactory (but certainly perfectible) performance on two of the largest subcellular localization datasets currently available, thanks to its use and adaptation of cutting-edge machine learning approaches such as LSTM and attention modules, without which prediction accuracy is generally inferior. Although the problem of predicting localization from sequence has some similarity to other sequence-based function prediction, its difficulty stands out because of the complexity of the mechanisms at play and the relative weakness and noisiness of the localization signal of most transcripts, among other reasons. The variable length of transcripts also leads to new challenges, both in terms of generalization and computational efficiency. Beyond being able to predict subcellular localization of full-length transcripts, RNATracker is able to locate candidate <italic>cis</italic>-regulatory regulatory regions (zipcodes) in strongly localized transcripts. In the absence of a large set of experimentally identified zipcodes, validating these predictions are challenging, but an analysis of interspecies sequence conservation, used a proxy for negative selection and thus function, indicates that many of our predicted zipcode are under stronger selection than surrounding 3′ UTR regions.</p>
    <p>Somewhat surprisingly, and despite our best attempts, we were unable to demonstrate significant benefits from the consideration of RNA secondary structure. This may be explained by a number of factors, and certainly does not suggest that structure plays no role in localization. First, our ability to accurately characterize secondary structure is imperfect, and our use of RNAplfold, which only considers relatively short-range interactions, may be limiting; the probabilistic structure profile proposed by <xref rid="btz337-B12" ref-type="bibr">Cook <italic>et al.</italic> (2017)</xref> may be good alternative. Second, incorporating RNA structure information increases the size of the input feature space, from 4 bit per position for pure sequence, to 10 or 24 depending on whether the seq+struct or seq×struct encoding is used. This may more easily lead to overfitting, thereby negating the benefits of this potentially valuable information. More condensed encodings (e.g. paired/unpaired) may prove beneficial. Finally, rather than feeding as input precomputed structural information, one may consider letting the model learn to reconstruct them from some lower-level sequence/structural features.</p>
    <p>Several factors may be limiting the accuracy of RNATracker. First and foremost, the quantity and specificity of RNA localization data remains relatively low, which limits the sophistication of the models learned from it and forces the use of strict regularization (limitation in model complexity, early stopping, dropout) to avoid too severe overfitting, which in turn limits the space of reasonable hyperparameters. This is in part due to the fact that isoforms are currently not distinguished (all expression data are mapped to the longest annotated isoform), although this could be addressed by more advanced processing of future ceFra-seq/APEX-like data, provided higher sequencing depth is obtained. Second, localization data produced by ceFra-seq/APEX are inherently noisy and may sometimes inaccurately reflect a transcripts true localization. Combined with the fact that many transcripts exhibit only slightly asymmetrical localization or strong localization to more than one subcellular fraction, this makes for hard data to train from.</p>
    <p>Improvements to our current approach could be considered in several directions, most of which are currently being explored. First, we may be able to take advantage of transfer learning to exploit models trained for other types of prediction tasks relevant to mRNA localization, such as the easier prediction of RBP binding (<xref rid="btz337-B2" ref-type="bibr">Alipanahi <italic>et al.</italic>, 2015</xref>; <xref rid="btz337-B32" ref-type="bibr">Li <italic>et al.</italic>, 2017</xref>; <xref rid="btz337-B35" ref-type="bibr">Pan and Shen, 2017</xref>) or possibly alternative splicing (<xref rid="btz337-B31" ref-type="bibr">Leung <italic>et al.</italic>, 2014</xref>). This would involve building a predictive model initialized from a model previously trained for one of these tasks, or reusing certain components of it, such as its convolution filters. Our initial attempts in that direction, based on reusing the convolutional filters trained to predict RBP binding events from Clip-Seq data (<xref rid="btz337-B42" ref-type="bibr">Stražar <italic>et al.</italic>, 2016</xref>), did not provide improved accuracy. Indeed, the convolution filters only take up a small proportion of all trainable weights. Alternatively, we could directly use prior knowledge about RBP binding affinities, e.g. from <xref rid="btz337-B38" ref-type="bibr">Ray <italic>et al.</italic> (2013)</xref>; <xref rid="btz337-B16" ref-type="bibr">Dominguez <italic>et al.</italic> (2018)</xref>, to initialize convolutional filters.</p>
    <p>Second, in this study, we used interspecies conservation as an indirect valuation of our zipcode predictions. One could instead make direct use of this information as an input to the predictor or to its attention module.</p>
    <p>Finally, bootstrapping techniques, e.g. reconstruction loss (<xref rid="btz337-B39" ref-type="bibr">Reed <italic>et al.</italic>, 2014</xref>), can be integrated into the training to account for the noise of the targets, together with unlabeled RNA sequences.</p>
    <p>With mRNA subcellular localization increasingly recognized as a key player in regulating gene expression, new and improved datasets will rapidly become available, and the power of approaches such as RNATracker will increase. At the same time, the predictions made by RNATracker, both in terms of location of zipcode elements and the way in which individual motifs combine to results in its localization predictions, constitute testable hypotheses that will fuel discovery in the field. All in all, this represents a rich, promising and challenging area for future research in bioinformatics and machine learning.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="sup1">
      <label>btz337_Supplementary_Data</label>
      <media xlink:href="btz337_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="ack1">
    <title>Acknowledgements</title>
    <p>We thank Faizy Ashan for insightful discussions, Louis Philip Benoit Bouvrette for providing assistance to the mapping of transcript-genome coordinates and Jérôme Waldispühl for advice on RNA secondary structure prediction.</p>
    <sec>
      <title>Funding</title>
      <p>This work was supported by a team grant from the Fond de Rechreche Québécois sur la Nature et les Technologies (FRQNT) to M.B. and E.L.; and a technology development grant from the Institut de Valorisation des Données (IVADO) to M.B. and E.L. </p>
      <p><italic>Conflict of Interest</italic>: none declared.</p>
    </sec>
  </ack>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btz337-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Aken</surname><given-names>B.L.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Ensembl 2017</article-title>. <source>Nucleic Acids Res</source>., <volume>45</volume>, <fpage>D635</fpage>–<lpage>D642</lpage>.<pub-id pub-id-type="pmid">27899575</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alipanahi</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning</article-title>. <source>Nat. Biotechnol</source>., <volume>33</volume>, <fpage>831.</fpage><pub-id pub-id-type="pmid">26213851</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Bahdanau</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) Neural machine translation by jointly learning to align and translate. In: <italic>International Conference on Learning Representations</italic>, San Diego, CA.</mixed-citation>
    </ref>
    <ref id="btz337-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bailey</surname><given-names>T.L.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>Meme suite: tools for motif discovery and searching</article-title>. <source>Nucleic Acids Res</source>., <volume>37</volume>, <fpage>W202</fpage>–<lpage>W208</lpage>.<pub-id pub-id-type="pmid">19458158</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Benoit Bouvrette</surname><given-names>L.P.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>CeFra-seq reveals broad asymmetric mRNA and noncoding RNA distribution profiles in drosophila and human cells</article-title>. <source>RNA</source>, <volume>24</volume>, <fpage>98</fpage>–<lpage>113</lpage>.<pub-id pub-id-type="pmid">29079635</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bergalet</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Lécuyer</surname><given-names>E.</given-names></name></person-group> (<year>2014</year>) <chapter-title>The functions and regulatory principles of mRNA intracellular trafficking</chapter-title>
<source>Adv. Exp. Med. Biol.</source>, <volume>825</volume>, <fpage>57</fpage>–<lpage>96</lpage>.<pub-id pub-id-type="pmid">25201103</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bernhart</surname><given-names>S.H.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>Local RNA base pairing probabilities in large sequences</article-title>. <source>Bioinformatics</source>, <volume>22</volume>, <fpage>614</fpage>–<lpage>615</lpage>.<pub-id pub-id-type="pmid">16368769</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bramham</surname><given-names>C.R.</given-names></name>, <name name-style="western"><surname>Wells</surname><given-names>D.G.</given-names></name></person-group> (<year>2007</year>) 
<article-title>Dendritic mRNA: transport, translation and function</article-title>. <source>Nat. Rev. Neurosci</source>., <volume>8</volume>, <fpage>776</fpage>.<pub-id pub-id-type="pmid">17848965</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chin</surname><given-names>A.</given-names></name>, <name name-style="western"><surname>Lecuyer</surname><given-names>E.</given-names></name></person-group> (<year>2017</year>) 
<article-title>RNA localization: making its way to the center stage</article-title>. <source>Biochim. Biophys. Acta Gen. Subj</source>., <volume>1861</volume>, <fpage>2956</fpage>–<lpage>2970</lpage>.</mixed-citation>
    </ref>
    <ref id="btz337-B10">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Chollet</surname><given-names>F.</given-names></name></person-group> (<year>2015</year>) Keras. <ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras">https://github.com/fchollet/keras</ext-link>, 2015.</mixed-citation>
    </ref>
    <ref id="btz337-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cook</surname><given-names>K.B.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>RBPDB: a database of RNA-binding specificities</article-title>. <source>Nucleic Acids Res</source>., <volume>39</volume>, <fpage>D301</fpage>–<lpage>D308</lpage>.<pub-id pub-id-type="pmid">21036867</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cook</surname><given-names>K.B.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>RNAcompete-S: combined RNA sequence/structure preferences for RNA binding proteins derived from a single-step in vitro selection</article-title>. <source>Methods</source>, <volume>126</volume>, <fpage>18</fpage>–<lpage>28</lpage>.<pub-id pub-id-type="pmid">28651966</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cooper</surname><given-names>T.A.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) 
<article-title>RNA and disease</article-title>. <source>Cell</source>, <volume>136</volume>, <fpage>777</fpage>–<lpage>793</lpage>.<pub-id pub-id-type="pmid">19239895</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Crooks</surname><given-names>G.E.</given-names></name></person-group><etal>et al</etal> (<year>2004</year>) 
<article-title>Weblogo: a sequence logo generator</article-title>. <source>Genome Res</source>., <volume>14</volume>, <fpage>1188</fpage>–<lpage>1190</lpage>.<pub-id pub-id-type="pmid">15173120</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Delong</surname><given-names>A.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Inference of the human polyadenylation code</article-title>. <source>Bioinformatics</source>, <volume>34</volume>, <fpage>2889</fpage>–<lpage>2898</lpage>.<pub-id pub-id-type="pmid">29648582</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dominguez</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2018</year>) 
<article-title>Sequence, structure, and context preferences of human RNA binding proteins</article-title>. <source>Mol. Cell</source>, <volume>70</volume>, <fpage>854</fpage>–<lpage>867</lpage>.<pub-id pub-id-type="pmid">29883606</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B17">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Dozat</surname><given-names>T.</given-names></name></person-group> (<year>2016</year>) Incorporating Nesterov momentum into Adam. In: <italic>Proceedings of 4th International Conference on Learning Representations, Workshop Track</italic>, Banff, Canada.</mixed-citation>
    </ref>
    <ref id="btz337-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ferrè</surname><given-names>F.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Revealing protein-lncRNA interaction</article-title>. <source>Brief. Bioinform</source>., <volume>17</volume>, <fpage>106</fpage>–<lpage>116</lpage>.<pub-id pub-id-type="pmid">26041786</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gerstberger</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>A census of human RNA-binding proteins</article-title>. <source>Nat. Rev. Genet</source>., <volume>15</volume>, <fpage>829.</fpage><pub-id pub-id-type="pmid">25365966</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ghandi</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Enhanced regulatory sequence prediction using gapped k-mer features</article-title>. <source>PLoS Comput. Biol</source>., <volume>10</volume>, <fpage>e1003711.</fpage><pub-id pub-id-type="pmid">25033408</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gudenas</surname><given-names>B.L.</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>L.</given-names></name></person-group> (<year>2018</year>) 
<article-title>Prediction of LncRNA subcellular localization with deep learning from sequence features</article-title>. <source>Sci. Rep</source>., <volume>8</volume>, <fpage>16385.</fpage><pub-id pub-id-type="pmid">30401954</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Haeussler</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2019</year>) 
<article-title>The UCSC genome browser database: 2019 update</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>D853</fpage>–<lpage>D858</lpage>.<pub-id pub-id-type="pmid">30407534</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hermesh</surname><given-names>O.</given-names></name>, <name name-style="western"><surname>Jansen</surname><given-names>R.-P.</given-names></name></person-group> (<year>2013</year>) 
<article-title>Take the (RN)A-train: localization of mRNA to the endoplasmic reticulum</article-title>. <source>Biochim. Biophys. Acta</source>, <volume>1833</volume>, <fpage>2519</fpage>–<lpage>2525</lpage>.<pub-id pub-id-type="pmid">23353632</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hochreiter</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Schmidhuber</surname><given-names>J.</given-names></name></person-group> (<year>1997</year>) 
<article-title>Long short-term memory</article-title>. <source>Neural Comput</source>., <volume>9</volume>, <fpage>1735</fpage>–<lpage>1780</lpage>.<pub-id pub-id-type="pmid">9377276</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B25">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Ioffe</surname><given-names>S.</given-names></name>, <name name-style="western"><surname>Szegedy</surname><given-names>C.</given-names></name></person-group> (<year>2015</year>) Batch normalization: accelerating deep network training by reducing internal covariate shift. In: <italic>Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, ICML’15</italic>, pp. 448–456. JMLR.org.</mixed-citation>
    </ref>
    <ref id="btz337-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kaewsapsak</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Live-cell mapping of organelle-associated RNAs via proximity biotinylation combined with protein-RNA crosslinking</article-title>. <source>eLife</source>, <volume>6</volume>, <fpage>e29224</fpage>.<pub-id pub-id-type="pmid">29239719</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kerpedjiev</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2015</year>) 
<article-title>Predicting RNA 3D structure using a coarse-grain helix-centered model</article-title>. <source>RNA</source>, <volume>21</volume>, <fpage>1110</fpage>–<lpage>1121</lpage>.<pub-id pub-id-type="pmid">25904133</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>LeCun</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>1989</year>) 
<article-title>Backpropagation applied to handwritten zip code recognition</article-title>. <source>Neural Comput</source>., <volume>1</volume>, <fpage>541</fpage>–<lpage>551</lpage>.</mixed-citation>
    </ref>
    <ref id="btz337-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lécuyer</surname><given-names>E.</given-names></name></person-group><etal>et al</etal> (<year>2007</year>) 
<article-title>Global analysis of mRNA localization reveals a prominent role in organizing cellular architecture and function</article-title>. <source>Cell</source>, <volume>131</volume>, <fpage>174</fpage>–<lpage>187</lpage>.<pub-id pub-id-type="pmid">17923096</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lefebvre</surname><given-names>F.A.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>CeFra-seq: systematic mapping of RNA subcellular distribution properties through cell fractionation coupled to deep-sequencing</article-title>. <source>Methods</source>, <volume>126</volume>, <fpage>138</fpage>–<lpage>148</lpage>.<pub-id pub-id-type="pmid">28579403</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Leung</surname><given-names>M.K.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Deep learning of the tissue-regulated splicing code</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>i121</fpage>–<lpage>i129</lpage>.<pub-id pub-id-type="pmid">24931975</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>A deep boosting based approach for capturing the sequence binding preferences of RNA-binding proteins from high-throughput clip-seq data</article-title>. <source>Nucleic Acids Res</source>., <volume>45</volume>, <fpage>e129</fpage>–<lpage>e129</lpage>.<pub-id pub-id-type="pmid">28575488</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>Motifmap-RNA: a genome-wide map of rbp binding sites</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>2029</fpage>–<lpage>2031</lpage>.<pub-id pub-id-type="pmid">28334276</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lorenz</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>ViennaRNA package 2.0</article-title>. <source>Algorithm Mol. Biol</source>., <volume>6</volume>, <fpage>26.</fpage></mixed-citation>
    </ref>
    <ref id="btz337-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pan</surname><given-names>X.</given-names></name>, <name name-style="western"><surname>Shen</surname><given-names>H.-B.</given-names></name></person-group> (<year>2017</year>) 
<article-title>RNA-protein binding motifs mining with a new hybrid deep learning based cross-domain knowledge integration approach</article-title>. <source>BMC Bioinformatics</source>, <volume>18</volume>, <fpage>136.</fpage><pub-id pub-id-type="pmid">28245811</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pollard</surname><given-names>K.S.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Detection of nonneutral substitution rates on mammalian phylogenies</article-title>. <source>Genome Res</source>., <volume>20</volume>, <fpage>110</fpage>–<lpage>121</lpage>.<pub-id pub-id-type="pmid">19858363</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B37">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Quang</surname><given-names>D.</given-names></name>, <name name-style="western"><surname>Xie</surname><given-names>X.</given-names></name></person-group> (<year>2016</year>) 
<article-title>Danq: a hybrid convolutional and recurrent deep neural network for quantifying the function of DNA sequences</article-title>. <source>Nucleic Acids Res</source>., <volume>44</volume>, <fpage>e107</fpage>.<pub-id pub-id-type="pmid">27084946</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ray</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2013</year>) 
<article-title>A compendium of RNA-binding motifs for decoding gene regulation</article-title>. <source>Nature</source>, <volume>499</volume>, <fpage>172.</fpage><pub-id pub-id-type="pmid">23846655</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B39">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Reed</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) Training deep neural networks on noisy labels with bootstrapping. <italic>arXiv preprint arXiv</italic>: 1412.6596.</mixed-citation>
    </ref>
    <ref id="btz337-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Robin</surname><given-names>X.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>proc: an open-source package for r and s+ to analyze and compare roc curves</article-title>. <source>BMC Bioinformatics</source>, <volume>12</volume>, <fpage>77.</fpage><pub-id pub-id-type="pmid">21414208</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Schuster</surname><given-names>M.</given-names></name>, <name name-style="western"><surname>Paliwal</surname><given-names>K.K.</given-names></name></person-group> (<year>1997</year>) 
<article-title>Bidirectional recurrent neural networks</article-title>. <source>IEEE Trans. Signal Process</source>., <volume>45</volume>, <fpage>2673</fpage>–<lpage>2681</lpage>.</mixed-citation>
    </ref>
    <ref id="btz337-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Stražar</surname><given-names>M.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Orthogonal matrix factorization enables integrative analysis of multiple RNA binding proteins</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>1527</fpage>–<lpage>1535</lpage>.<pub-id pub-id-type="pmid">26787667</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B43">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Yang</surname><given-names>Z.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) Hierarchical attention networks for document classification. In: <italic>Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</italic>, pp. 1480–1489.</mixed-citation>
    </ref>
    <ref id="btz337-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhou</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Troyanskaya</surname><given-names>O.G.</given-names></name></person-group> (<year>2015</year>) 
<article-title>Predicting effects of noncoding variants with deep learning–based sequence model</article-title>. <source>Nat. Methods</source>, <volume>12</volume>, <fpage>931.</fpage><pub-id pub-id-type="pmid">26301843</pub-id></mixed-citation>
    </ref>
    <ref id="btz337-B45">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Zhou</surname><given-names>P.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) Attention-based bidirectional long short-term memory networks for relation classification. In: <italic>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</italic>, pp. 207–212.</mixed-citation>
    </ref>
    <ref id="btz337-B46">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zuckerman</surname><given-names>B.</given-names></name>, <name name-style="western"><surname>Ulitsky</surname><given-names>I.</given-names></name></person-group> (<year>2019</year>) 
<article-title>Predictive models of subcellular localization of long RNAs</article-title>. <source>RNA</source>, <volume>25</volume>, <fpage>557</fpage>–<lpage>572</lpage>.<pub-id pub-id-type="pmid">30745363</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
