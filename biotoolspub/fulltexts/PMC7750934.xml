<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7750934</article-id>
    <article-id pub-id-type="pmid">32449747</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btaa542</article-id>
    <article-id pub-id-type="publisher-id">btaa542</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Papers</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Genome Analysis</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>TaxoNN: ensemble of neural networks on stratified microbiome data for disease prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Sharma</surname>
          <given-names>Divya</given-names>
        </name>
        <aff>Division of Biostatistics, <institution>Dalla Lana School of Public Health, University of Toronto, Toronto, ON, Canada M5T 3M7</institution></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Paterson</surname>
          <given-names>Andrew D</given-names>
        </name>
        <aff>Division of Biostatistics, <institution>Dalla Lana School of Public Health, University of Toronto, Toronto, ON, Canada M5T 3M7</institution></aff>
        <aff>
          <institution>Genetics and Genome Biology Program, The Hospital for Sick Children, Toronto, ON, Canada, M5G 1X8</institution>
        </aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Xu</surname>
          <given-names>Wei</given-names>
        </name>
        <aff>Division of Biostatistics, <institution>Dalla Lana School of Public Health, University of Toronto, Toronto, ON, Canada M5T 3M7</institution></aff>
        <aff>
          <institution>Department of Biostatistics, Princess Margaret Cancer Center, University Health Network, Toronto, ON, Canada, M5G 2C1</institution>
        </aff>
        <xref rid="btaa542-cor1" ref-type="corresp"/>
        <!--Wei.Xu@uhnresearch.ca-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Luigi Martelli</surname>
          <given-names>Pier</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btaa542-cor1">To whom correspondence should be addressed. E-mail: <email>Wei.Xu@uhnresearch.ca</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <day>01</day>
      <month>9</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2020-05-25">
      <day>25</day>
      <month>5</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>25</day>
      <month>5</month>
      <year>2020</year>
    </pub-date>
    <volume>36</volume>
    <issue>17</issue>
    <fpage>4544</fpage>
    <lpage>4550</lpage>
    <history>
      <date date-type="received">
        <day>10</day>
        <month>3</month>
        <year>2020</year>
      </date>
      <date date-type="rev-recd">
        <day>08</day>
        <month>5</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>19</day>
        <month>5</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbynclicense">https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btaa542.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>Research supports the potential use of microbiome as a predictor of some diseases. Motivated by the findings that microbiome data is complex in nature, and there is an inherent correlation due to hierarchical taxonomy of microbial Operational Taxonomic Units (OTUs), we propose a novel machine learning method incorporating a stratified approach to group OTUs into phylum clusters. Convolutional Neural Networks (CNNs) were used to train within each of the clusters individually. Further, through an ensemble learning approach, features obtained from each cluster were then concatenated to improve prediction accuracy. Our two-step approach comprising stratification prior to combining multiple CNNs, aided in capturing the relationships between OTUs sharing a phylum efficiently, as compared to using a single CNN ignoring OTU correlations.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We used simulated datasets containing 168 OTUs in 200 cases and 200 controls for model testing. Thirty-two OTUs, potentially associated with risk of disease were randomly selected and interactions between three OTUs were used to introduce non-linearity. We also implemented this novel method in two human microbiome studies: (i) Cirrhosis with 118 cases, 114 controls; (ii) type 2 diabetes (T2D) with 170 cases, 174 controls; to demonstrate the model’s effectiveness. Extensive experimentation and comparison against conventional machine learning techniques yielded encouraging results. We obtained mean AUC values of 0.88, 0.92, 0.75, showing a consistent increment (5%, 3%, 7%) in simulations, Cirrhosis and T2D data, respectively, against the next best performing method, Random Forest.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p><ext-link xlink:href="https://github.com/divya031090/TaxoNN_OTU" ext-link-type="uri">https://github.com/divya031090/TaxoNN_OTU</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Natural Sciences and Engineering Research Council of Canada</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000038</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>RGPIN-2017-06672</award-id>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Crohn’s and Colitis Canada</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>CCC-GEMIII</institution>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>Helmsley Charitable Trust</institution>
            <institution-id institution-id-type="DOI">10.13039/100007028</institution-id>
          </institution-wrap>
        </funding-source>
      </award-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NSERC</institution>
            <institution-id institution-id-type="DOI">10.13039/501100000038</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>RGPIN-2017-06672</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>The human microbiome comprises a collection of microbes which live on and inside the human body. The microbiome data are usually quantified into Operational Taxonomic Units (OTUs), based on their sequence similarity to reference datasets (<xref rid="btaa542-B3" ref-type="bibr">Blaxter <italic toggle="yes">et al.</italic>, 2005</xref>). The risk of some diseases has been found to be associated with the host’s microbiome (<xref rid="btaa542-B12" ref-type="bibr">Jackson <italic toggle="yes">et al.</italic>, 2018</xref>), making prediction of risk of disease based on microbiome analysis an important problem. In this regard, machine learning can efficiently understand the relationship between the microbiomes and between microbiomes and diseases (<xref rid="btaa542-B26" ref-type="bibr">Sommer <italic toggle="yes">et al.</italic>, 2017</xref>).</p>
    <p>The role of the microbiome has been examined in subjects with a variety of diseases such as Inflammatory Bowel Diseases (<xref rid="btaa542-B5" ref-type="bibr">Gevers <italic toggle="yes">et al.</italic>, 2014</xref>), Cirrhosis (<xref rid="btaa542-B25" ref-type="bibr">Schnabl and Brenner, 2014</xref>) and type 2 diabetes (T2D) (<xref rid="btaa542-B10" ref-type="bibr">Hartstra <italic toggle="yes">et al.</italic>, 2015</xref>) justifying the potential use of the microbiome as a disease risk prediction tool. A sparse distance-based learning method for multiclass classification of human microbiota is proposed by <xref rid="btaa542-B16" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> (2011)</xref>; <xref rid="btaa542-B20" ref-type="bibr">Pasolli <italic toggle="yes">et al.</italic> (2016)</xref> proposed a computational framework for prediction tasks using species-level relative abundances and strain-specific markers. Whereas, <xref rid="btaa542-B4" ref-type="bibr">Bokulich <italic toggle="yes">et al.</italic> (2018)</xref> presented a comparison of supervised learning classifiers and regressors for microbiomes using a Python-based machine-learning library. <xref rid="btaa542-B1" ref-type="bibr">Ananthakrishnan <italic toggle="yes">et al.</italic> (2017)</xref> incorporated clinical and microbiome data to classify treatment response and <xref rid="btaa542-B17" ref-type="bibr">Lo and Marculescu (2019)</xref> proposed a neural network framework for disease prediction with data augmentation to mitigate over-fitting. However, the role of taxonomy in prediction using OTU data is often unclear, wherein similar OTUs are often correlated across samples.</p>
    <p>Convolutional Neural Networks (CNNs) (<xref rid="btaa542-B14" ref-type="bibr">Krizhevsky <italic toggle="yes">et al.</italic>, 2012</xref>) have been successfully applied to diversified areas such as face recognition (<xref rid="btaa542-B34" ref-type="bibr">Yang <italic toggle="yes">et al.</italic>, 2016</xref>), optical character recognition (<xref rid="btaa542-B2" ref-type="bibr">Bai <italic toggle="yes">et al.</italic>, 2014</xref>) and medical diagnosis (<xref rid="btaa542-B27" ref-type="bibr">Sun <italic toggle="yes">et al.</italic>, 2016</xref>). CNNs perform well in capturing spatial and temporal dependencies in the input data. CNNs are also capable to capture interactions in the data during prediction (<xref rid="btaa542-B31" ref-type="bibr">Tsang <italic toggle="yes">et al.</italic>, 2017</xref>). Ensemble learning has also garnered a lot of attention in the field of bioimage classification (<xref rid="btaa542-B18" ref-type="bibr">Nanni <italic toggle="yes">et al.</italic>, 2018</xref>) and scene-text recognition (<xref rid="btaa542-B19" ref-type="bibr">Park <italic toggle="yes">et al.</italic>, 2016</xref>) wherein multiple neural networks are combined together to enhance model performance as well as incorporate multiple inputs. However, we observed that CNNs have not been widely applied in the area of microbiome analysis to predict disease risk. One reason could be that OTU relative abundance data in itself (without any re-arrangement) does not show any spatial similarity that the CNNs can capture.</p>
    <p>Motivated by the inherent correlation shared by the OTUs in the same taxonomy level and the non-linear relationship between the OTUs during disease prediction (<xref rid="btaa542-B30" ref-type="bibr">Tsai <italic toggle="yes">et al.</italic>, 2015</xref>; <xref rid="btaa542-B33" ref-type="bibr">Xiao <italic toggle="yes">et al.</italic>, 2018</xref>), we propose a novel deep learning model <italic toggle="yes">taxoNN</italic> (taxonomy-based Neural Network). <italic toggle="yes">taxoNN</italic> stratifies input OTU data into various clusters based on their phylum information. Further, as ensemble learning is effective, hence, we propose an ensemble of CNNs over the stratified clusters containing OTUs sharing the same phylum. The rationale is that OTUs after the phylum level division share similarity and hence, some correlation with each other. Moreover, to introduce spatial relationship in the input OTUs for the CNNs to capture, we order the OTUs on the basis of correlation with each other and Euclidean distance from the centre of the cluster.</p>
  </sec>
  <sec>
    <title>2 Materials and methods</title>
    <sec>
      <title>2.1 Proposed neural network framework: <italic toggle="yes">taxoNN</italic></title>
      <p>We experimented with using three types of CNN models. To begin with, we used a basic convolutional framework (CNN_basic), where the input OTUs were arranged in an alphabetical order of their taxonomic label and hence, their order did not represent a biological relationship.</p>
      <p>We then experimented with shuffling the OTUs (CNN_shuffle) in the input on each iteration of the neural network, in the assumption that the various iterations of shuffling would in turn lead to correlated microbiomes arrange in one window. However, this assumption might limit the prediction accuracy.</p>
      <p>Hence, we finally examined incorporating the inherent phylogenetic relationship in the OTU data before providing it as an input to the neural network model. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S1</xref>, shows a sample taxonomy tree containing various taxonomic levels and illustrates that hierarchy in OTU data is complex and clusters corresponding to the different phyla can contain a varied number of OTUs.</p>
      <p>Let there be ‘I’ subjects in the whole study, the OTU data for <italic toggle="yes">i</italic>th subject (where, <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo></mml:mrow></mml:math></inline-formula> I), was presented in a 1-D vector format to the network, as, <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mtext>th</mml:mtext><mml:mo> </mml:mo><mml:mtext>subject</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mi>N</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, where, <italic toggle="yes">N</italic> was the total number of OTUs in a subject. These OTUs were then stratified into four clusters based on their phyla such that each cluster had different number of OTUs. For example the first cluster contained ‘p’ OTUs, second contained ‘q’ OTUs, third contained ‘r’ OTUs and fourth contained ‘s’ OTUs (where <italic toggle="yes">p</italic> + <italic toggle="yes">q</italic>+<italic toggle="yes">r</italic> + <italic toggle="yes">s</italic> = <italic toggle="yes">N</italic>), and CNN was applied to each cluster individually. To order and place correlated OTUs together, we adopted two approaches:</p>
      <p><bold>Approach 1: Ordering based on distance to the cluster centre:</bold> In this approach, for a cluster, we took ‘p’ OTUs of I-dimension each (corresponding to ‘I’ number of subjects), inside the cluster. We then calculated the medoid of that cluster. A medoid is a representative object of a dataset whose average dissimilarity to all the objects in the cluster is minimal. A medoid in a cluster containing OTUs of the same phyla, is calculated using the formula:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mtext>medoid</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>argmin</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mi>d</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>As can be seen in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S12a</xref>, for ease of representation, we took a few OTUs and considered their OTU vectors to contain only three subjects. OTUs are shown as blue dots representing relative abundance of that particular OTU and medoid of these OTUs was then calculated (shown as red dot <xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S12b</xref>) using <xref rid="E1" ref-type="disp-formula">Equation 1</xref>. Further, Euclidean distances <italic toggle="yes">d<sub>i</sub></italic>, <italic toggle="yes">d<sub>j</sub></italic> and <italic toggle="yes">d<sub>k</sub></italic> of three sample OTUs (<italic toggle="yes">i</italic>, <italic toggle="yes">j</italic> and <italic toggle="yes">k</italic>) from the medoid were calculated (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S12c</xref>) and OTUs were ordered on the basis of their increasing distance to the medoid. In this way, we obtained <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, therefore, OTU<sub><italic toggle="yes">i</italic></sub> was ordered before OTU<sub><italic toggle="yes">j</italic></sub> and OTU<sub><italic toggle="yes">k</italic></sub> in the OTU vector that was provided as an input to the CNN. This idea was extended to all the ‘p’ OTU vectors in the cluster.</p>
      <p>This ordering combined with the convolutional sliding window helped to combine OTUs which were closely located and shared more similarity in the cluster. OTUs in the same sliding window, combined with the weight vector in the neural network led to creating non-linear terms that were sent to the next layer of the neural network and hence, this helped in understanding the non-linear relationship between them. We named this variation of <italic toggle="yes">taxoNN</italic> as <italic toggle="yes">taxoNN</italic><sub>dis</sub>.</p>
      <p><bold>Approach 2: Ordering based on correlation:</bold> The second approach that we used was to order the OTUs based on their correlation with each other using Spearman rank. This gave us a <italic toggle="yes">p </italic>×<italic toggle="yes"> p</italic> matrix for <italic toggle="yes">p</italic> OTUs in a cluster as shown in <xref rid="btaa542-F1" ref-type="fig">Figure 1a</xref>. Next, each row of this correlation matrix was reduced to a cumulative correlation coefficient, calculated with respect to all the OTUs in a single row using the formula:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>row</mml:mtext></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mroot><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mo>·</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mo>⋯</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:mroot></mml:mrow></mml:math></disp-formula>for <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula></p>
      <fig position="float" id="btaa542-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>An illustration of correlation-based ordering in the OTUs in a cluster. (<bold>a</bold>) Example heatmap obtained by plotting Spearman rank coefficients between positively correlated OTUs in a cluster. (<bold>b</bold>) Cumulative coefficient obtained with respect to each row of the heatmap matrix. (<bold>c</bold>) Vector of cumulative coefficients arranged in a decreasing order where, <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mtext>row</mml:mtext><mml:mn>5</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mtext>row</mml:mtext><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mtext>row</mml:mtext><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mtext>row</mml:mtext><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mtext>row</mml:mtext><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. (<bold>d</bold>) The cumulative coefficients are renamed as <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>row</mml:mtext></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> to represent that they are now arranged in a decreasing order. (<bold>e</bold>) Heatmap sorted based on the new order of cumulative coefficients, making the correlated terms concentrate in a space and arrange closer in the matrix</p>
        </caption>
        <graphic xlink:href="btaa542f1" position="float"/>
      </fig>
      <p>The set of these cumulative coefficients is represented as <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (<xref rid="btaa542-F1" ref-type="fig">Fig. 1b</xref>) as:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>row</mml:mtext></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>row</mml:mtext></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>row</mml:mtext></mml:mrow></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>Thus, we obtained a vector of correlation coefficients, <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> based on <xref rid="E3" ref-type="disp-formula">Equation 3</xref>, with each value representing a cumulative correlation coefficient for each row. The values in the set <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> were then arranged in a decreasing order and a new vector <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> was created containing cumulative correlation coefficients in decreasing order which were further re-indexed from 1 to <italic toggle="yes">p</italic>. The asterisk here represents re-indexing.
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mtext>row</mml:mtext><mml:mn>5</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:mtext>row</mml:mtext><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>row</mml:mtext></mml:mrow></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></disp-formula>
 <disp-formula id="E5"><label>(5)</label><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:msubsup><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msubsup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>row</mml:mtext></mml:mrow></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>*</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>row</mml:mtext></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>*</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mo>ρ</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mtext>row</mml:mtext></mml:mrow></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>*</mml:mo></mml:msubsup><mml:mo>}</mml:mo></mml:mrow></mml:math></disp-formula></p>
      <p>Subsequently, the heatmap obtained by the correlations in the OTU data is reordered based on the decreasing order of the cumulative correlation coefficients. Through this ordering the correlation structure between the OTUs was used to establish a similarity in the neighbouring OTUs before being provided to the neural network model. We named this variation of <italic toggle="yes">taxoNN</italic> as <italic toggle="yes">taxoNN</italic><sub>corr</sub>.</p>
      <p>The broad overview of our CNN framework is presented in <xref rid="btaa542-F2" ref-type="fig">Figure 2a</xref>. <xref rid="btaa542-F2" ref-type="fig">Figure 2b</xref> illustrates various layers in the neural network acting on each cluster of the OTU data. We defined the model with two 1-D convolutional layers, each followed by a pooling layer. The data has been pre-processed in such a way that each vector contains <italic toggle="yes">N</italic> OTUs. These OTUs are then divided into clusters based on their phylum level with first cluster containing ‘p’ OTUs, second containing ‘q’ OTUs, third containing ‘r’ OTUs and fourth containing ‘s’ OTUs. The first convolutional layer (Conv1) defines 32 filters (feature detectors) of height 5 (window size) and stride size (number by which sliding window slides) of 1. For activation, we use Rectified Linear Unit (ReLU) (<xref rid="btaa542-B6" ref-type="bibr">Glorot <italic toggle="yes">et al.</italic>, 2011</xref>) and after the convolution operation (<xref rid="btaa542-B14" ref-type="bibr">Krizhevsky <italic toggle="yes">et al.</italic>, 2012</xref>) in the first layer, the extracted features were forwarded to the pooling layer (Pool1). A pooling layer is often used after a CNN layer in order to reduce the complexity of the output and prevent overfitting of the data. Similarly, a second set of convolutional (with 64 filters) and pooling Layer (Conv2 and Pool2) were used to extract features. Finally, the feature vectors obtained were flattened to a single vector. In a similar manner features were learned and flattened from each cluster.
</p>
      <fig position="float" id="btaa542-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Illustration of the layers in the CNN framework. (<bold>a</bold>) Detailed illustration of the phylum-based stratification and ensemble learning of CNNs for disease prediction. The four different clusters are color coded with different colours and after phyla stratification are input to the four neural networks (N1, N2, N3 and N4). Later the features extracted are flattened and stacked during the concatenation step to further lead to prediction of disease outcome. (<bold>b</bold>) Illustration of the layers in a single neural network (N1/N2/N3/N4) acting on one particular cluster of the input data. (Color version of this figure is available at <italic toggle="yes">Bioinformatics</italic> online.)</p>
        </caption>
        <graphic xlink:href="btaa542f2" position="float"/>
      </fig>
      <p>Next, ensemble learning (<xref rid="btaa542-B9" ref-type="bibr">Hansen and Salamon, 1990</xref>) was used, where, features from each cluster were combined. The flattened vectors obtained from each cluster were merged via concatenation to make one very long vector that was then interpreted and sent to two fully connected layers before a prediction was made. In the two fully connected layers the first layer had 100 nodes followed by a ReLU activation while the second layer had only a binary node with a softmax activation (<xref rid="btaa542-B7" ref-type="bibr">Goodfellow <italic toggle="yes">et al.</italic>, 2016</xref>) to predict the two classes according to the disease status (Disease/Control). The details about the input and output processing through each layer are shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S19</xref>. We also experimented with adding variables such as age and sex as input along with the OTU data in the model. In this scenario, two separate vectors, one containing age values and other, the sex values were given as input to the individual CNNs along with the OTU vectors in each cluster.</p>
    </sec>
    <sec>
      <title>2.2 Simulated studies</title>
      <p>We designed simulation studies using the microbiome data available in the ‘Genetic, Environmental, Microbial’ (GEM) project (<xref rid="btaa542-B32" ref-type="bibr">Turpin <italic toggle="yes">et al.</italic>, 2016</xref>). Subjects were first-degree relatives of subjects with Crohn’s disease between 6 and 35 years of age and recruited between 2008 and 2015. This project aimed to identify microbial, genetic and environmental factors responsible for the initiation of Crohn’s disease. Stool samples were collected for 16S ribosomal DNA sequencing at a minimum depth of 30 000 reads/sample. Samples with fewer than 30 000 reads and OTUs with prevalence of <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>5</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math></inline-formula> were removed from the analysis. Analysis was restricted to merged OTUs with the same taxonomic assignment.</p>
      <p>Our simulated datasets were created using 1796 subjects provided in the GEM study data. Each sample contained values for 168 OTUs. The OTUs in this simulated dataset were categorized into taxonomy levels with 12 phyla, 15 classes, 20 orders, 37 families and 60 genera. The three dominant bacterial phyla in terms of the number of OTUs were Firmicutes, Proteobacteria and Actinobacteria.</p>
      <p>We used this data to create a population with 100 000 samples. Instead of a simple replication we added noise to each OTU using a normally distributed function with mean equal to a random number in the range <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> and standard deviation of <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> to create new samples. While doing so we ensured that we preserve the zeroes and also considered that the relative abundance is equal to one, by adding and subtracting the noise term in equal proportion in each OTU set, keeping the zeroes. We then generated the disease status (<italic toggle="yes">y</italic> = 1 for case; <italic toggle="yes">y</italic> = 0 for control) using the formula:
<disp-formula id="E6"><label>(6)</label><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>α</mml:mo><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>32</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mo>α</mml:mo><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>32</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>·</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mtext>OTU</mml:mtext></mml:mrow></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <italic toggle="yes">β<sub>i</sub></italic> were the regression coefficients associated with OTUs, <italic toggle="yes">α</italic> was the base prevalence, <italic toggle="yes">β<sub>ij</sub></italic> were the regression coefficients for the pairwise interaction terms, <italic toggle="yes">y</italic> was the outcome variable and <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> was the probability of the outcome variable to be 1, i.e. disease status positive. In general, the OTUs that are potentially associated with risk of disease, in a microbiome dataset are unknown and their number can range from zero to a very large value. Carefully choosing the number of these OTUs during simulating data, thus, becomes a challenge. Therefore, based on a trade-off between the model performance upon analysis with various number of OTUs (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>) and the realistic estimation of OTUs potentially associated with risk of disease in a real microbiome dataset, we selected 32 OTUs randomly as the OTUs that were potentially associated with risk of disease, also ensuring that all clusters contribute to these OTUs. We set the value of <italic toggle="yes">α</italic> as -2.5, <italic toggle="yes">β<sub>i</sub></italic> in 1st cluster ranging from [1,1.5], 2nd cluster ranging from [1,2], 3rd cluster ranging from [1.5,2] and 4th cluster [0.5,1]. Interaction terms were added to introduce non-linearity in the data. Out of the 32 OTUs potentially associated with risk of disease, 3 OTUs were randomly picked and three pairwise interactions between them were generated (as shown in <xref rid="E6" ref-type="disp-formula">Equation 6</xref>), where, <italic toggle="yes">β<sub>ij</sub></italic> was taken as [1,1.5,2]. In this way, we generated 2000 samples as cases and 98 000 as controls from the 100 000 samples. For the simulation data to evaluate our algorithm, we then randomly selected 200 cases from theses 2000 case samples and randomly selected 200 matched controls based on age and sex. We performed 1:1 matching of cases to controls for age in the range of ±5 years and exact match for sex. Hence, obtained a case-control dataset of 200 cases and 200 controls. 100 simulation datasets were generated following the same strategy.</p>
      <p>The phyla-based stratification on the OTUs in the simulated dataset was done in the following manner: for 168 OTUs, after phyla-based stratification, 1st cluster contained 92 OTUs, 2nd contained 28 OTUs, 3rd contained 27 OTUs and 4th contained 21 OTUs. Each cluster was provided as an input to an individual CNN to understand the relationships between OTUs inside each phyla and later the extracted features were used for making the predictions.</p>
    </sec>
    <sec>
      <title>2.3 Real studies: T2D study and Cirrhosis study</title>
      <p>To assess the prediction power of <italic toggle="yes">taxoNN</italic> on linking the gut microbiome with disease risk, we implemented our algorithm on a T2D (<xref rid="btaa542-B21" ref-type="bibr">Qin <italic toggle="yes">et al.</italic>, 2012</xref>) study containing 174 cases and 170 controls and a liver Cirrhosis study (<xref rid="btaa542-B22" ref-type="bibr">Qin <italic toggle="yes">et al.</italic>, 2014</xref>), containing 118 cases and 114 controls. OTUs at the genus level in the kingdom ‘Bacteria’ were used as an input. The T2D data was based on deep next-generation shotgun sequencing of DNA extracted from the stool samples from Chinese subjects. The subjects in the Cirrhosis data were of Han Chinese origin. In both studies Proteobacteria, Actinobacteria and Firmicutes emerged as the phyla with majority of OTUs, leading to forming three major clusters for <italic toggle="yes">taxoNN</italic>. <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S2 and S3</xref> give more details about the OTUs in each cluster in the T2D study and Cirrhosis study, respectively. Details of variables like age and sex of the subjects provided with both studies are given in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref>. The box-plots containing relative abundance percentages of OTUs in each phylum of T2D and Cirrhosis studies are presented in Supplementary Figures S3 and S7, respectively. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figures S4–S6</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figures S8–S10</xref> provide box-plots for relative abundance percentages of genera in each cluster of the T2D and Cirrhosis studies.</p>
    </sec>
    <sec>
      <title>2.4 Model specification and evaluation criteria</title>
      <p>For training the neural network model on the simulated study, 70% of the subjects were considered in the training data and 30% in the test data. Therefore, out of 200 controls and cases which were pair-matched for age and sex as described in Section 2.2, 140 controls and 140 cases were used for training the network, and 60 controls and 60 cases were used for testing the network. Similarly, for the T2D and Cirrhosis studies, 70% of the subjects were considered in the training data and, 30% in the test data. Thereby, in the T2D study 119 cases and 119 controls were used for training and 55 cases and 50 controls were used for the test set. In Cirrhosis study, 83 controls and 83 cases were used for training and 31 controls and 35 cases were used to test the model. We also performed an internal validation using 10 times 10-fold cross validation on the training set itself, to analyze model performance before testing and to eliminate overfitting. For the cross-validation, we used 90% of the total training set selected at random for training, and the remaining 10% as a hold out set for testing. We obtained 10 AUC values corresponding to initial 10-folds in the training set. We repeated this process 10 times in order to generate corresponding 100 AUC values. We then calculated the 95% confidence intervals using these 100 AUC values. 400 epochs were run for the neural network model with a stride size of 1, window size of 5, number of OTUs related to disease outcome set as 32 for the first layer and number of filters in the CNN network as 32. Each network was trained using stochastic gradient descent with a learning rate of 0.001. We trained our network on an NVIDIA Tesla P100 GPU with 16GB of RAM using tensorflow library in Python alongwith some data analysis using R version 3.5.3.</p>
      <p>The performance of our technique was evaluated through a Receiver Operating Characteristics curve (ROC curve) using specificity, sensitivity and thereafter calculating mean Area Under Curve (AUC), where a larger AUC meant a better classification model. Given the number of true positives (TP), false positives (FP), true negatives (TN) and false negatives (FN), the measures are mathematically expressed as follows: Sensitivity=TP/(TP+FN) and Specificity=TN/(TN+FP).</p>
      <p>We compared the results obtained by our proposed model <italic toggle="yes">taxoNN</italic> in its two variations <italic toggle="yes">taxoNN</italic><sub>dis</sub> and <italic toggle="yes">taxoNN</italic><sub>corr</sub> against conventional machine learning models like Random Forests (RFs) (<xref rid="btaa542-B15" ref-type="bibr">Liaw <italic toggle="yes">et al.</italic>, 2002</xref>), Gaussian Bayes Classifier (GBC) (<xref rid="btaa542-B8" ref-type="bibr">Hand and Yu, 2001</xref>), Naive Bayes (NB) (<xref rid="btaa542-B23" ref-type="bibr">Rish <italic toggle="yes">et al.</italic>, 2001</xref>), Ridge regression (<xref rid="btaa542-B11" ref-type="bibr">Hoerl and Kennard, 1970</xref>), Lasso regression (<xref rid="btaa542-B29" ref-type="bibr">Tibshirani, 1996</xref>) and Support Vector Machines (SVM) (<xref rid="btaa542-B28" ref-type="bibr">Suykens and Vandewalle, 1999</xref>).</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Simulation results</title>
      <sec>
        <label>3.1.1</label>
        <title>Type 1 error performance</title>
        <p>In the simulated datasets, first, we tested for <italic toggle="yes">taxoNN</italic> under the null, i.e. where none of the OTUs in the input data were related to the outcome i.e. disease status. We obtained an AUC value of 0.513 using <italic toggle="yes">taxoNN</italic><sub>corr</sub> and 0.504 with <italic toggle="yes">taxoNN</italic><sub>dis</sub> model. Comparing the AUC values obtained from our model with RF (AUC = 0.502), SVM (AUC = 0.523), Ridge (AUC = 0.517) and Lasso (AUC = 0.510) we observed that our model was stable under the null and shows that the prediction of disease status was not governed by the OTUs in the case of non-causal relationship between the OTUs and disease.</p>
      </sec>
      <sec>
        <label>3.1.2</label>
        <title>Comparison of predictive performance</title>
        <p>For the simulated datasets under the situation of association, the ROC curves obtained are presented in <xref rid="btaa542-F3" ref-type="fig">Figure 3</xref>. As can be seen in <xref rid="btaa542-F3" ref-type="fig">Figure 3</xref>, the blue and the brown plot lines in the graph depict the ROC curve for <italic toggle="yes">taxoNN</italic><sub>corr</sub> and <italic toggle="yes">taxoNN</italic><sub>dis</sub>, respectively. The area under the curve was highest for our proposed models, <italic toggle="yes">taxoNN</italic><sub>corr</sub> and <italic toggle="yes">taxoNN</italic><sub>dis</sub> with AUC values, 0.883 and 0.874, respectively, followed by RF technique (AUC = 0.846). As discussed, we initially experimented with predicting disease status using a basic CNN model. As the arrangement of input OTU data in this case did not signify any relationships, therefore, the AUC obtained was equal to 0.753. The second variation we tried was to shuffle the input data on each iteration of the CNN (CNN_shuffle) so that, we can approximate OTU correlations by making them fall in the same CNN window for combination into the next layer. We observed that, in this case the performance of the CNN improved (AUC = 0.822), as compared to the basic CNN. However, the performance in this method is highly dependent upon the OTU combinations resulting due to the shuffling and thus, might vary upon shuffling the OTUs. The other machine learning methods like RF and SVM with AUCs 0.846 and 0.825, respectively, performed relatively better than GBC and NB (AUC = 0.792, 0.789, respectively) due to their tree-based structure, rendering their ability to capture non-linearity in the data. However, there was a clear under-performance by these methods as compared to <italic toggle="yes">taxoNN</italic><sub>corr</sub> with a difference in AUC ranging from about 0.038 for RF and increasing to about 0.094 for the least efficient performing method GBC. The computation time taken by our method on an NVIDIA Tesla P100 GPU with 16GB of RAM for each iteration of the ensemble of neural networks was 9.35 s. The initial ordering of the input OTU data took 1.27 s. Therefore, each iteration took about 10.62 s. The neural networks ran simultaneously for each cluster and took 400 epochs to learn, therefore, the overall time taken for <italic toggle="yes">taxoNN</italic> to train was about 70.8 min for the simulated dataset. Details of the performance of <italic toggle="yes">taxoNN</italic> in case of change in parameters associated with the neural network, in presence of interaction terms and in case of imbalance of case and controls is shown in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>, <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S5</xref> and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S11</xref>, respectively.
</p>
        <fig position="float" id="btaa542-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>ROC curve obtained on the test set of the simulated study. The test set comprised 60 controls and 60 cases. The red dotted line corresponds to AUC equal to 0.5, indicating a random classification model</p>
          </caption>
          <graphic xlink:href="btaa542f3" position="float"/>
        </fig>
      </sec>
    </sec>
    <sec>
      <title>3.2 Results for T2D and Cirrhosis studies</title>
      <p>In this section, we present results on the training and test sets of the T2D and Cirrhosis studies. We filtered the data in both the studies, eliminating OTUs that had a zero proportion in all individuals and thereby obtained 184 OTUs for the Cirrhosis study and 208 for the T2D study after this filtering. <xref rid="sup1" ref-type="supplementary-material">Supplementary Figure S2</xref> illustrates pie-charts corresponding to the OTU distribution in the T2D and Cirrhosis studies. Illustration of how the heatmaps are sorted and rearranged based on the correlations between the OTUs in each cluster are provided in <xref rid="sup1" ref-type="supplementary-material">Supplementary Figures S13–S15</xref> for T2D and <xref rid="sup1" ref-type="supplementary-material">Supplementary Figures S16–S18</xref> for Cirrhosis study. An additional analysis on an external validation cohort (<xref rid="btaa542-B13" ref-type="bibr">Karlsson <italic toggle="yes">et al.</italic>, 2013</xref>) is presented in <xref rid="sup1" ref-type="supplementary-material">Supplementary Tables S7 and S8</xref>.</p>
      <sec>
        <label>3.2.1</label>
        <title>Results for T2D study</title>
        <p>The results for T2D dataset taking 10-fold cross validation on the training set are presented in <xref rid="btaa542-F4" ref-type="fig">Figure 4a</xref> (also, <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S6</xref>). We plotted the 95% confidence intervals (CI) for each of the methods. The mean AUC values obtained for <italic toggle="yes">taxoNN</italic> and <italic toggle="yes">taxoNN</italic> were 0.753 (95% CI: 0.741–0.761) and 0.741 (95% CI: 0.731–0.750), respectively, followed by RF (AUC = 0.740), CNN_shuffle (AUC = 0.736), SVM (AUC = 0.721), Ridge regression (AUC = 0.699), Lasso regression (AUC = 0.687), GBC (AUC = 0.684) and NB (AUC = 0.682). We also calculated the results on the test set of the T2D study (tabulated in <xref rid="btaa542-T1" ref-type="table">Table 1</xref> second column), and obtained a mean AUC value of 0.733 using <italic toggle="yes">taxoNN</italic><sub>corr</sub> which was considerably higher than the other machine learning methods on the test set.
</p>
        <fig position="float" id="btaa542-F4">
          <label>Fig. 4.</label>
          <caption>
            <p>95% confidence intervals obtained for the mean AUC values for 10 times 10-fold cross validation on the training set for the (<bold>a</bold>) T2D study and the (<bold>b</bold>) Cirrhosis study</p>
          </caption>
          <graphic xlink:href="btaa542f4" position="float"/>
        </fig>
        <table-wrap position="float" id="btaa542-T1">
          <label>Table 1.</label>
          <caption>
            <p>AUC values tabulated for various machine learning methods on test set of T2D and Cirrhosis studies</p>
          </caption>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col valign="top" align="left" span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
              <col valign="top" align="char" char="." span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th colspan="2" rowspan="1">AUC T2D<hr/></th>
                <th colspan="2" rowspan="1">AUC Cirrhosis<hr/></th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1">Method</th>
                <th rowspan="1" colspan="1">w/o age+sex</th>
                <th rowspan="1" colspan="1">w age+sex</th>
                <th rowspan="1" colspan="1">w/o age+sex</th>
                <th rowspan="1" colspan="1">w age+sex</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">RF</td>
                <td rowspan="1" colspan="1">0.703</td>
                <td rowspan="1" colspan="1">0.708</td>
                <td rowspan="1" colspan="1">0.893</td>
                <td rowspan="1" colspan="1">0.901</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">GBC</td>
                <td rowspan="1" colspan="1">0.642</td>
                <td rowspan="1" colspan="1">0.648</td>
                <td rowspan="1" colspan="1">0.816</td>
                <td rowspan="1" colspan="1">0.825</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">SVM</td>
                <td rowspan="1" colspan="1">0.701</td>
                <td rowspan="1" colspan="1">0.704</td>
                <td rowspan="1" colspan="1">0.877</td>
                <td rowspan="1" colspan="1">0.882</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Lasso regression</td>
                <td rowspan="1" colspan="1">0.665</td>
                <td rowspan="1" colspan="1">0.670</td>
                <td rowspan="1" colspan="1">0.823</td>
                <td rowspan="1" colspan="1">0.831</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Ridge regression</td>
                <td rowspan="1" colspan="1">0.700</td>
                <td rowspan="1" colspan="1">0.705</td>
                <td rowspan="1" colspan="1">0.842</td>
                <td rowspan="1" colspan="1">0.848</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">NB</td>
                <td rowspan="1" colspan="1">0.682</td>
                <td rowspan="1" colspan="1">0.685</td>
                <td rowspan="1" colspan="1">0.802</td>
                <td rowspan="1" colspan="1">0.807</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CNN_basic</td>
                <td rowspan="1" colspan="1">0.643</td>
                <td rowspan="1" colspan="1">0.647</td>
                <td rowspan="1" colspan="1">0.799</td>
                <td rowspan="1" colspan="1">0.801</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">CNN_shuffle</td>
                <td rowspan="1" colspan="1">0.712</td>
                <td rowspan="1" colspan="1">0.718</td>
                <td rowspan="1" colspan="1">0.844</td>
                <td rowspan="1" colspan="1">0.852</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <italic toggle="yes">taxoNN</italic>
                  <sub>dis</sub>
                </td>
                <td rowspan="1" colspan="1">0.720</td>
                <td rowspan="1" colspan="1">0.725</td>
                <td rowspan="1" colspan="1">0.903</td>
                <td rowspan="1" colspan="1">0.908</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <bold>
                    <italic toggle="yes">taxoNN</italic>
                    <sub>corr</sub>
                  </bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.733</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.762</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.911</bold>
                </td>
                <td rowspan="1" colspan="1">
                  <bold>0.938</bold>
                </td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <fn id="tblfn1">
              <p><italic toggle="yes">Note</italic>: The results are reported on both studies considering model performance without (w/o) including age and sex and with (w) age and sex. Note that the last row (values in bold) shows the consistent improvement in the performance of the proposed model <italic toggle="yes">taxoNN</italic><sub>corr</sub> for both studies.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <label>3.2.2</label>
        <title>Results for Cirrhosis study</title>
        <p>The results for Cirrhosis study taking 10 times 10-fold cross validation by creating 10-folds in the training set and using 1 out of the 10-folds for testing each time are presented in <xref rid="btaa542-F4" ref-type="fig">Figure 4b</xref> (also, <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S6</xref>). The 95% confidence interval over the 100 mean AUC values were calculated for the other machine learning methods in comparison to <italic toggle="yes">taxoNN</italic>. We obtained a mean AUC value as high as 0.921 (95% CI: 0.911–0.930) for the proposed <italic toggle="yes">taxoNN</italic><sub>corr</sub> model closely followed in performance by the <italic toggle="yes">taxoNN</italic><sub>dis</sub> model with a mean AUC of 0.919 (95% CI: 0.909–0.925). An improvement of 0.025 was noted when comparing the AUC value of <italic toggle="yes">taxoNN</italic><sub>corr</sub> to the next best performing method of RF (AUC = 0.892) followed by the SVM method which was observed to give a mean AUC of 0.881. The GBC, NB and Ridge regression performed comparably with mean AUC values of 0.874, 0.870 and 0.877, respectively. It was observed that the least efficient method in this case was the basic CNN model with AUC as low as 0.832. Results on the test set for Cirrhosis study are reported in <xref rid="btaa542-T1" ref-type="table">Table 1</xref>, fourth column, showing the effectiveness of <italic toggle="yes">taxoNN</italic> on the Cirrhosis study.</p>
      </sec>
      <sec>
        <label>3.2.3</label>
        <title>Incorporating clinical variables</title>
        <p>As tabulated in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref>, we observed that in both studies cases were significantly older than the controls. In the T2D study the cases had a significantly greater proportion of males than controls. Whereas, for Cirrhosis study, there were no significant differences in sex between cases and controls. To analyze further, we evaluated the prediction power of our model including age and sex data. We observed an AUC value of 0.592 given the age and sex for the Cirrhosis dataset using logistic regression. Similar, observation was made for the T2D dataset where we obtained an AUC value of 0.613 using just the age and sex. When we combined these two variables along with the OTU training set (performing 10 times 10-fold validation) and provided it as input (<xref rid="btaa542-T1" ref-type="table">Table 1</xref> third column) to <italic toggle="yes">taxoNN</italic><sub>corr</sub> for the T2D study, we obtained an improved AUC of 0.762 as compared to 0.738 previously obtained using only the OTUs. The same held valid for the Cirrhosis study, where the AUC after combining environmental variables increased from 0.921 to 0.938 (<xref rid="btaa542-T1" ref-type="table">Table 1</xref> fifth column). We also observed that when age and sex were provided to other machine learning models of the T2D study, enhanced their performance a little, with an increase of 0.008, 0.009, 0.005, 0.008, 0.006, 0.005 in the AUC values of RFs, SVM, GBC, NB, Lasso Regression, Ridge Regression, respectively (<xref rid="btaa542-T1" ref-type="table">Table 1</xref>). A similar trend was observed for the performance in Cirrhosis study, with an increase of ∼0.005 in AUC values for other machine learning methods. However, it is to be noted that in <italic toggle="yes">taxoNN</italic>, inclusion of age and sex enhanced the performance to a larger degree as compared to other machine learning methods (increase of 0.017 and 0.009 in the AUC in T2D and Cirrhosis studies, respectively).</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Discussion</title>
    <p>Extensive analysis on three datasets establish that stratifying OTU data into clusters and using ensembles of CNN models on the clusters to predict disease status as proposed in <italic toggle="yes">taxoNN</italic> leads to efficiently capturing OTU data. We observed that <italic toggle="yes">taxoNN</italic> performs consistently better across all the three datasets. Other methods like RFs which have a record of working well with non-linear data (<xref rid="btaa542-B24" ref-type="bibr">Ryo and Rillig, 2017</xref>), performed slightly better than NB and GBC methods while predicting the risk of disease (<xref rid="btaa542-T1" ref-type="table">Table 1</xref>). We also observed that in general, the AUC values obtained by performing 10 times 10-fold validation on the training set (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S6</xref>) were higher than the one obtained by working on the test set (<xref rid="btaa542-T1" ref-type="table">Table 1</xref>).</p>
    <p>By changing the parameters associated with the CNN (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>) such as window size and the number of filters in each layer, we observed a trend of dropping in performance upon increasing these parameters beyond a certain level. We inferred that up to window size of five the performance was good, but increasing the window size further resulted in adding unnecessary amount of correlations between the OTUs in the input data which might not truly reflect the scenario in the real data. Similarly, when we increased the number of filters from 32 to 64 we observed that the performance dropped.</p>
    <p>We also analyzed the methods in the literature that propose machine learning techniques for disease prediction for T2D and Cirrhosis studies. <xref rid="btaa542-B22" ref-type="bibr">Qin <italic toggle="yes">et al.</italic> (2014)</xref> used an SVM method with training set (AUC of 0.918) and leave-one-out cross-validation set (AUC of 0.838) for the Cirrhosis data. In comparison, <italic toggle="yes">taxoNN</italic><sub>corr</sub> using the 10-fold cross validation outperformed by a significant margin giving an AUC value of 0.921 and similarly, <italic toggle="yes">taxoNN</italic><sub>dis</sub> also gave a much higher AUC of 0.919 suggesting our model’s efficiency. <xref rid="btaa542-B21" ref-type="bibr">Qin <italic toggle="yes">et al.</italic> (2012)</xref> propose a T2D classifier system based on the 50 gene markers through a minimum redundancy–maximum relevance (mRMR) feature selection method, to exploit the potential ability of T2D classification by gut microbiota. An AUC of 0.81 was reported using SVM for classification through the gene markers. As our model focused on relative abundance of the OTUs, therefore, a straight comparison to the results provided by <xref rid="btaa542-B21" ref-type="bibr">Qin <italic toggle="yes">et al.</italic> (2012)</xref> was not feasible.</p>
    <p>However, there are a few assumptions and limitations of our method. Microbiomes can reside in various sites in the body such as skin, mammary glands, uterus, ovarian follicles, oral mucosa and gut. However, for the scope of this article, we implemented our algorithm only on gut microbiome data, limiting our analysis to predicting diseases caused by gut microbiomes. As discussed earlier, the OTUs that are potentially associated with risk of disease in a microbiome dataset are unknown and their number in a study can be arbitrary, ranging from zero to a very large value. We experimented with taking 8, 16 and 32 OTUs associated to disease outcome in the simulation study, which ranges from 5 to 15% of the total OTUs in the study. We then selected 32 OTUs as the OTUs associated with risk of disease based on their performance in <italic toggle="yes">taxoNN</italic> (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S1</xref>). However, we might be under or over estimating the number of OTUs and it would be interesting to consider different number of OTUs in the future to evaluate the model better. Also, we simulated the data, taking three interaction terms w.r.t three randomly selected OTUs to add non-linearity in our OTU data. However, just three pairs of OTUs might not be enough to approximate the complex relationship presented within real OTU data. Hence, a better analysis by varying the number of interacting OTUs needs to be done to evaluate model performance. For our analysis, we consider phylum level stratification in <italic toggle="yes">taxoNN</italic> in all the three studies, due to presence of adequate number of OTUs in phylum level which is required for efficient model training. However, in the future, it will be interesting to observe studies which have adequate OTUs in other taxonomy levels like class and order along with phylum level (<xref rid="sup1" ref-type="supplementary-material">Supplementary Table S9</xref>).</p>
    <p>As tabulated in <xref rid="sup1" ref-type="supplementary-material">Supplementary Table S4</xref>, age has been identified to be associated with the disease outcome for both T2D and Cirrhosis, whereas sex has been identified to be associated with T2D. This may represent poorly matched subjects in these studies. If these factors are causally associated with disease, then when used along with OTU data, they can enhance the performance of the model. However, our model is currently limited to just these two variables alongside the OTU data. A more comprehensive analysis taking other environmental variables like ethnicity, smoking status, dietary habits and medication can be conducted to evaluate their effects in disease prediction alongside microbiome data. We also observed that our method performs fairly robustly with respect to imbalance in the number of cases and controls up to a certain level (<xref rid="sup1" ref-type="supplementary-material">Supplementary Fig. S11</xref>), but the performance dropped considerably when the imbalance increased (1:4 ratio between cases and controls). Hence, better techniques to handle data imbalance need to be examined.</p>
  </sec>
  <sec>
    <title>5 Conclusion</title>
    <p>We propose a technique to predict disease status through gut microbiome data using a novel ensemble of neural networks. Using the inherent biological information in the OTU data, we divided the OTUs into clusters based on their phylum and trained on each cluster individually and later ensembled features from each neural network to predict disease status. We also proposed two novel ordering methods based on correlation and cluster centre distance to arrange input OTUs based on their similarity to help capture the spatial similarity in the input as required by the CNN. We obtained encouraging results on simulation data, Cirrhosis and T2D studies and consistent improvement in performance across both test and training sets compared to competing methods.</p>
    <p>From our analysis we can infer, that non-linearity in the OTU data can be captured well using a CNN and relationships provided by the taxonomy in OTU data can help to improve accuracy of disease prediction. In the future, we would like to apply <italic toggle="yes">taxoNN</italic> for predicting continuous and time-to-event outcomes in addition to the current binary outcome and potentially implement our model on pathway analysis in genetic data. We would aim to identify specific microbiomes which play an important role for causing a particular disease. The limitations discussed in Section 4, pertaining to dealing with imbalance in input data and experimenting with more interaction terms also provide a good scope for future studies.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>Wei Xu was funded by Natural Sciences and Engineering Research Council of Canada (NSERC Grant RGPIN-2017-06672), Crohn’s and Colitis Canada (CCC Grant CCC-GEMIII), and Helmsley Charitable Trust. Divya Sharma was supported by NSERC Grant RGPIN-2017-06672 and CCC Grant CCC-GEMIII.</p>
    <p><italic toggle="yes">Financial Support</italic>: none declared.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btaa542_Supplementary_Data</label>
      <media xlink:href="btaa542_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btaa542-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ananthakrishnan</surname><given-names>A.N.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) 
<article-title>Gut microbiome function predicts response to anti-integrin biologic therapy in inflammatory bowel diseases</article-title>. <source>Cell Host Microbe</source>, <volume>21</volume>, <fpage>603</fpage>–<lpage>610</lpage>.<pub-id pub-id-type="pmid">28494241</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B2">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bai</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) Image character recognition using deep convolutional neural network learned from different languages. In <italic toggle="yes">Proceedings of the IEEE International Conference on Image Processing</italic>, pp. <fpage>2560</fpage>–<lpage>2564</lpage>. IEEE.</mixed-citation>
    </ref>
    <ref id="btaa542-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Blaxter</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2005</year>) 
<article-title>Defining operational taxonomic units using DNA barcode data</article-title>. <source>Philos. Trans. R. Soc. B Biol. Sci</source>., <volume>360</volume>, <fpage>1935</fpage>–<lpage>1943</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa542-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bokulich</surname><given-names>N.A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) 
<article-title>q2-sample-classifier: machine-learning tools for microbiome classification and regression</article-title>. <source>J. Open Res. Softw</source>., <volume>3</volume>, <fpage>934</fpage>.<pub-id pub-id-type="pmid">31552137</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gevers</surname><given-names>D.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) 
<article-title>The treatment-naive microbiome in new-onset Crohn’s disease</article-title>. <source>Cell Host Microbe</source>, <volume>15</volume>, <fpage>382</fpage>–<lpage>392</lpage>.<pub-id pub-id-type="pmid">24629344</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B6">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Glorot</surname><given-names>X.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) Deep sparse rectifier neural networks. In <italic toggle="yes">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics</italic>, JMLR, W&amp;CP (15), pp. <fpage>315</fpage>–<lpage>323</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa542-B7">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Goodfellow</surname><given-names>I.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) <source>Deep Learning</source>. 
<publisher-name>MIT Press, Cambridge, MA</publisher-name>.</mixed-citation>
    </ref>
    <ref id="btaa542-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hand</surname><given-names>D.J.</given-names></string-name>, <string-name><surname>Yu</surname><given-names>K.</given-names></string-name></person-group> (<year>2001</year>) 
<article-title>Idiot’s Bayes—not so stupid after all?</article-title>  <source>Int. Stat. Rev</source>., <volume>69</volume>, <fpage>385</fpage>–<lpage>398</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa542-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hansen</surname><given-names>L.K.</given-names></string-name>, <string-name><surname>Salamon</surname><given-names>P.</given-names></string-name></person-group> (<year>1990</year>) 
<article-title>Neural network ensembles</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell</source>., <volume>12</volume>, <fpage>993</fpage>–<lpage>1001</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa542-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hartstra</surname><given-names>A.V.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) 
<article-title>Insights into the role of the microbiome in obesity and type 2 diabetes</article-title>. <source>Diabetes Care</source>, <volume>38</volume>, <fpage>159</fpage>–<lpage>165</lpage>.<pub-id pub-id-type="pmid">25538312</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hoerl</surname><given-names>A.E.</given-names></string-name>, <string-name><surname>Kennard</surname><given-names>R.W.</given-names></string-name></person-group> (<year>1970</year>) 
<article-title>Ridge regression: biased estimation for nonorthogonal problems</article-title>. <source>Technometrics</source>, <volume>12</volume>, <fpage>55</fpage>–<lpage>67</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa542-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jackson</surname><given-names>M.A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) 
<article-title>Gut microbiota associations with common diseases and prescription medications in a population-based cohort</article-title>. <source>Nat. Commun</source>., <volume>9</volume>, <fpage>1</fpage>–<lpage>8</lpage>.<pub-id pub-id-type="pmid">29317637</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Karlsson</surname><given-names>F.H.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2013</year>) 
<article-title>Gut metagenome in European women with normal, impaired and diabetic glucose control</article-title>. <source>Nature</source>, <volume>498</volume>, <fpage>99</fpage>–<lpage>103</lpage>.<pub-id pub-id-type="pmid">23719380</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B14">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Krizhevsky</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) Imagenet classification with deep convolutional neural networks. In: <italic toggle="yes">Advances in Neural Information Processing Systems</italic>, Curran Associates, Inc., NY, US, pp. <fpage>1097</fpage>–<lpage>1105</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa542-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liaw</surname><given-names>A.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2002</year>) 
<article-title>Classification and regression by RandomForest</article-title>. <source>R News</source>, <volume>2</volume>, <fpage>18</fpage>–<lpage>22</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa542-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname><given-names>Z.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2011</year>) 
<article-title>Sparse distance-based learning for simultaneous multiclass classification and feature selection of metagenomic data</article-title>. <source>Bioinformatics</source>, <volume>27</volume>, <fpage>3242</fpage>–<lpage>3249</lpage>.<pub-id pub-id-type="pmid">21984758</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B17">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lo</surname><given-names>C.</given-names></string-name>, <string-name><surname>Marculescu</surname><given-names>R.</given-names></string-name></person-group> (<year>2019</year>) 
<article-title>MetaNN: accurate classification of host phenotypes from metagenomic data using neural networks</article-title>. <source>BMC Bioinformatics</source>, <volume>20</volume>, <pub-id pub-id-type="doi">10.1186/s12859&amp;ndash;019&amp;ndash;2833&amp;ndash;2</pub-id>.</mixed-citation>
    </ref>
    <ref id="btaa542-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nanni</surname><given-names>L.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) 
<article-title>Ensemble of convolutional neural networks for bioimage classification</article-title>. <source>Appl. Comput. Inf</source>., doi: 10.1016/j.aci.2018.06.002.</mixed-citation>
    </ref>
    <ref id="btaa542-B19">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Park</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) Combining multiple sources of knowledge in deep CNNs for action recognition. In Proceedings of IEEE Winter Conference on Applications of Computer Vision, Curran Associates, Inc., NY, US, pp. <fpage>1</fpage>–<lpage>8</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa542-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pasolli</surname><given-names>E.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) 
<article-title>Machine learning meta-analysis of large metagenomic datasets: tools and biological insights</article-title>. <source>PLoS Comput. Biol</source>., <volume>12</volume>, <fpage>e1004977</fpage>.<pub-id pub-id-type="pmid">27400279</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qin</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2012</year>) 
<article-title>A metagenome-wide association study of gut microbiota in type 2 diabetes</article-title>. <source>Nature</source>, <volume>490</volume>, <fpage>55</fpage>–<lpage>60</lpage>.<pub-id pub-id-type="pmid">23023125</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qin</surname><given-names>N.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2014</year>) 
<article-title>Alterations of the human gut microbiome in liver cirrhosis</article-title>. <source>Nature</source>, <volume>513</volume>, <fpage>59</fpage>–<lpage>64</lpage>.<pub-id pub-id-type="pmid">25079328</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rish</surname><given-names>I.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2001</year>) An empirical study of the naive Bayes classifier. In: <italic toggle="yes">IJCAI 2001 Workshop on Empirical Methods in Artificial Intelligence</italic>, Vol. <volume>3</volume>, pp. <fpage>41</fpage>–<lpage>46</lpage>. IBM, New York.</mixed-citation>
    </ref>
    <ref id="btaa542-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ryo</surname><given-names>M.</given-names></string-name>, <string-name><surname>Rillig</surname><given-names>M.C.</given-names></string-name></person-group> (<year>2017</year>) 
<article-title>Statistically reinforced machine learning for nonlinear patterns and variable interactions</article-title>. <source>Ecosphere</source>, <volume>8</volume>, <fpage>e01976</fpage>.</mixed-citation>
    </ref>
    <ref id="btaa542-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schnabl</surname><given-names>B.</given-names></string-name>, <string-name><surname>Brenner</surname><given-names>D.A.</given-names></string-name></person-group> (<year>2014</year>) 
<article-title>Interactions between the intestinal microbiome and liver diseases</article-title>. <source>Gastroenterology</source>, <volume>146</volume>, <fpage>1513</fpage>–<lpage>1524</lpage>.<pub-id pub-id-type="pmid">24440671</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sommer</surname><given-names>F.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) 
<article-title>The resilience of the intestinal microbiota influences health and disease</article-title>. <source>Nat. Rev. Microbiol</source>., <volume>15</volume>, <fpage>630</fpage>–<lpage>638</lpage>.<pub-id pub-id-type="pmid">28626231</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname><given-names>W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) 
<article-title>Computer aided lung cancer diagnosis with deep learning algorithms</article-title>. <source>Med. Imaging 2016 Comput. Aided Diagn</source>., 9785, 97850Z, doi 10.1117/12.2216307.</mixed-citation>
    </ref>
    <ref id="btaa542-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Suykens</surname><given-names>J.A.</given-names></string-name>, <string-name><surname>Vandewalle</surname><given-names>J.</given-names></string-name></person-group> (<year>1999</year>) 
<article-title>Least squares support vector machine classifiers</article-title>. <source>Neural Process. Lett</source>., <volume>9</volume>, <fpage>293</fpage>–<lpage>300</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa542-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tibshirani</surname><given-names>R.</given-names></string-name></person-group> (<year>1996</year>) 
<article-title>Regression shrinkage and selection via the lasso</article-title>. <source>J. R. Stat. Soc. Ser. B (Methodological)</source>, <volume>58</volume>, <fpage>267</fpage>–<lpage>288</lpage>.</mixed-citation>
    </ref>
    <ref id="btaa542-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tsai</surname><given-names>K.-N.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2015</year>) 
<article-title>Inferring microbial interaction network from microbiome data using RMN algorithm</article-title>. <source>BMC Syst. Biol</source>., <volume>9</volume>, <fpage>54</fpage>.<pub-id pub-id-type="pmid">26337930</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B31">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Tsang</surname><given-names>M.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2017</year>) Detecting statistical interactions from neural network weights. <italic toggle="yes">arXiv preprint arXiv : 1705.04977.</italic></mixed-citation>
    </ref>
    <ref id="btaa542-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Turpin</surname><given-names>W.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) 
<article-title>Association of host genome with intestinal microbial composition in a large healthy cohort</article-title>. <source>Nat. Genet</source>., <volume>48</volume>, <fpage>1413</fpage>–<lpage>1417</lpage>.<pub-id pub-id-type="pmid">27694960</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xiao</surname><given-names>J.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2018</year>) 
<article-title>Predictive modeling of microbiome data using a phylogeny-regularized generalized linear mixed model</article-title>. <source>Front. Microbiol</source>., <volume>9</volume>, <fpage>1391</fpage>.<pub-id pub-id-type="pmid">29997602</pub-id></mixed-citation>
    </ref>
    <ref id="btaa542-B34">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Yang</surname><given-names>S.</given-names></string-name></person-group>  <etal>et al</etal> (<year>2016</year>) Wider face: a face detection benchmark. In: <italic toggle="yes">IEEE conference on Computer Vision and Pattern Recognition</italic>, Institute of Electrical and Electronics Engineers, Inc., NJ, US, pp. <fpage>5525</fpage>–<lpage>5533</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
