<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PeerJ</journal-id>
    <journal-id journal-id-type="iso-abbrev">PeerJ</journal-id>
    <journal-id journal-id-type="pmc">PeerJ</journal-id>
    <journal-id journal-id-type="publisher-id">PeerJ</journal-id>
    <journal-title-group>
      <journal-title>PeerJ</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2167-8359</issn>
    <publisher>
      <publisher-name>PeerJ Inc.</publisher-name>
      <publisher-loc>San Diego, USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6371918</article-id>
    <article-id pub-id-type="publisher-id">6398</article-id>
    <article-id pub-id-type="doi">10.7717/peerj.6398</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Biodiversity</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Evolutionary Studies</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Statistics</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Quantitative color profiling of digital images with earth mover’s distance using the R package colordistance</article-title>
    </title-group>
    <contrib-group>
      <contrib id="author-1" contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-5252-4282</contrib-id>
        <name>
          <surname>Weller</surname>
          <given-names>Hannah I.</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
        <xref ref-type="aff" rid="aff-2">2</xref>
        <email>hannah_weller@brown.edu</email>
      </contrib>
      <contrib id="author-2" contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-3548-7002</contrib-id>
        <name>
          <surname>Westneat</surname>
          <given-names>Mark W.</given-names>
        </name>
        <xref ref-type="aff" rid="aff-1">1</xref>
      </contrib>
      <aff id="aff-1"><label>1</label><institution>Department of Organismal Biology and Anatomy, University of Chicago</institution>, <addr-line>Chicago, IL</addr-line>, <country>USA</country></aff>
      <aff id="aff-2"><label>2</label><institution>Department of Ecology and Evolutionary Biology, Brown University</institution>, <addr-line>Providence, RI</addr-line>, <country>USA</country></aff>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Williams</surname>
          <given-names>Suzanne</given-names>
        </name>
      </contrib>
    </contrib-group>
    <pub-date pub-type="epub" date-type="pub" iso-8601-date="2019-02-06">
      <day>6</day>
      <month>2</month>
      <year iso-8601-date="2019">2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>7</volume>
    <elocation-id>e6398</elocation-id>
    <history>
      <date date-type="received" iso-8601-date="2018-02-05">
        <day>5</day>
        <month>2</month>
        <year iso-8601-date="2018">2018</year>
      </date>
      <date date-type="accepted" iso-8601-date="2019-01-03">
        <day>3</day>
        <month>1</month>
        <year iso-8601-date="2019">2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2019 Weller and Westneat</copyright-statement>
      <copyright-year>2019</copyright-year>
      <copyright-holder>Weller and Westneat</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, reproduction and adaptation in any medium and for any purpose provided that it is properly attributed. For attribution, the original author(s), title, publication source (PeerJ) and either DOI or URL of the article must be cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="https://peerj.com/articles/6398"/>
    <abstract>
      <p>Biological color may be adaptive or incidental, seasonal or permanent, species- or population-specific, or modified for breeding, defense or camouflage. Although color is a hugely informative aspect of biology, quantitative color comparisons are notoriously difficult. Color comparison is limited by categorization methods, with available tools requiring either subjective classifications, or expensive equipment, software, and expertise. We present an R package for processing images of organisms (or other objects) in order to quantify color profiles, gather color trait data, and compare color palettes on the basis of color similarity and amount. The package treats image pixels as 3D coordinates in a “color space,” producing a multidimensional color histogram for each image. Pairwise distances between histograms are computed using earth mover’s distance, a technique borrowed from computer vision, that compares histograms using transportation costs. Users choose a color space, parameters for generating color histograms, and a pairwise comparison method to produce a color distance matrix for a set of images. The package is intended as a more rigorous alternative to subjective, manual digital image analyses, not as a replacement for more advanced techniques that rely on detailed spectrophotometry methods unavailable to many users. Here, we outline the basic functions of colordistance, provide guidelines for the available color spaces and quantification methods, and compare this toolkit with other available methods. The tools presented for quantitative color analysis may be applied to a broad range of questions in biology and other disciplines.</p>
    </abstract>
    <kwd-group kwd-group-type="author">
      <kwd>R packages</kwd>
      <kwd>Color</kwd>
      <kwd>Image processing</kwd>
      <kwd>Phylogenetics</kwd>
      <kwd>Camouflage</kwd>
      <kwd>Earth mover’s distance</kwd>
      <kwd>Statistics</kwd>
    </kwd-group>
    <funding-group>
      <award-group id="fund-1">
        <funding-source>NSF</funding-source>
        <award-id>IOS 1425049 and DEB 1541547</award-id>
      </award-group>
      <funding-statement>This research was supported by NSF grants IOS 1425049 and DEB 1541547 to Mark Westneat. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
  </article-meta>
</front>
<body>
  <sec sec-type="intro">
    <title>Introduction</title>
    <p>Color is an information-rich trait, and has provided countless insights in biology, including into camouflage, mimicry, pollination, signaling, mate attraction, pathogen infection, and thermoregulation (<xref rid="ref-12" ref-type="bibr">Cuthill et al., 2017</xref>; <xref rid="ref-25" ref-type="bibr">Liu &amp; Nizet, 2009</xref>; <xref rid="ref-11" ref-type="bibr">Clegg &amp; Durbin, 2000</xref>; <xref rid="ref-46" ref-type="bibr">Smith &amp; Goldberg, 2015</xref>; <xref rid="ref-44" ref-type="bibr">Smith et al., 2016</xref>; <xref rid="ref-5" ref-type="bibr">Bechtel, Rivard &amp; Sánchez-Azofeifa, 2002</xref>; <xref rid="ref-23" ref-type="bibr">Lev-Yadun et al., 2004</xref>; <xref rid="ref-32" ref-type="bibr">Pérez-De la Fuente et al., 2012</xref>; <xref rid="ref-47" ref-type="bibr">Stevens, Lown &amp; Wood, 2014</xref>; <xref rid="ref-10" ref-type="bibr">Chiao et al., 2011</xref>; <xref rid="ref-7" ref-type="bibr">Brady et al., 2015</xref>; <xref rid="ref-49" ref-type="bibr">Troscianko et al., 2016</xref>). Unlike many other informative traits, collecting color information can be minimally invasive, and can be done with inexpensive, commercially available digital cameras. Although the resulting digital images are intended to mimic human vision, appropriate calibration and an understanding of these limitations can allow scientists to answer a much wider range of questions with this simpler data format (<xref rid="ref-48" ref-type="bibr">Troscianko &amp; Stevens, 2015</xref>).</p>
    <p>Despite the questions surrounding the role of coloration in ecological and evolutionary processes, color is notoriously difficult to categorize. Classifications are often subjective, especially when trying to compare organisms with highly variable appearances. Any objective categorization must account for the amount, distribution, classification, and variety of colors consistently across a set of images. Researchers must also account for the limits of using digital images to answer questions about the visual systems of non-human animals. Common approaches to color profiling often address one or several of these problems, and include qualitative categorization (<xref rid="ref-35" ref-type="bibr">Puebla, Bermingham &amp; Whiteman, 2007</xref>), analysis of digital photographs using pixel color spectra (<xref rid="ref-8" ref-type="bibr">Byers, 2006</xref>), binary character matrices scoring color presence (<xref rid="ref-28" ref-type="bibr">Marshall et al., 2003</xref>), and quantitative point spectrophotometry (<xref rid="ref-3" ref-type="bibr">Badiane et al., 2017</xref>; <xref rid="ref-40" ref-type="bibr">Safran &amp; Mcgraw, 2004</xref>; <xref rid="ref-28" ref-type="bibr">Marshall et al., 2003</xref>). Generally, more comprehensive methods require expensive equipment, expertise, and coding skills, while more straightforward methods are tailored for specific studies, giving them a more limited scope.</p>
    <p>Recently, software toolboxes have been gaining popularity as accessible, comprehensive, and consistent methods for image analysis (<xref rid="ref-48" ref-type="bibr">Troscianko &amp; Stevens, 2015</xref>; <xref rid="ref-6" ref-type="bibr">Bradski, 2000</xref>), including a number of R packages. R is among the most popular coding languages for biologists, partly because it is user-friendly and open-source. Although there are several R packages designed for digital image analysis (<xref rid="ref-53" ref-type="bibr">Van Belleghem et al., 2017</xref>; <xref rid="ref-27" ref-type="bibr">Maia et al., 2013</xref>; <xref rid="ref-4" ref-type="bibr">Barthelme, 2017</xref>; <xref rid="ref-9" ref-type="bibr">Carlson, 2016</xref>), to our knowledge, none of them provide methods for profiling and quantitatively comparing colors across images in multiple color spaces.</p>
    <p>Here, we present a quantitative approach to color profiling and comparison with digital images in an R package, colordistance, which provides a viable, statistically rigorous option for color profiling and comparison in a user-friendly format (<xref rid="ref-36" ref-type="bibr">R Core Team, 2018</xref>). Although the standard red-green-blue (RGB) format of digital images is a poor proxy for non-human vision (<xref rid="ref-55" ref-type="bibr">Vorobyev et al., 2001</xref>; <xref rid="ref-14" ref-type="bibr">Endler, 2012</xref>; <xref rid="ref-48" ref-type="bibr">Troscianko &amp; Stevens, 2015</xref>), appropriate image calibration and color space conversion can still provide meaningful biological insights with a lower barrier to entry than spectrophotometric methods, and can reflect the visual sensitivities of many species (<xref rid="ref-26" ref-type="bibr">Losey et al., 2003</xref>; <xref rid="ref-28" ref-type="bibr">Marshall et al., 2003</xref>).</p>
    <p>Colordistance provides an objective comparative tool for any color analysis that might otherwise rely on a more subjective classification scheme. The package also comes with a pipeline function for streamlined analysis. The central aims of this method are (1) to enable the user to quickly quantify colors in images of organisms (or other objects), (2) to provide tools for categorizing diverse color palettes into bins of similar colors and quantify their extent on a surface, and (3) to develop approaches for color profile comparison and assessment of “color distance,” a metric that borrows techniques from computational image processing to measure the difference in color between objects (<xref rid="ref-59" ref-type="bibr">Zhang, Barhomi &amp; Serre, 2012</xref>; <xref rid="ref-8" ref-type="bibr">Byers, 2006</xref>; <xref rid="ref-33" ref-type="bibr">Phung et al., 2005</xref>; <xref rid="ref-41" ref-type="bibr">Scheunders, 1997</xref>). Colordistance is not meant to replace more comprehensive methods of color comparison, but to provide a more objective, consistent, and easy-to-use alternative to manual classifications. It can also be used to supplement other methods that address different aspects of color diversity in organisms.</p>
  </sec>
  <sec sec-type="materials|methods">
    <title>Materials and Methods</title>
    <sec>
      <title>Package details</title>
      <p>Colordistance includes 29 exported functions, the most central of which are listed in <xref rid="table-1" ref-type="table">Table 1</xref>. Colordistance imports or suggests R packages for image analysis and data clustering, including jpeg (<xref rid="ref-51" ref-type="bibr">Urbanek, 2014</xref>), png (<xref rid="ref-50" ref-type="bibr">Urbanek, 2013</xref>), clue (<xref rid="ref-19" ref-type="bibr">Hornik, 2005</xref>), spatstat (<xref rid="ref-2" ref-type="bibr">Baddeley, Rubak &amp; Turner, 2015</xref>), ape (<xref rid="ref-31" ref-type="bibr">Paradis, Claude &amp; Strimmer, 2004</xref>), mgcv (<xref rid="ref-57" ref-type="bibr">Wood, 2011</xref>), emdist (<xref rid="ref-52" ref-type="bibr">Urbanek &amp; Rubner, 2012</xref>), scatterplot3d (<xref rid="ref-24" ref-type="bibr">Liggs &amp; Mächler, 2003</xref>), plotly (<xref rid="ref-43" ref-type="bibr">Sievert et al., 2017</xref>), gplots (<xref rid="ref-56" ref-type="bibr">Warnes et al., 2016</xref>), and abind (<xref rid="ref-34" ref-type="bibr">Plate &amp; Heiberger, 2016</xref>).</p>
      <table-wrap id="table-1" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.6398/table-1</object-id>
        <label>Table 1</label>
        <caption>
          <title>Primary colordistance functions and descriptions.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="peerj-07-6398-g007"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col span="1"/>
              <col span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Function</th>
                <th rowspan="1" colspan="1">Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">
                  <monospace>loadImage</monospace>
                </td>
                <td rowspan="1" colspan="1">Import image as 3D array and generate filtered 2D pixel array(s) of non-masked objects</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <monospace>convertColorSpace</monospace>
                </td>
                <td rowspan="1" colspan="1">Convert pixels between different color spaces (CIE Lab, RGB, and HSV)</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <monospace>plotPixels</monospace>
                </td>
                <td rowspan="1" colspan="1">Plot pixels from an image in color space</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><monospace>getImageHist</monospace> and <monospace>getHistList</monospace></td>
                <td rowspan="1" colspan="1">Generate a 3D histogram based on color distribution in an image (or list of histograms for a set of images)</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1"><monospace>getKMeanColors</monospace> and <monospace>getKMeansList</monospace></td>
                <td rowspan="1" colspan="1">Generate color clusters using k-means clustering for an image (or list of clusters for a set of images)</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <monospace>combineList</monospace>
                </td>
                <td rowspan="1" colspan="1">Combine a list of cluster features into a single cluster set</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <monospace>getColorDistanceMatrix</monospace>
                </td>
                <td rowspan="1" colspan="1">Generate a distance matrix for a list of color histograms or cluster sets</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <monospace>imageClusterPipeline</monospace>
                </td>
                <td rowspan="1" colspan="1">Generate and plot a color distance matrix from a set of images</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>A stable distribution of the colordistance package can be downloaded for free at <uri xlink:href="https://CRAN.R-project.org/package=colordistance">https://CRAN.R-project.org/package=colordistance</uri>, and the development version and installation instructions can be found at <uri xlink:href="https://github.com/hiweller/colordistance">https://github.com/hiweller/colordistance</uri>, along with a forum for user feedback and suggestions. A series of explanatory vignettes providing more detailed explanations and examples is available at the corresponding GitHub Pages site, <uri xlink:href="https://hiweller.github.io/colordistance/">https://hiweller.github.io/colordistance/</uri>. Questions or issues can be posted on <uri xlink:href="https://github.com/hiweller/colordistance/issues">https://github.com/hiweller/colordistance/issues</uri>.</p>
      <p>The CRAN version of the package can be installed by running the following line of code in the R console:</p>
      <p>
        <code language="java" position="float" orientation="portrait" xml:space="preserve">&gt; install.packages(<styled-content style="color:#9400D1">“colordistance”)</styled-content>    1</code>
      </p>
      <p>The main work flow of colordistance consists of three steps:
<list list-type="order"><list-item><p><italic>Image preparation.</italic> Quality color images (JPEG or PNG) of the object(s) of interest are obtained, color calibrated, and backgrounds are masked out with a uniform color, using an image editor outside of the R environment. See below for a discussion of image calibration.</p></list-item><list-item><p><italic>Color binning.</italic> Images are read into R as 3D arrays, and non-background pixels are binned into color categories via one of two provided binning methods to produce a normalized color space histogram.</p></list-item><list-item><p><italic>Histogram comparisons.</italic> Earth mover’s distance (EMD) (<xref rid="ref-38" ref-type="bibr">Rubner &amp; Tomasi, 2013</xref>) or another metric is used for pairwise comparisons of histograms from a set of images, resulting in a distance matrix summarizing the color distance score between each pair of images.</p></list-item></list></p>
      <p>The most important user-specifiable parameters for the analysis are provided in <xref rid="table-2" ref-type="table">Table 2</xref>.</p>
      <table-wrap id="table-2" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.6398/table-2</object-id>
        <label>Table 2</label>
        <caption>
          <title>User-specifiable parameters in colordistance analyses.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="peerj-07-6398-g008"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Parameter</th>
                <th rowspan="1" colspan="1">Function</th>
                <th rowspan="1" colspan="1">Options</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">Color space</td>
                <td rowspan="1" colspan="1">One of three common three-component color spaces used in digital images</td>
                <td rowspan="1" colspan="1">CIE Lab, red-green-blue (RGB) or hue-saturation-value (HSV)</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Background color</td>
                <td rowspan="1" colspan="1">Color(s) to be ignored in analysis</td>
                <td rowspan="1" colspan="1">Any color range specified by the user</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Binning method</td>
                <td rowspan="1" colspan="1">Method for grouping pixels in organism/object into bins to summarize and compare images</td>
                <td rowspan="1" colspan="1">Color histogram or k-means clustering</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Bins</td>
                <td rowspan="1" colspan="1">How to divide up color space so that pixels assigned to the same bin are grouped into one color</td>
                <td rowspan="1" colspan="1">Either a number of bins per color space channel (if using color histogram) or a total number of clusters (if using k-means clustering)</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Color distance metric</td>
                <td rowspan="1" colspan="1">Method for calculating the distance between one binned image and another</td>
                <td rowspan="1" colspan="1">Earth mover’s distance, χ<sup>2</sup> distance, Euclidean color distance, or a weighted combination</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec>
      <title>Image preparation and calibration</title>
      <p>Digital cameras are an accessible, affordable, and non-invasive method of data collection. The resulting images, however, are optimized for human vision and for display on commercial RGB monitors. The actual spectral reflectance of the photographed object is therefore distorted in a digital image. Accurate image calibration, including white balance, radiance normalization, and converting to the color sensitivities of non-human animals, is an essential step before image analysis. A comprehensive discussion of image calibration is beyond the scope of this paper, but see <xref rid="ref-48" ref-type="bibr">Troscianko &amp; Stevens (2015)</xref>, <xref rid="ref-8" ref-type="bibr">Byers (2006)</xref>, <xref rid="ref-15" ref-type="bibr">Endler &amp; Mielke (2005)</xref> and <xref rid="ref-42" ref-type="bibr">Schindelin et al. (2012)</xref>.</p>
      <p>Because colordistance does not include image calibration tools, images should be calibrated before being analyzed in R. There are a variety of tools available for image calibration, including simple white-balance correction in most image editing applications. The image calibration and analysis ImageJ toolbox by <xref rid="ref-48" ref-type="bibr">Troscianko &amp; Stevens (2015)</xref> allows users to not only calibrate images, but also to correct for the non-linearity of RGB images and to incorporate ultraviolet (UV) channels to simulate animal color vision; the plug-in is free and comes with a comprehensive guide for users with camera RAW images.</p>
      <p>Background masking is the last step of image preparation. Any part of an image that the user wants to ignore should be masked out with a uniform background color that is not similar to any of the colors in the object itself; the examples below use bright green (RGB triplet of (0, 1, 0) on a 0–1 scale) and white (RGB triplet of (1, 1, 1)). This can be accomplished with Photoshop, ImageJ, or other image editing software.</p>
    </sec>
    <sec>
      <title>Color spaces, binning methods, and distance metrics</title>
      <p>No universal set of parameters will produce optimal results for all datasets. Instead, colordistance provides several options for each step of an analysis (<xref rid="table-1" ref-type="table">Table 1</xref>). The functions come with defaults that act as useful starting points, but understanding how each parameter will affect the outcome is crucial for accurately interpreting results. See Discussion for suggestions on when to use which options.</p>
      <sec>
        <title>Color space</title>
        <p>The three available color spaces in colordistance are CIE Lab (luminance, red-green, and blue-yellow channels), RGB (red, green, and blue channels), and HSV (hue, saturation, and value channels). The advantages and disadvantages of each color space are discussed more thoroughly both in the discussion and in the “Color Spaces” vignette that comes with the package (also accessible on the CRAN repository).</p>
        <p>Briefly, CIE Lab is a perceptually uniform, device-independent color space, meaning that Euclidean distances between colors in CIE Lab-space reflect the degree of perceived difference between those colors in human color vision. RGB is also modeled on human color vision, but is not perceptually uniform, and is largely optimized for digital displays. HSV color space is intended largely for color manipulation and is not modeled on perception, but is useful for image segmentation for analyses that are not concerned with replicating animal color vision (<xref rid="ref-18" ref-type="bibr">Hill, Roger &amp; Vorhagen, 1997</xref>). <xref ref-type="fig" rid="fig-1">Figure 1</xref> illustrates how standard RGB pixels are distributed very differently in RGB and CIE Lab color spaces. In colordistance, RGB color space is set as the default color space, but RGB analyses come with warnings about perceptual non-uniformity to encourage users to read about and implement CIE Lab analyses instead.</p>
        <fig id="fig-1" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.6398/fig-1</object-id>
          <label>Figure 1</label>
          <caption>
            <title>RGB colors as displayed in RGB and CIE Lab color spaces.</title>
            <p>(A–D) A total of 100,000 random RGB pixels as displayed and clustered in RGB space. (A) and (B) Pixels plotted in RGB space, viewed from different angles; (C) clustering results for binning pixels into 27 equally spaced bins; (D) histogram representation of the clusters in C. (E–H) Same as (A–D) but in CIE Lab rather than RGB space.</p>
          </caption>
          <graphic xlink:href="peerj-07-6398-g001"/>
        </fig>
      </sec>
      <sec>
        <title>Binning methods</title>
        <p>The two methods for binning pixels, histogram and <italic>k</italic>-means clustering, are fairly common approaches to cluster analysis. Briefly, <italic>k</italic>-means clustering partitions pixels in color space into a specified number of bins in order to minimize the overall sum of pixel-center distances. Though popular, this method can be fairly slow and the cluster locations will be biased toward dominant colors. The histogram method (default) divides a 3D color space into regions depending on user-specified boundaries, computes the proportion of pixels and average pixel value in each region to produce a 3D histogram whose bin centers will vary from image to image. This method is typically faster and not biased by color proportions, but risks breaking up a single color cluster across multiple boundaries.</p>
        <p>The <italic>a</italic> and <italic>b</italic> channels of CIE Lab color space are theoretically unbounded, but in practice, RGB colors converted to CIE Lab space have <italic>a</italic> and <italic>b</italic> values between −128 and 127 (<xref rid="ref-18" ref-type="bibr">Hill, Roger &amp; Vorhagen, 1997</xref>); these are used as the upper and lower bounds for each channel unless otherwise specified.</p>
      </sec>
      <sec>
        <title>Distance metrics</title>
        <p>Colordistance includes four color distance metrics, but the most comprehensive is the earth mover’s distance (EMD). The EMD or Wasserstein metric measures the distance between two distributions as a transport cost—essentially, what is the minimum cost of transforming one distribution into the other (<xref rid="ref-39" ref-type="bibr">Rubner, Tomasi &amp; Guibas, 2000</xref>)? It takes into account both spatial color information and size information. For colordistance, when using RGB color space, EMD also has the advantage of having a consistent lower and upper bound. The maximum EMD score in RGB space is <inline-formula><alternatives><inline-graphic xlink:href="peerj-07-6398-i001.jpg"/><tex-math id="M1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\sqrt 3 $\end{document}</tex-math><mml:math id="mml-ieqn-1"><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>, which is the cost of moving all of the data (<italic>p</italic> = 1) as far as possible across RGB or HSV color space (the diagonal of a cube with sides of length 1). χ<sup>2</sup> distance also performs well in many cases, but treats bins as independent of each other, so it can result in higher color distances when images have similar colors that are binned differently (i.e., an all-black and all-gray image will have the same distance as an all-black and all-white image). EMD is therefore the default. Other distance metrics are discussed in the “Distance metrics” vignette, which comes with the package or can be found at <uri xlink:href="https://cran.r-project.org/web/packages/colordistance/vignettes/color-metrics.html">https://cran.r-project.org/web/packages/colordistance/vignettes/color-metrics.html</uri>.</p>
      </sec>
    </sec>
    <sec>
      <title>Implementation</title>
      <p>All examples in this paper can be reproduced by cloning the colordistance_examples GitHub repository (<uri xlink:href="http://github.com/hiweller/colordistance_examples">http://github.com/hiweller/colordistance_examples</uri>) and setting the R working directory to that folder. Lines preceded by “&gt;” indicate commands executed in the R console.</p>
      <p>
        <code language="java" position="float" orientation="portrait" xml:space="preserve">&gt; library(colordistance)            1
 &gt; setwd(<styled-content style="color:#9400D1">“[path/to/directory]/Examples”</styled-content>)   2</code>
      </p>
      <p><xref ref-type="fig" rid="fig-2">Figure 2</xref> illustrates how the package handles a single image. Prior to loading the image into colordistance, the background of the photograph has been masked out using pure green, which has an RGB triplet of (0, 1, 0) (<xref ref-type="fig" rid="fig-2">Fig. 2A</xref>). The <monospace>plotPixels</monospace> function can be used to visualize the distribution of the flower’s colors in CIE Lab color space. In order to plot the flower in CIE Lab color space (<xref ref-type="fig" rid="fig-2">Fig. 2B</xref>), we provide <monospace>plotPixels</monospace> with: (1) the path to the background-masked image, (2) lower and upper bounds for RGB pixels to ignore, (3) the color space in which to plot, and (4) the name of a standard reference white for RGB to CIE Lab conversion, since the image is stored in an RGB format.</p>
      <fig id="fig-2" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.6398/fig-2</object-id>
        <label>Figure 2</label>
        <caption>
          <title>Color binning of a single object.</title>
          <p>(A) Image of a flower with a background mask of bright green pixels (RGB triplet value (0, 1, 0)); (B) 3D scatterplot of all non-background pixels in CIE Lab color space using plotPixels function; (C) clusters from the histogram in (B) displayed in CIE Lab color space; (D) histogram from getLabHist function showing the proportion of total non-background pixels assigned to each of eight bins, with the color ranges of the bins on the <italic>X</italic> axis. The vertical lines in D indicate the <italic>X</italic> and <italic>Y</italic> (Luminance and a channel) positions of each cluster; the size of each cluster has been increased by 3% so that the locations of empty clusters are still visible. Bins in (C) and (D) have been colored by the average color of the pixels in each bin. Photo credit: H. Weller.</p>
        </caption>
        <graphic xlink:href="peerj-07-6398-g002"/>
      </fig>
      <p>
        <code language="java" position="float" orientation="portrait" xml:space="preserve">&gt; plotPixels(<styled-content style="color:#9400D1">“Flower/flower_greenscreen.jpg”</styled-content>,            1
     lower = c(0, 0.6, 0), upper = c(0.4, 1, 0.4),       2
     color.space = <styled-content style="color:#9400D1">“lab”</styled-content>, ref.white = <styled-content style="color:#9400D1">“D65”</styled-content>)           3</code>
      </p>
      <p>The lower and upper arguments passed to plotPixels are the lower and upper bounds for background pixels; any pixel with 0 ≤ R ≤ 0.4, 0.6 ≤ G ≤ 1, and 0 ≤ B ≤ 0.4 will be ignored.</p>
      <p>The <monospace>getLabHist</monospace> function sorts each non-background pixel in the image into a bin, with boundaries defined by the <monospace>bins</monospace> argument. Line 1 uses two bins per channel, meaning each of the luminance, <italic>a</italic> (red-green), and <italic>b</italic> (blue-yellow) channels is divided at the halfway point, resulting in 2<sup>3</sup> = 8 bins. The <monospace>a.bounds</monospace> and <monospace>b.bounds</monospace> arguments bound the <italic>a</italic> and <italic>b</italic> channels at −100 and 100, rather than −128 and 127. These bounds were chosen because none of the pixels in the image fall outside of these bounds, and narrowing the upper and lower limits reduces the number of empty bins.</p>
      <p>
        <code language="java" position="float" orientation="portrait" xml:space="preserve">&gt; image_histogram &lt;- getLabHist(<styled-content style="color:#9400D1">“Flower/flower_greenscreen.jpg”</styled-content>,    1
   lower = c(0, 0.6, 0), upper = c(0.4, 1, 0.4),      2
    a.bounds = c(-100, 100), b.bounds = c(-100, 100),  3
    bins = c(2, 2, 2), plotting = TRUE, ref.white = <styled-content style="color:#9400D1">“D65”</styled-content>)      4</code>
      </p>
      <p>Binning the pixels produces a three-dimensional histogram, with the location of each bin determined by the average value of the pixels in that bin, and the size determined by the proportion of total pixels in the bin, ranging from 0 to 1. <xref ref-type="fig" rid="fig-2">Figure 2C</xref> illustrates the relative size and location of each bin in CIE Lab space, while 2D is the diagnostic histogram produced by <monospace>getLabHist</monospace>. Each histogram bin represents one of the spheres in 2C.</p>
      <p>
        <code language="java" position="float" orientation="portrait" xml:space="preserve">&gt; print(image_histogram)      1
  L  a  b  Pct          2
1 25.00 -64.25 -64.25 0.00     3
2 75.00 -64.25 -64.25 0.00     4
3 31.46 21.93 -2.78 0.01      5
4 54.81 23.00 -6.52 0.00      6
5 40.14 -6.82 40.77 0.00      7
6 74.86 -26.66 68.94 0.01      8
7 23.72 13.98 18.18 0.15      9
8 77.16 11.82 77.82 0.82      10</code>
      </p>
      <p>The first three columns in the resulting R dataframe represent the average color coordinates of all pixels in a bin; if no pixels were assigned to that bin (as in bins 1, 2, 4, and 5), the center of the bin is used. The last column, percent, represents the proportion of pixels assigned to that bin. For example, the yellow petals of the flower, which fall into bin 8, have a high average luminance (<italic>L</italic> = 77.16 on a 0–100 scale), don’t skew particularly red or green in the <italic>a</italic> (red-green) channel (11.82 on a −100–100 scale), and are much more toward the yellow end of the <italic>b</italic> (blue-yellow) channel (77.82 on a −100–100 scale). They also make up 82% of the image. Histograms are generated for every provided image and a pairwise distance matrix is computed for the image set, providing a quantitative measure of color palette similarities.</p>
    </sec>
    <sec>
      <title>Comparison with patternize</title>
      <p>We analyzed the same set of images with colordistance and patternize (<xref rid="ref-53" ref-type="bibr">Van Belleghem et al., 2017</xref>) to illustrate the differences between the two packages. Wherever possible, we chose options in patternize that were comparable to the methods provided by colordistance in order to provide a reasonable basis for comparison. Because the dataset in question (images of five species of parrotfishes) have substantial variety in color, pattern, and body shape, we used landmark alignment rather than Procrustes alignment of patterns to align the images.</p>
      <p>Because all of our images were lateral views of the fish, we chose 11 homologous landmarks for alignment in patternize: (1) the center of the eye; (2)–(3) the bases of the first and last fin rays of the dorsal fin; (4)–(6) the bases of the dorsal, midline, and ventral fin rays of the caudal fin where they meet the caudal peduncle; (7)–(10) the bases of the first and last fin rays of the anal and pelvic fins; (11) the anterior tip of the lower jaw. Landmark locations expressed as pixel coordinates for each image were stored as text files, and the backgrounds of the images themselves were masked out with white.</p>
      <p>To perform pattern analyses, patternize requires either the specification of an RGB triplet with which to define a pattern or the use of <italic>k</italic>-means clustering to find patterns automatically. <italic>K</italic>-means clustering does not necessarily return a set of colors that are comparable across images, since not all images in the dataset share a color palette, so we chose to manually specify RGB colors. Colors were chosen by selecting patches of a given color in an image and finding the average RGB value, then adjusting the color offset (i.e., allowed deviance from the specified color) until the full color pattern appeared to be captured for each image.</p>
      <p>The chosen colors were green-blue (RGB: 0.08, 0.47, 0.43), orange (RGB: 0.78, 0.47, 0.31), pink (RGB: 0.82, 0.59, 0.57), and brown (0.57, 0.49, 0.33). The <monospace>patLanRGB</monospace> function was called for the images for each color, and principal component analysis was performed using patternize’s <monospace>patPCA</monospace> function. To combine the four sets of PCA results into a single distance matrix for comparison with colordistance, the distance between each pair of images for each color was found by measuring the Euclidean distance between each pair of principal component scores, and the values of the distance matrices were then averaged to produce the final set of similarity scores.</p>
      <p>To analyze the same dataset in colordistance, images were analyzed in CIE Lab colorspace with a D65 reference white. The <italic>a</italic>- and <italic>b</italic>-channel ranges were restricted to the range exhibited by the images themselves (see example 2, below), but otherwise, default parameters were used.</p>
    </sec>
  </sec>
  <sec sec-type="results">
    <title>Results</title>
    <sec>
      <title>Benchmarking</title>
      <sec>
        <title>Earth mover’s distance</title>
        <p>We created two simple image sets with known RGB values and proportions (<xref ref-type="fig" rid="fig-3">Fig. 3</xref>) to test whether the colordistance application of EMD provides scores that accurately reflect the amount and similarities of colors across images. The first set (<xref ref-type="fig" rid="fig-3">Figs. 3A</xref>–<xref ref-type="fig" rid="fig-3">3E</xref>) varies the relative proportions of two colors, cyan (RGB triplet of 0, 1, 1) and red (1, 0, 0), and was designed to test whether the distance scores provided by colordistance reflect the differences in the quantities of colors in an image set. The second set (<xref ref-type="fig" rid="fig-3">Figs. 3F</xref>–<xref ref-type="fig" rid="fig-3">3J</xref>) samples a gradient from blue (0, 0, 1) to yellow (1, 1, 0), and was designed to test whether scores reflect the relative similarities of colors in an image set. The pipeline function (<xref rid="table-1" ref-type="table">Table 1</xref> and see below) was used to test each set in both RGB and CIE Lab color spaces:</p>
        <fig id="fig-3" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.6398/fig-3</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Artificial color images for testing colordistance’s ability to discriminate color quantity (A–E) and color similarity (F–J).</title>
            <p>RGB triplets are given in the lower left-hand corners. (A–E) Varies the relative amounts of red and cyan in each square: (A) Completely cyan; (B) <inline-formula><alternatives><inline-graphic xlink:href="peerj-07-6398-i002.jpg"/><tex-math id="M2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${3 \over 4}$\end{document}</tex-math><mml:math id="mml-ieqn-2"><mml:mrow><mml:mfrac><mml:mn>3</mml:mn><mml:mn>4</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> cyan, <inline-formula><alternatives><inline-graphic xlink:href="peerj-07-6398-i003.jpg"/><tex-math id="M3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${1 \over 4}$\end{document}</tex-math><mml:math id="mml-ieqn-3"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> red; (C) <inline-formula><alternatives><inline-graphic xlink:href="peerj-07-6398-i004.jpg"/><tex-math id="M4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${1 \over 2}$\end{document}</tex-math><mml:math id="mml-ieqn-4"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> of each color; (D) <inline-formula><alternatives><inline-graphic xlink:href="peerj-07-6398-i005.jpg"/><tex-math id="M5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${3 \over 4}$\end{document}</tex-math><mml:math id="mml-ieqn-5"><mml:mrow><mml:mfrac><mml:mn>3</mml:mn><mml:mn>4</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> red, <inline-formula><alternatives><inline-graphic xlink:href="peerj-07-6398-i006.jpg"/><tex-math id="M6">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${1 \over 4}$\end{document}</tex-math><mml:math id="mml-ieqn-6"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> cyan; (E) completely red. (F–J) Varies the entire square color on a blue-yellow gradient. Note that for each set, the extremes (A), (E), (F), and (J) are on opposite ends of RGB color space.</p>
          </caption>
          <graphic xlink:href="peerj-07-6398-g003"/>
        </fig>
        <p>
          <code language="java" position="float" orientation="portrait" xml:space="preserve">&gt; imageClusterPipeline(<styled-content style="color:#9400D1">‘Benchmark/Color_quantity’</styled-content>,                   1
          color.space = <styled-content style="color:#9400D1">“rgb”</styled-content>, distance.method = <styled-content style="color:#9400D1">“emd”</styled-content>)            2
&gt; imageClusterPipeline(<styled-content style="color:#9400D1">‘Benchmark/Color_quantity’</styled-content>,                   3
          color.space = <styled-content style="color:#9400D1">“lab”</styled-content>, ref.white = <styled-content style="color:#9400D1">“D65”</styled-content>, distance.method = <styled-content style="color:#9400D1">“emd”</styled-content>) 4
&gt; imageClusterPipeline(<styled-content style="color:#9400D1">‘Benchmark/Color_similarity/’</styled-content>,                  5
          color.space = <styled-content style="color:#9400D1">“rgb”</styled-content>, distance.method = <styled-content style="color:#9400D1">“emd”</styled-content>)            6
&gt; imageClusterPipeline(<styled-content style="color:#9400D1">‘Benchmark/Color_similarity/’</styled-content>,                  7
          color.space = <styled-content style="color:#9400D1">“lab”</styled-content>, ref.white = <styled-content style="color:#9400D1">“D65”</styled-content>, distance.method = <styled-content style="color:#9400D1">“emd”</styled-content>) 8</code>
        </p>
        <p>Distance matrices using EMD were calculated for both RGB space and CIE Lab space. Because RGB space is a cube with sides of length 1, the maximum EMD score should be the length of the diagonal of the cube <inline-formula><alternatives><inline-graphic xlink:href="peerj-07-6398-i007.jpg"/><tex-math id="M7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$(\sqrt 3)$\end{document}</tex-math><mml:math id="mml-ieqn-7"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> multiplied by the maximum proportion of pixels that can be separated by this distance (<italic>p</italic> = 1). RGB space was used here, because it has a known maximum score in EMD. CIE Lab space cannot be scaled universally, partly because the maximum score will depend on the conversion parameters, and partly because the shape occupied by visible colors in CIE Lab space is asymmetrical (<xref ref-type="fig" rid="fig-1">Figs. 1E</xref> and <xref ref-type="fig" rid="fig-1">1F</xref>). Scores are typically below 250.</p>
        <p>Square color distance matrices are shown in <xref rid="table-2" ref-type="table">Tables 2</xref> through <xref rid="table-5" ref-type="table">5</xref>, with distances expressed as proportions of <inline-formula><alternatives><inline-graphic xlink:href="peerj-07-6398-i008.jpg"/><tex-math id="M8">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\sqrt 3 $\end{document}</tex-math><mml:math id="mml-ieqn-8"><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula> for RGB space. The pairs of extremes for each set (A and E; F and J) scored 1, the maximum distance, as expected for colors on opposite ends of RGB color space (<xref rid="table-3" ref-type="table">Tables 3</xref> and <xref rid="table-5" ref-type="table">5</xref>). For images A–E, the distance scores between image pairs reflect the proportions of each color in each: <xref ref-type="fig" rid="fig-3">Figs. 3A</xref> and <xref ref-type="fig" rid="fig-3">3B</xref> have a low distance score of 0.25, reflecting the fact that <inline-formula><alternatives><inline-graphic xlink:href="peerj-07-6398-i009.jpg"/><tex-math id="M9">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${1 \over 4}$\end{document}</tex-math><mml:math id="mml-ieqn-9"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> of B is red while the rest is the same color as A, as are D and E. <xref ref-type="fig" rid="fig-3">Figure 3C</xref> is <inline-formula><alternatives><inline-graphic xlink:href="peerj-07-6398-i010.jpg"/><tex-math id="M10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${1 \over 2}$\end{document}</tex-math><mml:math id="mml-ieqn-10"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> of each color, and as expected is half-maximal distance from each of A and B. Although the EMD scores for CIE Lab space (<xref rid="table-4" ref-type="table">Table 4</xref>) are considerably higher, the relative proportions are the same, with the lowest score (40) being approximately <inline-formula><alternatives><inline-graphic xlink:href="peerj-07-6398-i011.jpg"/><tex-math id="M11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}${1 \over 4}$\end{document}</tex-math><mml:math id="mml-ieqn-11"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> the maximum score (157), and <xref ref-type="fig" rid="fig-3">Figs. 3A</xref> and <xref ref-type="fig" rid="fig-3">3E</xref> having the highest score.</p>
        <table-wrap id="table-3" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.6398/table-3</object-id>
          <label>Table 3</label>
          <caption>
            <title>RGB pairwise colordistance matrix for <xref ref-type="fig" rid="fig-3">Figs. 3A</xref>–<xref ref-type="fig" rid="fig-3">3E</xref> normalized to <inline-formula><alternatives><inline-graphic xlink:href="peerj-07-6398-i012.jpg"/><tex-math id="M12">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\sqrt 3 $\end{document}</tex-math><mml:math id="mml-ieqn-12"><mml:mrow><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt></mml:mrow></mml:math></alternatives></inline-formula>, the maximum EMD score for RGB space.</title>
          </caption>
          <alternatives>
            <graphic xlink:href="peerj-07-6398-g009"/>
            <table frame="hsides" rules="groups">
              <colgroup span="1">
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th rowspan="1" colspan="1"/>
                  <th rowspan="1" colspan="1">A</th>
                  <th rowspan="1" colspan="1">B</th>
                  <th rowspan="1" colspan="1">C</th>
                  <th rowspan="1" colspan="1">D</th>
                  <th rowspan="1" colspan="1">E</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">A</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">B</td>
                  <td rowspan="1" colspan="1">0.25</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">C</td>
                  <td rowspan="1" colspan="1">0.50</td>
                  <td rowspan="1" colspan="1">0.25</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">D</td>
                  <td rowspan="1" colspan="1">0.75</td>
                  <td rowspan="1" colspan="1">0.50</td>
                  <td rowspan="1" colspan="1">0.25</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">E</td>
                  <td rowspan="1" colspan="1">
                    <bold>1.0</bold>
                  </td>
                  <td rowspan="1" colspan="1">0.75</td>
                  <td rowspan="1" colspan="1">0.50</td>
                  <td rowspan="1" colspan="1">0.25</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="table-3fn">
              <p>
                <bold>Note:</bold>
              </p>
            </fn>
            <fn id="table-3fn1" fn-type="other">
              <p>Maximum score is in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>Similarly, for the color gradient in <xref ref-type="fig" rid="fig-3">Figs. 3F</xref>–<xref ref-type="fig" rid="fig-3">3J</xref>, F and J received the maximum distance score of 1 (<xref rid="table-4" ref-type="table">Table 4</xref>), with images I and J and images F and G receiving lower distance scores of 0.28 in RGB space, reflecting their closer color similarities. <xref ref-type="fig" rid="fig-3">Figure 3H</xref> scores as equidistant from either F or J with a distance score of 0.64 from either extreme. Unlike in A–E, where C was exactly half-maximal distance from either extreme, the green square in H is not precisely halfway between F and J in color space, and so has a distance score of &gt; 0.5. The computed color distances reflect the known RGB distances of the squares on a quantified scale. Note, however, that for CIE Lab space, the maximum distance score is between <xref ref-type="fig" rid="fig-3">Figs. 3F</xref> and <xref ref-type="fig" rid="fig-3">3I</xref>, rather than F and J. This is because blue and yellow RGB values occupy opposite ends of the <italic>b</italic> channel (blue-yellow) of CIE Lab space, and both have very high luminance values (<italic>L</italic> = 90 and <italic>L</italic> = 97 for blue and yellow, respectively).</p>
        <table-wrap id="table-4" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.6398/table-4</object-id>
          <label>Table 4</label>
          <caption>
            <title>CIE Lab pairwise colordistance matrix for <xref ref-type="fig" rid="fig-3">Figs. 3A</xref>–<xref ref-type="fig" rid="fig-3">3E</xref>.</title>
          </caption>
          <alternatives>
            <graphic xlink:href="peerj-07-6398-g010"/>
            <table frame="hsides" rules="groups">
              <colgroup span="1">
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th rowspan="1" colspan="1"/>
                  <th rowspan="1" colspan="1">A</th>
                  <th rowspan="1" colspan="1">B</th>
                  <th rowspan="1" colspan="1">C</th>
                  <th rowspan="1" colspan="1">D</th>
                  <th rowspan="1" colspan="1">E</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">A</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">B</td>
                  <td rowspan="1" colspan="1">40</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">C</td>
                  <td rowspan="1" colspan="1">78</td>
                  <td rowspan="1" colspan="1">40</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">D</td>
                  <td rowspan="1" colspan="1">118</td>
                  <td rowspan="1" colspan="1">78</td>
                  <td rowspan="1" colspan="1">40</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">E</td>
                  <td rowspan="1" colspan="1">
                    <bold>157</bold>
                  </td>
                  <td rowspan="1" colspan="1">118</td>
                  <td rowspan="1" colspan="1">78</td>
                  <td rowspan="1" colspan="1">40</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="table-4fn">
              <p>
                <bold>Note:</bold>
              </p>
            </fn>
            <fn id="table-4fn1" fn-type="other">
              <p>Not normalized because there is no absolute maximum EMD score in CIE Lab space. Maximum score is in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <table-wrap id="table-5" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.6398/table-5</object-id>
          <label>Table 5</label>
          <caption>
            <title>RGB pairwise colordistance matrix for <xref ref-type="fig" rid="fig-3">Figs. 3F</xref>–<xref ref-type="fig" rid="fig-3">3J</xref>, normalized as in <xref rid="table-3" ref-type="table">Table 3</xref>.</title>
          </caption>
          <alternatives>
            <graphic xlink:href="peerj-07-6398-g011"/>
            <table frame="hsides" rules="groups">
              <colgroup span="1">
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th rowspan="1" colspan="1"/>
                  <th rowspan="1" colspan="1">F</th>
                  <th rowspan="1" colspan="1">G</th>
                  <th rowspan="1" colspan="1">H</th>
                  <th rowspan="1" colspan="1">I</th>
                  <th rowspan="1" colspan="1">J</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">F</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">G</td>
                  <td rowspan="1" colspan="1">0.28</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">H</td>
                  <td rowspan="1" colspan="1">0.64</td>
                  <td rowspan="1" colspan="1">0.40</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">I</td>
                  <td rowspan="1" colspan="1">0.86</td>
                  <td rowspan="1" colspan="1">0.70</td>
                  <td rowspan="1" colspan="1">0.40</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">J</td>
                  <td rowspan="1" colspan="1">
                    <bold>1.0</bold>
                  </td>
                  <td rowspan="1" colspan="1">0.86</td>
                  <td rowspan="1" colspan="1">0.64</td>
                  <td rowspan="1" colspan="1">0.28</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="table-5fn">
              <p>
                <bold>Note:</bold>
              </p>
            </fn>
            <fn id="table-5fn1" fn-type="other">
              <p>Maximum score is in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>For both color spaces, EMD scores reflect differences in both amount and similarity of colors in the images.</p>
      </sec>
      <sec>
        <title>Function timing</title>
        <p>The most time-consuming functions in colordistance are those that directly process or handle images, including loading the images, converting between color spaces, and binning. To time these functions, we generated random square RGB images with sizes ranging between 100 × 100 and 1,000 × 1,000 pixels. These images were used to time several colordistance functions using the rbenchmark package (<xref rid="ref-22" ref-type="bibr">Kusnierczyk, 2012</xref>). Results are reported in <xref rid="table-6" ref-type="table">Table 6</xref>.</p>
        <table-wrap id="table-6" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.6398/table-6</object-id>
          <label>Table 6</label>
          <caption>
            <title>CIE Lab pairwise colordistance matrix for <xref ref-type="fig" rid="fig-3">Figs. 3F</xref>–<xref ref-type="fig" rid="fig-3">3J</xref>.</title>
          </caption>
          <alternatives>
            <graphic xlink:href="peerj-07-6398-g012"/>
            <table frame="hsides" rules="groups">
              <colgroup span="1">
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th rowspan="1" colspan="1"/>
                  <th rowspan="1" colspan="1">F</th>
                  <th rowspan="1" colspan="1">G</th>
                  <th rowspan="1" colspan="1">H</th>
                  <th rowspan="1" colspan="1">I</th>
                  <th rowspan="1" colspan="1">J</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">F</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">G</td>
                  <td rowspan="1" colspan="1">72</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">H</td>
                  <td rowspan="1" colspan="1">224</td>
                  <td rowspan="1" colspan="1">155</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">I</td>
                  <td rowspan="1" colspan="1">
                    <bold>247</bold>
                  </td>
                  <td rowspan="1" colspan="1">181</td>
                  <td rowspan="1" colspan="1">39</td>
                  <td rowspan="1" colspan="1">–</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">J</td>
                  <td rowspan="1" colspan="1">232</td>
                  <td rowspan="1" colspan="1">174</td>
                  <td rowspan="1" colspan="1">73</td>
                  <td rowspan="1" colspan="1">48</td>
                  <td rowspan="1" colspan="1">–</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="table-6fn">
              <p>
                <bold>Note:</bold>
              </p>
            </fn>
            <fn id="table-6fn1" fn-type="other">
              <p>Maximum score is in bold.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>The most time-consuming function is <monospace>convertColorSpace</monospace>, which converts from RGB to CIE Lab space, since this is a non-linear transform (<xref rid="ref-18" ref-type="bibr">Hill, Roger &amp; Vorhagen, 1997</xref>). The default behavior of colordistance is to use a random sample of 100,000 non-background pixels from a given image for CIE Lab conversion, since this typically takes fewer than 5 s and provides an accurate representation of the whole image.</p>
      </sec>
    </sec>
    <sec>
      <title>Examples</title>
      <p>Unlike the artificial color images provided above, most real-world data involves comparing multiple colors across a range of both similarities and quantities. Quantitative, repeatable measurement and comparison of color profiles in images offers a valuable approach for answering a range of biological questions, which colordistance aims to make accessible with minimum requirements. Here, we present two analytical examples illustrating the different methods in colordistance, and how they can be used to quantitatively test color hypotheses about mimicry in butterflies and camouflage in flounder fish. The first example illustrates the utility of EMD as a distance metric in accounting for the similarity of non-identical colors using k-means clustering. The second example uses histograms and color range restriction.</p>
      <p>The examples provided here use only one image per category (species, substrate, etc.) for simplicity and to keep the example datasets small, but a more robust analysis would use multiple images for each category, averaging color distributions together using the <monospace>combineClusters</monospace> function before computing a pairwise distance matrix. This approach will allow users to test color hypotheses with more statistically rigorous approaches.</p>
      <p>Both examples use CIE Lab color space rather than RGB space, and use a D65 (indirect sunlight) standard illuminant to convert between RGB and CIE Lab space.</p>
      <sec>
        <title>Example 1: Scoring mimicry in butterflies using earth mover’s distance and χ<sup>2</sup> distance</title>
        <p>To illustrate how EMD outperforms more standard distribution comparison metrics, we used both EMD and χ<sup>2</sup> distance to compare a set of four <italic>Heliconius</italic> butterflies with similar color palettes. <italic>Heliconius</italic> butterflies have been particularly well studied with respect to the evolution of color, pattern, and Müllerian mimicry (<xref rid="ref-21" ref-type="bibr">Kronforst &amp; Papa, 2015</xref>; <xref rid="ref-13" ref-type="bibr">Enciso-Romero et al., 2017</xref>). Here, we illustrate the use of EMD with mimicry in two color forms of <italic>Heliconius numata</italic> and two color forms of <italic>H. melpomene</italic> (<xref ref-type="fig" rid="fig-4">Figs. 4A</xref>–<xref ref-type="fig" rid="fig-4">4D</xref>), as a way of testing the color similarity among forms in this system.</p>
        <fig id="fig-4" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.6398/fig-4</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Color similarity analysis of <italic>Heliconius</italic> butterflies using earth mover’s distance and χ<sup>2</sup> distance.</title>
            <p>(A–L) Butterfly images (A–D) with k-means clustering output as generated by <monospace>getKmeansList</monospace>, displayed as the default bar (E–H) and scaled to size in CIE Lab color space (I–L). (A) and (B) Two color morphs of <italic>H. numata</italic>; (C) and (D) two morphs of <italic>H. melpomene</italic>; (M) and (N) heatmaps of resulting color distance matrices, clustered by similarity, using earth mover’s distance (M) or χ<sup>2</sup> distance (N). Dark blue is more similar, magenta is more dissimilar. Image credit for (A–D): Fig. 1 of <xref rid="ref-30" ref-type="bibr">Meyer (2006)</xref>.</p>
          </caption>
          <graphic xlink:href="peerj-07-6398-g004"/>
        </fig>
        <p>K-means clustering is useful for extracting the exact colors of an image when the number of colors is known in advance, rather than dividing a single patch of color into multiple bins (<xref rid="ref-37" ref-type="bibr">Ray &amp; Turi, 1999</xref>). In this case, each butterfly appears to have three distinct colors (<xref ref-type="fig" rid="fig-4">Figs. 4A</xref>–<xref ref-type="fig" rid="fig-4">4D</xref>). To generate k-means fit objects for each image, the <monospace>getKMeansList</monospace> function is used, specifying 3 bins. The <monospace>lower</monospace> and <monospace>upper</monospace> arguments specify the lower and upper limits for RGB pixels to ignore as background—here, any pixels with R, G, and B values all between 0.8 and 1 (pale gray to pure white) will be ignored.</p>
        <p>
          <code language="java" position="float" orientation="portrait" xml:space="preserve">&gt; kmeans_fits &lt;- getKMeansList(<styled-content style="color:#9400D1">“Butterfly_mimicry/”</styled-content>, bins = 3,    1
      lower = c(0.8, 0.8, 0.8), upper = c(1, 1, 1),        2
      color.space = <styled-content style="color:#9400D1">“lab”</styled-content>, ref.white = <styled-content style="color:#9400D1">“D65”</styled-content>,            3
      plotting = TRUE)                        4
&gt; kmeans_list &lt;- extractClusters(kmeans_fits, ordering = TRUE)    5</code>
        </p>
        <p>Line 1 returns a list of <monospace>k-means</monospace> fit objects using the kmeans function from the stats package and produces the bar plots shown in <xref ref-type="fig" rid="fig-4">Figs. 4A</xref>–<xref ref-type="fig" rid="fig-4">4D</xref>, with upper and lower bounds set to eliminate white pixels; these diagnostic plots are intended to help users determine whether the clustering accurately reflects the color distribution in the image. Line 2 extracts the clusters in the same format as <monospace>getHistList</monospace> for use with other colordistance functions; the <monospace>ordering = TRUE</monospace> flag uses an application of the Hungarian algorithm (<xref rid="ref-20" ref-type="bibr">Jonker &amp; Volgenant, 1986</xref>) to order the most similar clusters in the same rows across dataframes. In this case, it ensures that all of the dark brown or black clusters are compared, the orange or red clusters are compared, and the yellow clusters are compared, rather than comparing the yellow cluster from one image to the black cluster from another. This is the default behavior of the function.</p>
        <p>
          <code language="java" position="float" orientation="portrait" xml:space="preserve">&gt; emd_distance_matrix &lt;- getColorDistanceMatrix(kmeans_list, method = <styled-content style="color:#9400D1">“emd”</styled-content>)    1
&gt; chisq_distance_matrix &lt;- getColorDistanceMatrix(kmeans_list,         2
  method = <styled-content style="color:#9400D1">“chisq”</styled-content>)                           3</code>
        </p>
        <p>Earth mover’s distance takes into account both the location and size of a given cluster when comparing one set of clusters to another, so that the final distance reflects the similarity of the clusters in both size and color (<xref rid="ref-38" ref-type="bibr">Rubner &amp; Tomasi, 2013</xref>; <xref rid="ref-39" ref-type="bibr">Rubner, Tomasi &amp; Guibas, 2000</xref>). χ<sup>2</sup> distance, a more conventional metric for measuring the similarity of two distributions, compares bins only on the basis of size. To compare the two methods, the <monospace>getColorDistanceMatrix</monospace> function was used to compute a distance matrix for the clusters generated above using both EMD and χ<sup>2</sup> distance. Lines 1 and 2 above produce the distance matrices in 4M-N. Note that the scales for each metric are different, and we will only be discussing the relative scores as indicated by the scaling of the colors in the heatmaps.</p>
        <p>For either metric, butterflies C and D have the lowest distance (score as the most similar). Using χ<sup>2</sup> distance, however, butterfly A is grouped outside of the rest of the photographs, because its orange cluster is considerably larger than the orange or red clusters of any of the other images, and its black cluster is much smaller (<xref ref-type="fig" rid="fig-4">Fig. 4F</xref>). Using EMD, butterflies A and B score as more similar to each other than to either of the <italic>H. melpomene</italic> forms, because EMD takes into account the fact that the orange clusters for both images are closer in color space than they are to the red clusters of C and D. EMD balances color amount and color similarity when providing a distance score.</p>
      </sec>
      <sec>
        <title>Example 2: Camouflage color matching in flounder using range-restricted histograms</title>
        <p>The ability of many organisms to display color patterns for camouflage against their surroundings provides insight into the relationships of organisms with their environments and with each other (<xref rid="ref-16" ref-type="bibr">Hanlon, 2007</xref>; <xref rid="ref-7" ref-type="bibr">Brady et al., 2015</xref>). Some species are capable of adaptive camouflage, in which the color pattern can be changed to match that of the environment or background. In this example, we illustrate the use of restricting the color binning range to test camouflage efficacy (fish matching the background) in winter flounder, <italic>Pleuronectes americanus</italic> (<xref ref-type="fig" rid="fig-5">Fig. 5</xref>). Both sand and gravel substrates were analyzed, with an actively camouflaged flounder present on each background.</p>
        <fig id="fig-5" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.6398/fig-5</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Background-matching analysis.</title>
            <p>(A) and (B) Flounder photographed on sand (A) and gravel (B), with fish outlined in cyan; (C–F) color histograms across a restricted color range in CIE Lab space, generated by <monospace>getLabList</monospace>, with insets indicating which part of the image was masked out in green and bars colored according to the average color of the pixels in each bin; (G) heatmap representation of distance matrix generated using <monospace>getColorDistanceMatrix</monospace>. Photo credit: H. Weller.</p>
          </caption>
          <graphic xlink:href="peerj-07-6398-g005"/>
        </fig>
        <p>Because the colors are limited to tans and browns in both images, binning across all of a given color space will produce a large number of empty bins, and a small number of bins of extremely similar size and color across all four images, resulting in uninformative color distance calculations.</p>
        <p>In order to produce a more informative histogram, the range of color space in which to divide pixels can be restricted. Here, inspection of pixel ranges in each color channel of CIE Lab space revealed that colors across all of the image had a-channel values between −20 and 40, and b-channel values between 0 and 50. Therefore, when calling the <monospace>getLabHistList</monospace> function to generate CIE Lab histograms for each image, these ranges were specified for the <monospace>a.bounds</monospace> and <monospace>b.bounds</monospace> arguments. Different numbers of bins for each channel—2 for luminance, 3 for a, and 5 for b—were also specified. Lower and upper ranges for ignoring bright green pixels are specified.</p>
        <p>
          <code language="java" position="float" orientation="portrait" xml:space="preserve">&gt; flounder_hist &lt;- getLabHistList(flounder, ref.white = <styled-content style="color:#9400D1">“D65”</styled-content>,   1
       bins = c(2, 3, 5),                       2
       lower = c(0, 0.4, 0), upper = c(0.6, 1, 0.6),       3
       a.bounds = c(-20, 40), b.bounds = c(0, 50))        4
&gt; flounder_distance_matrix &lt;- getColorDistanceMatrix(flounder_hist) 5</code>
        </p>
        <p>The results of lines 1 and 2 are shown in <xref ref-type="fig" rid="fig-5">Figs. 5C</xref>–<xref ref-type="fig" rid="fig-5">5G</xref>. Camouflaged flounder score as most similar to the substrates on which they were photographed (<xref ref-type="fig" rid="fig-5">Fig. 5G</xref>), quantitatively reflecting the species’ well-characterized ability to adjust color and pattern to a variety of backgrounds (<xref rid="ref-1" ref-type="bibr">Akkaynak et al., 2017</xref>). In each image, the fish were able to match the background color profile with the strikingly low distance of 3.05, while the sediments showed a difference of 9.39, more than three times as different. Study of the ability of organisms to change color either rapidly in an adaptive camouflage situation, or more gradually across life history stages may be a valuable application of this method. Because digital images are a poor proxy for visual systems that differ significantly from human visual sensitivities, however, caution should be used in interpreting the results.</p>
        <p>In general, colordistance does not provide a categorical classification of images as similar or different, but instead a quantitative measurement of the degree of difference between each set of images. The final heatmap clusters images based on color similarity, but this clustering is intended as a visual tool for inspecting the results. Interpretation of the quantified differences will depend on the research question.</p>
      </sec>
    </sec>
    <sec>
      <title>Pipeline</title>
      <p>The results in above examples can also be reproduced in their entirety using <monospace>imageClusterPipeline</monospace>, a function that produces a distance matrix from a set of images by calling on the binning, matrix calculation, and plotting functions in order, with specification options for every part of the pipeline.</p>
      <p>For example 1:</p>
      <p>
        <code language="java" position="float" orientation="portrait" xml:space="preserve">&gt; imageClusterPipeline(<styled-content style="color:#9400D1">“Butterfly_mimicry/”</styled-content>,    1
          lower = c(0.8, 0.8, 0.8), upper = c(1, 1, 1),    2
          cluster.method = <styled-content style="color:#9400D1">“kmeans”</styled-content>, kmeans.bins = 3,    3
          color.space = <styled-content style="color:#9400D1">“lab”</styled-content>, ref.white = <styled-content style="color:#9400D1">“D65”</styled-content>)    4</code>
      </p>
      <p>For example 2:</p>
      <p>
        <code language="java" position="float" orientation="portrait" xml:space="preserve">&gt; imageClusterPipeline(<styled-content style="color:#9400D1">“Flounder_camouflage/”</styled-content>,    1
          lower = c(0, 0.4, 0), upper = c(0.6, 1, 0.6),    2
          cluster.method = <styled-content style="color:#9400D1">“hist”</styled-content>, hist.bins = c(2, 3, 5),    3
          a.bounds = c(-20, 40), b.bounds = c(0, 50),    4
          color.space = <styled-content style="color:#9400D1">“lab”</styled-content>, ref.white = <styled-content style="color:#9400D1">“D65”</styled-content>)    5</code>
      </p>
      <p>This function is convenient for quick tweaks or parameter checks, as the entire analysis can be run with a single line of code. The intermediate steps, however, may be more helpful for users performing other analyses.</p>
    </sec>
    <sec>
      <title>Comparison with the patternize R package</title>
      <p>To illustrate the advantages of colordistance over other approaches for color and pattern analysis, we analyzed the same set of images of five parrotfish using both colordistance and patternize, an R package for quantifying color pattern variation (<xref rid="ref-53" ref-type="bibr">Van Belleghem et al., 2017</xref>). All images were captured under similar conditions against a gray background with a standard daylight flash. We used the default parameters of colordistance, including CIE Lab color space, histogram clustering with three bins per channel, and EMD for calculating color distances.</p>
      <p>For a similar comparison with patternize, we used homologous landmarks to align the images and predefined RGB colors based on earlier color sampling to compare the patterns of four dominant colors across species: green-blue, orange, pink, and brown (see methods). We chose to use predefined RGB colors because k-means clustering required the specification of so many clusters to account for the color variation in the more colorful images that it broke up dominant colors in other images, and the patterns in the images were not well-defined enough to use the watershedding approach. We then pooled the results of the principal component analyses for each color pattern into a single normalized distance matrix to compare similarity scores from the two packages (<xref ref-type="fig" rid="fig-6">Fig. 6</xref>). The image of <italic>Scarus flavipectoralis</italic> is of an initial phase individual and therefore has no measurable green-blue coloration, which did not impact the colordistance analysis. Because patternize analyzes a single color at a time, however, the distance scores for <italic>S. flavipectoralis</italic> only include the results for the other three colors, which are present in the image (<xref ref-type="fig" rid="fig-6">Fig. 6D</xref>).</p>
      <fig id="fig-6" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerj.6398/fig-6</object-id>
        <label>Figure 6</label>
        <caption>
          <title>Similarity analyses produced by colordistance (A &amp; C) and patternize (B &amp; D) for the same set of parrotfish images.</title>
          <p>(A) and (B) Cluster analyses for color distance matrices produced by colordistance (A) and patternize (B). Branch lengths are proportional to the distances in the heatmaps below each dendrogram. Note the change in position of <italic>Scarus flavipectoralis</italic>. (C) and (D) Heatmap representations of normalized distance matrices produced by colordistance (C) and patternize (D), with species displayed in the same order for comparison between the heatmaps. Photo credit: M. Westneat/J. T. Williams.</p>
        </caption>
        <graphic xlink:href="peerj-07-6398-g006"/>
      </fig>
      <p>The cluster analyses of both packages have relatively similar topologies: <italic>S. dimidiatus</italic> and <italic>S. psittacus</italic>, both of which are predominantly green-blue in color, group together, as do <italic>Chlorurus japanensis</italic> and <italic>S. tricolor</italic>, the two more colorful species. The location of <italic>S. flavipectoralis</italic> varies between the analyses: the colordistance analysis places it closer to <italic>C. japanensis</italic> and <italic>S. tricolor</italic>, while patternize places it closer to the predominantly green-blue species.</p>
      <p>Other differences include that <italic>S. flavipectoralis</italic> and <italic>S. dimidiatus</italic> have the highest distance score in the colordistance analysis, while <italic>S. tricolor</italic> has the highest overall distance scores across all comparisons in patternize, with no distances below 90% of the maximum distance score. The lowest score in the colordistance analysis is between <italic>C. japanensis</italic> and <italic>S. tricolor</italic>, while in patternize it is between <italic>S. dimidiatus</italic> and <italic>S. psittacus</italic> (and <italic>C. japanensis</italic> and <italic>S. tricolor</italic> have a fairly high distance score despite grouping together in the cluster analysis). The numerical scores themselves are not reported, as the scales are not comparable—the patternize scores come from principal component analysis, while the colordistance scores come from EMDs in CIE Lab space.</p>
      <p>In benchmark tests with the rbenchmark package (<xref rid="ref-22" ref-type="bibr">Kusnierczyk, 2012</xref>), colordistance performed the full analysis significantly faster than patternize (colordistance: 8.0 <italic>±</italic> 0.6 s; patternize: 158 <italic>±</italic> 8 s; <italic>p</italic> &lt; 1.6 × 10<sup>−6</sup> using a Student’s <italic>t</italic>-test), largely because colordistance discards spatial information, significantly speeding up computation. Implications of these results for the utility of colordistance compared to patternize are discussed below.</p>
    </sec>
  </sec>
  <sec sec-type="discussion">
    <title>Discussion</title>
    <p>Colordistance provides an accessible tool for making quantitative color comparisons between images. The goal of the package is to provide a method for comparing both color quantity and similarity in an objective, repeatable way, without necessarily requiring homologous colors or even homologous morphologies. Given that many color pattern analyses do not have a method of scoring colors that are similar but not identical, colordistance provides a valuable additional analysis whenever there is considerable color variation across images in a dataset. Results provided by the package can be combined with other kinds of color and pattern toolkits to provide a comprehensive analysis of a system. The package is especially useful when considering systems where the colors across images are not necessarily homologous, and the degree of similarity between non-identical colors becomes more important. Here, we provide brief guidelines for choosing between the different color spaces, binning methods, and distance metrics in colordistance, and discuss how colordistance differs from similar packages and methods.</p>
    <sec>
      <title>Choosing parameters</title>
      <p>The choices of color space, binning method, and distance metric used to analyze images in colordistance will all affect the final distance scores. Although default parameters generally perform well, and provide a reasonable trade-off between precision and efficiency, choosing appropriate parameters will depend on both the research question and the image set. Here, we provide brief guidelines for choosing parameters; more exhaustive discussions of color spaces, binning methods, and distance metrics are available in the literature (see <xref rid="ref-18" ref-type="bibr">Hill, Roger &amp; Vorhagen, 1997</xref>; <xref rid="ref-37" ref-type="bibr">Ray &amp; Turi, 1999</xref>; <xref rid="ref-38" ref-type="bibr">Rubner &amp; Tomasi, 2013</xref>; <xref rid="ref-39" ref-type="bibr">Rubner, Tomasi &amp; Guibas, 2000</xref> and on the colordistance GitHub Pages site, <uri xlink:href="https://hiweller.github.io/colordistance">https://hiweller.github.io/colordistance</uri>).</p>
      <sec>
        <title>Color spaces</title>
        <p>In general, users trade biological relevance for ease-of-use in choosing a color space. Of the three available color spaces (CIE Lab, RGB, and HSV) in colordistance, CIE Lab is generally the superior choice for measuring biologically relevant quantitative color similarities. Unlike RGB and HSV, CIE Lab is intended to be perceptually uniform, meaning that colors separated by an equal distance in CIE Lab space will be perceived as equally different. RGB and HSV color spaces are more computationally tractable because each channel in either color space ranges from 0 to 1; this allows for more consistent binning, even sampling, and universally scaled color distance measurements, since the absolute maximum distance will be fixed.</p>
        <p>Although CIE Lab space is generally recommended for making quantitative color comparisons, it has several disadvantages compared to RGB or HSV. Because most digital images are stored in RGB format, working in CIE Lab space requires converting from RGB to CIE Lab. These conversions can be fairly time-consuming (<xref rid="table-7" ref-type="table">Table 7</xref>), and require the specification of a white reference. It should also be noted that perceptually uniform color spaces like CIE Lab are designed to be uniform with respect to <italic>human</italic> color vision. The scaling in CIE Lab space therefore may not be perceptually uniform for other organisms, even those with trichromatic vision, because they may have significantly different peak visual sensitivities (<xref rid="ref-1" ref-type="bibr">Akkaynak et al., 2017</xref>; <xref rid="ref-16" ref-type="bibr">Hanlon, 2007</xref>). CIE Lab will still provide a closer approximation than a color space that doesn’t attempt perceptual uniformity, but caution should be used in interpreting the results. One possible workaround would be to use an image calibration, such as the software suite by <xref rid="ref-48" ref-type="bibr">Troscianko &amp; Stevens (2015)</xref>, to calibrate and normalize camera RAW files for non-human color visual systems before processing them with colordistance.</p>
        <table-wrap id="table-7" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.7717/peerj.6398/table-7</object-id>
          <label>Table 7</label>
          <caption>
            <title>Timing for the most time-consuming functions of colordistance.</title>
          </caption>
          <alternatives>
            <graphic xlink:href="peerj-07-6398-g013"/>
            <table frame="hsides" rules="groups">
              <colgroup span="1">
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
                <col span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th rowspan="1" colspan="1"/>
                  <th rowspan="1" colspan="1">Function</th>
                  <th rowspan="1" colspan="1">Coefficient</th>
                  <th rowspan="1" colspan="1">
                    <italic>R</italic>
                    <sup>2</sup>
                  </th>
                  <th rowspan="1" colspan="1"><italic>p</italic>-value</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">Loading images</td>
                  <td rowspan="1" colspan="1">
                    <monospace>loadImage</monospace>
                  </td>
                  <td rowspan="1" colspan="1">0.24 <italic>s pixels</italic><sup>−6</sup></td>
                  <td rowspan="1" colspan="1">0.97</td>
                  <td rowspan="1" colspan="1">&lt;0.01</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">Converting from RGB to CIE Lab</td>
                  <td rowspan="1" colspan="1">
                    <monospace>convertColorSpace</monospace>
                  </td>
                  <td rowspan="1" colspan="1">57.3 <italic>s pixels</italic><sup>−6</sup></td>
                  <td rowspan="1" colspan="1">0.99</td>
                  <td rowspan="1" colspan="1">&lt;0.01</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">Histogram binning</td>
                  <td rowspan="1" colspan="1">
                    <monospace>getLabHist</monospace>
                  </td>
                  <td rowspan="1" colspan="1">1.43 <italic>s pixels</italic><sup>−6</sup></td>
                  <td rowspan="1" colspan="1">0.97</td>
                  <td rowspan="1" colspan="1">&lt;0.01</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">k-means binning</td>
                  <td rowspan="1" colspan="1">
                    <monospace>getKMeanColors</monospace>
                  </td>
                  <td rowspan="1" colspan="1">25.4 <italic>s pixels</italic><sup>−6</sup></td>
                  <td rowspan="1" colspan="1">0.97</td>
                  <td rowspan="1" colspan="1">&lt;0.01</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="table-7fn">
              <p>
                <bold>Note:</bold>
              </p>
            </fn>
            <fn id="table-7fn1" fn-type="other">
              <p>A total of five runs of each analysis were performed on an early 2015 MacBook Pro with a 2.7 GHz Intel Core i5 processor.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>If the research question does not hinge on organismal color perception, however, RGB or HSV color spaces may be no more or less appropriate than a perceptually uniform color space. For example, if a user is attempting to quantify the proportion of discoloration on a series of leaves, any color space capable of separating the discolored and normal portions of the leaves in color space may be equally appropriate for quantifying the images. In this case, RGB or HSV would work well, and analyses in these color spaces will be considerably faster than in CIE Lab space. RGB is generally recommended over HSV because it is based on a tri-stimulus model of human color vision, with red, green, and blue channels that correspond approximately to human peak cone sensitivities (<xref rid="ref-8" ref-type="bibr">Byers, 2006</xref>).</p>
      </sec>
      <sec>
        <title>Binning methods</title>
        <p>Of the two binning methods, histogram binning and k-means clustering, histogram binning is the default because it makes fewer assumptions about color clustering in an image. Histogram binning counts how many pixels fall into each of a set of predetermined bounds, without the need for iteration, making it considerably faster than k-means clustering. Because the bins have the exact same bounds for each image, comparing bins across images is fairly straightforward, and empty bins account for the lack of specific colors in images. Histogram binning also has the advantage of retaining details, such as small accent colors in an image, rather than collapsing them into a larger cluster. However, it risks dividing up a single color into multiple bins, and can result in a large number of empty bins if the color range is not restricted (but see the flounder camouflage example above). Similarly, two different colors with pixels that happen to fall within the same bin will be averaged into a single color.</p>
        <p>K-means clustering typically returns one cluster per dominant color in an image, provided an accurate number of clusters was specified (see <xref rid="ref-14" ref-type="bibr">Endler (2012)</xref> for methods of estimating the number of color classes). This can be useful when comparing a set of organisms or objects which have the same number of color classes, but different colors or amounts (see <italic>Heliconius</italic> example above). However, if users are attempting to compare objects with different numbers of colors, quantitative comparisons using k-means clusters requires either: (1) specifying a different number of clusters for each image and generating empty bins for the unmatched colors between images, or (2) specifying the highest required number of clusters for all images, typically breaking up colors across multiple clusters.</p>
      </sec>
      <sec>
        <title>Distance metrics</title>
        <p>Colordistance provides four metrics for quantifying the similarity of binned images, but EMD is recommended unless users have a specific reason for using one of the other three. Unlike the binning methods or color space, any of the given metrics will take approximately the same time to implement, since they require relatively little calculation unless a set of images is extremely large or uses hundreds or thousands of bins per image.</p>
        <p>Of the four metrics, EMD is recommended for making general comparisons, as it takes both color similarity (relative location in color space) and amount (cluster size) into account to produce a single distance measurement for every pair of images in the dataset. EMD measures the difference between two images as a transport cost—how much work is required to reshape the distribution of image A so it resembles that of image B, or vice versa? Clusters of extremely different size require moving a large amount of data, and clusters in different parts of color space require moving data a long distance. Either one will increase the EMD, so that the highest EMD is the result of moving all of the data as far as possible across color space (e.g., an all-black cluster to an all-white cluster has to move 100% of the data the longest possible distance across RGB space).</p>
        <p>Earth mover’s distance typically provides the best balance of color proportion and type in a set of images, and the resulting distance matrices reflect intuitive similarities in images (<xref rid="ref-38" ref-type="bibr">Rubner &amp; Tomasi, 2013</xref>).</p>
        <p>χ<sup>2</sup> distance compares clusters only on the basis of size, even if two bins are slightly different colors (compare <xref ref-type="fig" rid="fig-4">Figs. 4E</xref> and <xref ref-type="fig" rid="fig-4">4F</xref>). Color similarity is still taken into account in that using the same set of bins or setting <monospace>ordering = TRUE</monospace> for <monospace>extractClusters()</monospace> will guarantee that bins are comparable, but the relative color similarity of two bins is ignored beyond this. In practice, χ<sup>2</sup> distance often performs about as well as EMD, except in cases where similar colors are placed into different bins, or have clusters of substantially different sizes. If users want to ignore these color differences, however—for example, when comparing images with the same expected color classes—χ<sup>2</sup> distance is a viable choice.</p>
        <p>The other two metrics, described in the “Color Distance Metrics” vignette in the package, calculate a distance score based on either (1) only color similarity, ignoring bin size, or (2) combining the size and color similarity scores according to specified weights. Although these metrics may be useful for certain questions or datasets, they don’t perform as well as either EMD or χ<sup>2</sup> for general use, and are included only for specialized cases.</p>
      </sec>
    </sec>
    <sec>
      <title>Comparison with existing methods</title>
      <p>Although color is notoriously subjective, it is also an indispensable tool for analyzing images. Computational solutions offer a repeatable, objective method for quantifying color with open-source tools, providing a statistically rigorous alternative to subjective analysis of images without requiring additional equipment beyond a personal computer. Colordistance is not intended as a superior replacement for more comprehensive image analysis tools, but as a complementary, easy-to-use option for including an analysis of color similarity that makes no assumptions about the homology of the images provided.</p>
      <sec>
        <title>Comparison with patternize</title>
        <p>Patternize uses either k-means, watershedding, or manual color specification approaches to segment images of organisms, and compares shapes of color patches to quantify the pattern similarities across a set of images. This method provides a rigorous comparison of pattern based on color, but has a number of limitations. Patternize works best when (1) the patterns share a relatively limited color palette across all objects, (2) the objects being compared have sharply defined color patterns, and (3) the objects have homologous shapes that can be aligned using a shape outline or a series of landmarks. It is therefore an extremely robust approach for comparing minor variations in color patterns within populations or between closely related species that share the same dominant colors (<xref rid="ref-21" ref-type="bibr">Kronforst &amp; Papa, 2015</xref>).</p>
        <p>In comparing parrotfish species, however, many of these conditions were fully or partially violated: some species are nearly uniform in color, while others display many distinct colors; many of the patterns are not sharply defined; and while species do share homologous landmarks, they vary considerably in their actual proportions, meaning that landmark alignment doesn’t ensure that the patterns themselves are actually aligned (<xref ref-type="fig" rid="fig-6">Fig. 6</xref>). As a result, patternize alone cannot account for much of the interesting variation in this small example dataset. The initial phase <italic>S. flavipectoralis</italic>, for example, is almost entirely brown with an orange dorsal fin, yet it scores as relatively similar to the images of <italic>S. psittacus</italic> and <italic>S. dimidiatus</italic>, both of which are almost entirely green-blue. This is largely because they cluster together in the principal component analysis for the pink and orange patterns (<italic>C. japanensis</italic> and <italic>S. tricolor</italic> have substantial pink or orange on their flanks, while the other images do not), and because patternize does not account for the similarity of colors in different patterns.</p>
        <p>In this case, even though the light brown coloration that dominates <italic>S. flavipectoralis</italic> is closer in color to the pinks and oranges of <italic>C. japanensis</italic> and <italic>S. tricolor</italic>, it groups as more similar to the green-blue fishes because all colors were treated as equally different. Similarly, <italic>S. tricolor</italic> scores as highly dissimilar from all of the other fishes, largely because much of its flank is classified as orange, while the other species have only orange accents; this ignores the similarity of the orange coloration. Moreover, many of the pattern elements themselves are not shared across the images—most of the fishes have a long stripe of some color on the dorsal fin, but only <italic>S. dimidiatus</italic> and <italic>C. japanensis</italic> have a dorsal saddle (in different colors), for example, which is not well-defined on either fish.</p>
        <p>Colordistance, by contrast, takes into account the similarity and amount of each color in the images, while ignoring spatial information. While this fails to account for the shared pattern motifs, this method does account for the similarity of colors without the assumption that any set of colors is identical across images. Although the dominant brown coloration of <italic>S. flavipectoralis</italic> is not identical to the predominantly orange <italic>S. tricolor</italic> or the even more colorful <italic>C. japanensis</italic>, the similarity of their colors means that <italic>S. flavipectoralis</italic> scores as more similar to these two fishes than to either of the green-blue species, because orange and brown are much closer in CIE Lab space than brown and green-blue. For the same reasons, colordistance scores <italic>S. tricolor</italic> as quite similar to <italic>C. japanensis</italic> and <italic>S. flavipectoralis</italic>.</p>
        <p>Neither of these analyses is necessarily superior to the other: they each reflect a different kind of information about the colors and patterns present in the images. The use of one over the other depends on the dataset and the research question. In this example, the colordistance analysis is more appropriate for questions about which species share similar color palettes despite wide variation in the actual pattern motifs displayed. An analysis with patternize would be more appropriate for answering questions about the similarity of the pattern motifs, perhaps ignoring color (in order to, e.g., compare dorsal saddles or facial markings of different colors). Interestingly, the similarity analyses produced by both methods are incongruent with parrotfish phylogeny (<xref rid="ref-45" ref-type="bibr">Smith et al., 2008</xref>), supporting that color on coral reef fishes is a highly adaptive trait (<xref rid="ref-17" ref-type="bibr">Hemingson et al., 2018</xref>). For broader comparative studies, such as comparing the diversity of shape and color across a large phylogeny or within an environment (<xref rid="ref-28" ref-type="bibr">Marshall et al., 2003</xref>), users may want to include an analysis of color similarity in addition to pattern similarity. Because both packages are available in R and can be used on the same datasets, users could combine information from both to weight both color and pattern similarity, for example, using colordistance to analyze the pattern similarity of patterns identified by patternize.</p>
      </sec>
      <sec>
        <title>Color analyses with popular software</title>
        <p>There are a number of computational tools that analyze color in digital images. The most popular tools for scientific analyses include the color plugins for Fiji/ImageJ (<xref rid="ref-42" ref-type="bibr">Schindelin et al., 2012</xref>), the MATLAB image processing toolkit (<xref rid="ref-29" ref-type="bibr">MATLAB Image Processing Toolbox, 2017</xref>), or the scikit-image and OpenCV libraries in Python (<xref rid="ref-54" ref-type="bibr">Van Der Walt et al., 2014</xref>; <xref rid="ref-6" ref-type="bibr">Bradski, 2000</xref>).</p>
        <p>The image processing libraries available in MATLAB, Python, and C++ are geared largely toward explicit computer vision applications, rather than comparative pipelines. These libraries could be used to reconstruct any of the methods employed by colordistance by combining available clustering algorithms and appropriate distance metrics. However, the image analysis and statistical experience required to construct the pipeline from scratch may be prohibitive. Similarly, while ImageJ could be used to achieve the same results as colordistance, this would require images to be analyzed one at a time, and then for the histogram results to be analyzed in a separate program. This same result is achieved with a single line of code in colordistance, making it easier to test different color spaces, binning methods, and distance metrics, and to work with considerably larger image sets.</p>
        <p>Colordistance is an R package, so it can easily be combined with other R packages and tools for color analysis or more general statistics. Because R is among the most popular coding languages in biological research, making these functions available in R allows users to make use of them without having to learn additional coding languages or to transfer the results of different analyses into new coding environments (<xref rid="ref-36" ref-type="bibr">R Core Team, 2018</xref>).</p>
      </sec>
      <sec>
        <title>Other color comparison methods</title>
        <p>Several other methods for comparing organismal color and pattern already exist, either as detailed protocols or software pipelines and packages.</p>
        <p>A number of other R packages offer complementary functionality, including RImagePallette (extracts colors from images; <xref rid="ref-9" ref-type="bibr">Carlson (2016)</xref>), imager (a set of image processing tools; <xref rid="ref-4" ref-type="bibr">Barthelme (2017)</xref>), colorspace (mapping between color palettes; <xref rid="ref-58" ref-type="bibr">Zeileis, Hornik &amp; Murrell (2009)</xref>), and pavo (spectral analysis; <xref rid="ref-27" ref-type="bibr">Maia et al. (2013)</xref>).</p>
        <p><xref rid="ref-14" ref-type="bibr">Endler (2012)</xref> provides a comprehensive analysis pipeline from image acquisition to color pattern geometry comparison. This method and similar ones are typically designed to answer specific questions about signaling, mate attraction, predator/prey camouflage, or pollination. A variety of tools could be used for different parts of the pipeline, including patternize and the other software tools mentioned above. Colordistance can be used as part of the analysis, specifically for determining and binning pixels into different categories, but the package isn’t designed to replicate or replace the spatial components of the analysis.</p>
        <p>Instead, colordistance is intended to be one part of a larger color analysis toolbox, and can be used in conjunction with image segmentation or patch comparison methods to provide a more complete picture of how colors and patterns vary across images.</p>
      </sec>
    </sec>
    <sec>
      <title>Advantages and drawbacks</title>
      <p>The major advantage of colordistance is that it has the same requirements as manual digital image classification (digital images and a computer), but provides a consistent, repeatable, objective alternative to subjective analysis, with a low barrier to entry. Because the analysis pipeline is reasonably fast and includes default parameters, an initial analysis is fairly quick and can be run in as little as a single line of code. This allows users to check for potential issues and tweak parameters to suit a dataset without spending hours or days re-running the analysis.</p>
      <p>Users may employ multiple R packages for color processing, analysis and quantification of both color profile and pattern for a wide range of applications in biology. The colordistance package and tutorials, in combination with these other packages, provides an accessible method for researchers with a set of color images to perform a quantitative analysis of color similarity, all within the R environment.</p>
      <p>However, colordistance is not a comprehensive analytical tool, and most notably does not perform any spatial analysis when considering the amount and similarity of colors in images. This means that two images with the exact same colors but completely different spatial distributions will receive the same similarity score as images with the same spatial distribution of colors. If pattern is a very important aspect of the analysis, then colordistance alone is not a sufficient tool, and should only be used as a complement to tools that are intended for spatial pattern analyses, such as patternize (<xref rid="ref-53" ref-type="bibr">Van Belleghem et al., 2017</xref>) or the method detailed by <xref rid="ref-14" ref-type="bibr">Endler (2012)</xref>.</p>
      <p>The package is also currently limited to a three-channel model, as all available color spaces in the package contain only three channels. This works well enough for most digital images, which are stored in a three-channel format, and for making comparisons through the lens of human vision, but it is not applicable for many animal models of color vision, since it is tailored for the visual sensitivities of human beings (<xref rid="ref-15" ref-type="bibr">Endler &amp; Mielke, 2005</xref>, <xref rid="ref-1" ref-type="bibr">Akkaynak et al., 2017</xref>). Combining digital images with an ultraviolet sensor and using calibration tools to combine these channels (<xref rid="ref-48" ref-type="bibr">Troscianko &amp; Stevens, 2015</xref>) is an excellent first step before attempting to use colordistance.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions">
    <title>Conclusion</title>
    <p>Consistent, objective color comparisons are ideal for studying color in biology. Quantitative analyses are reproducible and scalable across datasets, without being prone to the subjective, variable, or inconsistent analyses that can result from more conventional categorizations of color. The examples presented here, illustrate how colordistance can produce quantitative answers to comparative questions about color in a flexible, user-friendly format. It is important to note that full color analyses would involve large samples of images (rather than the individual comparisons shown here) with appropriate statistical analyses of color profiles and distance metrics. The package provides a dynamic method of making quantified color comparisons between objects and computing distance matrices of color variation among objects. Color profile data and distance matrices are easily saved for incorporation into other R packages for statistics or phylogenetic comparative methods.</p>
    <p>The method developed here is currently being used to analyze and compare the color palettes among families of coral reef fishes and other organisms, and should be applicable to analyses with a wide range of objectives. Although the package was developed for biological analysis, it can be used for any image set that requires quantitative color comparisons, from camouflage efficacy to trends in apparel. Current uses include an auto safety application, a study of soil color, a dominance study in lizards, and quantification of areas of fungal infection on plant leaves and bat wings.</p>
    <p>Future development of the colordistance package will include expansion to include additional color channels (especially an ultraviolet channel), integration with landmark-based morphometric data sets, and user tools for partitioning objects into different regions. The analysis pipeline presented here could also be combined with pattern analysis software, such as the patternize R package (<xref rid="ref-53" ref-type="bibr">Van Belleghem et al., 2017</xref>), to compare both color and pattern similarities.</p>
  </sec>
</body>
<back>
  <ack>
    <p>Thanks to Aaron Olsen, Charlene McCord, Andrew George, Chloe Nash, and Elska Kaczmarek for coding ideas and discussion of color. Thanks to Roger Hanlon for advice.</p>
  </ack>
  <sec sec-type="additional-information">
    <title>Additional Information and Declarations</title>
    <fn-group content-type="competing-interests">
      <title>Competing Interests</title>
      <fn fn-type="COI-statement" id="conflict-1">
        <p>The authors declare that they have no competing interests.</p>
      </fn>
    </fn-group>
    <fn-group content-type="author-contributions">
      <title>Author Contributions</title>
      <fn fn-type="con" id="contribution-1">
        <p><xref ref-type="contrib" rid="author-1">Hannah Weller</xref> conceived and designed the experiments, performed the experiments, analyzed the data, contributed reagents/materials/analysis tools, prepared figures and/or tables, authored or reviewed drafts of the paper, approved the final draft, wrote, tested, and published R package.</p>
      </fn>
      <fn fn-type="con" id="contribution-2">
        <p><xref ref-type="contrib" rid="author-2">Mark Westneat</xref> conceived and designed the experiments, contributed reagents/materials/analysis tools, authored or reviewed drafts of the paper, approved the final draft.</p>
      </fn>
    </fn-group>
    <fn-group content-type="other">
      <title>Data Availability</title>
      <fn id="addinfo-1">
        <p>The following information was supplied regarding data availability:</p>
        <p>GitHub (development version of code): <uri xlink:href="https://github.com/hiweller/colordistance">https://github.com/hiweller/colordistance</uri>.</p>
        <p>GitHub (example images and code): <uri xlink:href="https://github.com/hiweller/colordistance_examples">https://github.com/hiweller/colordistance_examples</uri>.</p>
        <p>Comprehensive R Archive Network (CRAN) (stable release code only): <uri xlink:href="https://CRAN.R-project.org/package=colordistance">https://CRAN.R-project.org/package=colordistance</uri>.</p>
      </fn>
    </fn-group>
  </sec>
  <ref-list content-type="authoryear">
    <title>References</title>
    <ref id="ref-1">
      <label>Akkaynak et al. (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Akkaynak</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Siemann</surname>
            <given-names>LA</given-names>
          </name>
          <name>
            <surname>Barbosa</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mäthger</surname>
            <given-names>LM</given-names>
          </name>
        </person-group>
        <article-title>Changeable camouflage: how well can flounder resemble the colour and spatial scale of substrates in their natural habitats?</article-title>
        <source>Royal Society Open Science</source>
        <year>2017</year>
        <volume>4</volume>
        <issue>3</issue>
        <fpage>160824</fpage>
        <pub-id pub-id-type="doi">10.1098/rsos.160824</pub-id>
        <pub-id pub-id-type="pmid">28405370</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-2">
      <label>Baddeley, Rubak &amp; Turner (2015)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Baddeley</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Rubak</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Turner</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <source>Spatial point patterns: methodology and applications with R</source>
        <year>2015</year>
        <publisher-loc>London</publisher-loc>
        <publisher-name>Chapman and Hall/CRC Press</publisher-name>
      </element-citation>
    </ref>
    <ref id="ref-3">
      <label>Badiane et al. (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Badiane</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Pérez i de Lanuza</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Carmen García‐Custodio</surname>
            <given-names>MD</given-names>
          </name>
          <name>
            <surname>Carazo</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Font</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Colour patch size and measurement error using reflectance spectrophotometry</article-title>
        <source>Methods in Ecology and Evolution</source>
        <year>2017</year>
        <volume>8</volume>
        <issue>11</issue>
        <fpage>1585</fpage>
        <lpage>1593</lpage>
        <pub-id pub-id-type="doi">10.1111/2041-210x.12801</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-4">
      <label>Barthelme (2017)</label>
      <element-citation publication-type="software">
        <person-group person-group-type="author">
          <name>
            <surname>Barthelme</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <data-title>imager: image processing library based on ‘CImg’</data-title>
        <year>2017</year>
        <version designator="0.40.2">R package version 0.40.2</version>
        <uri xlink:href="https://CRAN.R-project.org/package=imager">https://CRAN.R-project.org/package=imager</uri>
      </element-citation>
    </ref>
    <ref id="ref-5">
      <label>Bechtel, Rivard &amp; Sánchez-Azofeifa (2002)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bechtel</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Rivard</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Sánchez-Azofeifa</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Spectral properties of foliose and crustose lichens based on laboratory experiments</article-title>
        <source>Remote Sensing of Environment</source>
        <year>2002</year>
        <volume>82</volume>
        <issue>2–3</issue>
        <fpage>389</fpage>
        <lpage>396</lpage>
        <pub-id pub-id-type="doi">10.1016/s0034-4257(02)00055-x</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-6">
      <label>Bradski (2000)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bradski</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>The OpenCV Library</article-title>
        <source>Dr. Dobb’s Journal of Software Tools</source>
        <year>2000</year>
        <volume>120</volume>
        <fpage>122</fpage>
        <lpage>125</lpage>
      </element-citation>
    </ref>
    <ref id="ref-7">
      <label>Brady et al. (2015)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brady</surname>
            <given-names>PC</given-names>
          </name>
          <name>
            <surname>Gilerson</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Kattawar</surname>
            <given-names>GW</given-names>
          </name>
          <name>
            <surname>Sullivan</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Twardowski</surname>
            <given-names>MS</given-names>
          </name>
          <name>
            <surname>Dierssen</surname>
            <given-names>HM</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Travis</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Etheredge</surname>
            <given-names>RI</given-names>
          </name>
          <name>
            <surname>Tonizzo</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ibrahim</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Carrizo</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Gu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Russell</surname>
            <given-names>BJ</given-names>
          </name>
          <name>
            <surname>Mislinski</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Cummings</surname>
            <given-names>ME</given-names>
          </name>
        </person-group>
        <article-title>Open-ocean fish reveal an omnidirectional solution to camouflage in polarized environments</article-title>
        <source>Science</source>
        <year>2015</year>
        <volume>350</volume>
        <issue>6263</issue>
        <fpage>965</fpage>
        <lpage>969</lpage>
        <pub-id pub-id-type="doi">10.1126/science.aad5284</pub-id>
        <pub-id pub-id-type="pmid">26586762</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-8">
      <label>Byers (2006)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Byers</surname>
            <given-names>JA</given-names>
          </name>
        </person-group>
        <article-title>Analysis of insect and plant colors in digital images using java software on the internet</article-title>
        <source>Annals of the Entomological Society of America</source>
        <year>2006</year>
        <volume>99</volume>
        <issue>5</issue>
        <fpage>865</fpage>
        <lpage>874</lpage>
        <pub-id pub-id-type="doi">10.1603/0013-8746(2006)99[865:aoiapc]2.0.co;2</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-9">
      <label>Carlson (2016)</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Carlson</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <data-title>RImagePalette: extract the colors from images</data-title>
        <year>2016</year>
        <version designator="0.1.1">R package version 0.1.1</version>
        <uri xlink:href="https://CRAN.R-project.org/package=RImagePalette">https://CRAN.R-project.org/package=RImagePalette</uri>
      </element-citation>
    </ref>
    <ref id="ref-10">
      <label>Chiao et al. (2011)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chiao</surname>
            <given-names>C-C</given-names>
          </name>
          <name>
            <surname>Wickiser</surname>
            <given-names>JK</given-names>
          </name>
          <name>
            <surname>Allen</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Genter</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Hanlon</surname>
            <given-names>RT</given-names>
          </name>
        </person-group>
        <article-title>Hyperspectral imaging of cuttlefish camouflage indicates good color match in the eyes of fish predators</article-title>
        <source>Proceedings of the National Academy of Sciences of the United States of America</source>
        <year>2011</year>
        <volume>108</volume>
        <issue>22</issue>
        <fpage>9148</fpage>
        <lpage>9153</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1019090108</pub-id>
        <pub-id pub-id-type="pmid">21576487</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-11">
      <label>Clegg &amp; Durbin (2000)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Clegg</surname>
            <given-names>MT</given-names>
          </name>
          <name>
            <surname>Durbin</surname>
            <given-names>ML</given-names>
          </name>
        </person-group>
        <article-title>Flower color variation: a model for the experimental study of evolution</article-title>
        <source>Proceedings of the National Academy of Sciences of the United States of America</source>
        <year>2000</year>
        <volume>97</volume>
        <issue>13</issue>
        <fpage>7016</fpage>
        <lpage>7023</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.97.13.7016</pub-id>
        <pub-id pub-id-type="pmid">10860965</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-12">
      <label>Cuthill et al. (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cuthill</surname>
            <given-names>IC</given-names>
          </name>
          <name>
            <surname>Allen</surname>
            <given-names>WL</given-names>
          </name>
          <name>
            <surname>Arbuckle</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Caspers</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Chaplin</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Hauber</surname>
            <given-names>ME</given-names>
          </name>
          <name>
            <surname>Hill</surname>
            <given-names>GE</given-names>
          </name>
          <name>
            <surname>Jablonski</surname>
            <given-names>NG</given-names>
          </name>
          <name>
            <surname>Jiggins</surname>
            <given-names>CD</given-names>
          </name>
          <name>
            <surname>Kelber</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>The biology of color</article-title>
        <source>Science</source>
        <year>2017</year>
        <volume>357</volume>
        <issue>6350</issue>
        <fpage>eaan0221</fpage>
        <pub-id pub-id-type="doi">10.1126/science.aan0221</pub-id>
        <pub-id pub-id-type="pmid">28774901</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-13">
      <label>Enciso-Romero et al. (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Enciso-Romero</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Pardo-Daz</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Martin</surname>
            <given-names>SH</given-names>
          </name>
          <name>
            <surname>Arias</surname>
            <given-names>CF</given-names>
          </name>
          <name>
            <surname>Linares</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>McMillan</surname>
            <given-names>WO</given-names>
          </name>
          <name>
            <surname>Jiggins</surname>
            <given-names>CD</given-names>
          </name>
          <name>
            <surname>Salazar</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Evolution of novel mimicry rings facilitated by adaptive introgression in tropical butterflies</article-title>
        <source>Molecular Ecology</source>
        <year>2017</year>
        <volume>26</volume>
        <issue>19</issue>
        <fpage>5160</fpage>
        <lpage>5172</lpage>
        <pub-id pub-id-type="doi">10.1111/mec.14277</pub-id>
        <pub-id pub-id-type="pmid">28777894</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-14">
      <label>Endler (2012)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Endler</surname>
            <given-names>JA</given-names>
          </name>
        </person-group>
        <article-title>A framework for analysing colour pattern geometry: adjacent colours</article-title>
        <source>Biological Journal of the Linnean Society</source>
        <year>2012</year>
        <volume>107</volume>
        <issue>2</issue>
        <fpage>233</fpage>
        <lpage>253</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1095-8312.2012.01937.x</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-15">
      <label>Endler &amp; Mielke (2005)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Endler</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Mielke</surname>
            <given-names>PW</given-names>
            <suffix>Jr</suffix>
          </name>
        </person-group>
        <article-title>Comparing entire colour patterns as birds see them</article-title>
        <source>Biological Journal of the Linnean Society</source>
        <year>2005</year>
        <volume>86</volume>
        <issue>4</issue>
        <fpage>405</fpage>
        <lpage>431</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1095-8312.2005.00540.x</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-16">
      <label>Hanlon (2007)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hanlon</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Cephalopod dynamic camouflage</article-title>
        <source>Current Biology</source>
        <year>2007</year>
        <volume>17</volume>
        <issue>11</issue>
        <fpage>R400</fpage>
        <lpage>R404</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cub.2007.03.034</pub-id>
        <pub-id pub-id-type="pmid">17550761</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-17">
      <label>Hemingson et al. (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hemingson</surname>
            <given-names>CR</given-names>
          </name>
          <name>
            <surname>Cowman</surname>
            <given-names>PF</given-names>
          </name>
          <name>
            <surname>Hodge</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Bellwood</surname>
            <given-names>DR</given-names>
          </name>
        </person-group>
        <article-title>Colour pattern divergence in reef fish species is rapid and driven by both range overlap and symmetry</article-title>
        <source>Ecology Letters</source>
        <year>2018</year>
        <volume>22</volume>
        <issue>1</issue>
        <fpage>190</fpage>
        <lpage>199</lpage>
        <pub-id pub-id-type="doi">10.1111/ele.13180</pub-id>
        <pub-id pub-id-type="pmid">30467938</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-18">
      <label>Hill, Roger &amp; Vorhagen (1997)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hill</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Roger</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Vorhagen</surname>
            <given-names>FW</given-names>
          </name>
        </person-group>
        <article-title>Comparative analysis of the quantization of color spaces on the basis of the cielab color-difference formula</article-title>
        <source>ACM Transactions on Graphics</source>
        <year>1997</year>
        <volume>16</volume>
        <issue>2</issue>
        <fpage>109</fpage>
        <lpage>154</lpage>
        <pub-id pub-id-type="doi">10.1145/248210.248212</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-19">
      <label>Hornik (2005)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hornik</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>A clue for cluster ensembles</article-title>
        <source>Journal of Statistical Software</source>
        <year>2005</year>
        <volume>14</volume>
        <issue>12</issue>
        <fpage>1</fpage>
        <lpage>25</lpage>
        <pub-id pub-id-type="doi">10.18637/jss.v014.i12</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-20">
      <label>Jonker &amp; Volgenant (1986)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jonker</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Volgenant</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Improving the Hungarian assignment algorithm</article-title>
        <source>Operations Research Letters</source>
        <year>1986</year>
        <volume>5</volume>
        <issue>4</issue>
        <fpage>171</fpage>
        <lpage>175</lpage>
        <pub-id pub-id-type="doi">10.1016/0167-6377(86)90073-8</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-21">
      <label>Kronforst &amp; Papa (2015)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kronforst</surname>
            <given-names>MR</given-names>
          </name>
          <name>
            <surname>Papa</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>The functional basis of wing patterning in heliconius butterflies: the molecules behind mimicry</article-title>
        <source>Genetics</source>
        <year>2015</year>
        <volume>200</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>19</lpage>
        <pub-id pub-id-type="doi">10.1534/genetics.114.172387</pub-id>
        <pub-id pub-id-type="pmid">25953905</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-22">
      <label>Kusnierczyk (2012)</label>
      <element-citation publication-type="software">
        <person-group person-group-type="author">
          <name>
            <surname>Kusnierczyk</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <data-title>rbenchmark: benchmarking routine for R</data-title>
        <year>2012</year>
        <version designator="1.0.0">R package version 1.0.0</version>
        <uri xlink:href="https://CRAN.R-project.org/package=rbenchmark">https://CRAN.R-project.org/package=rbenchmark</uri>
      </element-citation>
    </ref>
    <ref id="ref-23">
      <label>Lev-Yadun et al. (2004)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lev-Yadun</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Dafni</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Flaishman</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Inbar</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Izhaki</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Katzir</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Ne’eman</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Plant coloration undermines herbivorous insect camouflage</article-title>
        <source>BioEssays</source>
        <year>2004</year>
        <volume>26</volume>
        <issue>10</issue>
        <fpage>1126</fpage>
        <lpage>1130</lpage>
        <pub-id pub-id-type="doi">10.1002/bies.20112</pub-id>
        <pub-id pub-id-type="pmid">15382135</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-24">
      <label>Liggs &amp; Mächler (2003)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liggs</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Mächler</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Scatterplot3d–an R package for visualizing multivariate data</article-title>
        <source>Journal of Statistical Software</source>
        <year>2003</year>
        <volume>8</volume>
        <issue>11</issue>
        <fpage>1</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="doi">10.18637/jss.v008.i11</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-25">
      <label>Liu &amp; Nizet (2009)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>GY</given-names>
          </name>
          <name>
            <surname>Nizet</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>Color me bad: microbial pigments as virulence factors</article-title>
        <source>Trends in Microbiology</source>
        <year>2009</year>
        <volume>17</volume>
        <issue>9</issue>
        <fpage>406</fpage>
        <lpage>413</lpage>
        <pub-id pub-id-type="doi">10.1016/j.tim.2009.06.006</pub-id>
        <pub-id pub-id-type="pmid">19726196</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-26">
      <label>Losey et al. (2003)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Losey</surname>
            <given-names>GS</given-names>
          </name>
          <name>
            <surname>McFarland</surname>
            <given-names>WN</given-names>
          </name>
          <name>
            <surname>Loew</surname>
            <given-names>ER</given-names>
          </name>
          <name>
            <surname>Zamzow</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Nelson</surname>
            <given-names>PA</given-names>
          </name>
          <name>
            <surname>Marshall</surname>
            <given-names>NJ</given-names>
          </name>
        </person-group>
        <article-title>Visual biology of Hawaiian coral reef fishes. I. Ocular transmission and visual pigments</article-title>
        <source>Copeia</source>
        <year>2003</year>
        <volume>2003</volume>
        <issue>3</issue>
        <fpage>433</fpage>
        <lpage>454</lpage>
        <pub-id pub-id-type="doi">10.1643/01-053</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-27">
      <label>Maia et al. (2013)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Maia</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Eliason</surname>
            <given-names>CM</given-names>
          </name>
          <name>
            <surname>Bitton</surname>
            <given-names>P-P</given-names>
          </name>
          <name>
            <surname>Doucet</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Shawkey</surname>
            <given-names>MD</given-names>
          </name>
        </person-group>
        <article-title>pavo: an R package for the analysis, visualization and organization of spectral data</article-title>
        <source>Methods in Ecology and Evolution</source>
        <year>2013</year>
        <volume>4</volume>
        <fpage>609</fpage>
        <lpage>613</lpage>
        <pub-id pub-id-type="doi">10.1111/2041-210x.12069</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-28">
      <label>Marshall et al. (2003)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Marshall</surname>
            <given-names>NJ</given-names>
          </name>
          <name>
            <surname>Jennings</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>McFarland</surname>
            <given-names>WN</given-names>
          </name>
          <name>
            <surname>Loew</surname>
            <given-names>ER</given-names>
          </name>
          <name>
            <surname>Losey</surname>
            <given-names>GS</given-names>
          </name>
        </person-group>
        <article-title>Visual biology of Hawaiian coral reef fishes. II. Colors of Hawaiian coral reef fish</article-title>
        <source>Copeia</source>
        <year>2003</year>
        <volume>2003</volume>
        <issue>3</issue>
        <fpage>455</fpage>
        <lpage>466</lpage>
        <pub-id pub-id-type="doi">10.1643/01-055</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-29">
      <label>MATLAB Image Processing Toolbox (2017)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <collab>
            <institution>MATLAB Image Processing Toolbox</institution>
          </collab>
        </person-group>
        <source>MATLAB image processing toolbox</source>
        <year>2017</year>
        <publisher-loc>Natick</publisher-loc>
        <publisher-name>The MathWorks</publisher-name>
      </element-citation>
    </ref>
    <ref id="ref-30">
      <label>Meyer (2006)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meyer</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Repeating patterns of mimicry</article-title>
        <source>PLOS Biology</source>
        <year>2006</year>
        <volume>4</volume>
        <issue>10</issue>
        <elocation-id>e341</elocation-id>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.0040341</pub-id>
        <pub-id pub-id-type="pmid">17048984</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-31">
      <label>Paradis, Claude &amp; Strimmer (2004)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Paradis</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Claude</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Strimmer</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>APE: analyses of phylogenetics and evolution in R language</article-title>
        <source>Bioinformatics</source>
        <year>2004</year>
        <volume>20</volume>
        <fpage>289</fpage>
        <lpage>290</lpage>
        <pub-id pub-id-type="pmid">14734327</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-32">
      <label>Pérez-De la Fuente et al. (2012)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pérez-De la Fuente</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Delclòs</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Peñalver</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Speranza</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wierzchos</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ascaso</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Engel</surname>
            <given-names>MS</given-names>
          </name>
        </person-group>
        <article-title>Early evolution and ecology of camouflage in insects</article-title>
        <source>Proceedings of the National Academy of Sciences of the United States of America</source>
        <year>2012</year>
        <volume>109</volume>
        <issue>52</issue>
        <fpage>21414</fpage>
        <lpage>21419</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1213775110</pub-id>
        <pub-id pub-id-type="pmid">23236135</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-33">
      <label>Phung et al. (2005)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Phung</surname>
            <given-names>SL</given-names>
          </name>
          <name>
            <surname>Bouzerdoum</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Member</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Chai</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Member</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Skin segmentation using color pixel classification: analysis and comparison</article-title>
        <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>
        <year>2005</year>
        <volume>27</volume>
        <issue>1</issue>
        <fpage>148</fpage>
        <lpage>154</lpage>
        <pub-id pub-id-type="doi">10.1109/tpami.2005.17</pub-id>
        <pub-id pub-id-type="pmid">15628277</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-34">
      <label>Plate &amp; Heiberger (2016)</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Plate</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Heiberger</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>abind: combine multidimensional arrays</article-title>
        <year>2016</year>
        <uri xlink:href="https://CRAN.R-project.org/package=abind">https://CRAN.R-project.org/package=abind</uri>
      </element-citation>
    </ref>
    <ref id="ref-35">
      <label>Puebla, Bermingham &amp; Whiteman (2007)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Puebla</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Bermingham</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Whiteman</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Colour pattern as a single trait driving speciation in Hypoplectrus coral reef fishes?</article-title>
        <source>Proceedings of the Royal Society B: Biological Sciences</source>
        <year>2007</year>
        <volume>274</volume>
        <issue>1615</issue>
        <fpage>1265</fpage>
        <lpage>1271</lpage>
        <pub-id pub-id-type="doi">10.1098/rspb.2006.0435</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-36">
      <label>R Core Team (2018)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <collab>
            <institution>R Core Team</institution>
          </collab>
        </person-group>
        <data-title>R: a language and environment for statistical computing</data-title>
        <year>2018</year>
        <publisher-loc>Vienna</publisher-loc>
        <publisher-name>The R Foundation for Statistical Computing</publisher-name>
        <uri xlink:href="http://www.R-project.org/">http://www.R-project.org/</uri>
      </element-citation>
    </ref>
    <ref id="ref-37">
      <label>Ray &amp; Turi (1999)</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Ray</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Turi</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Determination of number of clusters in k-means clustering and application in colour image segmentation</article-title>
        <conf-name>Proceedings of the 4th International Conference on Advances in Pattern Recognition and Digital Techniques</conf-name>
        <publisher-loc>Calcutta, India</publisher-loc>
        <year>1999</year>
        <fpage>137</fpage>
        <lpage>143</lpage>
      </element-citation>
    </ref>
    <ref id="ref-38">
      <label>Rubner &amp; Tomasi (2013)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Rubner</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Tomasi</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <source>Perceptual metrics for image database navigation</source>
        <year>2013</year>
        <volume>594</volume>
        <publisher-loc>Norwell, Massachusetts</publisher-loc>
        <publisher-name>Springer Science &amp; Business Media</publisher-name>
      </element-citation>
    </ref>
    <ref id="ref-39">
      <label>Rubner, Tomasi &amp; Guibas (2000)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rubner</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Tomasi</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Guibas</surname>
            <given-names>LJ</given-names>
          </name>
        </person-group>
        <article-title>The earth mover’s distance as a metric for image retrieval</article-title>
        <source>International Journal of Computer Vision</source>
        <year>2000</year>
        <volume>40</volume>
        <issue>2</issue>
        <fpage>99</fpage>
        <lpage>121</lpage>
      </element-citation>
    </ref>
    <ref id="ref-40">
      <label>Safran &amp; Mcgraw (2004)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Safran</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Mcgraw</surname>
            <given-names>KJ</given-names>
          </name>
        </person-group>
        <article-title>Plumage coloration, not length or symmetry of tail-streamers, is a sexually selected trait in North American barn swallows</article-title>
        <source>Behavioral Ecology</source>
        <year>2004</year>
        <volume>15</volume>
        <issue>3</issue>
        <fpage>455</fpage>
        <lpage>461</lpage>
        <pub-id pub-id-type="doi">10.1093/beheco/arh035</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-41">
      <label>Scheunders (1997)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scheunders</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>A comparison of clustering algorithms applied to color image quantization</article-title>
        <source>Pattern Recognition Letters</source>
        <year>1997</year>
        <volume>18</volume>
        <issue>11–13</issue>
        <fpage>1379</fpage>
        <lpage>1384</lpage>
        <pub-id pub-id-type="doi">10.1016/s0167-8655(97)00116-5</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-42">
      <label>Schindelin et al. (2012)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schindelin</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Arganda-Carreras</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Frise</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Kaynig</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Longair</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Pietzsch</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Preibisch</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Rueden</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Saalfeld</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schmid</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Tinevez</surname>
            <given-names>J-Y</given-names>
          </name>
          <name>
            <surname>White</surname>
            <given-names>DJ</given-names>
          </name>
          <name>
            <surname>Hartenstein</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Eliceiri</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Tomancak</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Cardona</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Fiji: an open-source platform for biological-image analysis</article-title>
        <source>Nature Methods</source>
        <year>2012</year>
        <volume>9</volume>
        <issue>7</issue>
        <fpage>676</fpage>
        <lpage>682</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.2019</pub-id>
        <pub-id pub-id-type="pmid">22743772</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-43">
      <label>Sievert et al. (2017)</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Sievert</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Parmer</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Hocking</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Chamberlain</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Ram</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Corvellec</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Despouy</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>plotly: create interactive web graphics via ‘plotly.js’</article-title>
        <year>2017</year>
        <uri xlink:href="https://CRAN.R-project.org/package=plotly">https://CRAN.R-project.org/package=plotly</uri>
      </element-citation>
    </ref>
    <ref id="ref-44">
      <label>Smith et al. (2016)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Smith</surname>
            <given-names>KR</given-names>
          </name>
          <name>
            <surname>Cadena</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Endler</surname>
            <given-names>JA</given-names>
          </name>
          <name>
            <surname>Kearney</surname>
            <given-names>MR</given-names>
          </name>
          <name>
            <surname>Porter</surname>
            <given-names>WP</given-names>
          </name>
          <name>
            <surname>Stuart-Fox</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Color change for thermoregulation versus camouflage in free-ranging lizards</article-title>
        <source>American Naturalist</source>
        <year>2016</year>
        <volume>188</volume>
        <issue>6</issue>
        <fpage>668</fpage>
        <lpage>678</lpage>
        <pub-id pub-id-type="doi">10.1086/688765</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-45">
      <label>Smith et al. (2008)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Smith</surname>
            <given-names>LL</given-names>
          </name>
          <name>
            <surname>Fessler</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Alfaro</surname>
            <given-names>ME</given-names>
          </name>
          <name>
            <surname>Streelman</surname>
            <given-names>JT</given-names>
          </name>
          <name>
            <surname>Westneat</surname>
            <given-names>MW</given-names>
          </name>
        </person-group>
        <article-title>Phylogenetic relationships and the evolution of regulatory gene sequences in the parrotfishes</article-title>
        <source>Molecular Phylogenetics and Evolution</source>
        <year>2008</year>
        <volume>49</volume>
        <issue>1</issue>
        <fpage>136</fpage>
        <lpage>152</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ympev.2008.06.008</pub-id>
        <pub-id pub-id-type="pmid">18621133</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-46">
      <label>Smith &amp; Goldberg (2015)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Smith</surname>
            <given-names>SD</given-names>
          </name>
          <name>
            <surname>Goldberg</surname>
            <given-names>EE</given-names>
          </name>
        </person-group>
        <article-title>Tempo and mode of flower color evolution</article-title>
        <source>American Journal of Botany</source>
        <year>2015</year>
        <volume>102</volume>
        <issue>7</issue>
        <fpage>1014</fpage>
        <lpage>1025</lpage>
        <pub-id pub-id-type="doi">10.3732/ajb.1500163</pub-id>
        <pub-id pub-id-type="pmid">26199360</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-47">
      <label>Stevens, Lown &amp; Wood (2014)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stevens</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lown</surname>
            <given-names>AE</given-names>
          </name>
          <name>
            <surname>Wood</surname>
            <given-names>LE</given-names>
          </name>
        </person-group>
        <article-title>Color change and camouflage in juvenile shore crabs Carcinus maenas</article-title>
        <source>Frontiers in Ecology and Evolution</source>
        <year>2014</year>
        <volume>2</volume>
        <fpage>14</fpage>
        <pub-id pub-id-type="doi">10.3389/fevo.2014.00014</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-48">
      <label>Troscianko &amp; Stevens (2015)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Troscianko</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Stevens</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Image calibration and analysis toolbox–a free software suite for objectively measuring reflectance, colour and pattern</article-title>
        <source>Methods in Ecology and Evolution</source>
        <year>2015</year>
        <volume>6</volume>
        <issue>11</issue>
        <fpage>1320</fpage>
        <lpage>1331</lpage>
        <pub-id pub-id-type="doi">10.1111/2041-210x.12439</pub-id>
        <pub-id pub-id-type="pmid">27076902</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-49">
      <label>Troscianko et al. (2016)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Troscianko</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wilson-Aggarwal</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Stevens</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Spottiswoode</surname>
            <given-names>CN</given-names>
          </name>
        </person-group>
        <article-title>Camouflage predicts survival in ground-nesting birds</article-title>
        <source>Scientific Reports</source>
        <year>2016</year>
        <volume>6</volume>
        <issue>1</issue>
        <fpage>19966</fpage>
        <pub-id pub-id-type="doi">10.1038/srep19966</pub-id>
        <pub-id pub-id-type="pmid">26822039</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-50">
      <label>Urbanek (2013)</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Urbanek</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>png: Read and write PNG images</article-title>
        <year>2013</year>
        <uri xlink:href="https://CRAN.R-project.org/package=png">https://CRAN.R-project.org/package=png</uri>
      </element-citation>
    </ref>
    <ref id="ref-51">
      <label>Urbanek (2014)</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Urbanek</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>jpeg: read and write JPEG images</article-title>
        <year>2014</year>
        <uri xlink:href="https://CRAN.R-project.org/package=jpeg">https://CRAN.R-project.org/package=jpeg</uri>
      </element-citation>
    </ref>
    <ref id="ref-52">
      <label>Urbanek &amp; Rubner (2012)</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Urbanek</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Rubner</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>emdist: earth mover’s distance</article-title>
        <year>2012</year>
        <uri xlink:href="https://CRAN.R-project.org/package=emdist">https://CRAN.R-project.org/package=emdist</uri>
      </element-citation>
    </ref>
    <ref id="ref-53">
      <label>Van Belleghem et al. (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Van Belleghem</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Papa</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Ortiz-Zuazaga</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Hendrickx</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Jiggins</surname>
            <given-names>CD</given-names>
          </name>
          <name>
            <surname>Mcmillan</surname>
            <given-names>WO</given-names>
          </name>
          <name>
            <surname>Counterman</surname>
            <given-names>BA</given-names>
          </name>
        </person-group>
        <article-title>patternize: an R package for quantifying color pattern variation</article-title>
        <source>Methods in Ecology and Evolution</source>
        <year>2017</year>
        <volume>9</volume>
        <issue>2</issue>
        <fpage>390</fpage>
        <lpage>398</lpage>
        <pub-id pub-id-type="doi">10.1111/2041-210X.12853</pub-id>
        <pub-id pub-id-type="pmid">29755717</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-54">
      <label>Van Der Walt et al. (2014)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Van Der Walt</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schönberger</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Nunez-Iglesias</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Boulogne</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Warner</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>Yager</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Gouillart</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>scikit-image: image processing in python</article-title>
        <source>PeerJ</source>
        <year>2014</year>
        <volume>2</volume>
        <elocation-id>e453</elocation-id>
        <pub-id pub-id-type="doi">10.7717/peerj.453</pub-id>
        <pub-id pub-id-type="pmid">25024921</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-55">
      <label>Vorobyev et al. (2001)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vorobyev</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Marshall</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Osorio</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Ibarra</surname>
            <given-names>NHD</given-names>
          </name>
          <name>
            <surname>Menzel</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Colourful objects through animal eyes</article-title>
        <source>Color Research and Application</source>
        <year>2001</year>
        <volume>26</volume>
        <issue>S1</issue>
        <fpage>S214</fpage>
        <lpage>S217</lpage>
        <pub-id pub-id-type="doi">10.1002/1520-6378(2001)26:1+&lt;::aid-col45&gt;3.0.co;2-a</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-56">
      <label>Warnes et al. (2016)</label>
      <element-citation publication-type="other">
        <person-group person-group-type="author">
          <name>
            <surname>Warnes</surname>
            <given-names>GR</given-names>
          </name>
          <name>
            <surname>Bolker</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Bonebakker</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Gentleman</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Huber</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Liaw</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lumley</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Maechler</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Magnusson</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Moeller</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schwartz</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Venables</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>gplots: various R programming tools for plotting data</article-title>
        <year>2016</year>
        <uri xlink:href="https://CRAN.R-project.org/package=gplots">https://CRAN.R-project.org/package=gplots</uri>
      </element-citation>
    </ref>
    <ref id="ref-57">
      <label>Wood (2011)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wood</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Fast stable restricted maximum likelihood and marginal likelihood estimation of semiparametric generalized linear models</article-title>
        <source>Journal of the Royal Statistical Society Series B (Statistical Methodology)</source>
        <year>2011</year>
        <volume>73</volume>
        <issue>1</issue>
        <fpage>3</fpage>
        <lpage>36</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1467-9868.2010.00749.x</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-58">
      <label>Zeileis, Hornik &amp; Murrell (2009)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zeileis</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hornik</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Murrell</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Escaping RGBland: selecting colors for statistical graphics</article-title>
        <source>Computational Statistics &amp; Data Analysis</source>
        <year>2009</year>
        <volume>53</volume>
        <issue>9</issue>
        <fpage>3259</fpage>
        <lpage>3270</lpage>
        <pub-id pub-id-type="doi">10.1016/j.csda.2008.11.033</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-59">
      <label>Zhang, Barhomi &amp; Serre (2012)</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Barhomi</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Serre</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>A new biologically inspired color image descriptor</article-title>
        <source>European Conference on Computer Vision</source>
        <year>2012</year>
        <publisher-loc>Berlin, Heidelberg</publisher-loc>
        <publisher-name>Springer</publisher-name>
        <fpage>312</fpage>
        <lpage>324</lpage>
      </element-citation>
    </ref>
  </ref-list>
</back>
