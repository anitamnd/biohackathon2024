<?OLF?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?covid-19-tdm?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Behav Res Methods</journal-id>
    <journal-id journal-id-type="iso-abbrev">Behav Res Methods</journal-id>
    <journal-title-group>
      <journal-title>Behavior Research Methods</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1554-351X</issn>
    <issn pub-type="epub">1554-3528</issn>
    <publisher>
      <publisher-name>Springer US</publisher-name>
      <publisher-loc>New York</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9450820</article-id>
    <article-id pub-id-type="publisher-id">1948</article-id>
    <article-id pub-id-type="doi">10.3758/s13428-022-01948-8</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>jsQuestPlus: A JavaScript implementation of the QUEST+ method for estimating psychometric function parameters in online experiments</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Kuroki</surname>
          <given-names>Daiichiro</given-names>
        </name>
        <address>
          <email>kurokid@kyudai.jp</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Pronk</surname>
          <given-names>Thomas</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.177174.3</institution-id><institution-id institution-id-type="ISNI">0000 0001 2242 4849</institution-id><institution>Department of Psychology, School of Letters, </institution><institution>Kyushu University, </institution></institution-wrap>744 Motooka, Nishi-ku, Fukuoka, 819-0395 Japan </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.7177.6</institution-id><institution-id institution-id-type="ISNI">0000000084992262</institution-id><institution>Behavioural Science Lab, Faculty of Social and Behavioural Sciences, </institution><institution>University of Amsterdam, </institution></institution-wrap>Amsterdam, Netherlands </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>7</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <fpage>1</fpage>
    <lpage>8</lpage>
    <history>
      <date date-type="accepted">
        <day>1</day>
        <month>8</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Psychonomic Society, Inc. 2022, Springer Nature or its licensor holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.</copyright-statement>
      <license>
        <license-p>This article is made available via the PMC Open Access Subset for unrestricted research re-use and secondary analysis in any form or by any means with acknowledgement of the original source. These permissions are granted for the duration of the World Health Organization (WHO) declaration of COVID-19 as a global pandemic.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">The two Bayesian adaptive psychometric methods named QUEST (Watson &amp; Pelli, 1983) and QUEST+ (Watson, 2017) are widely used to estimate psychometric parameters, especially the threshold, in laboratory-based psychophysical experiments. Considering the increase of online psychophysical experiments in recent years, there is a growing need to have the QUEST and QUEST+ methods available online as well. We developed JavaScript libraries for both, with this article introducing one of them: jsQuestPlus. We offer integrations with online experimental tools such as jsPsych (de Leeuw, 2015), PsychoPy/JS (Peirce et al., 2019), and lab.js (Henninger et al., 2021). We measured the computation time required by jsQuestPlus under four conditions. Our simulations on 37 browser–computer combinations showed that the mean initialization time was 461.08 ms, 95% CI [328.29, 593.87], the mean computation time required to determine the stimulus parameters for the next trial was less than 1 ms, and the mean update time was 79.39 ms, 95% CI [46.22, 112.55] even in extremely demanding conditions. Additionally, psychometric parameters were estimated as accurately as the original QUEST+ method did. We conclude that jsQuestPlus is fast and accurate enough to conduct online psychophysical experiments despite the complexity of the matrix calculations. The latest version of jsQuestPlus can be downloaded freely from <ext-link ext-link-type="uri" xlink:href="https://github.com/kurokida/jsQuestPlus">https://github.com/kurokida/jsQuestPlus</ext-link> under the MIT license.</p>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Online experiments</kwd>
      <kwd>Psychophysical threshold</kwd>
      <kwd>Psychometric functions</kwd>
      <kwd>Adaptive psychometric methods</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par2">Adaptive psychometric procedures enable experimenters to estimate thresholds efficiently by determining the stimulus parameters based on the stimuli and the observer’s responses in the preceding trials (for reviews, see Leek, <xref ref-type="bibr" rid="CR24">2001</xref>; Treutwein, <xref ref-type="bibr" rid="CR46">1995</xref>). This efficiency is desirable for experiments in general, but even more so when faced with time constraints, such as in experiments on children and/or in clinical settings. Adaptive procedures have been refined over the decades and show enduring popularity, but as yet mainly in laboratory-based psychophysical research (e.g., Keefe et al., <xref ref-type="bibr" rid="CR16">2021</xref>; Kim &amp; Chong, <xref ref-type="bibr" rid="CR17">2021</xref>; Levinson et al., <xref ref-type="bibr" rid="CR25">2021</xref>; Song et al., <xref ref-type="bibr" rid="CR44">2021</xref>; Yu &amp; Postle, <xref ref-type="bibr" rid="CR49">2021</xref>).</p>
    <p id="Par3">On the other hand, there has been an increase in online psychophysical experiments (e.g., Bunce et al., <xref ref-type="bibr" rid="CR6">2021</xref>; Kawabe, <xref ref-type="bibr" rid="CR15">2021</xref>; Santacroce et al., <xref ref-type="bibr" rid="CR42">2021</xref>; Sasaki &amp; Yamada, <xref ref-type="bibr" rid="CR43">2019</xref>). Santacroce et al. (<xref ref-type="bibr" rid="CR42">2021</xref>) were not planning to do their experiments online but decided to conduct part of the experiments online due to COVID-19. In addition to efficient recruitment of a large number and wide variety of participants (Reips, <xref ref-type="bibr" rid="CR41">2021</xref>), online experiments can proceed regardless of any lockdown measures. Considering the rise in online psychophysical experiments, there is a growing need for online experiment tools to match the functionality offered in the lab. Specifically, we focus on online experiments as web applications that can be deployed via the Internet to web browsers on laptops, desktops, smartphones, and tablets. We focus on the former, because these types of online experiments are extremely widely supported and based on durable open standards, such as HTML, CSS, and JavaScript (Pronk et al., <xref ref-type="bibr" rid="CR38">2020</xref>).</p>
    <p id="Par4">Given the popularity of adaptive procedures, these are excellent candidates to offer online. For one of the older and most well-known adaptive methods, the up-down staircase (Levitt, <xref ref-type="bibr" rid="CR26">1971</xref>), some excellent online implementations are already available (e.g., Hadrien &amp; Jaquiery, <xref ref-type="bibr" rid="CR9">2016</xref>; Hirst, <xref ref-type="bibr" rid="CR11">2020</xref>). A more modern method is based on a Bayesian framework introduced by Watson and Pelli (<xref ref-type="bibr" rid="CR48">1983</xref>), which combines the experimenter’s prior knowledge of psychometric parameters with actual data obtained through a series of trials in the current experiment. The original staircase method based on this Bayesian framework, named QUEST (Watson &amp; Pelli, <xref ref-type="bibr" rid="CR48">1983</xref>), assumes one stimulus dimension, two response options (e.g., Yes/No or Correct/Incorrect), and can estimate one psychometric parameter, usually a threshold. In the QUEST method, a unimodal probability density function (PDF), such as a Gaussian function, is assumed as a prior PDF as shown in the MATLAB-based program (Pelli, <xref ref-type="bibr" rid="CR36">1996</xref>). The PDF is updated every trial to best fit the stimulus intensities and responses in the preceding trials. The stimulus intensity for the next trial and the final estimate of the threshold are determined by using the mode of the current PDF (Watson &amp; Pelli, <xref ref-type="bibr" rid="CR48">1983</xref>), the quantile (Pelli, 1987 as cited in Pelli, <xref ref-type="bibr" rid="CR36">1996</xref>), or the mean (King-Smith et al., <xref ref-type="bibr" rid="CR18">1994</xref>). The reference implementation of QUEST was written in BASIC, with a MATLAB version included in Psychtoolbox (Brainard, <xref ref-type="bibr" rid="CR4">1997</xref>; Pelli, <xref ref-type="bibr" rid="CR37">1997</xref>), and a Python version (Straw, <xref ref-type="bibr" rid="CR45">2008</xref>) included in PsychoPy (Peirce, <xref ref-type="bibr" rid="CR34">2007</xref>; Peirce et al., <xref ref-type="bibr" rid="CR35">2019</xref>).</p>
    <p id="Par5">Watson (<xref ref-type="bibr" rid="CR47">2017</xref>) extended the QUEST method to allow multiple stimulus parameters, multiple psychometric parameters, and more than two responses options. The QUEST+ method calculates the expected entropies of the PDF of the psychometric parameters, selecting stimulus parameters that minimize the expected entropy for the next trial (Kontsevich &amp; Tyler, <xref ref-type="bibr" rid="CR19">1999</xref>; Watson, <xref ref-type="bibr" rid="CR47">2017</xref>). Finally, the parameters with the highest PDF are regarded as the estimates. For the QUEST+ method, Watson's (<xref ref-type="bibr" rid="CR47">2017</xref>) reference implementation is in Mathematica, followed by versions in MATLAB (Brainard, <xref ref-type="bibr" rid="CR5">2017</xref>; Jones, <xref ref-type="bibr" rid="CR13">2018</xref>) and Python (Höchenberger, <xref ref-type="bibr" rid="CR12">2019</xref>).</p>
    <p id="Par6">The QUEST and QUEST+ implementations above have been written in programming languages (BASIC, Mathematica, MATLAB, and Python) that are not compatible with web browsers. Hence, using any of these implementations in the context of an online study would require server-side infrastructure and client–server communication, thereby introducing significant complexity and possible latency. Alternatively, QUEST and QUEST+ implementations in JavaScript could run in a web browser, thereby having the potential to be simpler and easier to integrate into existing online task software.</p>
    <p id="Par7">Hence, we developed JavaScript implementations of both QUEST and QUEST+, named jsQUEST (Kuroki &amp; Pronk, <xref ref-type="bibr" rid="CR22">2021a</xref>) and jsQuestPlus (Kuroki &amp; Pronk, <xref ref-type="bibr" rid="CR23">2021b</xref>). Since the QUEST+ method is an extension of the QUEST method, one might think that there is no need to develop JavaScript libraries for both. While that assertion is correct, we had to be prudent because of two reasons. Firstly, experimenters may prefer the traditional QUEST method for a simple experiment in which there are a single stimulus parameter, a single psychometric parameter (e.g., threshold), and two response options because they can more concisely code their experiment compared to the QUEST+ method. Secondly, it is possible that the QUEST method is persistently used in the laboratory and hence is required when directly replicating studies from such a lab online. For these reasons, we have developed both jsQUEST and jsQuestPlus, but the remainder of this paper will focus primarily on the QUEST+ method (jsQuestPlus).</p>
    <p id="Par8">In the next section, we briefly introduce the core functionality of jsQuestPlus via an example from the paper introducing QUEST+ (Watson, <xref ref-type="bibr" rid="CR47">2017</xref>). In the associated GitHub repositories, we offer brief tutorials for integrating jsQUEST and jsQuestPlus into three major experiment libraries: jsPsych (de Leeuw, <xref ref-type="bibr" rid="CR8">2015</xref>), lab.js (Henninger et al., <xref ref-type="bibr" rid="CR10">2021</xref>), and PsychoJS (Peirce et al., <xref ref-type="bibr" rid="CR35">2019</xref>).</p>
  </sec>
  <sec id="Sec2">
    <title>Functions of jsQuestPlus</title>
    <p id="Par9">The QUEST+ method consists of three parts: initialization, determining the stimulus parameters for the next trial, and updating the data (based on the response to a given stimulus). We will explain the details according to the second example, labeled as <italic>Estimation of contrast threshold, slope, and lapse {1, 3, 2}</italic>, in Watson (<xref ref-type="bibr" rid="CR47">2017</xref>). In this example, there is a single stimulus parameter (contrast) and three psychometric parameters (threshold, slope, and lapse). A Weibull function is assumed to be the psychometric function, and the task is two-alternative forced choice. Using the QUEST+ method, the three psychometric parameters can be estimated.</p>
    <p id="Par10">To initialize the QUEST+ data, the psychometric functions corresponding to each response must be specified. For example, the function representing probabilities of incorrect responses (response = 0) can be written as follows.</p>
    <graphic position="anchor" xlink:href="13428_2022_1948_Figa_HTML" id="MO1"/>
    <p id="Par11">This describes the Weibull function, which is also available in jsQuestPlus as <italic>jsquest.weibull</italic>. The function representing probabilities of correct responses (response = 1) can be written as follows:</p>
    <graphic position="anchor" xlink:href="13428_2022_1948_Figb_HTML" id="MO2"/>
    <p id="Par12">The <italic>func_resp0</italic> and <italic>func_resp1</italic> are complementary, in other words, the probabilities they return add up to 1. Next, we need to specify the range of possible values for the stimulus and psychometric parameters. These parameters must be specified as an array, also when they are single values, for which <italic>jsQuestPlus.linspace</italic> and <italic>jsQuestPlus.array</italic> can be used:</p>
    <graphic position="anchor" xlink:href="13428_2022_1948_Figc_HTML" id="MO3"/>
    <p id="Par13">Note that a larger number of samples will affect the execution time of the QUEST+ method. This will be discussed in more detail in the simulation section. After specifying the psychometric functions and possible parameters, initialize the QUEST+ object as follows:</p>
    <graphic position="anchor" xlink:href="13428_2022_1948_Figd_HTML" id="MO4"/>
    <p id="Par14">Here, <italic>jsqp</italic> is an abbreviation of jsQuestPlus, but any valid JavaScript variable name could be used instead. The jsQuestPlus constructor should receive one argument, which is an object with three properties: <italic>psych_func</italic>, <italic>stim_samples</italic>, and <italic>psych_samples</italic>. Note that the elements in the <italic>psych_samples</italic> array (i.e., threshold, slope, guess, and lapse) must be written in the order specified in the psychometric function declaration. Although priors will be treated as a uniform probability over all psychometric parameter combinations by default, these can be specified individually. See the associated GitHub repositories for details.</p>
    <p id="Par15">After completing the initialization, the stimulus parameters that are predicted to yield the most informative results at the next trial can be obtained as follows:</p>
    <graphic position="anchor" xlink:href="13428_2022_1948_Fige_HTML" id="MO5"/>
    <p id="Par16">The <italic>getStimParams</italic> function returns the stimulus parameter(s) that minimize(s) the expected entropies of the PDF of the psychometric parameters. The QUEST+ method recommends presenting the stimulus with the returned parameters and obtaining the response. In the example task, the response is 0 or 1. This response should match the index of the corresponding psychometric function in the array passed to the jsQuestPlus constructor. If a correct response (response = 1) is obtained, update the PDF and the expected entropies as follows:</p>
    <graphic position="anchor" xlink:href="13428_2022_1948_Figf_HTML" id="MO6"/>
    <p id="Par17">The presentation of stimuli, obtaining the responses, and updating of the data are repeated a predetermined number of times. Finally, the psychometric parameter estimates with the highest posterior probability can be obtained as follows:</p>
    <graphic position="anchor" xlink:href="13428_2022_1948_Figg_HTML" id="MO7"/>
    <p id="Par18">The <italic>estimates</italic> array includes the estimates of each psychometric parameter, that is, the threshold, slope, and lapse in this example.</p>
  </sec>
  <sec id="Sec3">
    <title>Simulation</title>
    <p id="Par19">The computational complexity of the QUEST+ method has been found to increase in proportion to the number of stimulus parameters, the number of psychometric parameters, the number of response options, and the number of samples in each parameter (Watson, <xref ref-type="bibr" rid="CR47">2017</xref>). Watson conducted a simulation that measured the computation time for various numbers of samples and reported that it does not exceed one second per trial even under extremely high computational complexity. In laboratory-based experiments, the QUEST+ method is considered practical because a single computer with high computing power is often used. Web-based experiments could require longer computation times because (a) participants’ computers have more variation in processing power than in a lab, and (b) in contrast to MATLAB or Mathematica, JavaScript is not optimized for matrix computations. Hence, it is important to ensure our library is tested for performance: does it deliver psychometric parameters fast enough? Hence, we examined the performance of jsQuestPlus as a function of computational complexity across a range of commodity devices and browsers.</p>
  </sec>
  <sec id="Sec4">
    <title>Methods</title>
    <p id="Par20">For our performance test, we selected four conditions from Watson’s (<xref ref-type="bibr" rid="CR47">2017</xref>) simulations, corresponding to Examples 1, 2, 4, and 5 in the paper, respectively. The number of samples was calculated by multiplying the number of possible values in each parameter. For example, in Example 2 of Watson (<xref ref-type="bibr" rid="CR47">2017</xref>), the number of samples is 41 (-40, -39, -38, …, 0) for the stimulus parameter, is 41 (-40, -39, -38, …, 0) for threshold, is 4 (2, 3, 4, 5) for slope, is 5 (0, .01, .02, .03, .04) for lapse, and is 2 for response; the total number of samples is 67240 by multiplying all the sample numbers. See also the complexity and timing section of Watson (<xref ref-type="bibr" rid="CR47">2017</xref>). Our four conditions are summarized in Table <xref rid="Tab1" ref-type="table">1</xref>.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Number of parameters, number of responses, and number of samples in the four simulated conditions</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Condition</th><th>Number of stimulus parameters</th><th>Number of psychometric parameters</th><th>Number of responses</th><th>Total number of samples</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>1</td><td>2</td><td>3,362</td></tr><tr><td>2</td><td>1</td><td>3</td><td>2</td><td>67,240</td></tr><tr><td>3</td><td>2</td><td>3</td><td>2</td><td>660,660</td></tr><tr><td>4</td><td>3</td><td>4</td><td>2</td><td>911,250</td></tr></tbody></table></table-wrap></p>
    <p id="Par21">The simulation program was written using jsPsych (de Leeuw, <xref ref-type="bibr" rid="CR8">2015</xref>) and jsQuestPlus. Following Watson’s (<xref ref-type="bibr" rid="CR47">2017</xref>) examples, the four conditions were repeated 32, 64, 32, and 64 times, respectively. We measured (a) the time it took to initialize jsQuestPlus, (b) the time it took to determine the stimulus parameters, specifically the time to call the <italic>getStimParams</italic> function, and (c) the time it took to call the update function. Each duration was measured using the <italic>performance.now</italic> function, which provides a timestamp with microsecond precision. Duration (a) was obtained once for each browser–computer combination, while durations (b) and (c) were averaged over trials since they were measured repeatedly for each browser–computer combination.</p>
    <p id="Par22">We asked the members of the authors' research groups to access the simulation program via the Internet. Participants could run the program as many times as they wished under the condition that such participations used different web browsers on the same device or used a different device. Both operating system (OS) and web browser information were obtained using platform.js (Dalton &amp; Tan, <xref ref-type="bibr" rid="CR7">2020</xref>). In total, we obtained simulation data of 37 browser–computer combinations. OS and browser are summarized in Tables <xref rid="Tab2" ref-type="table">2</xref> and <xref rid="Tab3" ref-type="table">3</xref>.<table-wrap id="Tab2"><label>Table 2</label><caption><p>Number of operating systems tested</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Operating system</th><th>Number</th></tr></thead><tbody><tr><td>Android</td><td>4</td></tr><tr><td>iOS</td><td>6</td></tr><tr><td>Mac OS X</td><td>6</td></tr><tr><td>Windows</td><td>21</td></tr></tbody></table></table-wrap><table-wrap id="Tab3"><label>Table 3</label><caption><p>Number of web browsers tested</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Web browser</th><th>Number</th></tr></thead><tbody><tr><td>Chrome</td><td>12</td></tr><tr><td>Chrome Mobile</td><td>4</td></tr><tr><td>Firefox</td><td>6</td></tr><tr><td>Firefox Mobile</td><td>1</td></tr><tr><td>Microsoft Edge</td><td>7</td></tr><tr><td>Safari</td><td>7</td></tr></tbody></table></table-wrap></p>
    <p id="Par23">One might be interested in the result of computers with low performance. Although platform.js could not basically collect detailed information such as model number, we confirmed from the user agent information that SONY 801SO, SHARP SHV47, and HUAWEI RNE-L22 were included. These are smartphones—a device type of which recent studies suggest that they may be a suitable medium for administering cognitive tasks (Pronk et al., <xref ref-type="bibr" rid="CR39">2022</xref>). As for the RNE-L22, it was a low-spec model released several years ago (CPU: 2.36 GHz 4 core &amp; 1.7 GHz 4 core; RAM: 4 GB). Moreover, detailed OS numbers are also recorded for iOS and Mac OS. We found a Mac using macOS High Sierra (10.13.6), which was released in 2017. The computation time on these computers can be used as a reference when conducting experiments using equipment with low computational power. All the user agent information is available at OSF (<ext-link ext-link-type="uri" xlink:href="https://osf.io/tqesb/">https://osf.io/tqesb/</ext-link>).</p>
  </sec>
  <sec id="Sec5">
    <title>Results</title>
    <p id="Par24">The time required to initialize jsQuestPlus, determine the stimulus parameters, and update the data are summarized in Table <xref rid="Tab4" ref-type="table">4</xref>. Values in brackets represent 95% confidence intervals assuming a <italic>t</italic> distribution (<italic>df</italic> = 36). While the time required for initialization and updating increased with the number of parameters, the time required to determine the stimulus parameters did not show such a trend, and was fast enough to be considered a negligible factor in an actual experiment. Although the time required for initialization was relatively long compared to the update times, it was less than one second. The time required for updating was, contrary to our concerns, much faster than that reported by Watson (<xref ref-type="bibr" rid="CR47">2017</xref>). When using hardware with relatively low computational power, the computation time in the most demanding condition (condition 4) was 1713 ms (RNE-L22) and 353.3 ms (maOS High Sierra) for initialization, 0.12 ms (RNE-L22) and 0.08 ms (maOS High Sierra) for determination of stimulus parameters, and 198.3 ms (RNE-L22) and 38.9 ms (maOS High Sierra) for updating. Histograms for computation time in the most demanding condition is shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. Histograms for all the conditions are available at OSF (<ext-link ext-link-type="uri" xlink:href="https://osf.io/tqesb/">https://osf.io/tqesb/</ext-link>).<table-wrap id="Tab4"><label>Table 4</label><caption><p>Computation times required to run jsQuestPlus in milliseconds. Confidence intervals (CIs) assume a <italic>t</italic> distribution (<italic>df</italic> = 36). The larger the condition number, the greater the computational load</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Condition</th><th colspan="2">Initialization</th><th colspan="2">Determination of stimulus parameters</th><th colspan="2">Update</th><th rowspan="2">Watson (<xref ref-type="bibr" rid="CR47">2017</xref>)</th></tr><tr><th>Mean</th><th>95% CI</th><th>Mean</th><th>95% CI</th><th>Mean</th><th>95% CI</th></tr></thead><tbody><tr><td>1</td><td>12.68</td><td>[8.49, 16.88]</td><td>0.07</td><td>[0.04, 0.09]</td><td>1.29</td><td>[0.96, 1.62]</td><td>4.4</td></tr><tr><td>2</td><td>47.38</td><td>[35.93, 58.82]</td><td>0.03</td><td>[0.02, 0.04]</td><td>12.25</td><td>[8.68, 15.81]</td><td>41</td></tr><tr><td>3</td><td>333.96</td><td>[239.35, 428.57]</td><td>0.05</td><td>[0.03, 0.07]</td><td>61.58</td><td>[39.04, 84.12]</td><td>200</td></tr><tr><td>4</td><td>461.08</td><td>[328.29, 593.87]</td><td>0.06</td><td>[0.03, 0.08]</td><td>79.39</td><td>[46.22, 112.55]</td><td>270</td></tr></tbody></table><table-wrap-foot><p>Watson (<xref ref-type="bibr" rid="CR47">2017</xref>) reported the total time required to determine stimulus parameters and to update the data for the next trial</p></table-wrap-foot></table-wrap><fig id="Fig1"><label>Fig. 1</label><caption><p>Histograms for computation time in the most demanding condition (condition 4). <bold>a</bold> Time for initialization. <bold>b</bold> Time for determination of stimulus parameters. <bold>c</bold> Time for updating. The respective bin sizes are (<bold>a</bold>) 50 ms, (<bold>b</bold>) 0.2 ms, and (<bold>c</bold>) 50 ms</p></caption><graphic xlink:href="13428_2022_1948_Fig1_HTML" id="MO8"/></fig></p>
    <p id="Par25">A reviewer suggested presenting not only the time data but also the validation data of jsQuestPlus. The simulation program described above measured time as well as estimated psychometric parameters. Table <xref rid="Tab5" ref-type="table">5</xref> summarized the estimates and 95% confidence intervals (CIs) of the psychometric parameters for each condition. The 95% CIs include simulated values except for the slope and lapse parameters in the condition 2.<table-wrap id="Tab5"><label>Table 5</label><caption><p>Simulated values and values estimated by jsQuestPlus. Confidence intervals (CIs) assume a <italic>t</italic> distribution (<italic>df</italic> = 36). For more information on the simulated conditions, see Watson (<xref ref-type="bibr" rid="CR47">2017</xref>)</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Condition</th><th>Psychometric parameter</th><th>Simulated value</th><th>Estimate</th><th>95% CI</th><th>Watson (<xref ref-type="bibr" rid="CR47">2017</xref>)</th></tr></thead><tbody><tr><td>1</td><td>Threshold</td><td>-20</td><td>-19.97</td><td>[-20.75, -19.19]</td><td>-20</td></tr><tr><td>2</td><td>Threshold</td><td>-20</td><td>-19.78</td><td>[-20.10, -19.47]</td><td>-20</td></tr><tr><td/><td>Slope</td><td>3</td><td>3.92</td><td>[3.47, 4.37]</td><td>5</td></tr><tr><td/><td>Lapse</td><td>0.02</td><td>0.0073</td><td>[0.0031, 0.0115]</td><td>0.04</td></tr><tr><td>3</td><td>Minimum threshold (t)</td><td>-35</td><td>-34.70</td><td>[-36.07, -33.33]</td><td>-32</td></tr><tr><td/><td>Coefficient (c0)</td><td>-50</td><td>-49.84</td><td>[-51.59, -48.08]</td><td>-56</td></tr><tr><td/><td>Coefficient (cf)</td><td>1.2</td><td>1.19</td><td>[1.14, 1.24]</td><td>1.4</td></tr><tr><td>4</td><td>Minimum threshold (t)</td><td>-40</td><td>-40.95</td><td>[-42.05, -39.85]</td><td>-35</td></tr><tr><td/><td>Coefficient (c0)</td><td>-50</td><td>-50.68</td><td>[-52.05, -49.31]</td><td>-50</td></tr><tr><td/><td>Coefficient (cf)</td><td>1.2</td><td>1.22</td><td>[1.17, 1.26]</td><td>1.2</td></tr><tr><td/><td>Coefficient (cw)</td><td>1.0</td><td>1.01</td><td>[0.97, 1.05]</td><td>1.0</td></tr></tbody></table></table-wrap></p>
  </sec>
  <sec id="Sec6">
    <title>Discussion</title>
    <p id="Par26">This study presented a Bayesian adaptive psychometric method for online experiments named jsQuestPlus. It works in combination with existing online experimental tools such as jsPsych (de Leeuw, <xref ref-type="bibr" rid="CR8">2015</xref>), PsychoJS (Peirce et al., <xref ref-type="bibr" rid="CR35">2019</xref>), and lab.js (Henninger et al., <xref ref-type="bibr" rid="CR10">2021</xref>), and should work with other experimental tools like OpenSesame/OSWeb (Mathôt et al., <xref ref-type="bibr" rid="CR30">2012</xref>) and Gorilla (Anwyl-Irvine et al., <xref ref-type="bibr" rid="CR1">2020</xref>).</p>
    <p id="Par27">Our simulation showed that computation times were short enough for most online psychophysical experiments. With a large number of samples, initialization could be relatively slow. However, initialization is only required at the beginning of a series of trials, so it is unlikely that the initialization time will cause problems in conducting an experiment. The time for updating the data tends to become longer as the total number of samples increases and may take up to 100 ms on average, so the function should be called during a less time-critical phase of a task, such as after the end of the previous trial. The execution time of the function to determine the stimulus intensity (<italic>getStimParams</italic>) was less than 1 ms, so calling it immediately before the stimulus is presented should not be a problem. If the execution time would ever become a concern, execution of <italic>getStimParams</italic> could be relegated to a less time-critical phase of a task, similar to what we recommend for updating the data. A more flexible solution would be the incorporation of Web Workers (Mozilla, <xref ref-type="bibr" rid="CR31">2022</xref>), so that jsQuestPlus calculations are executed as a background process that is less likely to interfere with the task procedure.</p>
    <p id="Par28">The jsQuestPlus library could accurately estimate psychometric parameters except for the slope and lapse parameters in the condition 2. When inaccurate, the biases displayed by jsQuestPlus were similar to those observed in QUEST+ by Watson (<xref ref-type="bibr" rid="CR47">2017</xref>). In other words, we explain the biases we observed in jsQuestPlus as being endemic to the QUEST+ method. Solving this problem is an interesting topic, but beyond the scope of our study. Regardless, the parameter that tends to be of the greatest interest to psychometric models, namely threshold, is being estimated very accurately.</p>
    <p id="Par29">In laboratory-based experiments, the QUEST method has been often used to modulate the contrast of a grating (e.g., Keefe et al., <xref ref-type="bibr" rid="CR16">2021</xref>; Kim &amp; Chong, <xref ref-type="bibr" rid="CR17">2021</xref>; Yu &amp; Postle, <xref ref-type="bibr" rid="CR49">2021</xref>). Such procedures require calibrating the monitor brightness. In online experiments, it is very difficult to calibrate the monitors used by participants. Moreover, the resolution of a standard 8-bit display (256 discrete levels of brightness) might be too small for some of the psychophysical experiments. A limited solution for these problems is to restrict the model of the devices and to allow participants to participate in the experiment if they can prepare their devices before taking part.</p>
    <p id="Par30">On the other hand, recent laboratory-based experiments have used the QUEST method to manipulate the number of random dots (Kurki, <xref ref-type="bibr" rid="CR20">2019</xref>), the motion direction of random dots (Song et al., <xref ref-type="bibr" rid="CR44">2021</xref>), and the size of an aperture (Luzardo &amp; Yeshurun, <xref ref-type="bibr" rid="CR28">2021</xref>). These experiments should be suitable for online administration, especially now that technology for online random dot kinematograms (Rajananda et al., <xref ref-type="bibr" rid="CR40">2018</xref>), virtual chinrests (Li et al., <xref ref-type="bibr" rid="CR27">2020</xref>), and a jsPsych plugin for psychophysics (Kuroki, <xref ref-type="bibr" rid="CR21">2021</xref>) are available. Moreover, it is noteworthy that Myrodia et al. (<xref ref-type="bibr" rid="CR32">2021</xref>) showed that there was no difference in perceptual thresholds of the perceived quality of computer-generated images between laboratory-based and online experiments using the QUEST+ method. Future research could investigate whether well-known results of laboratory-based experiments using the QUEST/QUEST+ method can be replicated online.</p>
    <p id="Par31">The accuracy of the QUEST+ method, both online and in the lab, can be affected by lapses in concentration. Jones (<xref ref-type="bibr" rid="CR14">2019</xref>) reviewed several approaches for taking lapses into account and proposed to weigh participants' responses by the probability that a lapse occurred. For detecting whether a lapse occurred, they suggest using eye, head, or upper body movements, in combination with response latency or consistency. Such measures can also be acquired online since modern web browsers offer access to a wide range of sensors. For instance, online head- and eye-tracking can be performed via WebGazer (Papoutsaki et al., <xref ref-type="bibr" rid="CR33">2016</xref>) and mouse-tracking via MouseView (Anwyl-Irvine et al., <xref ref-type="bibr" rid="CR2">2021</xref>).</p>
    <p id="Par32">One useful feature that jsQuestPlus does not provide, but that QUEST+ based on Mathematica and MATLAB do, is fitting which is performed post hoc, and enables to estimate the psychometric parameters with a high degree of precision and range. As illustrated by Manning et al. (<xref ref-type="bibr" rid="CR29">2018</xref>), more finely grained estimates can be closer to the true threshold, especially when analyzing data of children with attentional lapses. Although the fitting function is not included in jsQuestPlus, it can be performed afterwards using Mathematica or MATLAB. See the associated GitHub repositories for details.</p>
    <p id="Par33">While there are some limitations to conducting psychophysical experiments online, there are many advantages as well. For example, researchers can efficiently recruit a diverse group of participants and data collection at home can be conducted regardless of lock-down measures (as have been issued lately in response to COVID-19). In addition, online experiments embrace open science values, because, in principle, anyone can replicate procedures without needing to purchase any software licenses or specialized hardware. We hope that the tools introduced here will further increase the variety of experiments that can be conducted online. Both the jsQUEST (<ext-link ext-link-type="uri" xlink:href="https://github.com/kurokida/jsQUEST">https://github.com/kurokida/jsQUEST</ext-link>) and jsQuestPlus (<ext-link ext-link-type="uri" xlink:href="https://github.com/kurokida/jsQuestPlus">https://github.com/kurokida/jsQuestPlus</ext-link>) libraries are available under the MIT license on the GitHub registry, where they can be downloaded, forked, discussed, and improved.</p>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Open practices statement</bold>
      </p>
      <p>The data and materials for all experiments are available at Open Science Framework (<ext-link ext-link-type="uri" xlink:href="https://osf.io/tqesb/">https://osf.io/tqesb/</ext-link>), and none of the experiments was preregistered.</p>
    </fn>
    <fn>
      <p>
        <bold>Publisher’s note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ref-list id="Bib1">
    <title>
References</title>
    <ref id="CR1">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Anwyl-Irvine</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Massonnié</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Flitton</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kirkham</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Evershed</surname>
            <given-names>JK</given-names>
          </name>
        </person-group>
        <article-title>Gorilla in our midst: An online behavioral experiment builder</article-title>
        <source>Behavior Research Methods</source>
        <year>2020</year>
        <volume>52</volume>
        <issue>1</issue>
        <fpage>388</fpage>
        <lpage>407</lpage>
        <pub-id pub-id-type="doi">10.3758/s13428-019-01237-x</pub-id>
        <?supplied-pmid 31016684?>
        <pub-id pub-id-type="pmid">31016684</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <mixed-citation publication-type="other">Anwyl-Irvine, A. L., Armstrong, T., &amp; Dalmaijer, E. S. (2021). MouseView.js: Reliable and valid attention tracking in web-based experiments using a cursor-directed aperture. <italic>Behavior Research Methods</italic>. 10.3758/s13428-021-01703-5</mixed-citation>
    </ref>
    <ref id="CR4">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brainard</surname>
            <given-names>DH</given-names>
          </name>
        </person-group>
        <article-title>The Psychophysics Toolbox</article-title>
        <source>Spatial Vision</source>
        <year>1997</year>
        <volume>10</volume>
        <issue>4</issue>
        <fpage>433</fpage>
        <lpage>436</lpage>
        <pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id>
        <?supplied-pmid 9176952?>
        <pub-id pub-id-type="pmid">9176952</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <mixed-citation publication-type="other">Brainard, D. H. (2017). <italic>mQUESTPlus: MATLAB implementation of Watson’s Quest+</italic>. <ext-link ext-link-type="uri" xlink:href="https://github.com/BrainardLab/mQUESTPlus">https://github.com/BrainardLab/mQUESTPlus</ext-link></mixed-citation>
    </ref>
    <ref id="CR6">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bunce</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Gray</surname>
            <given-names>KLH</given-names>
          </name>
          <name>
            <surname>Cook</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>The perception of interpersonal distance is distorted by the Müller-Lyer illusion</article-title>
        <source>Scientific Reports</source>
        <year>2021</year>
        <volume>11</volume>
        <fpage>Article 494</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-020-80073-y</pub-id>
        <?supplied-pmid 33436801?>
        <pub-id pub-id-type="pmid">33436801</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Dalton</surname>
            <given-names>J-D</given-names>
          </name>
          <name>
            <surname>Tan</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <source>
          <italic>platform.js: A platform detection library (Version 1.3.6)</italic>
        </source>
        <year>2020</year>
        <publisher-name>[Computer software]</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR8">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Leeuw</surname>
            <given-names>JR</given-names>
          </name>
        </person-group>
        <article-title>jsPsych: A JavaScript library for creating behavioral experiments in a Web browser</article-title>
        <source>Behavior Research Methods</source>
        <year>2015</year>
        <volume>47</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.3758/s13428-014-0458-y</pub-id>
        <?supplied-pmid 24683129?>
        <pub-id pub-id-type="pmid">24683129</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <mixed-citation publication-type="other">Hadrien, J., &amp; Jaquiery, M. (2016). <italic>StaircaseJS: Adaptive staircase procedure in JavaScript</italic>. <ext-link ext-link-type="uri" xlink:href="https://github.com/hadrienj/StaircaseJS">https://github.com/hadrienj/StaircaseJS</ext-link></mixed-citation>
    </ref>
    <ref id="CR10">
      <mixed-citation publication-type="other">Henninger, F., Shevchenko, Y., Mertens, U. K., Kieslich, P. J., &amp; Hilbig, B. E. (2021). lab.js: A free, open, online study builder. <italic>Behavior Research Methods</italic>. 10.3758/s13428-019-01283-5</mixed-citation>
    </ref>
    <ref id="CR11">
      <mixed-citation publication-type="other">Hirst, R. J. (2020). <italic>Basic JND orientation discrimination demo</italic>. <ext-link ext-link-type="uri" xlink:href="https://gitlab.pavlovia.org/lpxrh6/staircase-demo">https://gitlab.pavlovia.org/lpxrh6/staircase-demo</ext-link></mixed-citation>
    </ref>
    <ref id="CR12">
      <mixed-citation publication-type="other">Höchenberger, R. (2019). <italic>questplus: A QUEST+ implementation in Python</italic>. <ext-link ext-link-type="uri" xlink:href="https://github.com/hoechenberger/questplus">https://github.com/hoechenberger/questplus</ext-link></mixed-citation>
    </ref>
    <ref id="CR13">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>PR</given-names>
          </name>
        </person-group>
        <article-title>QuestPlus: A Matlab implementation of the QUEST+ adaptive psychometric method</article-title>
        <source>Journal of Open Research Software</source>
        <year>2018</year>
        <volume>6</volume>
        <issue>1</issue>
        <fpage>Article 27</fpage>
        <pub-id pub-id-type="doi">10.5334/jors.195</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>PR</given-names>
          </name>
        </person-group>
        <article-title>Sit still and pay attention: Using the Wii Balance-Board to detect lapses in concentration in children during psychophysical testing</article-title>
        <source>Behavior Research Methods</source>
        <year>2019</year>
        <volume>51</volume>
        <issue>1</issue>
        <fpage>28</fpage>
        <lpage>39</lpage>
        <pub-id pub-id-type="doi">10.3758/s13428-018-1045-4</pub-id>
        <?supplied-pmid 29770907?>
        <pub-id pub-id-type="pmid">29770907</pub-id>
      </element-citation>
    </ref>
    <ref id="CR15">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kawabe</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Perceptual properties of the Poisson effect</article-title>
        <source>Frontiers in Psychology</source>
        <year>2021</year>
        <volume>11</volume>
        <fpage>Article 612368</fpage>
        <pub-id pub-id-type="doi">10.3389/fpsyg.2020.612368</pub-id>
        <?supplied-pmid 33551923?>
        <pub-id pub-id-type="pmid">33551923</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Keefe</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Pokta</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Störmer</surname>
            <given-names>VS</given-names>
          </name>
        </person-group>
        <article-title>Cross-modal orienting of exogenous attention results in visual-cortical facilitation, not suppression</article-title>
        <source>Scientific Reports</source>
        <year>2021</year>
        <volume>11</volume>
        <fpage>Article 10237</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-021-89654-x</pub-id>
        <?supplied-pmid 33986384?>
        <pub-id pub-id-type="pmid">33986384</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kim</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>SC</given-names>
          </name>
        </person-group>
        <article-title>Partial awareness can be induced by independent cognitive access to different spatial frequencies</article-title>
        <source>Cognition</source>
        <year>2021</year>
        <volume>212</volume>
        <fpage>Article 104692</fpage>
        <pub-id pub-id-type="doi">10.1016/J.COGNITION.2021.104692</pub-id>
        <?supplied-pmid 33773425?>
        <pub-id pub-id-type="pmid">33773425</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>King-Smith</surname>
            <given-names>PE</given-names>
          </name>
          <name>
            <surname>Grigsby</surname>
            <given-names>SS</given-names>
          </name>
          <name>
            <surname>Vingrys</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Benes</surname>
            <given-names>SC</given-names>
          </name>
          <name>
            <surname>Supowit</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Efficient and unbiased modifications of the QUEST threshold method: Theory, simulations, experimental evaluation and practical implementation</article-title>
        <source>Vision Research</source>
        <year>1994</year>
        <volume>34</volume>
        <issue>7</issue>
        <fpage>885</fpage>
        <lpage>912</lpage>
        <pub-id pub-id-type="doi">10.1016/0042-6989(94)90039-6</pub-id>
        <?supplied-pmid 8160402?>
        <pub-id pub-id-type="pmid">8160402</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kontsevich</surname>
            <given-names>LL</given-names>
          </name>
          <name>
            <surname>Tyler</surname>
            <given-names>CW</given-names>
          </name>
        </person-group>
        <article-title>Bayesian adaptive estimation of psychometric slope and threshold</article-title>
        <source>Vision Research</source>
        <year>1999</year>
        <volume>39</volume>
        <issue>16</issue>
        <fpage>2729</fpage>
        <lpage>2737</lpage>
        <pub-id pub-id-type="doi">10.1016/S0042-6989(98)00285-5</pub-id>
        <?supplied-pmid 10492833?>
        <pub-id pub-id-type="pmid">10492833</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kurki</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Stimulus information supporting bilateral symmetry perception</article-title>
        <source>Vision Research</source>
        <year>2019</year>
        <volume>161</volume>
        <fpage>18</fpage>
        <lpage>24</lpage>
        <pub-id pub-id-type="doi">10.1016/J.VISRES.2019.02.017</pub-id>
        <?supplied-pmid 31085205?>
        <pub-id pub-id-type="pmid">31085205</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kuroki</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>A new jsPsych plugin for psychophysics, providing accurate display duration and stimulus onset asynchrony</article-title>
        <source>Behavior Research Methods</source>
        <year>2021</year>
        <volume>53</volume>
        <fpage>301</fpage>
        <lpage>310</lpage>
        <pub-id pub-id-type="doi">10.3758/s13428-020-01445-w</pub-id>
        <?supplied-pmid 32700239?>
        <pub-id pub-id-type="pmid">32700239</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <mixed-citation publication-type="other">Kuroki, D., &amp; Pronk, T. (2021a). <italic>jsQUEST: A Bayesian adaptive psychometric method for measuring thresholds in online experiments</italic>. <ext-link ext-link-type="uri" xlink:href="https://github.com/kurokida/jsQUEST">https://github.com/kurokida/jsQUEST</ext-link></mixed-citation>
    </ref>
    <ref id="CR23">
      <mixed-citation publication-type="other">Kuroki, D., &amp; Pronk, T. (2021b). <italic>jsQuestPlus: A JavaScript library to use the QUEST+ method in online experiments</italic>. <ext-link ext-link-type="uri" xlink:href="https://github.com/kurokida/jsQuestPlus">https://github.com/kurokida/jsQuestPlus</ext-link></mixed-citation>
    </ref>
    <ref id="CR24">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Leek</surname>
            <given-names>MR</given-names>
          </name>
        </person-group>
        <article-title>Adaptive procedures in psychophysical research</article-title>
        <source>Perception &amp; Psychophysics</source>
        <year>2001</year>
        <volume>63</volume>
        <issue>8</issue>
        <fpage>1279</fpage>
        <lpage>1292</lpage>
        <pub-id pub-id-type="doi">10.3758/BF03194543</pub-id>
        <pub-id pub-id-type="pmid">11800457</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Levinson</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Podvalny</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Baete</surname>
            <given-names>SH</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Cortical and subcortical signatures of conscious object recognition</article-title>
        <source>Nature Communications</source>
        <year>2021</year>
        <volume>12</volume>
        <fpage>Article 2930</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-021-23266-x</pub-id>
        <?supplied-pmid 34006884?>
        <pub-id pub-id-type="pmid">34006884</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Levitt</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Transformed up-down methods in psychoacoustics</article-title>
        <source>The Journal of the Acoustical Society of America</source>
        <year>1971</year>
        <volume>49</volume>
        <issue>2B</issue>
        <fpage>467</fpage>
        <lpage>477</lpage>
        <pub-id pub-id-type="doi">10.1121/1.1912375</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Joo</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Yeatman</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>Reinecke</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Controlling for participants’ viewing distance in large-scale, psychophysical online experiments using a virtual chinrest</article-title>
        <source>Scientific Reports</source>
        <year>2020</year>
        <volume>10</volume>
        <fpage>Article 904</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-019-57204-1</pub-id>
        <?supplied-pmid 31969579?>
        <pub-id pub-id-type="pmid">31969579</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luzardo</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Yeshurun</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Inter-individual variations in internal noise predict the effects of spatial attention</article-title>
        <source>Cognition</source>
        <year>2021</year>
        <volume>217</volume>
        <fpage>Article 104888</fpage>
        <pub-id pub-id-type="doi">10.1016/j.cognition.2021.104888</pub-id>
        <?supplied-pmid 34450395?>
        <pub-id pub-id-type="pmid">34450395</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Manning</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>PR</given-names>
          </name>
          <name>
            <surname>Dekker</surname>
            <given-names>TM</given-names>
          </name>
          <name>
            <surname>Pellicano</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>Psychophysics with children: Investigating the effects of attentional lapses on threshold estimates</article-title>
        <source>Attention, Perception, &amp; Psychophysics</source>
        <year>2018</year>
        <volume>80</volume>
        <issue>5</issue>
        <fpage>1311</fpage>
        <lpage>1324</lpage>
        <pub-id pub-id-type="doi">10.3758/s13414-018-1510-2</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mathôt</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schreij</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Theeuwes</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>OpenSesame: An open-source, graphical experiment builder for the social sciences</article-title>
        <source>Behavior Research Methods</source>
        <year>2012</year>
        <volume>44</volume>
        <issue>2</issue>
        <fpage>314</fpage>
        <lpage>324</lpage>
        <pub-id pub-id-type="doi">10.3758/s13428-011-0168-7</pub-id>
        <?supplied-pmid 22083660?>
        <pub-id pub-id-type="pmid">22083660</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <mixed-citation publication-type="other">Mozilla. (2022). <italic>Using Web Workers</italic>. <ext-link ext-link-type="uri" xlink:href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers">https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers</ext-link></mixed-citation>
    </ref>
    <ref id="CR32">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Myrodia</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Buisine</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Madelain</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Comparison of threshold measurements in laboratory and online studies using a Quest+ algorithm</article-title>
        <source>Journal of Vision</source>
        <year>2021</year>
        <volume>21</volume>
        <issue>9</issue>
        <fpage>Article 1959</fpage>
        <pub-id pub-id-type="doi">10.1167/jov.21.9.1959</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <mixed-citation publication-type="other">Papoutsaki, A., Sangkloy, P., Laskey, J., Daskalova, N., Huang, J., &amp; Hays, J. (2016). WebGazer: Scalable webcam eye tracking using user interactions. <italic>Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI)</italic>, 3839–3845.</mixed-citation>
    </ref>
    <ref id="CR34">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peirce</surname>
            <given-names>JW</given-names>
          </name>
        </person-group>
        <article-title>PsychoPy-Psychophysics software in Python</article-title>
        <source>Journal of Neuroscience Methods</source>
        <year>2007</year>
        <volume>162</volume>
        <issue>1–2</issue>
        <fpage>8</fpage>
        <lpage>13</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2006.11.017</pub-id>
        <?supplied-pmid 17254636?>
        <pub-id pub-id-type="pmid">17254636</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peirce</surname>
            <given-names>JW</given-names>
          </name>
          <name>
            <surname>Gray</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Simpson</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>MacAskill</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Höchenberger</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Sogo</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Kastman</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Lindeløv</surname>
            <given-names>JK</given-names>
          </name>
        </person-group>
        <article-title>PsychoPy2: Experiments in behavior made easy</article-title>
        <source>Behavior Research Methods</source>
        <year>2019</year>
        <volume>51</volume>
        <issue>1</issue>
        <fpage>195</fpage>
        <lpage>203</lpage>
        <pub-id pub-id-type="doi">10.3758/s13428-018-01193-y</pub-id>
        <?supplied-pmid 30734206?>
        <pub-id pub-id-type="pmid">30734206</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <mixed-citation publication-type="other">Pelli, D. G. (1996). <italic>QuestDemo</italic>. <ext-link ext-link-type="uri" xlink:href="https://github.com/Psychtoolbox-3/Psychtoolbox-3/blob/master/Psychtoolbox/Quest/QuestDemo.m">https://github.com/Psychtoolbox-3/Psychtoolbox-3/blob/master/Psychtoolbox/Quest/QuestDemo.m</ext-link></mixed-citation>
    </ref>
    <ref id="CR37">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pelli</surname>
            <given-names>DG</given-names>
          </name>
        </person-group>
        <article-title>The VideoToolbox software for visual psychophysics: transforming numbers into movies</article-title>
        <source>Spatial Vision</source>
        <year>1997</year>
        <volume>10</volume>
        <issue>4</issue>
        <fpage>437</fpage>
        <lpage>442</lpage>
        <pub-id pub-id-type="doi">10.1163/156856897X00366</pub-id>
        <?supplied-pmid 9176953?>
        <pub-id pub-id-type="pmid">9176953</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pronk</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Wiers</surname>
            <given-names>RW</given-names>
          </name>
          <name>
            <surname>Molenkamp</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Murre</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Mental chronometry in the pocket? Timing accuracy of web applications on touchscreen and keyboard devices</article-title>
        <source>Behavior Research Methods</source>
        <year>2020</year>
        <volume>52</volume>
        <issue>3</issue>
        <fpage>1371</fpage>
        <lpage>1382</lpage>
        <pub-id pub-id-type="doi">10.3758/s13428-019-01321-2</pub-id>
        <?supplied-pmid 31823223?>
        <pub-id pub-id-type="pmid">31823223</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <mixed-citation publication-type="other">Pronk, T., Hirst, R. J., Wiers, R. W., &amp; Murre, J. M. J. (2022). Can we measure individual differences in cognitive measures reliably via smartphones? A comparison of the flanker effect across device types and samples. <italic>Behavior Research Methods</italic>. 10.3758/S13428-022-01885-6</mixed-citation>
    </ref>
    <ref id="CR40">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rajananda</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lau</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Odegaard</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>A random-dot kinematogram for web-based vision research</article-title>
        <source>Journal of Open Research Software</source>
        <year>2018</year>
        <volume>6</volume>
        <issue>1</issue>
        <fpage>Article 6</fpage>
        <pub-id pub-id-type="doi">10.5334/jors.194</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Reips</surname>
            <given-names>U-D</given-names>
          </name>
        </person-group>
        <article-title>Web-based research in psychology</article-title>
        <source>Zeitschrift für Psychologie</source>
        <year>2021</year>
        <volume>229</volume>
        <issue>4</issue>
        <fpage>198</fpage>
        <lpage>213</lpage>
        <pub-id pub-id-type="doi">10.1027/2151-2604/a000475</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <mixed-citation publication-type="other">Santacroce, L. A., Carlos, B. J., Petro, N., &amp; Tamber-Rosenau, B. J. (2021). Nontarget emotional stimuli must be highly conspicuous to modulate the attentional blink. <italic>Attention, Perception, &amp; Psychophysics</italic>. 10.3758/s13414-021-02260-x</mixed-citation>
    </ref>
    <ref id="CR43">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sasaki</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Yamada</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Crowdsourcing visual perception experiments : a case of contrast threshold</article-title>
        <source>PeerJ</source>
        <year>2019</year>
        <volume>7</volume>
        <fpage>Article e8339</fpage>
        <pub-id pub-id-type="doi">10.7717/peerj.8339</pub-id>
        <?supplied-pmid 31875164?>
        <pub-id pub-id-type="pmid">31875164</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Song</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>Effects of daily training amount on visual motion perceptual learning</article-title>
        <source>Journal of Vision</source>
        <year>2021</year>
        <volume>21</volume>
        <issue>4</issue>
        <fpage>Article 6</fpage>
        <pub-id pub-id-type="doi">10.1167/jov.21.4.6</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Straw</surname>
            <given-names>AD</given-names>
          </name>
        </person-group>
        <article-title>Vision Egg: An open-source library for real-time visual stimulus generation. <italic>Frontiers</italic></article-title>
        <source>Neuroinformatics</source>
        <year>2008</year>
        <volume>2</volume>
        <fpage>Article 4</fpage>
        <pub-id pub-id-type="doi">10.3389/neuro.11.004.2008</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Treutwein</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Adaptive psychophysical procedures</article-title>
        <source>Vision Research</source>
        <year>1995</year>
        <volume>35</volume>
        <issue>17</issue>
        <fpage>2503</fpage>
        <lpage>2522</lpage>
        <pub-id pub-id-type="doi">10.1016/0042-6989(95)00016-X</pub-id>
        <?supplied-pmid 8594817?>
        <pub-id pub-id-type="pmid">8594817</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Watson</surname>
            <given-names>AB</given-names>
          </name>
        </person-group>
        <article-title>QUEST+: A general multidimensional Bayesian adaptive psychometric method</article-title>
        <source>Journal of Vision</source>
        <year>2017</year>
        <volume>17</volume>
        <issue>3</issue>
        <fpage>1</fpage>
        <lpage>27</lpage>
        <pub-id pub-id-type="doi">10.1167/17.3.10</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Watson</surname>
            <given-names>AB</given-names>
          </name>
          <name>
            <surname>Pelli</surname>
            <given-names>DG</given-names>
          </name>
        </person-group>
        <article-title>Quest: A Bayesian adaptive psychometric method</article-title>
        <source>Perception &amp; Psychophysics</source>
        <year>1983</year>
        <volume>33</volume>
        <issue>2</issue>
        <fpage>113</fpage>
        <lpage>120</lpage>
        <pub-id pub-id-type="doi">10.3758/BF03202828</pub-id>
        <pub-id pub-id-type="pmid">6844102</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Postle</surname>
            <given-names>BR</given-names>
          </name>
        </person-group>
        <article-title>The neural codes underlying internally generated representations in visual working memory</article-title>
        <source>Journal of Cognitive Neuroscience</source>
        <year>2021</year>
        <volume>33</volume>
        <issue>6</issue>
        <fpage>1142</fpage>
        <lpage>1157</lpage>
        <pub-id pub-id-type="doi">10.1162/jocn_a_01702</pub-id>
        <?supplied-pmid 34428785?>
        <pub-id pub-id-type="pmid">34428785</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
