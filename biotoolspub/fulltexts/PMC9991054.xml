<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9991054</article-id>
    <article-id pub-id-type="pmid">36790067</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btad089</article-id>
    <article-id pub-id-type="publisher-id">btad089</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Original Paper</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Systems Biology</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI01060</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Using graph neural networks for site-of-metabolism prediction and its applications to ranking promiscuous enzymatic products</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Porokhin</surname>
          <given-names>Vladimir</given-names>
        </name>
        <aff><institution>Department of Computer Science, Tufts University</institution>, Medford, MA 02155, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Liu</surname>
          <given-names>Li-Ping</given-names>
        </name>
        <aff><institution>Department of Computer Science, Tufts University</institution>, Medford, MA 02155, <country country="US">USA</country></aff>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0001-9477-2199</contrib-id>
        <name>
          <surname>Hassoun</surname>
          <given-names>Soha</given-names>
        </name>
        <aff><institution>Department of Computer Science, Tufts University</institution>, Medford, MA 02155, <country country="US">USA</country></aff>
        <aff><institution>Department of Chemical and Biological Engineering, Tufts University</institution>, Medford, MA 02155, <country country="US">USA</country></aff>
        <xref rid="btad089-cor1" ref-type="corresp"/>
        <!--soha.hassoun@tufts.edu-->
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Martelli</surname>
          <given-names>Pier Luigi</given-names>
        </name>
        <role>Associate Editor</role>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="btad089-cor1">To whom correspondence should be addressed. <email>soha.hassoun@tufts.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-02-15">
      <day>15</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>15</day>
      <month>2</month>
      <year>2023</year>
    </pub-date>
    <volume>39</volume>
    <issue>3</issue>
    <elocation-id>btad089</elocation-id>
    <history>
      <date date-type="received">
        <day>25</day>
        <month>7</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>31</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="editorial-decision">
        <day>06</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>14</day>
        <month>2</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>06</day>
        <month>3</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btad089.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>While traditionally utilized for identifying site-specific metabolic activity within a compound to alter its interaction with a metabolizing enzyme, predicting the site-of-metabolism (SOM) is essential in analyzing the promiscuity of enzymes on substrates. The successful prediction of SOMs and the relevant promiscuous products has a wide range of applications that include creating extended metabolic models (EMMs) that account for enzyme promiscuity and the construction of novel heterologous synthesis pathways. There is therefore a need to develop generalized methods that can predict molecular SOMs for a wide range of metabolizing enzymes.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>This article develops a Graph Neural Network (GNN) model for the classification of an atom (or a bond) being an SOM. Our model, GNN-SOM, is trained on enzymatic interactions, available in the KEGG database, that span all enzyme commission numbers. We demonstrate that GNN-SOM consistently outperforms baseline machine learning models, when trained on all enzymes, on Cytochrome P450 (CYP) enzymes, or on non-CYP enzymes. We showcase the utility of GNN-SOM in prioritizing predicted enzymatic products due to enzyme promiscuity for two biological applications: the construction of EMMs and the construction of synthesis pathways.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p>A python implementation of the trained SOM predictor model can be found at <ext-link xlink:href="https://github.com/HassounLab/GNN-SOM" ext-link-type="uri">https://github.com/HassounLab/GNN-SOM</ext-link>.</p>
      </sec>
      <sec id="s5">
        <title>Supplementary information</title>
        <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <institution-wrap>
            <institution>NSF</institution>
            <institution-id institution-id-type="DOI">10.13039/100000001</institution-id>
          </institution-wrap>
        </funding-source>
        <award-id>CCF-1909536</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Identifying sites-of-metabolism (SOMs) can significantly enhance our understanding of metabolism. Such sites refer to specific sites within molecules that are susceptible to chemical change. SOMs can therefore be defined as specific atoms (<xref rid="btad089-B12" ref-type="bibr">Finkelmann <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btad089-B18" ref-type="bibr">Kirchmair <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btad089-B35" ref-type="bibr">Tyzack and Kirchmair, 2019</xref>) and/or bonds (<xref rid="btad089-B4" ref-type="bibr">Dang <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btad089-B14" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2017</xref>), and, less conventionally, pairs of unshared valence electrons (<xref rid="btad089-B4" ref-type="bibr">Dang <italic toggle="yes">et al.</italic>, 2020</xref>). A primary application that has driven the development of SOM prediction tools is determining the enzymatic transformations of xenobiotic compounds including drug molecules. Such transformations are generally classified in two groups—‘Phase I’ activity involving oxidation–reduction and hydrolysis reactions and ‘Phase II’ reactions referring to conjugation transformations (<xref rid="btad089-B34" ref-type="bibr">Testa <italic toggle="yes">et al.</italic>, 2012</xref>). Cytochrome P450 (CYP) enzymes, a superfamily of structurally diverse metabolic enzymes with broad specificity, are known to be responsible for the metabolism of over 70% of all drugs in use (<xref rid="btad089-B40" ref-type="bibr">Zanger and Schwab, 2013</xref>; <xref rid="btad089-B41" ref-type="bibr">Zaretzki <italic toggle="yes">et al.</italic>, 2013</xref>) and are the primary facilitators of ‘Phase I’ reactions (<xref rid="btad089-B20" ref-type="bibr">McDonnell and Dang, 2013</xref>). As such, CYP enzymes have been the focus of many SOM prediction methods. RS-Predictor (<xref rid="btad089-B42" ref-type="bibr">Zaretzki <italic toggle="yes">et al.</italic>, 2012</xref>), XenoSite (<xref rid="btad089-B41" ref-type="bibr">Zaretzki <italic toggle="yes">et al.</italic>, 2013</xref>), Rainbow XenoSite (<xref rid="btad089-B4" ref-type="bibr">Dang <italic toggle="yes">et al.</italic>, 2020</xref>) and others (<xref rid="btad089-B14" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2017</xref>) predict SOMs for specific CYP isoforms.</p>
    <p>Non-CYP enzymes, however, play a role in a number of ‘phase I’ interactions and are primary drivers of ‘phase II’ metabolism, e.g. UDP-glucuronosyltransferases (UGT) and sulfotransferases (SULT) (<xref rid="btad089-B6" ref-type="bibr">Dixit <italic toggle="yes">et al.</italic>, 2017</xref>). Techniques such as FAME (Fast Metabolizer) (<xref rid="btad089-B18" ref-type="bibr">Kirchmair <italic toggle="yes">et al.</italic>., 2013</xref>) and MetScore (<xref rid="btad089-B12" ref-type="bibr">Finkelmann <italic toggle="yes">et al.</italic>, 2018</xref>) address this issue by aiming for high prediction accuracy in both ‘phase I’ and ‘phase II’ metabolism. Such approaches therefore are broader than CYP-specific or phase-specific activity prediction tools. Further, there are no prior works that assess the loss in accuracy when broadening activity predictors.</p>
    <p>Importantly, broad enzyme specificity is not restricted to CYP enzymes or only those associated with phase I and II metabolism. Most, if not all, enzymes are promiscuous, acting on substrates other than the ones they evolved to catalyze (<xref rid="btad089-B22" ref-type="bibr">Nobeli <italic toggle="yes">et al.</italic>, 2009</xref>; <xref rid="btad089-B32" ref-type="bibr">Tawfik, 2020</xref>). Three applications, constructing of de novo synthesis pathways (<xref rid="btad089-B24" ref-type="bibr">Otero-Muras and Carbonell, 2021</xref>), creating extended metabolic models (EMMs) that account for enzyme promiscuity (<xref rid="btad089-B25" ref-type="bibr">Porokhin <italic toggle="yes">et al.</italic>, 2021</xref>), and identifying metabolic products measured through metabolomics (<xref rid="btad089-B31" ref-type="bibr">Strutz <italic toggle="yes">et al.</italic>, 2022</xref>), have driven the development of tools to analyze broad promiscuity. The prevailing approach is to first identify a set of reaction rules (e.g. <xref rid="btad089-B8" ref-type="bibr">Duigou <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btad089-B19" ref-type="bibr">Kotera <italic toggle="yes">et al.</italic>, 2004</xref>; <xref rid="btad089-B30" ref-type="bibr">Sivakumar <italic toggle="yes">et al.</italic>, 2016</xref>) in the form of a local biochemical transformation, followed by matching them to query molecules. Matching rules specify the site of the transformation as well as its local neighborhood to ensure they are sufficiently specific to generate likely promiscuous products. Tuning this specificity (e.g. by radius adjustment) however is a challenge and matching rules may still yield infeasible biotransformations. When paired with rule-based methods, machine learning (ML)-based SOM prediction approaches provide two major advantages. First, they can account for a wider molecular context and learn specialized representations necessary for accurate predictions. Second, they provide a continuous likelihood estimate for the SOM, allowing the ranking of promiscuous products. These improvements can enrich the results of rule-based methods and broaden their applications.</p>
    <p>We explore in this work graph-based deep-learning techniques for predicting SOM. Specifically, we use Graph Neural Networks (GNNs) (<xref rid="btad089-B43" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2019</xref>; <xref rid="btad089-B44" ref-type="bibr">Zhou <italic toggle="yes">et al.</italic>, 2020</xref>) (GNNs) to learn atom representations in their molecular graph context in an end-to-end fashion (<xref rid="btad089-B7" ref-type="bibr">Donti <italic toggle="yes">et al.</italic>, 2017</xref>). These representations can be utilized in downstream classification tasks: either to predict the likelihood of an atom being an SOM or to predict the likelihood of a bond between two atoms being an SOM. A major advantage of using GNNs for SOM prediction is the more natural problem representation as atoms and bonds in molecular structures trivially correspond to nodes and edges in graphs, respectively. Therefore, GNNs can provide more meaningful molecular representations than neural networks used in XenoSite (<xref rid="btad089-B41" ref-type="bibr">Zaretzki <italic toggle="yes">et al.</italic>, 2013</xref>) and Rainbow XenoSite (<xref rid="btad089-B4" ref-type="bibr">Dang <italic toggle="yes">et al.</italic>, 2020</xref>), as well as other techniques. Another important advantage of utilizing GNNs over current traditional ML approaches, e.g. Random Forest and Support Vector Machines (SVM), is effective representation learning, which helps avoid the burdensome task of feature selection. In MetScore (<xref rid="btad089-B12" ref-type="bibr">Finkelmann <italic toggle="yes">et al.</italic>, 2018</xref>), feature combinations were optimized separately for ‘phase I’ and ‘phase II’ interactions. FAME (<xref rid="btad089-B18" ref-type="bibr">Kirchmair <italic toggle="yes">et al.</italic>, 2013</xref>) considered information gain as their selection criterion for descriptors. XenoSite (<xref rid="btad089-B41" ref-type="bibr">Zaretzki <italic toggle="yes">et al.</italic>, 2013</xref>) uses a variety of feature types including quantum chemical properties and SMARTCyp (<xref rid="btad089-B27" ref-type="bibr">Rydberg <italic toggle="yes">et al.</italic>, 2010</xref>) reactivity. He et al. used a set of four feature selection algorithms prior to classification. The need for feature selection is reflective of the large input dimensionality (<xref rid="btad089-B28" ref-type="bibr">Saeys <italic toggle="yes">et al.</italic>, 2007</xref>) required by those methods. In contrast, the representation learning capabilities of GNNs allow models to perform well with a handful of basic features, such as atom element types and enzyme category labels. We explore several GNN models and show that the GNN-SOM, built using the Chebyshev convolutional operator (<xref rid="btad089-B5" ref-type="bibr">Defferrard <italic toggle="yes">et al.</italic>, 2016</xref>), outperforms other GNN and traditional ML models when trained to predict the reaction center as defined in the KEGG database (<ext-link xlink:href="https://www.genome.jp/kegg/reaction/KCF.html" ext-link-type="uri">https://www.genome.jp/kegg/reaction/KCF.html</ext-link>). Using labeled reaction centers from the KEGG database(<xref rid="btad089-B38" ref-type="bibr">Yamada <italic toggle="yes">et al.</italic>, 2005</xref>), we explore several GNN models and show that the GNN-SOM, built using the Chebyshev convolutional operator (<xref rid="btad089-B5" ref-type="bibr">Defferrard <italic toggle="yes">et al.</italic>, 2016</xref>), outperforms other GNN and traditional ML models (Random Forest, MLP and AdaBoost) that were used in prior works. Further, we demonstrate the utility of SOM prediction for improving rule-based enzyme promiscuity prediction in the context of creating EMMs and constructing synthesis pathways. Our primary contributions are:
</p>
    <list list-type="bullet">
      <list-item>
        <p>Formulating the SOM prediction problem across all enzyme classes (not just CYP or phase I/II enzymes) as a classification task on either atoms (the atomic SOM problem) or as a classification task on pairs thereof (the bond SOM problem).</p>
      </list-item>
      <list-item>
        <p>Exploring several GNN models and demonstrating the effectiveness of GNNs in representation learning and SOM prediction over traditional ML approaches that require feature selection.</p>
      </list-item>
      <list-item>
        <p>Demonstrating the relative difficulty of SOM prediction for CYP-mediated reactions and showing that our general-purpose SOM prediction model performs as well as the versions specific to CYP and non-CYP interactions, thus alleviating the need for separate predictors for the two cases.</p>
      </list-item>
      <list-item>
        <p>Presenting two biological applications of our SOM predictor, where identifying SOMs measurably improves the quality of predicted promiscuous products and identification of 3-HP synthesis pathways in <italic toggle="yes">Escherichia coli</italic>.</p>
      </list-item>
    </list>
  </sec>
  <sec>
    <title>2 Methods</title>
    <sec>
      <title>2.1 Problem formulation: SOM prediction</title>
      <p>As in prior ML methods (<xref rid="btad089-B4" ref-type="bibr">Dang <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btad089-B14" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2017</xref>: <xref rid="btad089-B12" ref-type="bibr">Finkelmann <italic toggle="yes">et al.</italic>, 2018</xref>; <xref rid="btad089-B18" ref-type="bibr">Kirchmair <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btad089-B41" ref-type="bibr">Zaretzki <italic toggle="yes">et al.</italic>, 2013</xref>), the SOM prediction problem can be formulated as a binary classification task. We formally define the ‘atomic SOM’ prediction problem as follows: given a query enzyme and a query molecule, the model predicts the likelihood of each <italic toggle="yes">atom</italic> being an SOM. Similarly, we define the ‘bond SOM’ prediction problem as a bond classification problem, where we predict the likelihood of each <italic toggle="yes">bond</italic> being an SOM. <xref rid="btad089-F1" ref-type="fig">Figure 1</xref> provides an example of atomic and bond SOMs.</p>
      <fig position="float" id="btad089-F1">
        <label>Fig. 1.</label>
        <caption>
          <p>An example of a reaction and the corresponding sites of metabolism. (<bold>a</bold>) In this biotransformation, the enzymatic activity of glutamate-oxidase (EC 1.4.3.11) causes the amine group in <sc>l</sc>-glutamate (left) to be replaced with a carbonyl group, leading to the formation of 2-oxoglutarate (right). (<bold>b</bold>) On a structural level, the biotransformation converts a single bond to a double bond, in addition to replacing a nitrogen atom with an oxygen atom. As a result, both atoms (oxygen and nitrogen) across the modified bond are considered ‘atomic SOMs.’ (<bold>c</bold>) Alternatively, the modified bond itself could be considered a ‘bond SOM’</p>
        </caption>
        <graphic xlink:href="btad089f1" position="float"/>
      </fig>
      <p>Each molecule is represented using an undirected graph <italic toggle="yes">G =</italic> (<italic toggle="yes">V, E</italic>), where every node <italic toggle="yes">i ∈ V</italic> represents an atom and every edge (<italic toggle="yes">i, j</italic>) <italic toggle="yes">∈ E</italic> for nodes <italic toggle="yes">i, j ∈ V</italic> represents a bond. The atomic SOM prediction problem then becomes a <italic toggle="yes">node</italic> classification task. Given a representation <bold>x</bold><sub><italic toggle="yes">i</italic></sub> for atom <italic toggle="yes">i ∈ V</italic>, we seek to find its predicted SOM label <italic toggle="yes">ŷ<sub>i</sub></italic>.</p>
      <p>We formulate the bond SOM prediction problem similarly to a link prediction task: the objective is to make the determination <italic toggle="yes">ŷ<sub>i,j</sub></italic> whether a bond SOM exists between a pair of atoms <italic toggle="yes">i</italic>, <italic toggle="yes">j</italic> ∈ <italic toggle="yes">V</italic> with their respective representations <bold>x</bold><sub><italic toggle="yes">i</italic></sub> and <bold>x</bold><sub><italic toggle="yes">j</italic></sub>. The link prediction is performed by applying a multi-layer perceptron (MLP) to a concatenation of the two atom representations. Since there is no order preference on the atoms, this calculation is performed on both <bold>x</bold><sub><italic toggle="yes">i</italic></sub> ‖ <bold>x</bold><sub><italic toggle="yes">j</italic></sub> and <bold>x</bold><sub><italic toggle="yes">j</italic></sub> ‖ <bold>x</bold><sub><italic toggle="yes">i</italic></sub> arrangements and the reported prediction is the average of the two. We therefore calculate this prediction as follows:</p>
      <disp-formula id="E1">
        <label>(1)</label>
        <mml:math id="M1" display="block" overflow="scroll">
          <mml:msub>
            <mml:mrow>
              <mml:mrow>
                <mml:mover accent="true">
                  <mml:mrow>
                    <mml:mi>y</mml:mi>
                  </mml:mrow>
                  <mml:mo>^</mml:mo>
                </mml:mover>
              </mml:mrow>
            </mml:mrow>
            <mml:mrow>
              <mml:mi>i</mml:mi>
              <mml:mo>,</mml:mo>
              <mml:mi>j</mml:mi>
            </mml:mrow>
          </mml:msub>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:mo>=</mml:mo>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:mfrac>
            <mml:mrow>
              <mml:mi mathvariant="normal">MLP</mml:mi>
              <mml:mo>(</mml:mo>
              <mml:msub>
                <mml:mrow>
                  <mml:mi mathvariant="bold">x</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mo> </mml:mo>
              <mml:mo>|</mml:mo>
              <mml:mo>|</mml:mo>
              <mml:mi mathvariant="normal"> </mml:mi>
              <mml:msub>
                <mml:mrow>
                  <mml:mi mathvariant="bold">x</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>j</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mo>)</mml:mo>
            </mml:mrow>
            <mml:mrow>
              <mml:mn>2</mml:mn>
            </mml:mrow>
          </mml:mfrac>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:mo>+</mml:mo>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:mfrac>
            <mml:mrow>
              <mml:mi mathvariant="normal">MLP</mml:mi>
              <mml:mo>(</mml:mo>
              <mml:msub>
                <mml:mrow>
                  <mml:mi mathvariant="bold">x</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>j</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mi mathvariant="normal"> </mml:mi>
              <mml:mo>|</mml:mo>
              <mml:mo>|</mml:mo>
              <mml:mi mathvariant="normal"> </mml:mi>
              <mml:msub>
                <mml:mrow>
                  <mml:mi mathvariant="bold">x</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mo>)</mml:mo>
            </mml:mrow>
            <mml:mrow>
              <mml:mn>2</mml:mn>
            </mml:mrow>
          </mml:mfrac>
          <mml:mo>.</mml:mo>
        </mml:math>
      </disp-formula>
    </sec>
    <sec>
      <title>2.2 Representation learning using GNNs</title>
      <p>For learning node representations, we consider GNNs that consist of a series of layers operating on atom-level embeddings. Such layers can be used to directly make per-atom SOM predictions as in <xref rid="btad089-F2" ref-type="fig">Figure 2a</xref>, or using a separate bond classifier MLP for bond SOM predictions as in <xref rid="btad089-F2" ref-type="fig">Figure 2b</xref>. Each convolution layer extracts local substructure features for individual nodes and learns a compact representation thereof. We evaluate several GNN message passing layer types for predicting SOMs. The graph convolution operator from Graph Isomorphism Networks (GINs) (<xref rid="btad089-B37" ref-type="bibr">Xu <italic toggle="yes">et al.</italic>, 2018</xref>) is used as a representative example of a spatial GNN layer. In that work, the authors noted that any aggregation based GNN is at most as powerful as the Weisfeiler–Lehman test and proposed an architecture that generalizes this test. Given input node features <bold>x</bold>, transformed features <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mo> </mml:mo></mml:mrow><mml:mrow><mml:mi>′</mml:mi></mml:mrow></mml:msubsup><mml:mi mathvariant="normal"> </mml:mi></mml:math></inline-formula>are calculated for every node <italic toggle="yes">i</italic> as follows:</p>
      <disp-formula id="E2">
        <label>(2)</label>
        <mml:math id="M2" display="block" overflow="scroll">
          <mml:msubsup>
            <mml:mrow>
              <mml:mi mathvariant="bold">x</mml:mi>
            </mml:mrow>
            <mml:mrow>
              <mml:mi>i</mml:mi>
            </mml:mrow>
            <mml:mrow>
              <mml:mi>′</mml:mi>
            </mml:mrow>
          </mml:msubsup>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:mo>=</mml:mo>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:mi mathvariant="normal">MLP</mml:mi>
          <mml:mfenced open="(" close=")" separators="|">
            <mml:mrow>
              <mml:mo>(</mml:mo>
              <mml:mn>1</mml:mn>
              <mml:mi mathvariant="normal"> </mml:mi>
              <mml:mo>+</mml:mo>
              <mml:mi mathvariant="normal"> </mml:mi>
              <mml:mo>ϵ</mml:mo>
              <mml:mo>)</mml:mo>
              <mml:msub>
                <mml:mrow>
                  <mml:mi mathvariant="bold">x</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mi mathvariant="normal"> </mml:mi>
              <mml:mo>+</mml:mo>
              <mml:mi mathvariant="normal"> </mml:mi>
              <mml:mrow>
                <mml:msub>
                  <mml:mo stretchy="false">∑</mml:mo>
                  <mml:mrow>
                    <mml:mi>j</mml:mi>
                    <mml:mi mathvariant="normal"> </mml:mi>
                    <mml:mo>∈</mml:mo>
                    <mml:mi>N</mml:mi>
                    <mml:mo>(</mml:mo>
                    <mml:mi>i</mml:mi>
                    <mml:mo>)</mml:mo>
                  </mml:mrow>
                </mml:msub>
                <mml:mrow>
                  <mml:msub>
                    <mml:mrow>
                      <mml:mi mathvariant="bold">x</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>j</mml:mi>
                    </mml:mrow>
                  </mml:msub>
                </mml:mrow>
              </mml:mrow>
            </mml:mrow>
          </mml:mfenced>
          <mml:mo>,</mml:mo>
        </mml:math>
      </disp-formula>
      <p>where <italic toggle="yes">ϵ</italic> is a learnable parameter and <italic toggle="yes">N</italic>(<italic toggle="yes">i</italic>) is the set of neighbors of node <italic toggle="yes">i</italic>. In this framework, an MLP is applied to the linear combination of features around the node with the aim of generating unique representations for different neighborhoods.</p>
      <fig position="float" id="btad089-F2">
        <label>Fig. 2.</label>
        <caption>
          <p>Architecture of GNN-SOM models. (<bold>a</bold>) GNN-SOM for atomic SOM prediction. Atom features <bold>x</bold> are processed through a number of GNN layers, each generating intermediate representations of a fixed size. The last intermediate representation is used as the input to the final GNN layer that generates a single value representing the SOM prediction for that atom. (<bold>b</bold>) GNN-SOM for bond SOM prediction. Atom features for both endpoints of a bond, <bold>x</bold><sub>1</sub> and <bold>x</bold><sub>2</sub>, are processed through the same GNN layers as before; however, the final GNN layer is excluded. The resulting intermediate representations, <bold>x</bold><inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mi mathvariant="normal">'</mml:mi></mml:math></inline-formula><sub>1</sub> and <bold>x</bold><inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mi mathvariant="normal">'</mml:mi></mml:math></inline-formula><sub>2</sub>, are concatenated two different ways and provided to a bond classifier MLP. The MLP makes two predictions, one for each concatenation, and the average of those represents the final SOM prediction for the bond</p>
        </caption>
        <graphic xlink:href="btad089f2" position="float"/>
      </fig>
      <p>We also consider a GNN convolution layer designed to mimic circular molecular fingerprints (<xref rid="btad089-B9" ref-type="bibr">Duvenaud <italic toggle="yes">et al.</italic>, 2015</xref>). Circular fingerprinting identifies important substructures in a molecule and encodes them in a binary vector. The conventional algorithm for generating such fingerprints features several non-differentiable operations on node features, most notably concatenation and hashing. In their GNN rendition of the molecular fingerprinting (MF) GNN concept, the authors replaced the concatenation by a summation over node features; the hashing was replaced by a multiplication of node features by degree-specific learnable weight matrices—one for a node’s own features, <bold>W</bold>, and one for the sum of its neighbors’ features, <bold>H</bold>. For organic molecules, the maximum number of degrees is expected to be five. The resulting convolution is defined as follows:</p>
      <disp-formula id="E3">
        <label>(3)</label>
        <mml:math id="M3" display="block" overflow="scroll">
          <mml:msubsup>
            <mml:mrow>
              <mml:mi mathvariant="bold">x</mml:mi>
            </mml:mrow>
            <mml:mrow>
              <mml:mi>i</mml:mi>
            </mml:mrow>
            <mml:mrow>
              <mml:mi>′</mml:mi>
            </mml:mrow>
          </mml:msubsup>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:mo>=</mml:mo>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:msup>
            <mml:mrow>
              <mml:mi mathvariant="bold">W</mml:mi>
            </mml:mrow>
            <mml:mrow>
              <mml:mo>(</mml:mo>
              <mml:mi mathvariant="normal">deg</mml:mi>
              <mml:mo>(</mml:mo>
              <mml:mi>i</mml:mi>
              <mml:mo>)</mml:mo>
              <mml:mo>)</mml:mo>
            </mml:mrow>
          </mml:msup>
          <mml:msub>
            <mml:mrow>
              <mml:mi mathvariant="bold">x</mml:mi>
            </mml:mrow>
            <mml:mrow>
              <mml:mi>i</mml:mi>
            </mml:mrow>
          </mml:msub>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:mo>+</mml:mo>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:msup>
            <mml:mrow>
              <mml:mi mathvariant="bold">H</mml:mi>
            </mml:mrow>
            <mml:mrow>
              <mml:mo>(</mml:mo>
              <mml:mi mathvariant="normal">deg</mml:mi>
              <mml:mo>(</mml:mo>
              <mml:mi>i</mml:mi>
              <mml:mo>)</mml:mo>
              <mml:mo>)</mml:mo>
            </mml:mrow>
          </mml:msup>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:mrow>
            <mml:msub>
              <mml:mo stretchy="false">∑</mml:mo>
              <mml:mrow>
                <mml:mi>j</mml:mi>
                <mml:mo> </mml:mo>
                <mml:mo>∈</mml:mo>
                <mml:mi mathvariant="normal"> </mml:mi>
                <mml:mi>N</mml:mi>
                <mml:mo>(</mml:mo>
                <mml:mi>i</mml:mi>
                <mml:mo>)</mml:mo>
              </mml:mrow>
            </mml:msub>
            <mml:mrow>
              <mml:msub>
                <mml:mrow>
                  <mml:mi mathvariant="bold">x</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>j</mml:mi>
                </mml:mrow>
              </mml:msub>
            </mml:mrow>
          </mml:mrow>
          <mml:mo>.</mml:mo>
        </mml:math>
      </disp-formula>
      <p>The key difference between the MF GNN and GIN is its variability with respect to a node’s degree, or in other words, its neighborhood size. The molecular fingerprinting convolution learns a separate linear mapping of node features to representations for every degree. The GIN approach, on the other hand, learns one mapping for all degrees. With more learnable parameters in the model, MF GNNs can capture richer representations.</p>
      <p>The third GNN architecture leverages the Chebyshev convolutional operator, originally proposed by <xref rid="btad089-B5" ref-type="bibr">Defferrard <italic toggle="yes">et al.</italic> (2016)</xref>. Unlike the previous two approaches, this spectral graph method considers a wide portion of a graph at any given GNN layer. It uses a <italic toggle="yes">K</italic>-polynomial filter that integrates features within the <italic toggle="yes">K</italic>-hop neighborhood of a node, which in turn helps it achieve good localization in the node domain (<xref rid="btad089-B43" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2019</xref>). Our approach relies on the following convolution definition (<xref rid="btad089-B11" ref-type="bibr">Fey and Lenssen, 2019</xref>):</p>
      <disp-formula id="E4">
        <label>(4)</label>
        <mml:math id="M4" display="block" overflow="scroll">
          <mml:mrow>
            <mml:mtable columnalign="left">
              <mml:mtr>
                <mml:mtd>
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">x</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo> </mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>′</mml:mi>
                      </mml:mrow>
                    </mml:msubsup>
                    <mml:mo>=</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mo>Σ</mml:mo>
                      </mml:mrow>
                      <mml:mi>k</mml:mi>
                    </mml:msub>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mrow>
                          <mml:msub>
                            <mml:mrow/>
                            <mml:mrow>
                              <mml:mo>=</mml:mo>
                              <mml:mn>1</mml:mn>
                            </mml:mrow>
                          </mml:msub>
                        </mml:mrow>
                      </mml:mrow>
                      <mml:mi>K</mml:mi>
                    </mml:msup>
                    <mml:mi mathvariant="bold">Z</mml:mi>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mi>k</mml:mi>
                      <mml:mo>)</mml:mo>
                    </mml:mrow>
                    <mml:mo> </mml:mo>
                    <mml:mo>·</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi mathvariant="bold">Θ</mml:mi>
                      </mml:mrow>
                      <mml:mi>k</mml:mi>
                    </mml:msub>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mrow>
                    <mml:mi mathvariant="bold">Z</mml:mi>
                    <mml:mrow>
                      <mml:mo>(</mml:mo>
                      <mml:mn>1</mml:mn>
                      <mml:mo>)</mml:mo>
                    </mml:mrow>
                    <mml:mo>=</mml:mo>
                    <mml:mi mathvariant="bold">x</mml:mi>
                  </mml:mrow>
                </mml:mtd>
              </mml:mtr>
              <mml:mtr>
                <mml:mtd>
                  <mml:mtable columnalign="left">
                    <mml:mtr>
                      <mml:mtd>
                        <mml:mi mathvariant="bold">Z</mml:mi>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mn>2</mml:mn>
                          <mml:mo>)</mml:mo>
                        </mml:mrow>
                        <mml:mo>=</mml:mo>
                        <mml:mover accent="true">
                          <mml:mi mathvariant="bold">L</mml:mi>
                          <mml:mo>¯</mml:mo>
                        </mml:mover>
                        <mml:mo>·</mml:mo>
                        <mml:mi mathvariant="bold">x</mml:mi>
                      </mml:mtd>
                    </mml:mtr>
                    <mml:mtr>
                      <mml:mtd>
                        <mml:mi mathvariant="bold">Z</mml:mi>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mi>k</mml:mi>
                          <mml:mo>)</mml:mo>
                        </mml:mrow>
                        <mml:mo>=</mml:mo>
                        <mml:mn>2</mml:mn>
                        <mml:mo> </mml:mo>
                        <mml:mo>·</mml:mo>
                        <mml:mover accent="true">
                          <mml:mi mathvariant="bold">L</mml:mi>
                          <mml:mo>¯</mml:mo>
                        </mml:mover>
                        <mml:mo>·</mml:mo>
                        <mml:mi mathvariant="bold">Z</mml:mi>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mrow>
                            <mml:mi>k</mml:mi>
                            <mml:mo>–</mml:mo>
                            <mml:mo> </mml:mo>
                            <mml:mn>1</mml:mn>
                          </mml:mrow>
                          <mml:mo>)</mml:mo>
                        </mml:mrow>
                        <mml:mo> </mml:mo>
                        <mml:mo>–</mml:mo>
                        <mml:mi mathvariant="bold">Z</mml:mi>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mrow>
                            <mml:mi>k</mml:mi>
                            <mml:mo>–</mml:mo>
                            <mml:mo> </mml:mo>
                            <mml:mn>2</mml:mn>
                          </mml:mrow>
                          <mml:mo>)</mml:mo>
                        </mml:mrow>
                      </mml:mtd>
                    </mml:mtr>
                  </mml:mtable>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:mrow>
          <mml:mo>,</mml:mo>
        </mml:math>
      </disp-formula>
      <p>where the summation above represents the <italic toggle="yes">K</italic>-polynomial filter, <bold>Z</bold>(<italic toggle="yes">k</italic>) is the Chebyshev polynomial of order <italic toggle="yes">k</italic> approximating the spectral graph convolution (<xref rid="btad089-B43" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic>, 2019</xref>), <bold>Θ</bold> represents the learnable parameters of the filter, <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mover accent="true"><mml:mi mathvariant="bold">L</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> refers to the normalized graph Laplacian and <italic toggle="yes">K</italic> is the Chebyshev filter size. The features at the input of the layer are given by <bold>x</bold>. An example showcasing the three convolutional layers is provided in the <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S1.4</xref>.</p>
      <p>For all three GNN models, the node classification task is implemented by inserting an additional graph convolutional layer, accepting <bold>x</bold><sub><italic toggle="yes">i</italic></sub> as the input and generating <italic toggle="yes">ŷ<sub>i</sub></italic> as the output, while the edge classification task is implemented using an MLP on the concatenation of two atom representations <bold>x</bold><sub><italic toggle="yes">i</italic></sub> and <bold>x</bold><sub><italic toggle="yes">j</italic></sub> as described earlier.</p>
      <p>The models are trained using Adam optimization (<xref rid="btad089-B17" ref-type="bibr">Kingma and Ba, 2014</xref>), with binary cross-entropy as the loss function. Hyperparameters are tuned using the grid search approach. Ranges for the hyperparameters were selected manually based on their expected effects and practical considerations for runtime. The hyperparameters include the size of the latent representations (set to 64, 128, 256 or 512) and the number of GNN layers (ranging from 1 to 5). In addition, we adjusted the filter size (from 1 to 10) for GNNs for the Chebyshev convolutional operator, and maximum number of degrees (from 1 to 5) for models using the molecular fingerprinting convolution. The models were constructed using the convolutional layer implementations provided by PyTorch Geometric (<xref rid="btad089-B11" ref-type="bibr">Fey and Lenssen, 2019</xref>).</p>
    </sec>
    <sec>
      <title>2.3 Baseline models</title>
      <p>Random Forest, MLP and AdaBoost are selected as baseline models for the same classification task. These models have been used prior for SOM prediction in on reaction-specific datasets and can be considered representative examples of the current state of the art in SOM prediction. For example, Random Forest (RF) classifiers form the basis of the MetScore (<xref rid="btad089-B12" ref-type="bibr">Finkelmann <italic toggle="yes">et al.</italic>, 2018</xref>) and FAME (<xref rid="btad089-B18" ref-type="bibr">Kirchmair et al., 2013</xref>) methods. XenoSite (<xref rid="btad089-B41" ref-type="bibr">Zaretzki <italic toggle="yes">et al.</italic>, 2013</xref>) and Rainbow XenoSite (<xref rid="btad089-B4" ref-type="bibr">Dang <italic toggle="yes">et al.</italic>, 2020</xref>) utilize MLP models for their prediction task. Finally, the work of He et al. (<xref rid="btad089-B14" ref-type="bibr">He <italic toggle="yes">et al.</italic>, 2017</xref>) leverages a collection of ML techniques, including RF and AdaBoost. We use the same input feature vectors and datasets for both our GNN and baseline models, therefore allowing for a fair comparison between baselines and GNN models.</p>
      <p>The MLP models are trained using Adam optimization with cross-entropy loss. For Random Forest models, we used Gini impurity as the splitting algorithm. The SAMME.R boosting algorithm was used in building the AdaBoost models. The models were constructed using the scikit-learn package. Hyperparameter tuning is performed using grid search. For MLP, we varied the size of the latent representations (set to 32, 64, 128, 256 or 512) and the number of hidden layers (from 1 to 5). Meanwhile, for both Random Forest and AdaBoost, we adjusted the number of decision trees (set to 100, 250, 500 or 1000).</p>
    </sec>
    <sec>
      <title>2.4 Dataset construction</title>
      <p>We derive our atom SOM dataset from the KEGG RPAIR database (<xref rid="btad089-B38" ref-type="bibr">Yamada <italic toggle="yes">et al.</italic>, 2005</xref>), a collection of atom-mapped reactant pairs associated with specific transformation patterns. Each RPAIR has cross-references to reactions in the KEGG database as well as the relevant Enzyme Commission (EC) numbers. The transformation patterns are encoded using R, D and M (RDM, for short) atom-level tags. ‘R’ distinguishes the reaction center atoms, which we assume to be the sites of metabolism. The ‘D’ (difference) tag points to molecular substructures modified by the biochemical transformation, while the ‘M’ (match) tag refers to substructures neighboring the ‘R’ tagged atom that remain unchanged.</p>
      <p>We create separate versions of the dataset, one for the atomic-SOM problem, and one for the bond-SOM problem. To create the atom-centric version of the dataset we assign SOM labels to every atom at the reaction center of an RDM pattern (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section S1.1</xref>). To create a dataset suited for bond SOM prediction, we identify bonds that change due to a chemical transformation and label them as SOMs instead (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section S1.2</xref>). As this dataset is not readily available, we curate the KEGG RPAIR database to generate such a set. The dataset was further processed to improve SOM labeling (<xref rid="sup1" ref-type="supplementary-material">Supplementary Section S1.3</xref>). Some adjustments are specific to a given version of the dataset. A symmetry adjustment is applied to both datasets to account for molecular symmetrical features.</p>
      <p>The feature vectors representing atoms consist of three components, which include the atom elemental type, the KEGG atom type (an atom label that represents the atom type and the atom’s relationships to nearby elements and bonds), and the first two levels of the EC (Enzyme Commission) number of the enzyme associated with the transformation. Further details can be found in <xref rid="sup1" ref-type="supplementary-material">Supplementary Section S1</xref>.</p>
    </sec>
  </sec>
  <sec>
    <title>3 Results</title>
    <sec>
      <title>3.1 Data splits</title>
      <p>To assess the effectiveness of the models on the available dataset (21 023 molecules), we employ a cross-validation scheme. We create ten different data splits, with 80% of molecules allocated for training, 10% for validation, and the remaining 10% for testing. The partitions are generated by performing shuffle splits on the set of biotransformations, which ensures there is no information leakage across the substrate and product sides of a reaction or across enzymes associated with the same transformation. The set of training molecules is used to train several versions of a model with different hyperparameter combinations. The best combination is then selected based on its performance on the validation set. Finally, the selected model is evaluated on the test set. This process is repeated ten times, once for each data split, and we report the average test set performance for each method.</p>
      <p>This approach yields ten different models with varying training set molecules and hyperparameters. For use in biological applications, we create a combined model that applies all ten models to a query molecule and reports the average predicted SOM probabilities for each atom.</p>
    </sec>
    <sec>
      <title>3.2 GNN model evaluation</title>
      <p>In our evaluation of various models, we considered several performance metrics, including area under the ROC curve (AUROC) and <italic toggle="yes">R</italic>-precision. AUROC evaluates the model’s ability to rank SOM sites higher than any site where metabolism is not known to occur. <italic toggle="yes">R</italic>-precision measures the fraction of SOMs present among the top <italic toggle="yes">R</italic> predictions, where <italic toggle="yes">R</italic> is the total number of SOMs in the molecule or the test set.</p>
      <p>We calculated AUROC and <italic toggle="yes">R</italic>-precision using two different methods. The ‘molecular’ benchmarks were defined to be the average value of the corresponding metric when calculated on a per-molecule basis. This represents the expected performance in applications where the objective is to identify SOMs in a specific queried molecule. The alternative approach is to calculate AUROC and <italic toggle="yes">R</italic>-precision on the full set of atoms where all molecules are pooled together. Such ‘atomic’ measurements are representative of a model’s performance in scenarios where the goal is to locate the most likely SOMs in a group of molecules. We also considered the ‘top-two’ correctness rate, a molecular metric that is frequently used to evaluate the performance of CYP SOM predictors (<xref rid="btad089-B4" ref-type="bibr">Dang <italic toggle="yes">et al.</italic>, 2020</xref>; <xref rid="btad089-B41" ref-type="bibr">Zaretzki <italic toggle="yes">et al.</italic>, 2013</xref>). It represents the proportion of molecules where a known SOM appears among the molecule’s top-two predicted sites. Therefore, in contrast to the other measures, it ‘saturates’ and does not require a completely correct ranking for a perfect score to be assigned to a molecule. Several versions of each model with different hyperparameters were evaluated. Although there were five performance metrics that we considered important, they were all strongly correlated with one another. As such, model selection was performed by maximizing the molecular <italic toggle="yes">R</italic>-precision on the validation set.</p>
      <p>Model evaluation is reported for the best-in-class GNNs (<xref rid="btad089-T1" ref-type="table">Table 1</xref>). GNNs using the Chebyshev convolutional operator achieved the best performance by all five metrics, with models based on the molecular fingerprinting convolution being a close second. Performance of GIN-based models, however, was markedly worse. For the remainder of the manuscript, we refer to the GNN that utilizes the Chebyshev convolutional operator as GNN-SOM.</p>
      <table-wrap position="float" id="btad089-T1">
        <label>Table 1.</label>
        <caption>
          <p>GNN and non-GNN model evaluation</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Molecular R-precision</th>
              <th rowspan="1" colspan="1">Molecular AUROC</th>
              <th rowspan="1" colspan="1">Top-2 correctness rate</th>
              <th rowspan="1" colspan="1">Atomic R-precision</th>
              <th rowspan="1" colspan="1">Atomic AUROC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td colspan="6" rowspan="1">(A) GNN model evaluation</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> GNN-SOM (GIN)</td>
              <td rowspan="1" colspan="1">0.676</td>
              <td rowspan="1" colspan="1">0.915</td>
              <td rowspan="1" colspan="1">0.812</td>
              <td rowspan="1" colspan="1">0.635</td>
              <td rowspan="1" colspan="1">0.939</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> GNN-SOM (MF)</td>
              <td rowspan="1" colspan="1">0.764</td>
              <td rowspan="1" colspan="1">0.946</td>
              <td rowspan="1" colspan="1">0.851</td>
              <td rowspan="1" colspan="1">0.731</td>
              <td rowspan="1" colspan="1">0.963</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> GNN-SOM (Cheb)</td>
              <td rowspan="1" colspan="1">0.789</td>
              <td rowspan="1" colspan="1">0.953</td>
              <td rowspan="1" colspan="1">0.868</td>
              <td rowspan="1" colspan="1">0.771</td>
              <td rowspan="1" colspan="1">0.971</td>
            </tr>
            <tr>
              <td colspan="6" rowspan="1">(B) Models with KEGG atom types</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> RF</td>
              <td rowspan="1" colspan="1">0.520</td>
              <td rowspan="1" colspan="1">0.850</td>
              <td rowspan="1" colspan="1">0.716</td>
              <td rowspan="1" colspan="1">0.469</td>
              <td rowspan="1" colspan="1">0.872</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> Ada</td>
              <td rowspan="1" colspan="1">0.520</td>
              <td rowspan="1" colspan="1">0.850</td>
              <td rowspan="1" colspan="1">0.713</td>
              <td rowspan="1" colspan="1">0.470</td>
              <td rowspan="1" colspan="1">0.871</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> MLP</td>
              <td rowspan="1" colspan="1">0.519</td>
              <td rowspan="1" colspan="1">0.850</td>
              <td rowspan="1" colspan="1">0.714</td>
              <td rowspan="1" colspan="1">0.470</td>
              <td rowspan="1" colspan="1">0.871</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> GNN-SOM</td>
              <td rowspan="1" colspan="1">0.789</td>
              <td rowspan="1" colspan="1">0.953</td>
              <td rowspan="1" colspan="1">0.868</td>
              <td rowspan="1" colspan="1">0.771</td>
              <td rowspan="1" colspan="1">0.971</td>
            </tr>
            <tr>
              <td colspan="6" rowspan="1">(C) Models without KEGG atom types</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> RF</td>
              <td rowspan="1" colspan="1">0.294</td>
              <td rowspan="1" colspan="1">0.649</td>
              <td rowspan="1" colspan="1">0.501</td>
              <td rowspan="1" colspan="1">0.276</td>
              <td rowspan="1" colspan="1">0.713</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> Ada</td>
              <td rowspan="1" colspan="1">0.295</td>
              <td rowspan="1" colspan="1">0.650</td>
              <td rowspan="1" colspan="1">0.502</td>
              <td rowspan="1" colspan="1">0.276</td>
              <td rowspan="1" colspan="1">0.713</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> MLP</td>
              <td rowspan="1" colspan="1">0.297</td>
              <td rowspan="1" colspan="1">0.651</td>
              <td rowspan="1" colspan="1">0.505</td>
              <td rowspan="1" colspan="1">0.275</td>
              <td rowspan="1" colspan="1">0.711</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> GNN-SOM</td>
              <td rowspan="1" colspan="1">0.749</td>
              <td rowspan="1" colspan="1">0.934</td>
              <td rowspan="1" colspan="1">0.849</td>
              <td rowspan="1" colspan="1">0.725</td>
              <td rowspan="1" colspan="1">0.963</td>
            </tr>
            <tr>
              <td colspan="6" rowspan="1">(D) Expectation via random guessing</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> Expectation</td>
              <td rowspan="1" colspan="1">0.111</td>
              <td rowspan="1" colspan="1">0.500</td>
              <td rowspan="1" colspan="1">0.111</td>
              <td rowspan="1" colspan="1">0.044</td>
              <td rowspan="1" colspan="1">0.500</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn1">
            <p><italic toggle="yes">Note</italic>: (A) Different GNN models. (B) Performance on the original dataset that includes the KEGG atom types (C) Model performance with the removal of the KEGG atom types. (D) Expected performance that would be achieved on this dataset via random guessing. Standard deviation for all listed values is 0.02 or less.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.3 GNN models outperform non-GNN models</title>
      <p>We compared the best GNN model, GNN-SOM, to several baseline approaches. GNN-SOM outperforms baseline methods on all five considered metrics (<xref rid="btad089-T1" ref-type="table">Table 1</xref>). The use of GNNs led to an approximately 10% improvement in molecular and atomic AUROCs and as much as a 30% increase in atomic <italic toggle="yes">R</italic>-precision.</p>
      <p>We postulate that the limited information about an atom’s local chemical environment is a major factor responsible for performance differences. To evaluate the contributions of the KEGG atom types, we removed the node feature responsible for this property and observed a 15–20% reduction of the baseline models’ evaluation metrics, while the performance of GNN-based models was only minorly affected. Baseline models are able to utilize the KEGG atom types as a part of the node feature vector, while GNNs can natively infer it from the graph structure.</p>
      <p>We provide the expected performance achievable via random guessing as a means of evaluating the inherent complexity of the prediction problem. A binary classifier making random guesses with no bias towards any specific class achieves AUROC of 0.5 (<xref rid="btad089-B10" ref-type="bibr">Fawcett, 2006</xref>). Given <italic toggle="yes">R</italic> relevant SOMs and <italic toggle="yes">N</italic> total SOM candidates, the expected <italic toggle="yes">R</italic>-precision and top-two correctness rates for a set of atoms were calculated as follows:</p>
      <disp-formula id="E5">
        <label>(5)</label>
        <mml:math id="M5" display="block" overflow="scroll">
          <mml:mi mathvariant="normal">Rprecision</mml:mi>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:mo>=</mml:mo>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:mfrac>
            <mml:mrow>
              <mml:mn>1</mml:mn>
            </mml:mrow>
            <mml:mrow>
              <mml:mi>R</mml:mi>
            </mml:mrow>
          </mml:mfrac>
          <mml:mrow>
            <mml:msubsup>
              <mml:mo stretchy="false">∑</mml:mo>
              <mml:mrow>
                <mml:mi>i</mml:mi>
                <mml:mi mathvariant="normal"> </mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mi mathvariant="normal"> </mml:mi>
                <mml:mn>0</mml:mn>
              </mml:mrow>
              <mml:mrow>
                <mml:mi>R</mml:mi>
                <mml:mi mathvariant="normal"> </mml:mi>
                <mml:mo>-</mml:mo>
                <mml:mi mathvariant="normal"> </mml:mi>
                <mml:mn>1</mml:mn>
              </mml:mrow>
            </mml:msubsup>
            <mml:mrow>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mi>R</mml:mi>
                  <mml:mo>-</mml:mo>
                  <mml:mi mathvariant="normal"> </mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>N</mml:mi>
                  <mml:mi mathvariant="normal"> </mml:mi>
                  <mml:mo>-</mml:mo>
                  <mml:mi mathvariant="normal"> </mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
          </mml:mrow>
          <mml:mo>,</mml:mo>
        </mml:math>
      </disp-formula>
      <disp-formula id="E6">
        <mml:math id="M6" display="block" overflow="scroll">
          <mml:mi mathvariant="normal">Top</mml:mi>
          <mml:mi mathvariant="italic">Two</mml:mi>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:mo>=</mml:mo>
          <mml:mi mathvariant="normal"> </mml:mi>
          <mml:mfrac>
            <mml:mrow>
              <mml:mn>1</mml:mn>
            </mml:mrow>
            <mml:mrow>
              <mml:mn>2</mml:mn>
            </mml:mrow>
          </mml:mfrac>
          <mml:mrow>
            <mml:msubsup>
              <mml:mo stretchy="false">∑</mml:mo>
              <mml:mrow>
                <mml:mi>i</mml:mi>
                <mml:mi mathvariant="normal"> </mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mi mathvariant="normal"> </mml:mi>
                <mml:mn>0</mml:mn>
              </mml:mrow>
              <mml:mrow>
                <mml:mn>1</mml:mn>
              </mml:mrow>
            </mml:msubsup>
            <mml:mrow>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mi>R</mml:mi>
                  <mml:mi mathvariant="normal"> </mml:mi>
                  <mml:mo>-</mml:mo>
                  <mml:mi mathvariant="normal"> </mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>N</mml:mi>
                  <mml:mi mathvariant="normal"> </mml:mi>
                  <mml:mo>-</mml:mo>
                  <mml:mi mathvariant="normal"> </mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:mrow>
              </mml:mfrac>
            </mml:mrow>
          </mml:mrow>
          <mml:mo>.</mml:mo>
        </mml:math>
      </disp-formula>
      <p>In each iteration of a summation, we computed the expected number of selected SOMs from the set of the remaining available candidates. For <italic toggle="yes">R</italic>-precision, we considered the total number of sites selected among the top <italic toggle="yes">R</italic> prediction attempts and divided it by the number of attempts made, following the definition of the metric. For top-two correctness rate, we found the probability of selecting an SOM within the first two attempts using a similar approach.</p>
    </sec>
    <sec>
      <title>3.4 Bond SOM prediction and atomic SOM prediction</title>
      <p>We found that the bond SOM prediction problem is inherently more difficult than the atomic SOM prediction, with limited advantages offered in the way of combining the two approaches. The <italic toggle="yes">expected</italic> performance metrics, with the exception of AUROC, are lower for the bond SOM prediction task by approximately a factor of two: this is a consequence of there being about twice as many SOM edge candidates in the bond prediction problem with no proportional increase in the number of true sites. To quantify the potential benefits of combining the two problems for more accurate predictions overall, we compared molecular <italic toggle="yes">R</italic>-precision values achieved by the best models for each data split, counting the number of molecules where the performance of one model exceeded that of the other or where there was a tie. On average across the ten data splits, the node-centric model achieves better molecular <italic toggle="yes">R</italic>-precision for 733.3 molecules (SD 40.6), the edge-centric model outperforms in 172.3 (SD 25.4) cases and the remaining 1202 (SD 46.0) molecules experienced identical performance on the two models. Therefore, in most cases, the node-centric model would be the ideal choice, with it providing better predictions for a larger number of molecules. The comparison of the overall performance of the two types of models is provided in <xref rid="btad089-T2" ref-type="table">Table 2</xref>.</p>
      <table-wrap position="float" id="btad089-T2">
        <label>Table 2.</label>
        <caption>
          <p>Performance of GNN-based models on node-centric and edge-centric versions of the dataset</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Molecular R-precision</th>
              <th rowspan="1" colspan="1">Molecular AUROC</th>
              <th rowspan="1" colspan="1">Top-2 correctness rate</th>
              <th rowspan="1" colspan="1">Atomic R-precision</th>
              <th rowspan="1" colspan="1">Atomic AUROC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="1" colspan="1">GNN-SOM</td>
              <td rowspan="1" colspan="1">0.789</td>
              <td rowspan="1" colspan="1">0.953</td>
              <td rowspan="1" colspan="1">0.868</td>
              <td rowspan="1" colspan="1">0.771</td>
              <td rowspan="1" colspan="1">0.971</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Expectation, atom</td>
              <td rowspan="1" colspan="1">0.111</td>
              <td rowspan="1" colspan="1">0.500</td>
              <td rowspan="1" colspan="1">0.111</td>
              <td rowspan="1" colspan="1">0.044</td>
              <td rowspan="1" colspan="1">0.500</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">GNN-SOM-Bond</td>
              <td rowspan="1" colspan="1">0.612</td>
              <td rowspan="1" colspan="1">0.940</td>
              <td rowspan="1" colspan="1">0.777</td>
              <td rowspan="1" colspan="1">0.543</td>
              <td rowspan="1" colspan="1">0.946</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1">Expectation, bond</td>
              <td rowspan="1" colspan="1">0.059</td>
              <td rowspan="1" colspan="1">0.500</td>
              <td rowspan="1" colspan="1">0.062</td>
              <td rowspan="1" colspan="1">0.024</td>
              <td rowspan="1" colspan="1">0.500</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn2">
            <p><italic toggle="yes">Note</italic>: Standard deviations are 0.02 or less.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>3.5 CYP versus non-CYP prediction</title>
      <p>To evaluate the applicability of our model across different types of reactions, we investigated performance of our models on interactions mediated by CYP and non-CYP enzymes. We found that CYP-specific reactions are more challenging than non-CYP interactions for all models. When trained and tested on one type of reaction, GNNs and baseline methods alike performed significantly better on non-CYP interactions despite the expected performance of a random classifier being similar in both sets (<xref rid="btad089-T3" ref-type="table">Table 3A</xref> and <xref rid="btad089-T3" ref-type="table">B</xref>). Furthermore, the models specific to non-CYP reactions—unencumbered by the more challenging CYP interactions—demonstrated slightly better performance compared to general models (<xref rid="btad089-T2" ref-type="table">Table 2</xref>) on their respective molecule sets. We believe this difference was in part due to a comparatively small number of CYP reactions available for training: in our dataset, there were 18 139 non-CYP reactions and 2877 CYP-associated reactions. However, the performance gap between the CYP and non-CYP reactions was less pronounced for our GNN approach compared to the baseline ML techniques, indicating that GNNs can more effectively learn a wide range of SOMs when training data is limited. As before, the GNNs consistently outperformed the baseline models given the same circumstances.</p>
      <table-wrap position="float" id="btad089-T3">
        <label>Table 3.</label>
        <caption>
          <p>Performance of GNNs and baseline models on CYP and non-CYP mediated interactions separately</p>
        </caption>
        <table frame="hsides" rules="groups">
          <colgroup span="1">
            <col valign="top" align="left" span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
            <col valign="top" align="char" char="." span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th rowspan="1" colspan="1"/>
              <th rowspan="1" colspan="1">Molecular R-precision</th>
              <th rowspan="1" colspan="1">Molecular AUROC</th>
              <th rowspan="1" colspan="1">Top-2 correctness rate</th>
              <th rowspan="1" colspan="1">Atomic R-precision</th>
              <th rowspan="1" colspan="1">Atomic AUROC</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td colspan="6" rowspan="1">(A) Models trained and tested on only CYP reactions</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> RF, CYP</td>
              <td rowspan="1" colspan="1">0.359</td>
              <td rowspan="1" colspan="1">0.723</td>
              <td rowspan="1" colspan="1">0.573</td>
              <td rowspan="1" colspan="1">0.359</td>
              <td rowspan="1" colspan="1">0.758</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> Ada, CYP</td>
              <td rowspan="1" colspan="1">0.358</td>
              <td rowspan="1" colspan="1">0.725</td>
              <td rowspan="1" colspan="1">0.575</td>
              <td rowspan="1" colspan="1">0.360</td>
              <td rowspan="1" colspan="1">0.761</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> MLP, CYP</td>
              <td rowspan="1" colspan="1">0.362</td>
              <td rowspan="1" colspan="1">0.728</td>
              <td rowspan="1" colspan="1">0.575</td>
              <td rowspan="1" colspan="1">0.358</td>
              <td rowspan="1" colspan="1">0.758</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> GNN-SOM, CYP</td>
              <td rowspan="1" colspan="1">0.693</td>
              <td rowspan="1" colspan="1">0.912</td>
              <td rowspan="1" colspan="1">0.767</td>
              <td rowspan="1" colspan="1">0.695</td>
              <td rowspan="1" colspan="1">0.955</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> Expectation, CYP</td>
              <td rowspan="1" colspan="1">0.108</td>
              <td rowspan="1" colspan="1">0.500</td>
              <td rowspan="1" colspan="1">0.112</td>
              <td rowspan="1" colspan="1">0.051</td>
              <td rowspan="1" colspan="1">0.500</td>
            </tr>
            <tr>
              <td colspan="6" rowspan="1">(B) Models trained and tested on only non-CYP reactions</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> RF, non-CYP</td>
              <td rowspan="1" colspan="1">0.545</td>
              <td rowspan="1" colspan="1">0.870</td>
              <td rowspan="1" colspan="1">0.731</td>
              <td rowspan="1" colspan="1">0.488</td>
              <td rowspan="1" colspan="1">0.885</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> Ada, non-CYP</td>
              <td rowspan="1" colspan="1">0.546</td>
              <td rowspan="1" colspan="1">0.870</td>
              <td rowspan="1" colspan="1">0.734</td>
              <td rowspan="1" colspan="1">0.489</td>
              <td rowspan="1" colspan="1">0.885</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> MLP, non-CYP</td>
              <td rowspan="1" colspan="1">0.547</td>
              <td rowspan="1" colspan="1">0.870</td>
              <td rowspan="1" colspan="1">0.737</td>
              <td rowspan="1" colspan="1">0.488</td>
              <td rowspan="1" colspan="1">0.886</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> GNN-SOM, Non-CYP</td>
              <td rowspan="1" colspan="1">0.799</td>
              <td rowspan="1" colspan="1">0.958</td>
              <td rowspan="1" colspan="1">0.878</td>
              <td rowspan="1" colspan="1">0.782</td>
              <td rowspan="1" colspan="1">0.973</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> Expectation, non-CYP</td>
              <td rowspan="1" colspan="1">0.111</td>
              <td rowspan="1" colspan="1">0.500</td>
              <td rowspan="1" colspan="1">0.111</td>
              <td rowspan="1" colspan="1">0.044</td>
              <td rowspan="1" colspan="1">0.500</td>
            </tr>
            <tr>
              <td colspan="6" rowspan="1">(C) Models trained on all reactions but tested only on CYP or non-CYP</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> GNN-SOM, CYP</td>
              <td rowspan="1" colspan="1">0.690</td>
              <td rowspan="1" colspan="1">0.910</td>
              <td rowspan="1" colspan="1">0.775</td>
              <td rowspan="1" colspan="1">0.694</td>
              <td rowspan="1" colspan="1">0.956</td>
            </tr>
            <tr>
              <td rowspan="1" colspan="1"> GNN-SOM, non-CYP</td>
              <td rowspan="1" colspan="1">0.804</td>
              <td rowspan="1" colspan="1">0.959</td>
              <td rowspan="1" colspan="1">0.883</td>
              <td rowspan="1" colspan="1">0.784</td>
              <td rowspan="1" colspan="1">0.973</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn id="tblfn3">
            <p><italic toggle="yes">Note</italic>: Standard deviations are 0.03 or less.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>We also found that our general-purpose SOM prediction model is as effective as the CYP and non-CYP-specific models. The SOM predictor trained on all available interactions, achieves very similar performance on the CYP and non-CYP subsets compared to models trained on each reaction type specifically (<xref rid="btad089-T3" ref-type="table">Table 3C</xref>). As such, our approach alleviates the necessity for separate predictors for CYP and non-CYP interactions.</p>
    </sec>
    <sec>
      <title>3.6 Applications of using SOM prediction</title>
      <p>While several techniques predict overall reaction feasibility, such as thermodynamic feasibility [e.g. eQuilibrator (<xref rid="btad089-B2" ref-type="bibr">Beber <italic toggle="yes">et al.</italic>, 2022</xref>; <xref rid="btad089-B23" ref-type="bibr">Noor <italic toggle="yes">et al.</italic>, 2013</xref>)], or likelihood of a biochemical conversion between a substrate and a product [e.g. DeepRFC (<xref rid="btad089-B16" ref-type="bibr">Kim <italic toggle="yes">et al.</italic>, 2021</xref>) and ELP (<xref rid="btad089-B15" ref-type="bibr">Jiang <italic toggle="yes">et al.</italic>, 2021</xref>)], SOM prediction determines the likelihood of an enzyme class acting on a particular atom or bond within a molecule. Therefore, when paired with a rule-based method, the SOM likelihood can be assumed a proxy for the likelihood of reaction occurrence. We demonstrate the utility of SOM prediction using two applications: screening promiscuous products generated using rule-based prediction methods, and ranking synthesis pathways based on SOM likelihood of each pathway’s individual reaction steps. While we selected PROXIMAL (<xref rid="btad089-B39" ref-type="bibr">Yousofshahi <italic toggle="yes">et al.</italic>, 2015</xref>) as our companion rule-based method, our GNN-SOM method is independent of PROXIMAL, and can be used with other rule-based techniques as well.</p>
      <sec>
        <title>3.6.1 Screening promiscuous products generated from rule-based prediction methods to create EMMs</title>
        <p>To evaluate GNN-SOM’s utility in improving prediction of products arising due to enzyme promiscuity, we leveraged GNN-SOM as a screening step for rule-based product prediction methods to eliminate unlikely promiscuous products. We chose to evaluate the impact of including this step on creating EMMs (<xref rid="btad089-B1" ref-type="bibr">Amin <italic toggle="yes">et al.</italic>, 2019</xref>), which are intended to account for promiscuous enzymatic activities. In that work, the <italic toggle="yes">i</italic>ML1515 model of <italic toggle="yes">E.coli</italic> (<xref rid="btad089-B21" ref-type="bibr">Monk <italic toggle="yes">et al.</italic>, 2017</xref>) was extended with a number of reactions that could arise due to uncatalogued promiscuous enzyme activity. The PROXIMAL tool was used to predict interactions occurring between native enzymes and substrates listed in <italic toggle="yes">i</italic>ML1515. The resulting putative products were then searched in ECMDB (<xref rid="btad089-B13" ref-type="bibr">Guo <italic toggle="yes">et al.</italic>, 2013</xref>; <xref rid="btad089-B29" ref-type="bibr">Sajed <italic toggle="yes">et al.</italic>, 2016</xref>) and PubChem to identify promiscuous transformations that were observed previously but are missing from the <italic toggle="yes">i</italic>ML1515 model. Balanced reactions were then constructed for each transformation, and after manual curation, 23 new reactions were recommended for addition into the model.</p>
        <p>PROXIMAL generates products via application of RDM patterns on molecular graphs of queried substrates: it does not consider SOMs. As a result, it may propose unfeasible or unlikely biotransformations. Using SOM predictions as a criterion for applying patterns can help lower the number of such unfeasible products, potentially reducing the amount of manual curation required. We use our SOM predictor as a filter on the products. For a biotransformation to be accepted, the reaction center in the substrate at which PROXIMAL applied the pattern must be at or above a certain threshold. If the reaction center is below that value, we consider the transformation to be unlikely and discard it.</p>
        <p>Our application of 1875 PROXIMAL operators presented by Amin <italic toggle="yes">et al.</italic> to 106 high-concentration metabolites (<xref rid="btad089-B33" ref-type="bibr">Tepper <italic toggle="yes">et al.</italic>, 2013</xref>) in <italic toggle="yes">E.coli</italic> yielded a set of 1989 products, 1390 of which we could cross-reference between the PubChem online REST API and the derivative products presented in the publication. Additionally, there were 55 products that were cross-referenced to ECMDB. Such products were considered to be ‘verifiable’ since there was concrete evidence of their existence in <italic toggle="yes">E.coli</italic>. In comparison, predicted products merely found in PubChem are less likely to occur in <italic toggle="yes">E.coli</italic>, since this set includes a great many metabolites never observed in the organism before. As such, the ratio between the number of compounds confirmed by both databases and PubChem only, represents a metric of interest. Thus, retaining a higher percentage of ECMDB-confirmed products when filtering using GNN-SOM compared to the overall predicted products showcases the utility of GNN-SOM.</p>
        <p>Instead of examining the number of products under a fixed threshold (likelihood), we explore how the threshold impacts the number of products. We applied a range of filter thresholds from 0.0 to 1.0 in 0.1 increments (<xref rid="btad089-F3" ref-type="fig">Fig. 3</xref>). As the threshold increases, fewer products—confirmed and overall—pass the filter. Importantly, the proportion of confirmed products grows with the threshold. The ratio of verifiable products steadily increases as the threshold is raised (<xref rid="btad089-F3" ref-type="fig">Fig. 3</xref>), indicating that metabolites confirmed to exist in <italic toggle="yes">E.coli</italic> are removed at a lower rate than unconfirmed metabolites; the ratio is at its lowest prior to the application of the filter (threshold = 0.0). Therefore, GNN-SOM enables more efficient prediction of metabolites suitable for creating EMMs. While we applied GNN-SOM post-promiscuous product generation as a screening tool, GNN-SOM can also be used to identify likely SOMs where the rules can be applied.</p>
        <fig position="float" id="btad089-F3">
          <label>Fig. 3.</label>
          <caption>
            <p>Percentage of products passed by the SOM predictor filter for different sets of metabolites, at different thresholds</p>
          </caption>
          <graphic xlink:href="btad089f3" position="float"/>
        </fig>
      </sec>
      <sec>
        <title>3.6.2 Ranking synthesis pathways based on SOM likelihood</title>
        <p>SOM predictors can guide synthesis pathway construction. In this experiment, we compare known engineered two- and three-step pathways for 3-hydroxypropionic acid (3-HP) synthesis in <italic toggle="yes">E.coli</italic> to a number of putative synthesis pathways generated by PROXIMAL. To compare pathways based on SOM-GNN guidance, we calculate a pathway likelihood by taking the product of GNN-SOM predictions for the constituent reactions of each pathway. The output of GNN-SOM is a continuous value, representing a given site’s likelihood of being an SOM for a certain EC number. Since the site and the type of biotransformation is specified, such likelihood is reflective of the probability of occurrence for the entire reaction. The overall likelihood of a pathway is calculated as the product of the probabilities of its reaction steps. Pathway likelihoods thus provide a relative metric that allows comparing pathways based on SOM likelihood. As pathway construction (without filtering, e.g. based on yield or other metrics) generates a large number of putative pathways, we expect engineered pathways to have, on average, a higher pathway likelihood than the putative pathways.</p>
        <p>We considered two engineered pathways for 3-HP synthesis known from the literature. The first pathway is catalyzed by a non-native enzyme, malonyl-CoA reductase, to produce 3-HP in two reaction steps (<xref rid="btad089-B3" ref-type="bibr">Cheng <italic toggle="yes">et al.</italic>, 2016</xref>; <xref rid="btad089-B26" ref-type="bibr">Rathnasingh <italic toggle="yes">et al.</italic>, 2012</xref>). The second pathway relies on heterologous expression of several genes—<italic toggle="yes">panD</italic>, <italic toggle="yes">gabT</italic> and <italic toggle="yes">ydfG—</italic>to yield 3-HP in three reaction steps starting from L-aspartate (<xref rid="btad089-B36" ref-type="bibr">Wang <italic toggle="yes">et al.</italic>, 2014</xref>). Both pathways have been successfully used as a part of longer pathways for sourcing 3-HP and derivatives from glucose consumed by <italic toggle="yes">E.coli</italic>. In many reactions comprising those pathways, there were multiple options for the selection of a reaction center. To identify the most plausible set of centers, we calculated GNN-SOM likelihoods for all possible combinations and selected the one that maximized the likelihood of the pathway.</p>
        <p>The family of generated pathways was constructed via prediction of promiscuous activity involving 3-HP and enzymes natively present in <italic toggle="yes">E.coli—</italic>and since the bacterium does not natively produce this molecule, such interactions are representative of unsuccessful pathway synthesis outcomes. Working back from the target metabolite, PROXIMAL was used to propose precursor metabolites and the necessary reaction steps (enzyme as well as the reaction center) that could ultimately yield 3-HP. Because the number of such pathways can be extremely large, 50 000 pathways of each depth were sampled at random, followed by removing duplicates. This process produced 7869 two-step and 45 622 three-step synthetic pathways. This set was further refined by removing pathways with intermediates not listed in the PubChem—such intermediates may less likely occur in nature than metabolites previously observed and catalogued in the database. In the end, we obtained 1226 two-step and 1118 three-step PubChem-only pathways.</p>
        <p>The average likelihood of putative pathways was 0.24 for two-step and 0.17 for three-step interactions. For PubChem-only synthetic pathways, the mean likelihoods were 0.30 and 0.37 for two- and three-step pathways, respectively—the higher likelihood observed in this case suggests the model assigns greater confidence to interactions with evidence of the metabolite’s existence. Finally, the likelihoods of the two effective synthesis pathways for the most plausible sets of reaction centers were found to be 0.987 and 0.956 in the cases of malonyl-CoA and <sc>l</sc>-aspartate pathways, respectively.</p>
        <p>The calculated likelihoods allow ranking synthetic pathways based on the likelihood of the SOMs they depend on, and ideally, such ordering would prioritize functional pathways over the putative ones. The quality of this ranking can be quantified using the AUROC metric. The likelihood of the two-step malonyl-CoA pathway exceeded those of <italic toggle="yes">all</italic> considered two-step putative pathways, leading to the AUROC of 1.0. For the <sc>l</sc>-aspartate pathway and its putative three-step counterparts, the AUROC was 0.997. Therefore, our SOM predictor allows unlikely candidates to be deprioritized or removed from consideration at a low computational expense.</p>
      </sec>
    </sec>
  </sec>
  <sec>
    <title>4 Conclusion</title>
    <p>We explored in this article GNN-based models that predict atomic and bond SOMs for enzymatic reactions. Our analysis revealed that the bond-SOM prediction problem is more difficult than the atom-SOM prediction problem. Our GNN model, GNN-SOM, based on the Chebyshev convolutional operator consistently outperforms baseline ML classification models. Importantly, we showed that training on all enzymatic reactions outperforms the same model when trained on only CYP enzymes. Thus, the SOM prediction task (for CYP and non-CYP enzymes) benefits from a larger and more diverse training dataset. We also showed that the use of GNN-SOM can provide ranking on promiscuous products when evaluating the construction of EMMs and synthesis pathways for 3-HP.</p>
    <p>There are several avenues for improving our work. Although bond-based GNN models showed lower performance compared to atom-based ones, there were still several molecules where using them would be advantageous. Identifying characteristics of those molecules and combining the two types of models may provide an opportunity to enhance SOM prediction. Adding physicochemical molecule descriptors can improve prediction results as GNN-SOM only considers element and bond information that can be elucidated from the 2D molecular structure. Finally, pre-training the model using a larger molecular dataset could further improve accuracy and applicability of GNN-SOM.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>btad089_Supplementary_Data</label>
      <media xlink:href="btad089_supplementary_data.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Funding</title>
    <p>This work was supported by NSF (National Science Foundation), Award [CCF-1909536] and by NIGMS (National Institute of General Medical Sciences) of the National Institutes of Health, Award [R01GM132391]. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.</p>
    <p><italic toggle="yes">Conflict of Interest</italic>: none declared.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>The RPAIR data set was downloaded from the Kyoto Encyclopedia of Genes and Genomes (KEGG) database under an academic license.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btad089-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Amin</surname><given-names>S.A.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Towards creating an extended metabolic model (EMM) for <italic toggle="yes">E. coli</italic> using enzyme promiscuity prediction and metabolomics data</article-title>. <source>Microb. Cell Fact</source>., <volume>18</volume>, <fpage>109</fpage>.<pub-id pub-id-type="pmid">31196115</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Beber</surname><given-names>M.E.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>eQuilibrator 3.0: a database solution for thermodynamic constant estimation</article-title>. <source>Nucleic Acids Res</source>., <volume>50</volume>, <fpage>D603</fpage>–<lpage>D609</lpage>.<pub-id pub-id-type="pmid">34850162</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheng</surname><given-names>Z.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>Enhanced production of 3-hydroxypropionic acid from glucose via malonyl-CoA pathway by engineered <italic toggle="yes">Escherichia coli</italic></article-title>. <source>Bioresour. Technol</source>., <volume>200</volume>, <fpage>897</fpage>–<lpage>904</lpage>.<pub-id pub-id-type="pmid">26606325</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dang</surname><given-names>N.L.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>The metabolic rainbow: deep learning phase I metabolism in five colors</article-title>. <source>J. Chem. Inf. Model</source>, <volume>60</volume>, <fpage>1146</fpage>–<lpage>1164</lpage>.<pub-id pub-id-type="pmid">32040319</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B5">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Defferrard</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) Convolutional neural networks on graphs with fast localized spectral filtering. doi:<pub-id pub-id-type="doi">10.48550/ARXIV.1606.09375</pub-id>.</mixed-citation>
    </ref>
    <ref id="btad089-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dixit</surname><given-names>V.A.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Recent advances in the prediction of non-CYP450-mediated drug metabolism</article-title>. <source>WIREs Comput. Mol. Sci</source>., <volume>7</volume>, <fpage>e1323</fpage>.</mixed-citation>
    </ref>
    <ref id="btad089-B7">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Donti</surname><given-names>P.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) Task-based end-to-end model learning in stochastic optimization. In <italic toggle="yes">NIPS’17: Proceedings of the 31st international conference on neural information processing systems</italic> (pp. 5490–5500). NIPS.</mixed-citation>
    </ref>
    <ref id="btad089-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Duigou</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>RetroRules: a database of reaction rules for engineering biology</article-title>. <source>Nucleic Acids Res</source>., <volume>47</volume>, <fpage>D1229</fpage>–<lpage>D1235</lpage>.<pub-id pub-id-type="pmid">30321422</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B9">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Duvenaud</surname><given-names>D.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) <italic toggle="yes">Convolutional networks on graphs for learning molecular fingerprints</italic>. arXiv preprint arXiv:1509.09292, 2015.</mixed-citation>
    </ref>
    <ref id="btad089-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fawcett</surname><given-names>T.</given-names></string-name></person-group> (<year>2006</year>) <article-title>An introduction to ROC analysis</article-title>. <source>Patt. Recognit. Lett</source>., <volume>27</volume>, <fpage>861</fpage>–<lpage>874</lpage>.</mixed-citation>
    </ref>
    <ref id="btad089-B11">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Fey</surname><given-names>M.</given-names></string-name>, <string-name><surname>Lenssen</surname><given-names>J.E.</given-names></string-name></person-group> (<year>2019</year>) <italic toggle="yes">Fast graph representation learning with PyTorch geometric</italic>. arXiv preprint arXiv:1903.02428.</mixed-citation>
    </ref>
    <ref id="btad089-B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Finkelmann</surname><given-names>A.R.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) <article-title>MetScore: site of metabolism prediction beyond cytochrome P450 enzymes</article-title>. <source>ChemMedChem</source>, <volume>13</volume>, <fpage>2281</fpage>–<lpage>2289</lpage>.<pub-id pub-id-type="pmid">30184341</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname><given-names>A.C.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <article-title>ECMDB: the <italic toggle="yes">E. coli</italic> metabolome database</article-title>. <source>Nucleic Acids Res</source>., <volume>41</volume>, <fpage>D625</fpage>–<lpage>630</lpage>.<pub-id pub-id-type="pmid">23109553</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>He</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>Site of metabolism prediction for oxidation reactions mediated by oxidoreductases based on chemical bond</article-title>. <source>Bioinformatics</source>, <volume>33</volume>, <fpage>363</fpage>–<lpage>372</lpage>.<pub-id pub-id-type="pmid">27667794</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiang</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Learning graph representations of biochemical networks and its application to enzymatic link prediction</article-title>. <source>Bioinformatics</source>, <volume>37</volume>, <fpage>793</fpage>–<lpage>799</lpage>.<pub-id pub-id-type="pmid">33051674</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>A deep learning approach to evaluate the feasibility of enzymatic reactions generated by retrobiosynthesis</article-title>. <source>Biotechnol. J</source>., <volume>16</volume>, <fpage>e2000605</fpage>.<pub-id pub-id-type="pmid">33386776</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B17">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Kingma</surname><given-names>D.P.</given-names></string-name>, <string-name><surname>Ba</surname><given-names>J.</given-names></string-name></person-group> (<year>2014</year>) <source>Adam: A Method for Stochastic Optimization</source>. arXiv preprint arXiv:1412.6980, 2014.</mixed-citation>
    </ref>
    <ref id="btad089-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kirchmair</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <article-title>FAst MEtabolizer (FAME): a rapid and accurate predictor of sites of metabolism in multiple species by endogenous enzymes</article-title>. <source>J. Chem. Inf. Model</source>., <volume>53</volume>, <fpage>2896</fpage>–<lpage>2907</lpage>.<pub-id pub-id-type="pmid">24219364</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kotera</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2004</year>) <article-title>Computational assignment of the EC numbers for genomic-scale analysis of enzymatic reactions</article-title>. <source>J. Am. Chem. Soc</source>., <volume>126</volume>, <fpage>16487</fpage>–<lpage>16498</lpage>.<pub-id pub-id-type="pmid">15600352</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McDonnell</surname><given-names>A.M.</given-names></string-name>, <string-name><surname>Dang</surname><given-names>C.H.</given-names></string-name></person-group> (<year>2013</year>) <article-title>Basic review of the cytochrome p450 system</article-title>. <source>J. Adv. Pract. Oncol</source>., <volume>4</volume>, <fpage>263</fpage>–<lpage>268</lpage>.<pub-id pub-id-type="pmid">25032007</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Monk</surname><given-names>J.M.</given-names></string-name></person-group><etal>et al</etal> (<year>2017</year>) <article-title>iML1515, a knowledgebase that computes <italic toggle="yes">Escherichia coli</italic> traits</article-title>. <source>Nat. Biotechnol</source>., <volume>35</volume>, <fpage>904</fpage>–<lpage>908</lpage>.<pub-id pub-id-type="pmid">29020004</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nobeli</surname><given-names>I.</given-names></string-name></person-group><etal>et al</etal> (<year>2009</year>) <article-title>Protein promiscuity and its implications for biotechnology</article-title>. <source>Nat. Biotechnol</source>., <volume>27</volume>, <fpage>157</fpage>–<lpage>167</lpage>.<pub-id pub-id-type="pmid">19204698</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Noor</surname><given-names>E.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <article-title>Consistent estimation of Gibbs energy using component contributions</article-title>. <source>PLoS Comput. Biol</source>., <volume>9</volume>, <fpage>e1003098</fpage>.<pub-id pub-id-type="pmid">23874165</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Otero-Muras</surname><given-names>I.</given-names></string-name>, <string-name><surname>Carbonell</surname><given-names>P.</given-names></string-name></person-group> (<year>2021</year>) <article-title>Automated engineering of synthetic metabolic pathways for efficient biomanufacturing</article-title>. <source>Metab. Eng</source>., <volume>63</volume>, <fpage>61</fpage>–<lpage>80</lpage>.<pub-id pub-id-type="pmid">33316374</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Porokhin</surname><given-names>V.</given-names></string-name></person-group><etal>et al</etal> (<year>2021</year>) <article-title>Analysis of metabolic network disruption in engineered microbial hosts due to enzyme promiscuity</article-title>. <source>Metab. Eng. Commun</source>., <volume>12</volume>, <fpage>e00170</fpage>.<pub-id pub-id-type="pmid">33850714</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rathnasingh</surname><given-names>C.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>Production of 3-hydroxypropionic acid via malonyl-CoA pathway using recombinant <italic toggle="yes">Escherichia coli</italic> strains</article-title>. <source>J. Biotechnol</source>., <volume>157</volume>, <fpage>633</fpage>–<lpage>640</lpage>.<pub-id pub-id-type="pmid">21723339</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rydberg</surname><given-names>P.</given-names></string-name></person-group><etal>et al</etal> (<year>2010</year>) <article-title>SMARTCyp: a 2D method for prediction of cytochrome P450-Mediated drug metabolism</article-title>. <source>ACS Med. Chem. Lett</source>., <volume>1</volume>, <fpage>96</fpage>–<lpage>100</lpage>.<pub-id pub-id-type="pmid">24936230</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Saeys</surname><given-names>Y.</given-names></string-name></person-group><etal>et al</etal> (<year>2007</year>) <article-title>A review of feature selection techniques in bioinformatics</article-title>. <source>Bioinformatics</source>, <volume>23</volume>, <fpage>2507</fpage>–<lpage>2517</lpage>.<pub-id pub-id-type="pmid">17720704</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sajed</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>ECMDB 2.0: a richer resource for understanding the biochemistry of <italic toggle="yes">E. coli</italic></article-title>. <source>Nucleic Acids Res</source>., <volume>44</volume>, <fpage>D495</fpage>–<lpage>501</lpage>.<pub-id pub-id-type="pmid">26481353</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B30">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sivakumar</surname><given-names>T.V.</given-names></string-name></person-group><etal>et al</etal> (<year>2016</year>) <article-title>ReactPRED: a tool to predict and analyze biochemical reactions</article-title>. <source>Bioinformatics</source>, <volume>32</volume>, <fpage>3522</fpage>–<lpage>3524</lpage>.<pub-id pub-id-type="pmid">27485447</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B31">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Strutz</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2022</year>) <article-title>MINE 2.0: enhanced biochemical coverage for peak identification in untargeted metabolomics</article-title>. <source>Bioinformatics</source>., <volume>38</volume>(<issue>13</issue>), <fpage>3484</fpage>-<lpage>3487</lpage>.<pub-id pub-id-type="pmid">35595247</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tawfik</surname><given-names>D.S.</given-names></string-name></person-group> (<year>2020</year>) <article-title>Enzyme promiscuity and evolution in light of cellular metabolism</article-title>. <source>Wiley Online Library</source>, <volume>287</volume>, <fpage>1260</fpage>–<lpage>1261</lpage>.</mixed-citation>
    </ref>
    <ref id="btad089-B33">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tepper</surname><given-names>N.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <article-title>Steady-state metabolite concentrations reflect a balance between maximizing enzyme efficiency and minimizing total metabolite load</article-title>. <source>PLoS One</source>, <volume>8</volume>, <fpage>e75370</fpage>.<pub-id pub-id-type="pmid">24086517</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B34">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Testa</surname><given-names>B.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>Reactions and enzymes in the metabolism of drugs and other xenobiotics</article-title>. <source>Drug Discov. Today</source>, <volume>17</volume>, <fpage>549</fpage>–<lpage>560</lpage>.<pub-id pub-id-type="pmid">22305937</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tyzack</surname><given-names>J.D.</given-names></string-name>, <string-name><surname>Kirchmair</surname><given-names>J.</given-names></string-name></person-group> (<year>2019</year>) <article-title>Computational methods and tools to predict cytochrome P450 metabolism for drug discovery</article-title>. <source>Chem. Biol. Drug Des</source>., <volume>93</volume>, <fpage>377</fpage>–<lpage>386</lpage>.<pub-id pub-id-type="pmid">30471192</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B36">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname><given-names>Q.</given-names></string-name></person-group><etal>et al</etal> (<year>2014</year>) <article-title>Metabolic engineering of <italic toggle="yes">Escherichia coli</italic> for poly(3-hydroxypropionate) production from glycerol and glucose</article-title>. <source>Biotechnol. Lett</source>., <volume>36</volume>, <fpage>2257</fpage>–<lpage>2262</lpage>.<pub-id pub-id-type="pmid">25048226</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B37">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Xu</surname><given-names>K.</given-names></string-name></person-group><etal>et al</etal> (<year>2018</year>) How powerful are graph neural networks? arXiv.</mixed-citation>
    </ref>
    <ref id="btad089-B38">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Yamada</surname><given-names>T.</given-names></string-name></person-group><etal>et al</etal> (<year>2005</year>) RPAIR: a database of chemical transformation patterns in enzymatic reactions. In: <italic toggle="yes">GIW 2005: The Sixteenth International Conference on Genome Informatics</italic>. Pacifico Yokohama, Japan.</mixed-citation>
    </ref>
    <ref id="btad089-B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yousofshahi</surname><given-names>M.</given-names></string-name></person-group><etal>et al</etal> (<year>2015</year>) <article-title>PROXIMAL: a method for prediction of xenobiotic metabolism</article-title>. <source>BMC Syst. Biol</source>., <volume>9</volume>, <fpage>94</fpage>.<pub-id pub-id-type="pmid">26695483</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zanger</surname><given-names>U.M.</given-names></string-name>, <string-name><surname>Schwab</surname><given-names>M.</given-names></string-name></person-group> (<year>2013</year>) <article-title>Cytochrome P450 enzymes in drug metabolism: regulation of gene expression, enzyme activities, and impact of genetic variation</article-title>. <source>Pharmacol. Ther</source>., <volume>138</volume>, <fpage>103</fpage>–<lpage>141</lpage>.<pub-id pub-id-type="pmid">23333322</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B41">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zaretzki</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2013</year>) <article-title>XenoSite: accurately predicting CYP-mediated sites of metabolism with neural networks</article-title>. <source>J. Chem. Inf. Model</source>., <volume>53</volume>, <fpage>3373</fpage>–<lpage>3383</lpage>.<pub-id pub-id-type="pmid">24224933</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B42">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zaretzki</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2012</year>) <article-title>RS-Predictor models augmented with SMARTCyp reactivities: robust metabolic regioselectivity predictions for nine CYP isozymes</article-title>. <source>J. Chem. Inf. Model</source>., <volume>52</volume>, <fpage>1637</fpage>–<lpage>1659</lpage>.<pub-id pub-id-type="pmid">22524152</pub-id></mixed-citation>
    </ref>
    <ref id="btad089-B43">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname><given-names>S.</given-names></string-name></person-group><etal>et al</etal> (<year>2019</year>) <article-title>Graph convolutional networks: a comprehensive review</article-title>. <source>Comput. Soc. Netw</source>., <volume>6</volume>, <fpage>11</fpage>.</mixed-citation>
    </ref>
    <ref id="btad089-B44">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname><given-names>J.</given-names></string-name></person-group><etal>et al</etal> (<year>2020</year>) <article-title>Graph neural networks: a review of methods and applications</article-title>. <source>AI Open</source>, <volume>1</volume>, <fpage>57</fpage>–<lpage>81</lpage>.</mixed-citation>
    </ref>
  </ref-list>
</back>
