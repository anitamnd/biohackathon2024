<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_DCN101068 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEgr5 jpg ?>
<?FILEgr6 jpg ?>
<?FILEgr7 jpg ?>
<?FILEgr8 jpg ?>
<?FILEgr9 jpg ?>
<?FILEmmc1 docx ?>
<?FILEsi0001 svg ?>
<?FILEsi0002 svg ?>
<?FILEsi0003 svg ?>
<?FILEsi0004 svg ?>
<?FILEsi0005 svg ?>
<?FILEsi0006 svg ?>
<?FILEsi0007 svg ?>
<?FILEsi0008 svg ?>
<?FILEsi0009 svg ?>
<?FILEsi0010 svg ?>
<?FILEsi0011 svg ?>
<?FILEsi0012 svg ?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Dev Cogn Neurosci</journal-id>
    <journal-id journal-id-type="iso-abbrev">Dev Cogn Neurosci</journal-id>
    <journal-title-group>
      <journal-title>Developmental Cognitive Neuroscience</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1878-9293</issn>
    <issn pub-type="epub">1878-9307</issn>
    <publisher>
      <publisher-name>Elsevier</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8800139</article-id>
    <article-id pub-id-type="pii">S1878-9293(22)00012-3</article-id>
    <article-id pub-id-type="doi">10.1016/j.dcn.2022.101068</article-id>
    <article-id pub-id-type="publisher-id">101068</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Articles from the Special Issue on EEG Methods for Developmental Cognitive Neuroscientists: A Tutorial Approach; Edited by George Buzzell; Emilio Valadez; Santiago Morales; Nathan Fox; Sabine Hunnius</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>NEAR: An artifact removal pipeline for human newborn EEG data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au0005">
        <name>
          <surname>Kumaravel</surname>
          <given-names>Velu Prabhakar</given-names>
        </name>
        <xref rid="aff0005" ref-type="aff">a</xref>
        <xref rid="aff0010" ref-type="aff">b</xref>
      </contrib>
      <contrib contrib-type="author" id="au0010">
        <name>
          <surname>Farella</surname>
          <given-names>Elisabetta</given-names>
        </name>
        <xref rid="aff0005" ref-type="aff">a</xref>
      </contrib>
      <contrib contrib-type="author" id="au0015">
        <name>
          <surname>Parise</surname>
          <given-names>Eugenio</given-names>
        </name>
        <xref rid="aff0010" ref-type="aff">b</xref>
      </contrib>
      <contrib contrib-type="author" id="au0020">
        <name>
          <surname>Buiatti</surname>
          <given-names>Marco</given-names>
        </name>
        <email>marco.buiatti@unitn.it</email>
        <xref rid="aff0010" ref-type="aff">b</xref>
        <xref rid="cor1" ref-type="corresp">⁎</xref>
      </contrib>
      <aff id="aff0005"><label>a</label>Fondazione Bruno Kessler, Trento, Italy</aff>
      <aff id="aff0010"><label>b</label>CIMeC, Center for Mind/Brain Sciences, University of Trento, Rovereto, Italy</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>⁎</label>Correspondence to: CIMeC, Center for Mind/Brain Sciences, University of Trento, Piazza Manifattura 1, 38068 Rovereto, Italy. <email>marco.buiatti@unitn.it</email></corresp>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>15</day>
      <month>1</month>
      <year>2022</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>15</day>
      <month>1</month>
      <year>2022</year>
    </pub-date>
    <volume>54</volume>
    <elocation-id>101068</elocation-id>
    <history>
      <date date-type="received">
        <day>18</day>
        <month>6</month>
        <year>2021</year>
      </date>
      <date date-type="rev-recd">
        <day>15</day>
        <month>11</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>13</day>
        <month>1</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 The Authors</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="ab0010">
      <p>Electroencephalography (EEG) is arising as a valuable method to investigate neurocognitive functions shortly after birth. However, obtaining high-quality EEG data from human newborn recordings is challenging. Compared to adults and older infants, datasets are typically much shorter due to newborns’ limited attentional span and much noisier due to non-stereotyped artifacts mainly caused by uncontrollable movements. We propose Newborn EEG Artifact Removal (NEAR), a pipeline for EEG artifact removal designed explicitly for human newborns. NEAR is based on two key steps: 1) A novel bad channel detection tool based on the Local Outlier Factor (LOF), a robust outlier detection algorithm; 2) A parameter calibration procedure for adapting to newborn EEG data the algorithm Artifacts Subspace Reconstruction (ASR), developed for artifact removal in mobile adult EEG. Tests on simulated data showed that NEAR outperforms existing methods in removing representative newborn non-stereotypical artifacts. NEAR was validated on two developmental populations (newborns and 9-month-old infants) recorded with two different experimental designs (frequency-tagging and ERP). Results show that NEAR artifact removal successfully reproduces established EEG responses from noisy datasets, with a higher statistical significance than the one obtained by existing artifact removal methods. The EEGLAB-based NEAR pipeline is freely available at <ext-link ext-link-type="uri" xlink:href="https://github.com/vpKumaravel/NEAR" id="ir0005">https://github.com/vpKumaravel/NEAR</ext-link>.</p>
    </abstract>
    <kwd-group id="keys0005">
      <title>Keywords</title>
      <kwd>EEG</kwd>
      <kwd>Newborns</kwd>
      <kwd>Infants</kwd>
      <kwd>Artifact removal</kwd>
      <kwd>Local Outlier Factor</kwd>
      <kwd>Artifact Subspace Reconstruction</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="sec0005">
    <label>1</label>
    <title>Introduction</title>
    <p id="p0005">Studying human newborns in the first days of life provides key insights on the neurocognitive predispositions that humans are endowed with before interacting with the outside world. While most of the research in this field is behavioural, the recent availability of high-quality Electroencephalography (EEG) systems suitable for newborns opened the way to an increasing number of investigations on the neural bases of such predispositions with EEG (<xref rid="bib3" ref-type="bibr">Beauchemin et al., 2011</xref>, <xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>, <xref rid="bib12" ref-type="bibr">Fifer et al., 2010</xref>, <xref rid="bib33" ref-type="bibr">Ronga et al., 2021</xref>).</p>
    <p id="p0010">However, analyzing newborn EEG data is a challenging task, especially in the case of visual stimulation, because of two main factors: 1) Due to newborns’ limited attentional span, the data segments during which newborns effectively attend to the stimuli are very short; 2) Since newborns are unconstrained, the most frequent artifacts are caused by a variety of movements (head, arms, frowning, sucking) which generate non-stereotyped artifacts that constantly vary in topography and temporal dynamics. Because of these factors, artifact removal for newborn EEG data is an arbitrary and time-consuming task. Since most artifacts are non-stereotyped, ICA-based methods that are successful with adults (<xref rid="bib24" ref-type="bibr">Mognon et al., 2011</xref>, <xref rid="bib32" ref-type="bibr">Pion-Tonachini et al., 2019</xref>) or older infants (<xref rid="bib22" ref-type="bibr">Leach et al., 2020</xref>) might not be equally efficient in this case because ICA captures only stereotyped artifacts (<xref rid="bib30" ref-type="bibr">Onton et al., 2006</xref>).</p>
    <p id="p0015">One promising tool for correcting non-stereotyped artifacts is Artifact Subspace Reconstruction (ASR), an algorithm specifically designed to remove transient or large-amplitude artifacts of any nature (<xref rid="bib19" ref-type="bibr">Kothe and Jung, 2016</xref>). However, ASR performance depends on some user-defined parameters that have not been established for developmental data. Moreover, both ASR and ICA require a preliminary bad channel detection step and, as we show in this paper, the ones proposed by several state-of-the-art methods are too strict for analyzing newborn EEG data, especially with frequency-tagging paradigms that are less affected by artifacts than ERP designs.</p>
    <p id="p0020">Here we propose NEAR (Newborn EEG Artifact Removal), a method for efficient artifact removal from raw newborn EEG data. Compared to existing methods for artifact removal, NEAR introduces two innovative features: First, a novel bad channel detection tool relying on the Local Outlier Factor (LOF), a robust, density-based local outlier detection algorithm (<xref rid="bib5" ref-type="bibr">Breunig et al., 2000</xref>); Second, a standard procedure for calibrating the two user-defined key parameters of ASR to newborn EEG data: ASR parameter <italic>k</italic> and ASR processing mode, which can be either correction or removal of the detected bad segments.</p>
    <p id="p0025">In this paper, we start by illustrating each processing step of NEAR within a full pre-processing pipeline transforming the raw data to artifact-free data ready to be analyzed. This pipeline includes a procedure for calibrating both the bad channel detection and the bad segment correction/removal parameters.</p>
    <p id="p0030">We then describe the three steps used to test NEAR performance:<list list-type="simple" id="li0005"><list-item id="u0005"><label>1)</label><p id="p0035">As a proof-of-concept, by using the simulation toolbox SEREEGA (<xref rid="bib20" ref-type="bibr">Krol et al., 2018</xref>), we tested NEAR on simulated, neurophysiologically plausible EEG data, including transient, high-amplitude artifacts predominantly found in EEG data of newborns and young infants;</p></list-item><list-item id="u0010"><label>2)</label><p id="p0040">We tested NEAR performance on newborn EEG data based on a frequency-tagging paradigm (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>), an experimental design consisting of a periodic temporal stimulation and measuring the stimulus-related response with the EEG oscillations at the stimulation frequency. This design is increasingly used with infants (<xref rid="bib17" ref-type="bibr">de Heering and Rossion, 2015</xref>, <xref rid="bib18" ref-type="bibr">Kabdebon et al., 2015</xref>) and newborns (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>) as it generally achieves a higher signal-to-noise ratio than Event-Related Potential (ERP) designs (<xref rid="bib28" ref-type="bibr">Norcia et al., 2015</xref>).</p></list-item><list-item id="u0015"><label>3)</label><p id="p0045">To test NEAR performance on an older population with an event-related design and with data recorded in another lab, we also evaluated NEAR on infant EEG data recorded on 9-months-old infants with an ERP paradigm (<xref rid="bib31" ref-type="bibr">Parise and Csibra, 2012</xref>).</p></list-item></list></p>
    <p id="p0050">We calibrated NEAR parameters on a training dataset for the tests on real data and validated NEAR on an independent dataset.</p>
    <p id="p0055">Validation also included comparison with state-of-the-art methods: EEGLAB’s <italic>clean_rawdata</italic> function (for bad channel detection only) and two automated artifact removal pipelines designed for developmental research, HAPPE (<xref rid="bib15" ref-type="bibr">Gabard-Durnam et al., 2018</xref>) and MADE (<xref rid="bib9" ref-type="bibr">Debnath et al., 2020</xref>).</p>
    <p id="p0060">NEAR scripts are made freely available for the users, along with an anonymized example dataset. A user-friendly step-by-step tutorial of the entire pipeline for the use of NEAR is provided in the <xref rid="sec0310" ref-type="sec">Appendix</xref>.</p>
  </sec>
  <sec id="sec0010">
    <label>2</label>
    <title>Materials and methods</title>
    <sec id="sec0015">
      <label>2.1</label>
      <title>Training and Test datasets</title>
      <sec id="sec0020">
        <label>2.1.1</label>
        <title>Newborn datasets</title>
        <p id="p0065">Newborn Training and Test datasets belong to two studies performed at the Neonatal Neuroimaging Unit (CIMeC, University of Trento) installed in the maternity ward of Rovereto Hospital “Santa Maria del Carmine” (Rovereto, Italy). Both studies were approved by the local ethical committee for clinical research (Comitato Etico per le Sperimentazioni Cliniche, Azienda Provinciale Servizi Sanitari, Province of Trento, Italy); parents were informed about the content and goal of the study and gave their written informed consent.</p>
        <p id="p0070">Both datasets were recorded by an EGI EEG system (GES400, Electrical Geodesic, Inc, Eugene, OR, USA) with 125 channels. Scalp voltages were referenced to the vertex, amplified and digitized at 250 Hz. Electrode impedances were kept below 100 kΩ. Newborns were tested in a calm, dimly illuminated space in the maternity ward, seated on the lap of a trained researcher in front of a 60 cm × 33.8 cm LCD screen (distance eyes-screen: about 30 cm) while wearing the EEG cap. Video recording from a hidden camera on the top of the screen provided online monitoring of the infant. The newborn’s parents, when present, were off the sight of the infant (separated by a curtain) and instructed to keep silent during the recordings. For both datasets, visual stimuli were presented dynamically with sinusoidal contrast modulation (the visibility of each stimulus gradually rises with respect to the gray background from 0% at the beginning of the cycle to 100% at mid-cycle, then gradually decreases to 0% towards the end of the cycle, see <xref rid="fig0005" ref-type="fig">Fig. 1</xref> in (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>), at a rate of 0.8 Hz (frequency-tagging paradigm). We used sinusoidal contrast modulation instead of squared on–off dynamics, both to minimize nonlinear effects in the brain frequency response (<xref rid="bib28" ref-type="bibr">Norcia et al., 2015</xref>) and to make the stimulation more pleasant to the babies (<xref rid="bib17" ref-type="bibr">de Heering and Rossion, 2015</xref>). The slow presentation rate (0.8 Hz) was chosen to ensure that newborns fully perceived the stimulus at each cycle of the periodic, peekaboo-like presentation.<fig id="fig0005"><label>Fig. 1</label><caption><p>Schematic representation of NEAR pipeline. Green boxes indicate the artifact removal part. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</p></caption><alt-text id="at0005">Fig. 1</alt-text><graphic xlink:href="gr1"/></fig></p>
        <p id="p0075">The Training Dataset is part of an ongoing study investigating the neural bases of number perception in newborns (Buiatti et al., in preparation). Visual stimuli consisted in a set of 4 or 12 coloured simple geometrical shapes, presented in blocks of 50 s or until the subject stopped attending them; shape, number and spatial arrangement were constant within each block and randomly changed between blocks. For the whole duration of the study, an auditory stimulation consisting of sequences of syllables was simultaneously presented (the response to the auditory stimulation will not be considered here). For the purpose of this paper, the Training Dataset includes all the subjects that attended at least 15 s of visual stimulation, independently whether they attended one or both number conditions (11 newborns, six males; mean age 40 ± 16 h; all were healthy [APGAR(1 min) ≥ 8, APGAR(5 min) = 10 for all subjects] and born full-term (gestation age, 39.9 ± 0.9 wk).</p>
        <p id="p0080">The Test Dataset belongs to a study investigating the cortical bases of facelike pattern processing (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>). Visual stimuli consisted of a white head-shaped form containing three black squares and differed only in the spatial configuration of the three squares to form the three stimuli (upright face, inverted face, and scrambled face). Stimuli were presented in blocks of 50 s or until the subject stopped attending them. Subjects were 10 healthy newborns (six males; mean age 60 ± 22 h). All were healthy [APGAR(1 min) ≥ 8, APGAR(5 min) = 10 for all subjects] and born full-term (gestation age, 39.7 ± 1.5 wk). Further details in (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>).</p>
      </sec>
      <sec id="sec0025">
        <label>2.1.2</label>
        <title>Infant datasets</title>
        <p id="p0085">Infant Training and Test datasets belong to a study investigating semantic understanding of common nouns in preverbal infants, performed at the Cognitive Development Center (CDC, Central European University) and whose results are published in (<xref rid="bib31" ref-type="bibr">Parise and Csibra, 2012</xref>). Ethical approvals were obtained from the ethics committee of the Central European University, Budapest; parents were informed about the content and goal of the study and gave their written informed consent. All infants were born full term (gestational age: 37–41 weeks) in the normal weight range (&gt; 2500 g).</p>
        <p id="p0090">Both the Training and the Test dataset included 14 healthy infants (Training: 6 females; mean age = 278 days, range = 266–285 days. Test: 5 females; mean age = 277 days, range = 269–286 days). Both datasets were acquired using an EGI amplifier (GES 300, Electrical Geodesic, Inc, Eugene, OR, USA) at a sampling rate of 500 Hz with a low-pass filter at 200 Hz. Continuous EEG was recorded by 125-channel Geodesic Sensor Nets referenced to the vertex. Infants were tested in a calm, dimly illuminated room in the CDC BabyLab, sitting on a high chair 70 cm in front of a 9-inch, 800 × 600, 100 Hz CRT monitor. The infants were video-recorded throughout the session from a hidden camera placed below the presentation monitor. The infant’s mother and an experimenter sat on chairs at either side of the infant.</p>
        <p id="p0095">For both datasets, each trial started with a live auditory stimulus delivered either by the experimenter (Training dataset) or by the infant’s mother (Test dataset) while a dynamic fixation stimulus (a colorful rectangle 343 ×363 pixels) was presented on top of an occluder. After the live auditory stimulus ended, the fixation stimulus stopped moving, and the display remained frozen for 600–800 ms. Then the fixation stimulus disappeared, and the occluder started to fall forward (a 90° rotation on the basis-hinge) revealing an object behind it (see <xref rid="fig0005" ref-type="fig">Fig. 1</xref> in <xref rid="bib31" ref-type="bibr">Parise and Csibra, 2012</xref>). The object, laying on a black background, was fully visible for 1000 ms before the occluder began to rise, hiding the object again. This was followed by an intertrial interval lasting 1100 to 1300 ms. The pictures of 15 different objects were used; their average size was 302.5 × 321.6 pixels. Trials were presented as long as the infants were attentive. The minimum inclusion criterion for the infants was at least 10 artifact-free trials in each of two experimental conditions. Further details in (<xref rid="bib31" ref-type="bibr">Parise and Csibra, 2012</xref>).</p>
      </sec>
    </sec>
    <sec id="sec0030">
      <label>2.2</label>
      <title>NEAR</title>
      <p id="p0100">NEAR preprocessing pipeline consists of a set of custom MATLAB scripts that can be executed as a fully automated EEG preprocessing within the EEGLAB (<xref rid="bib10" ref-type="bibr">Delorme and Makeig, 2004</xref>) framework. The core, innovative parts of the pipeline integrating EEGLAB scripts with original custom scripts consist in the artifact removal processing block: preliminary calibration of the bad channel detection threshold (LOF) and of the ASR cut-off parameter, bad channel detection using LOF algorithm and correction/removal of bad segments using ASR, both endowed with original visualization of the outcomes. In addition, we provided the scripts (based on EEGLAB functions) for a fully automated EEG processing from raw to clean data: importing and filtering raw data, interpolation of removed channels and re-referencing. Depending on the application requirements, these auxiliary steps can easily be modified. <xref rid="fig0005" ref-type="fig">Fig. 1</xref> shows the steps involved in the NEAR preprocessing pipeline. In the following sections, we describe each step in detail. A step-by-step tutorial including figures illustrating the main steps of NEAR artifact removal is presented in the <xref rid="sec0310" ref-type="sec">Appendix</xref> of this manuscript.</p>
      <sec id="sec0035">
        <label>2.2.1</label>
        <title>Import raw data</title>
        <p id="p0105">NEAR supports import functionality of four main formats: .mff, .raw, .set and .edf. We considered these formats because most developmental EEG raw data fall into one of these categories. For other formats, users can import the data with EEGLAB importing tools and use NEAR with the resulting EEGLAB format .set.</p>
      </sec>
      <sec id="sec0040">
        <label>2.2.2</label>
        <title>Band-pass filtering</title>
        <p id="p0110">The principle underlying band-pass filtering is that it is convenient for all the subsequent analyses to keep the frequency range of the signal that we want to analyze and discard the higher and lower frequencies, especially those that likely contain artifacts. At the higher end, it is beneficial to use a low-pass filter with a cut-off frequency below the power line (50 Hz or 60 Hz) to avoid line noise. At the lower end, i.e. below 1 Hz, the EEG signal typically contains eye movement, respiration and heart-beat artifacts. We, therefore, recommend using the highest high-pass filter cut-off frequency that preserves the signal of interest, paying attention to the width of the filter roll-off and, in the case of ERP designs, to the risk of introducing spurious effects (<xref rid="bib1" ref-type="bibr">Acunzo et al., 2012</xref>).</p>
        <p id="p0115">For the newborn data, we applied a low-pass FIR filter with a cut-off frequency at 40 Hz (by using EEGLAB’s default filter). Since for the analysis considered in this paper, we need to preserve the frequency components down to 0.5 Hz (see Section Neural measure: FTR), we used a non-causal high pass filter between 0.15 and 0.3 Hz and a stop-band attenuation of 80 dB.</p>
        <p id="p0120">The infant data were band-pass filtered between 0.3 and 30 Hz by using the default EEGLAB filter.</p>
      </sec>
      <sec id="sec0045">
        <label>2.2.3</label>
        <title>Data segmentation</title>
        <p id="p0125">For studies involving a stimulation paradigm, a key pre-processing step for identifying the relevant data in newborn/infant EEG recordings is to restrict data analysis to the intervals during which newborns/infants were effectively attending to the stimuli. We, therefore, recommend segmenting the data related to stimulation (i.e. segmenting stimulation periods for continuous stimulation or segmenting event-related epochs in case of event-related designs). Furthermore, for visual stimulations, we strongly recommend recording newborns/infants with a camera or an eye-tracker and light conditions guaranteeing clear monitoring of eye movements, and devoting careful attention to the identification of the effective looking times. This pre-processing step is crucial because not only it minimizes noise in the data, but it also removes data segments associated with unattended intervals that are usually very artifacted, potentially causing biases in the subsequent artifact analysis. For this reason, this step is performed before detecting bad channels and segments.</p>
        <p id="p0130">For resting-state EEG studies as well, our scripts can be adapted to retain good segments (or remove bad segments) of data known apriori. See <xref rid="sec0310" ref-type="sec">Appendix</xref>, Step 4 for details.</p>
      </sec>
      <sec id="sec0050">
        <label>2.2.4</label>
        <title>Bad channel detection</title>
        <p id="p0135">Bad channel detection in newborn/infant EEG data is a challenging step because, due to typically short preparation time devoted to lowering electrode impedance and frequent movement artifacts, electrode contact and stability is generally much lower than in adult data. In particular, after some preliminary tests on our data, we realized that the existing methods of bad channel detection are generally too strict for newborn EEG data. To overcome this issue, we implemented an algorithm in which the core step is a novel bad channel detection method based on LOF, a robust, data-driven outlier detector. The three steps of the algorithm are as follows:</p>
        <sec id="sec0055">
          <label>2.2.4.1</label>
          <title>Flat signals</title>
          <p id="p0140">Because of defective contact with the scalp or disconnection from the recording device, sometimes electrodes record a flat signal. To remove these channels, we adopted the function <italic>clean_flatlines</italic> from the EEGLAB <italic>clean_rawdata</italic> plugin (<ext-link ext-link-type="uri" xlink:href="https://github.com/sccn/clean_rawdata" id="ir0010">https://github.com/sccn/clean_rawdata</ext-link>). A channel is marked as flat by default if it records a flat signal for more than 5 consecutive seconds.</p>
        </sec>
        <sec id="sec0060">
          <label>2.2.4.2</label>
          <title>Local Outlier Factor (LOF)</title>
          <p id="p0145">Traditional outlier detection methods based on statistical measures such as mean, median, IQR or mean absolute deviation are too sensitive to outliers in the context of newborn EEG. To tackle this challenge, we introduce (to the authors’ knowledge, for the first time in the context of EEG data analysis) a robust unsupervised method called Local Outlier Factor (LOF), a density-based data-driven approach (<xref rid="bib5" ref-type="bibr">Breunig et al., 2000</xref>) to detect and remove bad channels. This technique operates in a multidimensional channel space where the “distance” between channels is computed as a robust distance estimation (Squared Euclidean distance (‘seuclidean’ in MATLAB)) between the activity vectors associated to each channel (i.e., the time series of each EEG signal) (not to be confused with the physical distance between the channels). Precisely, it assigns each channel a degree of “local outlierness” depending on how isolated the channel is with respect to its <italic>k</italic> neighbor channels (<xref rid="bib13" ref-type="bibr">Fix and Hodges, 1989</xref>).</p>
          <p id="p0150">To demonstrate the efficiency of the LOF algorithm, we show <xref rid="fig0010" ref-type="fig">Fig. 2</xref> that contains sample data clusters for illustration purposes. Suppose C<sub>1</sub> and C<sub>2</sub> are two main clusters and two additional objects o<sub>1</sub> and o<sub>2</sub>. As shown in <xref rid="fig0010" ref-type="fig">Fig. 2</xref>, both objects o<sub>1</sub> and o<sub>2</sub> are outliers for the respective clusters C<sub>1</sub> and C<sub>2</sub>. While most statistical-based and distance-based algorithms would correctly capture the o<sub>1</sub> as an outlier, LOF being a local density-based approach is capable of identifying objects like o<sub>2</sub> as well.<fig id="fig0010"><label>Fig. 2</label><caption><p>A sample dataset that contains two clusters of data (C<sub>1</sub> and C<sub>2</sub>) and two outlier objects (o<sub>1</sub> and o<sub>2</sub>).</p></caption><alt-text id="at0010">Fig. 2</alt-text><graphic xlink:href="gr2"/></fig></p>
          <p id="p0155">LOF algorithm is implemented as follows:</p>
          <p id="p0160">
            <list list-type="simple" id="li0010">
              <list-item id="u0020">
                <label>1)</label>
                <p id="p0165">For each channel <italic>p</italic>, LOF algorithm identifies <italic>k</italic> nearest neighbors based on a distance metric (by default, Squared Euclidean in NEAR pipeline).</p>
              </list-item>
              <list-item id="u0025">
                <label>2)</label>
                <p id="p0170">A reachability distance is computed between a channel <italic>p</italic> and each neighbor. For example, let us consider channel <italic>o</italic> that falls within the <italic>k</italic> neighbors of channel <italic>p</italic>. Then, the reachability distance between <italic>p</italic> and <italic>o</italic> is computed as follows:<disp-formula id="eqn0005"><mml:math id="M1" altimg="si0001.svg"><mml:mrow><mml:mi mathvariant="italic">reachability</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi mathvariant="italic">dist</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>o</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mo linebreak="goodbreak">=</mml:mo><mml:mi mathvariant="normal">max</mml:mi><mml:mrow><mml:mfenced open="{" close="}"><mml:mrow><mml:mtext>k-distance</mml:mtext><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mtext>o</mml:mtext></mml:mrow></mml:mfenced></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>d</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>where <italic>d(p,o)</italic> is the actual distance between two channel vectors.</p>
                <p id="p0175">Intuitively, if channel <italic>p</italic> is far away from <italic>o</italic>, then the reachability distance is simply their actual distance. Instead, if they are “sufficiently” close, the actual distance is replaced by the <italic>k-distance</italic> of channel <italic>o</italic>.</p>
              </list-item>
              <list-item id="u0030">
                <label>3)</label>
                <p id="p0180">Once, the reachability distances of each channel with respect to its neighbors is computed, the local reachability density (LRD) is determined as follows:<disp-formula id="eqn0010"><mml:math id="M2" altimg="si0002.svg"><mml:mrow><mml:mi>L</mml:mi><mml:mi>R</mml:mi><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced open="(" close=")"><mml:mi>p</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mfenced open="(" close=")"><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>p</mml:mi></mml:mfenced></mml:mrow></mml:munder><mml:mi mathvariant="italic">reachability</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:msub><mml:mi mathvariant="italic">dist</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mfenced open="|" close="|"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>p</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:mfrac></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
                <p id="p0185">To put it in words, LRD of the channel <italic>p</italic> is the inverse of the average reachability distance based on the <italic>k</italic>-nearest neighbors of <italic>p</italic>. Intuitively, channel <italic>p</italic> will have a lower LRD if it were an outlier (i.e., bad) channel because it is not easily reachable by its neighbors.</p>
              </list-item>
              <list-item id="u0035">
                <label>4)</label>
                <p id="p0190">Then, the local outlier factor (LOF) is computed as follows:<disp-formula id="eqn0015"><mml:math id="M3" altimg="si0003.svg"><mml:mrow><mml:msub><mml:mi mathvariant="italic">LOF</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>p</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>p</mml:mi></mml:mfenced></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:mi>L</mml:mi><mml:mi>R</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>o</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mi>R</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>p</mml:mi></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow><mml:mfenced open="|" close="|"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mfenced open="(" close=")"><mml:mi>p</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
                <p id="p0195">LOF of channel p is the average of the ratio of the LRD of p and those of <italic>p</italic>’s <italic>k-</italic>nearest neighbors. The lower <italic>p</italic>’s LRD is, and the higher the LRD of <italic>p</italic>’s <italic>k</italic>-nearest neighbors are, the higher is the LOF value of <italic>p</italic> (and therefore possibly an outlier). In other words, an outlier channel would display a lower LRD (therefore, larger in distance) compared to its neighbours (on average).</p>
              </list-item>
            </list>
          </p>
          <p id="p0200">As it can be noted, <italic>k</italic> is the hyperparameter in the computations of LOF. In this work, we used the Natural Neighbors algorithm (<xref rid="bib35" ref-type="bibr">Zhu et al., 2016</xref>) to compute a data-driven <italic>k</italic> value. We adapted the MATLAB-based implementation of the LOF algorithm (Density-based Outlier Detection Algorithms, <ext-link ext-link-type="uri" xlink:href="https://github.com/BlueBirdHouse/DDoutlier" id="ir0015">https://github.com/BlueBirdHouse/DDoutlier</ext-link>. Retrieved June 3, 2021.) in order to make it compatible with the EEGLAB data structure. Further, following a systematic study of the application of LOF to EEG data (<xref rid="bib21" ref-type="bibr">Kumaravel et al., 2021</xref>), we found the Standardized Euclidean distance metric (defined as ‘<italic>seuclidean’</italic> in MATLAB) outperforming the default Euclidean metric to compute the <italic>k</italic>-distance (<italic>knnsearch</italic> function, MATLAB).</p>
          <p id="p0205">Once LOF is computed for all the channels in a given dataset, it is important to set a threshold to separate the inlier channels from the outlier ones. In the original theory, if a channel exhibits an LOF of more than 1.5 (section 7.3 in <xref rid="bib5" ref-type="bibr">Breunig et al., 2000</xref>), it shall be considered as an outlier. For the application to EEG data that we are considering in this work, we proposed an adaptive approach by estimating the optimal threshold value for LOF from a Training Dataset on the basis of a standard scoring of the bad channels (See <xref rid="sec0215" ref-type="sec">Section 3.2.1</xref>).</p>
        </sec>
        <sec id="sec0065">
          <label>2.2.4.3</label>
          <title>Periodogram Analysis</title>
          <p id="p0210">To detect channels that predominantly recorded motion-related artifacts that manifest as an increase in power in Beta range, and a decrease in power in Delta and Alpha ranges (<xref rid="bib16" ref-type="bibr">Georgieva et al., 2020</xref>), we implemented a bad channel detection method based on a spectral measure (<italic>periodogram</italic> function, MATLAB). For the datasets analyzed in this paper, we noted that while this method captures the most significant bad channels, they were already detected by at least one of the previous two steps. Therefore, we kept this method as optional in NEAR’s bad channel detection plugin (see <xref rid="sec0310" ref-type="sec">Fig. A1 in Appendix</xref>).</p>
        </sec>
      </sec>
      <sec id="sec0070">
        <label>2.2.5</label>
        <title>Artifact removal using Artifact Subspace Reconstruction (ASR)</title>
        <p id="p0215">ASR is an automated artifact removal technique to detect/remove transient high-amplitude artifacts in continuous EEG data (<xref rid="bib19" ref-type="bibr">Kothe and Jung, 2016</xref>). It is available as an open-source EEGLAB plug-in function <italic>clean_rawdata</italic>. ASR has been tested extensively both on simulated data and on real EEG acquired using mobile setup from adult participants (<xref rid="bib21" ref-type="bibr">Kumaravel et al., 2021</xref>, <xref rid="bib26" ref-type="bibr">Mullen et al., 2015</xref>). Thanks to its efficient artifact removal, ASR is now considered as one of the default preprocessing algorithms within the EEGLAB framework. However, ASR has only been evaluated on adult EEG data thus far (<xref rid="bib4" ref-type="bibr">Blum et al., 2019</xref>, <xref rid="bib7" ref-type="bibr">Chang et al., 2020</xref>, <xref rid="bib26" ref-type="bibr">Mullen et al., 2015</xref>). For the first time, in this work, we evaluate ASR on noisier developmental EEG data and propose it as one of the core blocks in our pipeline. In addition, we propose a calibration procedure for adapting ASR algorithm to developmental data. ASR processes artifacts in three steps that are briefly described as follows (for more detailed technical documentation, please refer to <xref rid="bib19" ref-type="bibr">Kothe and Jung, 2016</xref>, and <xref rid="bib7" ref-type="bibr">Chang et al., 2020</xref>).</p>
        <sec id="sec0075">
          <label>2.2.5.1</label>
          <title>ASR algorithm</title>
          <p id="p0220">
            <list list-type="simple" id="li0015">
              <list-item id="u0040">
                <label>1)</label>
                <p id="p0225">First, ASR identifies cleaner data portions according to a predefined robust statistical distribution of EEG-like data.</p>
              </list-item>
              <list-item id="u0045">
                <label>2)</label>
                <p id="p0230">Then, ASR performs Principal Component Analysis (PCA) on the obtained cleaner segments of data to extract a rejection threshold, defined as follows:<disp-formula id="eqn0020"><mml:math id="M4" altimg="si0004.svg"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>*</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula>where <italic>i</italic> is the Principal Component (PC) index, <inline-formula><mml:math id="M5" altimg="si0005.svg"><mml:mi>μ</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="M6" altimg="si0006.svg"><mml:mi>σ</mml:mi></mml:math></inline-formula> are the corresponding mean and variance and <italic>k</italic> is the user-defined multiplicative SD factor (also known as ASR cut-off parameter).</p>
              </list-item>
              <list-item id="u0050">
                <label>3)</label>
                <p id="p0235">With the extracted threshold T, ASR identifies the artifacts subspace on the original data and reconstructs them based on the statistics obtained using the cleaner portions of the data.</p>
              </list-item>
            </list>
          </p>
          <p id="p0240">To calibrate ASR to newborn/infant EEG data, we analyzed two crucial user-defined parameters of ASR:</p>
        </sec>
        <sec id="sec0080">
          <label>2.2.5.2</label>
          <title>ASR cut-off parameter (<italic>k</italic>)</title>
          <p id="p0245">ASR defines an upper-bound threshold for a PC representing EEG-like components based on the mean and variance of PCs extracted from the cleaner portion of the data. Therefore, the components exceeding this threshold are most likely artifactual. The threshold is computed as defined in step 2) of the previous subsection. It can be observed that a lower <italic>k</italic> implies a lower threshold and therefore a strict artifact detection (i.e. more artifacts are detected); a higher <italic>k</italic> implies a looser cleaning of the data (i.e. less artifacts are detected). For adult EEG, the optimal <italic>k</italic> values lie in the range between 20 and 30 (<xref rid="bib7" ref-type="bibr">Chang et al., 2020</xref>). As mentioned before, to the best of our knowledge, the ASR parameter <italic>k</italic> has never been evaluated on developmental data.</p>
        </sec>
        <sec id="sec0085">
          <label>2.2.5.3</label>
          <title>Processing mode</title>
          <p id="p0250">Using the <italic>clean_rawdata</italic> plugin, ASR can be operated in two distinct modes: ASR Correction (hereafter, indicated as ASR<sub>C</sub> throughout this manuscript) in which the bad portions of the data are corrected to ‘EEG-like’ data, and ASR Removal (indicated as ASR<sub>R</sub>) in which the detected bad portions are removed from the data.</p>
          <p id="p0255">To calibrate these two parameters to newborn EEG data, a grid-search was performed on the Training Dataset (see Results).</p>
        </sec>
      </sec>
      <sec id="sec0090">
        <label>2.2.6</label>
        <title>Bad channel interpolation</title>
        <p id="p0260">The removed channels are interpolated from neighbouring channels by using EEGLAB’s function <italic>pop_interp</italic>. As suggested by EEGLAB developers, we recommend using <italic>spherical</italic> interpolation. However, using the NEAR pipeline, it is possible to use other supported techniques such as <italic>v4</italic>.</p>
      </sec>
      <sec id="sec0095">
        <label>2.2.7</label>
        <title>Re-referencing</title>
        <p id="p0265">For re-referencing, NEAR provides options for both average re-referencing (recommended and most commonly used in developmental EEG studies) and re-referencing to a particular channel (e.g., Cz). For this task, NEAR uses EEGLAB’s <italic>pop_reref</italic> function.</p>
      </sec>
      <sec id="sec0100">
        <label>2.2.8</label>
        <title>Calibration of artifact removal parameters</title>
        <p id="p0270">A key feature of NEAR is the preliminary calibration of its artifact removal parameters (LOF bad channel threshold, ASR parameter <italic>k</italic> and ASR processing mode). We provide scripts for this calibration and we highly recommend NEAR users to perform it on previously analyzed datasets from the same setup and experimental design as these parameters impact the quality of preprocessing (see <xref rid="sec0215" ref-type="sec">Section 3.2.1</xref> NEAR parameter calibration).</p>
      </sec>
      <sec id="sec0105">
        <label>2.2.9</label>
        <title>Other functionalities of NEAR</title>
        <p id="p0275">NEAR supports both single-subject processing and batch-processing (in case of multiple subjects). The relevant scripts for these functionalities can be found in the repository.</p>
        <p id="p0280">Finally, NEAR supports saving functionality and provides a comprehensive report that summarizes the preprocessing done on each of the input EEG files. This report might be useful to review the effects of preprocessing done on the raw input EEG.</p>
      </sec>
    </sec>
    <sec id="sec0110">
      <label>2.3</label>
      <title>Validation tools</title>
      <sec id="sec0115">
        <label>2.3.1</label>
        <title>Simulated data</title>
        <p id="p0285">Simulated data were generated with SEREEGA (<xref rid="bib20" ref-type="bibr">Krol et al., 2018</xref>), a Matlab-based toolbox that simulates EEG datasets consisting in neurophysiologically realistic continuous and/or event-related brain activity. We generated two datasets simulating newborn EEG data with a frequency-tagging stimulation as in (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>), and with an event-related stimulation similar to the one in (<xref rid="bib31" ref-type="bibr">Parise and Csibra, 2012</xref>), respectively. More specifically, we generated a 64-channels EEG dataset with the following components:</p>
        <sec id="sec0120">
          <label>2.3.1.1</label>
          <title>Component 1</title>
          <p id="p0290">A stimulus response, in the form of a sinusoidal Steady-State Visual Evoked Potential (SSVEP) (stimulation frequency = 0.8 Hz) for the frequency-tagging stimulation, and in the form of an event-related potential (latency=300 ms) for the event-related stimulation. Both responses were localized in two bilateral sources in the early visual cortex (MNI coordinates: [-8-76 10] and [8-76 10]).</p>
        </sec>
        <sec id="sec0125">
          <label>2.3.1.2</label>
          <title>Component 2</title>
          <p id="p0295">Event-unrelated ongoing EEG activity originating in 62 randomly selected cortical sources, plus in the 2 sources of the first component located in the early visual cortex. Such activity is generated as Brown noise (power spectrum increasing as <inline-formula><mml:math id="M7" altimg="si0007.svg"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="M8" altimg="si0008.svg"><mml:mrow><mml:mi>f</mml:mi><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), mimicking the one observed in newborns (<xref rid="bib14" ref-type="bibr">Fransson et al., 2013</xref>). Importantly, the signal-to-noise ratio between component 1 and component 2 was of the same order of magnitude as the one measured on real, artifact-free newborn EEG data. The first two components represent the <italic>ground truth</italic>.</p>
        </sec>
        <sec id="sec0130">
          <label>2.3.1.3</label>
          <title>Component 3</title>
          <p id="p0300">Artifacts in (5 randomly chosen) single channels consisting in intermittent potential shifts and flat signals mimicking electrical discontinuities, and low-frequency fluctuations (0–10 Hz) mimicking local bad contacts and movement artifacts;.</p>
        </sec>
        <sec id="sec0135">
          <label>2.3.1.4</label>
          <title>Component 4</title>
          <p id="p0305">Transient high-amplitude artifacts involving all the channels in the form of intermittent abrupt potential shifts or smoother Gaussian-like fluctuations, where both the amplitude at each channel and the duration varies randomly for each transient artifact (mean duration=1.6 s). Durations and amplitudes are of the same order of magnitude as those observed in real newborn data. This component mimics motion artifacts, which are very frequent in newborns.</p>
          <p id="p0310"><xref rid="fig0015" ref-type="fig">Fig. 3</xref> shows that this simulation well represents the main features of newborn EEG ongoing activity and artifacts. The scripts generating the simulation datasets are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/vpKumaravel/NEAR" id="ir0020">https://github.com/vpKumaravel/NEAR</ext-link> and the simulated datasets described in the Results are available here: <ext-link ext-link-type="uri" xlink:href="https://osf.io/79mzg/" id="ir0025">https://osf.io/79mzg/</ext-link>.<fig id="fig0015"><label>Fig. 3</label><caption><p>Top Panel: Newborn EEG data from (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>). Bottom Panel: Simulated EEG data (<italic>ground truth</italic> plus artifacts). Data are shown in butterfly mode (all electrode signals overlapped).</p></caption><alt-text id="at0015">Fig. 3</alt-text><graphic xlink:href="gr3"/></fig></p>
        </sec>
      </sec>
      <sec id="sec0140">
        <label>2.3.2</label>
        <title>Standard semi-automatic expert artifact removal procedure</title>
        <p id="p0315">As a reference for a standard semi-automatic artifact processing performed by experts (hereafter abbreviated as <italic>standard</italic>), we report the original procedures of artifact rejection performed in the original papers from which the newborn and infant datasets are taken (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>, <xref rid="bib31" ref-type="bibr">Parise and Csibra, 2012</xref>). Their bad channel scoring will be taken as the reference standard scoring both for the calibration and the validation of NEAR’s bad channel detection algorithm.</p>
        <sec id="sec0145">
          <label>2.3.2.1</label>
          <title>Newborns</title>
          <p id="p0320">Bad channels were detected on both datasets after band-pass-filtering and segmentation. Channels were marked as bad if they 1) had a standard deviation (computed on the whole data length by using the TrimOutlier toolbox: <ext-link ext-link-type="uri" xlink:href="https://sccn.ucsd.edu/wiki/TrimOutlier" id="ir0030">https://sccn.ucsd.edu/wiki/TrimOutlier</ext-link>) higher than 150 μV (to detect channels with high-amplitude artifacts) or lower than 1 μV (to detect flat or weakly responsive channels); 2) showed artifactual patterns after accurate visual inspection of the time course and power spectrum plots of suspicious channels and comparison with their neighbours.</p>
          <p id="p0325">Once bad channels were removed, identification of bad data segments was based on 1) the detection of amplitude jumps exceeding ± 200 μV; 2) the presence of paroxysmal artifacts after accurate visual inspection of the time course and topography of the EEG data.</p>
        </sec>
        <sec id="sec0150">
          <label>2.3.2.2</label>
          <title>Infants</title>
          <p id="p0330">Both infant datasets were automatically and manually edited. Automatic data rejection for body and eyes movements was performed whenever the average amplitude of a 80 ms sliding window exceeded ± 200 μV at any channel. A bad channel score was obtained by considering as bad the channels that were marked as rejected for at least 40% of the epochs. Bad channels were automatically interpolated in epochs in which ≤ 10% of the channels contained artifacts; epochs in which &gt; 10% of the channels contained artifacts were automatically rejected. Data was then manually edited by visual inspection of each individual epoch.</p>
        </sec>
      </sec>
      <sec id="sec0155">
        <label>2.3.3</label>
        <title>Other bad channel detection methods</title>
        <p id="p0335">To validate the performance of NEAR’s channel rejection tool against existing methods, we considered the following three state-of-the-art bad channel removal methods:<list list-type="simple" id="li0020"><list-item id="u0055"><label>1)</label><p id="p0340">The default EEGLAB function <italic>clean_rawdata</italic> (CRD, <ext-link ext-link-type="uri" xlink:href="https://github.com/sccn/clean_rawdata" id="ir0035">https://github.com/sccn/clean_rawdata</ext-link>) detects flat-line channels, channels contaminated with high-frequency noise and channels uncorrelated with its neighbors.</p></list-item><list-item id="u0060"><label>2)</label><p id="p0345">HAPPE (<xref rid="bib15" ref-type="bibr">Gabard-Durnam et al., 2018</xref>) uses EEGLAB <italic>pop_rejchan</italic> function to detect bad channels based on amplitude and spectral thresholding (z-score threshold=3 instead of EEGLAB default 5), running it twice to avoid residual bad channels.</p></list-item><list-item id="u0065"><label>3)</label><p id="p0350">FASTER (<xref rid="bib27" ref-type="bibr">Nolan et al., 2010</xref>) detects bad channels by computing the temporal correlation between channels, their variance, and a score based on the Hurst exponent.</p></list-item></list></p>
      </sec>
      <sec id="sec0160">
        <label>2.3.4</label>
        <title>Other automated pipelines for artifact removal in developmental EEG</title>
        <sec id="sec0165">
          <label>2.3.4.1</label>
          <title>MADE</title>
          <p id="p0355">The Maryland Analysis for Developmental EEG (MADE) is an automated standardized pre-processing pipeline specifically developed for developmental populations (<xref rid="bib9" ref-type="bibr">Debnath et al., 2020</xref>). MADE uses FASTER (<xref rid="bib27" ref-type="bibr">Nolan et al., 2010</xref>) to remove bad channels and ICA to correct data from artifacts. Bad ICs are classified automatically using Adjusted-ADJUST (<xref rid="bib22" ref-type="bibr">Leach et al., 2020</xref>), a modified version of ADJUST (<xref rid="bib24" ref-type="bibr">Mognon et al., 2011</xref>) developed specifically for infant data. Residual epochs contaminated by ocular artifacts are removed by employing a predefined amplitude threshold. MADE has been validated on infants starting from 1 year of age to childhood (3–6 years old) and late adolescence (16 years old).</p>
        </sec>
        <sec id="sec0170">
          <label>2.3.4.2</label>
          <title>HAPPE</title>
          <p id="p0360">The Harvard Automated Processing Pipeline for EEG (HAPPE) is a standardized automated pipeline for developmental EEG that contains high degree of artifact contamination and often short recording lengths (<xref rid="bib15" ref-type="bibr">Gabard-Durnam et al., 2018</xref>). HAPPE pipeline consists of 9 steps including bad channel rejection using pop_rejchan.m (<xref rid="bib11" ref-type="bibr">Delorme et al., 2015</xref>) and a wavelet-integrated ICA decomposition to recover artifactual segments. Bad ICs are classified automatically using MARA (<xref rid="bib34" ref-type="bibr">Winkler et al., 2014</xref>). HAPPE has been validated on resting-state developmental EEG data (age between 3 and 36 months). As HAPPE is not suitable for event-related designs (<xref rid="bib15" ref-type="bibr">Gabard-Durnam et al., 2018</xref>), we will compare it with NEAR on the continuous datasets only.</p>
        </sec>
      </sec>
      <sec id="sec0175">
        <label>2.3.5</label>
        <title>Neural measures for calibration and validation</title>
        <sec id="sec0180">
          <label>2.3.5.1</label>
          <title>Frequency-tagging designs: FTR</title>
          <p id="p0365">To compute a signal-to-noise ratio of the stimulus-related EEG response for both ASR parameter calibration and overall NEAR validation, we used the same measure defined in (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>). EEG data were segmented in partially overlapping epochs of 10 s (overlap varied between one-half and three-fourths of epoch length to adjust to the variable length of clean data segments). For each electrode, the Fourier transform <inline-formula><mml:math id="M9" altimg="si0009.svg"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> of each epoch was calculated using a fast Fourier transform algorithm (MATLAB function FFT). To avoid rejecting data segments shorter than 10 s but still potentially containing relevant neural signals, zero-padding to 10 s was applied before FFT for data segments between 5 s and 10 s. Data segments shorter than 5 s were discarded. The power spectrum was calculated from these Fourier coefficients as the average over epochs of the single-epoch power spectrum:<disp-formula id="eqn0025"><mml:math id="M10" altimg="si0010.svg"><mml:msub><mml:mrow><mml:mi mathvariant="italic">PS</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">〈</mml:mi><mml:mi>F</mml:mi><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mo>*</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mfenced open="(" close=")"><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mi mathvariant="normal">〉</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ep</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p>
          <p id="p0370">The Frequency-Tagged Response (FTR) at the tag frequency (0.8 Hz) was calculated as the ratio between the power spectrum at the tagged frequency and the background power, i.e. the value at 0.8 Hz of the power-law fit of the power spectrum estimated from the six neighboring frequency bins ( ± 0.3 Hz), where the power-law fit was computed by fitting a line to the logarithm of the power at the six neighboring frequency bins (MATLAB function <italic>Polyfit</italic>).</p>
        </sec>
        <sec id="sec0185">
          <label>2.3.5.2</label>
          <title>Event-related potential designs: SNR(ERP)</title>
          <p id="p0375">As a signal-to-noise ratio (SNR) of the ERP for ASR parameter calibration, we computed the one based on the Standardized Measurement Error (SME) recently proposed by (<xref rid="bib23" ref-type="bibr">Luck et al., 2021</xref>). The SME is an estimate of the noise in the measure of an ERP score (computed on a time window and a set of electrodes) based on its trial-by-trial variability:<disp-formula id="eqn0030"><mml:math id="M11" altimg="si0011.svg"><mml:mrow><mml:mi mathvariant="italic">SME</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">SD</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="italic">ERP</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">tr</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <italic>SD(ERP</italic><sub><italic>tr</italic></sub><italic>)</italic> denotes the standard deviation (across trials) of the single-trial ERP averaged over a time window and a set of electrodes, and <italic>N</italic> is the number of epochs. For each subject, the <italic>SNR(ERP)</italic> is the ratio between the ERP (averaged over trials) and the <italic>SME</italic>.</p>
        </sec>
      </sec>
    </sec>
  </sec>
  <sec id="sec0190">
    <label>3</label>
    <title>Results</title>
    <sec id="sec0195">
      <label>3.1</label>
      <title>Validation of NEAR on simulated data</title>
      <p id="p0380">We first validated NEAR on two synthetic EEG datasets simulating EEG signals that contain a SSVEP at 0.8 Hz like in (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>) (<italic>frequency-tagging dataset</italic>) and an ERP response similar to the one recorded in (<xref rid="bib31" ref-type="bibr">Parise and Csibra, 2012</xref>) (<italic>ERP dataset</italic>), respectively. Both datasets also include three key components of newborn/infant EEG data: Brown-noise-like background EEG, artifacts in single channels mimicking bad or unstable electrode contacts, transient high-amplitude fluctuations across most of the channels mimicking motion artifacts. Signal-to-noise ratios, data duration and proportion of artifacts are similar to the ones of real data (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>, <xref rid="bib31" ref-type="bibr">Parise and Csibra, 2012</xref>). Since it is difficult to incorporate enough variability to generate realistically different training and test datasets within the simulation framework, we set NEAR parameters to predefined values: LOF threshold= 2 and ASR parameter k = 20.</p>
      <sec id="sec0200">
        <label>3.1.1</label>
        <title>Frequency-tagging dataset</title>
        <p id="p0385">The ground truth data (SSVEP plus Brown-noise-like background EEG) shows a clear peak in the power spectrum at the stimulation frequency (0.8 Hz) that stands out of the background EEG power spectrum (blue line in <xref rid="fig0020" ref-type="fig">Fig. 4</xref>). The topography of the associated FTR at 0.8 Hz shows a neat posterior medial activation (<xref rid="fig0020" ref-type="fig">Fig. 4</xref>, bottom panel) fully compatible with the early visual cortex sources generated in the simulation (for details, see <xref rid="sec0115" ref-type="sec">Section 2.3.1</xref>). Artifacts cause a massive positive shift of the power spectrum at low frequencies, almost completely masking the SSVEP response peak (red line in <xref rid="fig0020" ref-type="fig">Fig. 4</xref>). Consequently, the topography of the FTR at 0.8 Hz does not show any clear posterior activation (<xref rid="fig0020" ref-type="fig">Fig. 4</xref>, bottom panel).<fig id="fig0020"><label>Fig. 4</label><caption><p>Top panel: Power spectrum of the simulated <italic>frequency-tagging dataset</italic> between 0.5 and 1.1 Hz, averaged over the electrodes showing the largest FTR amplitude in the <italic>ground truth</italic> data (PO3, POz, PO4). Bottom panel: Topography of the FTR (defined in <xref rid="sec0175" ref-type="sec">Section 2.3.5</xref>) at 0.8 Hz (the stimulation frequency). (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</p></caption><alt-text id="at0020">Fig. 4</alt-text><graphic xlink:href="gr4"/></fig></p>
        <p id="p0390">NEAR bad channel detection algorithm efficiently captured the simulated 5 bad channels (and no additional channels). ASR<sub>R</sub> was very efficient in removing all the transient artifacted segments from the data: the resulting peak at the stimulation frequency in the power spectrum almost overlaps with the one of the ground truth data (yellow line in <xref rid="fig0020" ref-type="fig">Fig. 4</xref>), and the topography of the FTR at 0.8 Hz is very similar to the one of the ground truth (<xref rid="fig0020" ref-type="fig">Fig. 4</xref>, bottom panel). ASR<sub>C</sub> performance was slightly inferior: while the power spectrum peak was recovered, its amplitude was lower than the ground truth, and the overall power spectrum at low frequencies was shifted to lower values (magenta line in <xref rid="fig0020" ref-type="fig">Fig. 4</xref>). This could depend on the fact that while all transient artifacts were correctly detected and removed by ASR, the correction also suppressed part of the SSVEP and of the background EEG. Nevertheless, the FTR topography was very similar to the ground truth one, even if with a slightly lower amplitude (<xref rid="fig0020" ref-type="fig">Fig. 4</xref>, bottom panel).</p>
        <p id="p0395">For comparison with state-of-the-art methods for artifact removal, we also tested the ICA-based artifact removal pipelines of MADE (<xref rid="bib9" ref-type="bibr">Debnath et al., 2020</xref>) and HAPPE (<xref rid="bib15" ref-type="bibr">Gabard-Durnam et al., 2018</xref>). MADE was not able to correct or remove almost any of the transient artifacts, as shown by its power spectrum (green line in <xref rid="fig0020" ref-type="fig">Fig. 4</xref>) and its FTR topography at 0.8 Hz (<xref rid="fig0020" ref-type="fig">Fig. 4</xref>, bottom panel), that are both very similar to the ones of the contaminated data. HAPPE was more successful: it corrected most of the low-frequency artifacts (cyan line in <xref rid="fig0020" ref-type="fig">Fig. 4</xref>) and FTR topography shows a posterior activation similar to that of the ground truth, although with a much lower amplitude than the ground truth and NEAR processing with ASR in both modalities (<xref rid="fig0020" ref-type="fig">Fig. 4</xref>, bottom panel). The rationale behind this reduction in overall amplitude might be due to the wavelet-based ICA thresholding, as also highlighted by the authors (<xref rid="bib15" ref-type="bibr">Gabard-Durnam et al., 2018</xref>).</p>
      </sec>
      <sec id="sec0205">
        <label>3.1.2</label>
        <title>ERP dataset</title>
        <p id="p0400">Results on the ERP dataset were very similar to the ones of the frequency-tagging dataset. The ground truth ERP mildly fluctuates around zero until 200 ms, then rises at 300 ms (the peak latency) and decreases again afterwards (blue line, top panel of <xref rid="fig0025" ref-type="fig">Fig. 5</xref>). Its topography at the peak latency is neatly posterior (bottom panel, <xref rid="fig0025" ref-type="fig">Fig. 5</xref>). Artifacts cause the ERP to spuriously rise even before the stimulus onset, and although the ERP peak is visible in the posterior electrodes (red line, top panel of <xref rid="fig0025" ref-type="fig">Fig. 5</xref>), the topography at the peak latency is very noisy (bottom panel, <xref rid="fig0025" ref-type="fig">Fig. 5</xref>).<fig id="fig0025"><label>Fig. 5</label><caption><p>Top panel: ERP of the simulated <italic>ERP dataset</italic> around the onset of the simulated stimulus, averaged over the electrodes showing the largest ERP amplitude in the <italic>ground truth</italic> data (PO3, POz, PO4). Bottom panel: Topography of the ERP averaged between 275 and 325 ms. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</p></caption><alt-text id="at0025">Fig. 5</alt-text><graphic xlink:href="gr5"/></fig></p>
        <p id="p0405">NEAR bad channel detection algorithm efficiently captured the simulated 5 bad channels (and no additional channels). ASR<sub>R</sub> was very efficient also in this case in removing all the transient artifacted segments from the data: the ERP peak at 300 ms almost overlaps with the one of the ground truth, even if the ERP profile is a bit noisier at higher latencies (yellow line, top panel of <xref rid="fig0025" ref-type="fig">Fig. 5</xref>), possibly an effect of the lower number of trials. The topography at 300 ms is very similar to the one of the ground truth (<xref rid="fig0025" ref-type="fig">Fig. 5</xref>, bottom panel). ASR<sub>C</sub> ERP peak has a lower amplitude than the ground truth but the ERP profile outside the peak is very clean with low fluctuations around zero (magenta line in <xref rid="fig0025" ref-type="fig">Fig. 5</xref>). The ERP topography at 300 ms is as neat as the one of the ground truth (<xref rid="fig0025" ref-type="fig">Fig. 5</xref>, bottom panel).</p>
        <p id="p0410">In comparison, also in this case, MADE could not remove the artifacts on the electrodes showing the posterior activation (green line, top panel of <xref rid="fig0025" ref-type="fig">Fig. 5</xref>). However, its topography at 300 ms shows moderate success in removing artifacts from other electrodes, though much less successfully than NEAR (<xref rid="fig0025" ref-type="fig">Fig. 5</xref>, bottom panel).</p>
      </sec>
    </sec>
    <sec id="sec0210">
      <label>3.2</label>
      <title>Validation of NEAR on newborn data</title>
      <sec id="sec0215">
        <label>3.2.1</label>
        <title>NEAR parameter calibration</title>
        <p id="p0415">We first calibrated the parameters of bad channel detection and ASR on the Training Dataset.</p>
        <sec id="sec0220">
          <label>3.2.1.1</label>
          <title>Calibration of LOF bad channel detection</title>
          <p id="p0420">NEAR’s bad channel detection algorithm (Flat lines + LOF) was tested by comparing it to the <italic>standard</italic> bad channel detection score implemented in the original paper ((<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>), see <xref rid="sec0140" ref-type="sec">Section 2.3.2</xref> for details) with the quality metric F1 Score defined as<disp-formula id="eqn0035"><mml:math id="M12" altimg="si0012.svg"><mml:mrow><mml:mi mathvariant="normal">F</mml:mi><mml:mn>1</mml:mn><mml:mspace width="0.25em"/><mml:mi>Score</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>*</mml:mo><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>*</mml:mo><mml:mi mathvariant="italic">TP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FP</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">FN</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where TP, FP and FN indicate the number of True Positives, False Positives and False Negatives respectively (<xref rid="bib8" ref-type="bibr">Dalianis, 2018</xref>).</p>
          <p id="p0425">By changing the LOF threshold from 1 to 10 in steps of 0.1, we found that the maximal F1 Score was achieved with a threshold of 2.5 (<xref rid="fig0030" ref-type="fig">Fig. 6</xref>). We therefore selected this value for performing bad channel detection on the newborn Test Dataset.<fig id="fig0030"><label>Fig. 6</label><caption><p>Optimal threshold tuning for LOF using F1 Score as evaluation metric on the newborn Training Dataset. The highest F1 Score is obtained with a threshold of 2.5.</p></caption><alt-text id="at0030">Fig. 6</alt-text><graphic xlink:href="gr6"/></fig></p>
        </sec>
        <sec id="sec0225">
          <label>3.2.1.2</label>
          <title>Calibration of ASR</title>
          <p id="p0430">To identify the optimal ASR parameter <italic>k</italic> and processing mode, we applied ASR on the newborn Training Dataset while systematically varying ASR parameter <italic>k</italic> between 1 and 100 for both modes of processing (bad segment removal (ASR<sub>R</sub>) and correction (ASR<sub>C</sub>)). As a validation measure, after a preliminary bad segment removal by visual inspection, we identified a broad occipital cluster of electrodes showing a visual response (<xref rid="fig0035" ref-type="fig">Fig. 7</xref>, top inset); we then computed the average visual response FTR (see Materials and Methods) in this predefined occipital cluster for each <italic>k</italic> and processing mode. Results show that both processing modes achieve a similar maximum value of FTR by (t(10) = −0.28, P = 0.78), but for different <italic>k</italic> values: <italic>k</italic> = 24 for removal mode, <italic>k</italic> = 13 for correction mode. One possible explanation of this difference is that while for <italic>k</italic> between 20 and 30 the correction is not very effective, for <italic>k</italic> &lt; 15 the removal mode rejects too many segments, providing too few samples for a robust computation of FTR. Since the two processing modes provide equivalent results for their optimal <italic>k,</italic> we will test both modes in the validation phase.<fig id="fig0035"><label>Fig. 7</label><caption><p>A grid-search analysis to find the best ASR parameter settings on the newborn Training Dataset: Average visual response (FTR) on a predefined occipital cluster of electrodes (topography in top inset) as a function of ASR Parameter <italic>k</italic> and Processing Mode, computed on the Training Dataset (n = 11). The mean FTR is maximum at <italic>k</italic> = 13 for ASR Correction (ASR<sub>C</sub>) and <italic>k</italic> = 24 for ASR Removal (ASR<sub>R</sub>). (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</p></caption><alt-text id="at0035">Fig. 7</alt-text><graphic xlink:href="gr7"/></fig></p>
        </sec>
      </sec>
      <sec id="sec0230">
        <label>3.2.2</label>
        <title>NEAR validation</title>
        <sec id="sec0235">
          <label>3.2.2.1</label>
          <title>NEAR bad channel detection</title>
          <p id="p0435">Once the optimal parameters were identified by calibration, we used them to validate NEAR artifact removal on the newborn Test Dataset. First, we validated NEAR’s bad channel detection method by evaluating its performance in matching the bad channel scoring implemented in the original study (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>), here considered as the ground truth (see <xref rid="sec0140" ref-type="sec">Section 2.3.2</xref> for details). We also compared its performance with one of the three state-of-the-art methods: the default EEGLAB function <italic>clean_rawdata</italic> (CRD) and the bad channel detection methods used by two popular pipelines specifically implemented for infant EEG data, HAPPE (<xref rid="bib15" ref-type="bibr">Gabard-Durnam et al., 2018</xref>) and MADE (<xref rid="bib9" ref-type="bibr">Debnath et al., 2020</xref>) (the latter using FASTER bad channel detection tool (<xref rid="bib27" ref-type="bibr">Nolan et al., 2010</xref>)). As shown in <xref rid="tbl0005" ref-type="table">Table 1</xref>, the number of bad channels in the ground truth widely varies between subjects, from a minimum of zero to a maximum of 14. Results (<xref rid="tbl0005" ref-type="table">Table 1</xref>) show that NEAR is the tool that best captures this high variability (F1 score = 0.81). All the other methods tend to mark more bad channels (therefore, more false positives with respect to the ground truth).<table-wrap position="float" id="tbl0005"><label>Table 1</label><caption><p>Performance of NEAR Bad Channel Detection tool compared to other methods (<italic>standard</italic> (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>), <italic>clean_rawdata</italic> (CRD), HAPPE and FASTER). Top panel: Total number of detected channels for each subject. Bottom panel: Comparison of classification performance in matching standard bad channel detection (TP, FN, FP, TN, ACC indicate the number of True Positives, False Negatives, False Positives, True Negatives and Accuracy, respectively). NEAR shows the closest match with the <italic>standard</italic> bad channel detection score compared to other methods.</p></caption><alt-text id="at0050">Table 1</alt-text><table frame="hsides" rules="groups"><thead><tr><th colspan="11" align="center">Bad Channel Detection<hr/></th></tr><tr><th>Methods/Subjects</th><th align="center">S1</th><th align="center">S2</th><th align="center">S3</th><th align="center">S4</th><th align="center">S5</th><th align="center">S6</th><th align="center">S7</th><th align="center">S8</th><th align="center">S9</th><th align="center">S10</th></tr></thead><tbody><tr><td><italic><bold>Standard</bold></italic></td><td align="center">1</td><td align="center">2</td><td align="center">3</td><td align="center">0</td><td align="center">1</td><td align="center">7</td><td align="center">2</td><td align="center">14</td><td align="center">7</td><td align="center">13</td></tr><tr><td><bold>CRD</bold></td><td align="center">5</td><td align="center">8</td><td align="center">8</td><td align="center">6</td><td align="center">0</td><td align="center">13</td><td align="center">6</td><td align="center">22</td><td align="center">9</td><td align="center">9</td></tr><tr><td><bold>HAPPE</bold></td><td align="center">9</td><td align="center">8</td><td align="center">15</td><td align="center">8</td><td align="center">18</td><td align="center">13</td><td align="center">6</td><td align="center">2</td><td align="center">6</td><td align="center">6</td></tr><tr><td><bold>FASTER</bold></td><td align="center">4</td><td align="center">4</td><td align="center">8</td><td align="center">4</td><td align="center">7</td><td align="center">3</td><td align="center">3</td><td align="center">10</td><td align="center">6</td><td align="center">7</td></tr><tr><td><bold>NEAR</bold></td><td align="center">2</td><td align="center">2</td><td align="center">3</td><td align="center">1</td><td align="center">1</td><td align="center">5</td><td align="center">1</td><td align="center">23</td><td align="center">8</td><td align="center">14</td></tr><tr><td colspan="11" align="center"><bold>Classification Metrics</bold></td></tr><tr><td><bold>Methods</bold></td><td align="center"><bold>TP</bold></td><td align="center"><bold>FN</bold></td><td align="center"><bold>FP</bold></td><td align="center"><bold>TN</bold></td><td align="center"><bold>ACC</bold></td><td colspan="5" align="center"><bold>F1-Score</bold></td></tr><tr><td><bold>CRD</bold></td><td align="center">3.3</td><td align="center">1.7</td><td align="center">5.6</td><td align="center">113.4</td><td align="center">94.11</td><td colspan="5" align="center">0.47</td></tr><tr><td><bold>HAPPE</bold></td><td align="center">2.3</td><td align="center">2.7</td><td align="center">6.8</td><td align="center">112.2</td><td align="center">92.34</td><td colspan="5" align="center">0.33</td></tr><tr><td><bold>FASTER</bold></td><td align="center">2.6</td><td align="center">2.4</td><td align="center">3</td><td align="center">116</td><td align="center">97.58</td><td colspan="5" align="center">0.40</td></tr><tr><td><bold>NEAR</bold></td><td align="center">4.5</td><td align="center">0.5</td><td align="center">1.5</td><td align="center">117.5</td><td align="center">98.38</td><td colspan="5" align="center">0.81</td></tr></tbody></table></table-wrap></p>
        </sec>
        <sec id="sec0240">
          <label>3.2.2.2</label>
          <title>Overall NEAR validation</title>
          <p id="p0440">Then we validated the overall performance of NEAR artifact removal by testing whether the EEG data cleaned by NEAR showed the statistical significance of the two main neural responses described in (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>): 1) The EEG response to the overall visual stimulation, by comparing the power at the tag frequency with the background power estimated at the same frequency in the occipital cluster of electrodes identified in (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>)(<xref rid="fig0010" ref-type="fig">Fig. 2</xref>A therein); 2) The facelike pattern response, comparing the FTR to facelike stimuli with the one to inverted facelike patterns in the posterior cluster of electrodes illustrated in (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>) (<xref rid="fig0015" ref-type="fig">Fig. 3</xref>A therein). We also compared NEAR performance with the one obtained using a standard artifact processing as in the original paper (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>) and with the two artifact removal pipelines for developmental data<xref rid="fn1" ref-type="fn">1</xref> (MADE (<xref rid="bib9" ref-type="bibr">Debnath et al., 2020</xref>) and HAPPE (<xref rid="bib15" ref-type="bibr">Gabard-Durnam et al., 2018</xref>)).</p>
          <p id="p0445">Removing artifacts with ASR (both processing modes) on the Test Dataset resulted in rejecting one subject because of too short clean segments for computing FTR. To ensure a fair comparison, we restricted the validation results to the remaining 9 subjects for all the considered methods.</p>
          <p id="p0450">For the visual response, standard processing resulted in a significant effect even with one less subject (t(8) = 3.03, P = 0.016) (<xref rid="fig0040" ref-type="fig">Fig. 8</xref>, first row, left-hand panel). Compared to standard processing, ASR<sub>R</sub> resulted in a somewhat lower power peak at the tag frequency accompanied by a similar decrease in the background power (<xref rid="fig0040" ref-type="fig">Fig. 8</xref>, second row, left-hand panel), likely resulting from a more efficient noise reduction together with a slight power reduction. This minor difference impacted equivalently on the numerator and denominator of the FTR, obtaining a significant effect (t(8) = 3.04; P = 0.016) equivalent to the standard processing, and a response which is statistically indistinguishable from the standard mode (paired t-test between standard and ASR<sub>R</sub> of the difference between power and background at the tag frequency across subjects: t(8) = 0.034, P = 0.97). The power spectrum resulting from ASR<sub>C</sub> is further reduced, in particular at the tag frequency (<xref rid="fig0040" ref-type="fig">Fig. 8</xref>, third row, left-hand panel), probably due to a slightly sub-optimal reconstruction of the steady-state response in bad segments. Nonetheless, the statistical effect is also significant (t(8) = 2.60, P = 0.032) and the response is only marginally lower than the standard mode (paired t-test as above: t(8) = 1.91, P = 0.093). On the contrary, the overall profile of the power spectrum resulting from MADE processing is notably higher than the one from the standard mode and with a much wider variance at low frequencies (&lt;0.8 Hz), likely the effect of residual low-frequency artifacts (<xref rid="fig0040" ref-type="fig">Fig. 8</xref>, fourth row, left-hand panel). Still, the visual response is statistically significant also in this case (t(8) = 2.47, P = 0.039), though marginally lower than the one obtained with ASR<sub>R</sub> (paired t-test t(8) = 1.95, P = 0.086) and with standard correction (paired t-test t(8) = 2.14, P = 0.065). HAPPE (<xref rid="fig0040" ref-type="fig">Fig. 8</xref>, fifth row, left-hand panel) also recovers a statistically significant peak of the visual response (t(8) = 2.58, P = 0.033) but it is significantly lower than for ASR<sub>R</sub> (t(8) = 3.04, P = 0.016), ASR<sub>C</sub> (t(8) = 2.59, P = 0.032) and standard processing (t(8) = 3.01, P = 0.016).<fig id="fig0040"><label>Fig. 8</label><caption><p>Performance of NEAR in obtaining statistically significant neural responses from the raw newborn Test Dataset. Each row corresponds to an artifact removal method: <italic>Standard</italic> processing (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>), NEAR using ASR<sub>R</sub>, NEAR using ASR<sub>C</sub>, MADE and HAPPE, respectively. Left-hand column: Power spectrum elicited by the overall visual stimulation. Shaded contour indicates the s.e.m. across subjects. The spectral peak at the tag frequency is statistically significant for all the methods, but NEAR using ASR<sub>R</sub> obtains the highest t-value. Mid column: Power spectrum associated with upright (red line) and inverted (blue line) facelike stimuli. While the facelike effect is statistically significant for both NEAR processing modes, it is only marginally significant after MADE processing and not significant after HAPPE processing. Right-hand column: Single-subject FTR for upright (red bars) and inverted (blue bars) facelike images. The facelike effect is present in all subjects for NEAR processing, but not for MADE and HAPPE processing. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</p></caption><alt-text id="at0040">Fig. 8</alt-text><graphic xlink:href="gr8"/></fig></p>
          <p id="p0455">Validation on the facelike pattern response shows similar results. NEAR with ASR<sub>R</sub> processing recovered a statistically significant effect (t(8) = 2.79, P = 0.023) and the facelike response was statistically equivalent to that obtained with the <italic>standard</italic> processing (paired t-test between standard and ASR<sub>R</sub> of the difference between FTR for facelike and inverted facelike patterns across subjects: t(8) = −0.38, P = 0.71) (<xref rid="fig0040" ref-type="fig">Fig. 8</xref>, first and second row, middle panel). Similar results are obtained with ASR<sub>C</sub>: a significant facelike effect (t(8) = 2.69, P = 0.027), and no significant difference with standard mode (t(8) = 1.67, P = 0.13) (<xref rid="fig0040" ref-type="fig">Fig. 8</xref>, third row, middle panel). However, MADE processing resulted in a shallower spectral peak (<xref rid="fig0040" ref-type="fig">Fig. 8</xref>, fourth row, middle panel) and recovered only a marginally significant facelike effect (t(8) = 2.02, P = 0.078), showing again a marginally significant difference compared to both ASR<sub>R</sub> (t(8) = 1.96, P = 0.085) and standard processing (t(8) = 1.88, P = 0.097). HAPPE processing resulted in an even shallower peak (<xref rid="fig0040" ref-type="fig">Fig. 8</xref>, fifth row, middle panel), failing to report a significant facelike effect (t(8) = 1.21, P = 0.26), although in this case the difference with NEAR methods is not significant (vs ASR<sub>R</sub>: t(8) = 1.59, P = 0.15; vs ASR<sub>C</sub>: t(8) = 1.35, P = 0.21), nor the one with standard <italic>standard</italic> processing (t(8) = 1.98, P = 0.08). These results are reflected in the single-subject responses (<xref rid="fig0040" ref-type="fig">Fig. 8</xref>, right-hand column panel): While NEAR with both ASR<sub>R</sub> and ASR<sub>C</sub> recovered a preference for facelike patterns for all the subjects as with standard processing, two subjects following MADE and HAPPE processing showed an inverted effect.</p>
        </sec>
      </sec>
    </sec>
    <sec id="sec0245">
      <label>3.3</label>
      <title>Validation of NEAR on infant data</title>
      <p id="p0460">Although NEAR has been developed to remove artifacts in continuous newborn EEG data, here we show that NEAR is also efficient in removing artifacts from data of older infants and with event-related designs (thereby, proving its extensibility) by applying it to a 9-months-old EEG dataset recorded with an ERP paradigm (<xref rid="bib31" ref-type="bibr">Parise and Csibra, 2012</xref>).</p>
      <sec id="sec0250">
        <label>3.3.1</label>
        <title>NEAR parameter calibration</title>
        <p id="p0465">Following the same procedure performed with newborns (<xref rid="sec0215" ref-type="sec">Section 3.2.1</xref>), we calibrated LOF threshold for bad channel detection on the infant Training Dataset. By using F1 Score as the quality metric, the optimal LOF threshold obtained is 2, which is 0.5 lower than the one obtained on newborn data.</p>
        <p id="p0470">Likewise, the calibration of the ASR parameter <italic>k</italic> yielded an optimal value of <italic>k</italic> = 21 for ASR<sub>R</sub> and <italic>k</italic> = 3 for ASR<sub>C</sub>. Compared to what was obtained on newborns, this parameter is much lower for ASR<sub>C</sub> than for ASR<sub>R</sub>.</p>
      </sec>
      <sec id="sec0255">
        <label>3.3.2</label>
        <title>NEAR validation</title>
        <sec id="sec0260">
          <label>3.3.2.1</label>
          <title>NEAR bad channel detection</title>
          <p id="p0475">As done with the newborns data, we validated NEAR’s bad channel detection method by evaluating its performance to match standard bad channel detection on the infant Test Dataset. For comparison, we also tested the performance of the three state-of-the-art methods: CRD, HAPPE and FASTER. As for newborns, NEAR’s bad channel detection algorithm yielded the highest match with standard scoring: NEAR F1 = 0.69, HAPPE F1 = 0.42, FASTER F1 = 0.33, CRD F1 = 0.33.</p>
        </sec>
        <sec id="sec0265">
          <label>3.3.2.2</label>
          <title>Overall NEAR validation</title>
          <p id="p0480">Then, as for newborns, we validated the overall performance of NEAR pre-processing by direct comparison of the statistical significance of the main effect obtained by manual pre-processing in the original work (<xref rid="bib31" ref-type="bibr">Parise and Csibra, 2012</xref>): a N400 differential response between incongruous and congruous conditions higher on the right region-of-interest than on the left one (where the regions of interest were identified by the electrodes between C3 and P3 and between C4 and P4, over the left and right hemisphere, respectively) (<xref rid="fig0045" ref-type="fig">Fig. 9</xref>).<fig id="fig0045"><label>Fig. 9</label><caption><p>Event-related potential (ERP) results for each of the processing modes: <italic>Standard</italic> processing (<xref rid="bib31" ref-type="bibr">Parise and Csibra, 2012</xref>), NEAR using ASR<sub>R</sub>, NEAR using ASR<sub>C</sub> and MADE, respectively. The figure shows grand-average waveforms on congruous and incongruous trials in left (left-hand panels) and right (right-hand panels) regions of interest (marked by black points on the scalp maps). The gray shading indicates the time window of the infant N400 (500–650 ms), and the vertical line marks the time at which the object in each trial appeared from behind an occluder. The scalp maps (middle panels) depict the spatial distribution of the difference in ERP amplitude between incongruous and congruous trials in the given time window. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)</p></caption><alt-text id="at0045">Fig. 9</alt-text><graphic xlink:href="gr9"/></fig></p>
          <p id="p0485">We also compared NEAR’s performance with the state-of-the-art artifact removal pipeline for developmental data MADE (<xref rid="bib9" ref-type="bibr">Debnath et al., 2020</xref>).</p>
          <p id="p0490">Results show that the only method that recovered a significant ANOVA with factors condition and hemisphere is ASR<sub>R</sub> (F(1,13)= 5.13, P = 0.041), while no significant effect is observed for ASR<sub>C</sub> (F(1,13)= 1.68, P = 0.22), nor for MADE (F(1,13)= 2.90, P = 0.11). More specifically, NEAR using ASR<sub>R</sub> yielded a clear congruency effect on the right hemisphere that was absent on the left hemisphere, similarly to <italic>standard</italic> processing (<xref rid="fig0045" ref-type="fig">Fig. 9</xref>, first two rows). NEAR using ASR<sub>C</sub> resulted in similar but shallower effects compared to ASR<sub>R</sub> (<xref rid="fig0045" ref-type="fig">Fig. 9</xref>, third row). MADE also exhibited a congruency difference between the hemisphere in the same direction, but with the congruous condition higher than for the other methods (<xref rid="fig0045" ref-type="fig">Fig. 9</xref>, fourth row). However, no significant difference was found between the three methods on the size of the effect (paired t-test between the ERP difference between hemispheres of the difference between conditions of ASR<sub>R</sub> vs MADE: t(13) = 0.01, P = 0.99; ASR<sub>C</sub> vs MADE: t(13) = −1.00, P = 0.33; ASR<sub>R</sub> vs ASR<sub>C</sub>: t(13) = 1.70, P = 0.11).</p>
        </sec>
      </sec>
    </sec>
  </sec>
  <sec id="sec0270">
    <label>4</label>
    <title>Discussion</title>
    <p id="p0495">This paper presented NEAR, a pipeline that transforms artifacted raw developmental EEG data into clean data ready for downstream analysis. We demonstrated that NEAR’s novel artifact removal procedure efficiently removes artifacts both from newborn and infant EEG data (high sensitivity), while preserving the EEG signal of neural origin (high specificity). NEAR will hopefully contribute to establish a more objective and reproducible preprocessing procedure within the developmental EEG community, a much-needed improvement considering the negative consequences of the variability of EEG data editing practices (<xref rid="bib25" ref-type="bibr">Monroy et al., 2021</xref>). Hereafter we comment on some key aspects of NEAR in the general context of EEG artifact removal.</p>
    <sec id="sec0275">
      <label>4.1</label>
      <title>An artifact removal method for non-stereotyped artifacts</title>
      <p id="p0500">The most problematic and predominant artifacts in newborn EEG data are non-stereotyped transient high-amplitude fluctuations involving variable sets of channels. By specifically simulating these artifacts, we showed that ASR processing included in NEAR is very efficient in detecting and removing them. On the other hand, ICA-based methods as MADE (<xref rid="bib9" ref-type="bibr">Debnath et al., 2020</xref>) and (to a lesser extent) HAPPE (<xref rid="bib15" ref-type="bibr">Gabard-Durnam et al., 2018</xref>) failed in processing these artifacts, most probably because they are developed to detect mainly the stereotyped ones. Notably, both MADE and HAPPE are more successful on newborn EEG data than on simulated data, possibly because real newborn EEG artifacts are more stereotyped (i.e. their spatial distribution and temporal profile are partly correlated across occurrences) than simulated ones, which are generated by random shuffling of the artifact topographical distribution. As discussed more extensively below, a combination of detection methods for non-stereotyped and stereotyped artifacts might be the solution to deal with the wide range of EEG artifacts, especially in developmental data.</p>
    </sec>
    <sec id="sec0280">
      <label>4.2</label>
      <title>ASR parameter calibration</title>
      <p id="p0505">One core tool used by NEAR is ASR (<xref rid="bib19" ref-type="bibr">Kothe and Jung, 2016</xref>), an efficient algorithm that nevertheless depends on some user-defined parameters. The selection of these parameters is not univocal: the most systematic investigation on this issue (<xref rid="bib7" ref-type="bibr">Chang et al., 2020</xref>) proposes that the optimal value of the ASR <italic>k</italic> parameter for adults lies “between 20 and 30", implicitly suggesting that it may be variable. Moreover, while ASR default processing mode is to correct the data from artifacts (a choice driven by the original aim of providing an efficient algorithm for real-time applications), the main developers of the EEGLAB software suggest removing the artifacted segments identified by ASR because the effects of ASR correction on the data “are not clearly understood” (<ext-link ext-link-type="uri" xlink:href="https://eeglab.org/tutorials/06_RejectArtifacts/cleanrawdata.html" id="ir0040">https://eeglab.org/tutorials/06_RejectArtifacts/cleanrawdata.html</ext-link>, Retrieved June 7, 2021). Our study confirms that ASR performance significantly depends on the choice of both ASR Parameter <italic>k</italic> and processing mode (<xref rid="fig0035" ref-type="fig">Fig. 7</xref>). The quality of developmental EEG data may vary substantially between different EEG setups, and different data analyses may require different thresholds. Therefore, we propose an adaptive approach to ASR: run ASR on a dataset previously collected with the same EEG setup and analyzed with the same analysis chosen for the current data and find the <italic>k</italic> and processing mode that best recover the EEG effects observed on that dataset. We provide a script for this calibration procedure and we recommend NEAR users to perform it before applying NEAR to newly recorded data. Once these parameters are identified, validation shown in this paper suggests that NEAR might be safely used in automatic mode. If a training dataset is not available, we recommend tuning NEAR parameters on at least a few subjects by measuring a well-known sensory response for both processing modes and <italic>k</italic> between 10 and 30. In any case, we strongly recommend that users keep monitoring the efficiency of NEAR (an easy task provided by the visualization tools along NEAR’s pipeline and the report file), as unpredicted single-subject variations are always possible - automatic does not mean magic!</p>
    </sec>
    <sec id="sec0285">
      <label>4.3</label>
      <title>Artifact removal vs correction</title>
      <p id="p0510">Testing ASR on simulated data showed that removal mode is slightly more efficient than correction mode in cleaning the data from the effect of artifacts; results from the simulation suggest that while correction efficiently suppresses the artifacts, it also severely attenuates the underlying neural activity. This effect was consistently observed in the application of NEAR on both the newborn and infant data. This observation, together with the fact that the effects of ASR correction on the data are not fully understood yet, lead us to adopt EEGLAB recommendation to set the removal mode by default for off-line analysis, unless the performance of the correction mode on some training datasets shows significantly better results. In both processing modes, we recommend users to notice the amount of data being rejected (in case of ASR<sub>R</sub>), or modified (in case of ASR<sub>C</sub>) and the mean reduction of RMS variance in the processed signal. These values can be found in our report files. In particular for ASR<sub>C</sub>, we recommend users to customize these values to set inclusion criteria for the subjects into the group-level analysis to avoid the risk of mostly relying on the reconstruction of heavily artefacted data.</p>
    </sec>
    <sec id="sec0290">
      <label>4.4</label>
      <title>Using NEAR on other experimental designs</title>
      <p id="p0515">NEAR has been trained and validated on a frequency-tagging paradigm by using a measure of the SSVEP and on an event-related design by using an ERP measure. The adaptive approach of NEAR provides a straightforward strategy to tune NEAR parameters to data recorded from other experimental designs that include event-related measures like time-frequency analysis or resting-state measures like (de)synchronization in specific frequency ranges or connectivity measures.</p>
    </sec>
    <sec id="sec0295">
      <label>4.5</label>
      <title>Combining NEAR with ICA for developmental EEG artifact removal</title>
      <p id="p0520">In comparison with NEAR, the pipeline for artifact removal of developmental data MADE performed moderately worse on newborn and infant data, mostly because it was not equally efficient in removing low-frequency artifacts. We see two possible reasons for this difference: 1) MADE’s bad channel and bad segment identification tools were not calibrated to newborn EEG data; 2) As mentioned above, the benefit of removing artifacts by ICA is limited by the fact that most artifacts in newborn EEG data are non-stereotyped, therefore not easily captured by ICA. Nonetheless, ICA (and in particular Adjusted-ADJUST (<xref rid="bib22" ref-type="bibr">Leach et al., 2020</xref>), the IC classifier developed for infant data and included in MADE) may be beneficial as a further processing step after NEAR because it could correct the data from residual stereotyped artifacts without any further data rejection. However, one issue that might be problematic for an efficient ICA decomposition of developmental EEG data with high-density systems is the very limited duration of the clean data segments. Rather than reducing the number of electrodes as in (<xref rid="bib22" ref-type="bibr">Leach et al., 2020</xref>) (which would drastically decrease EEG spatial resolution, preventing a potential source reconstruction (<xref rid="bib29" ref-type="bibr">Odabaee et al., 2014</xref>)), a possible solution would be to use PCA for dimensionality reduction. However, the application of PCA on EEG data has significant limitations (<xref rid="bib2" ref-type="bibr">Artoni et al., 2018</xref>); therefore, investigations on alternative methods to run ICA on high-density EEG data of short duration would be very useful.</p>
    </sec>
  </sec>
  <sec id="sec0300">
    <title>NEAR availability</title>
    <p id="p0525">NEAR is publicly available as open-source software at <ext-link ext-link-type="uri" xlink:href="https://github.com/vpKumaravel/NEAR" id="ir0045">https://github.com/vpKumaravel/NEAR</ext-link> under GNU General Public License. An example anonymized dataset taken from the Test Dataset analyzed in the paper (data from (<xref rid="bib6" ref-type="bibr">Buiatti et al., 2019</xref>)) has been deposited in the Open Science Framework and is freely available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/79mzg/" id="ir0050">https://osf.io/79mzg/</ext-link>. A step-by-step tutorial for the use of NEAR is included in the <xref rid="sec0310" ref-type="sec">Appendix</xref>.</p>
  </sec>
  <sec sec-type="COI-statement">
    <title>Declaration of Competing Interest</title>
    <p id="p0530">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p>
  </sec>
</body>
<back>
  <ref-list id="bibliog0005">
    <title>References</title>
    <ref id="bib1">
      <element-citation publication-type="journal" id="sbref1">
        <person-group person-group-type="author">
          <name>
            <surname>Acunzo</surname>
            <given-names>D.J.</given-names>
          </name>
          <name>
            <surname>MacKenzie</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>van Rossum</surname>
            <given-names>M.C.W.</given-names>
          </name>
        </person-group>
        <article-title>Systematic biases in early ERP and ERF components as a result of high-pass filtering</article-title>
        <source>J. Neurosci. Methods</source>
        <volume>209</volume>
        <issue>1</issue>
        <year>2012</year>
        <fpage>212</fpage>
        <lpage>218</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2012.06.011</pub-id>
        <pub-id pub-id-type="pmid">22743800</pub-id>
      </element-citation>
    </ref>
    <ref id="bib2">
      <element-citation publication-type="journal" id="sbref2">
        <person-group person-group-type="author">
          <name>
            <surname>Artoni</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Delorme</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Makeig</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Applying dimension reduction to EEG data by Principal Component Analysis reduces the quality of its subsequent Independent Component decomposition</article-title>
        <source>NeuroImage</source>
        <volume>175</volume>
        <year>2018</year>
        <fpage>176</fpage>
        <lpage>187</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.03.016</pub-id>
        <pub-id pub-id-type="pmid">29526744</pub-id>
      </element-citation>
    </ref>
    <ref id="bib3">
      <element-citation publication-type="journal" id="sbref3">
        <person-group person-group-type="author">
          <name>
            <surname>Beauchemin</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Gonzaíez-Frankenberger</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Tremblay</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Vannasing</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Martınez-Montes</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Belin</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Beíand</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Francoeur</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Carceller</surname>
            <given-names>A.-M.</given-names>
          </name>
          <name>
            <surname>Wallois</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Lassonde</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>FEATURE ARTICLE mother and stranger: an electrophysiological study of voice processing in newborns</article-title>
        <source>Cereb. Cortex August</source>
        <volume>21</volume>
        <year>2011</year>
        <fpage>1705</fpage>
        <lpage>1711</lpage>
        <pub-id pub-id-type="doi">10.1093/cercor/bhq242</pub-id>
      </element-citation>
    </ref>
    <ref id="bib4">
      <mixed-citation publication-type="other" id="othref0005">Blum, S., Mirkovic, B., Debener, S. , 2019. Evaluation of Riemannian ASR on cEEGrid data: an artifact correction method for BCIs, in: Proceedings of the 2019 IEEE International Conference on Systems, Man and Cybernetics (SMC), 3625–3630.</mixed-citation>
    </ref>
    <ref id="bib5">
      <mixed-citation publication-type="other" id="othref0010">Breunig, M.M., Kriegel, H.-P., Ng, R.T., Sander, J., 2000. LOF: identifying density-based local outliers, in: Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, 93–104. 〈<pub-id pub-id-type="doi">10.1145/342009.335388</pub-id>〉.</mixed-citation>
    </ref>
    <ref id="bib6">
      <element-citation publication-type="journal" id="sbref4">
        <person-group person-group-type="author">
          <name>
            <surname>Buiatti</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Di Giorgio</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Piazza</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Polloni</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Menna</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Taddei</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Baldo</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Vallortigara</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Cortical route for facelike pattern processing in human newborns</article-title>
        <source>Proc. Natl. Acad. Sci. USA</source>
        <volume>116</volume>
        <issue>10</issue>
        <year>2019</year>
        <fpage>4625</fpage>
        <lpage>4630</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1812419116</pub-id>
        <pub-id pub-id-type="pmid">30755519</pub-id>
      </element-citation>
    </ref>
    <ref id="bib7">
      <element-citation publication-type="journal" id="sbref5">
        <person-group person-group-type="author">
          <name>
            <surname>Chang</surname>
            <given-names>C.-Y.</given-names>
          </name>
          <name>
            <surname>Hsu</surname>
            <given-names>S.-H.</given-names>
          </name>
          <name>
            <surname>Pion-Tonachini</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Jung</surname>
            <given-names>T.-P.</given-names>
          </name>
        </person-group>
        <article-title>Evaluation of artifact subspace reconstruction for automatic artifact components removal in multi-channel EEG recordings</article-title>
        <source>IEEE Trans. Biomed. Eng.</source>
        <volume>67</volume>
        <issue>4</issue>
        <year>2020</year>
        <fpage>1114</fpage>
        <lpage>1121</lpage>
        <pub-id pub-id-type="doi">10.1109/TBME.2019.2930186</pub-id>
        <pub-id pub-id-type="pmid">31329105</pub-id>
      </element-citation>
    </ref>
    <ref id="bib8">
      <element-citation publication-type="book" id="sbref6">
        <person-group person-group-type="author">
          <name>
            <surname>Dalianis</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <part-title>Evaluation Metrics and Evaluation BT - Clinical Text Mining: Secondary Use of Electronic Patient Records</part-title>
        <person-group person-group-type="editor">
          <name>
            <surname>Dalianis</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <publisher-name>Springer International Publishing</publisher-name>
        <fpage>45</fpage>
        <lpage>53</lpage>
        <pub-id pub-id-type="doi">10.1007/978-3-319-78503-5_6</pub-id>
      </element-citation>
    </ref>
    <ref id="bib9">
      <element-citation publication-type="journal" id="sbref7">
        <person-group person-group-type="author">
          <name>
            <surname>Debnath</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Buzzell</surname>
            <given-names>G.A.</given-names>
          </name>
          <name>
            <surname>Morales</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Bowers</surname>
            <given-names>M.E.</given-names>
          </name>
          <name>
            <surname>Leach</surname>
            <given-names>S.C.</given-names>
          </name>
          <name>
            <surname>Fox</surname>
            <given-names>N.A.</given-names>
          </name>
        </person-group>
        <article-title>The Maryland analysis of developmental EEG (MADE) pipeline</article-title>
        <source>Psychophysiology</source>
        <volume>57</volume>
        <issue>6</issue>
        <year>2020</year>
        <object-id pub-id-type="publisher-id">e13580</object-id>
        <pub-id pub-id-type="doi">10.1111/psyp.13580</pub-id>
      </element-citation>
    </ref>
    <ref id="bib10">
      <element-citation publication-type="journal" id="sbref8">
        <person-group person-group-type="author">
          <name>
            <surname>Delorme</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Makeig</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title>
        <source>J. Neurosci. Methods</source>
        <volume>134</volume>
        <issue>1</issue>
        <year>2004</year>
        <fpage>9</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2003.10.009</pub-id>
        <pub-id pub-id-type="pmid">15102499</pub-id>
      </element-citation>
    </ref>
    <ref id="bib11">
      <element-citation publication-type="journal" id="sbref9">
        <person-group person-group-type="author">
          <name>
            <surname>Delorme</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Miyakoshi</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Jung</surname>
            <given-names>T.-P.</given-names>
          </name>
          <name>
            <surname>Makeig</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Grand average ERP-image plotting and statistics: a method for comparing variability in event-related single-trial EEG activities across subjects and conditions</article-title>
        <source>J. Neurosci. Methods</source>
        <volume>250</volume>
        <year>2015</year>
        <fpage>3</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2014.10.003</pub-id>
        <pub-id pub-id-type="pmid">25447029</pub-id>
      </element-citation>
    </ref>
    <ref id="bib12">
      <element-citation publication-type="journal" id="sbref10">
        <person-group person-group-type="author">
          <name>
            <surname>Fifer</surname>
            <given-names>W.P.</given-names>
          </name>
          <name>
            <surname>Byrd</surname>
            <given-names>D.L.</given-names>
          </name>
          <name>
            <surname>Kaku</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Eigsti</surname>
            <given-names>I.-M.</given-names>
          </name>
          <name>
            <surname>Isler</surname>
            <given-names>J.R.</given-names>
          </name>
          <name>
            <surname>Grose-Fifer</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Tarullo</surname>
            <given-names>A.R.</given-names>
          </name>
          <name>
            <surname>Balsam</surname>
            <given-names>P.D.</given-names>
          </name>
        </person-group>
        <article-title>Newborn infants learn during sleep</article-title>
        <source>Proc. Natl. Acad. Sci.</source>
        <volume>107</volume>
        <issue>22</issue>
        <year>2010</year>
        <fpage>10320</fpage>
        <lpage>10323</lpage>
        <pub-id pub-id-type="doi">10.1073/PNAS.1005061107</pub-id>
        <pub-id pub-id-type="pmid">20479232</pub-id>
      </element-citation>
    </ref>
    <ref id="bib13">
      <element-citation publication-type="journal" id="sbref11">
        <person-group person-group-type="author">
          <name>
            <surname>Fix</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Hodges</surname>
            <given-names>J.L.</given-names>
          </name>
        </person-group>
        <article-title>Discriminatory analysis. nonparametric discrimination: consistency properties</article-title>
        <source>Int. Stat. Rev. / Rev. Int. De. Stat.</source>
        <volume>57</volume>
        <issue>3</issue>
        <year>1989</year>
        <fpage>238</fpage>
        <lpage>247</lpage>
        <pub-id pub-id-type="doi">10.2307/1403797</pub-id>
      </element-citation>
    </ref>
    <ref id="bib14">
      <element-citation publication-type="journal" id="sbref12">
        <person-group person-group-type="author">
          <name>
            <surname>Fransson</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Metsäranta</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Blennow</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Åden</surname>
            <given-names>U.</given-names>
          </name>
          <name>
            <surname>Lagercrantz</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Vanhatalo</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Early development of spatial patterns of power-law frequency scaling in fMRI resting-state and EEG data in the newborn brain</article-title>
        <source>Cereb. Cortex</source>
        <volume>23</volume>
        <issue>3</issue>
        <year>2013</year>
        <fpage>638</fpage>
        <lpage>646</lpage>
        <pub-id pub-id-type="doi">10.1093/cercor/bhs047</pub-id>
        <pub-id pub-id-type="pmid">22402348</pub-id>
      </element-citation>
    </ref>
    <ref id="bib15">
      <element-citation publication-type="journal" id="sbref13">
        <person-group person-group-type="author">
          <name>
            <surname>Gabard-Durnam</surname>
            <given-names>L.J.</given-names>
          </name>
          <name>
            <surname>Mendez Leal</surname>
            <given-names>A.S.</given-names>
          </name>
          <name>
            <surname>Wilkinson</surname>
            <given-names>C.L.</given-names>
          </name>
          <name>
            <surname>Levin</surname>
            <given-names>A.R.</given-names>
          </name>
        </person-group>
        <article-title>The Harvard Automated Processing Pipeline for Electroencephalography (HAPPE): standardized processing software for developmental and high-artifact data</article-title>
        <source>Front. Neurosci.</source>
        <volume>12</volume>
        <year>2018</year>
        <fpage>97</fpage>
        <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/article/10.3389/fnins.2018.00097" id="ir0065">〈https://www.frontiersin.org/article/10.3389/fnins.2018.00097〉</ext-link>
        <pub-id pub-id-type="pmid">29535597</pub-id>
      </element-citation>
    </ref>
    <ref id="bib16">
      <element-citation publication-type="journal" id="sbref14">
        <person-group person-group-type="author">
          <name>
            <surname>Georgieva</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lester</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Noreika</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Yilmaz</surname>
            <given-names>M.N.</given-names>
          </name>
          <name>
            <surname>Wass</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Leong</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>Toward the understanding of topographical and spectral signatures of infant movement artifacts in naturalistic EEG</article-title>
        <source>Front. Neurosci.</source>
        <volume>14</volume>
        <year>2020</year>
        <fpage>352</fpage>
        <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/article/10.3389/fnins.2020.00352" id="ir0070">〈https://www.frontiersin.org/article/10.3389/fnins.2020.00352〉</ext-link>
        <pub-id pub-id-type="pmid">32410940</pub-id>
      </element-citation>
    </ref>
    <ref id="bib17">
      <element-citation publication-type="journal" id="sbref15">
        <person-group person-group-type="author">
          <name>
            <surname>de Heering</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Rossion</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>Rapid categorization of natural face images in the infant right hemisphere</article-title>
        <source>ELife</source>
        <volume>4</volume>
        <year>2015</year>
        <object-id pub-id-type="publisher-id">e06564</object-id>
        <pub-id pub-id-type="doi">10.7554/eLife.06564</pub-id>
      </element-citation>
    </ref>
    <ref id="bib18">
      <element-citation publication-type="journal" id="sbref16">
        <person-group person-group-type="author">
          <name>
            <surname>Kabdebon</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Pena</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Buiatti</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Dehaene-Lambertz</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Electrophysiological evidence of statistical learning of long-distance dependencies in 8-month-old preterm and full-term infants</article-title>
        <source>Brain Lang.</source>
        <volume>148</volume>
        <year>2015</year>
        <fpage>25</fpage>
        <lpage>36</lpage>
        <pub-id pub-id-type="doi">10.1016/j.bandl.2015.03.005</pub-id>
        <pub-id pub-id-type="pmid">25865749</pub-id>
      </element-citation>
    </ref>
    <ref id="bib19">
      <mixed-citation publication-type="other" id="othref0015">Kothe, C.A. E., Jung, T. , 2016. Artifact removal techniques with signal reconstruction, Google Patents.</mixed-citation>
    </ref>
    <ref id="bib20">
      <element-citation publication-type="journal" id="sbref17">
        <person-group person-group-type="author">
          <name>
            <surname>Krol</surname>
            <given-names>L.R.</given-names>
          </name>
          <name>
            <surname>Pawlitzki</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Lotte</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Gramann</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Zander</surname>
            <given-names>T.O.</given-names>
          </name>
        </person-group>
        <article-title>SEREEGA: simulating event-related EEG activity</article-title>
        <source>J. Neurosci. Methods</source>
        <volume>309</volume>
        <year>2018</year>
        <fpage>13</fpage>
        <lpage>24</lpage>
        <pub-id pub-id-type="doi">10.1016/J.JNEUMETH.2018.08.001</pub-id>
        <pub-id pub-id-type="pmid">30114381</pub-id>
      </element-citation>
    </ref>
    <ref id="bib21">
      <mixed-citation publication-type="other" id="othref0020">Kumaravel, V.P., Kartsch, V., Benatti, S., Vallortigara, G., Farella, E., Buiatti, M., 2021. Efficient artifact removal from low-density wearable EEG using artifacts subspace reconstruction, in: Proceedings of 43rd Annual International Conference of the IEEE Engineering in Medicine and Biology Society, 333–336.</mixed-citation>
    </ref>
    <ref id="bib22">
      <element-citation publication-type="journal" id="sbref18">
        <person-group person-group-type="author">
          <name>
            <surname>Leach</surname>
            <given-names>S.C.</given-names>
          </name>
          <name>
            <surname>Morales</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Bowers</surname>
            <given-names>M.E.</given-names>
          </name>
          <name>
            <surname>Buzzell</surname>
            <given-names>G.A.</given-names>
          </name>
          <name>
            <surname>Debnath</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Beall</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Fox</surname>
            <given-names>N.A.</given-names>
          </name>
        </person-group>
        <article-title>Adjusting ADJUST: optimizing the ADJUST algorithm for pediatric data using geodesic nets</article-title>
        <source>Psychophysiology</source>
        <year>2020</year>
        <pub-id pub-id-type="doi">10.1111/psyp.13566</pub-id>
      </element-citation>
    </ref>
    <ref id="bib23">
      <element-citation publication-type="journal" id="sbref19">
        <person-group person-group-type="author">
          <name>
            <surname>Luck</surname>
            <given-names>S.J.</given-names>
          </name>
          <name>
            <surname>Stewart</surname>
            <given-names>A.X.</given-names>
          </name>
          <name>
            <surname>Simmons</surname>
            <given-names>A.M.</given-names>
          </name>
          <name>
            <surname>Rhemtulla</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Standardized measurement error: a universal metric of data quality for averaged event‐related potentials</article-title>
        <source>Psychophysiology</source>
        <year>2021</year>
        <object-id pub-id-type="publisher-id">e13793</object-id>
        <pub-id pub-id-type="doi">10.31234/osf.io/jc3sd</pub-id>
      </element-citation>
    </ref>
    <ref id="bib24">
      <element-citation publication-type="journal" id="sbref20">
        <person-group person-group-type="author">
          <name>
            <surname>Mognon</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Jovicich</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Bruzzone</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Buiatti</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>ADJUST: an automatic EEG artifact detector based on the joint use of spatial and temporal features</article-title>
        <source>Psychophysiology</source>
        <year>2011</year>
        <pub-id pub-id-type="doi">10.1111/j.1469-8986.2010.01061.x</pub-id>
      </element-citation>
    </ref>
    <ref id="bib25">
      <element-citation publication-type="journal" id="sbref21">
        <person-group person-group-type="author">
          <name>
            <surname>Monroy</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Domínguez-Martínez</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Taylor</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Portolés</surname>
            <given-names>O.M.</given-names>
          </name>
          <name>
            <surname>Parise</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Reid</surname>
            <given-names>V.M.</given-names>
          </name>
        </person-group>
        <article-title>Understanding the causes and consequences of variability in infant ERP editing practices</article-title>
        <source>Dev. Psychobiol.</source>
        <year>2021</year>
        <pub-id pub-id-type="doi">10.1002/dev.22217</pub-id>
      </element-citation>
    </ref>
    <ref id="bib26">
      <element-citation publication-type="journal" id="sbref22">
        <person-group person-group-type="author">
          <name>
            <surname>Mullen</surname>
            <given-names>T.R.</given-names>
          </name>
          <name>
            <surname>Kothe</surname>
            <given-names>C.A.E.</given-names>
          </name>
          <name>
            <surname>Chi</surname>
            <given-names>Y.M.</given-names>
          </name>
          <name>
            <surname>Ojeda</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Kerth</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Makeig</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Jung</surname>
            <given-names>T.P.</given-names>
          </name>
          <name>
            <surname>Cauwenberghs</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Real-time neuroimaging and cognitive monitoring using wearable dry EEG</article-title>
        <source>IEEE Trans. Biomed. Eng.</source>
        <volume>62</volume>
        <issue>11</issue>
        <year>2015</year>
        <pub-id pub-id-type="doi">10.1109/TBME.2015.2481482</pub-id>
      </element-citation>
    </ref>
    <ref id="bib27">
      <element-citation publication-type="journal" id="sbref23">
        <person-group person-group-type="author">
          <name>
            <surname>Nolan</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Whelan</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Reilly</surname>
            <given-names>R.B.</given-names>
          </name>
        </person-group>
        <article-title>FASTER: fully automated statistical thresholding for EEG artifact rejection</article-title>
        <source>J. Neurosci. Methods</source>
        <volume>192</volume>
        <issue>1</issue>
        <year>2010</year>
        <fpage>152</fpage>
        <lpage>162</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jneumeth.2010.07.015</pub-id>
        <pub-id pub-id-type="pmid">20654646</pub-id>
      </element-citation>
    </ref>
    <ref id="bib28">
      <element-citation publication-type="journal" id="sbref24">
        <person-group person-group-type="author">
          <name>
            <surname>Norcia</surname>
            <given-names>A.M.</given-names>
          </name>
          <name>
            <surname>Appelbaum</surname>
            <given-names>L.G.</given-names>
          </name>
          <name>
            <surname>Ales</surname>
            <given-names>J.M.</given-names>
          </name>
          <name>
            <surname>Cottereau</surname>
            <given-names>B.R.</given-names>
          </name>
          <name>
            <surname>Rossion</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>The steady-state visual evoked potential in vision research: a review</article-title>
        <source>J. Vis.</source>
        <volume>15</volume>
        <issue>6</issue>
        <year>2015</year>
        <fpage>4</fpage>
        <pub-id pub-id-type="doi">10.1167/15.6.4</pub-id>
      </element-citation>
    </ref>
    <ref id="bib29">
      <element-citation publication-type="journal" id="sbref25">
        <person-group person-group-type="author">
          <name>
            <surname>Odabaee</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Tokariev</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Layeghy</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Mesbah</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Colditz</surname>
            <given-names>P.B.</given-names>
          </name>
          <name>
            <surname>Ramon</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Vanhatalo</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Neonatal EEG at scalp is focal and implies high skull conductivity in realistic neonatal head models</article-title>
        <source>NeuroImage</source>
        <volume>96</volume>
        <year>2014</year>
        <fpage>73</fpage>
        <lpage>80</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.04.007</pub-id>
        <pub-id pub-id-type="pmid">24736169</pub-id>
      </element-citation>
    </ref>
    <ref id="bib30">
      <element-citation publication-type="book" id="sbref26">
        <person-group person-group-type="author">
          <name>
            <surname>Onton</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Westerfield</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Townsend</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Makeig</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <part-title>Imaging human EEG dynamics using independent component analysis</part-title>
        <series>Neuroscience and Biobehavioral Reviews</series>
        <volume>vol. 30</volume>
        <year>2006</year>
        <publisher-name>Pergamon</publisher-name>
        <fpage>808</fpage>
        <lpage>822</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neubiorev.2006.06.007</pub-id>
      </element-citation>
    </ref>
    <ref id="bib31">
      <element-citation publication-type="journal" id="sbref27">
        <person-group person-group-type="author">
          <name>
            <surname>Parise</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Csibra</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Electrophysiological evidence for the understanding of maternal speech by 9-month-old infants</article-title>
        <source>Psychol. Sci.</source>
        <volume>23</volume>
        <issue>7</issue>
        <year>2012</year>
        <fpage>728</fpage>
        <lpage>733</lpage>
        <pub-id pub-id-type="doi">10.1177/0956797612438734</pub-id>
        <pub-id pub-id-type="pmid">22692337</pub-id>
      </element-citation>
    </ref>
    <ref id="bib32">
      <element-citation publication-type="journal" id="sbref28">
        <person-group person-group-type="author">
          <name>
            <surname>Pion-Tonachini</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Kreutz-Delgado</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Makeig</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>ICLabel: an automated electroencephalographic independent component classifier, dataset, and website</article-title>
        <source>NeuroImage</source>
        <volume>198</volume>
        <year>2019</year>
        <fpage>181</fpage>
        <lpage>197</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.05.026</pub-id>
        <pub-id pub-id-type="pmid">31103785</pub-id>
      </element-citation>
    </ref>
    <ref id="bib33">
      <element-citation publication-type="journal" id="sbref29">
        <person-group person-group-type="author">
          <name>
            <surname>Ronga</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Galigani</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Bruno</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Noel</surname>
            <given-names>J.-P.</given-names>
          </name>
          <name>
            <surname>Gazzin</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Perathoner</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Serino</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Garbarini</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>Spatial tuning of electrophysiological responses to multisensory stimuli reveals a primitive coding of the body boundaries in newborns</article-title>
        <source>Proc. Natl. Acad. Sci. USA</source>
        <volume>118</volume>
        <issue>12</issue>
        <year>2021</year>
        <pub-id pub-id-type="doi">10.1073/pnas.2024548118</pub-id>
      </element-citation>
    </ref>
    <ref id="bib34">
      <element-citation publication-type="journal" id="sbref30">
        <person-group person-group-type="author">
          <name>
            <surname>Winkler</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Brandl</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Horn</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Waldburger</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Allefeld</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Tangermann</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Robust artifactual independent component classification for BCI practitioners</article-title>
        <source>J. Neural Eng.</source>
        <volume>11</volume>
        <issue>3</issue>
        <year>2014</year>
        <object-id pub-id-type="publisher-id">035013</object-id>
        <pub-id pub-id-type="doi">10.1088/1741-2560/11/3/035013</pub-id>
      </element-citation>
    </ref>
    <ref id="bib35">
      <element-citation publication-type="journal" id="sbref31">
        <person-group person-group-type="author">
          <name>
            <surname>Zhu</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Natural neighbor: a self-adaptive neighborhood method without parameter K</article-title>
        <source>Pattern Recognit. Lett.</source>
        <volume>80</volume>
        <year>2016</year>
        <fpage>30</fpage>
        <lpage>36</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patrec.2016.05.007</pub-id>
      </element-citation>
    </ref>
  </ref-list>
  <sec id="sec0310" sec-type="supplementary-material">
    <label>Appendix A</label>
    <title>Supplementary material</title>
    <p id="p0545"><supplementary-material content-type="local-data" id="ec0005"><caption><p>Supplementary material.</p></caption><media xlink:href="mmc1.docx"/></supplementary-material>.</p>
  </sec>
  <ack id="ack0005">
    <title>Acknowledgements</title>
    <p id="p0535">We thank the three anonymous reviewers for their constructive comments and Barbara Pomiechowska for her help with data format exporting and sharing. This work was supported by the <funding-source id="gs1"><institution-wrap><institution-id institution-id-type="doi">10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source> Proof of Concept grant NeuroSoNew (842243).</p>
  </ack>
  <fn-group>
    <fn id="fn1">
      <label>1</label>
      <p id="ntp0005">Neither MADE nor HAPPE are equipped with a method to detect flat channels. Since flat channels cause errors in the ICA classification algorithms used by these methods, we removed them before applying MADE and HAPPE to the data.</p>
    </fn>
    <fn id="sec0305" fn-type="supplementary-material">
      <label>Appendix A</label>
      <p id="p0540">Supplementary data associated with this article can be found in the online version at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.dcn.2022.101068" id="ir0055">doi:10.1016/j.dcn.2022.101068</ext-link>.</p>
    </fn>
  </fn-group>
</back>
