<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Genomics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Genomics</journal-id>
    <journal-title-group>
      <journal-title>BMC Genomics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2164</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8973509</article-id>
    <article-id pub-id-type="publisher-id">8414</article-id>
    <article-id pub-id-type="doi">10.1186/s12864-022-08414-x</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>ENNGene: an Easy Neural Network model building tool for Genomics</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Chalupová</surname>
          <given-names>Eliška</given-names>
        </name>
        <address>
          <email>chalupovaeliska@email.cz</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Vaculík</surname>
          <given-names>Ondřej</given-names>
        </name>
        <address>
          <email>vaculik.ond@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Poláček</surname>
          <given-names>Jakub</given-names>
        </name>
        <address>
          <email>456491@mail.muni.cz</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Jozefov</surname>
          <given-names>Filip</given-names>
        </name>
        <address>
          <email>492770@mail.muni.cz</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Majtner</surname>
          <given-names>Tomáš</given-names>
        </name>
        <address>
          <email>majtner.tom@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3437-7482</contrib-id>
        <name>
          <surname>Alexiou</surname>
          <given-names>Panagiotis</given-names>
        </name>
        <address>
          <email>panagiotis.alexiou@ceitec.muni.cz</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.10267.32</institution-id><institution-id institution-id-type="ISNI">0000 0001 2194 0956</institution-id><institution>Faculty of Science, National Centre for Biomolecular Research, Masaryk University, </institution></institution-wrap>Brno, Czechia </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.10267.32</institution-id><institution-id institution-id-type="ISNI">0000 0001 2194 0956</institution-id><institution>Central European Institute of Technology (CEITEC), </institution><institution>Masaryk University, </institution></institution-wrap>Brno, Czechia </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.10267.32</institution-id><institution-id institution-id-type="ISNI">0000 0001 2194 0956</institution-id><institution>Faculty of Informatics, </institution><institution>Masaryk University, </institution></institution-wrap>Brno, Czechia </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>31</day>
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>31</day>
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>248</elocation-id>
    <history>
      <date date-type="received">
        <day>5</day>
        <month>11</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>23</day>
        <month>2</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">The recent big data revolution in Genomics, coupled with the emergence of Deep Learning as a set of powerful machine learning methods, has shifted the standard practices of machine learning for Genomics. Even though Deep Learning methods such as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) are becoming widespread in Genomics, developing and training such models is outside the ability of most researchers in the field.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Here we present ENNGene—Easy Neural Network model building tool for Genomics. This tool simplifies training of custom CNN or hybrid CNN-RNN models on genomic data via an easy-to-use Graphical User Interface. ENNGene allows multiple input branches, including sequence, evolutionary conservation, and secondary structure, and performs all the necessary preprocessing steps, allowing simple input such as genomic coordinates. The network architecture is selected and fully customized by the user, from the number and types of the layers to each layer's precise set-up. ENNGene then deals with all steps of training and evaluation of the model, exporting valuable metrics such as multi-class ROC and precision-recall curve plots or TensorBoard log files. To facilitate interpretation of the predicted results, we deploy Integrated Gradients, providing the user with a graphical representation of an attribution level of each input position. To showcase the usage of ENNGene, we train multiple models on the RBP24 dataset, quickly reaching the state of the art while improving the performance on more than half of the proteins by including the evolutionary conservation score and tuning the network per protein.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">As the role of DL in big data analysis in the near future is indisputable, it is important to make it available for a broader range of researchers. We believe that an easy-to-use tool such as ENNGene can allow Genomics researchers without a background in Computational Sciences to harness the power of DL to gain better insights into and extract important information from the large amounts of data available in the field.</p>
      </sec>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s12864-022-08414-x.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Deep Learning</kwd>
      <kwd>Convolutional Neural Network</kwd>
      <kwd>Recurrent Neural Network</kwd>
      <kwd>Evolutionary Conservation Score</kwd>
      <kwd>RNA Secondary Structure</kwd>
      <kwd>GUI</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010684</institution-id>
            <institution>H2020 Spreading Excellence and Widening Participation</institution>
          </institution-wrap>
        </funding-source>
        <award-id>867414</award-id>
        <principal-award-recipient>
          <name>
            <surname>Alexiou</surname>
            <given-names>Panagiotis</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100010653</institution-id>
            <institution>Masarykova Univerzita</institution>
          </institution-wrap>
        </funding-source>
        <award-id>CZ.02.2.69/0.0/0.0/18 053/0016952</award-id>
        <principal-award-recipient>
          <name>
            <surname>Majtner</surname>
            <given-names>Tomáš</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par21">Artificial Neural Networks (ANNs) are a family of Machine Learning (ML) algorithms, which learn complex tasks via the connection of simple artificial neurons. ANNs have been used for a multitude of tasks since their inception more than 50 years ago [<xref ref-type="bibr" rid="CR1">1</xref>], such as image and signal processing, natural language processing and translation, and many more. In recent years, the field of ANNs has undergone a revolutionary change, with the adoption of Deep Neural Networks, or Deep Learning (DL) [<xref ref-type="bibr" rid="CR2">2</xref>]. These types of ANNs utilize a large number of stacked artificial layers of neurons in order to learn increasingly complex representations of input data. DL consistently outperforms other ML methods in cases where moderately large training sets are available.</p>
    <p id="Par22">Some of the commonly used networks for Deep Learning are Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). CNNs make use of Convolutional neural layers to effectively model specific aspects of input samples while reducing the number of parameters that need to be trained. That allows training with fewer input data, together with the development of deeper architectures. RNNs utilize different architectures such as Long-Short Term Memory (LSTM) and Gated Recurrent Units (GRU) to introduce a temporal memory capability. In Genomics, DL models were quickly applied to problems such as the prediction of biomolecule binding specificities [<xref ref-type="bibr" rid="CR3">3</xref>], prediction of the effect of non-coding variants [<xref ref-type="bibr" rid="CR4">4</xref>], learning the functional activity of DNA sequences [<xref ref-type="bibr" rid="CR5">5</xref>], and many more [<xref ref-type="bibr" rid="CR6">6</xref>].</p>
    <p id="Par23">Training DL models from scratch requires high-level programming skills and an understanding of DL programming libraries. Recently, projects such as pysster [<xref ref-type="bibr" rid="CR7">7</xref>], Selene [<xref ref-type="bibr" rid="CR8">8</xref>], or Janggu [<xref ref-type="bibr" rid="CR9">9</xref>] have been developed to standardize the usage of Deep Learning in Genomics and lower the prerequisite for training DL models for genomics data. Pysster [<xref ref-type="bibr" rid="CR7">7</xref>] is a Python package focusing on CNNs for biological sequence data. Pysster enables learning sequence and structure motifs and visualizing them along with information about their positional and class enrichment. Selene [<xref ref-type="bibr" rid="CR8">8</xref>] is a PyTorch-based library for working with sequence-based DL models. It offers workflows for applying an existing model, retraining it on new data, or developing new model architectures. Though it is meant to be run by simple scripts, the input is provided via extensive configuration files. When creating a new architecture, users must be able to define it in a separate Python file properly. Together, this is a rather intricate process that can discourage researchers not versed in programming or scripting. Finally, Janggu [<xref ref-type="bibr" rid="CR9">9</xref>] is a library offering support for both Keras and PyTorch [<xref ref-type="bibr" rid="CR10">10</xref>] backend, together with unified dataset objects simplifying data acquisition and preprocessing. It supports visualization options, including genomic tracks and input feature importance via Integrated Gradients. While these tools offer a measure of facilitation for developing DL models, they still expect users to have at least intermediate programming skills.</p>
    <p id="Par24">We have experienced the need for an accessible and user-friendly framework that could allow Genomics researchers with minimal programming skills to access the power of applying DL on their preferred dataset. With this motivation, we have developed ENNGene, a tool utilizing a user-friendly Graphical User Interface (GUI) to handle data preprocessing, model building, training, and evaluation, as well as interpretation of the predicted results (Fig. <xref rid="Fig1" ref-type="fig">1</xref>). ENNGene allows users to select among up to three input branches—genomic sequence, predicted RNA secondary structure, and, unlike any other DL implementation for Genomics, phylogenetic conservation scores. In the last decade, most of the progress in the DL field has been concentrated on finding better performing, easier-to-train deep neural networks. In practice, it is also essential to be able to verify the results and validate the process that led to them. That is especially important in applications such as the Genomic and Biomedical fields, where the model's reliability must be guaranteed. ENNGene offers an interpretation of trained models based on a novel implementation of the Integrated Gradients method [<xref ref-type="bibr" rid="CR11">11</xref>] that can be applied on multi-branch networks.<fig id="Fig1"><label>Fig. 1</label><caption><p><bold>a</bold> The Graphical User Interface (GUI) of ENNGene—ENNGene is fully operated via the GUI. Users define the input parameters using simple interactive elements, such as dropdown menus or checkboxes. Warnings and hints are displayed via the GUI in a user-friendly way directly as the user interacts with it. Web browser being at the basis of the GUI, interactive plots or results are visualized immediately throughout or after the calculations. <bold>b</bold> Simplified data flow—ENNGene comprises multiple subsequent modules with separate functionality, covering the whole process from input preparation and network architecture definition to model evaluation and interpretation</p></caption><graphic xlink:href="12864_2022_8414_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par25">We demonstrate the functionality of ENNGene on the use case of a well-known benchmark dataset based on the classification of RNA Binding Protein (RBP) binding sites [<xref ref-type="bibr" rid="CR12">12</xref>]. On this benchmark, we show that models developed using ENNGene, without specific hand-crafted features based on domain knowledge, match or outperform state-of-the-art methods created explicitly for this task.</p>
    <sec id="Sec2">
      <title>Implementation</title>
      <p id="Par26">ENNGene uses the open-source Streamlit framework (<ext-link ext-link-type="uri" xlink:href="https://streamlit.io/">https://streamlit.io/</ext-link>) and is built atop TensorFlow [<xref ref-type="bibr" rid="CR13">13</xref>], one of the most popular DL backends. It runs locally on both physical and virtual machines, using either Central Processing Units (CPUs) or Graphics Processing Units (GPUs), which offer a considerable speed-up when training larger networks [<xref ref-type="bibr" rid="CR14">14</xref>]. Our major considerations in the implementation of ENNGene were ease of use, generic functionality on various genomic problems, and reproducibility of results. The software consists of four linearly connected modules: (a) preprocessing module, (b) training module, (c) prediction module, and (d) evaluation module.</p>
    </sec>
    <sec id="Sec3">
      <title>User input</title>
      <p id="Par27">The minimal user input is a Browser Extensible Data (BED) file containing DNA/RNA sequences and a genome or transcriptome (fasta) reference file. An additional PhyloP [<xref ref-type="bibr" rid="CR15">15</xref>] reference file must be provided if the user wishes to utilize the evolutionary conservation. Such reference files are readily available for most organisms from public repositories such as Ensembl [<xref ref-type="bibr" rid="CR16">16</xref>] or UCSC Genome Tables Browser [<xref ref-type="bibr" rid="CR17">17</xref>]. Optionally, the user may also input a log file (Yaml) from a previous ENNGene run, instantly reproducing the input configuration. This way, users can guarantee full reproducibility across different instances of ENNGene, provided the same input files are available. To avoid re-mapping the same inputs to the same reference multiple times, ENNGene provides an option to save and reuse mapped files between runs.</p>
    </sec>
    <sec id="Sec4">
      <title>Module 1: preprocessing</title>
      <p id="Par28">In the first module, data is preprocessed into a format convenient for CNN input. The user may select one or more input types engineered from the given interval files. (a) Sequence – one-hot encoded RNA or DNA sequence, obtained by mapping given intervals to the reference genome or transcriptome fasta file. (b) RNA secondary structure is based on the mapped sequences and computed by the ViennaRNA2 package [<xref ref-type="bibr" rid="CR18">18</xref>]. When calculating the secondary structure, users can choose the number of CPU cores dedicated to the computation. (c) The evolutionary conservation score is mapped similarly to the sequence, with the user-provided phylogenetic conservation file as a reference.</p>
      <p id="Par29">As required by CNNs, all input sequences must be of the same length. One strategy for ensuring same length inputs is N or 0 padding [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR20">20</xref>]. However, such an approach runs the danger of introducing a blind spot or even learning the padding artifact above the legitimate features when sequences of different classes do not have the same length distribution [<xref ref-type="bibr" rid="CR21">21</xref>]. In the case of ENNGene, we avoid this by extending or trimming the provided genomic coordinates to the same length, thus ‘padding’ our intervals with actual neighboring sequences and other features.</p>
      <p id="Par30">The training of CNNs can be affected by an imbalance in class sizes [<xref ref-type="bibr" rid="CR22">22</xref>]. It is common practice to artificially balance the various classes in training sets by downsampling the more populous classes. ENNGene makes this optional preprocessing step easy by allowing users to define a reduction by an absolute or relative dataset size (e.g., 5,000 out of 10,000 sequences, or 0.5 ratio).</p>
      <p id="Par31">Following this step, datasets are split into ‘training’, ‘validation’, ‘evaluation’ (testing), and ‘black-box’ (left-out testing) randomly at a user-defined ratio or based on reference chromosome number. The ‘training’ and ‘validation’ datasets are used throughout the training process. The ‘evaluation’ dataset is used for model evaluation directly after the training. The last one, the ‘black-box’ dataset, is optional and is never seen by any part of the training or evaluation modules of ENNGene. It is a truly left-out dataset that can be used for final evaluation after multiple rounds of hyperparameters tuning and architecture exploration in order to avoid overfitting the evaluation dataset. Splitting the sequences based on the chromosome they are found on also ensures that each of these datasets comes from entirely unrelated genomic regions and that there is no possibility for one part of the process encountering a left-out locus, for example, when using input files with nearly overlapping genomic loci.</p>
    </sec>
    <sec id="Sec5">
      <title>Module 2: training</title>
      <p id="Par32">In the second module, the user can use the GUI to define the neural network architecture and training hyperparameters: (a) batch size, (b) learning rate, and (c) choose one of three available optimizers: stochastic gradient descent (SGD)—preset with Nesterov’s momentum to 0.9 [<xref ref-type="bibr" rid="CR23">23</xref>], RMSprop [<xref ref-type="bibr" rid="CR24">24</xref>], or Adam [<xref ref-type="bibr" rid="CR25">25</xref>]. If SGD is selected, two additional learning rate options become available, using a learning rate scheduler or applying one cycle policy [<xref ref-type="bibr" rid="CR26">26</xref>]. Users may also define a specific number of training epochs or apply the early stopping callback, which stops the training when there is no more improvement on the validation dataset. We have opted to simplify hyperparameter selection as much as possible while not compromising the power of the produced models.</p>
      <p id="Par33">ENNGene enables the building of CNNs consisting of convolutional layers followed by fully connected layers, or hybrid CNN-RNNs. In the latter case, the convolutional layers are first followed by recurrent layers—either GRU [<xref ref-type="bibr" rid="CR27">27</xref>] or LSTM [<xref ref-type="bibr" rid="CR28">28</xref>], finally followed by dense layers. The details of the network architecture are defined per each section separately, having one section for each selected branch corresponding to the preprocessed input types and one section for the common part of the network following the concatenation of the branches.</p>
      <p id="Par34">After setting up the number and types of the layers, the layer parameters can be customized. For each layer, users can pick a dropout rate [<xref ref-type="bibr" rid="CR29">29</xref>], choose to apply the batch normalization [<xref ref-type="bibr" rid="CR30">30</xref>], and set the layer-specific options—the number and size of the convolutional filters, the number of dense or recurrent units, and the application of a bidirectional wrapper on the recurrent layers. In accordance with the focus of the ENNGene on classification problems for two or more classes, the loss function is preset to categorical cross-entropy, together with the last layer set as the softmax activation function with the number of units corresponding to the number of classes.</p>
      <p id="Par35">Models created by ENNGene are trained using the TensorFlow framework with the support of GPU acceleration. The GPU is automatically detected and used when available on the machine, providing considerable speed up during the training phase. Throughout the training, users can monitor the progress, together with the development of the accuracy and loss metrics on an interactive plot. These metrics are also plotted and exported for later use.</p>
      <p id="Par36">After the training, the resulting model is directly evaluated on the user-defined evaluation dataset. Above the basic metrics, the receiver operating characteristic (ROC) and precision-recall curves, both adjusted for the multi-class classification problems, are calculated and exported in the form of plots and tables (Fig. <xref rid="Fig2" ref-type="fig">2</xref> (a, b)). Furthermore, TensorBoard [<xref ref-type="bibr" rid="CR13">13</xref>] files allowing visualization and browsing of the model architecture, as well as metrics comparison between multiple runs, can be produced.<fig id="Fig2"><label>Fig. 2</label><caption><p><bold>a</bold> Precision-recall curve—the precision-recall metric indicates the relationship between the model’s positive predictive value (precision) and sensitivity (recall) at various thresholds. <bold>b</bold> Receiver Operating Characteristic (ROC) curve—the ROC metric is calculated as a ratio between the true positive rate and the false positive rate at various thresholds. Both the metrics, precision-recall and ROC calculated by ENNGene, are adjusted for multi-class classification problems and thus can be applied to models with any number of classes. Both curves and other metrics (accuracy, loss, AUROC) are a standard part of exported results after a model evaluation, optionally with Integrated Gradients’ scores. <bold>c</bold> Integrated Gradients visualization—IG scores of ten sequences with the highest predicted score per class are directly visualized in the browser. Scores are displayed in separate rows for each input type used—sequence, secondary structure, and conservation score. The higher the nucleotide’s attribution to the prediction of a given class, the more pronounced is its red color. On the other hand, the blue color means a low level of attribution</p></caption><graphic xlink:href="12864_2022_8414_Fig2_HTML" id="MO2"/></fig></p>
    </sec>
    <sec id="Sec6">
      <title>Modules 3&amp;4: prediction and evaluation</title>
      <p id="Par37">The final two modules allow the user to evaluate a previously trained model on a different dataset (Evaluation) or apply the model to classify novel data samples (Prediction). The two modules share most of the functionality; therefore, they will be addressed together in this last section. At this point, the user may upload any pre-trained model, either produced by ENNGene or not, and a set of genomic loci to be evaluated either with known class labels (Evaluation) or not (Prediction).</p>
      <p id="Par38">Loci to be evaluated are preprocessed in the same way described in the first module. For evaluation purposes, the black-box dataset prepared during the preprocessing of the original data can be used. If the trained model does not use a conservation branch, then even simple fasta files containing sequences of the correct length may be used for prediction.</p>
      <p id="Par39">Calculated predictions are exported as probability scores for each class, with the highest-scoring class highlighted. ENNGene does not return a single ‘predicted class’, as that can vary based on the subjective choice of a threshold for each class. Optionally, Integrated Gradients (IG) [<xref ref-type="bibr" rid="CR11">11</xref>] are calculated for each sample and exported as a list of scores for custom visualization. At the same time, the top ten predictions per class are directly displayed in the browser (Fig. <xref rid="Fig2" ref-type="fig">2</xref> (c)). The IG technique is based on calculating the difference between the baseline, a vector of zeros in our case, and an input sequence. That dependency is the core of the attribution and is expressed as the color adjustment of each nucleobase across all the input types. The higher the attribution of the sequence to the prediction, the more pronounced red is its color. On the other hand, blue means a low level of attribution. The attribution visualization can be used for auxiliary evaluation and debugging of the model.</p>
    </sec>
  </sec>
  <sec id="Sec7">
    <title>Results and discussion</title>
    <p id="Par40">ENNGene is a generic tool created to enable researchers to produce state-of-the-art DL models with minimal programming knowledge. It was developed with a focus on ease of use, reproducibility, and interpretability while avoiding compromising the power of the produced models.</p>
    <sec id="Sec8">
      <title>Ease of use and reproducibility</title>
      <p id="Par41">The entirety of ENNGene’s code is freely and openly available at GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/ML-Bioinfo-CEITEC/ENNGene">https://github.com/ML-Bioinfo-CEITEC/ENNGene</ext-link> under an open-source GNU Affero General Public License. ENNGene runs on a Linux system and was extensively tested on the Ubuntu distribution. Using the Anaconda package manager, we ensure containerization and safe un/installation of the application. A step-by-step guided installation script, as well as extensive documentation, can be found at the project’s code repository and as a supplementary file accompanying this publication (Additional file <xref rid="MOESM1" ref-type="media">1</xref>).</p>
      <p id="Par42">We have taken various steps to improve the user experience. The application verifies every provided input information. Specific warnings or hints are returned to the user immediately during the parameter set-up or just before any further calculations are started. All the user input, warnings, and errors are logged throughout the whole session. After the session is finished, the log file is placed in the user-specified output folder. If an error occurs during the session, the user is notified of the location of the log file containing the additional details.</p>
      <p id="Par43">To ensure full reproducibility of the results, ENNGene logs all the parameters set by the user and exports them as a Yaml file. The file can be imported into the application at any time in the future, immediately setting all the parameters for the chosen task. This way, users can recreate all their results or quickly tune chosen hyperparameters. Above that, all the tracked parameters are exported into one.tsv file, shared across all the application sessions within the same output folder, with one line per session. This file can significantly streamline the comparison of multiple models, as the user has all the preprocessing and training parameters used to create each of the models in one place.</p>
    </sec>
    <sec id="Sec9">
      <title>Case Study: RBP24 classification—comparison to the state of the art</title>
      <p id="Par44">To demonstrate the functionality of ENNGene, we chose the problem of the RNA-binding proteins (RBPs) target site classification. So far, DL methods published in the field provide one or more trained models (e.g. [<xref ref-type="bibr" rid="CR3">3</xref>] and [<xref ref-type="bibr" rid="CR31">31</xref>]) prepared specifically to address this task. For example, a wide range of pretrained models for RBP binding site prediction can be found on the RBPsuite web server [<xref ref-type="bibr" rid="CR32">32</xref>]. Using the RBPsuite, users can choose from models trained on linear RNA based on the iDeepS architecture [<xref ref-type="bibr" rid="CR33">33</xref>] or trained on the circular RNA with the underlying CRIP architecture [<xref ref-type="bibr" rid="CR34">34</xref>]. Though operated via GUI, its function is limited to applying a trained model too, with no option of training a new one.</p>
      <p id="Par45">CNNs were applied to the RBP target site classification problem for the first time in 2015 [<xref ref-type="bibr" rid="CR3">3</xref>]. Since then, there have been many novel approaches, including several different network architectures. With the target RNA sequence as the primary feature, predicted secondary structure [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR35">35</xref>–<xref ref-type="bibr" rid="CR37">37</xref>] and transcript region type [<xref ref-type="bibr" rid="CR38">38</xref>, <xref ref-type="bibr" rid="CR39">39</xref>] are the other most commonly used features. Up to date, several different network types have been applied to the RBP binding site classification problem. Those include the CNN [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR36">36</xref>], RNN [<xref ref-type="bibr" rid="CR40">40</xref>], or often a combination of the two [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR36">36</xref>, <xref ref-type="bibr" rid="CR39">39</xref>, <xref ref-type="bibr" rid="CR41">41</xref>], deep belief network (DBN) [<xref ref-type="bibr" rid="CR35">35</xref>, <xref ref-type="bibr" rid="CR38">38</xref>], deep residual network [<xref ref-type="bibr" rid="CR42">42</xref>], and attention network [<xref ref-type="bibr" rid="CR37">37</xref>]. ENNGene allows the users to use the two most widely applied architectures—CNN and hybrid CNN-RNN networks. In most cases, one model per RBP is trained. In a few exceptions, a multi-label classifier is built for all the proteins [<xref ref-type="bibr" rid="CR39">39</xref>], for example, by applying classifier chains to learn the correlation between labels [<xref ref-type="bibr" rid="CR43">43</xref>]. Using ENNGene, we have applied the two most commonly used network types (CNN and hybrid CNN-RNN) on the RBP24 dataset introduced in GraphProt [<xref ref-type="bibr" rid="CR12">12</xref>], producing one model for each RBP in the dataset.</p>
      <p id="Par46">We selected this widely used benchmark dataset as it has already been used for benchmarking by several state-of-the-art methods [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR35">35</xref>, <xref ref-type="bibr" rid="CR42">42</xref>]. The RBP24 dataset consists of 21 RNA-binding protein target sites from 24 CLIP-seq experiments. Since ENNGene works with input bed files, we extracted the interval coordinates from the sequence header from the original RBP24 dataset (see the extracted genomic coordinates at the project’s GitHub repository; the original fasta files can be obtained from GraphProt repository at <ext-link ext-link-type="uri" xlink:href="http://www.bioinf.uni-freiburg.de/Software/GraphProt/">http://www.bioinf.uni-freiburg.de/Software/GraphProt/</ext-link>). Following the original dataset, intervals were mapped to the human (hg19) genome reference on a 150 nt long window centered at the initial coordinates. The length of 150 nucleotides has been previously used in several RBP target site predictors [<xref ref-type="bibr" rid="CR35">35</xref>] and has been proven to be the best choice for secondary structure prediction [<xref ref-type="bibr" rid="CR44">44</xref>]. The base-wise conservation scores by PhyloP [<xref ref-type="bibr" rid="CR15">15</xref>] from the PHAST package [<xref ref-type="bibr" rid="CR45">45</xref>], created by multiple alignments of 99 vertebrate genomes to the human genome, were obtained from the UCSC file storage. Only the PTBv1 dataset was mapped to the older (hg18) genome reference and the corresponding PhyloP files (with 43 vertebrate genomes aligned) according to the original dataset specification. ENNGene being a generic tool works well with any genomic assembly and depth of conservation file.</p>
      <p id="Par47">The number of samples in the RBP24 dataset widely differs between the experiments, with the ratio between positive and negative classes always close to 1:1. We used the original training files for model training and parameter search purposes, dividing them into training, validation, and testing datasets. The original testing samples were left entirely out as a ‘black-box’ dataset. We chose the best models based on the Area Under Receiver Operating Characteristic curve (AUROC) metric upon the testing dataset while prioritizing the simplest architecture available. We performed a human-guided search of selected hyperparameters since fully covering the data and model hyperparameter space by grid search would be too time-consuming for a simple demonstration. The tuned parameters were number and combination of branches, batch size, number of epochs, optimizer, learning rate, number of layers per section, as well as the type of the layer and specific parameters per layer (number of units/filters, bidirectionality, kernel size, dropout rate, batch normalization). The models were trained for different numbers of epochs, optionally using the early stopping with parameters set to patience = 10 and delta = 0.01 to avoid overfitting. A complete list of the hyperparameters used for each final model can be found in Additional file <xref rid="MOESM2" ref-type="media">2</xref>.</p>
      <p id="Par48">The left-out files were used only for the final evaluation of the already tuned models. We show that using ENNGene we were able to produce models that perform to the current state-of-the-art standard. For more than half of the experiments in the RBP24 dataset, ENNGene models outperform the state of the art, producing an improved average AUROC value of 0.947 on the whole RBP24 dataset (Table <xref rid="Tab1" ref-type="table">1</xref>, Additional file <xref rid="MOESM3" ref-type="media">3</xref>). All the final trained models can be found at the project’s GitHub repository.<table-wrap id="Tab1"><label>Table 1</label><caption><p>AUROC values from the evaluation of the final models, together with the RBP24 dataset properties. Models created using ENNGene outperform the state-of-the-art tools on more than half of the experiments in the RBP24 dataset while also improving the average AUROC value on the whole dataset. The AUROC values of the other tools are </p><p>taken from the original publications. The highest AUROC score reached for the experiment is highlighted in bold</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="3">Protein</th><th align="left" colspan="10">RBP-24</th></tr><tr><th align="left" colspan="3"><bold>Dataset info</bold></th><th align="left" colspan="7"><bold>Results (AUROC)</bold></th></tr><tr><th align="left"><bold>Clip method</bold></th><th align="left"><bold># positives</bold></th><th align="left"><bold># negatives</bold></th><th align="left"><bold>GraphProt</bold></th><th align="left"><bold>deepnet-rbp</bold></th><th align="left"><bold>DeepBind</bold></th><th align="left"><bold>iDeepV</bold></th><th align="left"><bold>iDeepE</bold></th><th align="left"><bold>DeepRKE</bold></th><th align="left"><bold>ENNGene</bold></th></tr></thead><tbody><tr><td align="left"><bold>Ago1-4</bold></td><td align="left">PAR-CLIP</td><td align="left">36,902</td><td align="left">31,310</td><td char="." align="char">0.895</td><td char="." align="char">0.881</td><td char="." align="char">0.919</td><td char="." align="char">0.925</td><td char="." align="char">0.915</td><td char="." align="char"><bold>0.932</bold></td><td char="." align="char">0.927</td></tr><tr><td align="left"><bold>Ago2</bold></td><td align="left">HITS-CLIP</td><td align="left">48,095</td><td align="left">44,251</td><td char="." align="char">0.765</td><td char="." align="char">0.809</td><td char="." align="char">0.879</td><td char="." align="char">0.886</td><td char="." align="char">0.884</td><td char="." align="char">0.9</td><td char="." align="char"><bold>0.94</bold></td></tr><tr><td align="left"><bold>ALKBH5</bold></td><td align="left">PAR-CLIP</td><td align="left">1213</td><td align="left">1197</td><td char="." align="char">0.68</td><td char="." align="char">0.714</td><td char="." align="char">0.668</td><td char="." align="char">0.643</td><td char="." align="char">0.758</td><td char="." align="char">0.74</td><td char="." align="char"><bold>0.877</bold></td></tr><tr><td align="left"><bold>C17ORF85</bold></td><td align="left">PAR-CLIP</td><td align="left">1860</td><td align="left">1849</td><td char="." align="char">0.8</td><td char="." align="char">0.82</td><td char="." align="char">0.755</td><td char="." align="char">0.74</td><td char="." align="char">0.83</td><td char="." align="char">0.824</td><td char="." align="char"><bold>0.916</bold></td></tr><tr><td align="left"><bold>C22ORF28</bold></td><td align="left">PAR-CLIP</td><td align="left">9369</td><td align="left">9136</td><td char="." align="char">0.751</td><td char="." align="char">0.792</td><td char="." align="char">0.809</td><td char="." align="char">0.823</td><td char="." align="char">0.837</td><td char="." align="char">0.832</td><td char="." align="char"><bold>0.908</bold></td></tr><tr><td align="left"><bold>CAPRIN1</bold></td><td align="left">PAR-CLIP</td><td align="left">8140</td><td align="left">7901</td><td char="." align="char">0.855</td><td char="." align="char">0.834</td><td char="." align="char">0.888</td><td char="." align="char">0.824</td><td char="." align="char">0.893</td><td char="." align="char">0.869</td><td char="." align="char"><bold>0.896</bold></td></tr><tr><td align="left" rowspan="4"><bold>ELAVL1</bold></td><td align="left">HITS-CLIP</td><td align="left">8595</td><td align="left">8436</td><td char="." align="char">0.955</td><td char="." align="char">0.966</td><td char="." align="char">0.98</td><td char="." align="char">0.966</td><td char="." align="char">0.964</td><td char="." align="char">0.978</td><td char="." align="char"><bold>0.991</bold></td></tr><tr><td align="left">PAR-CLIP (A)</td><td align="left">27,275</td><td align="left">23,974</td><td char="." align="char">0.959</td><td char="." align="char">0.966</td><td char="." align="char">0.972</td><td char="." align="char">0.973</td><td char="." align="char"><bold>0.988</bold></td><td char="." align="char">0.978</td><td char="." align="char">0.965</td></tr><tr><td align="left">PAR-CLIP (B)</td><td align="left">9464</td><td align="left">9283</td><td char="." align="char">0.935</td><td char="." align="char">0.961</td><td char="." align="char">0.961</td><td char="." align="char">0.962</td><td char="." align="char">0.971</td><td char="." align="char">0.98</td><td char="." align="char"><bold>0.987</bold></td></tr><tr><td align="left">PAR-CLIP (C)</td><td align="left">125,202</td><td align="left">113,686</td><td char="." align="char">0.991</td><td char="." align="char">0.994</td><td char="." align="char">0.989</td><td char="." align="char">0.99</td><td char="." align="char">0.979</td><td char="." align="char"><bold>0.996</bold></td><td char="." align="char">0.989</td></tr><tr><td align="left"><bold>EWSR1</bold></td><td align="left">PAR-CLIP</td><td align="left">16,292</td><td align="left">14,720</td><td char="." align="char">0.935</td><td char="." align="char">0.966</td><td char="." align="char">0.969</td><td char="." align="char">0.962</td><td char="." align="char">0.969</td><td char="." align="char">0.971</td><td char="." align="char"><bold>0.972</bold></td></tr><tr><td align="left"><bold>FUS</bold></td><td align="left">PAR-CLIP</td><td align="left">34,581</td><td align="left">31,480</td><td char="." align="char">0.968</td><td char="." align="char">0.98</td><td char="." align="char">0.983</td><td char="." align="char">0.976</td><td char="." align="char">0.985</td><td char="." align="char"><bold>0.988</bold></td><td char="." align="char">0.977</td></tr><tr><td align="left"><bold>hnRNPC</bold></td><td align="left">iCLIP</td><td align="left">21,472</td><td align="left">19,794</td><td char="." align="char">0.952</td><td char="." align="char">0.962</td><td char="." align="char"><bold>0.979</bold></td><td char="." align="char"><bold>0.979</bold></td><td char="." align="char">0.976</td><td char="." align="char">0.978</td><td char="." align="char">0.977</td></tr><tr><td align="left"><bold>IGF2BP1-3</bold></td><td align="left">PAR-CLIP</td><td align="left">8539</td><td align="left">6838</td><td char="." align="char">0.889</td><td char="." align="char">0.879</td><td char="." align="char">0.939</td><td char="." align="char">0.923</td><td char="." align="char"><bold>0.947</bold></td><td char="." align="char">0.943</td><td char="." align="char">0.946</td></tr><tr><td align="left"><bold>MOV10</bold></td><td align="left">PAR-CLIP</td><td align="left">13,793</td><td align="left">12,987</td><td char="." align="char">0.863</td><td char="." align="char">0.854</td><td char="." align="char">0.899</td><td char="." align="char">0.896</td><td char="." align="char">0.916</td><td char="." align="char">0.92</td><td char="." align="char"><bold>0.922</bold></td></tr><tr><td align="left"><bold>PUM2</bold></td><td align="left">PAR-CLIP</td><td align="left">9116</td><td align="left">8227</td><td char="." align="char">0.954</td><td char="." align="char">0.971</td><td char="." align="char">0.964</td><td char="." align="char">0.965</td><td char="." align="char">0.967</td><td char="." align="char">0.965</td><td char="." align="char"><bold>0.972</bold></td></tr><tr><td align="left"><bold>PTB</bold></td><td align="left">HITS-CLIP</td><td align="left">44,574</td><td align="left">43,700</td><td char="." align="char">0.937</td><td char="." align="char"><bold>0.983</bold></td><td char="." align="char">0.944</td><td char="." align="char">0.936</td><td char="." align="char">0.944</td><td char="." align="char">0.953</td><td char="." align="char">0.954</td></tr><tr><td align="left"><bold>QKI</bold></td><td align="left">PAR-CLIP</td><td align="left">10,276</td><td align="left">9142</td><td char="." align="char">0.957</td><td char="." align="char">0.983</td><td char="." align="char">0.973</td><td char="." align="char">0.965</td><td char="." align="char">0.97</td><td char="." align="char">0.975</td><td char="." align="char"><bold>0.984</bold></td></tr><tr><td align="left"><bold>SFRS1</bold></td><td align="left">HITS-CLIP</td><td align="left">19,438</td><td align="left">17,195</td><td char="." align="char">0.898</td><td char="." align="char">0.931</td><td char="." align="char">0.929</td><td char="." align="char">0.905</td><td char="." align="char"><bold>0.946</bold></td><td char="." align="char">0.945</td><td char="." align="char">0.939</td></tr><tr><td align="left"><bold>TAF15</bold></td><td align="left">PAR-CLIP</td><td align="left">7298</td><td align="left">6606</td><td char="." align="char">0.97</td><td char="." align="char">0.983</td><td char="." align="char">0.978</td><td char="." align="char">0.978</td><td char="." align="char">0.976</td><td char="." align="char"><bold>0.985</bold></td><td char="." align="char"><bold>0.985</bold></td></tr><tr><td align="left"><bold>TDP43</bold></td><td align="left">iCLIP</td><td align="left">92,031</td><td align="left">75,079</td><td char="." align="char">0.874</td><td char="." align="char">0.876</td><td char="." align="char">0.93</td><td char="." align="char">0.935</td><td char="." align="char">0.945</td><td char="." align="char"><bold>0.954</bold></td><td char="." align="char">0.924</td></tr><tr><td align="left"><bold>TIA1</bold></td><td align="left">iCLIP</td><td align="left">18,049</td><td align="left">16,135</td><td char="." align="char">0.861</td><td char="." align="char">0.891</td><td char="." align="char">0.929</td><td char="." align="char">0.941</td><td char="." align="char">0.937</td><td char="." align="char">0.942</td><td char="." align="char"><bold>0.959</bold></td></tr><tr><td align="left"><bold>TIAL1</bold></td><td align="left">iCLIP</td><td align="left">42,332</td><td align="left">36,652</td><td char="." align="char">0.833</td><td char="." align="char">0.87</td><td char="." align="char">0.922</td><td char="." align="char">0.929</td><td char="." align="char">0.934</td><td char="." align="char">0.946</td><td char="." align="char"><bold>0.95</bold></td></tr><tr><td align="left"><bold>ZC3H7B</bold></td><td align="left">PAR-CLIP</td><td align="left">20,962</td><td align="left">20,018</td><td char="." align="char">0.82</td><td char="." align="char">0.796</td><td char="." align="char">0.875</td><td char="." align="char">0.883</td><td char="." align="char">0.907</td><td char="." align="char"><bold>0.914</bold></td><td char="." align="char">0.862</td></tr><tr><td align="left"/><td align="left" colspan="3"><bold>AVERAGE AUROC:</bold></td><td align="left">0.887</td><td align="left">0.903</td><td char="." align="char">0.918</td><td char="." align="char">0.913</td><td char="." align="char">0.931</td><td char="." align="char">0.934</td><td char="." align="char"><bold>0.947</bold></td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec10">
      <title>Importance of network branches beyond sequence</title>
      <p id="Par49">Easily producing Deep Learning models at the state-of-the-art level is the primary objective of ENNGene. However, we are also interested in exploring additional features beyond sequence, namely evolutionary conservation and predicted RNA secondary structure (Fig. <xref rid="Fig3" ref-type="fig">3</xref>). Previously [<xref ref-type="bibr" rid="CR46">46</xref>], we have used a multi-branch approach with the same features to identify small RNA loci, outperforming the state of the art. Both the conservation and secondary structure branches were shown to be important for that task. In the RBP24 dataset presented here, we investigated networks of various configurations, starting from the simple sequence, adding either evolutionary conservation or secondary structure branches, and finally, all three branches together. We identified that adding an evolutionary conservation branch improved the performance of all but five protein datasets (FUS, HNRNPC, ELAVL1—PAR-CLIP C, PTB, and TDP43) that had similar performance with or without the conservation feature. On the contrary, we had not registered improvement in any model when the secondary structure was included.<fig id="Fig3"><label>Fig. 3</label><caption><p>Simplified representation of model architecture. The model in this example was trained on 150 nt long sequences using all three available input types—sequence, secondary structure, and conservation score—each represented by a separate model branch. After the network extracts information from the separate inputs, the branches are concatenated, and the network continues learning interdependencies by looking at the combined information via dense or recurrent layers. Boxes represent individual layers, while the adjacent numbers indicate the data dimensionality. A plain graphical representation of the network architecture is produced and exported by ENNGene for every trained model</p></caption><graphic xlink:href="12864_2022_8414_Fig3_HTML" id="MO3"/></fig></p>
      <p id="Par50">Evolutionary conservation features have been extensively used by machine learning classifiers predating the beginning of DL, along with many other features such as amino acid composition and hydrophobicity, predicted secondary structure, and other global protein features [<xref ref-type="bibr" rid="CR47">47</xref>]. An essential concept in CNNs is that using convolutional layers can bypass the process of derivative feature generation, as the network itself learns how to derive complex features from raw data. However, unlike, for example, a predicted secondary structure, the conservation information can not be derived from the given sequence, and as such, it may provide the network with additional information. The group of authors behind the iDeepV and iDeepE methods [<xref ref-type="bibr" rid="CR19">19</xref>, <xref ref-type="bibr" rid="CR42">42</xref>] showed that in both approaches, they were able to reach state-of-the-art performance on the RBP24 dataset without using secondary structure information. DeepCLIP [<xref ref-type="bibr" rid="CR41">41</xref>] presents a hybrid CNN-RNN network that outperforms structure-based models, as well as the iDeepV and iDeepE models, using sequence data alone. The authors hypothesize that context-dependency can be better modeled implicitly by the recurrent layers rather than by predefined features, such as the predicted secondary structure. However, other models such as DeepRKE [<xref ref-type="bibr" rid="CR31">31</xref>], Deepnet-rbp [<xref ref-type="bibr" rid="CR35">35</xref>], and DLPRB [<xref ref-type="bibr" rid="CR20">20</xref>] show a performance improvement when utilizing secondary structure features in a small fraction of proteins. That emphasizes the need for individually designed architectures for each protein separately. In the case of evolutionary conservation, which is not a derivative feature, it is clear that substantial additional information is indeed given to the network under training. Conservation features have not been used by other DL algorithms tackling this question, probably because of the difficulty of retrieving and preprocessing conservation data. ENNGene’s preprocessing module takes care of this process for the user and makes this important feature available.</p>
      <p id="Par51">It has been previously shown that the combination of derived/hand-crafted and learned features can lead to better performance [<xref ref-type="bibr" rid="CR48">48</xref>]. We have avoided adding more hand-crafted features to retain the generality of ENNGene to deal with genomic questions. We decided to retain the secondary structure feature as it is a commonly used feature that we have found useful in other applications of CNNs [<xref ref-type="bibr" rid="CR46">46</xref>].</p>
    </sec>
    <sec id="Sec11">
      <title>Interpretation of predictions</title>
      <p id="Par52">To gain an insight into what a DL model has learned, many studies utilizing CNNs use a heuristic based on convolution kernel analysis [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR36">36</xref>, <xref ref-type="bibr" rid="CR41">41</xref>]. This approach is characteristic for the Genomics field, as it allows one to visualize a learned pattern as a pseudo motif-representing position weight matrix [<xref ref-type="bibr" rid="CR49">49</xref>]. However, for the full understanding of the relationship between an input sequence and an output prediction, simply analyzing filters of one convolutional layer is not sufficient.</p>
      <p id="Par53">To evaluate the importance of each nucleotide, [<xref ref-type="bibr" rid="CR3">3</xref>] applied input modification, also known in the field as an in silico mutagenesis. In this approach, each nucleotide is substituted by every other possible nucleotide, and a prediction is re-calculated for every ‘mutated’ sequence to identify the essential parts. Such an exhaustive input perturbation involves very high computational costs. Increasing the number of nucleotides to be perturbed exponentially increases the computational time needed to calculate effects. Therefore, in most cases, only a part of the sequence is modified, based either on random selection or on a previously defined motif, and important parts of the sequence might be completely ignored [<xref ref-type="bibr" rid="CR6">6</xref>].</p>
      <p id="Par54">Gradient-based approaches [<xref ref-type="bibr" rid="CR50">50</xref>–<xref ref-type="bibr" rid="CR56">56</xref>], to the contrary, are not only more computationally efficient but provide information about the whole sequence, allowing to find previously unexpected essential sections in the sequence. One issue of the earlier methods [<xref ref-type="bibr" rid="CR50">50</xref>, <xref ref-type="bibr" rid="CR51">51</xref>] is neuron saturation. Given a sequence with two binding regions, such an algorithm would assign a low score to both regions, as each such region is not individually important enough for the prediction. To address the saturation problem, methods like DeepLift [<xref ref-type="bibr" rid="CR55">55</xref>] and Integrated Gradients [<xref ref-type="bibr" rid="CR11">11</xref>] use a background reference to properly distinguish the crucial elements from noise. Integrated Gradients, the method adopted by ENNGene, gained popularity due to its mathematical and theoretical justifications and computational efficiency compared to alternative approaches. IGs can be applied to any differentiable model, not strictly focusing on the CNNs, and are suitable for large networks and feature spaces without the undesirable computational overhead. Only one recent RBP target site classifier [<xref ref-type="bibr" rid="CR39">39</xref>] utilizes the IGs to see what parts of the sequence and region, the two input types adopted in the study, were responsible for the predicted category. Similarly, for ENNGene, we use IGs to visualize important parts of the input within all branches of the trained model.</p>
    </sec>
    <sec id="Sec12">
      <title>Future development</title>
      <p id="Par55">At this point, ENNGene allows the production of state-of-the-art multi-branch CNN and CNN-RNN models via a user-friendly interface while providing one level of interpretation of the produced results. Despite the ease of training new models with ENNGene, automatic identification of the optimal model architecture and hyperparameter search would be an important future step. Neural Architecture Search (NAS) is an automated search of an optimal architecture on given data, using predefined building blocks. Using NAS, the network building blocks are handled similarly to other hyperparameters. Since around 2015, there are already several different NAS techniques [<xref ref-type="bibr" rid="CR57">57</xref>]. It has been shown that NAS can be on par or outperform hand-designed architectures [<xref ref-type="bibr" rid="CR58">58</xref>, <xref ref-type="bibr" rid="CR59">59</xref>]. Recently, NAS was implemented on genomics data, improving processing time and complexity of use [<xref ref-type="bibr" rid="CR60">60</xref>]. Even with the current computational power at hand, it is still a very resource-demanding process outside most research groups’ capabilities. We aim to incorporate some type of NAS in the future of ENNGene, as computational resources become more readily available and methods for NAS more efficient.</p>
      <p id="Par56">Currently, the process of manually tuning hyperparameters is fairly simple. Users can use the option to load the parameters from any previous session, change just the chosen parameters without setting up the rest, and start training again within moments. Nevertheless, we would like to add a separate module dedicated to automated hyperparameter tuning. The new module would provide options such as random or grid search of user-defined parameter space.</p>
      <p id="Par57">Finally, to support a broader user base in the future, we are considering setting up a dedicated server with the most common genome references available. That way, users would need to provide only the interval files, making the usage of ENNGene even easier. Depending on the current costs and funds available, the server might provide the GPU power, speeding up the NN training for the users with no other access to it.</p>
    </sec>
  </sec>
  <sec id="Sec13">
    <title>Conclusions</title>
    <p id="Par58">As genomic data generation accelerates, researchers in the field will increasingly require powerful but easy-to-use data science and machine learning methods. In this work, we have presented ENNGene, a tool that allows the development and interpretation of Deep Learning models without advanced programming knowledge. We believe that ENNGene will empower Genomics researchers to explore their data using the powerful models that ENNGene can produce. We have demonstrated these abilities by building state-of-the-art models for a well-known and competitive benchmark of RNA Binding Protein target sites. It is our intention to support ENNGene and its user base with continuous development and improvement over the following years, making it an important tool for the Genomics research community.</p>
    <sec id="Sec14">
      <title>Availability and requirements</title>
      <p id="Par59"><bold>Project name</bold>: ENNGene.</p>
      <p id="Par60"><bold>Project home page</bold>: <ext-link ext-link-type="uri" xlink:href="https://github.com/ML-Bioinfo-CEITEC/ENNGene">https://github.com/ML-Bioinfo-CEITEC/ENNGene</ext-link></p>
      <p id="Par61"><bold>Operating system(s)</bold>: Linux.</p>
      <p id="Par62"><bold>Programming language</bold>: Python 3.</p>
      <p id="Par63"><bold>Other requirements</bold>: Anaconda, web browser.</p>
      <p id="Par64"><bold>License</bold>: GNU Affero General Public License v3.0</p>
      <p id="Par65"><bold>Any restrictions to use by non-academics</bold>: None above the license.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec15">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12864_2022_8414_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1.</bold> Documentation. Complete documentation of the current version of the ENNGene application (v1.2.2) in pdf format. Each module and its functions, together with all the parameters and available options, are described in the documentation.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="12864_2022_8414_MOESM2_ESM.xlsx">
            <caption>
              <p><bold>Additional file 2.</bold> RBP24 model parameters. Complete list of the ENNGene parameters used to obtain the final models. Parameters from Preprocessing, Training, and Evaluation modules are reported and ensure full reproducibility of the results.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="12864_2022_8414_MOESM3_ESM.pdf">
            <caption>
              <p><bold>Additional file 3.</bold> RBP24 ROC curves. ROC curves generated by ENNGene for each experiment in the RBP24 dataset. The ROC curves are based on the evaluation of the final models on the leave-out data. The AUROC values of the corresponding ROC curves were used for comparison with the other publications and their reported AUROC values.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>AUROC</term>
        <def>
          <p id="Par4">Area Under the Receiver Operating Characteristic curve</p>
        </def>
      </def-item>
      <def-item>
        <term>BED</term>
        <def>
          <p id="Par5">Browser Extensible Data</p>
        </def>
      </def-item>
      <def-item>
        <term>BLSTM</term>
        <def>
          <p id="Par6">Bidirectional Long Short-Term Memory</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par7">Convolutional Neural Network</p>
        </def>
      </def-item>
      <def-item>
        <term>CPU</term>
        <def>
          <p id="Par8">Central Processing Unit</p>
        </def>
      </def-item>
      <def-item>
        <term>DBN</term>
        <def>
          <p id="Par9">Deep Belief Network</p>
        </def>
      </def-item>
      <def-item>
        <term>DL</term>
        <def>
          <p id="Par10">Deep Learning</p>
        </def>
      </def-item>
      <def-item>
        <term>GPU</term>
        <def>
          <p id="Par11">Graphics Processing Unit</p>
        </def>
      </def-item>
      <def-item>
        <term>GRU</term>
        <def>
          <p id="Par12">Gated Recurrent Unit</p>
        </def>
      </def-item>
      <def-item>
        <term>IGs</term>
        <def>
          <p id="Par13">Integrated Gradients</p>
        </def>
      </def-item>
      <def-item>
        <term>LSTM</term>
        <def>
          <p id="Par14">Long Short-Term Memory</p>
        </def>
      </def-item>
      <def-item>
        <term>ML</term>
        <def>
          <p id="Par15">Machine Learning</p>
        </def>
      </def-item>
      <def-item>
        <term>NAS</term>
        <def>
          <p id="Par16">Neural Architecture Search</p>
        </def>
      </def-item>
      <def-item>
        <term>RBP</term>
        <def>
          <p id="Par17">RNA-Binding Protein</p>
        </def>
      </def-item>
      <def-item>
        <term>RNN</term>
        <def>
          <p id="Par18">Recurrent Neural Network</p>
        </def>
      </def-item>
      <def-item>
        <term>ROC</term>
        <def>
          <p id="Par19">Receiver Operating Characteristic</p>
        </def>
      </def-item>
      <def-item>
        <term>SGD</term>
        <def>
          <p id="Par20">Stochastic Gradient Descent</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>EC created the ENNGene application. FJ and JP implemented the Integrated Gradients for ENNGene. OV created the installation script. EC and OV conducted the RBP24 use case. EC, OV, and TM tested the application. EC and PA prepared the manuscript. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This research was funded by grant Horizon 2020 Widening Fellowship by Horizon 2020 (H2020-WF-01–2018: 867414) to PA, and grant “Postdoc2@MUNI” by Operační program Výzkum, vývoj a vzdělávání (OPVVV, No. CZ.02.2.69/0.0/0.0/18 053/0016952) to TM. The funding bodies played no role in the design of the study and collection, analysis, and interpretation of data and in writing the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The datasets generated and analysed during the study are available in the GitHub repository at <ext-link ext-link-type="uri" xlink:href="https://github.com/ML-Bioinfo-CEITEC/ENNGene/tree/master/RBP24">https://github.com/ML-Bioinfo-CEITEC/ENNGene/tree/master/RBP24</ext-link>.</p>
    <p>The original fasta files used to obtain the genomic coordinates are available in GraphProt repository at <ext-link ext-link-type="uri" xlink:href="http://www.bioinf.uni-freiburg.de/Software/GraphProt/">http://www.bioinf.uni-freiburg.de/Software/GraphProt/</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par66">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par67">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par68">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rosenblatt</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>The perceptron: a probabilistic model for information storage and organization in the brain</article-title>
        <source>Psychol Rev</source>
        <year>1958</year>
        <volume>65</volume>
        <fpage>386</fpage>
        <lpage>408</lpage>
        <pub-id pub-id-type="doi">10.1037/h0042519</pub-id>
        <pub-id pub-id-type="pmid">13602029</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>LeCun</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Deep learning</article-title>
        <source>Nature</source>
        <year>2015</year>
        <volume>521</volume>
        <fpage>436</fpage>
        <lpage>444</lpage>
        <pub-id pub-id-type="doi">10.1038/nature14539</pub-id>
        <pub-id pub-id-type="pmid">26017442</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alipanahi</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Delong</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Weirauch</surname>
            <given-names>MT</given-names>
          </name>
          <name>
            <surname>Frey</surname>
            <given-names>BJ</given-names>
          </name>
        </person-group>
        <article-title>Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning</article-title>
        <source>Nat Biotechnol</source>
        <year>2015</year>
        <volume>33</volume>
        <fpage>831</fpage>
        <lpage>838</lpage>
        <pub-id pub-id-type="doi">10.1038/nbt.3300</pub-id>
        <pub-id pub-id-type="pmid">26213851</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Troyanskaya</surname>
            <given-names>OG</given-names>
          </name>
        </person-group>
        <article-title>Predicting effects of noncoding variants with deep learning-based sequence model</article-title>
        <source>Nat Methods</source>
        <year>2015</year>
        <volume>12</volume>
        <fpage>931</fpage>
        <lpage>934</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.3547</pub-id>
        <pub-id pub-id-type="pmid">26301843</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kelley</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>Snoek</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Rinn</surname>
            <given-names>JL</given-names>
          </name>
        </person-group>
        <article-title>Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks</article-title>
        <source>Genome Res</source>
        <year>2016</year>
        <volume>26</volume>
        <fpage>990</fpage>
        <lpage>999</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.200535.115</pub-id>
        <pub-id pub-id-type="pmid">27197224</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Eraslan</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Avsec</surname>
            <given-names>Ž</given-names>
          </name>
          <name>
            <surname>Gagneur</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Theis</surname>
            <given-names>FJ</given-names>
          </name>
        </person-group>
        <article-title>Deep learning: new computational modelling techniques for genomics</article-title>
        <source>Nat Rev Genet</source>
        <year>2019</year>
        <volume>20</volume>
        <fpage>389</fpage>
        <lpage>403</lpage>
        <pub-id pub-id-type="doi">10.1038/s41576-019-0122-6</pub-id>
        <pub-id pub-id-type="pmid">30971806</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Budach</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Marsico</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>pysster: classification of biological sequences by learning sequence and structure motifs with convolutional neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>3035</fpage>
        <lpage>3037</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty222</pub-id>
        <pub-id pub-id-type="pmid">29659719</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>KM</given-names>
          </name>
          <name>
            <surname>Cofer</surname>
            <given-names>EM</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Troyanskaya</surname>
            <given-names>OG</given-names>
          </name>
        </person-group>
        <article-title>Selene: a PyTorch-based deep learning library for sequence data</article-title>
        <source>Nat Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <fpage>315</fpage>
        <lpage>318</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-019-0360-8</pub-id>
        <pub-id pub-id-type="pmid">30923381</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kopp</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Monti</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Tamburrini</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ohler</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Akalin</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Deep learning for genomics using Janggu</article-title>
        <source>Nat Commun</source>
        <year>2020</year>
        <volume>11</volume>
        <fpage>3488</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-020-17155-y</pub-id>
        <pub-id pub-id-type="pmid">32661261</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">Paszke A, Gross S, Massa F, Lerer A, Bradbury J, Chanan G, et al. PyTorch: An Imperative Style, High-Performance Deep Learning Library. In: Wallach H, Larochelle H, Beygelzimer A, d\textquotesingle Alché-Buc F, Fox E, Garnett R, editors. Advances in Neural Information Processing Systems. Curran Associates, Inc.; 2019. <ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf">https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Sundararajan M, Taly A, Yan Q. Axiomatic Attribution for Deep Networks. In: Precup D, Teh YW, editors. Proceedings of the 34th International Conference on Machine Learning. PMLR; 2017. p. 3319–28. <ext-link ext-link-type="uri" xlink:href="http://proceedings.mlr.press/v70/sundararajan17a/sundararajan17a.pdf">http://proceedings.mlr.press/v70/sundararajan17a/sundararajan17a.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Maticzka</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Lange</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Costa</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Backofen</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>GraphProt: modeling binding preferences of RNA-binding proteins</article-title>
        <source>Genome Biol</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>R17</fpage>
        <pub-id pub-id-type="doi">10.1186/gb-2014-15-1-r17</pub-id>
        <pub-id pub-id-type="pmid">24451197</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Abadi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Chu</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Goodfellow</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>McMahan</surname>
            <given-names>HB</given-names>
          </name>
          <name>
            <surname>Mironov</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Talwar</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Deep Learning with Differential Privacy</article-title>
        <source>Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security</source>
        <year>2016</year>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>Association for Computing Machinery</publisher-name>
        <fpage>308</fpage>
        <lpage>18</lpage>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Buber</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Diri</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Performance Analysis and CPU vs GPU Comparison for Deep Learning</article-title>
        <source>2018 6th International Conference on Control Engineering Information Technology (CEIT)</source>
        <year>2018</year>
        <fpage>1</fpage>
        <lpage>6</lpage>
      </element-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pollard</surname>
            <given-names>KS</given-names>
          </name>
          <name>
            <surname>Hubisz</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Rosenbloom</surname>
            <given-names>KR</given-names>
          </name>
          <name>
            <surname>Siepel</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Detection of nonneutral substitution rates on mammalian phylogenies</article-title>
        <source>Genome Res</source>
        <year>2010</year>
        <volume>20</volume>
        <fpage>110</fpage>
        <lpage>121</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.097857.109</pub-id>
        <pub-id pub-id-type="pmid">19858363</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Howe</surname>
            <given-names>KL</given-names>
          </name>
          <name>
            <surname>Achuthan</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Allen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Allen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Alvarez-Jarreta</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Amode</surname>
            <given-names>MR</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Ensembl 2021</article-title>
        <source>Nucleic Acids Res</source>
        <year>2021</year>
        <volume>49</volume>
        <fpage>D884</fpage>
        <lpage>D891</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkaa942</pub-id>
        <pub-id pub-id-type="pmid">33137190</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Karolchik</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Hinrichs</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>Furey</surname>
            <given-names>TS</given-names>
          </name>
          <name>
            <surname>Roskin</surname>
            <given-names>KM</given-names>
          </name>
          <name>
            <surname>Sugnet</surname>
            <given-names>CW</given-names>
          </name>
          <name>
            <surname>Haussler</surname>
            <given-names>D</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>The UCSC Table Browser data retrieval tool</article-title>
        <source>Nucleic Acids Res</source>
        <year>2004</year>
        <volume>32 Database issue</volume>
        <fpage>D493</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkh103</pub-id>
        <pub-id pub-id-type="pmid">14681465</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lorenz</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Bernhart</surname>
            <given-names>SH</given-names>
          </name>
          <name>
            <surname>HönerZuSiederdissen</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Tafer</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Flamm</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Stadler</surname>
            <given-names>PF</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>ViennaRNA Package 20</article-title>
        <source>Algorithms Mol Biol</source>
        <year>2011</year>
        <volume>6</volume>
        <fpage>26</fpage>
        <pub-id pub-id-type="doi">10.1186/1748-7188-6-26</pub-id>
        <pub-id pub-id-type="pmid">22115189</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H-B</given-names>
          </name>
        </person-group>
        <article-title>Learning distributed representations of RNA sequences and its application for predicting RNA-protein binding sites with a convolutional neural network</article-title>
        <source>Neurocomputing</source>
        <year>2018</year>
        <volume>305</volume>
        <fpage>51</fpage>
        <lpage>58</lpage>
        <pub-id pub-id-type="doi">10.1016/j.neucom.2018.04.036</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ben-Bassat</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Chor</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Orenstein</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>A deep neural network approach for learning intrinsic protein-RNA binding preferences</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>i638</fpage>
        <lpage>i646</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty600</pub-id>
        <pub-id pub-id-type="pmid">30423078</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Alsallakh B, Kokhlikyan N, Miglani V, Yuan J, Reblitz-Richardson O. Mind the Pad -- CNNs can Develop Blind Spots. arXiv [cs.CV]. 2020. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2010.02178">http://arxiv.org/abs/2010.02178</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Johnson</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Khoshgoftaar</surname>
            <given-names>TM</given-names>
          </name>
        </person-group>
        <article-title>Survey on deep learning with class imbalance</article-title>
        <source>Journal of Big Data</source>
        <year>2019</year>
        <volume>6</volume>
        <fpage>1</fpage>
        <lpage>54</lpage>
        <pub-id pub-id-type="doi">10.1186/s40537-018-0162-3</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Sutskever I, Martens J, Dahl G, Geoffrey H. On the importance of initialization and momentum in deep learning. In: ICML’13: Proceedings of the 30th International Conference on International Conference on Machine Learning. 2013. p. III – 1139 – III – 1147. <ext-link ext-link-type="uri" xlink:href="http://proceedings.mlr.press/v28/sutskever13.pdf">http://proceedings.mlr.press/v28/sutskever13.pdf</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Tieleman T, Hinton G. Lecture 6.5-rmsprop: Divide the Gradient by a Running Average of Its Recent Magnitude. 2012. <ext-link ext-link-type="uri" xlink:href="https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf</ext-link>. Accessed 1 Nov 2021.</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Kingma DP, Ba J. Adam: A Method for Stochastic Optimization. arXiv [cs.LG]. 2014. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1412.6980">http://arxiv.org/abs/1412.6980</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Smith LN. Cyclical Learning Rates for Training Neural Networks. 2015. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1506.01186">http://arxiv.org/abs/1506.01186</ext-link>. Accessed 1 Nov 2021.</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Chung J, Gulcehre C, Cho K, Bengio Y. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling. 2014. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1412.3555">http://arxiv.org/abs/1412.3555</ext-link>. Accessed 1 Nov 2021.</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hochreiter</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Long Short-Term Memory</article-title>
        <source>Neural Comput</source>
        <year>1997</year>
        <volume>9</volume>
        <fpage>1735</fpage>
        <lpage>1780</lpage>
        <pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id>
        <pub-id pub-id-type="pmid">9377276</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
        <source>J Mach Learn Res</source>
        <year>2014</year>
        <volume>15</volume>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Ioffe S, Szegedy C. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. arXiv [cs.LG]. 2015. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1502.03167">http://arxiv.org/abs/1502.03167</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deng</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Deep neural networks for inferring binding sites of RNA-binding proteins by using distributed representations of RNA primary sequence and secondary structure</article-title>
        <source>BMC Genomics</source>
        <year>2020</year>
        <volume>21</volume>
        <issue>Suppl 13</issue>
        <fpage>866</fpage>
        <pub-id pub-id-type="doi">10.1186/s12864-020-07239-w</pub-id>
        <pub-id pub-id-type="pmid">33334313</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H-B</given-names>
          </name>
        </person-group>
        <article-title>RBPsuite: RNA-protein binding sites prediction suite based on deep learning</article-title>
        <source>BMC Genomics</source>
        <year>2020</year>
        <volume>21</volume>
        <fpage>884</fpage>
        <pub-id pub-id-type="doi">10.1186/s12864-020-07291-6</pub-id>
        <pub-id pub-id-type="pmid">33297946</pub-id>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Pan X, Rijnbeek P, Yan J, Shen H-B. Prediction of RNA-protein sequence and structure binding preferences using deep convolutional and recurrent neural networks. BMC Genomics. 2018;19. 10.1186/s12864-018-4889-1.</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H-B</given-names>
          </name>
        </person-group>
        <article-title>CRIP: predicting circRNA-RBP-binding sites using a codon-based encoding and hybrid deep neural networks</article-title>
        <source>RNA</source>
        <year>2019</year>
        <volume>25</volume>
        <fpage>1604</fpage>
        <lpage>1615</lpage>
        <pub-id pub-id-type="doi">10.1261/rna.070565.119</pub-id>
        <pub-id pub-id-type="pmid">31537716</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Gong</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A deep learning framework for modeling structural features of RNA-binding protein targets</article-title>
        <source>Nucleic Acids Res</source>
        <year>2016</year>
        <volume>44</volume>
        <fpage>e32</fpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv1025</pub-id>
        <pub-id pub-id-type="pmid">26467480</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Rijnbeek</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H-B</given-names>
          </name>
        </person-group>
        <article-title>Prediction of RNA-protein sequence and structure binding preferences using deep convolutional and recurrent neural networks</article-title>
        <source>BMC Genomics</source>
        <year>2018</year>
        <volume>19</volume>
        <fpage>511</fpage>
        <pub-id pub-id-type="doi">10.1186/s12864-018-4889-1</pub-id>
        <pub-id pub-id-type="pmid">29970003</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Du Z, Xiao X, Uversky VN. DeepA-RBPBS: A hybrid convolution and recurrent neural network combined with attention mechanism for predicting RBP binding site. J Biomol Struct Dyn. 2020;1–9. <ext-link ext-link-type="uri" xlink:href="https://pubmed.ncbi.nlm.nih.gov/33272122/">https://pubmed.ncbi.nlm.nih.gov/33272122/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H-B</given-names>
          </name>
        </person-group>
        <article-title>RNA-protein binding motifs mining with a new hybrid deep learning based cross-domain knowledge integration approach</article-title>
        <source>BMC Bioinformatics</source>
        <year>2017</year>
        <volume>18</volume>
        <fpage>136</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-017-1561-8</pub-id>
        <pub-id pub-id-type="pmid">28245811</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ghanbari</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ohler</surname>
            <given-names>U</given-names>
          </name>
        </person-group>
        <article-title>Deep neural networks for interpreting RNA-binding protein target preferences</article-title>
        <source>Genome Res</source>
        <year>2020</year>
        <volume>30</volume>
        <fpage>214</fpage>
        <lpage>226</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.247494.118</pub-id>
        <pub-id pub-id-type="pmid">31992613</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Park</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Han</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Discovering protein-binding RNA motifs with a generative model of RNA sequences</article-title>
        <source>Comput Biol Chem</source>
        <year>2020</year>
        <volume>84</volume>
        <fpage>107171</fpage>
        <pub-id pub-id-type="doi">10.1016/j.compbiolchem.2019.107171</pub-id>
        <pub-id pub-id-type="pmid">31931434</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grønning</surname>
            <given-names>AGB</given-names>
          </name>
          <name>
            <surname>Doktor</surname>
            <given-names>TK</given-names>
          </name>
          <name>
            <surname>Larsen</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Petersen</surname>
            <given-names>USS</given-names>
          </name>
          <name>
            <surname>Holm</surname>
            <given-names>LL</given-names>
          </name>
          <name>
            <surname>Bruun</surname>
            <given-names>GH</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DeepCLIP: predicting the effect of mutations on protein–RNA binding with deep learning</article-title>
        <source>Nucleic Acids Res</source>
        <year>2020</year>
        <volume>48</volume>
        <fpage>7099</fpage>
        <lpage>7118</lpage>
        <?supplied-pmid 32558887?>
        <pub-id pub-id-type="pmid">32558887</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H-B</given-names>
          </name>
        </person-group>
        <article-title>Predicting RNA–protein binding sites and motifs through combining local and global deep convolutional neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <fpage>3427</fpage>
        <lpage>3436</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty364</pub-id>
        <pub-id pub-id-type="pmid">29722865</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">Yang H, Deng Z, Pan X, Shen H-B, Choi K-S, Wang L, et al. RNA-binding protein recognition based on multi-view deep feature and multi-label learning. Brief Bioinform. 2021;22. 10.1093/bib/bbaa174.</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lange</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Maticzka</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Möhl</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Gagnon</surname>
            <given-names>JN</given-names>
          </name>
          <name>
            <surname>Brown</surname>
            <given-names>CM</given-names>
          </name>
          <name>
            <surname>Backofen</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Global or local? Predicting secondary structure and accessibility in mRNAs</article-title>
        <source>Nucleic Acids Res</source>
        <year>2012</year>
        <volume>40</volume>
        <fpage>5215</fpage>
        <lpage>5226</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gks181</pub-id>
        <pub-id pub-id-type="pmid">22373926</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Siepel</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bejerano</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Pedersen</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Hinrichs</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>Hou</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Rosenbloom</surname>
            <given-names>K</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Evolutionarily conserved elements in vertebrate, insect, worm, and yeast genomes</article-title>
        <source>Genome Res</source>
        <year>2005</year>
        <volume>15</volume>
        <fpage>1034</fpage>
        <lpage>1050</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.3715005</pub-id>
        <pub-id pub-id-type="pmid">16024819</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Georgakilas</surname>
            <given-names>GK</given-names>
          </name>
          <name>
            <surname>Grioni</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Liakos</surname>
            <given-names>KG</given-names>
          </name>
          <name>
            <surname>Chalupova</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Plessas</surname>
            <given-names>FC</given-names>
          </name>
          <name>
            <surname>Alexiou</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Multi-branch Convolutional Neural Network for Identification of Small Non-coding RNA genomic loci</article-title>
        <source>Sci Rep</source>
        <year>2020</year>
        <volume>10</volume>
        <fpage>9486</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-020-66454-3</pub-id>
        <pub-id pub-id-type="pmid">32528107</pub-id>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Si</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cui</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>computational prediction of RNA-Binding proteins and binding sites</article-title>
        <source>Int J Mol Sci</source>
        <year>2015</year>
        <volume>16</volume>
        <fpage>26303</fpage>
        <lpage>26317</lpage>
        <pub-id pub-id-type="doi">10.3390/ijms161125952</pub-id>
        <pub-id pub-id-type="pmid">26540053</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nanni</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Ghidoni</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Brahnam</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Handcrafted vs. non-handcrafted features for computer vision classification</article-title>
        <source>Pattern Recognit</source>
        <year>2017</year>
        <volume>71</volume>
        <fpage>158</fpage>
        <lpage>72</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patcog.2017.05.025</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <mixed-citation publication-type="other">Talukder A, Barham C, Li X, Hu H. Interpretation of deep learning in genomics and epigenomics. Briefings in Bioinformatics. 2021;22. 10.1093/bib/bbaa177.</mixed-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <mixed-citation publication-type="other">Simonyan K, Vedaldi A, Zisserman A. Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps. arXiv [cs.CV]. 2013. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1312.6034">http://arxiv.org/abs/1312.6034</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <mixed-citation publication-type="other">Zeiler MD, Fergus R. Visualizing and Understanding Convolutional Networks. In: Computer Vision – ECCV 2014. Springer International Publishing; 2014. p. 818–33. <ext-link ext-link-type="uri" xlink:href="https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53">https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <mixed-citation publication-type="other">Smilkov D, Thorat N, Kim B, Viégas F, Wattenberg M. SmoothGrad: removing noise by adding noise. arXiv [cs.LG]. 2017. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1706.03825">http://arxiv.org/abs/1706.03825</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bach</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Binder</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Montavon</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Klauschen</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Müller</surname>
            <given-names>K-R</given-names>
          </name>
          <name>
            <surname>Samek</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation</article-title>
        <source>PLoS One</source>
        <year>2015</year>
        <volume>10</volume>
        <fpage>e0130140</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0130140</pub-id>
        <pub-id pub-id-type="pmid">26161953</pub-id>
      </element-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Montavon</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Lapuschkin</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Binder</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Samek</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Müller</surname>
            <given-names>K-R</given-names>
          </name>
        </person-group>
        <article-title>Explaining nonlinear classification decisions with deep Taylor decomposition</article-title>
        <source>Pattern Recognit</source>
        <year>2017</year>
        <volume>65</volume>
        <fpage>211</fpage>
        <lpage>222</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patcog.2016.11.008</pub-id>
      </element-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <mixed-citation publication-type="other">Shrikumar A, Greenside P, Shcherbina A, Kundaje A. Not Just a Black Box: Learning Important Features Through Propagating Activation Differences. arXiv [cs.LG]. 2016. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1605.01713">http://arxiv.org/abs/1605.01713</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR56">
      <label>56.</label>
      <mixed-citation publication-type="other">Sundararajan M, Taly A, Yan Q. Axiomatic Attribution for Deep Networks. arXiv [cs.LG]. 2017. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1703.01365">http://arxiv.org/abs/1703.01365</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR57">
      <label>57.</label>
      <mixed-citation publication-type="other">Elsken T, Metzen JH, Hutter F. Neural Architecture Search: A Survey. arXiv [stat.ML]. 2018. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1808.05377">http://arxiv.org/abs/1808.05377</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR58">
      <label>58.</label>
      <mixed-citation publication-type="other">Zoph B, Le QV. Neural Architecture Search with Reinforcement Learning. arXiv [cs.LG]. 2016. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1611.01578">http://arxiv.org/abs/1611.01578</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR59">
      <label>59.</label>
      <mixed-citation publication-type="other">Zoph B, Vasudevan V, Shlens J, Le QV. Learning Transferable Architectures for Scalable Image Recognition. arXiv [cs.CV]. 2017. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1707.07012">http://arxiv.org/abs/1707.07012</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR60">
      <label>60.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>CY</given-names>
          </name>
          <name>
            <surname>Theesfeld</surname>
            <given-names>CL</given-names>
          </name>
          <name>
            <surname>Troyanskaya</surname>
            <given-names>OG</given-names>
          </name>
        </person-group>
        <article-title>An automated framework for efficiently designing deep convolutional neural networks in genomics</article-title>
        <source>Nature Machine Intelligence</source>
        <year>2021</year>
        <volume>3</volume>
        <fpage>392</fpage>
        <lpage>400</lpage>
        <pub-id pub-id-type="doi">10.1038/s42256-021-00316-z</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
