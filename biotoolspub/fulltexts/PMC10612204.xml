<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10612204</article-id>
    <article-id pub-id-type="publisher-id">5530</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-023-05530-7</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SeQual-Stream: approaching stream processing to quality control of NGS datasets</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Castellanos-Rodríguez</surname>
          <given-names>Óscar</given-names>
        </name>
        <address>
          <email>oscar.castellanos@udc.es</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Expósito</surname>
          <given-names>Roberto R.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Touriño</surname>
          <given-names>Juan</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01qckj285</institution-id><institution-id institution-id-type="GRID">grid.8073.c</institution-id><institution-id institution-id-type="ISNI">0000 0001 2176 8535</institution-id><institution>Universidade da Coruña, CITIC, </institution><institution>Computer Architecture Group, Campus de Elviña, </institution></institution-wrap>15071 A Coruña, Spain </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>27</day>
      <month>10</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>27</day>
      <month>10</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>24</volume>
    <elocation-id>403</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>12</day>
        <month>10</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Quality control of DNA sequences is an important data preprocessing step in many genomic analyses. However, all existing parallel tools for this purpose are based on a batch processing model, needing to have the complete genetic dataset before processing can even begin. This limitation clearly hinders quality control performance in those scenarios where the dataset must be downloaded from a remote repository and/or copied to a distributed file system for its parallel processing.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">In this paper we present SeQual-Stream, a streaming tool that allows performing multiple quality control operations on genomic datasets in a fast, distributed and scalable way. To do so, our approach relies on the Apache Spark framework and the Hadoop Distributed File System (HDFS) to fully exploit the stream paradigm and accelerate the preprocessing of large datasets as they are being downloaded and/or copied to HDFS. The experimental results have shown significant improvements in the execution times of SeQual-Stream when compared to a batch processing tool with similar quality control features, providing a maximum speedup of 2.7<inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M2"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq1.gif"/></alternatives></inline-formula> when processing a dataset with more than 250 million DNA sequences, while also demonstrating good scalability features.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p id="Par3">Our solution provides a more scalable and higher performance way to carry out quality control of large genomic datasets by taking advantage of stream processing features. The tool is distributed as free open-source software released under the GNU AGPLv3 license and is publicly available to download at <ext-link ext-link-type="uri" xlink:href="https://github.com/UDC-GAC/SeQual-Stream">https://github.com/UDC-GAC/SeQual-Stream</ext-link>.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Quality control</kwd>
      <kwd>Big data</kwd>
      <kwd>Stream processing</kwd>
      <kwd>Apache Spark</kwd>
      <kwd>Next generation sequencing (NGS)</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Xunta de Galicia and FEDER funds of the European Union</institution>
        </funding-source>
        <award-id>ED431G 2019/01</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100010801</institution-id>
            <institution>Xunta de Galicia</institution>
          </institution-wrap>
        </funding-source>
        <award-id>ED481A 2022/067</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004837</institution-id>
            <institution>Ministerio de Ciencia e Innovación</institution>
          </institution-wrap>
        </funding-source>
        <award-id>PID2019-104184RB-I00 / AEI / 10.13039 / 501100011033</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© BioMed Central Ltd., part of Springer Nature 2023</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par9">Obtaining DNA sequences from living beings is usually the first step in the studies developed by biologists and bioinformaticians. The continuous development of Next Generation Sequencing (NGS) technologies [<xref ref-type="bibr" rid="CR1">1</xref>] during the last decade has led to a vertiginous increase in the amount of available genomic data. Hundreds of millions of sequences (the so-called reads) can now be generated in a single experiment at a drastically reduced cost. However, the accuracy of current NGS platforms is not high in all cases. The quality of downstream analyses may be affected because of the artifacts introduced in some DNA fragments during the sequencing process [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>], regardless of the NGS platform. Therefore, quality control is an essential preprocessing step for raw NGS data [<xref ref-type="bibr" rid="CR4">4</xref>], removing or modifying those input reads that are not considered useful.</p>
    <p id="Par10">In this paper we introduce SeQual-Stream, a parallel tool implemented in Java that allows performing multiple quality control operations (e.g., trimming, filtering) on large genomic datasets in a distributed and scalable way. To do so, it takes full advantage of the Apache Spark Big Data framework [<xref ref-type="bibr" rid="CR5">5</xref>] together with the Hadoop Distributed File System (HDFS) [<xref ref-type="bibr" rid="CR6">6</xref>]. Up to our knowledge, all existing parallel quality control tools operate on a batch processing model, which means that they require the entire input dataset before any data processing can begin. This poses a performance constraint, as downloading the data from a remote repository and copying them to a distributed file system such as HDFS for parallel processing are costly operations that significantly delay the start of the quality control. This problem is especially relevant in the NGS context as the size of the genomic datasets is continuously increasing, which demands more efficient processing modes. To overcome this issue, SeQual-Stream has been implemented upon the Spark Structured Streaming API [<xref ref-type="bibr" rid="CR7">7</xref>], in order to apply the quality control operations to the input reads as the data are being downloaded from a remote location (e.g., a web repository) and/or copied to HDFS. This stream-based processing mode significantly reduces runtimes by enabling efficient overlapping of download and copy operations to HDFS with the actual data processing performed by SeQual-Stream.</p>
    <p id="Par11">The main contributions of this paper over the state of the art are the following:<list list-type="bullet"><list-item><p id="Par12">Up to our knowledge, we introduce the first quality control tool that can exploit the stream processing model to accelerate the preprocessing of raw NGS datasets.</p></list-item><list-item><p id="Par13">We conduct an extensive experimental evaluation on two cluster testbeds using publicly available real-world datasets, both to demonstrate the performance benefits of our approach compared to a batch processing quality control tool and to analyze its scalability.</p></list-item><list-item><p id="Par14">SeQual-Stream is implemented in “pure” (100%) Java code in order to maximize cross-platform portability, whereas supporting standard unaligned sequence formats (FASTQ/FASTA). The tool is publicly available under a GNU AGPLv3 license.</p></list-item></list></p>
    <sec id="Sec2">
      <title>Quality control</title>
      <p id="Par15">Current NGS technologies can generate a huge number of DNA segments massively and in parallel, in less time and at a lower cost per base than previous platforms. However, they also introduce errors in some sequences, making them not useful for downstream analyses. So, quality control consists of removing those sequences or modifying them to be useful in order to improve subsequent processing (e.g., sequence alignment). Multiple operations can be performed within the context of quality control. For example, different filtering criteria can be applied when removing sequences according to their length (i.e., number of bases), the quality scores of the bases, the proportion of content of certain bases, or according to the occurrence of certain base patterns. When modifying sequences, trimming techniques can be used so that they are trimmed, for instance, to a certain average quality or to a maximum length. Another example is formatting techniques, such as the conversion from FASTQ to FASTA or between DNA and RNA, as well as renaming the sequence identifiers, among others.</p>
    </sec>
    <sec id="Sec3">
      <title>Big data</title>
      <p id="Par16">The great development of NGS has led to a significant increase in the amount of genomic data to be processed, making the concept of Big Data a fundamental asset in current biomedicine. Big Data often refers to a massive volume of both structured and unstructured data that is so large and difficult to process using traditional methods and systems. The rise of Big Data is usually associated to novel technologies and algorithms such as MapReduce [<xref ref-type="bibr" rid="CR8">8</xref>], a parallel programming paradigm characterized by being divided into two distinct phases: Map and Reduce. These sub-processes are executed in a distributed manner relying on a cluster of nodes. MapReduce is also the name of the Google’s proprietary implementation, who first proposed the model in 2004, given the need to optimize user search results on the web. To support this type of processing, a distributed data storage system, based on storing data on more than one node, is used. Google proposed the Google File System (GFS) [<xref ref-type="bibr" rid="CR9">9</xref>], a high-performance distributed file system that follows a master/worker architecture. Following this model, other technologies implementing it came to light. Of particular note is the open-source Apache Hadoop framework [<xref ref-type="bibr" rid="CR10">10</xref>]. Hadoop integrates HDFS [<xref ref-type="bibr" rid="CR6">6</xref>] as storage layer to distribute files across the cluster divided into data blocks, thus providing the prior division of the data needed by the Hadoop MapReduce data processing engine, in addition to replicating those blocks to provide fault tolerance. Both MapReduce and Hadoop are intended for batch processing, since they require the input data to be stored completely in a distributed manner before processing begins.</p>
      <sec id="Sec4">
        <title>Apache Spark and stream processing</title>
        <p id="Par17">Apache Spark [<xref ref-type="bibr" rid="CR5">5</xref>] is an open-source, general-purpose framework for distributed processing designed to be simple and fast. Spark emerges as an evolution of Hadoop, which is very limited in terms of processing modes and performance. Some of the improvements that Spark brings over its predecessor are in-memory computing, support for stream processing and the ease to interact with multiple persistent storage systems, such as HDFS or Cassandra [<xref ref-type="bibr" rid="CR11">11</xref>].</p>
        <p id="Par18">Spark provides a fundamental data abstraction for distributed processing: the Resilient Distributed Dataset (RDD) [<xref ref-type="bibr" rid="CR12">12</xref>]. An RDD is defined as a collection of elements partitioned across the cluster nodes and capable of operating in parallel. Two alternatives to RDDs are currently offered by Spark: DataFrames and Datasets [<xref ref-type="bibr" rid="CR13">13</xref>]. DataFrames organize data in columns, similar to a table in a relational database. Unlike RDDs, they allow better handling of structured data and are able to optimize the queries performed. Datasets are an extension of DataFrames and try to combine the advantages of RDDs and DataFrames in the same API, i.e., the ease of use of RDDs and the performance optimization of DataFrames.</p>
        <p id="Par19">The key Spark feature for the development of SeQual-Stream is the support for stream processing by providing the Structured Streaming API [<xref ref-type="bibr" rid="CR7">7</xref>], as opposed to its batch API. Structured Streaming was designed as an evolution of the legacy Spark Streaming API [<xref ref-type="bibr" rid="CR14">14</xref>]. This legacy API represents the continuous data stream with a high-level abstraction called discretized stream (DStream), which is represented internally as a sequence of RDDs. Spark Streaming follows a micro-batch model, consisting of polling the source and dividing the input data into small batches that are processed using the batch API, thus generating batches of processed data. However, Structured Streaming brings several improvements over its predecessor. This API is built on top of the Spark SQL library, using higher-level DataFrames and Datasets as data abstractions. It is also capable of correctly processing data that arrive late to the processing engine. Legacy Spark Streaming only takes into account the timestamp of data reception by Spark, so if an event “a” arrives later than a subsequent event “b”, we would be losing accuracy in the information, which can be equal to data loss. However, Structured Streaming is able to process out-of-order data correctly if it includes a timestamp, thus generating consistent results.</p>
        <p id="Par20">By default, Structured Streaming queries are also processed internally using a micro-batch model, with the important difference that it treats the input data stream as an unbounded table that is continuously being appended by new rows, as shown graphically in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. The API also allows to choose an alternative processing mode called Continuous Processing, which can achieve lower end-to-end latencies, although it is still in an experimental state. Its operation is based on constantly reading the source and processing the data as soon as they are available, instead of polling the source periodically. Another feature is allowing stream jobs to be expressed in the same way as a batch job with static data. The Spark SQL engine takes care of executing it incrementally and continuously, updating the final result as the data arrive. Each time the result table is updated, it is written (persisted) to an external system, which can be a file or a Kafka topic [<xref ref-type="bibr" rid="CR15">15</xref>], among other options. Depending on the data to be written to the output, three modes are differentiated:<list list-type="bullet"><list-item><p id="Par21">Complete mode: all table rows are written in each update.</p></list-item><list-item><p id="Par22">Append mode: only new rows are written. This makes it only applicable when existing rows are expected to remain unchanged. This is the default mode.</p></list-item><list-item><p id="Par23">Update mode: the rows that have changed since the last table update are written.</p></list-item></list><fig id="Fig1"><label>Fig. 1</label><caption><p>Structured streaming model in Apache Spark</p></caption><graphic xlink:href="12859_2023_5530_Fig1_HTML" id="MO1"/></fig></p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec5">
    <title>Related work</title>
    <p id="Par24">There is a wide variety of tools within the context of bioinformatics. Many of them follow a batch processing model, such as CloudEC [<xref ref-type="bibr" rid="CR16">16</xref>] for error correction or BigBWA [<xref ref-type="bibr" rid="CR17">17</xref>] for sequence alignment, both of them Big Data tools relying on the Apache Hadoop framework.</p>
    <p id="Par25">Focusing on tools for performing quality control, all existing approaches are based on batch processing. Examples of such tools are FASTX-Toolkit [<xref ref-type="bibr" rid="CR18">18</xref>], PRINSEQ [<xref ref-type="bibr" rid="CR19">19</xref>], LongQC [<xref ref-type="bibr" rid="CR20">20</xref>] and iSeqQC [<xref ref-type="bibr" rid="CR21">21</xref>], which do not provide any support for parallel processing. QC-Chain [<xref ref-type="bibr" rid="CR22">22</xref>] and PRINSEQ++ [<xref ref-type="bibr" rid="CR23">23</xref>] does provide such parallel support through multithreading, and so their scalability is limited to a single node, whereas FastQC [<xref ref-type="bibr" rid="CR24">24</xref>] and Falco [<xref ref-type="bibr" rid="CR25">25</xref>], which is an emulation of the former, only support parallelism at the file level. SOAPnuke [<xref ref-type="bibr" rid="CR26">26</xref>] is able to distribute the data processing to a cluster of nodes through Hadoop, whereas SeQual [<xref ref-type="bibr" rid="CR27">27</xref>] is also capable of scaling out across a cluster by relying on the more efficient Spark RDDs, greatly enhancing performance compared to previous solutions. Nevertheless, both SOAPnuke and SeQual are still limited by the batch processing operation mode they are based on. In terms of functionality, we have taken SeQual as reference for developing SeQual-Stream due to its wide range of supported quality control operations (more than 30), one of the largest among the state of the art.</p>
    <p id="Par26">It is also interesting to mention other bioinformatics tools that follow a stream processing model for other purposes. For instance, we can find in the literature several solutions for estimating the number of k-mers in genomic datasets, such as KmerStream [<xref ref-type="bibr" rid="CR28">28</xref>], ntCard [<xref ref-type="bibr" rid="CR29">29</xref>], KmerEstimate [<xref ref-type="bibr" rid="CR30">30</xref>] and Khmer [<xref ref-type="bibr" rid="CR31">31</xref>]. Other tools are focused on sequence alignment (StreamAligner [<xref ref-type="bibr" rid="CR32">32</xref>], StreamBWA [<xref ref-type="bibr" rid="CR33">33</xref>]), metagenomics profiling (Flint [<xref ref-type="bibr" rid="CR34">34</xref>]) and DNA analysis (SparkGA2 [<xref ref-type="bibr" rid="CR35">35</xref>]). These latter examples are all implemented on top of the legacy Spark Streaming API instead of using Spark Structured Streaming as in our approach.</p>
    <p id="Par27">Finally, as our tool is based on Spark, we consider it important to highlight the usefulness of this Big Data framework in real biological studies. For example, SparkGATK [<xref ref-type="bibr" rid="CR36">36</xref>], a framework for DNA analysis, has been used to detect allele-specific expression genes in plants [<xref ref-type="bibr" rid="CR37">37</xref>]. SparkBWA [<xref ref-type="bibr" rid="CR38">38</xref>], a DNA sequence alignment tool, has been used in [<xref ref-type="bibr" rid="CR39">39</xref>] as part of the analysis pipeline to construct a high-density genetic linkage map for the common bean and identify a gene resistant to the bruchid, as well as to analyze the growth plasticity of bacteria in [<xref ref-type="bibr" rid="CR40">40</xref>].</p>
  </sec>
  <sec id="Sec6">
    <title>Implementation</title>
    <p id="Par28">SeQual-Stream is a parallel Java tool that provides a wide set of operations to apply quality control and data preprocessing on raw NGS data. These operations are grouped into three different categories depending on the functionality they provide: (1) single filters, responsible for discarding input sequences that do not meet a certain criteria (e.g., sequence length), evaluating each sequence independently of the others; (2) trimmers, operations that trim certain sequence bases at the beginning or end; and (3) formatters, operations to change the format of the input dataset (e.g., from DNA to RNA). The tool can receive as input single- or paired-end datasets, supporting FASTQ and FASTA formats. The input files can be stored either in HDFS or locally. It is important to note that there is no real dependency on HDFS as such, but on the Hadoop API, which is fully integrated into Spark. So our tool supports any other file system that is compatible with such an API. In fact, the local file system is just one of the available implementations in addition to HDFS or Amazon S3. For simplicity, we will keep using the term “HDFS” from now on, as it is also the file system used in the experimental evaluation. The datasets may be complete or in the process of being downloaded from a remote server, since SeQual-Stream can process data as new sequences continue to arrive. Note that in the case of having the complete files stored locally, they are also processed in a streaming way as they are being copied to HDFS. Furthermore, our tool features a graphical user interface to provide greater convenience to bioinformaticians and biologists (see Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S1 ).</p>
    <p id="Par29">Figure <xref rid="Fig2" ref-type="fig">2</xref> shows an overview of the SeQual-Stream dataflow to perform two quality control operations: a trimmer and a filter. In this example, there are only four DNA sequences stored in a remote server and we only show their bases for simplicity. At a certain moment, two of them have already been downloaded in a local file, so that SeQual-Stream can begin to process them by copying the available sequences to HDFS (labeled as “[A]” in the figure). Next, a Spark Dataset containing those sequences is created (“[B]”) to be operated by the trimmer and the filter (“[C]” and “[D]”, respectively). In this example, the trimmer operation is TrimRight, which trims a certain number of bases from each sequence starting from the right (three bases in this case). The filter operation is BaseN, which filters sequences according to whether or not they contain a maximum and/or minimum number of one or several base types (a maximum of three “T” bases is allowed in this case), discarding the first sequence and leaving at the end a single trimmed sequence in the Spark Dataset. Finally, the resulting sequences are written back to HDFS (“[E]”). When more content is obtained from the server, the local input file will be updated and the entire process is repeated with the new sequences. Note that this process is executed in parallel with a previous or subsequent iteration.<fig id="Fig2"><label>Fig. 2</label><caption><p>Overview of the SeQual-Stream dataflow</p></caption><graphic xlink:href="12859_2023_5530_Fig2_HTML" id="MO2"/></fig></p>
    <p id="Par30">Therefore, this dataflow can be divided into three main stages as follows: <list list-type="order"><list-item><p id="Par31">Reading of the input dataset(s), which may be stored in HDFS or locally and may be in the process of being downloaded.</p></list-item><list-item><p id="Par32">Processing of the available sequences by applying the quality control operations configured by the user.</p></list-item><list-item><p id="Par33">Writing of the results to the output files using the path specified by the user.</p></list-item></list>The next sections provide more specific details about the implementation of each stage.</p>
    <sec id="Sec7">
      <title>Reading of the input datasets</title>
      <p id="Par34">The objective of the first stage is the creation of a Spark Dataset that represents in a relational table the sequences to be processed in the next stage. Basically, Structured Streaming operates by indicating a directory in HDFS to be monitored and processing the files as they are written to such directory. The main problem is that once the available data of a certain file has been processed, such file is not processed again even if it is updated with new content. So, it cannot be used to process large files that are still in the process of downloading. To overcome this issue, the proposed solution consists of creating a previous stage in charge of reading the input dataset (“[A]” in Fig. <xref rid="Fig2" ref-type="fig">2</xref>) and generating new files formed by subsets of the input data (called “subfiles”) that Structured Streaming is able to process. Note that this reading stage works iteratively. For example, if there is a subset of sequences downloaded at a given time from a certain dataset, this stage will perform a first iteration to store those sequences in a new subfile on HDFS so that Structured Streaming can process it, and then it will wait for the remaining sequences to be downloaded. After a few seconds, it will recheck the state of the input dataset and, if new data is found, the procedure is repeated through a second iteration, generating a new subfile with new sequences to be processed.</p>
      <p id="Par35">It is important to remark that only complete sequences are copied to subfiles. If no more data is available at a given time and the last sequence is incomplete, only the complete sequences before the last one (if any) are copied while waiting for new data to arrive. Therefore, the copy operations cannot be done on a line-by-line basis, since it is necessary to evaluate if sequences are complete as they are represented in multiple lines (e.g., at least two for FASTA format). This process is even more complex for paired-end datasets, where there are two input files to be downloaded. In addition to copy only complete sequences, it must be done synchronously in both files because one of them may have more available data than the other as download speeds may differ. The solution to this issue is reading the sequences in pairs (i.e., only if both are complete) and copy them together within the same subfile.</p>
      <sec id="Sec8">
        <title>Parallel reading</title>
        <p id="Par36">In order to speed up the previously described process, the reading stage is divided and performed in parallel in one of the cluster nodes through multithreading support. The number of parallel threads used is adapted dynamically by the tool, depending on the computational capacity of the node and the amount of data available at that moment in order to avoid the overhead that would be generated by creating a lot of threads that read few data. A limit is imposed on the amount of data to be copied in a single iteration of the reading stage. This is done to improve the overlap of reading the input dataset and processing it with Structured Streaming. Without this limit, if there is a lot of data that have already been downloaded, the cluster nodes will be mostly idle while waiting for the reading stage to copy them all to HDFS.</p>
      </sec>
      <sec id="Sec9">
        <title>Creation of the Spark dataset</title>
        <p id="Par37">Once new subfiles are copied to HDFS, Structured Streaming is able to automatically detect them to allow SeQual-Stream creating a Spark Dataset of sequences (“[B]” in Fig. <xref rid="Fig2" ref-type="fig">2</xref>). Although Spark supports several common file formats (e.g., JSON, CSV), sequence formats cannot be read straightforwardly, and so the standard text-based file format provided by Spark must be used. By default, this format separates the file on a line-by-line basis. However, FASTQ/FASTA sequences are composed of multiple lines, so it would be interesting to use a character that clearly separates each one. The problem is that although FASTQ sequences begin with the “@” character, this character can also appear in the quality scores. To overcome this issue, the reading stage is in charge of adding a specific string before each sequence when copying it into a subfile in order to be used as an unambiguous separator. Once the sequences can be correctly separated, their different parts, such as their identifier and bases, can be obtained unambiguously, and the corresponding Spark Dataset can be created. For paired-end datasets, the separator string must be added to each pair written to the subfile. So, SeQual-Stream is able to differentiate each sequence of the pair when creating the Spark Dataset.</p>
      </sec>
    </sec>
    <sec id="Sec10">
      <title>Processing of the sequences</title>
      <p id="Par38">The next stage of the pipeline is the processing of the sequences contained on a Spark Dataset by applying the quality control operations selected by the user (“[C]” and “[D]” in Fig. <xref rid="Fig2" ref-type="fig">2</xref>). As previously mentioned, the functionality supported by our tool is inspired on those operations provided by SeQual [<xref ref-type="bibr" rid="CR27">27</xref>], but adapted to the stream processing model. The first group of quality control operations consists of 12 single filters that were implemented using the Spark’s <italic>filter</italic> method. Each operation implements the corresponding boolean function to discard those sequences that do not meet a certain criteria. For example, the Length filter evaluates whether the size of the sequence is smaller and/or larger than an upper and/or lower limit configured by the user.</p>
      <p id="Par39">The second and third group of operations (10 trimmers and 3 formatters, respectively) were implemented using the Spark’s <italic>map</italic> method, which allows to process the Dataset by applying a specific function to each element (i.e., sequence). For example, TrimLeft trims a given number of bases from each sequence (and their quality scores if applicable) starting from the left using the Java <italic>substring</italic> method. Another example is DNAToRNA, a formatter that changes the format of each sequence from DNA to RNA by replacing the thymine bases (represented by a “T” character) with uracil (“U” character) using the Java <italic>replace</italic> method.</p>
      <p id="Par40">Note that all the quality control operations are performed as new sequences get loaded into the Spark Dataset, so that the processing stage efficiently overlaps with the reading of the input dataset.</p>
    </sec>
    <sec id="Sec11">
      <title>Writing of the results</title>
      <p id="Par41">After a certain set of quality control operations is performed over the sequences, they must be written back to HDFS (“[E]” in Fig. <xref rid="Fig2" ref-type="fig">2</xref>). By default, the output sequences are written throughout different output files. This fact is due to two reasons: (1) when processing the sequences in a Spark Dataset, the processing tasks are executed on different cluster nodes so that each one writes to its corresponding output file (or “part” file); (2) when using our stream processing approach, the sequences are written as soon as the subfiles, which contain subsets of the input files, are processed by SeQual-Stream, and thus each subfile generates multiple part files distributed over the cluster.</p>
      <p id="Par42">The main issue of having multiple output files is how to keep the output sequences in the same order that the input. When persisting a Spark Dataset, the different parts are named in alphabetical order so that the original order is maintained. For example, the first part file (“part-0000”) may contain the sequences from 1 to 100, the second one (“part-0001”) from 101 to 200, and so on. The problem arises when using Structured Streaming, since Spark processes each subfile independently and does not preserve any alphabetical naming order between parts generated from different subfiles. Figure <xref rid="Fig3" ref-type="fig">3</xref> illustrates this issue, where two different subfiles are generated at different moments in time from the input dataset being downloaded. In this example, the processing of every subfile is distributed on two nodes, thus generating four part files in total. Parts labeled as “[P1]” and “[P2]” are named in alphabetical order, and the same applies to parts “[P3]” and “[P4]”, but the order is not respected between all of them. A naive solution to this issue would be using the write timestamp of each part file, since the first sequences should be processed and written before the following ones. However, this rule is not consistent: when several subfiles are written to the directory that Structured Streaming is monitoring, there is no guarantee that they will be processed in the same order they were created.</p>
      <p id="Par43">The solution proposed in SeQual-Stream consists of embedding a custom timestamp within each sequence during the reading stage (“[A]” in Fig. <xref rid="Fig2" ref-type="fig">2</xref>) so that the order is set from the very beginning. More specifically, SeQual-Stream must be able to differentiate each generated subfile during such reading stage. So, we use a timestamp composed of two integers to indicate, respectively, each iteration of the reading stage and the thread number that generated the corresponding subfile. For example, thread #5 during iteration #3 will embed the timestamp “3–5” in its sequences. Therefore, SeQual-Stream actually processes a Spark Dataset containing sequences tagged with a custom timestamp. Right before writing the results to HDFS, this Spark Dataset is separated into two columns through a <italic>flatmap</italic> operation: the sequences themselves and their timestamps. This approach allows writing the results partitioned by the timestamp column, an operation that consists of gathering the part files containing sequences with the same timestamp into the same output directory. Those parts are already sorted alphabetically, and thus the global order is ensured. For instance, the part files generated from the sequences with timestamp “3–5” are stored in a directory named “timestamp=3–5”. If a single output file containing all the resulting sequences is preferred by the user, our tool allows to configure an option to merge them together in the appropriate order.</p>
      <p id="Par44">Regarding the writing operation itself, it is done through a Spark object called “StreamingQuery” that remains in a loop as long as there is data to be written. This loop ends when the reading stage sends a specific signal meaning that there is no more input data, and when the StreamingQuery has no pending data to write. Finally, the output write mode for Structured Streaming will be “append”, since we are only interested in writing the new processed sequences in a new part file, whereas the already written sequences must not change.<fig id="Fig3"><label>Fig. 3</label><caption><p>Illustration of the naming order problem with several part files</p></caption><graphic xlink:href="12859_2023_5530_Fig3_HTML" id="MO3"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec12">
    <title>Results and discussion</title>
    <p id="Par45">The experimental evaluation of our proposal has been conducted on two different testbeds. The first one is a 17-node commodity cluster consisting of one master and 16 worker nodes. The hardware characteristics of each node are shown in Table <xref rid="Tab1" ref-type="table">1</xref>. This cluster provides a total of 256 physical cores and 1 TiB of memory for the processing tasks, and each node has one local hard disk for HDFS and temporary data storage during the execution of the experiments. The second testbed is a more modern, high-performance 9-node cluster consisting of one master and 8 worker nodes. Table <xref rid="Tab2" ref-type="table">2</xref> shows the characteristics of each node, providing a total of 256 physical cores and 2 TiB of memory for the processing tasks, with each node having two local disks: one large but slow hard disk and one small but fast solid state disk. Tables <xref rid="Tab1" ref-type="table">1</xref> and <xref rid="Tab2" ref-type="table">2</xref> also show the software configuration of each testbed, with both systems running CentOS Linux 7.9.2009. As can be observed, the Spark and Hadoop versions used in the experiments were the same in both testbeds. Some specific configuration parameters for Spark and HDFS are also shown in these tables, such as the block size for HDFS and the number of cores for Spark executors, which is adapted to the features of the cluster nodes.</p>
    <p id="Par46">Three publicly available FASTQ datasets have been evaluated, obtained from the Sequence Read Archive (SRA) [<xref ref-type="bibr" rid="CR41">41</xref>, <xref ref-type="bibr" rid="CR42">42</xref>], a public repository of genomic data belonging to the National Center for Biotechnology Information (NCBI) [<xref ref-type="bibr" rid="CR43">43</xref>, <xref ref-type="bibr" rid="CR44">44</xref>]. These datasets present a paired-end layout, so they consist of two input files (single-end experiments use one file). Their main characteristics are summarized in Table <xref rid="Tab3" ref-type="table">3</xref>, where the number of reads (third row) refers to the number of DNA sequences in each input file, and the read length (fourth row) refers to the number of base pairs (bp) per each sequence.</p>
    <p id="Par47">The experimental evaluation has been carried out comparatively with SeQual, the tool used as reference to implement our solution in terms of its functionality, as mentioned before. Four representative quality control operations have been selected for this performance comparison:<list list-type="bullet"><list-item><p id="Par48">QUALITY: a single filter that filters sequences based on an indicated maximum and/or minimum mean quality threshold. The quality score from each base is calculated following the Phred+33 quality score encoding [<xref ref-type="bibr" rid="CR45">45</xref>]. A minimum quality of 25 was used in the experiments.</p></list-item><list-item><p id="Par49">NONIUPAC: a single filter that removes sequences if they contain Non-IUPAC bases (that is, any base other than A, T, G, C or N).</p></list-item><list-item><p id="Par50">TRIMRIGHTP: a trimmer that trims sequences according to an indicated percentage of the total number of bases starting from the right. A 10% trimming was used in the experiments.</p></list-item><list-item><p id="Par51">DNATORNA: a formatter that transforms DNA sequences to RNA sequences.</p></list-item></list>In addition, two different scenarios have been tested depending on the state of the input dataset:<list list-type="bullet"><list-item><p id="Par52">“Downloaded”, where the full dataset is already locally stored in the master node (i.e., it was previously downloaded). In this scenario, SeQual first requires to copy the dataset to HDFS for processing it, since batch data processing can only begin once the complete dataset was copied. However, SeQual-Stream is able to read it directly from the local file system of the master node and start its processing while it is being copied to HDFS.</p></list-item><list-item><p id="Par53">“Downloading”, where the dataset is stored on a remote location outside the cluster (e.g., an external repository or server), so it must be first downloaded locally on the master node and then copied to HDFS for its processing. This second scenario serves to exploit one of the main advantages of our approach, as SeQual-Stream can start data processing as soon as the download operation is initiated, instead of waiting for the download to finish and copy the full dataset to HDFS. For simplicity, the datasets are stored on private servers instead of on a public repository to prevent that highly variable Internet download speeds could affect the results of these experiments. Each testbed has access to a separate private server with different download speeds: the first testbed downloads the datasets from a server providing speeds of 90–100 MiB/s, while the second one downloads them from a server with speeds of 600–700 MiB/s.</p></list-item></list>Finally, all the experiments were run a minimum of 5 times using the cluster nodes in a dedicated manner (i.e., the hardware was never shared by other users’ jobs running on the same cluster). Due to this fact, the observed standard deviations were not significant, and so the median value will be used as the performance metric in this work. Consequently, all the results shown in the next sections represent the median value of 5 measurements for each experiment.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Hardware and software characteristics of the cluster nodes (testbed 1)</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="left" colspan="3"><italic>Hardware</italic></td></tr><tr><td align="left">CPU Model</td><td align="left" colspan="2">2 × Intel Xeon E5-2660 Sandy Bridge-EP</td></tr><tr><td align="left">CPU Speed/Turbo</td><td align="left" colspan="2">2.20 GHz/3.0 GHz</td></tr><tr><td align="left">#Cores per node</td><td align="left" colspan="2">16</td></tr><tr><td align="left">#Threads per node</td><td align="left" colspan="2">32</td></tr><tr><td align="left">Cache L1/L2/L3</td><td align="left" colspan="2">32 KiB/256 KiB/20 MiB</td></tr><tr><td align="left">Memory</td><td align="left" colspan="2">64 GiB DDR3 1600 MHz</td></tr><tr><td align="left">Disk</td><td align="left" colspan="2">1 × HDD 1 TiB SATA3 7.2K rpm</td></tr><tr><td align="left">Network</td><td align="left" colspan="2">Gigabit Ethernet</td></tr><tr><td align="left" colspan="3"><italic>Software</italic></td></tr><tr><td align="left">OS Version</td><td align="left" colspan="2">CentOS Linux release 7.9.2009</td></tr><tr><td align="left">Kernel</td><td align="left" colspan="2">3.10.0-1160.62.1</td></tr><tr><td align="left">Java</td><td align="left" colspan="2">OpenJDK 1.8.0_322</td></tr><tr><td align="left" rowspan="4">Spark</td><td align="left">Version</td><td align="left">3.1.1</td></tr><tr><td align="left">Executors per node</td><td align="left">1</td></tr><tr><td align="left">Executor heap size</td><td align="left">55 GiB</td></tr><tr><td align="left">Executor cores</td><td align="left">16</td></tr><tr><td align="left">Hadoop</td><td align="left">Version</td><td align="left">2.10.1</td></tr><tr><td align="left" rowspan="2">HDFS</td><td align="left">Block size</td><td align="left">128 MiB</td></tr><tr><td align="left">Replication factor</td><td align="left">3</td></tr></tbody></table></table-wrap><table-wrap id="Tab2"><label>Table 2</label><caption><p>Hardware and software characteristics of the cluster nodes (testbed 2)</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="left" colspan="3"><italic>Hardware</italic></td></tr><tr><td align="left">CPU Model</td><td align="left" colspan="2">2 × Intel Xeon Silver 4216 Cascade Lake-SP</td></tr><tr><td align="left">CPU Speed/Turbo</td><td align="left" colspan="2">2.1 GHz/3.2 GHz</td></tr><tr><td align="left">#Cores per node</td><td align="left" colspan="2">32</td></tr><tr><td align="left">#Threads per node</td><td align="left" colspan="2">64</td></tr><tr><td align="left">Cache L1/L2/L3</td><td align="left" colspan="2">32 KiB/1 MiB/22 MiB</td></tr><tr><td align="left">Memory</td><td align="left" colspan="2">256 GiB DDR4 2933 MHhz</td></tr><tr><td align="left" rowspan="2">Disks</td><td align="left" colspan="2">1 × HDD 2 TiB SATA3 7.2K rpm</td></tr><tr><td align="left" colspan="2">1 × SSD 240 GiB SATA3</td></tr><tr><td align="left">Network</td><td align="left" colspan="2">InfiniBand FDR</td></tr><tr><td align="left" colspan="3"><italic>Software</italic></td></tr><tr><td align="left">OS Version</td><td align="left" colspan="2">CentOS Linux release 7.9.2009</td></tr><tr><td align="left">Kernel</td><td align="left" colspan="2">5.4.233-1</td></tr><tr><td align="left">Java</td><td align="left" colspan="2">OpenJDK 1.8.0_372</td></tr><tr><td align="left" rowspan="4">Spark</td><td align="left">Version</td><td align="left">3.1.1</td></tr><tr><td align="left">Executors per node</td><td align="left">1</td></tr><tr><td align="left">Executor heap size</td><td align="left">225 GiB</td></tr><tr><td align="left">Executor cores</td><td align="left">32</td></tr><tr><td align="left">Hadoop</td><td align="left">Version</td><td align="left">2.10.1</td></tr><tr><td align="left" rowspan="2">HDFS</td><td align="left">Block size</td><td align="left">128 MiB</td></tr><tr><td align="left">Replication factor</td><td align="left">3</td></tr></tbody></table></table-wrap><table-wrap id="Tab3"><label>Table 3</label><caption><p>Characteristics of the public datasets used in the performance evaluation</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">SRR567455</th><th align="left">SRR11442499</th><th align="left">SRR5893671</th></tr></thead><tbody><tr><td align="left">Tag</td><td align="left">SRR56</td><td align="left">SRR114</td><td align="left">SRR589</td></tr><tr><td align="left">Organism</td><td align="left">Homo sapiens</td><td align="left">Homo sapiens</td><td align="left">Triticum aestivum</td></tr><tr><td align="left">#Reads</td><td align="left">2 <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M4"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq2.gif"/></alternatives></inline-formula> 251.9 M</td><td align="left">2 <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M6"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq3.gif"/></alternatives></inline-formula> 250.3 M</td><td align="left">2 <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M8"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq4.gif"/></alternatives></inline-formula> 359.5 M</td></tr><tr><td align="left">Read length</td><td align="left">76 bp</td><td align="left">99 bp</td><td align="left">160 bp</td></tr><tr><td align="left">Size</td><td align="left">2 <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M10"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq5.gif"/></alternatives></inline-formula> 45 GiB</td><td align="left">2 <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M12"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq6.gif"/></alternatives></inline-formula> 62 GiB</td><td align="left">2 <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M14"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq7.gif"/></alternatives></inline-formula> 120 GiB</td></tr></tbody></table></table-wrap></p>
    <sec id="Sec13">
      <title>Experiments on testbed 1</title>
      <p id="Par54">This first group of experiments is performed on the first testbed (see Table <xref rid="Tab1" ref-type="table">1</xref>). The “downloaded” scenario is evaluated using the first two datasets (SRR56 and SRR114, see Table <xref rid="Tab3" ref-type="table">3</xref>) in both single- and paired-end mode, while the second scenario (“downloading”) is only tested with the second dataset for brevity of results, in single- and paired-end modes as well. The largest dataset (SRR589) is excluded from these experiments as it is so large and computationally expensive to process for this hardware that runtimes exceeded the time limits imposed on this testbed.</p>
      <sec id="Sec14">
        <title>“Downloaded” scenario</title>
        <p id="Par55">Tables <xref rid="Tab4" ref-type="table">4</xref> and <xref rid="Tab5" ref-type="table">5</xref> show the execution times of both tools for the first scenario. It is important to note that the results for SeQual take into account the time required to copy the input dataset before starting its processing. The results shown in the tables are organized according to the quality control operation being performed, the dataset and its corresponding single- or paired-end layout, and the number of worker nodes used in the experiment (from 1 to 16). The last column shows the speedup obtained by our solution over its batch counterpart.</p>
        <p id="Par56">On the one hand, it can be observed that the maximum speedup achieved by our tool is 2.70<inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M16"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq8.gif"/></alternatives></inline-formula>, which is obtained for the QUALITY filter when processing the SRR56 dataset in paired-end mode. On the other hand, the average speedup for all operations and datasets under evaluation in this first scenario is around 1.43<inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M18"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq9.gif"/></alternatives></inline-formula>. In general, the speedups are usually higher when using a small number of worker nodes (1–4), whereas it tends to converge to 1 when using 16 nodes. The main reason for this behavior is that there comes a point where there is so much computational power and disks on which to spread the write operations that the processing and writing of the results are fast enough, whereas the speed of copying the input files, which is similar for both tools, becomes the major performance limiting factor due to the slow HDD disks available on this testbed.</p>
        <p id="Par57">There are also some differences to be pointed out between the results obtained for the different operations. The QUALITY filter and the TRIMRIGHTP trimmer tend to generate smaller runtimes for both tools and obtain greater speedups than the NONIUPAC filter and the DNATORNA formatter. This is due to the different amount of data written to HDFS as output for each operation. Whereas QUALITY removes sequences from the input dataset and TRIMRIGHTP makes them smaller, NONIUPAC does not filter any (because all bases are in IUPAC nomenclature in these datasets) and DNATORNA simply changes their format (thus maintaining all the sequences and their length). Consequently, these last two operations write more output data and impose a greater overhead on the disks, a more limiting factor in SeQual-Stream because the copy of the input dataset(s) is being made in parallel with the processing and writing of the results.</p>
        <p id="Par58">Overall, the speedups obtained tend to increase noticeably for paired-end experiments compared to single-end ones. In fact, all speedups greater than 2<inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M20"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq10.gif"/></alternatives></inline-formula> are achieved in paired-end mode. It is important to remark that this mode involves copying and processing twice as much data as in single-end mode. As the amount of input data increases significantly, the time required to copy them to HDFS, process them with Spark and write their parts to HDFS also increases proportionally. Therefore, parallelizing all this process through a stream model is very beneficial and is precisely what was sought after with the development of this tool.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Runtimes (in seconds) and corresponding speedups of SeQual-Stream over SeQual for different single- and paired-end datasets using the QUALITY and NONIUPAC filters (“Downloaded” scenario, testbed 1)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Operation</th><th align="left">Dataset</th><th align="left">Mode</th><th align="left">Nodes</th><th align="left">SeQual</th><th align="left">SeQual-Stream</th><th align="left">Speedup</th></tr></thead><tbody><tr><td align="left" rowspan="20">QUALITY</td><td align="left" rowspan="10">SRR56</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">1386</td><td char="." align="char">927</td><td char="." align="char">1.49</td></tr><tr><td char="." align="char">2</td><td char="." align="char">993</td><td char="." align="char">708</td><td char="." align="char">1.40</td></tr><tr><td char="." align="char">4</td><td char="." align="char">780</td><td char="." align="char">595</td><td char="." align="char">1.31</td></tr><tr><td char="." align="char">8</td><td char="." align="char">566</td><td char="." align="char">507</td><td char="." align="char">1.12</td></tr><tr><td char="." align="char">16</td><td char="." align="char">522</td><td char="." align="char">513</td><td char="." align="char">1.02</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">5312</td><td char="." align="char">1967</td><td char="." align="char">2.70</td></tr><tr><td char="." align="char">2</td><td char="." align="char">3639</td><td char="." align="char">1470</td><td char="." align="char">2.47</td></tr><tr><td char="." align="char">4</td><td char="." align="char">2043</td><td char="." align="char">1102</td><td char="." align="char">1.85</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1119</td><td char="." align="char">949</td><td char="." align="char">1.18</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1024</td><td char="." align="char">940</td><td char="." align="char">1.09</td></tr><tr><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">2239</td><td char="." align="char">1918</td><td char="." align="char">1.17</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1569</td><td char="." align="char">1070</td><td char="." align="char">1.47</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1242</td><td char="." align="char">941</td><td char="." align="char">1.32</td></tr><tr><td char="." align="char">8</td><td char="." align="char">865</td><td char="." align="char">702</td><td char="." align="char">1.23</td></tr><tr><td char="." align="char">16</td><td char="." align="char">723</td><td char="." align="char">689</td><td char="." align="char">1.05</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">6983</td><td char="." align="char">4082</td><td char="." align="char">1.71</td></tr><tr><td char="." align="char">2</td><td char="." align="char">5367</td><td char="." align="char">2278</td><td char="." align="char">2.36</td></tr><tr><td char="." align="char">4</td><td char="." align="char">3126</td><td char="." align="char">1688</td><td char="." align="char">1.85</td></tr><tr><td char="." align="char">8</td><td char="." align="char">2085</td><td char="." align="char">1368</td><td char="." align="char">1.52</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1452</td><td char="." align="char">1306</td><td char="." align="char">1.11</td></tr><tr><td align="left" rowspan="20">NONIUPAC</td><td align="left" rowspan="10">SRR56</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">1430</td><td char="." align="char">1226</td><td char="." align="char">1.17</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1127</td><td char="." align="char">1081</td><td char="." align="char">1.04</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1013</td><td char="." align="char">703</td><td char="." align="char">1.44</td></tr><tr><td char="." align="char">8</td><td char="." align="char">586</td><td char="." align="char">513</td><td char="." align="char">1.14</td></tr><tr><td char="." align="char">16</td><td char="." align="char">539</td><td char="." align="char">518</td><td char="." align="char">1.04</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">5919</td><td char="." align="char">2748</td><td char="." align="char">2.15</td></tr><tr><td char="." align="char">2</td><td char="." align="char">4086</td><td char="." align="char">1958</td><td char="." align="char">2.09</td></tr><tr><td char="." align="char">4</td><td char="." align="char">2328</td><td char="." align="char">1413</td><td char="." align="char">1.65</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1240</td><td char="." align="char">990</td><td char="." align="char">1.25</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1056</td><td char="." align="char">960</td><td char="." align="char">1.10</td></tr><tr><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">2140</td><td char="." align="char">1896</td><td char="." align="char">1.13</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1600</td><td char="." align="char">1454</td><td char="." align="char">1.10</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1047</td><td char="." align="char">995</td><td char="." align="char">1.05</td></tr><tr><td char="." align="char">8</td><td char="." align="char">815</td><td char="." align="char">682</td><td char="." align="char">1.19</td></tr><tr><td char="." align="char">16</td><td char="." align="char">730</td><td char="." align="char">686</td><td char="." align="char">1.06</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">6858</td><td char="." align="char">4549</td><td char="." align="char">1.51</td></tr><tr><td char="." align="char">2</td><td char="." align="char">6044</td><td char="." align="char">3000</td><td char="." align="char">2.01</td></tr><tr><td char="." align="char">4</td><td char="." align="char">3098</td><td char="." align="char">2079</td><td char="." align="char">1.49</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1646</td><td char="." align="char">1370</td><td char="." align="char">1.20</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1439</td><td char="." align="char">1328</td><td char="." align="char">1.08</td></tr></tbody></table></table-wrap><table-wrap id="Tab5"><label>Table 5</label><caption><p>Runtimes (in seconds) and corresponding speedups of SeQual-Stream over SeQual for different single- and paired-end datasets using the TRIMRIGHTP trimmer and DNATORNA formatter (“Downloaded” scenario, testbed 1)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Operation</th><th align="left">Dataset</th><th align="left">Mode</th><th align="left">Nodes</th><th align="left">SeQual</th><th align="left">SeQual-Stream</th><th align="left">Speedup</th></tr></thead><tbody><tr><td align="left" rowspan="20">TRIMRIGHTP</td><td align="left" rowspan="10">SRR56</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">1682</td><td char="." align="char">1062</td><td char="." align="char">1.58</td></tr><tr><td char="." align="char">2</td><td char="." align="char">934</td><td char="." align="char">872</td><td char="." align="char">1.07</td></tr><tr><td char="." align="char">4</td><td char="." align="char">765</td><td char="." align="char">680</td><td char="." align="char">1.13</td></tr><tr><td char="." align="char">8</td><td char="." align="char">583</td><td char="." align="char">523</td><td char="." align="char">1.11</td></tr><tr><td char="." align="char">16</td><td char="." align="char">521</td><td char="." align="char">523</td><td char="." align="char">1.00</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">5850</td><td char="." align="char">2259</td><td char="." align="char">2.59</td></tr><tr><td char="." align="char">2</td><td char="." align="char">3400</td><td char="." align="char">1906</td><td char="." align="char">1.78</td></tr><tr><td char="." align="char">4</td><td char="." align="char">2280</td><td char="." align="char">1463</td><td char="." align="char">1.56</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1354</td><td char="." align="char">961</td><td char="." align="char">1.41</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1051</td><td char="." align="char">961</td><td char="." align="char">1.09</td></tr><tr><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">2855</td><td char="." align="char">1723</td><td char="." align="char">1.66</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1381</td><td char="." align="char">1281</td><td char="." align="char">1.08</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1050</td><td char="." align="char">909</td><td char="." align="char">1.16</td></tr><tr><td char="." align="char">8</td><td char="." align="char">849</td><td char="." align="char">723</td><td char="." align="char">1.17</td></tr><tr><td char="." align="char">16</td><td char="." align="char">729</td><td char="." align="char">688</td><td char="." align="char">1.06</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">5960</td><td char="." align="char">4119</td><td char="." align="char">1.45</td></tr><tr><td char="." align="char">2</td><td char="." align="char">5514</td><td char="." align="char">2391</td><td char="." align="char">2.31</td></tr><tr><td char="." align="char">4</td><td char="." align="char">3329</td><td char="." align="char">1969</td><td char="." align="char">1.69</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1859</td><td char="." align="char">1390</td><td char="." align="char">1.34</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1420</td><td char="." align="char">1325</td><td char="." align="char">1.07</td></tr><tr><td align="left" rowspan="20">DNATORNA</td><td align="left" rowspan="10">SRR56</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">1840</td><td char="." align="char">1588</td><td char="." align="char">1.16</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1194</td><td char="." align="char">1121</td><td char="." align="char">1.06</td></tr><tr><td char="." align="char">4</td><td char="." align="char">918</td><td char="." align="char">673</td><td char="." align="char">1.36</td></tr><tr><td char="." align="char">8</td><td char="." align="char">650</td><td char="." align="char">521</td><td char="." align="char">1.25</td></tr><tr><td char="." align="char">16</td><td char="." align="char">543</td><td char="." align="char">509</td><td char="." align="char">1.07</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">5072</td><td char="." align="char">3535</td><td char="." align="char">1.43</td></tr><tr><td char="." align="char">2</td><td char="." align="char">4069</td><td char="." align="char">1942</td><td char="." align="char">2.09</td></tr><tr><td char="." align="char">4</td><td char="." align="char">2556</td><td char="." align="char">1541</td><td char="." align="char">1.66</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1449</td><td char="." align="char">1062</td><td char="." align="char">1.36</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1057</td><td char="." align="char">950</td><td char="." align="char">1.11</td></tr><tr><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">3149</td><td char="." align="char">1999</td><td char="." align="char">1.57</td></tr><tr><td char="." align="char">2</td><td char="." align="char">2012</td><td char="." align="char">1116</td><td char="." align="char">1.80</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1146</td><td char="." align="char">1013</td><td char="." align="char">1.13</td></tr><tr><td char="." align="char">8</td><td char="." align="char">859</td><td char="." align="char">683</td><td char="." align="char">1.26</td></tr><tr><td char="." align="char">16</td><td char="." align="char">722</td><td char="." align="char">671</td><td char="." align="char">1.08</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">6322</td><td char="." align="char">4923</td><td char="." align="char">1.28</td></tr><tr><td char="." align="char">2</td><td char="." align="char">5547</td><td char="." align="char">2760</td><td char="." align="char">2.01</td></tr><tr><td char="." align="char">4</td><td char="." align="char">3650</td><td char="." align="char">1954</td><td char="." align="char">1.87</td></tr><tr><td char="." align="char">8</td><td char="." align="char">2288</td><td char="." align="char">1333</td><td char="." align="char">1.72</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1456</td><td char="." align="char">1286</td><td char="." align="char">1.13</td></tr></tbody></table></table-wrap></p>
      </sec>
      <sec id="Sec15">
        <title>“Downloading” scenario</title>
        <p id="Par59">Table <xref rid="Tab6" ref-type="table">6</xref> shows the execution times of both tools for the second scenario, where the dataset is downloaded from an external server with a bandwidth of up to 100 MiB/s, as mentioned earlier. Note that the results for SeQual take into account the time required to download and copy the full dataset before starting its processing. The results shown in the table follow the same format as in the previous scenario.</p>
        <p id="Par60">In this case, the speedups of our tool range from a minimum of 1.26<inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M22"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq11.gif"/></alternatives></inline-formula> up to a maximum of 2.45<inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M24"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq12.gif"/></alternatives></inline-formula>, obtained for the QUALITY filter in single-end mode using 16 nodes and the DNATORNA formatter in paired-end mode using 4 nodes, respectively. The average speedup is around 1.71<inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M26"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq13.gif"/></alternatives></inline-formula>, which is a 20% higher than in the “Downloaded” scenario. Overall, the speedups are much better even when using 16 worker nodes, especially for the paired-end experiments. For instance, SeQual-Stream reduces SeQual execution times by 24% and 30% when applying TRIMRIGHTP over the SRR114 dataset using 16 nodes in single- and paired-end mode, respectively.</p>
        <p id="Par61">It is also worth noting how the speedup difference between single- and paired-end mode is slightly attenuated in this second scenario compared to the previous one. For instance, even though almost all speedups greater than 2<inline-formula id="IEq14"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M28"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq14.gif"/></alternatives></inline-formula> are also achieved in paired-end mode as before, there is at least one experiment where a 2.10<inline-formula id="IEq15"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M30"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq15.gif"/></alternatives></inline-formula> speedup is obtained in single-end (TRIMRIGHTP), and yet, the maximum speedup (2.45<inline-formula id="IEq16"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M32"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq16.gif"/></alternatives></inline-formula>) is lower than in the first scenario (2.70<inline-formula id="IEq17"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M34"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq17.gif"/></alternatives></inline-formula>). The main reason is that reading two input files requires copying both files simultaneously to join each sequence with its corresponding pair. When both files are being downloaded, it is very likely that one file is downloaded faster than the other, and so the additional data available from the faster file cannot be used by SeQual-Stream, as it is required to wait for the paired sequences to arrive from the slower file.<table-wrap id="Tab6"><label>Table 6</label><caption><p>Runtimes (in seconds) and corresponding speedups of SeQual-Stream over SeQual for the SRR114 dataset and different quality control operations (“Downloading” scenario, testbed 1)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Operation</th><th align="left">Dataset</th><th align="left">Mode</th><th align="left">Nodes</th><th align="left">SeQual</th><th align="left">SeQual-Stream</th><th align="left">Speedup</th></tr></thead><tbody><tr><td align="left" rowspan="10">QUALITY</td><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">2599</td><td char="." align="char">1373</td><td char="." align="char">1.89</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1929</td><td char="." align="char">1134</td><td char="." align="char">1.70</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1602</td><td char="." align="char">1024</td><td char="." align="char">1.56</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1225</td><td char="." align="char">864</td><td char="." align="char">1.42</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1083</td><td char="." align="char">858</td><td char="." align="char">1.26</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">7703</td><td char="." align="char">3490</td><td char="." align="char">2.21</td></tr><tr><td char="." align="char">2</td><td char="." align="char">6087</td><td char="." align="char">2869</td><td char="." align="char">2.12</td></tr><tr><td char="." align="char">4</td><td char="." align="char">3846</td><td char="." align="char">1920</td><td char="." align="char">2.00</td></tr><tr><td char="." align="char">8</td><td char="." align="char">2805</td><td char="." align="char">1548</td><td char="." align="char">1.81</td></tr><tr><td char="." align="char">16</td><td char="." align="char">2172</td><td char="." align="char">1518</td><td char="." align="char">1.43</td></tr><tr><td align="left" rowspan="10">NONIUPAC</td><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">2500</td><td char="." align="char">1818</td><td char="." align="char">1.37</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1960</td><td char="." align="char">1273</td><td char="." align="char">1.54</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1407</td><td char="." align="char">918</td><td char="." align="char">1.53</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1175</td><td char="." align="char">843</td><td char="." align="char">1.39</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1090</td><td char="." align="char">829</td><td char="." align="char">1.31</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">7578</td><td char="." align="char">3611</td><td char="." align="char">2.10</td></tr><tr><td char="." align="char">2</td><td char="." align="char">6764</td><td char="." align="char">2959</td><td char="." align="char">2.29</td></tr><tr><td char="." align="char">4</td><td char="." align="char">3818</td><td char="." align="char">1891</td><td char="." align="char">2.02</td></tr><tr><td char="." align="char">8</td><td char="." align="char">2366</td><td char="." align="char">1561</td><td char="." align="char">1.52</td></tr><tr><td char="." align="char">16</td><td char="." align="char">2159</td><td char="." align="char">1559</td><td char="." align="char">1.38</td></tr><tr><td align="left" rowspan="10">TRIMRIGHTP</td><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">3215</td><td char="." align="char">1529</td><td char="." align="char">2.10</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1741</td><td char="." align="char">1174</td><td char="." align="char">1.48</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1410</td><td char="." align="char">1019</td><td char="." align="char">1.38</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1209</td><td char="." align="char">838</td><td char="." align="char">1.44</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1089</td><td char="." align="char">829</td><td char="." align="char">1.31</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">6680</td><td char="." align="char">3363</td><td char="." align="char">1.99</td></tr><tr><td char="." align="char">2</td><td char="." align="char">5874</td><td char="." align="char">2659</td><td char="." align="char">2.21</td></tr><tr><td char="." align="char">4</td><td char="." align="char">4049</td><td char="." align="char">1828</td><td char="." align="char">2.21</td></tr><tr><td char="." align="char">8</td><td char="." align="char">2579</td><td char="." align="char">1522</td><td char="." align="char">1.69</td></tr><tr><td char="." align="char">16</td><td char="." align="char">2140</td><td char="." align="char">1501</td><td char="." align="char">1.43</td></tr><tr><td align="left" rowspan="10">DNATORNA</td><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">3509</td><td char="." align="char">1953</td><td char="." align="char">1.80</td></tr><tr><td char="." align="char">2</td><td char="." align="char">2372</td><td char="." align="char">1678</td><td char="." align="char">1.41</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1506</td><td char="." align="char">1079</td><td char="." align="char">1.40</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1219</td><td char="." align="char">863</td><td char="." align="char">1.41</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1082</td><td char="." align="char">813</td><td char="." align="char">1.33</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">7042</td><td char="." align="char">4290</td><td char="." align="char">1.64</td></tr><tr><td char="." align="char">2</td><td char="." align="char">6267</td><td char="." align="char">2668</td><td char="." align="char">2.35</td></tr><tr><td char="." align="char">4</td><td char="." align="char">4370</td><td char="." align="char">1780</td><td char="." align="char">2.45</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3008</td><td char="." align="char">1559</td><td char="." align="char">1.93</td></tr><tr><td char="." align="char">16</td><td char="." align="char">2176</td><td char="." align="char">1488</td><td char="." align="char">1.46</td></tr></tbody></table></table-wrap></p>
      </sec>
    </sec>
    <sec id="Sec16">
      <title>Experiments on testbed 2</title>
      <p id="Par62">This set of experiments is performed on the second testbed (see Table <xref rid="Tab2" ref-type="table">2</xref>). The “downloaded” and “downloading” scenarios are both evaluated using the same four quality control operations and processing the largest dataset (SRR589, see Table <xref rid="Tab3" ref-type="table">3</xref>), in this case only in paired-end mode for brevity of results. These experiments require the use of the HDD disks available on the cluster nodes, as the SSD disks do not have enough space to store both the input and output data for this huge dataset.</p>
      <p id="Par63">On the one hand, Table <xref rid="Tab7" ref-type="table">7</xref> shows the execution times of both tools for the “downloaded” scenario using up to 8 worker nodes. Overall, it can be seen that the speedups are very similar to those obtained for the analogous scenario on the first testbed (see paired-end results in Tables <xref rid="Tab4" ref-type="table">4</xref> and <xref rid="Tab5" ref-type="table">5</xref>). Although the maximum speedup is slightly lower (up to 2.38<inline-formula id="IEq18"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M36"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq18.gif"/></alternatives></inline-formula>), the average values remain practically the same (from 1.63<inline-formula id="IEq19"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M38"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq19.gif"/></alternatives></inline-formula> to 1.62<inline-formula id="IEq20"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M40"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq20.gif"/></alternatives></inline-formula>). In these experiments, the speedups tend to be slightly lower due to the significantly higher computational power of the hardware. Consequently, the speed of copying the input files to the slow HDD disks becomes the main performance bottleneck using just 8 nodes instead of 16 as in the first testbed.</p>
      <p id="Par64">On the other hand, Table <xref rid="Tab8" ref-type="table">8</xref> shows the execution times for the “downloading” scenario. Note that the runtimes for SeQual remain the same as in the previous “downloaded” scenario. This is due to the higher download speed of the external server from which the datasets are downloaded, which is now fast enough so that the limiting factor in the download/copy pipeline to HDFS is the copy phase. SeQual-Stream runtimes are also very similar, although they tend to be slightly higher, suggesting that the streaming approach was able to take slightly more advantage of the fact that the input data was already complete. Compared to the analogous scenario evaluated on the first testbed (see paired-end results in Table <xref rid="Tab6" ref-type="table">6</xref>), the speedup results tend to be lower, with an average of 1.60<inline-formula id="IEq21"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M42"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq21.gif"/></alternatives></inline-formula>. Due to the faster download speed, there are fewer opportunities for overlapping and therefore fewer advantages for stream processing, although the maximum speedup achieved in these experiments (2.66<inline-formula id="IEq22"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M44"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq22.gif"/></alternatives></inline-formula>) is still higher than before (2.45<inline-formula id="IEq23"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M46"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq23.gif"/></alternatives></inline-formula>).</p>
      <p id="Par65">Overall, these experiments on the second testbed demonstrate that our tool can still achieve lower runtimes than its batch counterpart when using newer and faster hardware. However, SeQual-Stream can take even more advantage of slow/commodity hardware, as the chance for overlapping the download and/or copy of the datasets to HDFS with their processing is critical in this case. This proves that cutting-edge hardware is not necessary to use our tool, as good results can be obtained using commodity hardware such as in the first testbed.<table-wrap id="Tab7"><label>Table 7</label><caption><p>Runtimes (in seconds) and corresponding speedups of SeQual-Stream over SeQual for the SRR589 paired-end dataset (“Downloaded” scenario, testbed 2)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Operation</th><th align="left">Dataset</th><th align="left">Mode</th><th align="left">Nodes</th><th align="left">SeQual</th><th align="left">SeQual-Stream</th><th align="left">Speedup</th></tr></thead><tbody><tr><td align="left" rowspan="4">QUALITY</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">9369</td><td char="." align="char">5137</td><td char="." align="char">1.82</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7666</td><td char="." align="char">4629</td><td char="." align="char">1.66</td></tr><tr><td char="." align="char">4</td><td char="." align="char">5152</td><td char="." align="char">3059</td><td char="." align="char">1.68</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3418</td><td char="." align="char">2728</td><td char="." align="char">1.25</td></tr><tr><td align="left" rowspan="4">NONIUPAC</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">13253</td><td char="." align="char">5558</td><td char="." align="char">2.38</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7703</td><td char="." align="char">4498</td><td char="." align="char">1.71</td></tr><tr><td char="." align="char">4</td><td char="." align="char">4887</td><td char="." align="char">3307</td><td char="." align="char">1.48</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3172</td><td char="." align="char">2818</td><td char="." align="char">1.13</td></tr><tr><td align="left" rowspan="4">TRIMRIGHTP</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">13343</td><td char="." align="char">5875</td><td char="." align="char">2.27</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7532</td><td char="." align="char">4172</td><td char="." align="char">1.81</td></tr><tr><td char="." align="char">4</td><td char="." align="char">4813</td><td char="." align="char">3018</td><td char="." align="char">1.59</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3085</td><td char="." align="char">2718</td><td char="." align="char">1.14</td></tr><tr><td align="left" rowspan="4">DNATORNA</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">10256</td><td char="." align="char">5668</td><td char="." align="char">1.81</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7346</td><td char="." align="char">5468</td><td char="." align="char">1.34</td></tr><tr><td char="." align="char">4</td><td char="." align="char">5179</td><td char="." align="char">3098</td><td char="." align="char">1.67</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3196</td><td char="." align="char">2758</td><td char="." align="char">1.16</td></tr></tbody></table></table-wrap><table-wrap id="Tab8"><label>Table 8</label><caption><p>Runtimes (in seconds) and corresponding speedups of SeQual-Stream over SeQual for the SRR589 paired-end dataset (“Downloading” scenario, testbed 2)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Operation</th><th align="left">Dataset</th><th align="left">Mode</th><th align="left">Nodes</th><th align="left">SeQual</th><th align="left">SeQual-Stream</th><th align="left">Speedup</th></tr></thead><tbody><tr><td align="left" rowspan="4">QUALITY</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">9369</td><td char="." align="char">4924</td><td char="." align="char">1.90</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7666</td><td char="." align="char">4023</td><td char="." align="char">1.91</td></tr><tr><td char="." align="char">4</td><td char="." align="char">5152</td><td char="." align="char">3601</td><td char="." align="char">1.43</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3418</td><td char="." align="char">2797</td><td char="." align="char">1.22</td></tr><tr><td align="left" rowspan="4">NONIUPAC</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">13253</td><td char="." align="char">5894</td><td char="." align="char">2.25</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7703</td><td char="." align="char">5281</td><td char="." align="char">1.46</td></tr><tr><td char="." align="char">4</td><td char="." align="char">4887</td><td char="." align="char">3478</td><td char="." align="char">1.41</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3172</td><td char="." align="char">2870</td><td char="." align="char">1.11</td></tr><tr><td align="left" rowspan="4">TRIMRIGHTP</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">13343</td><td char="." align="char">5022</td><td char="." align="char">2.66</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7532</td><td char="." align="char">4285</td><td char="." align="char">1.76</td></tr><tr><td char="." align="char">4</td><td char="." align="char">4813</td><td char="." align="char">3483</td><td char="." align="char">1.38</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3085</td><td char="." align="char">2891</td><td char="." align="char">1.07</td></tr><tr><td align="left" rowspan="4">DNATORNA</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">10256</td><td char="." align="char">5632</td><td char="." align="char">1.82</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7346</td><td char="." align="char">5133</td><td char="." align="char">1.43</td></tr><tr><td char="." align="char">4</td><td char="." align="char">5179</td><td char="." align="char">3070</td><td char="." align="char">1.69</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3196</td><td char="." align="char">2864</td><td char="." align="char">1.12</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec17">
      <title>Analysis of the scalability</title>
      <p id="Par66">This section presents a final set of experiments aimed at improving and analyzing the scalability of our streaming tool. In order to demonstrate its scaling capabilities, these experiments are focused on overcoming the main bottlenecks that limited performance so far.</p>
      <p id="Par67">For this purpose, the “downloaded” scenario has been evaluated using the second testbed (see Table <xref rid="Tab2" ref-type="table">2</xref>), which provides SSD disks, to speed up the writing of both the input datasets and the results to HDFS. In addition, the input files have been previously copied to the SSD disk of the master node for faster read times. In these experiments, the same four operations have been executed using the largest dataset that can be processed in this testbed (i.e., SRR114, as SRR589 is too large to be stored on the SSD disks). Experiments with only one worker node must also use the HDD disk of the worker, as the full input dataset and the generated output do not fit entirely on its SSD. For the sake of simplicity, results are shown for paired-end mode only.</p>
      <p id="Par68">Table <xref rid="Tab9" ref-type="table">9</xref> shows the results obtained. Overall, the speedups are significantly higher, reaching a maximum value of 9.89x when using 8 nodes. It is interesting to note the significant differences between the operations. The NONIUPAC filter and the TRIMRIGHTP trimmer achieve the greatest speedups, followed by the DNATORNA formatter with a maximum of 6.26<inline-formula id="IEq24"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M48"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq24.gif"/></alternatives></inline-formula>. The QUALITY filter gives the worst results, with a maximum of 4.72<inline-formula id="IEq25"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M50"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq25.gif"/></alternatives></inline-formula>. As an attempt was made to remove all potential sources of bottlenecks in these experiments, most of the runtime corresponds to pure processing time and not to copying and/or writing the results. Therefore, the differences in runtimes and speedups are mainly due to the differences in performance and computational efficiency of each quality control operation.<table-wrap id="Tab9"><label>Table 9</label><caption><p>Runtimes (in seconds) and corresponding speedups of SeQual-Stream for the SRR114 paired-end dataset (“Downloaded” scenario, testbed 2 with SSD disks)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Operation</th><th align="left">Dataset</th><th align="left">Mode</th><th align="left">Nodes</th><th align="left">SeQual-Stream</th><th align="left">Speedup over 1 node</th></tr></thead><tbody><tr><td align="left" rowspan="4">QUALITY</td><td align="left" rowspan="4">SRR114</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">1440</td><td char="." align="char">1.00</td></tr><tr><td char="." align="char">2</td><td char="." align="char">625</td><td char="." align="char">2.30</td></tr><tr><td char="." align="char">4</td><td char="." align="char">590</td><td char="." align="char">2.44</td></tr><tr><td char="." align="char">8</td><td char="." align="char">305</td><td char="." align="char">4.72</td></tr><tr><td align="left" rowspan="4">NONIUPAC</td><td align="left" rowspan="4">SRR114</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">1661</td><td char="." align="char">1.00</td></tr><tr><td char="." align="char">2</td><td char="." align="char">818</td><td char="." align="char">2.03</td></tr><tr><td char="." align="char">4</td><td char="." align="char">412</td><td char="." align="char">4.03</td></tr><tr><td char="." align="char">8</td><td char="." align="char">186</td><td char="." align="char">8.93</td></tr><tr><td align="left" rowspan="4">TRIMRIGHTP</td><td align="left" rowspan="4">SRR114</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">1681</td><td char="." align="char">1.00</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1073</td><td char="." align="char">1.57</td></tr><tr><td char="." align="char">4</td><td char="." align="char">553</td><td char="." align="char">3.04</td></tr><tr><td char="." align="char">8</td><td char="." align="char">170</td><td char="." align="char">9.89</td></tr><tr><td align="left" rowspan="4">DNATORNA</td><td align="left" rowspan="4">SRR114</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">1541</td><td char="." align="char">1.00</td></tr><tr><td char="." align="char">2</td><td char="." align="char">683</td><td char="." align="char">2.26</td></tr><tr><td char="." align="char">4</td><td char="." align="char">535</td><td char="." align="char">2.88</td></tr><tr><td char="." align="char">8</td><td char="." align="char">246</td><td char="." align="char">6.26</td></tr></tbody></table></table-wrap></p>
    </sec>
  </sec>
  <sec id="Sec18">
    <title>Conclusion</title>
    <p id="Par69">The large amount of genomic data generated by modern NGS technologies reinforces the need for bioinformatics tools capable of reducing the time required for processing them as much as possible. In this paper we have presented SeQual-Stream, a Big Data tool for quality control of raw NGS datasets which seeks to reduce data processing times through exploiting Apache Spark and its Structured Streaming API. This combination allows our tool to take full advantage of distributed-memory systems such as clusters and to further accelerate quality control by overlapping data processing with downloading and/or HDFS copy operations.</p>
    <p id="Par70">The performance evaluation, conducted on two cluster testbeds using three publicly available datasets, has experimentally demonstrated that our stream approach can be up to nearly three times faster than the counterpart tool based on batch processing. This makes SeQual-Stream a useful tool in those cases where multiple large experiments need to be carried out, since such a speedup on each experiment would result in a significant overall improvement. This is especially significant when using small-scale clusters, which is a common computing facility that most biologists and bioinformaticians have access to. In fact, our results have also shown that a maximum speedup of around 10x can be achieved when using eight nodes compared to just using a single node.</p>
    <p id="Par71">As future work, we would be interested in adapting to the stream paradigm other quality control operations that perform their processing considering the whole set of sequences, which makes them much more complex to implement in streaming mode. The possibility of exploring the use of other stream processing frameworks such as Apache Flink is also of great interest.</p>
  </sec>
  <sec id="Sec19">
    <title>Availability and requirements</title>
    <p id="Par72">Project name: SeQual-Stream</p>
    <p id="Par73">Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/UDC-GAC/SeQual-Stream">https://github.com/UDC-GAC/SeQual-Stream</ext-link></p>
    <p id="Par74">Operating system(s): Platform independent</p>
    <p id="Par75">Programming language: Java</p>
    <p id="Par76">Other requirements: JRE 1.8 or higher, Apache Spark 3.0 or higher, Apache Hadoop 2.10 or higher (needed for HDFS)</p>
    <p id="Par77">License: GNU GPLv3</p>
    <p id="Par78">Any restrictions to use by non-academics: None</p>
  </sec>
  <sec sec-type="supplementary-material">
    <sec id="Sec20">
      <title>Supplementary Information</title>
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2023_5530_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1:</bold> PDF document containing a detailed user's guide for SeQual-Stream.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>NGS</term>
        <def>
          <p id="Par4">Next generation sequencing</p>
        </def>
      </def-item>
      <def-item>
        <term>HDFS</term>
        <def>
          <p id="Par5">Hadoop distributed file system</p>
        </def>
      </def-item>
      <def-item>
        <term>RDD</term>
        <def>
          <p id="Par6">Resilient distributed dataset</p>
        </def>
      </def-item>
      <def-item>
        <term>SRA</term>
        <def>
          <p id="Par7">Sequence read archive</p>
        </def>
      </def-item>
      <def-item>
        <term>NCBI</term>
        <def>
          <p id="Par8">National Center for Biotechnology Information</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary Information</title>
    <p>The online version contains supplementary material available at 10.1186/s12859-023-05530-7.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author Contributions</title>
    <p>OC and RRE conceived the software and designed the distributed implementation. OC is responsible for implementing the software. OC conducted the experiments and performed the data analysis. RRE and JT proposed and supervised the project. OC drafted the manuscript with contributions from all authors. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Grants PID2019-104184RB-I00 and PID2022-136435NB-I00, funded by MCIN/AEI/10.13039/501100011033, PID2022 also funded by “ERDF A way of making Europe”, EU. Grant ED431C 2021/30, funded by Xunta de Galicia under the Consolidation Program of Competitive Reference Groups. Predoctoral grant of Óscar Castellanos-Rodríguez ref. ED481A 2022/067, also funded by Xunta de Galicia. The funding agencies did not participate in the design of the study and collection, analysis, and interpretation of data and in writing the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The software, documentation and source code of SeQual-Stream are publicly available at the GitHub repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/UDC-GAC/SeQual-Stream">https://github.com/UDC-GAC/SeQual-Stream</ext-link>. The real datasets analyzed during this study are also publicly available at the NCBI SRA repository (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra">https://www.ncbi.nlm.nih.gov/sra</ext-link>) using the accession numbers: SRR567455, SRR11442499 and SRR5893671.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par79">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par80">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par81">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Phillips</surname>
            <given-names>KA</given-names>
          </name>
        </person-group>
        <article-title>Assessing the value of next-generation sequencing technologies: an introduction</article-title>
        <source>Value Health</source>
        <year>2018</year>
        <volume>21</volume>
        <issue>9</issue>
        <fpage>1031</fpage>
        <lpage>1032</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jval.2018.06.012</pub-id>
        <?supplied-pmid 30224105?>
        <pub-id pub-id-type="pmid">30224105</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Minoche</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Dohm</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Himmelbauer</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Evaluation of genomic high-throughput sequencing data generated on Illumina HiSeq and genome analyzer systems</article-title>
        <source>Genome Biol</source>
        <year>2011</year>
        <volume>12</volume>
        <issue>R112</issue>
        <fpage>1</fpage>
        <lpage>15</lpage>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Edgar</surname>
            <given-names>RC</given-names>
          </name>
          <name>
            <surname>Flyvbjerg</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Error filtering, pair assembly and error correction for next-generation sequencing reads</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>31</volume>
        <issue>21</issue>
        <fpage>3476</fpage>
        <lpage>3482</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btv401</pub-id>
        <?supplied-pmid 26139637?>
        <pub-id pub-id-type="pmid">26139637</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>B</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Assessing the impact of data preprocessing on analyzing Next Generation Sequencing data</article-title>
        <source>Front Bioeng Biotechnol</source>
        <year>2020</year>
        <volume>8</volume>
        <issue>817</issue>
        <fpage>1</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="pmid">32039188</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zaharia</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Apache Spark: a unified engine for big data processing</article-title>
        <source>Commun ACM</source>
        <year>2016</year>
        <volume>59</volume>
        <issue>11</issue>
        <fpage>56</fpage>
        <lpage>65</lpage>
        <pub-id pub-id-type="doi">10.1145/2934664</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">Shvachko K, Kuang H, Radia S, Chansler R. The Hadoop distributed file system. In: Proceedings of the IEEE 26th symposium on mass storage systems and technologies (MSST 2010), Incline Village, NV, USA, (2010); 1–10.</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">The Apache Software Foundation: structured streaming programming guide. <ext-link ext-link-type="uri" xlink:href="https://spark.apache.org/docs/3.1.1/structured-streaming-programming-guide.html">https://spark.apache.org/docs/3.1.1/structured-streaming-programming-guide.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dean</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ghemawat</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>MapReduce: simplified data processing on large clusters</article-title>
        <source>Commun ACM</source>
        <year>2008</year>
        <volume>51</volume>
        <issue>1</issue>
        <fpage>107</fpage>
        <lpage>113</lpage>
        <pub-id pub-id-type="doi">10.1145/1327452.1327492</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Ghemawat S, Gobioff H, Leung S-T. The Google file system. In: Proceedings of the 19th ACM symposium on operating systems principles (SOSP’03), Bolton Landing, NY, USA, 2003, pp 29–43</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">The Apache Software Foundation: Apache Hadoop. <ext-link ext-link-type="uri" xlink:href="https://hadoop.apache.org">https://hadoop.apache.org</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lakshman</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Malik</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Cassandra: a decentralized structured storage system</article-title>
        <source>ACM SIGOPS Oper Syst Rev</source>
        <year>2010</year>
        <volume>44</volume>
        <issue>2</issue>
        <fpage>35</fpage>
        <lpage>40</lpage>
        <pub-id pub-id-type="doi">10.1145/1773912.1773922</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Zaharia M, et al. Resilient Distributed Datasets: A fault-tolerant abstraction for in-memory cluster computing. In: Proceedings of the 9th USENIX symposium on networked systems design and implementation (NSDI’12), San Jose, CA, USA, 2012, pp 15–28</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">The Apache Software Foundation: Spark SQL, DataFrames and Datasets Guide. <ext-link ext-link-type="uri" xlink:href="https://spark.apache.org/docs/latest/sql-programming-guide.html">https://spark.apache.org/docs/latest/sql-programming-guide.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">The Apache Software Foundation: Spark Streaming Programming Guide. <ext-link ext-link-type="uri" xlink:href="https://spark.apache.org/docs/latest/streaming-programming-guide.html">https://spark.apache.org/docs/latest/streaming-programming-guide.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thein</surname>
            <given-names>KMM</given-names>
          </name>
        </person-group>
        <article-title>Apache Kafka: next generation distributed messaging system</article-title>
        <source>Int J Sci Eng Technol Res</source>
        <year>2014</year>
        <volume>3</volume>
        <issue>47</issue>
        <fpage>9478</fpage>
        <lpage>9483</lpage>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Chung W-C, Ho J-M, Lin C-Y, Lee D-T. CloudEC: A MapReduce-based algorithm for correcting errors in next-generation sequencing big data. In: Proceedings of the 2017 IEEE international conference on big data (IEEE BigData 2017), Boston, MA, USA, (2017);2836–2842.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Abuín</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Pichel</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Pena</surname>
            <given-names>TF</given-names>
          </name>
          <name>
            <surname>Amigo</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>BigBWA: approaching the Burrows-Wheeler aligner to big data technologies</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>31</volume>
        <issue>24</issue>
        <fpage>4003</fpage>
        <lpage>4005</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btv506</pub-id>
        <?supplied-pmid 26323715?>
        <pub-id pub-id-type="pmid">26323715</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Gordon A, Hannon GJ. FASTX-Toolkit: FASTQ/A Short-reads Pre-processing Tools. <ext-link ext-link-type="uri" xlink:href="http://hannonlab.cshl.edu/fastx_toolkit">http://hannonlab.cshl.edu/fastx_toolkit</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schmieder</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Edwards</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Quality control and preprocessing of metagenomic datasets</article-title>
        <source>Bioinformatics</source>
        <year>2011</year>
        <volume>27</volume>
        <issue>6</issue>
        <fpage>863</fpage>
        <lpage>864</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btr026</pub-id>
        <?supplied-pmid 21278185?>
        <pub-id pub-id-type="pmid">21278185</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fukasawa</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ermini</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Carty</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Cheung</surname>
            <given-names>M-S</given-names>
          </name>
        </person-group>
        <article-title>LongQC: a quality control tool for third generation sequencing long read data</article-title>
        <source>G3 Genes Genom Genet</source>
        <year>2020</year>
        <volume>10</volume>
        <issue>4</issue>
        <fpage>1193</fpage>
        <lpage>1196</lpage>
        <pub-id pub-id-type="doi">10.1534/g3.119.400864</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kumar</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Ertel</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Feldman</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Kupper</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Fortina</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>iSeqQC: a tool for expression-based quality control in RNA sequencing</article-title>
        <source>BMC Bioinform</source>
        <year>2020</year>
        <volume>21</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1186/s12859-020-3399-8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ning</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>QC-Chain: fast and holistic quality control method for next-generation sequencing data</article-title>
        <source>PLOS ONE</source>
        <year>2013</year>
        <volume>8</volume>
        <issue>4</issue>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0060234</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cantu</surname>
            <given-names>VA</given-names>
          </name>
          <name>
            <surname>Sadural</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Edwards</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>PRINSEQ++, a multi-threaded tool for fast and efficient quality control and preprocessing of sequencing datasets</article-title>
        <source>PeerJ Preprints</source>
        <year>2019</year>
        <volume>7</volume>
        <fpage>1</fpage>
        <lpage>3</lpage>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Andrews, S. FastQC: A Quality Control Tool for High Throughput Sequence Data. <ext-link ext-link-type="uri" xlink:href="https://www.bioinformatics.babraham.ac.uk/projects/fastqc/">https://www.bioinformatics.babraham.ac.uk/projects/fastqc/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Sena</surname>
            <given-names>Brandine G</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>AD</given-names>
          </name>
        </person-group>
        <article-title>Falco: high-speed FastQC emulation for quality control of sequencing data</article-title>
        <source>F1000Research</source>
        <year>2019</year>
        <volume>8</volume>
        <fpage>1874</fpage>
        <pub-id pub-id-type="doi">10.12688/f1000research.21142.1</pub-id>
        <pub-id pub-id-type="pmid">33552473</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>SOAPnuke: a MapReduce acceleration-supported software for integrated quality control and preprocessing of high-throughput sequencing data</article-title>
        <source>GigaScience</source>
        <year>2017</year>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>gix120</fpage>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Expósito</surname>
            <given-names>RR</given-names>
          </name>
          <name>
            <surname>Galego-Torreiro</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>González-Domínguez</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>SeQual: big data tool to perform quality control and data preprocessing of large NGS datasets</article-title>
        <source>IEEE Access</source>
        <year>2020</year>
        <volume>8</volume>
        <fpage>146075</fpage>
        <lpage>146084</lpage>
        <pub-id pub-id-type="doi">10.1109/ACCESS.2020.3015016</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Melsted</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Halldórsson</surname>
            <given-names>BV</given-names>
          </name>
        </person-group>
        <article-title>KmerStream: streaming algorithms for k-mer abundance estimation</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <issue>24</issue>
        <fpage>3541</fpage>
        <lpage>3547</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu713</pub-id>
        <?supplied-pmid 25355787?>
        <pub-id pub-id-type="pmid">25355787</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mohamadi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Birol</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>ntCard: a streaming algorithm for cardinality estimation in genomics data</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <issue>9</issue>
        <fpage>1324</fpage>
        <lpage>1330</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw832</pub-id>
        <?supplied-pmid 28453674?>
        <pub-id pub-id-type="pmid">28453674</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Behera S, Gayen S, Deogun JS, Vinodchandran NV. KmerEstimate: a streaming algorithm for estimating k-mer counts with optimal space usage. In: Proceedings of the 9th ACM international conference on bioinformatics, computational biology, and health informatics (ACM-BCB 2018), Washington, DC, USA, (2018);438–447.</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Irber LC, Brown CT. Efficient cardinality estimation for k-mers in large DNA sequencing data sets. bioRxiv, (2016);1–5.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rathee</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kashyap</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>StreamAligner: a streaming based sequence aligner on Apache Spark</article-title>
        <source>J Big Data</source>
        <year>2018</year>
        <volume>5</volume>
        <issue>8</issue>
        <fpage>1</fpage>
        <lpage>18</lpage>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Mushtaq H, Ahmed N, Al-Ars Z. Streaming distributed DNA sequence alignment using Apache Spark. In: Proceedings of the 2017 IEEE 17th International conference on bioinformatics and bioengineering (BIBE 2017), Washington, DC, USA, (2017);188–193.</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Valdes</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Stebliankin</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Narasimhan</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Large scale microbiome profiling in the cloud</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <issue>14</issue>
        <fpage>13</fpage>
        <lpage>22</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btz356</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mushtaq</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ahmed</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Al-Ars</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>SparkGA2: production-quality memory-efficient Apache Spark based genome analysis framework</article-title>
        <source>PLOS ONE</source>
        <year>2019</year>
        <volume>14</volume>
        <issue>12</issue>
        <fpage>1</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0224784</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Mushtaq H, Al-Ars Z. Cluster-based Apache Spark implementation of the GATK DNA analysis pipeline. In: Proceedings of the 2015 IEEE International conference on bioinformatics and biomedicine (BIBM’15), Washington, DC, USA, (2015);1471–1477.</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tian</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Transposon insertions regulate genome-wide allele-specific expression and underpin flower colour variations in apple (Malus spp.)</article-title>
        <source>Plant Biotechnol J</source>
        <year>2022</year>
        <volume>20</volume>
        <issue>7</issue>
        <fpage>1285</fpage>
        <lpage>1297</lpage>
        <pub-id pub-id-type="doi">10.1111/pbi.13806</pub-id>
        <?supplied-pmid 35258172?>
        <pub-id pub-id-type="pmid">35258172</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Abuín</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Pichel</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Pena</surname>
            <given-names>TF</given-names>
          </name>
          <name>
            <surname>Amigo</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>SparkBWA: speeding up the alignment of high-throughput DNA sequencing data</article-title>
        <source>PLOS ONE</source>
        <year>2016</year>
        <volume>11</volume>
        <issue>5</issue>
        <fpage>1</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0155461</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>QTL mapping and identification of genes associated with the resistance to <italic>Acanthoscelides obtectus</italic> in cultivated common bean using a high-density genetic linkage map</article-title>
        <source>BMC Plant Biol</source>
        <year>2022</year>
        <volume>22</volume>
        <fpage>1</fpage>
        <lpage>15</lpage>
        <?supplied-pmid 34979920?>
        <pub-id pub-id-type="pmid">34979920</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Bai</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Meixia</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Bivariate genome-wide association study of the growth plasticity of staphylococcus aureus in coculture with escherichia coli</article-title>
        <source>Appl Microbiol Biotechnol</source>
        <year>2020</year>
        <volume>104</volume>
        <fpage>5437</fpage>
        <lpage>5447</lpage>
        <pub-id pub-id-type="doi">10.1007/s00253-020-10636-6</pub-id>
        <?supplied-pmid 32350560?>
        <pub-id pub-id-type="pmid">32350560</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">National Center for Biotechnology Information: The Sequence Read Archive (SRA). <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra">https://www.ncbi.nlm.nih.gov/sra</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kodama</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shumway</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Leinonen</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>The sequence read archive: explosive growth of sequencing data</article-title>
        <source>Nucleic Acids Res</source>
        <year>2011</year>
        <volume>40</volume>
        <issue>D1</issue>
        <fpage>54</fpage>
        <lpage>56</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkr854</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">National Center for Biotechnology Information: NCBI. <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/">https://www.ncbi.nlm.nih.gov/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wheeler</surname>
            <given-names>DL</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Database resources of the National Center for Biotechnology Information</article-title>
        <source>Nucleic Acids Res</source>
        <year>2007</year>
        <volume>36</volume>
        <issue>Supp 1</issue>
        <fpage>13</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkm1000</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <mixed-citation publication-type="other">Shi H, Li W, Xu X. Learning the comparing and converting method of sequence Phred quality score. In: Proceedings of the 2016 6th International conference on management, education, information and control (MEICI 2016), Shenyang, China, (2016);260–263.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10612204</article-id>
    <article-id pub-id-type="publisher-id">5530</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-023-05530-7</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Software</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SeQual-Stream: approaching stream processing to quality control of NGS datasets</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Castellanos-Rodríguez</surname>
          <given-names>Óscar</given-names>
        </name>
        <address>
          <email>oscar.castellanos@udc.es</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Expósito</surname>
          <given-names>Roberto R.</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Touriño</surname>
          <given-names>Juan</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/01qckj285</institution-id><institution-id institution-id-type="GRID">grid.8073.c</institution-id><institution-id institution-id-type="ISNI">0000 0001 2176 8535</institution-id><institution>Universidade da Coruña, CITIC, </institution><institution>Computer Architecture Group, Campus de Elviña, </institution></institution-wrap>15071 A Coruña, Spain </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>27</day>
      <month>10</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>27</day>
      <month>10</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <volume>24</volume>
    <elocation-id>403</elocation-id>
    <history>
      <date date-type="received">
        <day>30</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>12</day>
        <month>10</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Quality control of DNA sequences is an important data preprocessing step in many genomic analyses. However, all existing parallel tools for this purpose are based on a batch processing model, needing to have the complete genetic dataset before processing can even begin. This limitation clearly hinders quality control performance in those scenarios where the dataset must be downloaded from a remote repository and/or copied to a distributed file system for its parallel processing.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">In this paper we present SeQual-Stream, a streaming tool that allows performing multiple quality control operations on genomic datasets in a fast, distributed and scalable way. To do so, our approach relies on the Apache Spark framework and the Hadoop Distributed File System (HDFS) to fully exploit the stream paradigm and accelerate the preprocessing of large datasets as they are being downloaded and/or copied to HDFS. The experimental results have shown significant improvements in the execution times of SeQual-Stream when compared to a batch processing tool with similar quality control features, providing a maximum speedup of 2.7<inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M2"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq1.gif"/></alternatives></inline-formula> when processing a dataset with more than 250 million DNA sequences, while also demonstrating good scalability features.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p id="Par3">Our solution provides a more scalable and higher performance way to carry out quality control of large genomic datasets by taking advantage of stream processing features. The tool is distributed as free open-source software released under the GNU AGPLv3 license and is publicly available to download at <ext-link ext-link-type="uri" xlink:href="https://github.com/UDC-GAC/SeQual-Stream">https://github.com/UDC-GAC/SeQual-Stream</ext-link>.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Quality control</kwd>
      <kwd>Big data</kwd>
      <kwd>Stream processing</kwd>
      <kwd>Apache Spark</kwd>
      <kwd>Next generation sequencing (NGS)</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Xunta de Galicia and FEDER funds of the European Union</institution>
        </funding-source>
        <award-id>ED431G 2019/01</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100010801</institution-id>
            <institution>Xunta de Galicia</institution>
          </institution-wrap>
        </funding-source>
        <award-id>ED481A 2022/067</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004837</institution-id>
            <institution>Ministerio de Ciencia e Innovación</institution>
          </institution-wrap>
        </funding-source>
        <award-id>PID2019-104184RB-I00 / AEI / 10.13039 / 501100011033</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© BioMed Central Ltd., part of Springer Nature 2023</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par9">Obtaining DNA sequences from living beings is usually the first step in the studies developed by biologists and bioinformaticians. The continuous development of Next Generation Sequencing (NGS) technologies [<xref ref-type="bibr" rid="CR1">1</xref>] during the last decade has led to a vertiginous increase in the amount of available genomic data. Hundreds of millions of sequences (the so-called reads) can now be generated in a single experiment at a drastically reduced cost. However, the accuracy of current NGS platforms is not high in all cases. The quality of downstream analyses may be affected because of the artifacts introduced in some DNA fragments during the sequencing process [<xref ref-type="bibr" rid="CR2">2</xref>, <xref ref-type="bibr" rid="CR3">3</xref>], regardless of the NGS platform. Therefore, quality control is an essential preprocessing step for raw NGS data [<xref ref-type="bibr" rid="CR4">4</xref>], removing or modifying those input reads that are not considered useful.</p>
    <p id="Par10">In this paper we introduce SeQual-Stream, a parallel tool implemented in Java that allows performing multiple quality control operations (e.g., trimming, filtering) on large genomic datasets in a distributed and scalable way. To do so, it takes full advantage of the Apache Spark Big Data framework [<xref ref-type="bibr" rid="CR5">5</xref>] together with the Hadoop Distributed File System (HDFS) [<xref ref-type="bibr" rid="CR6">6</xref>]. Up to our knowledge, all existing parallel quality control tools operate on a batch processing model, which means that they require the entire input dataset before any data processing can begin. This poses a performance constraint, as downloading the data from a remote repository and copying them to a distributed file system such as HDFS for parallel processing are costly operations that significantly delay the start of the quality control. This problem is especially relevant in the NGS context as the size of the genomic datasets is continuously increasing, which demands more efficient processing modes. To overcome this issue, SeQual-Stream has been implemented upon the Spark Structured Streaming API [<xref ref-type="bibr" rid="CR7">7</xref>], in order to apply the quality control operations to the input reads as the data are being downloaded from a remote location (e.g., a web repository) and/or copied to HDFS. This stream-based processing mode significantly reduces runtimes by enabling efficient overlapping of download and copy operations to HDFS with the actual data processing performed by SeQual-Stream.</p>
    <p id="Par11">The main contributions of this paper over the state of the art are the following:<list list-type="bullet"><list-item><p id="Par12">Up to our knowledge, we introduce the first quality control tool that can exploit the stream processing model to accelerate the preprocessing of raw NGS datasets.</p></list-item><list-item><p id="Par13">We conduct an extensive experimental evaluation on two cluster testbeds using publicly available real-world datasets, both to demonstrate the performance benefits of our approach compared to a batch processing quality control tool and to analyze its scalability.</p></list-item><list-item><p id="Par14">SeQual-Stream is implemented in “pure” (100%) Java code in order to maximize cross-platform portability, whereas supporting standard unaligned sequence formats (FASTQ/FASTA). The tool is publicly available under a GNU AGPLv3 license.</p></list-item></list></p>
    <sec id="Sec2">
      <title>Quality control</title>
      <p id="Par15">Current NGS technologies can generate a huge number of DNA segments massively and in parallel, in less time and at a lower cost per base than previous platforms. However, they also introduce errors in some sequences, making them not useful for downstream analyses. So, quality control consists of removing those sequences or modifying them to be useful in order to improve subsequent processing (e.g., sequence alignment). Multiple operations can be performed within the context of quality control. For example, different filtering criteria can be applied when removing sequences according to their length (i.e., number of bases), the quality scores of the bases, the proportion of content of certain bases, or according to the occurrence of certain base patterns. When modifying sequences, trimming techniques can be used so that they are trimmed, for instance, to a certain average quality or to a maximum length. Another example is formatting techniques, such as the conversion from FASTQ to FASTA or between DNA and RNA, as well as renaming the sequence identifiers, among others.</p>
    </sec>
    <sec id="Sec3">
      <title>Big data</title>
      <p id="Par16">The great development of NGS has led to a significant increase in the amount of genomic data to be processed, making the concept of Big Data a fundamental asset in current biomedicine. Big Data often refers to a massive volume of both structured and unstructured data that is so large and difficult to process using traditional methods and systems. The rise of Big Data is usually associated to novel technologies and algorithms such as MapReduce [<xref ref-type="bibr" rid="CR8">8</xref>], a parallel programming paradigm characterized by being divided into two distinct phases: Map and Reduce. These sub-processes are executed in a distributed manner relying on a cluster of nodes. MapReduce is also the name of the Google’s proprietary implementation, who first proposed the model in 2004, given the need to optimize user search results on the web. To support this type of processing, a distributed data storage system, based on storing data on more than one node, is used. Google proposed the Google File System (GFS) [<xref ref-type="bibr" rid="CR9">9</xref>], a high-performance distributed file system that follows a master/worker architecture. Following this model, other technologies implementing it came to light. Of particular note is the open-source Apache Hadoop framework [<xref ref-type="bibr" rid="CR10">10</xref>]. Hadoop integrates HDFS [<xref ref-type="bibr" rid="CR6">6</xref>] as storage layer to distribute files across the cluster divided into data blocks, thus providing the prior division of the data needed by the Hadoop MapReduce data processing engine, in addition to replicating those blocks to provide fault tolerance. Both MapReduce and Hadoop are intended for batch processing, since they require the input data to be stored completely in a distributed manner before processing begins.</p>
      <sec id="Sec4">
        <title>Apache Spark and stream processing</title>
        <p id="Par17">Apache Spark [<xref ref-type="bibr" rid="CR5">5</xref>] is an open-source, general-purpose framework for distributed processing designed to be simple and fast. Spark emerges as an evolution of Hadoop, which is very limited in terms of processing modes and performance. Some of the improvements that Spark brings over its predecessor are in-memory computing, support for stream processing and the ease to interact with multiple persistent storage systems, such as HDFS or Cassandra [<xref ref-type="bibr" rid="CR11">11</xref>].</p>
        <p id="Par18">Spark provides a fundamental data abstraction for distributed processing: the Resilient Distributed Dataset (RDD) [<xref ref-type="bibr" rid="CR12">12</xref>]. An RDD is defined as a collection of elements partitioned across the cluster nodes and capable of operating in parallel. Two alternatives to RDDs are currently offered by Spark: DataFrames and Datasets [<xref ref-type="bibr" rid="CR13">13</xref>]. DataFrames organize data in columns, similar to a table in a relational database. Unlike RDDs, they allow better handling of structured data and are able to optimize the queries performed. Datasets are an extension of DataFrames and try to combine the advantages of RDDs and DataFrames in the same API, i.e., the ease of use of RDDs and the performance optimization of DataFrames.</p>
        <p id="Par19">The key Spark feature for the development of SeQual-Stream is the support for stream processing by providing the Structured Streaming API [<xref ref-type="bibr" rid="CR7">7</xref>], as opposed to its batch API. Structured Streaming was designed as an evolution of the legacy Spark Streaming API [<xref ref-type="bibr" rid="CR14">14</xref>]. This legacy API represents the continuous data stream with a high-level abstraction called discretized stream (DStream), which is represented internally as a sequence of RDDs. Spark Streaming follows a micro-batch model, consisting of polling the source and dividing the input data into small batches that are processed using the batch API, thus generating batches of processed data. However, Structured Streaming brings several improvements over its predecessor. This API is built on top of the Spark SQL library, using higher-level DataFrames and Datasets as data abstractions. It is also capable of correctly processing data that arrive late to the processing engine. Legacy Spark Streaming only takes into account the timestamp of data reception by Spark, so if an event “a” arrives later than a subsequent event “b”, we would be losing accuracy in the information, which can be equal to data loss. However, Structured Streaming is able to process out-of-order data correctly if it includes a timestamp, thus generating consistent results.</p>
        <p id="Par20">By default, Structured Streaming queries are also processed internally using a micro-batch model, with the important difference that it treats the input data stream as an unbounded table that is continuously being appended by new rows, as shown graphically in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. The API also allows to choose an alternative processing mode called Continuous Processing, which can achieve lower end-to-end latencies, although it is still in an experimental state. Its operation is based on constantly reading the source and processing the data as soon as they are available, instead of polling the source periodically. Another feature is allowing stream jobs to be expressed in the same way as a batch job with static data. The Spark SQL engine takes care of executing it incrementally and continuously, updating the final result as the data arrive. Each time the result table is updated, it is written (persisted) to an external system, which can be a file or a Kafka topic [<xref ref-type="bibr" rid="CR15">15</xref>], among other options. Depending on the data to be written to the output, three modes are differentiated:<list list-type="bullet"><list-item><p id="Par21">Complete mode: all table rows are written in each update.</p></list-item><list-item><p id="Par22">Append mode: only new rows are written. This makes it only applicable when existing rows are expected to remain unchanged. This is the default mode.</p></list-item><list-item><p id="Par23">Update mode: the rows that have changed since the last table update are written.</p></list-item></list><fig id="Fig1"><label>Fig. 1</label><caption><p>Structured streaming model in Apache Spark</p></caption><graphic xlink:href="12859_2023_5530_Fig1_HTML" id="MO1"/></fig></p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec5">
    <title>Related work</title>
    <p id="Par24">There is a wide variety of tools within the context of bioinformatics. Many of them follow a batch processing model, such as CloudEC [<xref ref-type="bibr" rid="CR16">16</xref>] for error correction or BigBWA [<xref ref-type="bibr" rid="CR17">17</xref>] for sequence alignment, both of them Big Data tools relying on the Apache Hadoop framework.</p>
    <p id="Par25">Focusing on tools for performing quality control, all existing approaches are based on batch processing. Examples of such tools are FASTX-Toolkit [<xref ref-type="bibr" rid="CR18">18</xref>], PRINSEQ [<xref ref-type="bibr" rid="CR19">19</xref>], LongQC [<xref ref-type="bibr" rid="CR20">20</xref>] and iSeqQC [<xref ref-type="bibr" rid="CR21">21</xref>], which do not provide any support for parallel processing. QC-Chain [<xref ref-type="bibr" rid="CR22">22</xref>] and PRINSEQ++ [<xref ref-type="bibr" rid="CR23">23</xref>] does provide such parallel support through multithreading, and so their scalability is limited to a single node, whereas FastQC [<xref ref-type="bibr" rid="CR24">24</xref>] and Falco [<xref ref-type="bibr" rid="CR25">25</xref>], which is an emulation of the former, only support parallelism at the file level. SOAPnuke [<xref ref-type="bibr" rid="CR26">26</xref>] is able to distribute the data processing to a cluster of nodes through Hadoop, whereas SeQual [<xref ref-type="bibr" rid="CR27">27</xref>] is also capable of scaling out across a cluster by relying on the more efficient Spark RDDs, greatly enhancing performance compared to previous solutions. Nevertheless, both SOAPnuke and SeQual are still limited by the batch processing operation mode they are based on. In terms of functionality, we have taken SeQual as reference for developing SeQual-Stream due to its wide range of supported quality control operations (more than 30), one of the largest among the state of the art.</p>
    <p id="Par26">It is also interesting to mention other bioinformatics tools that follow a stream processing model for other purposes. For instance, we can find in the literature several solutions for estimating the number of k-mers in genomic datasets, such as KmerStream [<xref ref-type="bibr" rid="CR28">28</xref>], ntCard [<xref ref-type="bibr" rid="CR29">29</xref>], KmerEstimate [<xref ref-type="bibr" rid="CR30">30</xref>] and Khmer [<xref ref-type="bibr" rid="CR31">31</xref>]. Other tools are focused on sequence alignment (StreamAligner [<xref ref-type="bibr" rid="CR32">32</xref>], StreamBWA [<xref ref-type="bibr" rid="CR33">33</xref>]), metagenomics profiling (Flint [<xref ref-type="bibr" rid="CR34">34</xref>]) and DNA analysis (SparkGA2 [<xref ref-type="bibr" rid="CR35">35</xref>]). These latter examples are all implemented on top of the legacy Spark Streaming API instead of using Spark Structured Streaming as in our approach.</p>
    <p id="Par27">Finally, as our tool is based on Spark, we consider it important to highlight the usefulness of this Big Data framework in real biological studies. For example, SparkGATK [<xref ref-type="bibr" rid="CR36">36</xref>], a framework for DNA analysis, has been used to detect allele-specific expression genes in plants [<xref ref-type="bibr" rid="CR37">37</xref>]. SparkBWA [<xref ref-type="bibr" rid="CR38">38</xref>], a DNA sequence alignment tool, has been used in [<xref ref-type="bibr" rid="CR39">39</xref>] as part of the analysis pipeline to construct a high-density genetic linkage map for the common bean and identify a gene resistant to the bruchid, as well as to analyze the growth plasticity of bacteria in [<xref ref-type="bibr" rid="CR40">40</xref>].</p>
  </sec>
  <sec id="Sec6">
    <title>Implementation</title>
    <p id="Par28">SeQual-Stream is a parallel Java tool that provides a wide set of operations to apply quality control and data preprocessing on raw NGS data. These operations are grouped into three different categories depending on the functionality they provide: (1) single filters, responsible for discarding input sequences that do not meet a certain criteria (e.g., sequence length), evaluating each sequence independently of the others; (2) trimmers, operations that trim certain sequence bases at the beginning or end; and (3) formatters, operations to change the format of the input dataset (e.g., from DNA to RNA). The tool can receive as input single- or paired-end datasets, supporting FASTQ and FASTA formats. The input files can be stored either in HDFS or locally. It is important to note that there is no real dependency on HDFS as such, but on the Hadoop API, which is fully integrated into Spark. So our tool supports any other file system that is compatible with such an API. In fact, the local file system is just one of the available implementations in addition to HDFS or Amazon S3. For simplicity, we will keep using the term “HDFS” from now on, as it is also the file system used in the experimental evaluation. The datasets may be complete or in the process of being downloaded from a remote server, since SeQual-Stream can process data as new sequences continue to arrive. Note that in the case of having the complete files stored locally, they are also processed in a streaming way as they are being copied to HDFS. Furthermore, our tool features a graphical user interface to provide greater convenience to bioinformaticians and biologists (see Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Fig. S1 ).</p>
    <p id="Par29">Figure <xref rid="Fig2" ref-type="fig">2</xref> shows an overview of the SeQual-Stream dataflow to perform two quality control operations: a trimmer and a filter. In this example, there are only four DNA sequences stored in a remote server and we only show their bases for simplicity. At a certain moment, two of them have already been downloaded in a local file, so that SeQual-Stream can begin to process them by copying the available sequences to HDFS (labeled as “[A]” in the figure). Next, a Spark Dataset containing those sequences is created (“[B]”) to be operated by the trimmer and the filter (“[C]” and “[D]”, respectively). In this example, the trimmer operation is TrimRight, which trims a certain number of bases from each sequence starting from the right (three bases in this case). The filter operation is BaseN, which filters sequences according to whether or not they contain a maximum and/or minimum number of one or several base types (a maximum of three “T” bases is allowed in this case), discarding the first sequence and leaving at the end a single trimmed sequence in the Spark Dataset. Finally, the resulting sequences are written back to HDFS (“[E]”). When more content is obtained from the server, the local input file will be updated and the entire process is repeated with the new sequences. Note that this process is executed in parallel with a previous or subsequent iteration.<fig id="Fig2"><label>Fig. 2</label><caption><p>Overview of the SeQual-Stream dataflow</p></caption><graphic xlink:href="12859_2023_5530_Fig2_HTML" id="MO2"/></fig></p>
    <p id="Par30">Therefore, this dataflow can be divided into three main stages as follows: <list list-type="order"><list-item><p id="Par31">Reading of the input dataset(s), which may be stored in HDFS or locally and may be in the process of being downloaded.</p></list-item><list-item><p id="Par32">Processing of the available sequences by applying the quality control operations configured by the user.</p></list-item><list-item><p id="Par33">Writing of the results to the output files using the path specified by the user.</p></list-item></list>The next sections provide more specific details about the implementation of each stage.</p>
    <sec id="Sec7">
      <title>Reading of the input datasets</title>
      <p id="Par34">The objective of the first stage is the creation of a Spark Dataset that represents in a relational table the sequences to be processed in the next stage. Basically, Structured Streaming operates by indicating a directory in HDFS to be monitored and processing the files as they are written to such directory. The main problem is that once the available data of a certain file has been processed, such file is not processed again even if it is updated with new content. So, it cannot be used to process large files that are still in the process of downloading. To overcome this issue, the proposed solution consists of creating a previous stage in charge of reading the input dataset (“[A]” in Fig. <xref rid="Fig2" ref-type="fig">2</xref>) and generating new files formed by subsets of the input data (called “subfiles”) that Structured Streaming is able to process. Note that this reading stage works iteratively. For example, if there is a subset of sequences downloaded at a given time from a certain dataset, this stage will perform a first iteration to store those sequences in a new subfile on HDFS so that Structured Streaming can process it, and then it will wait for the remaining sequences to be downloaded. After a few seconds, it will recheck the state of the input dataset and, if new data is found, the procedure is repeated through a second iteration, generating a new subfile with new sequences to be processed.</p>
      <p id="Par35">It is important to remark that only complete sequences are copied to subfiles. If no more data is available at a given time and the last sequence is incomplete, only the complete sequences before the last one (if any) are copied while waiting for new data to arrive. Therefore, the copy operations cannot be done on a line-by-line basis, since it is necessary to evaluate if sequences are complete as they are represented in multiple lines (e.g., at least two for FASTA format). This process is even more complex for paired-end datasets, where there are two input files to be downloaded. In addition to copy only complete sequences, it must be done synchronously in both files because one of them may have more available data than the other as download speeds may differ. The solution to this issue is reading the sequences in pairs (i.e., only if both are complete) and copy them together within the same subfile.</p>
      <sec id="Sec8">
        <title>Parallel reading</title>
        <p id="Par36">In order to speed up the previously described process, the reading stage is divided and performed in parallel in one of the cluster nodes through multithreading support. The number of parallel threads used is adapted dynamically by the tool, depending on the computational capacity of the node and the amount of data available at that moment in order to avoid the overhead that would be generated by creating a lot of threads that read few data. A limit is imposed on the amount of data to be copied in a single iteration of the reading stage. This is done to improve the overlap of reading the input dataset and processing it with Structured Streaming. Without this limit, if there is a lot of data that have already been downloaded, the cluster nodes will be mostly idle while waiting for the reading stage to copy them all to HDFS.</p>
      </sec>
      <sec id="Sec9">
        <title>Creation of the Spark dataset</title>
        <p id="Par37">Once new subfiles are copied to HDFS, Structured Streaming is able to automatically detect them to allow SeQual-Stream creating a Spark Dataset of sequences (“[B]” in Fig. <xref rid="Fig2" ref-type="fig">2</xref>). Although Spark supports several common file formats (e.g., JSON, CSV), sequence formats cannot be read straightforwardly, and so the standard text-based file format provided by Spark must be used. By default, this format separates the file on a line-by-line basis. However, FASTQ/FASTA sequences are composed of multiple lines, so it would be interesting to use a character that clearly separates each one. The problem is that although FASTQ sequences begin with the “@” character, this character can also appear in the quality scores. To overcome this issue, the reading stage is in charge of adding a specific string before each sequence when copying it into a subfile in order to be used as an unambiguous separator. Once the sequences can be correctly separated, their different parts, such as their identifier and bases, can be obtained unambiguously, and the corresponding Spark Dataset can be created. For paired-end datasets, the separator string must be added to each pair written to the subfile. So, SeQual-Stream is able to differentiate each sequence of the pair when creating the Spark Dataset.</p>
      </sec>
    </sec>
    <sec id="Sec10">
      <title>Processing of the sequences</title>
      <p id="Par38">The next stage of the pipeline is the processing of the sequences contained on a Spark Dataset by applying the quality control operations selected by the user (“[C]” and “[D]” in Fig. <xref rid="Fig2" ref-type="fig">2</xref>). As previously mentioned, the functionality supported by our tool is inspired on those operations provided by SeQual [<xref ref-type="bibr" rid="CR27">27</xref>], but adapted to the stream processing model. The first group of quality control operations consists of 12 single filters that were implemented using the Spark’s <italic>filter</italic> method. Each operation implements the corresponding boolean function to discard those sequences that do not meet a certain criteria. For example, the Length filter evaluates whether the size of the sequence is smaller and/or larger than an upper and/or lower limit configured by the user.</p>
      <p id="Par39">The second and third group of operations (10 trimmers and 3 formatters, respectively) were implemented using the Spark’s <italic>map</italic> method, which allows to process the Dataset by applying a specific function to each element (i.e., sequence). For example, TrimLeft trims a given number of bases from each sequence (and their quality scores if applicable) starting from the left using the Java <italic>substring</italic> method. Another example is DNAToRNA, a formatter that changes the format of each sequence from DNA to RNA by replacing the thymine bases (represented by a “T” character) with uracil (“U” character) using the Java <italic>replace</italic> method.</p>
      <p id="Par40">Note that all the quality control operations are performed as new sequences get loaded into the Spark Dataset, so that the processing stage efficiently overlaps with the reading of the input dataset.</p>
    </sec>
    <sec id="Sec11">
      <title>Writing of the results</title>
      <p id="Par41">After a certain set of quality control operations is performed over the sequences, they must be written back to HDFS (“[E]” in Fig. <xref rid="Fig2" ref-type="fig">2</xref>). By default, the output sequences are written throughout different output files. This fact is due to two reasons: (1) when processing the sequences in a Spark Dataset, the processing tasks are executed on different cluster nodes so that each one writes to its corresponding output file (or “part” file); (2) when using our stream processing approach, the sequences are written as soon as the subfiles, which contain subsets of the input files, are processed by SeQual-Stream, and thus each subfile generates multiple part files distributed over the cluster.</p>
      <p id="Par42">The main issue of having multiple output files is how to keep the output sequences in the same order that the input. When persisting a Spark Dataset, the different parts are named in alphabetical order so that the original order is maintained. For example, the first part file (“part-0000”) may contain the sequences from 1 to 100, the second one (“part-0001”) from 101 to 200, and so on. The problem arises when using Structured Streaming, since Spark processes each subfile independently and does not preserve any alphabetical naming order between parts generated from different subfiles. Figure <xref rid="Fig3" ref-type="fig">3</xref> illustrates this issue, where two different subfiles are generated at different moments in time from the input dataset being downloaded. In this example, the processing of every subfile is distributed on two nodes, thus generating four part files in total. Parts labeled as “[P1]” and “[P2]” are named in alphabetical order, and the same applies to parts “[P3]” and “[P4]”, but the order is not respected between all of them. A naive solution to this issue would be using the write timestamp of each part file, since the first sequences should be processed and written before the following ones. However, this rule is not consistent: when several subfiles are written to the directory that Structured Streaming is monitoring, there is no guarantee that they will be processed in the same order they were created.</p>
      <p id="Par43">The solution proposed in SeQual-Stream consists of embedding a custom timestamp within each sequence during the reading stage (“[A]” in Fig. <xref rid="Fig2" ref-type="fig">2</xref>) so that the order is set from the very beginning. More specifically, SeQual-Stream must be able to differentiate each generated subfile during such reading stage. So, we use a timestamp composed of two integers to indicate, respectively, each iteration of the reading stage and the thread number that generated the corresponding subfile. For example, thread #5 during iteration #3 will embed the timestamp “3–5” in its sequences. Therefore, SeQual-Stream actually processes a Spark Dataset containing sequences tagged with a custom timestamp. Right before writing the results to HDFS, this Spark Dataset is separated into two columns through a <italic>flatmap</italic> operation: the sequences themselves and their timestamps. This approach allows writing the results partitioned by the timestamp column, an operation that consists of gathering the part files containing sequences with the same timestamp into the same output directory. Those parts are already sorted alphabetically, and thus the global order is ensured. For instance, the part files generated from the sequences with timestamp “3–5” are stored in a directory named “timestamp=3–5”. If a single output file containing all the resulting sequences is preferred by the user, our tool allows to configure an option to merge them together in the appropriate order.</p>
      <p id="Par44">Regarding the writing operation itself, it is done through a Spark object called “StreamingQuery” that remains in a loop as long as there is data to be written. This loop ends when the reading stage sends a specific signal meaning that there is no more input data, and when the StreamingQuery has no pending data to write. Finally, the output write mode for Structured Streaming will be “append”, since we are only interested in writing the new processed sequences in a new part file, whereas the already written sequences must not change.<fig id="Fig3"><label>Fig. 3</label><caption><p>Illustration of the naming order problem with several part files</p></caption><graphic xlink:href="12859_2023_5530_Fig3_HTML" id="MO3"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec12">
    <title>Results and discussion</title>
    <p id="Par45">The experimental evaluation of our proposal has been conducted on two different testbeds. The first one is a 17-node commodity cluster consisting of one master and 16 worker nodes. The hardware characteristics of each node are shown in Table <xref rid="Tab1" ref-type="table">1</xref>. This cluster provides a total of 256 physical cores and 1 TiB of memory for the processing tasks, and each node has one local hard disk for HDFS and temporary data storage during the execution of the experiments. The second testbed is a more modern, high-performance 9-node cluster consisting of one master and 8 worker nodes. Table <xref rid="Tab2" ref-type="table">2</xref> shows the characteristics of each node, providing a total of 256 physical cores and 2 TiB of memory for the processing tasks, with each node having two local disks: one large but slow hard disk and one small but fast solid state disk. Tables <xref rid="Tab1" ref-type="table">1</xref> and <xref rid="Tab2" ref-type="table">2</xref> also show the software configuration of each testbed, with both systems running CentOS Linux 7.9.2009. As can be observed, the Spark and Hadoop versions used in the experiments were the same in both testbeds. Some specific configuration parameters for Spark and HDFS are also shown in these tables, such as the block size for HDFS and the number of cores for Spark executors, which is adapted to the features of the cluster nodes.</p>
    <p id="Par46">Three publicly available FASTQ datasets have been evaluated, obtained from the Sequence Read Archive (SRA) [<xref ref-type="bibr" rid="CR41">41</xref>, <xref ref-type="bibr" rid="CR42">42</xref>], a public repository of genomic data belonging to the National Center for Biotechnology Information (NCBI) [<xref ref-type="bibr" rid="CR43">43</xref>, <xref ref-type="bibr" rid="CR44">44</xref>]. These datasets present a paired-end layout, so they consist of two input files (single-end experiments use one file). Their main characteristics are summarized in Table <xref rid="Tab3" ref-type="table">3</xref>, where the number of reads (third row) refers to the number of DNA sequences in each input file, and the read length (fourth row) refers to the number of base pairs (bp) per each sequence.</p>
    <p id="Par47">The experimental evaluation has been carried out comparatively with SeQual, the tool used as reference to implement our solution in terms of its functionality, as mentioned before. Four representative quality control operations have been selected for this performance comparison:<list list-type="bullet"><list-item><p id="Par48">QUALITY: a single filter that filters sequences based on an indicated maximum and/or minimum mean quality threshold. The quality score from each base is calculated following the Phred+33 quality score encoding [<xref ref-type="bibr" rid="CR45">45</xref>]. A minimum quality of 25 was used in the experiments.</p></list-item><list-item><p id="Par49">NONIUPAC: a single filter that removes sequences if they contain Non-IUPAC bases (that is, any base other than A, T, G, C or N).</p></list-item><list-item><p id="Par50">TRIMRIGHTP: a trimmer that trims sequences according to an indicated percentage of the total number of bases starting from the right. A 10% trimming was used in the experiments.</p></list-item><list-item><p id="Par51">DNATORNA: a formatter that transforms DNA sequences to RNA sequences.</p></list-item></list>In addition, two different scenarios have been tested depending on the state of the input dataset:<list list-type="bullet"><list-item><p id="Par52">“Downloaded”, where the full dataset is already locally stored in the master node (i.e., it was previously downloaded). In this scenario, SeQual first requires to copy the dataset to HDFS for processing it, since batch data processing can only begin once the complete dataset was copied. However, SeQual-Stream is able to read it directly from the local file system of the master node and start its processing while it is being copied to HDFS.</p></list-item><list-item><p id="Par53">“Downloading”, where the dataset is stored on a remote location outside the cluster (e.g., an external repository or server), so it must be first downloaded locally on the master node and then copied to HDFS for its processing. This second scenario serves to exploit one of the main advantages of our approach, as SeQual-Stream can start data processing as soon as the download operation is initiated, instead of waiting for the download to finish and copy the full dataset to HDFS. For simplicity, the datasets are stored on private servers instead of on a public repository to prevent that highly variable Internet download speeds could affect the results of these experiments. Each testbed has access to a separate private server with different download speeds: the first testbed downloads the datasets from a server providing speeds of 90–100 MiB/s, while the second one downloads them from a server with speeds of 600–700 MiB/s.</p></list-item></list>Finally, all the experiments were run a minimum of 5 times using the cluster nodes in a dedicated manner (i.e., the hardware was never shared by other users’ jobs running on the same cluster). Due to this fact, the observed standard deviations were not significant, and so the median value will be used as the performance metric in this work. Consequently, all the results shown in the next sections represent the median value of 5 measurements for each experiment.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Hardware and software characteristics of the cluster nodes (testbed 1)</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="left" colspan="3"><italic>Hardware</italic></td></tr><tr><td align="left">CPU Model</td><td align="left" colspan="2">2 × Intel Xeon E5-2660 Sandy Bridge-EP</td></tr><tr><td align="left">CPU Speed/Turbo</td><td align="left" colspan="2">2.20 GHz/3.0 GHz</td></tr><tr><td align="left">#Cores per node</td><td align="left" colspan="2">16</td></tr><tr><td align="left">#Threads per node</td><td align="left" colspan="2">32</td></tr><tr><td align="left">Cache L1/L2/L3</td><td align="left" colspan="2">32 KiB/256 KiB/20 MiB</td></tr><tr><td align="left">Memory</td><td align="left" colspan="2">64 GiB DDR3 1600 MHz</td></tr><tr><td align="left">Disk</td><td align="left" colspan="2">1 × HDD 1 TiB SATA3 7.2K rpm</td></tr><tr><td align="left">Network</td><td align="left" colspan="2">Gigabit Ethernet</td></tr><tr><td align="left" colspan="3"><italic>Software</italic></td></tr><tr><td align="left">OS Version</td><td align="left" colspan="2">CentOS Linux release 7.9.2009</td></tr><tr><td align="left">Kernel</td><td align="left" colspan="2">3.10.0-1160.62.1</td></tr><tr><td align="left">Java</td><td align="left" colspan="2">OpenJDK 1.8.0_322</td></tr><tr><td align="left" rowspan="4">Spark</td><td align="left">Version</td><td align="left">3.1.1</td></tr><tr><td align="left">Executors per node</td><td align="left">1</td></tr><tr><td align="left">Executor heap size</td><td align="left">55 GiB</td></tr><tr><td align="left">Executor cores</td><td align="left">16</td></tr><tr><td align="left">Hadoop</td><td align="left">Version</td><td align="left">2.10.1</td></tr><tr><td align="left" rowspan="2">HDFS</td><td align="left">Block size</td><td align="left">128 MiB</td></tr><tr><td align="left">Replication factor</td><td align="left">3</td></tr></tbody></table></table-wrap><table-wrap id="Tab2"><label>Table 2</label><caption><p>Hardware and software characteristics of the cluster nodes (testbed 2)</p></caption><table frame="hsides" rules="groups"><tbody><tr><td align="left" colspan="3"><italic>Hardware</italic></td></tr><tr><td align="left">CPU Model</td><td align="left" colspan="2">2 × Intel Xeon Silver 4216 Cascade Lake-SP</td></tr><tr><td align="left">CPU Speed/Turbo</td><td align="left" colspan="2">2.1 GHz/3.2 GHz</td></tr><tr><td align="left">#Cores per node</td><td align="left" colspan="2">32</td></tr><tr><td align="left">#Threads per node</td><td align="left" colspan="2">64</td></tr><tr><td align="left">Cache L1/L2/L3</td><td align="left" colspan="2">32 KiB/1 MiB/22 MiB</td></tr><tr><td align="left">Memory</td><td align="left" colspan="2">256 GiB DDR4 2933 MHhz</td></tr><tr><td align="left" rowspan="2">Disks</td><td align="left" colspan="2">1 × HDD 2 TiB SATA3 7.2K rpm</td></tr><tr><td align="left" colspan="2">1 × SSD 240 GiB SATA3</td></tr><tr><td align="left">Network</td><td align="left" colspan="2">InfiniBand FDR</td></tr><tr><td align="left" colspan="3"><italic>Software</italic></td></tr><tr><td align="left">OS Version</td><td align="left" colspan="2">CentOS Linux release 7.9.2009</td></tr><tr><td align="left">Kernel</td><td align="left" colspan="2">5.4.233-1</td></tr><tr><td align="left">Java</td><td align="left" colspan="2">OpenJDK 1.8.0_372</td></tr><tr><td align="left" rowspan="4">Spark</td><td align="left">Version</td><td align="left">3.1.1</td></tr><tr><td align="left">Executors per node</td><td align="left">1</td></tr><tr><td align="left">Executor heap size</td><td align="left">225 GiB</td></tr><tr><td align="left">Executor cores</td><td align="left">32</td></tr><tr><td align="left">Hadoop</td><td align="left">Version</td><td align="left">2.10.1</td></tr><tr><td align="left" rowspan="2">HDFS</td><td align="left">Block size</td><td align="left">128 MiB</td></tr><tr><td align="left">Replication factor</td><td align="left">3</td></tr></tbody></table></table-wrap><table-wrap id="Tab3"><label>Table 3</label><caption><p>Characteristics of the public datasets used in the performance evaluation</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Dataset</th><th align="left">SRR567455</th><th align="left">SRR11442499</th><th align="left">SRR5893671</th></tr></thead><tbody><tr><td align="left">Tag</td><td align="left">SRR56</td><td align="left">SRR114</td><td align="left">SRR589</td></tr><tr><td align="left">Organism</td><td align="left">Homo sapiens</td><td align="left">Homo sapiens</td><td align="left">Triticum aestivum</td></tr><tr><td align="left">#Reads</td><td align="left">2 <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M4"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq2.gif"/></alternatives></inline-formula> 251.9 M</td><td align="left">2 <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M6"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq3.gif"/></alternatives></inline-formula> 250.3 M</td><td align="left">2 <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M8"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq4.gif"/></alternatives></inline-formula> 359.5 M</td></tr><tr><td align="left">Read length</td><td align="left">76 bp</td><td align="left">99 bp</td><td align="left">160 bp</td></tr><tr><td align="left">Size</td><td align="left">2 <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M10"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq5.gif"/></alternatives></inline-formula> 45 GiB</td><td align="left">2 <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M12"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq6.gif"/></alternatives></inline-formula> 62 GiB</td><td align="left">2 <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M14"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq7.gif"/></alternatives></inline-formula> 120 GiB</td></tr></tbody></table></table-wrap></p>
    <sec id="Sec13">
      <title>Experiments on testbed 1</title>
      <p id="Par54">This first group of experiments is performed on the first testbed (see Table <xref rid="Tab1" ref-type="table">1</xref>). The “downloaded” scenario is evaluated using the first two datasets (SRR56 and SRR114, see Table <xref rid="Tab3" ref-type="table">3</xref>) in both single- and paired-end mode, while the second scenario (“downloading”) is only tested with the second dataset for brevity of results, in single- and paired-end modes as well. The largest dataset (SRR589) is excluded from these experiments as it is so large and computationally expensive to process for this hardware that runtimes exceeded the time limits imposed on this testbed.</p>
      <sec id="Sec14">
        <title>“Downloaded” scenario</title>
        <p id="Par55">Tables <xref rid="Tab4" ref-type="table">4</xref> and <xref rid="Tab5" ref-type="table">5</xref> show the execution times of both tools for the first scenario. It is important to note that the results for SeQual take into account the time required to copy the input dataset before starting its processing. The results shown in the tables are organized according to the quality control operation being performed, the dataset and its corresponding single- or paired-end layout, and the number of worker nodes used in the experiment (from 1 to 16). The last column shows the speedup obtained by our solution over its batch counterpart.</p>
        <p id="Par56">On the one hand, it can be observed that the maximum speedup achieved by our tool is 2.70<inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M16"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq8.gif"/></alternatives></inline-formula>, which is obtained for the QUALITY filter when processing the SRR56 dataset in paired-end mode. On the other hand, the average speedup for all operations and datasets under evaluation in this first scenario is around 1.43<inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M18"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq9.gif"/></alternatives></inline-formula>. In general, the speedups are usually higher when using a small number of worker nodes (1–4), whereas it tends to converge to 1 when using 16 nodes. The main reason for this behavior is that there comes a point where there is so much computational power and disks on which to spread the write operations that the processing and writing of the results are fast enough, whereas the speed of copying the input files, which is similar for both tools, becomes the major performance limiting factor due to the slow HDD disks available on this testbed.</p>
        <p id="Par57">There are also some differences to be pointed out between the results obtained for the different operations. The QUALITY filter and the TRIMRIGHTP trimmer tend to generate smaller runtimes for both tools and obtain greater speedups than the NONIUPAC filter and the DNATORNA formatter. This is due to the different amount of data written to HDFS as output for each operation. Whereas QUALITY removes sequences from the input dataset and TRIMRIGHTP makes them smaller, NONIUPAC does not filter any (because all bases are in IUPAC nomenclature in these datasets) and DNATORNA simply changes their format (thus maintaining all the sequences and their length). Consequently, these last two operations write more output data and impose a greater overhead on the disks, a more limiting factor in SeQual-Stream because the copy of the input dataset(s) is being made in parallel with the processing and writing of the results.</p>
        <p id="Par58">Overall, the speedups obtained tend to increase noticeably for paired-end experiments compared to single-end ones. In fact, all speedups greater than 2<inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M20"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq10.gif"/></alternatives></inline-formula> are achieved in paired-end mode. It is important to remark that this mode involves copying and processing twice as much data as in single-end mode. As the amount of input data increases significantly, the time required to copy them to HDFS, process them with Spark and write their parts to HDFS also increases proportionally. Therefore, parallelizing all this process through a stream model is very beneficial and is precisely what was sought after with the development of this tool.<table-wrap id="Tab4"><label>Table 4</label><caption><p>Runtimes (in seconds) and corresponding speedups of SeQual-Stream over SeQual for different single- and paired-end datasets using the QUALITY and NONIUPAC filters (“Downloaded” scenario, testbed 1)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Operation</th><th align="left">Dataset</th><th align="left">Mode</th><th align="left">Nodes</th><th align="left">SeQual</th><th align="left">SeQual-Stream</th><th align="left">Speedup</th></tr></thead><tbody><tr><td align="left" rowspan="20">QUALITY</td><td align="left" rowspan="10">SRR56</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">1386</td><td char="." align="char">927</td><td char="." align="char">1.49</td></tr><tr><td char="." align="char">2</td><td char="." align="char">993</td><td char="." align="char">708</td><td char="." align="char">1.40</td></tr><tr><td char="." align="char">4</td><td char="." align="char">780</td><td char="." align="char">595</td><td char="." align="char">1.31</td></tr><tr><td char="." align="char">8</td><td char="." align="char">566</td><td char="." align="char">507</td><td char="." align="char">1.12</td></tr><tr><td char="." align="char">16</td><td char="." align="char">522</td><td char="." align="char">513</td><td char="." align="char">1.02</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">5312</td><td char="." align="char">1967</td><td char="." align="char">2.70</td></tr><tr><td char="." align="char">2</td><td char="." align="char">3639</td><td char="." align="char">1470</td><td char="." align="char">2.47</td></tr><tr><td char="." align="char">4</td><td char="." align="char">2043</td><td char="." align="char">1102</td><td char="." align="char">1.85</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1119</td><td char="." align="char">949</td><td char="." align="char">1.18</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1024</td><td char="." align="char">940</td><td char="." align="char">1.09</td></tr><tr><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">2239</td><td char="." align="char">1918</td><td char="." align="char">1.17</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1569</td><td char="." align="char">1070</td><td char="." align="char">1.47</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1242</td><td char="." align="char">941</td><td char="." align="char">1.32</td></tr><tr><td char="." align="char">8</td><td char="." align="char">865</td><td char="." align="char">702</td><td char="." align="char">1.23</td></tr><tr><td char="." align="char">16</td><td char="." align="char">723</td><td char="." align="char">689</td><td char="." align="char">1.05</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">6983</td><td char="." align="char">4082</td><td char="." align="char">1.71</td></tr><tr><td char="." align="char">2</td><td char="." align="char">5367</td><td char="." align="char">2278</td><td char="." align="char">2.36</td></tr><tr><td char="." align="char">4</td><td char="." align="char">3126</td><td char="." align="char">1688</td><td char="." align="char">1.85</td></tr><tr><td char="." align="char">8</td><td char="." align="char">2085</td><td char="." align="char">1368</td><td char="." align="char">1.52</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1452</td><td char="." align="char">1306</td><td char="." align="char">1.11</td></tr><tr><td align="left" rowspan="20">NONIUPAC</td><td align="left" rowspan="10">SRR56</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">1430</td><td char="." align="char">1226</td><td char="." align="char">1.17</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1127</td><td char="." align="char">1081</td><td char="." align="char">1.04</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1013</td><td char="." align="char">703</td><td char="." align="char">1.44</td></tr><tr><td char="." align="char">8</td><td char="." align="char">586</td><td char="." align="char">513</td><td char="." align="char">1.14</td></tr><tr><td char="." align="char">16</td><td char="." align="char">539</td><td char="." align="char">518</td><td char="." align="char">1.04</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">5919</td><td char="." align="char">2748</td><td char="." align="char">2.15</td></tr><tr><td char="." align="char">2</td><td char="." align="char">4086</td><td char="." align="char">1958</td><td char="." align="char">2.09</td></tr><tr><td char="." align="char">4</td><td char="." align="char">2328</td><td char="." align="char">1413</td><td char="." align="char">1.65</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1240</td><td char="." align="char">990</td><td char="." align="char">1.25</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1056</td><td char="." align="char">960</td><td char="." align="char">1.10</td></tr><tr><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">2140</td><td char="." align="char">1896</td><td char="." align="char">1.13</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1600</td><td char="." align="char">1454</td><td char="." align="char">1.10</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1047</td><td char="." align="char">995</td><td char="." align="char">1.05</td></tr><tr><td char="." align="char">8</td><td char="." align="char">815</td><td char="." align="char">682</td><td char="." align="char">1.19</td></tr><tr><td char="." align="char">16</td><td char="." align="char">730</td><td char="." align="char">686</td><td char="." align="char">1.06</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">6858</td><td char="." align="char">4549</td><td char="." align="char">1.51</td></tr><tr><td char="." align="char">2</td><td char="." align="char">6044</td><td char="." align="char">3000</td><td char="." align="char">2.01</td></tr><tr><td char="." align="char">4</td><td char="." align="char">3098</td><td char="." align="char">2079</td><td char="." align="char">1.49</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1646</td><td char="." align="char">1370</td><td char="." align="char">1.20</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1439</td><td char="." align="char">1328</td><td char="." align="char">1.08</td></tr></tbody></table></table-wrap><table-wrap id="Tab5"><label>Table 5</label><caption><p>Runtimes (in seconds) and corresponding speedups of SeQual-Stream over SeQual for different single- and paired-end datasets using the TRIMRIGHTP trimmer and DNATORNA formatter (“Downloaded” scenario, testbed 1)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Operation</th><th align="left">Dataset</th><th align="left">Mode</th><th align="left">Nodes</th><th align="left">SeQual</th><th align="left">SeQual-Stream</th><th align="left">Speedup</th></tr></thead><tbody><tr><td align="left" rowspan="20">TRIMRIGHTP</td><td align="left" rowspan="10">SRR56</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">1682</td><td char="." align="char">1062</td><td char="." align="char">1.58</td></tr><tr><td char="." align="char">2</td><td char="." align="char">934</td><td char="." align="char">872</td><td char="." align="char">1.07</td></tr><tr><td char="." align="char">4</td><td char="." align="char">765</td><td char="." align="char">680</td><td char="." align="char">1.13</td></tr><tr><td char="." align="char">8</td><td char="." align="char">583</td><td char="." align="char">523</td><td char="." align="char">1.11</td></tr><tr><td char="." align="char">16</td><td char="." align="char">521</td><td char="." align="char">523</td><td char="." align="char">1.00</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">5850</td><td char="." align="char">2259</td><td char="." align="char">2.59</td></tr><tr><td char="." align="char">2</td><td char="." align="char">3400</td><td char="." align="char">1906</td><td char="." align="char">1.78</td></tr><tr><td char="." align="char">4</td><td char="." align="char">2280</td><td char="." align="char">1463</td><td char="." align="char">1.56</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1354</td><td char="." align="char">961</td><td char="." align="char">1.41</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1051</td><td char="." align="char">961</td><td char="." align="char">1.09</td></tr><tr><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">2855</td><td char="." align="char">1723</td><td char="." align="char">1.66</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1381</td><td char="." align="char">1281</td><td char="." align="char">1.08</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1050</td><td char="." align="char">909</td><td char="." align="char">1.16</td></tr><tr><td char="." align="char">8</td><td char="." align="char">849</td><td char="." align="char">723</td><td char="." align="char">1.17</td></tr><tr><td char="." align="char">16</td><td char="." align="char">729</td><td char="." align="char">688</td><td char="." align="char">1.06</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">5960</td><td char="." align="char">4119</td><td char="." align="char">1.45</td></tr><tr><td char="." align="char">2</td><td char="." align="char">5514</td><td char="." align="char">2391</td><td char="." align="char">2.31</td></tr><tr><td char="." align="char">4</td><td char="." align="char">3329</td><td char="." align="char">1969</td><td char="." align="char">1.69</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1859</td><td char="." align="char">1390</td><td char="." align="char">1.34</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1420</td><td char="." align="char">1325</td><td char="." align="char">1.07</td></tr><tr><td align="left" rowspan="20">DNATORNA</td><td align="left" rowspan="10">SRR56</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">1840</td><td char="." align="char">1588</td><td char="." align="char">1.16</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1194</td><td char="." align="char">1121</td><td char="." align="char">1.06</td></tr><tr><td char="." align="char">4</td><td char="." align="char">918</td><td char="." align="char">673</td><td char="." align="char">1.36</td></tr><tr><td char="." align="char">8</td><td char="." align="char">650</td><td char="." align="char">521</td><td char="." align="char">1.25</td></tr><tr><td char="." align="char">16</td><td char="." align="char">543</td><td char="." align="char">509</td><td char="." align="char">1.07</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">5072</td><td char="." align="char">3535</td><td char="." align="char">1.43</td></tr><tr><td char="." align="char">2</td><td char="." align="char">4069</td><td char="." align="char">1942</td><td char="." align="char">2.09</td></tr><tr><td char="." align="char">4</td><td char="." align="char">2556</td><td char="." align="char">1541</td><td char="." align="char">1.66</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1449</td><td char="." align="char">1062</td><td char="." align="char">1.36</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1057</td><td char="." align="char">950</td><td char="." align="char">1.11</td></tr><tr><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">3149</td><td char="." align="char">1999</td><td char="." align="char">1.57</td></tr><tr><td char="." align="char">2</td><td char="." align="char">2012</td><td char="." align="char">1116</td><td char="." align="char">1.80</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1146</td><td char="." align="char">1013</td><td char="." align="char">1.13</td></tr><tr><td char="." align="char">8</td><td char="." align="char">859</td><td char="." align="char">683</td><td char="." align="char">1.26</td></tr><tr><td char="." align="char">16</td><td char="." align="char">722</td><td char="." align="char">671</td><td char="." align="char">1.08</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">6322</td><td char="." align="char">4923</td><td char="." align="char">1.28</td></tr><tr><td char="." align="char">2</td><td char="." align="char">5547</td><td char="." align="char">2760</td><td char="." align="char">2.01</td></tr><tr><td char="." align="char">4</td><td char="." align="char">3650</td><td char="." align="char">1954</td><td char="." align="char">1.87</td></tr><tr><td char="." align="char">8</td><td char="." align="char">2288</td><td char="." align="char">1333</td><td char="." align="char">1.72</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1456</td><td char="." align="char">1286</td><td char="." align="char">1.13</td></tr></tbody></table></table-wrap></p>
      </sec>
      <sec id="Sec15">
        <title>“Downloading” scenario</title>
        <p id="Par59">Table <xref rid="Tab6" ref-type="table">6</xref> shows the execution times of both tools for the second scenario, where the dataset is downloaded from an external server with a bandwidth of up to 100 MiB/s, as mentioned earlier. Note that the results for SeQual take into account the time required to download and copy the full dataset before starting its processing. The results shown in the table follow the same format as in the previous scenario.</p>
        <p id="Par60">In this case, the speedups of our tool range from a minimum of 1.26<inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M22"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq11.gif"/></alternatives></inline-formula> up to a maximum of 2.45<inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M24"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq12.gif"/></alternatives></inline-formula>, obtained for the QUALITY filter in single-end mode using 16 nodes and the DNATORNA formatter in paired-end mode using 4 nodes, respectively. The average speedup is around 1.71<inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M26"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq13.gif"/></alternatives></inline-formula>, which is a 20% higher than in the “Downloaded” scenario. Overall, the speedups are much better even when using 16 worker nodes, especially for the paired-end experiments. For instance, SeQual-Stream reduces SeQual execution times by 24% and 30% when applying TRIMRIGHTP over the SRR114 dataset using 16 nodes in single- and paired-end mode, respectively.</p>
        <p id="Par61">It is also worth noting how the speedup difference between single- and paired-end mode is slightly attenuated in this second scenario compared to the previous one. For instance, even though almost all speedups greater than 2<inline-formula id="IEq14"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M28"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq14.gif"/></alternatives></inline-formula> are also achieved in paired-end mode as before, there is at least one experiment where a 2.10<inline-formula id="IEq15"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M30"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq15.gif"/></alternatives></inline-formula> speedup is obtained in single-end (TRIMRIGHTP), and yet, the maximum speedup (2.45<inline-formula id="IEq16"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M32"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq16.gif"/></alternatives></inline-formula>) is lower than in the first scenario (2.70<inline-formula id="IEq17"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M34"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq17.gif"/></alternatives></inline-formula>). The main reason is that reading two input files requires copying both files simultaneously to join each sequence with its corresponding pair. When both files are being downloaded, it is very likely that one file is downloaded faster than the other, and so the additional data available from the faster file cannot be used by SeQual-Stream, as it is required to wait for the paired sequences to arrive from the slower file.<table-wrap id="Tab6"><label>Table 6</label><caption><p>Runtimes (in seconds) and corresponding speedups of SeQual-Stream over SeQual for the SRR114 dataset and different quality control operations (“Downloading” scenario, testbed 1)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Operation</th><th align="left">Dataset</th><th align="left">Mode</th><th align="left">Nodes</th><th align="left">SeQual</th><th align="left">SeQual-Stream</th><th align="left">Speedup</th></tr></thead><tbody><tr><td align="left" rowspan="10">QUALITY</td><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">2599</td><td char="." align="char">1373</td><td char="." align="char">1.89</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1929</td><td char="." align="char">1134</td><td char="." align="char">1.70</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1602</td><td char="." align="char">1024</td><td char="." align="char">1.56</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1225</td><td char="." align="char">864</td><td char="." align="char">1.42</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1083</td><td char="." align="char">858</td><td char="." align="char">1.26</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">7703</td><td char="." align="char">3490</td><td char="." align="char">2.21</td></tr><tr><td char="." align="char">2</td><td char="." align="char">6087</td><td char="." align="char">2869</td><td char="." align="char">2.12</td></tr><tr><td char="." align="char">4</td><td char="." align="char">3846</td><td char="." align="char">1920</td><td char="." align="char">2.00</td></tr><tr><td char="." align="char">8</td><td char="." align="char">2805</td><td char="." align="char">1548</td><td char="." align="char">1.81</td></tr><tr><td char="." align="char">16</td><td char="." align="char">2172</td><td char="." align="char">1518</td><td char="." align="char">1.43</td></tr><tr><td align="left" rowspan="10">NONIUPAC</td><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">2500</td><td char="." align="char">1818</td><td char="." align="char">1.37</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1960</td><td char="." align="char">1273</td><td char="." align="char">1.54</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1407</td><td char="." align="char">918</td><td char="." align="char">1.53</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1175</td><td char="." align="char">843</td><td char="." align="char">1.39</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1090</td><td char="." align="char">829</td><td char="." align="char">1.31</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">7578</td><td char="." align="char">3611</td><td char="." align="char">2.10</td></tr><tr><td char="." align="char">2</td><td char="." align="char">6764</td><td char="." align="char">2959</td><td char="." align="char">2.29</td></tr><tr><td char="." align="char">4</td><td char="." align="char">3818</td><td char="." align="char">1891</td><td char="." align="char">2.02</td></tr><tr><td char="." align="char">8</td><td char="." align="char">2366</td><td char="." align="char">1561</td><td char="." align="char">1.52</td></tr><tr><td char="." align="char">16</td><td char="." align="char">2159</td><td char="." align="char">1559</td><td char="." align="char">1.38</td></tr><tr><td align="left" rowspan="10">TRIMRIGHTP</td><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">3215</td><td char="." align="char">1529</td><td char="." align="char">2.10</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1741</td><td char="." align="char">1174</td><td char="." align="char">1.48</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1410</td><td char="." align="char">1019</td><td char="." align="char">1.38</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1209</td><td char="." align="char">838</td><td char="." align="char">1.44</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1089</td><td char="." align="char">829</td><td char="." align="char">1.31</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">6680</td><td char="." align="char">3363</td><td char="." align="char">1.99</td></tr><tr><td char="." align="char">2</td><td char="." align="char">5874</td><td char="." align="char">2659</td><td char="." align="char">2.21</td></tr><tr><td char="." align="char">4</td><td char="." align="char">4049</td><td char="." align="char">1828</td><td char="." align="char">2.21</td></tr><tr><td char="." align="char">8</td><td char="." align="char">2579</td><td char="." align="char">1522</td><td char="." align="char">1.69</td></tr><tr><td char="." align="char">16</td><td char="." align="char">2140</td><td char="." align="char">1501</td><td char="." align="char">1.43</td></tr><tr><td align="left" rowspan="10">DNATORNA</td><td align="left" rowspan="10">SRR114</td><td align="left" rowspan="5">Single</td><td char="." align="char">1</td><td char="." align="char">3509</td><td char="." align="char">1953</td><td char="." align="char">1.80</td></tr><tr><td char="." align="char">2</td><td char="." align="char">2372</td><td char="." align="char">1678</td><td char="." align="char">1.41</td></tr><tr><td char="." align="char">4</td><td char="." align="char">1506</td><td char="." align="char">1079</td><td char="." align="char">1.40</td></tr><tr><td char="." align="char">8</td><td char="." align="char">1219</td><td char="." align="char">863</td><td char="." align="char">1.41</td></tr><tr><td char="." align="char">16</td><td char="." align="char">1082</td><td char="." align="char">813</td><td char="." align="char">1.33</td></tr><tr><td align="left" rowspan="5">Paired</td><td char="." align="char">1</td><td char="." align="char">7042</td><td char="." align="char">4290</td><td char="." align="char">1.64</td></tr><tr><td char="." align="char">2</td><td char="." align="char">6267</td><td char="." align="char">2668</td><td char="." align="char">2.35</td></tr><tr><td char="." align="char">4</td><td char="." align="char">4370</td><td char="." align="char">1780</td><td char="." align="char">2.45</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3008</td><td char="." align="char">1559</td><td char="." align="char">1.93</td></tr><tr><td char="." align="char">16</td><td char="." align="char">2176</td><td char="." align="char">1488</td><td char="." align="char">1.46</td></tr></tbody></table></table-wrap></p>
      </sec>
    </sec>
    <sec id="Sec16">
      <title>Experiments on testbed 2</title>
      <p id="Par62">This set of experiments is performed on the second testbed (see Table <xref rid="Tab2" ref-type="table">2</xref>). The “downloaded” and “downloading” scenarios are both evaluated using the same four quality control operations and processing the largest dataset (SRR589, see Table <xref rid="Tab3" ref-type="table">3</xref>), in this case only in paired-end mode for brevity of results. These experiments require the use of the HDD disks available on the cluster nodes, as the SSD disks do not have enough space to store both the input and output data for this huge dataset.</p>
      <p id="Par63">On the one hand, Table <xref rid="Tab7" ref-type="table">7</xref> shows the execution times of both tools for the “downloaded” scenario using up to 8 worker nodes. Overall, it can be seen that the speedups are very similar to those obtained for the analogous scenario on the first testbed (see paired-end results in Tables <xref rid="Tab4" ref-type="table">4</xref> and <xref rid="Tab5" ref-type="table">5</xref>). Although the maximum speedup is slightly lower (up to 2.38<inline-formula id="IEq18"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M36"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq18.gif"/></alternatives></inline-formula>), the average values remain practically the same (from 1.63<inline-formula id="IEq19"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M38"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq19.gif"/></alternatives></inline-formula> to 1.62<inline-formula id="IEq20"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M40"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq20.gif"/></alternatives></inline-formula>). In these experiments, the speedups tend to be slightly lower due to the significantly higher computational power of the hardware. Consequently, the speed of copying the input files to the slow HDD disks becomes the main performance bottleneck using just 8 nodes instead of 16 as in the first testbed.</p>
      <p id="Par64">On the other hand, Table <xref rid="Tab8" ref-type="table">8</xref> shows the execution times for the “downloading” scenario. Note that the runtimes for SeQual remain the same as in the previous “downloaded” scenario. This is due to the higher download speed of the external server from which the datasets are downloaded, which is now fast enough so that the limiting factor in the download/copy pipeline to HDFS is the copy phase. SeQual-Stream runtimes are also very similar, although they tend to be slightly higher, suggesting that the streaming approach was able to take slightly more advantage of the fact that the input data was already complete. Compared to the analogous scenario evaluated on the first testbed (see paired-end results in Table <xref rid="Tab6" ref-type="table">6</xref>), the speedup results tend to be lower, with an average of 1.60<inline-formula id="IEq21"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M42"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq21.gif"/></alternatives></inline-formula>. Due to the faster download speed, there are fewer opportunities for overlapping and therefore fewer advantages for stream processing, although the maximum speedup achieved in these experiments (2.66<inline-formula id="IEq22"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M44"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq22.gif"/></alternatives></inline-formula>) is still higher than before (2.45<inline-formula id="IEq23"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M46"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq23.gif"/></alternatives></inline-formula>).</p>
      <p id="Par65">Overall, these experiments on the second testbed demonstrate that our tool can still achieve lower runtimes than its batch counterpart when using newer and faster hardware. However, SeQual-Stream can take even more advantage of slow/commodity hardware, as the chance for overlapping the download and/or copy of the datasets to HDFS with their processing is critical in this case. This proves that cutting-edge hardware is not necessary to use our tool, as good results can be obtained using commodity hardware such as in the first testbed.<table-wrap id="Tab7"><label>Table 7</label><caption><p>Runtimes (in seconds) and corresponding speedups of SeQual-Stream over SeQual for the SRR589 paired-end dataset (“Downloaded” scenario, testbed 2)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Operation</th><th align="left">Dataset</th><th align="left">Mode</th><th align="left">Nodes</th><th align="left">SeQual</th><th align="left">SeQual-Stream</th><th align="left">Speedup</th></tr></thead><tbody><tr><td align="left" rowspan="4">QUALITY</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">9369</td><td char="." align="char">5137</td><td char="." align="char">1.82</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7666</td><td char="." align="char">4629</td><td char="." align="char">1.66</td></tr><tr><td char="." align="char">4</td><td char="." align="char">5152</td><td char="." align="char">3059</td><td char="." align="char">1.68</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3418</td><td char="." align="char">2728</td><td char="." align="char">1.25</td></tr><tr><td align="left" rowspan="4">NONIUPAC</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">13253</td><td char="." align="char">5558</td><td char="." align="char">2.38</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7703</td><td char="." align="char">4498</td><td char="." align="char">1.71</td></tr><tr><td char="." align="char">4</td><td char="." align="char">4887</td><td char="." align="char">3307</td><td char="." align="char">1.48</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3172</td><td char="." align="char">2818</td><td char="." align="char">1.13</td></tr><tr><td align="left" rowspan="4">TRIMRIGHTP</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">13343</td><td char="." align="char">5875</td><td char="." align="char">2.27</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7532</td><td char="." align="char">4172</td><td char="." align="char">1.81</td></tr><tr><td char="." align="char">4</td><td char="." align="char">4813</td><td char="." align="char">3018</td><td char="." align="char">1.59</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3085</td><td char="." align="char">2718</td><td char="." align="char">1.14</td></tr><tr><td align="left" rowspan="4">DNATORNA</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">10256</td><td char="." align="char">5668</td><td char="." align="char">1.81</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7346</td><td char="." align="char">5468</td><td char="." align="char">1.34</td></tr><tr><td char="." align="char">4</td><td char="." align="char">5179</td><td char="." align="char">3098</td><td char="." align="char">1.67</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3196</td><td char="." align="char">2758</td><td char="." align="char">1.16</td></tr></tbody></table></table-wrap><table-wrap id="Tab8"><label>Table 8</label><caption><p>Runtimes (in seconds) and corresponding speedups of SeQual-Stream over SeQual for the SRR589 paired-end dataset (“Downloading” scenario, testbed 2)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Operation</th><th align="left">Dataset</th><th align="left">Mode</th><th align="left">Nodes</th><th align="left">SeQual</th><th align="left">SeQual-Stream</th><th align="left">Speedup</th></tr></thead><tbody><tr><td align="left" rowspan="4">QUALITY</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">9369</td><td char="." align="char">4924</td><td char="." align="char">1.90</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7666</td><td char="." align="char">4023</td><td char="." align="char">1.91</td></tr><tr><td char="." align="char">4</td><td char="." align="char">5152</td><td char="." align="char">3601</td><td char="." align="char">1.43</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3418</td><td char="." align="char">2797</td><td char="." align="char">1.22</td></tr><tr><td align="left" rowspan="4">NONIUPAC</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">13253</td><td char="." align="char">5894</td><td char="." align="char">2.25</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7703</td><td char="." align="char">5281</td><td char="." align="char">1.46</td></tr><tr><td char="." align="char">4</td><td char="." align="char">4887</td><td char="." align="char">3478</td><td char="." align="char">1.41</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3172</td><td char="." align="char">2870</td><td char="." align="char">1.11</td></tr><tr><td align="left" rowspan="4">TRIMRIGHTP</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">13343</td><td char="." align="char">5022</td><td char="." align="char">2.66</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7532</td><td char="." align="char">4285</td><td char="." align="char">1.76</td></tr><tr><td char="." align="char">4</td><td char="." align="char">4813</td><td char="." align="char">3483</td><td char="." align="char">1.38</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3085</td><td char="." align="char">2891</td><td char="." align="char">1.07</td></tr><tr><td align="left" rowspan="4">DNATORNA</td><td align="left" rowspan="4">SRR589</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">10256</td><td char="." align="char">5632</td><td char="." align="char">1.82</td></tr><tr><td char="." align="char">2</td><td char="." align="char">7346</td><td char="." align="char">5133</td><td char="." align="char">1.43</td></tr><tr><td char="." align="char">4</td><td char="." align="char">5179</td><td char="." align="char">3070</td><td char="." align="char">1.69</td></tr><tr><td char="." align="char">8</td><td char="." align="char">3196</td><td char="." align="char">2864</td><td char="." align="char">1.12</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec17">
      <title>Analysis of the scalability</title>
      <p id="Par66">This section presents a final set of experiments aimed at improving and analyzing the scalability of our streaming tool. In order to demonstrate its scaling capabilities, these experiments are focused on overcoming the main bottlenecks that limited performance so far.</p>
      <p id="Par67">For this purpose, the “downloaded” scenario has been evaluated using the second testbed (see Table <xref rid="Tab2" ref-type="table">2</xref>), which provides SSD disks, to speed up the writing of both the input datasets and the results to HDFS. In addition, the input files have been previously copied to the SSD disk of the master node for faster read times. In these experiments, the same four operations have been executed using the largest dataset that can be processed in this testbed (i.e., SRR114, as SRR589 is too large to be stored on the SSD disks). Experiments with only one worker node must also use the HDD disk of the worker, as the full input dataset and the generated output do not fit entirely on its SSD. For the sake of simplicity, results are shown for paired-end mode only.</p>
      <p id="Par68">Table <xref rid="Tab9" ref-type="table">9</xref> shows the results obtained. Overall, the speedups are significantly higher, reaching a maximum value of 9.89x when using 8 nodes. It is interesting to note the significant differences between the operations. The NONIUPAC filter and the TRIMRIGHTP trimmer achieve the greatest speedups, followed by the DNATORNA formatter with a maximum of 6.26<inline-formula id="IEq24"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M48"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq24.gif"/></alternatives></inline-formula>. The QUALITY filter gives the worst results, with a maximum of 4.72<inline-formula id="IEq25"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\times$$\end{document}</tex-math><mml:math id="M50"><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href="12859_2023_5530_Article_IEq25.gif"/></alternatives></inline-formula>. As an attempt was made to remove all potential sources of bottlenecks in these experiments, most of the runtime corresponds to pure processing time and not to copying and/or writing the results. Therefore, the differences in runtimes and speedups are mainly due to the differences in performance and computational efficiency of each quality control operation.<table-wrap id="Tab9"><label>Table 9</label><caption><p>Runtimes (in seconds) and corresponding speedups of SeQual-Stream for the SRR114 paired-end dataset (“Downloaded” scenario, testbed 2 with SSD disks)</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Operation</th><th align="left">Dataset</th><th align="left">Mode</th><th align="left">Nodes</th><th align="left">SeQual-Stream</th><th align="left">Speedup over 1 node</th></tr></thead><tbody><tr><td align="left" rowspan="4">QUALITY</td><td align="left" rowspan="4">SRR114</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">1440</td><td char="." align="char">1.00</td></tr><tr><td char="." align="char">2</td><td char="." align="char">625</td><td char="." align="char">2.30</td></tr><tr><td char="." align="char">4</td><td char="." align="char">590</td><td char="." align="char">2.44</td></tr><tr><td char="." align="char">8</td><td char="." align="char">305</td><td char="." align="char">4.72</td></tr><tr><td align="left" rowspan="4">NONIUPAC</td><td align="left" rowspan="4">SRR114</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">1661</td><td char="." align="char">1.00</td></tr><tr><td char="." align="char">2</td><td char="." align="char">818</td><td char="." align="char">2.03</td></tr><tr><td char="." align="char">4</td><td char="." align="char">412</td><td char="." align="char">4.03</td></tr><tr><td char="." align="char">8</td><td char="." align="char">186</td><td char="." align="char">8.93</td></tr><tr><td align="left" rowspan="4">TRIMRIGHTP</td><td align="left" rowspan="4">SRR114</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">1681</td><td char="." align="char">1.00</td></tr><tr><td char="." align="char">2</td><td char="." align="char">1073</td><td char="." align="char">1.57</td></tr><tr><td char="." align="char">4</td><td char="." align="char">553</td><td char="." align="char">3.04</td></tr><tr><td char="." align="char">8</td><td char="." align="char">170</td><td char="." align="char">9.89</td></tr><tr><td align="left" rowspan="4">DNATORNA</td><td align="left" rowspan="4">SRR114</td><td align="left" rowspan="4">Paired</td><td char="." align="char">1</td><td char="." align="char">1541</td><td char="." align="char">1.00</td></tr><tr><td char="." align="char">2</td><td char="." align="char">683</td><td char="." align="char">2.26</td></tr><tr><td char="." align="char">4</td><td char="." align="char">535</td><td char="." align="char">2.88</td></tr><tr><td char="." align="char">8</td><td char="." align="char">246</td><td char="." align="char">6.26</td></tr></tbody></table></table-wrap></p>
    </sec>
  </sec>
  <sec id="Sec18">
    <title>Conclusion</title>
    <p id="Par69">The large amount of genomic data generated by modern NGS technologies reinforces the need for bioinformatics tools capable of reducing the time required for processing them as much as possible. In this paper we have presented SeQual-Stream, a Big Data tool for quality control of raw NGS datasets which seeks to reduce data processing times through exploiting Apache Spark and its Structured Streaming API. This combination allows our tool to take full advantage of distributed-memory systems such as clusters and to further accelerate quality control by overlapping data processing with downloading and/or HDFS copy operations.</p>
    <p id="Par70">The performance evaluation, conducted on two cluster testbeds using three publicly available datasets, has experimentally demonstrated that our stream approach can be up to nearly three times faster than the counterpart tool based on batch processing. This makes SeQual-Stream a useful tool in those cases where multiple large experiments need to be carried out, since such a speedup on each experiment would result in a significant overall improvement. This is especially significant when using small-scale clusters, which is a common computing facility that most biologists and bioinformaticians have access to. In fact, our results have also shown that a maximum speedup of around 10x can be achieved when using eight nodes compared to just using a single node.</p>
    <p id="Par71">As future work, we would be interested in adapting to the stream paradigm other quality control operations that perform their processing considering the whole set of sequences, which makes them much more complex to implement in streaming mode. The possibility of exploring the use of other stream processing frameworks such as Apache Flink is also of great interest.</p>
  </sec>
  <sec id="Sec19">
    <title>Availability and requirements</title>
    <p id="Par72">Project name: SeQual-Stream</p>
    <p id="Par73">Project home page: <ext-link ext-link-type="uri" xlink:href="https://github.com/UDC-GAC/SeQual-Stream">https://github.com/UDC-GAC/SeQual-Stream</ext-link></p>
    <p id="Par74">Operating system(s): Platform independent</p>
    <p id="Par75">Programming language: Java</p>
    <p id="Par76">Other requirements: JRE 1.8 or higher, Apache Spark 3.0 or higher, Apache Hadoop 2.10 or higher (needed for HDFS)</p>
    <p id="Par77">License: GNU GPLv3</p>
    <p id="Par78">Any restrictions to use by non-academics: None</p>
  </sec>
  <sec sec-type="supplementary-material">
    <sec id="Sec20">
      <title>Supplementary Information</title>
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2023_5530_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1:</bold> PDF document containing a detailed user's guide for SeQual-Stream.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>NGS</term>
        <def>
          <p id="Par4">Next generation sequencing</p>
        </def>
      </def-item>
      <def-item>
        <term>HDFS</term>
        <def>
          <p id="Par5">Hadoop distributed file system</p>
        </def>
      </def-item>
      <def-item>
        <term>RDD</term>
        <def>
          <p id="Par6">Resilient distributed dataset</p>
        </def>
      </def-item>
      <def-item>
        <term>SRA</term>
        <def>
          <p id="Par7">Sequence read archive</p>
        </def>
      </def-item>
      <def-item>
        <term>NCBI</term>
        <def>
          <p id="Par8">National Center for Biotechnology Information</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary Information</title>
    <p>The online version contains supplementary material available at 10.1186/s12859-023-05530-7.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author Contributions</title>
    <p>OC and RRE conceived the software and designed the distributed implementation. OC is responsible for implementing the software. OC conducted the experiments and performed the data analysis. RRE and JT proposed and supervised the project. OC drafted the manuscript with contributions from all authors. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>Grants PID2019-104184RB-I00 and PID2022-136435NB-I00, funded by MCIN/AEI/10.13039/501100011033, PID2022 also funded by “ERDF A way of making Europe”, EU. Grant ED431C 2021/30, funded by Xunta de Galicia under the Consolidation Program of Competitive Reference Groups. Predoctoral grant of Óscar Castellanos-Rodríguez ref. ED481A 2022/067, also funded by Xunta de Galicia. The funding agencies did not participate in the design of the study and collection, analysis, and interpretation of data and in writing the manuscript.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The software, documentation and source code of SeQual-Stream are publicly available at the GitHub repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/UDC-GAC/SeQual-Stream">https://github.com/UDC-GAC/SeQual-Stream</ext-link>. The real datasets analyzed during this study are also publicly available at the NCBI SRA repository (<ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra">https://www.ncbi.nlm.nih.gov/sra</ext-link>) using the accession numbers: SRR567455, SRR11442499 and SRR5893671.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par79">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par80">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par81">The authors declare that they have no competing interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Phillips</surname>
            <given-names>KA</given-names>
          </name>
        </person-group>
        <article-title>Assessing the value of next-generation sequencing technologies: an introduction</article-title>
        <source>Value Health</source>
        <year>2018</year>
        <volume>21</volume>
        <issue>9</issue>
        <fpage>1031</fpage>
        <lpage>1032</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jval.2018.06.012</pub-id>
        <?supplied-pmid 30224105?>
        <pub-id pub-id-type="pmid">30224105</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Minoche</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Dohm</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Himmelbauer</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Evaluation of genomic high-throughput sequencing data generated on Illumina HiSeq and genome analyzer systems</article-title>
        <source>Genome Biol</source>
        <year>2011</year>
        <volume>12</volume>
        <issue>R112</issue>
        <fpage>1</fpage>
        <lpage>15</lpage>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Edgar</surname>
            <given-names>RC</given-names>
          </name>
          <name>
            <surname>Flyvbjerg</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Error filtering, pair assembly and error correction for next-generation sequencing reads</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>31</volume>
        <issue>21</issue>
        <fpage>3476</fpage>
        <lpage>3482</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btv401</pub-id>
        <?supplied-pmid 26139637?>
        <pub-id pub-id-type="pmid">26139637</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>He</surname>
            <given-names>B</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Assessing the impact of data preprocessing on analyzing Next Generation Sequencing data</article-title>
        <source>Front Bioeng Biotechnol</source>
        <year>2020</year>
        <volume>8</volume>
        <issue>817</issue>
        <fpage>1</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="pmid">32039188</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zaharia</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Apache Spark: a unified engine for big data processing</article-title>
        <source>Commun ACM</source>
        <year>2016</year>
        <volume>59</volume>
        <issue>11</issue>
        <fpage>56</fpage>
        <lpage>65</lpage>
        <pub-id pub-id-type="doi">10.1145/2934664</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <mixed-citation publication-type="other">Shvachko K, Kuang H, Radia S, Chansler R. The Hadoop distributed file system. In: Proceedings of the IEEE 26th symposium on mass storage systems and technologies (MSST 2010), Incline Village, NV, USA, (2010); 1–10.</mixed-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <mixed-citation publication-type="other">The Apache Software Foundation: structured streaming programming guide. <ext-link ext-link-type="uri" xlink:href="https://spark.apache.org/docs/3.1.1/structured-streaming-programming-guide.html">https://spark.apache.org/docs/3.1.1/structured-streaming-programming-guide.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dean</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ghemawat</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>MapReduce: simplified data processing on large clusters</article-title>
        <source>Commun ACM</source>
        <year>2008</year>
        <volume>51</volume>
        <issue>1</issue>
        <fpage>107</fpage>
        <lpage>113</lpage>
        <pub-id pub-id-type="doi">10.1145/1327452.1327492</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Ghemawat S, Gobioff H, Leung S-T. The Google file system. In: Proceedings of the 19th ACM symposium on operating systems principles (SOSP’03), Bolton Landing, NY, USA, 2003, pp 29–43</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <mixed-citation publication-type="other">The Apache Software Foundation: Apache Hadoop. <ext-link ext-link-type="uri" xlink:href="https://hadoop.apache.org">https://hadoop.apache.org</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lakshman</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Malik</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Cassandra: a decentralized structured storage system</article-title>
        <source>ACM SIGOPS Oper Syst Rev</source>
        <year>2010</year>
        <volume>44</volume>
        <issue>2</issue>
        <fpage>35</fpage>
        <lpage>40</lpage>
        <pub-id pub-id-type="doi">10.1145/1773912.1773922</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">Zaharia M, et al. Resilient Distributed Datasets: A fault-tolerant abstraction for in-memory cluster computing. In: Proceedings of the 9th USENIX symposium on networked systems design and implementation (NSDI’12), San Jose, CA, USA, 2012, pp 15–28</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <mixed-citation publication-type="other">The Apache Software Foundation: Spark SQL, DataFrames and Datasets Guide. <ext-link ext-link-type="uri" xlink:href="https://spark.apache.org/docs/latest/sql-programming-guide.html">https://spark.apache.org/docs/latest/sql-programming-guide.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">The Apache Software Foundation: Spark Streaming Programming Guide. <ext-link ext-link-type="uri" xlink:href="https://spark.apache.org/docs/latest/streaming-programming-guide.html">https://spark.apache.org/docs/latest/streaming-programming-guide.html</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thein</surname>
            <given-names>KMM</given-names>
          </name>
        </person-group>
        <article-title>Apache Kafka: next generation distributed messaging system</article-title>
        <source>Int J Sci Eng Technol Res</source>
        <year>2014</year>
        <volume>3</volume>
        <issue>47</issue>
        <fpage>9478</fpage>
        <lpage>9483</lpage>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Chung W-C, Ho J-M, Lin C-Y, Lee D-T. CloudEC: A MapReduce-based algorithm for correcting errors in next-generation sequencing big data. In: Proceedings of the 2017 IEEE international conference on big data (IEEE BigData 2017), Boston, MA, USA, (2017);2836–2842.</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Abuín</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Pichel</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Pena</surname>
            <given-names>TF</given-names>
          </name>
          <name>
            <surname>Amigo</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>BigBWA: approaching the Burrows-Wheeler aligner to big data technologies</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>31</volume>
        <issue>24</issue>
        <fpage>4003</fpage>
        <lpage>4005</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btv506</pub-id>
        <?supplied-pmid 26323715?>
        <pub-id pub-id-type="pmid">26323715</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Gordon A, Hannon GJ. FASTX-Toolkit: FASTQ/A Short-reads Pre-processing Tools. <ext-link ext-link-type="uri" xlink:href="http://hannonlab.cshl.edu/fastx_toolkit">http://hannonlab.cshl.edu/fastx_toolkit</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schmieder</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Edwards</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Quality control and preprocessing of metagenomic datasets</article-title>
        <source>Bioinformatics</source>
        <year>2011</year>
        <volume>27</volume>
        <issue>6</issue>
        <fpage>863</fpage>
        <lpage>864</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btr026</pub-id>
        <?supplied-pmid 21278185?>
        <pub-id pub-id-type="pmid">21278185</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fukasawa</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ermini</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Carty</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Cheung</surname>
            <given-names>M-S</given-names>
          </name>
        </person-group>
        <article-title>LongQC: a quality control tool for third generation sequencing long read data</article-title>
        <source>G3 Genes Genom Genet</source>
        <year>2020</year>
        <volume>10</volume>
        <issue>4</issue>
        <fpage>1193</fpage>
        <lpage>1196</lpage>
        <pub-id pub-id-type="doi">10.1534/g3.119.400864</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kumar</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Ertel</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Feldman</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Kupper</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Fortina</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>iSeqQC: a tool for expression-based quality control in RNA sequencing</article-title>
        <source>BMC Bioinform</source>
        <year>2020</year>
        <volume>21</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1186/s12859-020-3399-8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhou</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Su</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Ning</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>QC-Chain: fast and holistic quality control method for next-generation sequencing data</article-title>
        <source>PLOS ONE</source>
        <year>2013</year>
        <volume>8</volume>
        <issue>4</issue>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0060234</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cantu</surname>
            <given-names>VA</given-names>
          </name>
          <name>
            <surname>Sadural</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Edwards</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>PRINSEQ++, a multi-threaded tool for fast and efficient quality control and preprocessing of sequencing datasets</article-title>
        <source>PeerJ Preprints</source>
        <year>2019</year>
        <volume>7</volume>
        <fpage>1</fpage>
        <lpage>3</lpage>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Andrews, S. FastQC: A Quality Control Tool for High Throughput Sequence Data. <ext-link ext-link-type="uri" xlink:href="https://www.bioinformatics.babraham.ac.uk/projects/fastqc/">https://www.bioinformatics.babraham.ac.uk/projects/fastqc/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Sena</surname>
            <given-names>Brandine G</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>AD</given-names>
          </name>
        </person-group>
        <article-title>Falco: high-speed FastQC emulation for quality control of sequencing data</article-title>
        <source>F1000Research</source>
        <year>2019</year>
        <volume>8</volume>
        <fpage>1874</fpage>
        <pub-id pub-id-type="doi">10.12688/f1000research.21142.1</pub-id>
        <pub-id pub-id-type="pmid">33552473</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>SOAPnuke: a MapReduce acceleration-supported software for integrated quality control and preprocessing of high-throughput sequencing data</article-title>
        <source>GigaScience</source>
        <year>2017</year>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>gix120</fpage>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Expósito</surname>
            <given-names>RR</given-names>
          </name>
          <name>
            <surname>Galego-Torreiro</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>González-Domínguez</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>SeQual: big data tool to perform quality control and data preprocessing of large NGS datasets</article-title>
        <source>IEEE Access</source>
        <year>2020</year>
        <volume>8</volume>
        <fpage>146075</fpage>
        <lpage>146084</lpage>
        <pub-id pub-id-type="doi">10.1109/ACCESS.2020.3015016</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Melsted</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Halldórsson</surname>
            <given-names>BV</given-names>
          </name>
        </person-group>
        <article-title>KmerStream: streaming algorithms for k-mer abundance estimation</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <issue>24</issue>
        <fpage>3541</fpage>
        <lpage>3547</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu713</pub-id>
        <?supplied-pmid 25355787?>
        <pub-id pub-id-type="pmid">25355787</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mohamadi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Birol</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>ntCard: a streaming algorithm for cardinality estimation in genomics data</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <issue>9</issue>
        <fpage>1324</fpage>
        <lpage>1330</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw832</pub-id>
        <?supplied-pmid 28453674?>
        <pub-id pub-id-type="pmid">28453674</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Behera S, Gayen S, Deogun JS, Vinodchandran NV. KmerEstimate: a streaming algorithm for estimating k-mer counts with optimal space usage. In: Proceedings of the 9th ACM international conference on bioinformatics, computational biology, and health informatics (ACM-BCB 2018), Washington, DC, USA, (2018);438–447.</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Irber LC, Brown CT. Efficient cardinality estimation for k-mers in large DNA sequencing data sets. bioRxiv, (2016);1–5.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rathee</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kashyap</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>StreamAligner: a streaming based sequence aligner on Apache Spark</article-title>
        <source>J Big Data</source>
        <year>2018</year>
        <volume>5</volume>
        <issue>8</issue>
        <fpage>1</fpage>
        <lpage>18</lpage>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Mushtaq H, Ahmed N, Al-Ars Z. Streaming distributed DNA sequence alignment using Apache Spark. In: Proceedings of the 2017 IEEE 17th International conference on bioinformatics and bioengineering (BIBE 2017), Washington, DC, USA, (2017);188–193.</mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Valdes</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Stebliankin</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Narasimhan</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Large scale microbiome profiling in the cloud</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <issue>14</issue>
        <fpage>13</fpage>
        <lpage>22</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btz356</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mushtaq</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ahmed</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Al-Ars</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>SparkGA2: production-quality memory-efficient Apache Spark based genome analysis framework</article-title>
        <source>PLOS ONE</source>
        <year>2019</year>
        <volume>14</volume>
        <issue>12</issue>
        <fpage>1</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0224784</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Mushtaq H, Al-Ars Z. Cluster-based Apache Spark implementation of the GATK DNA analysis pipeline. In: Proceedings of the 2015 IEEE International conference on bioinformatics and biomedicine (BIBM’15), Washington, DC, USA, (2015);1471–1477.</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tian</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Transposon insertions regulate genome-wide allele-specific expression and underpin flower colour variations in apple (Malus spp.)</article-title>
        <source>Plant Biotechnol J</source>
        <year>2022</year>
        <volume>20</volume>
        <issue>7</issue>
        <fpage>1285</fpage>
        <lpage>1297</lpage>
        <pub-id pub-id-type="doi">10.1111/pbi.13806</pub-id>
        <?supplied-pmid 35258172?>
        <pub-id pub-id-type="pmid">35258172</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Abuín</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Pichel</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Pena</surname>
            <given-names>TF</given-names>
          </name>
          <name>
            <surname>Amigo</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>SparkBWA: speeding up the alignment of high-throughput DNA sequencing data</article-title>
        <source>PLOS ONE</source>
        <year>2016</year>
        <volume>11</volume>
        <issue>5</issue>
        <fpage>1</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0155461</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>QTL mapping and identification of genes associated with the resistance to <italic>Acanthoscelides obtectus</italic> in cultivated common bean using a high-density genetic linkage map</article-title>
        <source>BMC Plant Biol</source>
        <year>2022</year>
        <volume>22</volume>
        <fpage>1</fpage>
        <lpage>15</lpage>
        <?supplied-pmid 34979920?>
        <pub-id pub-id-type="pmid">34979920</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Bai</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Meixia</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Jin</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Bivariate genome-wide association study of the growth plasticity of staphylococcus aureus in coculture with escherichia coli</article-title>
        <source>Appl Microbiol Biotechnol</source>
        <year>2020</year>
        <volume>104</volume>
        <fpage>5437</fpage>
        <lpage>5447</lpage>
        <pub-id pub-id-type="doi">10.1007/s00253-020-10636-6</pub-id>
        <?supplied-pmid 32350560?>
        <pub-id pub-id-type="pmid">32350560</pub-id>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">National Center for Biotechnology Information: The Sequence Read Archive (SRA). <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra">https://www.ncbi.nlm.nih.gov/sra</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kodama</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shumway</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Leinonen</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>The sequence read archive: explosive growth of sequencing data</article-title>
        <source>Nucleic Acids Res</source>
        <year>2011</year>
        <volume>40</volume>
        <issue>D1</issue>
        <fpage>54</fpage>
        <lpage>56</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkr854</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <mixed-citation publication-type="other">National Center for Biotechnology Information: NCBI. <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/">https://www.ncbi.nlm.nih.gov/</ext-link>.</mixed-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wheeler</surname>
            <given-names>DL</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Database resources of the National Center for Biotechnology Information</article-title>
        <source>Nucleic Acids Res</source>
        <year>2007</year>
        <volume>36</volume>
        <issue>Supp 1</issue>
        <fpage>13</fpage>
        <lpage>21</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkm1000</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <mixed-citation publication-type="other">Shi H, Li W, Xu X. Learning the comparing and converting method of sequence Phred quality score. In: Proceedings of the 2016 6th International conference on management, education, information and control (MEICI 2016), Shenyang, China, (2016);260–263.</mixed-citation>
    </ref>
  </ref-list>
</back>
