<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Entropy (Basel)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Entropy (Basel)</journal-id>
    <journal-id journal-id-type="publisher-id">entropy</journal-id>
    <journal-title-group>
      <journal-title>Entropy</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1099-4300</issn>
    <publisher>
      <publisher-name>MDPI</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7514418</article-id>
    <article-id pub-id-type="doi">10.3390/e21111074</article-id>
    <article-id pub-id-type="publisher-id">entropy-21-01074</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A Reference-Free Lossless Compression Algorithm for DNA Sequences Using a Competitive Prediction of Two Classes of Weighted Models</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-1176-552X</contrib-id>
        <name>
          <surname>Pratas</surname>
          <given-names>Diogo</given-names>
        </name>
        <xref ref-type="aff" rid="af1-entropy-21-01074">1</xref>
        <xref ref-type="aff" rid="af2-entropy-21-01074">2</xref>
        <xref ref-type="aff" rid="af3-entropy-21-01074">3</xref>
        <xref rid="c1-entropy-21-01074" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0001-8962-8985</contrib-id>
        <name>
          <surname>Hosseini</surname>
          <given-names>Morteza</given-names>
        </name>
        <xref ref-type="aff" rid="af1-entropy-21-01074">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-6331-6091</contrib-id>
        <name>
          <surname>Silva</surname>
          <given-names>Jorge M.</given-names>
        </name>
        <xref ref-type="aff" rid="af1-entropy-21-01074">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-9164-0016</contrib-id>
        <name>
          <surname>Pinho</surname>
          <given-names>Armando J.</given-names>
        </name>
        <xref ref-type="aff" rid="af1-entropy-21-01074">1</xref>
        <xref ref-type="aff" rid="af2-entropy-21-01074">2</xref>
      </contrib>
    </contrib-group>
    <aff id="af1-entropy-21-01074"><label>1</label>Institute of Electronics and Informatics Engineering of Aveiro, University of Aveiro, 3810-193 Aveiro, Portugal; <email>seyedmorteza@ua.pt</email> (M.H.); <email>jorge.miguel.ferreira.silva@ua.pt</email> (J.M.S.); <email>ap@ua.pt</email> (A.J.P.)</aff>
    <aff id="af2-entropy-21-01074"><label>2</label>Department of Electronics, Telecomunications and Informatics, University of Aveiro, 3810-193 Aveiro, Portugal</aff>
    <aff id="af3-entropy-21-01074"><label>3</label>Department of Virology, University of Helsinki, 00100 Helsinki, Finland</aff>
    <author-notes>
      <corresp id="c1-entropy-21-01074"><label>*</label>Correspondence: <email>pratas@ua.pt</email>; Tel.: +351-234-370-507</corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>02</day>
      <month>11</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>11</month>
      <year>2019</year>
    </pub-date>
    <volume>21</volume>
    <issue>11</issue>
    <elocation-id>1074</elocation-id>
    <history>
      <date date-type="received">
        <day>24</day>
        <month>9</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>31</day>
        <month>10</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2019 by the authors.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="open-access">
        <license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p>
      </license>
    </permissions>
    <abstract>
      <p>The development of efficient data compressors for DNA sequences is crucial not only for reducing the storage and the bandwidth for transmission, but also for analysis purposes. In particular, the development of improved compression models directly influences the outcome of anthropological and biomedical compression-based methods. In this paper, we describe a new lossless compressor with improved compression capabilities for DNA sequences representing different domains and kingdoms. The reference-free method uses a competitive prediction model to estimate, for each symbol, the best class of models to be used before applying arithmetic encoding. There are two classes of models: weighted context models (including substitutional tolerant context models) and weighted stochastic repeat models. Both classes of models use specific sub-programs to handle inverted repeats efficiently. The results show that the proposed method attains a higher compression ratio than state-of-the-art approaches, on a balanced and diverse benchmark, using a competitive level of computational resources. An efficient implementation of the method is publicly available, under the GPLv3 license.</p>
    </abstract>
    <kwd-group>
      <kwd>lossless data compression</kwd>
      <kwd>DNA sequences</kwd>
      <kwd>competitive prediction</kwd>
      <kwd>weighted models</kwd>
      <kwd>context models</kwd>
      <kwd>stochastic repeat models</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="sec1-entropy-21-01074">
    <title>1. Introduction</title>
    <p>The arrival of high throughput DNA sequencing technology has created a deluge of biological data [<xref rid="B1-entropy-21-01074" ref-type="bibr">1</xref>]. With the low sequencing costs of next-generation sequencing [<xref rid="B2-entropy-21-01074" ref-type="bibr">2</xref>], metagenomics [<xref rid="B3-entropy-21-01074" ref-type="bibr">3</xref>], ancient genomes [<xref rid="B4-entropy-21-01074" ref-type="bibr">4</xref>], and biomedical applications [<xref rid="B5-entropy-21-01074" ref-type="bibr">5</xref>], the number of available complete genomes is increasing widely. Most of the data are discarded and, when classified as crucial, compressed using general or specific purpose algorithms. Additionally, with the increasing of ancient sequenced genomes, the quantity of data to be compressed is now achieving a higher magnitude [<xref rid="B6-entropy-21-01074" ref-type="bibr">6</xref>,<xref rid="B7-entropy-21-01074" ref-type="bibr">7</xref>].</p>
    <p>There are many file formats to represent genomic data—for example, FASTA, FASTQ, BAM/SAM, VCF/BCF, and MSA, and many data compressors to represent specifically these formats [<xref rid="B8-entropy-21-01074" ref-type="bibr">8</xref>,<xref rid="B9-entropy-21-01074" ref-type="bibr">9</xref>,<xref rid="B10-entropy-21-01074" ref-type="bibr">10</xref>,<xref rid="B11-entropy-21-01074" ref-type="bibr">11</xref>,<xref rid="B12-entropy-21-01074" ref-type="bibr">12</xref>,<xref rid="B13-entropy-21-01074" ref-type="bibr">13</xref>,<xref rid="B14-entropy-21-01074" ref-type="bibr">14</xref>,<xref rid="B15-entropy-21-01074" ref-type="bibr">15</xref>,<xref rid="B16-entropy-21-01074" ref-type="bibr">16</xref>,<xref rid="B17-entropy-21-01074" ref-type="bibr">17</xref>,<xref rid="B18-entropy-21-01074" ref-type="bibr">18</xref>,<xref rid="B19-entropy-21-01074" ref-type="bibr">19</xref>,<xref rid="B20-entropy-21-01074" ref-type="bibr">20</xref>,<xref rid="B21-entropy-21-01074" ref-type="bibr">21</xref>,<xref rid="B22-entropy-21-01074" ref-type="bibr">22</xref>,<xref rid="B23-entropy-21-01074" ref-type="bibr">23</xref>]. All of these file formats have in common the genomic sequence part, although in different phases or using different representations. The ultimate aim of genomics, before downstream analysis, is to assemble high-quality genomic sequences, allowing for having high-quality analysis and consistent scientific findings.</p>
    <p>Genomic (or DNA) sequences are codified messages, from an alphabet of four symbols <inline-formula><mml:math id="mm1"><mml:mrow><mml:mrow><mml:mi mathvariant="sans-serif">Θ</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, containing instructions, structure, and historical marks of all known cellular organisms [<xref rid="B24-entropy-21-01074" ref-type="bibr">24</xref>]. Initially, genomic sequences were compressed with general-purpose algorithms or tools, such as gzip (<uri xlink:href="www.gzip.org">www.gzip.org</uri>), bzip2 (<uri xlink:href="http://sourceware.org/bzip2">http://sourceware.org/bzip2</uri>), or LZMA (<uri xlink:href="www.7-zip.org/sdk.html">www.7-zip.org/sdk.html</uri>). Since the emergence of BioCompress [<xref rid="B25-entropy-21-01074" ref-type="bibr">25</xref>], the development of specific compression algorithms for these sequences revolutionized the field.</p>
    <p>The development of specific compression algorithms of DNA sequences has now 27 years. There are many lossless compression algorithms explicitly developed for genomic sequences [<xref rid="B26-entropy-21-01074" ref-type="bibr">26</xref>]. These algorithms rely on a trade-off between compressibility and computational resources. The reasons are the specific need to balance the program with hardware characteristics and the compression purpose. Industrial-oriented compression purposes, often aiming for ultra-fast and low memory consumption computations at the expense of poor compressibility, are different from the scientific-oriented approach of developing novel models, usually aiming for better compressibility at the expense of higher computational resources.</p>
    <p>The nature of the specific data compressors takes advantage of the inclusion of sub-programs to efficiently handle specific DNA properties, namely a high number of copies, a high level of substitutional mutations, high heterogeneity, and multiple rearrangements, such as inverted repeats [<xref rid="B27-entropy-21-01074" ref-type="bibr">27</xref>,<xref rid="B28-entropy-21-01074" ref-type="bibr">28</xref>]. Additionally, genomic sequences may contain data from other sources—for example, environmental factors [<xref rid="B29-entropy-21-01074" ref-type="bibr">29</xref>,<xref rid="B30-entropy-21-01074" ref-type="bibr">30</xref>], exogeneous inclusion [<xref rid="B31-entropy-21-01074" ref-type="bibr">31</xref>,<xref rid="B32-entropy-21-01074" ref-type="bibr">32</xref>], and unknown sources [<xref rid="B33-entropy-21-01074" ref-type="bibr">33</xref>]. Compressing genomic sequences requires the ability to model heterogeneous, dynamic, incomplete, and imperfect information [<xref rid="B34-entropy-21-01074" ref-type="bibr">34</xref>].</p>
    <p>The lossless compression of genomic sequences has been addressed using two approaches: reference-based and reference-free [<xref rid="B35-entropy-21-01074" ref-type="bibr">35</xref>]. The reference-based approach usually achieves substantially better compression results, mainly because when two sequences are almost identical, a model that efficiently represents the differences of one according to the other achieves top compression results. Using variations of this methodology, several reference-based approaches were proposed [<xref rid="B8-entropy-21-01074" ref-type="bibr">8</xref>,<xref rid="B36-entropy-21-01074" ref-type="bibr">36</xref>,<xref rid="B37-entropy-21-01074" ref-type="bibr">37</xref>,<xref rid="B38-entropy-21-01074" ref-type="bibr">38</xref>,<xref rid="B39-entropy-21-01074" ref-type="bibr">39</xref>,<xref rid="B40-entropy-21-01074" ref-type="bibr">40</xref>,<xref rid="B41-entropy-21-01074" ref-type="bibr">41</xref>,<xref rid="B42-entropy-21-01074" ref-type="bibr">42</xref>,<xref rid="B43-entropy-21-01074" ref-type="bibr">43</xref>,<xref rid="B44-entropy-21-01074" ref-type="bibr">44</xref>,<xref rid="B45-entropy-21-01074" ref-type="bibr">45</xref>,<xref rid="B46-entropy-21-01074" ref-type="bibr">46</xref>,<xref rid="B47-entropy-21-01074" ref-type="bibr">47</xref>,<xref rid="B48-entropy-21-01074" ref-type="bibr">48</xref>].</p>
    <p>Although the reference-based approach is exceptionally efficient, there is the need to store a reference sequence. On the other hand, the reference-free approach has the advantage of not needing any reference. This approach is essential for reducing the storage of reference sequences and, more importantly, to estimate the quantity of information contained in a DNA sequence, an approximation of the Kolmogorov complexity [<xref rid="B49-entropy-21-01074" ref-type="bibr">49</xref>]. The latter has proven to be able to infer insights into genomic evolution as well as being suitable to group sequences by nature [<xref rid="B50-entropy-21-01074" ref-type="bibr">50</xref>].</p>
    <p>Despite the usage of general-purpose algorithms with heavy computational models, such as neural networks, to compress genomic sequences, the specific compressors that efficiently address the specific characteristics of genomic sequences show higher compression capabilities (5–10%) using substantially less computational resources [<xref rid="B51-entropy-21-01074" ref-type="bibr">51</xref>].</p>
    <p>As depicted in <xref ref-type="fig" rid="entropy-21-01074-f001">Figure 1</xref>, the first specific algorithm is Biocompress. The Biocompress is based on a Lempel–Ziv dictionary approach [<xref rid="B52-entropy-21-01074" ref-type="bibr">52</xref>], exploring repeats and palindromes. The Biocompress2 [<xref rid="B53-entropy-21-01074" ref-type="bibr">53</xref>] is an extension of Biocompress [<xref rid="B25-entropy-21-01074" ref-type="bibr">25</xref>], adding arithmetic coding of order-2 as a fallback mechanism.</p>
    <p>The Cfact algorithm [<xref rid="B54-entropy-21-01074" ref-type="bibr">54</xref>] uses parsing, where exact repeats are loaded in a suffix tree along with the positions indexes and encoding. The CDNA [<xref rid="B55-entropy-21-01074" ref-type="bibr">55</xref>] was the first algorithm to combine statistical compression with approximate repeat for DNA compression. The ARM algorithm [<xref rid="B56-entropy-21-01074" ref-type="bibr">56</xref>] explores the probability of a subsequence by summing the probabilities given the explanations of how a subsequence is generated. The ARM and CDNA algorithms yield significantly better compression ratios than older algorithms.</p>
    <p>The offline algorithm [<xref rid="B57-entropy-21-01074" ref-type="bibr">57</xref>] models repeated regions for compression. Only exact repeats are considered during each iteration, and the algorithm selects a substring that leads to the contraction suffix tree used to find the substring with the maximum possible number of non-overlapping occurrences. The GenCompress algorithm [<xref rid="B58-entropy-21-01074" ref-type="bibr">58</xref>] explores the existence of approximate repeats. The DNACompress [<xref rid="B59-entropy-21-01074" ref-type="bibr">59</xref>] finds approximate repeats using the PatternHunter [<xref rid="B60-entropy-21-01074" ref-type="bibr">60</xref>] and, then, uses a Lempel–Ziv approach [<xref rid="B52-entropy-21-01074" ref-type="bibr">52</xref>] for encoding. The CTW + LZ algorithm [<xref rid="B61-entropy-21-01074" ref-type="bibr">61</xref>] is based on the context tree weighting method, which uses a weighting of multiple models to determine the next symbol probabilities. The algorithm detects approximate repeats using dynamic programming and then encodes long exact and approximate repeats using an LZ77-type encoding. Short repeats and non-repeats are encoded using a CTW.</p>
    <p>The NMLComp algorithm [<xref rid="B62-entropy-21-01074" ref-type="bibr">62</xref>] uses the normalized maximum likelihood (NML) model to encode approximate repeats using discrete regression and, then, combines it with a first-order context model. The GeNML [<xref rid="B63-entropy-21-01074" ref-type="bibr">63</xref>] presents an improvement to NMLComp method, namely restricting the approximate repeats matches to reduce the cost of search, choosing the block sizes for parsing the target sequence, and uses scalable forgetting factors for the memory model.</p>
    <p>The DNASequitur [<xref rid="B64-entropy-21-01074" ref-type="bibr">64</xref>] is a grammar-based compression algorithm which infers a context-free grammar to represent the input sequence. Besides the exact repeats, it recognizes inverted repeats when creating rules and during substitutions. The DNA-X algorithm [<xref rid="B65-entropy-21-01074" ref-type="bibr">65</xref>] takes advantage of repetitions by searching and encoding exact and approximate repeats. The approach uses much lower computational resources than older algorithms while achieving a competitive compression ratio. The DNAC [<xref rid="B66-entropy-21-01074" ref-type="bibr">66</xref>] is an update of the Cfact algorithm working in four phases. It builds a suffix tree to locate exact repeats; all exact repeats are extended into approximate repeats by dynamic programming; it extracts the optimal non-overlapping repeats from the overlapping ones; it uses the Fibonacci encoding method to encode the repeats in a self-delimited way. The DNAPack algorithm [<xref rid="B67-entropy-21-01074" ref-type="bibr">67</xref>] works by finding approximate repeats to encode them optimally. It uses a dynamic programming approach for the selection of the segments.</p>
    <p>The XM algorithm [<xref rid="B68-entropy-21-01074" ref-type="bibr">68</xref>] is still one of the most successful compressors given its compression capabilities at the expense of more computational resources, both time and memory. It combines three types of models: repeat models, a low-order context model, and a short memory context model of 512 bytes. The probabilities are encoded using arithmetic coding.</p>
    <p>The Differential Direct Coding algorithm (2D) [<xref rid="B69-entropy-21-01074" ref-type="bibr">69</xref>] uses side information strategies to accommodate large data sets using multiple sequences and auxiliary data. 2D is suitable for any sequence data, including substantial length data sets, such as genomes and meta-genomes. The DNASC algorithm [<xref rid="B70-entropy-21-01074" ref-type="bibr">70</xref>] compresses the DNA sequence horizontally, first by using extended Lempel–Ziv style, and, then, vertically by taking a block size equal to 6, and a window size equal to 128. The GBC algorithm [<xref rid="B71-entropy-21-01074" ref-type="bibr">71</xref>] assigns binary bits in a preprocessing stage to exact and reverse repeat fragments of DNA sequences. The DNACompact algorithm [<xref rid="B72-entropy-21-01074" ref-type="bibr">72</xref>] uses a preprocessing edition of the bases for after representation using encoding by word-based tagged code (WBTC) [<xref rid="B73-entropy-21-01074" ref-type="bibr">73</xref>]. The POMA tool [<xref rid="B74-entropy-21-01074" ref-type="bibr">74</xref>] uses particle swarm optimization, which makes the algorithm feasible only for tiny sequences.</p>
    <p>The DNAEnc3 algorithm [<xref rid="B75-entropy-21-01074" ref-type="bibr">75</xref>] uses a competition of context models of several depths (orders up to sixteen) and, then, redirects the probabilities to an arithmetic encoder. It uses sub-programs embedded in the context models to handle the inverted repeats. The DNAEnc4v2 algorithm [<xref rid="B76-entropy-21-01074" ref-type="bibr">76</xref>], instead of competition as in DNAEnc3, the context models are combined with a soft-blending mechanism that uses a particular decaying forgetting factor to give importance to the context models that achieve better performance.</p>
    <p>The LUT algorithm [<xref rid="B77-entropy-21-01074" ref-type="bibr">77</xref>] uses a four-step coding rule. It includes the use of a LUT (Look Up Table), character transformations, tandem repeats handling, and segment decisions. The GenCodex algorithm [<xref rid="B78-entropy-21-01074" ref-type="bibr">78</xref>] yields a better compression ratio at high throughput by using graphical processing units (GPUs) and multi-core in two phases, namely bit-preprocessing and fragment representation using either one or two bytes.</p>
    <p>The BIND algorithm [<xref rid="B79-entropy-21-01074" ref-type="bibr">79</xref>] adopts a unique ’block-length’ encoding for representing binary data. BIND also handles other symbols than ACGT. The DNA-COMPACT algorithm [<xref rid="B80-entropy-21-01074" ref-type="bibr">80</xref>] exploits complementary contextual models to search for exact repeats and palindromes and represent them by a compact quadruplet. Then, it uses non-sequential contextual models where the predictions of these models are synthesized using a logistic regression model. The HighFCM algorithm [<xref rid="B81-entropy-21-01074" ref-type="bibr">81</xref>] explores a pre-analysis of the data before compression to identify regions of low complexity. This strategy enables the use of deeper context models (context order up to 32), supported by hash-tables, without requiring huge amounts of memory. The SeqCompress algorithm [<xref rid="B82-entropy-21-01074" ref-type="bibr">82</xref>] uses a statistical model and, then, arithmetic coding to compress DNA sequences.</p>
    <p>Transforming genomic sequences into images, where a two-dimensional space substitutes the one-dimensional space, is an approach that is used in [<xref rid="B83-entropy-21-01074" ref-type="bibr">83</xref>,<xref rid="B84-entropy-21-01074" ref-type="bibr">84</xref>]. In [<xref rid="B83-entropy-21-01074" ref-type="bibr">83</xref>], firstly, the Hilbert space-filling curve is exploited to map the target sequence into an image. Secondly, a context weighting model is used for encoding the image. In [<xref rid="B84-entropy-21-01074" ref-type="bibr">84</xref>], the CoGI (Compressing Genomes as an Image) algorithm is presented, which initially transforms the genomic sequence into a binary image (or bitmap), then, uses a rectangular partition coding method [<xref rid="B85-entropy-21-01074" ref-type="bibr">85</xref>] to compress the image and, finally, explores entropy coding for further compression of the encoded image and side information.</p>
    <p>The GeCo algorithm [<xref rid="B86-entropy-21-01074" ref-type="bibr">86</xref>] uses a soft-blending cooperation with a specific forgetting factor between context models and substitutional tolerant context models [<xref rid="B87-entropy-21-01074" ref-type="bibr">87</xref>] before employing arithmetic encoding. It has sub-programs to deal with inverted repeats and uses cache-hashes for deeper context models. In GeCo2 [<xref rid="B88-entropy-21-01074" ref-type="bibr">88</xref>], the mixture of models is enhanced, where each context model or tolerant context model now has a specific decay factor. Additionally, specific cache-hash sizes and the ability to run only a context model with inverted repeats are available.</p>
    <p>The OCW algorithm [<xref rid="B89-entropy-21-01074" ref-type="bibr">89</xref>] uses an optimized context weighting based on the minimum description length and the least-square algorithm for the optimization of the weights. The OBComp algorithm [<xref rid="B90-entropy-21-01074" ref-type="bibr">90</xref>] uses a single bit to code the two highest occurrence nucleotides. The positions of the two others are saved. Then, it uses a modified version of an RLE technique and the Huffman coding algorithm.</p>
    <p>In this paper, we propose a new algorithm (Jarvis) that uses a competitive prediction based on two different classes: Weighted context models and Weighted stochastic repeat models. The Weighted context models use a soft-blending mechanism, with a decaying forgetting factor, of context and substitutional tolerant context models. The Weighted stochastic repeat models also uses a soft-blending mechanism, with a decaying forgetting factor, between multiple repeat models of specific word size. Both classes use sub-programs to handle inverted repeats. The competitive prediction is based on the highest probability of each class at a precise moment. The model is trained along with the prediction using a context model. The final probabilities, for each base, are coded using an arithmetic encoder.</p>
    <p>This paper is organized as follows. In the next section, we describe the compressor in detail. Then, we present the comparative results of the proposed compressor against state-of-the-art algorithms in a fair and consistent benchmark proposed in [<xref rid="B91-entropy-21-01074" ref-type="bibr">91</xref>]. The latter includes a discussion of some possible development lines. Finally, we make some conclusions.</p>
  </sec>
  <sec id="sec2-entropy-21-01074">
    <title>2. Method</title>
    <p>The method is based on a competitive prediction between two classes of models: Weighted context models and Weighted stochastic repeat models. As depicted in <xref ref-type="fig" rid="entropy-21-01074-f002">Figure 2</xref>, for each prediction, the probabilities are redirected to an arithmetic encoder. The context models (at the left of <xref ref-type="fig" rid="entropy-21-01074-f002">Figure 2</xref>) are combined through a weighted set of context and substitutional tolerant context models [<xref rid="B86-entropy-21-01074" ref-type="bibr">86</xref>,<xref rid="B87-entropy-21-01074" ref-type="bibr">87</xref>] using a specific forgetting factor for each model, while the Weighted stochastic repeat models (at the right of <xref ref-type="fig" rid="entropy-21-01074-f002">Figure 2</xref>) use a common forgetting factor.</p>
    <p>The method enables setting any number of context models and repeat models, as long as at least one model is used. This setup permits very high flexibility to address different types of DNA sequences and creates space for further optimization algorithms.</p>
    <p>In the following subsections, we describe in detail the Weighted context models, the Weighted stochastic repeat models, the competitive prediction model, and the implementation of the algorithm. For the purpose, we assume that there is a source generating symbols from a finite alphabet <inline-formula><mml:math id="mm2"><mml:mrow><mml:mi mathvariant="sans-serif">Θ</mml:mi></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="mm3"><mml:mrow><mml:mrow><mml:mi mathvariant="sans-serif">Θ</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We also assume that the source has already generated the sequence of <italic>n</italic> symbols <inline-formula><mml:math id="mm4"><mml:mrow><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.277778em"/><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="sans-serif">Θ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. Therefore, a subsequence of <inline-formula><mml:math id="mm5"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, from position <italic>i</italic> to <italic>j</italic>, is denoted as <inline-formula><mml:math id="mm6"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p>
    <sec id="sec2dot1-entropy-21-01074">
      <title>2.1. Weighted Context Models</title>
      <p>Context models are finite statistical models assuming the Markov property. A context model of an information source assigns probability estimates to the symbols of the alphabet, according to a conditioning context computed over a finite and fixed number, <italic>k</italic>, of past outcomes (order-<italic>k</italic> context-model) [<xref rid="B92-entropy-21-01074" ref-type="bibr">92</xref>]. A substitutional tolerant context model (STCM) [<xref rid="B86-entropy-21-01074" ref-type="bibr">86</xref>,<xref rid="B87-entropy-21-01074" ref-type="bibr">87</xref>] is a probabilistic-algorithmic context model. It acts as a short program that enables setting the number of allowed substitutions in a certain context depth. In practice, it assigns probabilities according to a conditioning context that considers the last symbol, from the sequence to occur, as the most probable, given the occurrences stored in the memory instead of the true occurring symbol. An STCM, besides being probabilistic, is also algorithmic, namely because they can be switched on or off given its performance, according to a threshold, <italic>t</italic>, defined before the computation [<xref rid="B86-entropy-21-01074" ref-type="bibr">86</xref>]. The threshold enables or disables the model, according to the number of times that the context has been seen, given <italic>l</italic> hits or fails that are constantly stored in memory in a cache array. For both context models and STCMs, the number of conditioning states of the model is <inline-formula><mml:math id="mm7"><mml:mrow><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="sans-serif">Θ</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> (in our case, <inline-formula><mml:math id="mm8"><mml:mrow><mml:msup><mml:mn>4</mml:mn><mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>).</p>
      <p>We assume that the memory model starts with counters all set to zero. Through all the computation, the memory model is updated according to the outcomes. Therefore, the prediction of each context model is set along with the training. Notice that, in <xref ref-type="fig" rid="entropy-21-01074-f002">Figure 2</xref>, the models four and five share the same memory model (CM4) because model five is an STCM with the same <italic>k</italic> as in model four.</p>
      <p>The cooperation of both context models and STCM is supervised by a soft blending mechanism [<xref rid="B75-entropy-21-01074" ref-type="bibr">75</xref>,<xref rid="B93-entropy-21-01074" ref-type="bibr">93</xref>] that gives importance to the models that had a better performance, given an exponential decaying memory [<xref rid="B75-entropy-21-01074" ref-type="bibr">75</xref>]. <xref ref-type="fig" rid="entropy-21-01074-f002">Figure 2</xref> depicts an example of the cooperation between four context models and one substitutional tolerant context model, <inline-formula><mml:math id="mm9"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. Each of these models, <inline-formula><mml:math id="mm10"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, has a probability (<inline-formula><mml:math id="mm11"><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>), a weight (<inline-formula><mml:math id="mm12"><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>W</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>), and a memory model (<inline-formula><mml:math id="mm13"><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>) associated with it.</p>
      <p>For a model, the probability of each symbol, <inline-formula><mml:math id="mm14"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, is given by
<disp-formula id="FD1-entropy-21-01074"><label>(1)</label><mml:math id="mm15"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant="script">M</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>P</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.277778em"/><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> where <inline-formula><mml:math id="mm16"><mml:mrow><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the probability assigned to the next symbol by a context model or STCM, <italic>k</italic> is the order of the corresponding model <italic>m</italic>, and where <inline-formula><mml:math id="mm17"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> denotes the corresponding weighting factor, with
<disp-formula id="FD2-entropy-21-01074"><label>(2)</label><mml:math id="mm18"><mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∝</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:msup><mml:msub><mml:mi>P</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula> where the sum of the weights, for each respective model, is constrained to one, and where <inline-formula><mml:math id="mm19"><mml:mrow><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> acts as a forgetting factor for each model. We found experimentally that models with lower <italic>k</italic> are related to lower <inline-formula><mml:math id="mm20"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (typically, below 0.9), while higher <italic>k</italic>, is associated with higher <inline-formula><mml:math id="mm21"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (near 0.95). This means that, in this mixture type, the forgetting intensity should be lower for more complex models. A curious indication was also found for a context model of order six. This model seems to be efficient with <inline-formula><mml:math id="mm22"><mml:mrow><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mn>0.75</mml:mn><mml:mo>,</mml:mo><mml:mn>0.85</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and is associated with <inline-formula><mml:math id="mm23"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, which is the lowest <inline-formula><mml:math id="mm24"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> among the models. We hypothesize that this might be related to the period multiplicity found in the DNA [<xref rid="B94-entropy-21-01074" ref-type="bibr">94</xref>].</p>
      <p>The depth of the model, <italic>k</italic>, identifies the number of contiguous symbols seen in the past for predicting the next symbol and, hence, <inline-formula><mml:math id="mm25"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></inline-formula> [<xref rid="B92-entropy-21-01074" ref-type="bibr">92</xref>]. We use an estimator parameter (alpha) that allows for balancing between the uniform and the frequency distribution (usually the deepest models have lower alphas [<xref rid="B81-entropy-21-01074" ref-type="bibr">81</xref>]).</p>
      <p>Inverted repeats are essential to consider because they can give additional compression gain [<xref rid="B95-entropy-21-01074" ref-type="bibr">95</xref>]. Therefore, we use a short program that allows mapping for subsequences with similarity to inverted repeat sequences according to the algorithm of [<xref rid="B96-entropy-21-01074" ref-type="bibr">96</xref>].</p>
      <p>The cache-hash [<xref rid="B97-entropy-21-01074" ref-type="bibr">97</xref>] enables keeping in mind only the latest entries up to a certain number of hash collisions. This is very important because the memory models of the deepest context models have very sparse representations and, hence, storing its entries in a table would require <inline-formula><mml:math id="mm26"><mml:mrow><mml:msup><mml:mn>4</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> entries, which means that assuming counters of 8 bits for a <inline-formula><mml:math id="mm27"><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> would require 4 TB of RAM. A linear hash would be feasible, depending on the available RAM and sequence size. In order to remove space constraints, we set a maximum number of collisions, enabling us to maintain a maximum peak of RAM.</p>
    </sec>
    <sec id="sec2dot2-entropy-21-01074">
      <title>2.2. Weighted Stochastic Repeat Models</title>
      <p>The repeat model, also known as a copy expert from the XM compression method [<xref rid="B68-entropy-21-01074" ref-type="bibr">68</xref>], is a model that stores into memory the positions relative to the sequence that has an identical <italic>k</italic>-mer identified in the past of the sequence. The positions are stored, using a causal processing paradigm, usually in a memory model as a hash-table. The model is used after a <italic>k</italic>-mer match occurs and is switched off after a certain threshold of performance is reached.</p>
      <p><xref ref-type="fig" rid="entropy-21-01074-f003">Figure 3</xref> depicts an example of a repeat model with <italic>k</italic>-mer size of 8 while <xref ref-type="fig" rid="entropy-21-01074-f002">Figure 2</xref> (at the right side) represents the architecture. The positions of where the subsequence occurred in the past are stored in the hash table. In this example, two positions are identified, namely 14,251 and 14,275. If we used only one position, this would be similar to the GReEn implementation [<xref rid="B41-entropy-21-01074" ref-type="bibr">41</xref>]. However, we use the information at most from <inline-formula><mml:math id="mm28"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>P</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> models (<inline-formula><mml:math id="mm29"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>P</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> are the maximum number of repeats models which are shown in <xref ref-type="fig" rid="entropy-21-01074-f002">Figure 2</xref>). When the <inline-formula><mml:math id="mm30"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>P</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is higher than the available number of positions, the number of actual models is bounded by the maximum.</p>
      <p>These repeat models are called stochastic because, to start a new repeat (after a <italic>k</italic>-mer match), any position given the same <italic>k</italic>-mer (in the hash table) has the same probability of being used. If we used the sequential order, the initial positions of the sequence would be more used, given the number of repeats being upper bounded by <inline-formula><mml:math id="mm31"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>P</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. Therefore, the stochastic nature enables uniform distribution of the repeats to start in different positions along the sequence. Another advantage is the absence of indexes to represent the position of the repeat being used under the positions vector. As such, the stochastic nature allows decreasing the memory inherent to the representation of the hash table.</p>
      <p>Along with the hash table of positions, the sequence needs to be continuously preserved in memory (both in compression and decompression). To minimize its representation in memory, we pack each DNA symbol into two bits, instead of the common 8 bits. This approach allows for decreasing to a factor of four the memory associated with the representation of the sequence. Notice that sequences with length 100 MBases would require 100 MBytes of RAM just to be represented. With the packing approach, only 24 MB are needed.</p>
      <p>The repeat models are combined using the same methodology in the context models. For each repeat, there is a weight which is adapted according to its performance. In this case, the decaying (<inline-formula><mml:math id="mm32"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>) is very small since the weights need to be quickly adapted.</p>
    </sec>
    <sec id="sec2dot3-entropy-21-01074">
      <title>2.3. Competitive Prediction Context Model</title>
      <p>The competitive prediction is used to choose the best-predicted class of models between Weighted context models and Weighted stochastic repeat models. The prediction is modeled using a context model with a specific order-size defined as a parameter. The context model uses a binary alphabet, where each symbol corresponds to a different class. The sequence of symbols containing the best model is represented by <italic>Z</italic>, where <inline-formula><mml:math id="mm33"><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is a symbol of the sequence at a given instant <italic>i</italic>.</p>
      <p><xref ref-type="fig" rid="entropy-21-01074-f004">Figure 4</xref> depicts an example of a competitive prediction context model with a context order depth of five. To predict the best class of models to represent <inline-formula><mml:math id="mm34"><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, the probability of <inline-formula><mml:math id="mm35"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>Z</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> needs to be computed, having <italic>S</italic> as the next symbol (in this case <inline-formula><mml:math id="mm36"><mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) and <italic>k</italic> as the context order depth with the previous five symbols.</p>
      <p>The class that has the highest probability of being used is the one which will be used to model a specific base. Accordingly, the probabilities of the selected class will be forwarded to the arithmetic encoder. After that, the information of the best class is updated into the context model of the classes.</p>
      <p>Since in the CPCM the context order (<italic>k</italic>) is the crucial parameter, we assessed the impact of the variation of the context order according to different modes for different genomic sequences. <xref ref-type="fig" rid="entropy-21-01074-f005">Figure 5</xref> depicts this assessment using the HoSa, EnIn, AeCa, and YeMi sequences (in decreasing order of sequence length). The remaining plots for the other sequences in the dataset can be found at the code repository. Generally, there is a relation between the context order of the CPCM and the length of the sequence (according to the respective redundancy), where longer sequences require a higher context order, and shorter sequences stand for lower context orders. As an example, the HoSa sequence (largest) is better compressed (in level 12) with a context order of 16, while the YeMi sequence (shortest) is better compressed (in level 2) with a context order of 5.</p>
      <p>The described competitive prediction model runs in high-speed using reasonable accuracy. The accuracy of the model can improve with the development of a prediction based on multiple models, namely through Weighted context models. However, this creates a trade-off between accuracy and computational time, which may be very high for the gains that it may produce.</p>
    </sec>
    <sec id="sec2dot4-entropy-21-01074">
      <title>2.4. Decompression</title>
      <p>For a compression method to be considered lossless, all the compressed sequences must be decompressed exactly to the original sequences. The current compression and decompression methodologies are symmetric. This symmetry means that both Weighted context models, Weighted stochastic repeat models, and competitive prediction model are synchronized in the same order using the same characteristics. Additional side information is included in the compressed file (in the beginning) in order for the decompressor to use the same characteristics. For example, in the Weighted stochastic repeat models, the seed is passed in the header to ensure the exact beginning in the stochastic process.</p>
      <p>Accordingly, all the files used in this article have been losslessly decompressed using the same machine and OS (Linux Ubuntu). Regarding different floating-point hardware implementations, we have only tested one sequence compression–decompression (DrMe) between different hardware and OS version, namely compressing with one (server) machine and with a specific OS and, then, decompress with a different (Desktop) machine and OS version. Although it has worked in this example, we can not guarantee that it stays synchronized on machines if they have different floating-point hardware implementations.</p>
    </sec>
    <sec id="sec2dot5-entropy-21-01074">
      <title>2.5. Implementation</title>
      <p>The tool (Jarvis), written in C language, is available at <uri xlink:href="https://github.com/cobilab/jarvis">https://github.com/cobilab/jarvis</uri>, under the GPL-v3 license, and can be applied to compress/decompress any genomic sequence. The alphabet of the sequences is truncated to ACGT symbols. We use a slightly modified implementation of an Arithmetic Encoder provided by Moffat et al. [<xref rid="B98-entropy-21-01074" ref-type="bibr">98</xref>].</p>
      <p>The tool is accompanied with the appropriate decompressor, which uses slightly less time to decompress than to compress, and approximately the same RAM. The decompressor is approximately symmetric. All the sequences that we tested have been losslessly decompressed.</p>
      <p>The tool includes several default running modes from 1 to 15. Apart from some exceptions, lower levels use less computational resources (time and RAM) and are more prone to shorter sequences, while higher levels work better in larger sequences. Nevertheless, specific model configurations can be manually set as parameters to the program.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="sec3-entropy-21-01074">
    <title>3. Results</title>
    <p>In this section, we benchmark the proposed compressor against state-of-the-art data compressors. The dataset proposed for this benchmark contains 15 genomic sequences [<xref rid="B91-entropy-21-01074" ref-type="bibr">91</xref>], with a consistent balance between the number of sequences and sizes. Moreover, it reflects the main domains and kingdoms of biological organisms, enabling a comprehensive and balanced comparison. The dataset contains a total DNA sequence lenght of 534,263,017 bases (approximately half a GigaByte).</p>
    <p>Ranking the algorithms mentioned in the Introduction is a complex task. For example, some of these algorithms have been a contribution to other extensions or applications, while others are specialized for specific types of genomic sequences, such as bacteria, collections of genomes, and alignment data. There are also algorithms to cope with low computational resources. From our experience, we would highlight XM [<xref rid="B68-entropy-21-01074" ref-type="bibr">68</xref>] and GeCo/GeCo2 [<xref rid="B86-entropy-21-01074" ref-type="bibr">86</xref>,<xref rid="B88-entropy-21-01074" ref-type="bibr">88</xref>] given their ability to compress genomic sequences with high compression ratios. On average, XM is slightly better concerning compression ratio (approximately 0.4% and 0.2% over GeCo and GeCo2, respectively). However, XM uses substantially higher RAM and time than GeCo and GeCo2 [<xref rid="B88-entropy-21-01074" ref-type="bibr">88</xref>,<xref rid="B91-entropy-21-01074" ref-type="bibr">91</xref>]. An algorithm that uses substantially lower computational resources is CoGI [<xref rid="B84-entropy-21-01074" ref-type="bibr">84</xref>]; however, it is less efficient in the compaction. From a large number of available specific genomic data compressors, we choose XM, GeCo, GeCo2, and CoGI for a benchmark with Jarvis. In addition, we include two general-purpose compressors, namely LZMA and PAQ8 (both using the best compression parameters).</p>
    <p>The results presented in this paper can be reproduced, under a Linux OS, using the scripts provided at the repository <uri xlink:href="https://github.com/cobilab/jarvis">https://github.com/cobilab/jarvis</uri>, specifically <uri>scripts/Run.sh</uri>. The results of GeCo2 have been imported from [<xref rid="B88-entropy-21-01074" ref-type="bibr">88</xref>].</p>
    <p>We present the comparative results of the proposed compressor (Jarvis) against state-of-the-art algorithms. <xref rid="entropy-21-01074-t001" ref-type="table">Table 1</xref> depicts the number of bytes needed to compress each DNA sequence for each compressor and <xref rid="entropy-21-01074-t002" ref-type="table">Table 2</xref> the computational time. As can be seen, on average, Jarvis compressed the dataset to the lowest number of bytes. In some sequences, GeCo2 and XM were able to achieve better compression, although with a minimal difference. Jarvis uses pre-set levels to compute and, hence, these values may be improved with higher levels and optimization.</p>
    <p>Regarding PAQ8 (in its best compression option), Jarvis achieves a compression improvement of 5.2%, approximately. This comparison is according to the measures in [<xref rid="B51-entropy-21-01074" ref-type="bibr">51</xref>]. In addition, on average, Jarvis is faster 140 times than PAQ8.</p>
    <p>Regarding CoGI, the method provides a small factor of compressibility, better than gzip 2.3% (although not present in the table, gzip in the best option achieve 150,794,589 bytes). Nevertheless, CoGI is the fastest method. On average, CoGi is faster than Jarvis 28 times, although Jarvis achieved 31% higher compression ratio. CoGI is more suitable for industry-orientation purposes.</p>
    <p>Jarvis shows and improvement of 1.1% and 0.9% to GeCo and GeCo2, respectively. The computational time is competitive with GeCo and slighty more than GeCo2. Regarding the second-best tool in compression ratio (XM), Jarvis improves the compression to approximately 0.6%. In addition, it is faster 5.7 times more than XM. Regarding RAM, Jarvis used a maximum peak of 7.12 GB in the largest sequence. These are competitive memory values with GeCo/GeCo2 and, at least, half of the RAM needed by XM.</p>
    <p><xref ref-type="fig" rid="entropy-21-01074-f006">Figure 6</xref> shows the compressed size and speed, where the mean of speed values for all datasets is calculated to obtain the average speed for each method. As depicted, Jarvis shows the best compression rate since the compressed size is the lowest. On the other hand, GeCo, GeCo2, and XM seem to have very similar performance, while PAQ8 and LZMA are not so efficient in genomic data. Regarding the speed, Jarvis is approximately at the level of LZMA and GeCo2, showing that the trade-off between computational resources and precision is minimal.</p>
    <p>Additionally, Jarvis can run with other modes. In <xref ref-type="fig" rid="entropy-21-01074-f007">Figure 7</xref>, we include a comparison of all the fifteen modes in Jarvis for the three largest sequences. For example, running Jarvis with level 12 in HoSa sequence achieves <bold>38,280,246</bold> bytes (1.6139 BPS). This result is an improvement of 1% over Jarvis in mode 7. The trade-off is computational time and RAM, however still less than XM. Therefore, Jarvis is flexible and can be optimized to achieve considerably better compression ratios. The optimization, besides the choice of the best model, can be applied in a specific combination of the number of models, depths, estimator parameters, among many others.</p>
    <p>One of the main achievements of this paper is to combine Weighted context models with Weighted stochastic repeat models using a competitive prediction model. In order to test the impact of the inclusion of both repeat models and competitive prediction model, we include a very repetitive sequence (exogenous from the benchmarking dataset). This test has the underlying idea that repetitive regions are better modeled with Weighted stochastic repeat models than by Weighted context models. The test sequence is the assembled human Y-chromosome downloaded from the NCBI.</p>
    <p>As depicted in <xref ref-type="fig" rid="entropy-21-01074-f008">Figure 8</xref>, all the modes from Jarvis compress better than the best mode from GeCo2. Jarvis (mode 12) achieves a compression 5.413% better than GeCo2 (mode 15) using approximately the same computational time. This example shows a substantial improvement using both Weighted stochastic repeat models and the competitive prediction model.</p>
  </sec>
  <sec sec-type="conclusions" id="sec4-entropy-21-01074">
    <title>4. Conclusions</title>
    <p>The development of efficient DNA sequence compressors is fundamental for reducing the storage allocated to projects. The importance is also reflected for analysis purposes, given the search for optimized and new tools for anthropological and biomedical applications.</p>
    <p>In this paper, we presented a reference-free lossless data compressor with improved compression capabilities for DNA sequences. The method uses a competitive prediction model to estimate, for each symbol, the best class of models to be used before applying arithmetic encoding. The method uses two classes of models: Weighted context models (including substitutional tolerant context models) and Weighted stochastic repeat models. Both classes of models use specific sub-programs to handle inverted repeat subsequences efficiently.</p>
    <p>The results show that the proposed method attains a higher compression ratio than state-of-the-art approaches using a fair and diverse benchmark. The computational resources needed by the proposed approach are competitive. The decompression process uses approximately the same computational resources.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>This work was partially funded by FEDER (Programa Operacional Factores de Competitividade—COMPETE) and by National Funds through the FCT—Foundation for Science and Technology, in the context of the projects UID/CEC/00127/2014, PTCD/EEI-SII/6608/2014. M.H. acknowledges UID/CEC/00127/2019.</p>
  </ack>
  <notes>
    <title>Author Contributions</title>
    <p>D.P. and A.J.P. conceived and designed the experiments; D.P., M.H., and J.M.S. performed the experiments; D.P., M.H., J.M.S., and A.J.P. analyzed the data; D.P., M.H., J.M.S., and A.J.P. wrote the paper.</p>
  </notes>
  <notes>
    <title>Funding</title>
    <p>This research was funded by the National Funds Grant No. UID/CEC/00127/2014, PTCD/EEI-SII/6608/2014, UID/CEC/00127/2019.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Conflicts of Interest</title>
    <p>The authors declare no conflict of interest.</p>
  </notes>
  <glossary>
    <title>Abbreviations</title>
    <p>The following abbreviations are used in this manuscript:
<array orientation="portrait"><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">AeCa</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Aeropyrum camini</italic>—archaea</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">AgPh</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Aggregatibacter phage S1249</italic>—phage virus</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">BPS</td><td align="left" valign="middle" rowspan="1" colspan="1">Bits per symbol</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">BuEb</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Bundibugyo ebolavirus</italic>—virus</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CPCM</td><td align="left" valign="middle" rowspan="1" colspan="1">Competitive prediction context model</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">CTW</td><td align="left" valign="middle" rowspan="1" colspan="1">Context tree weighting</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">DaRe</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Danio rerio</italic>—fish</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">DrMe</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Drosophila miranda</italic>—fly</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">EnIn</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Entamoeba invadens</italic>—amoebozoa</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">EsCo</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Escherichia coli</italic>—bacteria</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">GaGa</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Gallus gallus</italic>—chicken</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">GeCo</td><td align="left" valign="middle" rowspan="1" colspan="1">Genomic Compressor (tool)</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">GPU</td><td align="left" valign="middle" rowspan="1" colspan="1">Graphical Processing Unit</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HaHi</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Haloarcula hispanica</italic>—archaea</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HePy</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Helicobacter pylori</italic>—bacteria</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">HoSa</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Homo sapiens</italic>—human</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">LUT</td><td align="left" valign="middle" rowspan="1" colspan="1">Look Up Table</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">NC</td><td align="left" valign="middle" rowspan="1" colspan="1">Normalized Compression</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">OrSa</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Oriza sativa</italic>—plant</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">OS</td><td align="left" valign="middle" rowspan="1" colspan="1">Operating System</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">PlFa</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Plasmodium falciparum</italic>–protozoan</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">RAM</td><td align="left" valign="middle" rowspan="1" colspan="1">Random Access Memory</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">RLE</td><td align="left" valign="middle" rowspan="1" colspan="1">Run Length Encoding</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">ScPo</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Schizosaccharomyces pombe</italic>—fungi</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">TB</td><td align="left" valign="middle" rowspan="1" colspan="1">TeraByte</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">XM</td><td align="left" valign="middle" rowspan="1" colspan="1">eXpert-Model</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">YeMi</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>Yellowstone lake</italic>—mimivirus</td></tr></tbody></array></p>
  </glossary>
  <ref-list>
    <title>References</title>
    <ref id="B1-entropy-21-01074">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schatz</surname>
            <given-names>M.C.</given-names>
          </name>
          <name>
            <surname>Langmead</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <article-title>The DNA data deluge</article-title>
        <source>IEEE Spectrum</source>
        <year>2013</year>
        <volume>50</volume>
        <fpage>28</fpage>
        <lpage>33</lpage>
        <pub-id pub-id-type="doi">10.1109/MSPEC.2013.6545119</pub-id>
        <?supplied-pmid 24920863?>
        <pub-id pub-id-type="pmid">24920863</pub-id>
      </element-citation>
    </ref>
    <ref id="B2-entropy-21-01074">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mardis</surname>
            <given-names>E.R.</given-names>
          </name>
        </person-group>
        <article-title>DNA sequencing technologies: 2006–2016</article-title>
        <source>Nat. Protocols</source>
        <year>2017</year>
        <volume>12</volume>
        <fpage>213</fpage>
        <pub-id pub-id-type="doi">10.1038/nprot.2016.182</pub-id>
        <?supplied-pmid 28055035?>
        <pub-id pub-id-type="pmid">28055035</pub-id>
      </element-citation>
    </ref>
    <ref id="B3-entropy-21-01074">
      <label>3.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Marco</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <source>Metagenomics: Theory, Methods and Applications</source>
        <publisher-name>Horizon Scientific Press</publisher-name>
        <publisher-loc>Poole, UK</publisher-loc>
        <year>2010</year>
      </element-citation>
    </ref>
    <ref id="B4-entropy-21-01074">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Duggan</surname>
            <given-names>A.T.</given-names>
          </name>
          <name>
            <surname>Perdomo</surname>
            <given-names>M.F.</given-names>
          </name>
          <name>
            <surname>Piombino-Mascali</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Marciniak</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Poinar</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Emery</surname>
            <given-names>M.V.</given-names>
          </name>
          <name>
            <surname>Buchmann</surname>
            <given-names>J.P.</given-names>
          </name>
          <name>
            <surname>Duchêne</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Jankauskas</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Humphreys</surname>
            <given-names>M.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>17th century variola virus reveals the recent history of smallpox</article-title>
        <source>Curr. Biol.</source>
        <year>2016</year>
        <volume>26</volume>
        <fpage>3407</fpage>
        <lpage>3412</lpage>
        <pub-id pub-id-type="doi">10.1016/j.cub.2016.10.061</pub-id>
        <?supplied-pmid 27939314?>
        <pub-id pub-id-type="pmid">27939314</pub-id>
      </element-citation>
    </ref>
    <ref id="B5-entropy-21-01074">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Weber</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Fussenegger</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Emerging biomedical applications of synthetic biology</article-title>
        <source>Nat. Rev. Genet.</source>
        <year>2012</year>
        <volume>13</volume>
        <fpage>21</fpage>
        <pub-id pub-id-type="doi">10.1038/nrg3094</pub-id>
        <?supplied-pmid 22124480?>
        <pub-id pub-id-type="pmid">22124480</pub-id>
      </element-citation>
    </ref>
    <ref id="B6-entropy-21-01074">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Marciniak</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Perry</surname>
            <given-names>G.H.</given-names>
          </name>
        </person-group>
        <article-title>Harnessing ancient genomes to study the history of human adaptation</article-title>
        <source>Nat. Rev. Genet.</source>
        <year>2017</year>
        <volume>18</volume>
        <fpage>659</fpage>
        <pub-id pub-id-type="doi">10.1038/nrg.2017.65</pub-id>
        <?supplied-pmid 28890534?>
        <pub-id pub-id-type="pmid">28890534</pub-id>
      </element-citation>
    </ref>
    <ref id="B7-entropy-21-01074">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stephens</surname>
            <given-names>Z.D.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>S.Y.</given-names>
          </name>
          <name>
            <surname>Faghri</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Campbell</surname>
            <given-names>R.H.</given-names>
          </name>
          <name>
            <surname>Zhai</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Efron</surname>
            <given-names>M.J.</given-names>
          </name>
          <name>
            <surname>Iyer</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Schatz</surname>
            <given-names>M.C.</given-names>
          </name>
          <name>
            <surname>Sinha</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Robinson</surname>
            <given-names>G.E.</given-names>
          </name>
        </person-group>
        <article-title>Big data: Astronomical or genomical?</article-title>
        <source>PLoS Biol.</source>
        <year>2015</year>
        <volume>13</volume>
        <elocation-id>e1002195</elocation-id>
        <pub-id pub-id-type="doi">10.1371/journal.pbio.1002195</pub-id>
        <pub-id pub-id-type="pmid">26151137</pub-id>
      </element-citation>
    </ref>
    <ref id="B8-entropy-21-01074">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deorowicz</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Grabowski</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Compression of DNA sequence reads in FASTQ format</article-title>
        <source>Bioinformatics</source>
        <year>2011</year>
        <volume>27</volume>
        <fpage>860</fpage>
        <lpage>862</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btr014</pub-id>
        <pub-id pub-id-type="pmid">21252073</pub-id>
      </element-citation>
    </ref>
    <ref id="B9-entropy-21-01074">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hanus</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Dingel</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Chalkidis</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Hagenauer</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Compression of whole genome alignments</article-title>
        <source>IEEE Trans. Inf. Theory</source>
        <year>2010</year>
        <volume>56</volume>
        <fpage>696</fpage>
        <lpage>705</lpage>
        <pub-id pub-id-type="doi">10.1109/TIT.2009.2037052</pub-id>
      </element-citation>
    </ref>
    <ref id="B10-entropy-21-01074">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Matos</surname>
            <given-names>L.M.O.</given-names>
          </name>
          <name>
            <surname>Pratas</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
        </person-group>
        <article-title>A compression model for DNA multiple sequence alignment blocks</article-title>
        <source>IEEE Trans. Inf. Theory</source>
        <year>2013</year>
        <volume>59</volume>
        <fpage>3189</fpage>
        <lpage>3198</lpage>
        <pub-id pub-id-type="doi">10.1109/TIT.2012.2236605</pub-id>
      </element-citation>
    </ref>
    <ref id="B11-entropy-21-01074">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mohammed</surname>
            <given-names>M.H.</given-names>
          </name>
          <name>
            <surname>Dutta</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Bose</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Chadaram</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Mande</surname>
            <given-names>S.S.</given-names>
          </name>
        </person-group>
        <article-title>DELIMINATE—A fast and efficient method for loss-less compression of genomic sequences</article-title>
        <source>Bioinformatics</source>
        <year>2012</year>
        <volume>28</volume>
        <fpage>2527</fpage>
        <lpage>2529</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bts467</pub-id>
        <pub-id pub-id-type="pmid">22833526</pub-id>
      </element-citation>
    </ref>
    <ref id="B12-entropy-21-01074">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Pratas</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>MFCompress: A compression tool for fasta and multi-fasta data</article-title>
        <source>Bioinformatics</source>
        <year>2013</year>
        <volume>30</volume>
        <fpage>117</fpage>
        <lpage>118</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btt594</pub-id>
        <?supplied-pmid 24132931?>
        <pub-id pub-id-type="pmid">24132931</pub-id>
      </element-citation>
    </ref>
    <ref id="B13-entropy-21-01074">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grabowski</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Deorowicz</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Roguski</surname>
            <given-names>Ł.</given-names>
          </name>
        </person-group>
        <article-title>Disk-based compression of data from genome sequencing</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>31</volume>
        <fpage>1389</fpage>
        <lpage>1395</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu844</pub-id>
        <?supplied-pmid 25536966?>
        <pub-id pub-id-type="pmid">25536966</pub-id>
      </element-citation>
    </ref>
    <ref id="B14-entropy-21-01074">
      <label>14.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hach</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Numanagić</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Alkan</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Sahinalp</surname>
            <given-names>S.C.</given-names>
          </name>
        </person-group>
        <article-title>SCALCE: Boosting sequence compression algorithms using locally consistent encoding</article-title>
        <source>Bioinformatics</source>
        <year>2012</year>
        <volume>28</volume>
        <fpage>3051</fpage>
        <lpage>3057</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bts593</pub-id>
        <?supplied-pmid 23047557?>
        <pub-id pub-id-type="pmid">23047557</pub-id>
      </element-citation>
    </ref>
    <ref id="B15-entropy-21-01074">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Layer</surname>
            <given-names>R.M.</given-names>
          </name>
          <name>
            <surname>Kindlon</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Karczewski</surname>
            <given-names>K.J.</given-names>
          </name>
          <name>
            <surname>Consortium</surname>
            <given-names>E.A.</given-names>
          </name>
          <name>
            <surname>Quinlan</surname>
            <given-names>A.R.</given-names>
          </name>
        </person-group>
        <article-title>Efficient genotype compression and analysis of large genetic-variation data sets</article-title>
        <source>Nat. Methods</source>
        <year>2016</year>
        <volume>13</volume>
        <fpage>63</fpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.3654</pub-id>
        <pub-id pub-id-type="pmid">26550772</pub-id>
      </element-citation>
    </ref>
    <ref id="B16-entropy-21-01074">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bonfield</surname>
            <given-names>J.K.</given-names>
          </name>
          <name>
            <surname>Mahoney</surname>
            <given-names>M.V.</given-names>
          </name>
        </person-group>
        <article-title>Compression of FASTQ and SAM format sequencing data</article-title>
        <source>PLoS ONE</source>
        <year>2013</year>
        <volume>8</volume>
        <elocation-id>e59190</elocation-id>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0059190</pub-id>
        <pub-id pub-id-type="pmid">23533605</pub-id>
      </element-citation>
    </ref>
    <ref id="B17-entropy-21-01074">
      <label>17.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Bai</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Chu</surname>
            <given-names>Y.S.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zang</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>DeepDNA: A hybrid convolutional and recurrent neural network for compressing human mitochondrial genomes</article-title>
        <source>Proceedings of the 2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</source>
        <conf-loc>Madrid, Spain</conf-loc>
        <conf-date>3–6 December 2018</conf-date>
        <fpage>270</fpage>
        <lpage>274</lpage>
      </element-citation>
    </ref>
    <ref id="B18-entropy-21-01074">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Benoit</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Lemaitre</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Lavenier</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Drezen</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Dayris</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Uricaru</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Rizk</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Reference-free compression of high throughput sequencing data with a probabilistic de Bruijn graph</article-title>
        <source>BMC Bioinform.</source>
        <year>2015</year>
        <volume>16</volume>
        <elocation-id>288</elocation-id>
        <pub-id pub-id-type="doi">10.1186/s12859-015-0709-7</pub-id>
      </element-citation>
    </ref>
    <ref id="B19-entropy-21-01074">
      <label>19.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Ochoa</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Baumgarte</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Hergenrother</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Voges</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Hernaez</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>AliCo: A new efficient representation for SAM files</article-title>
        <source>Proceedings of the 2019 Data Compression Conference (DCC)</source>
        <conf-loc>Snowbird, UT, USA</conf-loc>
        <conf-date>26–29 March 2019</conf-date>
        <fpage>93</fpage>
        <lpage>102</lpage>
      </element-citation>
    </ref>
    <ref id="B20-entropy-21-01074">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Ochoa</surname>
            <given-names>I.</given-names>
          </name>
        </person-group>
        <article-title>VEF: A Variant Filtering tool based on Ensemble methods</article-title>
        <source>bioRxiv</source>
        <year>2019</year>
        <fpage>540286</fpage>
        <pub-id pub-id-type="doi">10.1101/540286</pub-id>
      </element-citation>
    </ref>
    <ref id="B21-entropy-21-01074">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chandak</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Tatwawadi</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Ochoa</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Hernaez</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Weissman</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>SPRING: A next-generation compressor for FASTQ data</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>35</volume>
        <fpage>2674</fpage>
        <lpage>2676</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty1015</pub-id>
      </element-citation>
    </ref>
    <ref id="B22-entropy-21-01074">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Holley</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Wittler</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Stoye</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Hach</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>Dynamic alignment-free and reference-free read compression</article-title>
        <source>J. Comput. Biol.</source>
        <year>2018</year>
        <volume>25</volume>
        <fpage>825</fpage>
        <lpage>836</lpage>
        <pub-id pub-id-type="doi">10.1089/cmb.2018.0068</pub-id>
        <pub-id pub-id-type="pmid">30011247</pub-id>
      </element-citation>
    </ref>
    <ref id="B23-entropy-21-01074">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kumar</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Agarwal</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>WBMFC: Efficient and Secure Storage of Genomic Data</article-title>
        <source>Pertanika J. Sci. Technol.</source>
        <year>2018</year>
        <volume>26</volume>
        <fpage>4</fpage>
      </element-citation>
    </ref>
    <ref id="B24-entropy-21-01074">
      <label>24.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="editor">
          <name>
            <surname>Dougherty</surname>
            <given-names>E.R.</given-names>
          </name>
          <name>
            <surname>Shmulevich</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z.J.</given-names>
          </name>
        </person-group>
        <source>Genomic Signal Processing and Statistics</source>
        <publisher-name>Hindawi Publishing Corporation</publisher-name>
        <publisher-loc>London, UK</publisher-loc>
        <year>2005</year>
      </element-citation>
    </ref>
    <ref id="B25-entropy-21-01074">
      <label>25.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Grumbach</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Tahi</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>Compression of DNA sequences</article-title>
        <source>Proceedings of the Data Compression Conference (DCC 1993)</source>
        <conf-loc>Snowbird, UT, USA</conf-loc>
        <conf-date>30 March–2 April 1993</conf-date>
        <fpage>340</fpage>
        <lpage>350</lpage>
      </element-citation>
    </ref>
    <ref id="B26-entropy-21-01074">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hernaez</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Pavlichin</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Weissman</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Ochoa</surname>
            <given-names>I.</given-names>
          </name>
        </person-group>
        <article-title>Genomic Data Compression</article-title>
        <source>Annu. Rev. Biomed. Data Sci.</source>
        <year>2019</year>
        <volume>2</volume>
        <fpage>19</fpage>
        <lpage>37</lpage>
        <pub-id pub-id-type="doi">10.1146/annurev-biodatasci-072018-021229</pub-id>
      </element-citation>
    </ref>
    <ref id="B27-entropy-21-01074">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rieseberg</surname>
            <given-names>L.H.</given-names>
          </name>
        </person-group>
        <article-title>Chromosomal rearrangements and speciation</article-title>
        <source>Trends Ecol. Evol.</source>
        <year>2001</year>
        <volume>16</volume>
        <fpage>351</fpage>
        <lpage>358</lpage>
        <pub-id pub-id-type="doi">10.1016/S0169-5347(01)02187-5</pub-id>
        <pub-id pub-id-type="pmid">11403867</pub-id>
      </element-citation>
    </ref>
    <ref id="B28-entropy-21-01074">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Roeder</surname>
            <given-names>G.S.</given-names>
          </name>
          <name>
            <surname>Fink</surname>
            <given-names>G.R.</given-names>
          </name>
        </person-group>
        <article-title>DNA rearrangements associated with a transposable element in yeast</article-title>
        <source>Cell</source>
        <year>1980</year>
        <volume>21</volume>
        <fpage>239</fpage>
        <lpage>249</lpage>
        <pub-id pub-id-type="doi">10.1016/0092-8674(80)90131-2</pub-id>
        <pub-id pub-id-type="pmid">6250713</pub-id>
      </element-citation>
    </ref>
    <ref id="B29-entropy-21-01074">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Harris</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Evidence for recent, population-specific evolution of the human mutation rate</article-title>
        <source>Proc. Natl. Acad. Sci. USA</source>
        <year>2015</year>
        <volume>112</volume>
        <fpage>3439</fpage>
        <lpage>3444</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1418652112</pub-id>
        <?supplied-pmid 25733855?>
        <pub-id pub-id-type="pmid">25733855</pub-id>
      </element-citation>
    </ref>
    <ref id="B30-entropy-21-01074">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jeong</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>di Rienzo</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Adaptations to local environments in modern human populations</article-title>
        <source>Curr. Opin. Genet. Dev.</source>
        <year>2014</year>
        <volume>29</volume>
        <fpage>1</fpage>
        <lpage>8</lpage>
        <pub-id pub-id-type="doi">10.1016/j.gde.2014.06.011</pub-id>
        <?supplied-pmid 25129844?>
        <pub-id pub-id-type="pmid">25129844</pub-id>
      </element-citation>
    </ref>
    <ref id="B31-entropy-21-01074">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Beres</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Kachroo</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Nasser</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Olsen</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Flores</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>de la Riva</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Paez-Mayorga</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Jimenez</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Cantu</surname>
            <given-names>C.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Transcriptome remodeling contributes to epidemic disease caused by the human pathogen <italic>Streptococcus pyogenes</italic></article-title>
        <source>mBio</source>
        <year>2016</year>
        <volume>7</volume>
        <fpage>e00403-16</fpage>
        <pub-id pub-id-type="doi">10.1128/mBio.00403-16</pub-id>
        <pub-id pub-id-type="pmid">27247229</pub-id>
      </element-citation>
    </ref>
    <ref id="B32-entropy-21-01074">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fumagalli</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Sironi</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Human genome variability, natural selection and infectious diseases</article-title>
        <source>Curr. Opin. Immunol.</source>
        <year>2014</year>
        <volume>30</volume>
        <fpage>9</fpage>
        <lpage>16</lpage>
        <pub-id pub-id-type="doi">10.1016/j.coi.2014.05.001</pub-id>
        <pub-id pub-id-type="pmid">24880709</pub-id>
      </element-citation>
    </ref>
    <ref id="B33-entropy-21-01074">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Long</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Sung</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Kucukyildirim</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Williams</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>S.F.</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Patterson</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Gregory</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Strauss</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Stone</surname>
            <given-names>C.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Evolutionary determinants of genome-wide nucleotide composition</article-title>
        <source>Nat. Ecol. Evol.</source>
        <year>2018</year>
        <volume>2</volume>
        <fpage>237</fpage>
        <pub-id pub-id-type="doi">10.1038/s41559-017-0425-y</pub-id>
        <pub-id pub-id-type="pmid">29292397</pub-id>
      </element-citation>
    </ref>
    <ref id="B34-entropy-21-01074">
      <label>34.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Golan</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <source>Foundations of Info-Metrics: Modeling and Inference with Imperfect Information</source>
        <publisher-name>Oxford University Press</publisher-name>
        <publisher-loc>Oxford, UK</publisher-loc>
        <year>2017</year>
      </element-citation>
    </ref>
    <ref id="B35-entropy-21-01074">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hosseini</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Pratas</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
        </person-group>
        <article-title>A survey on data compression methods for biological sequences</article-title>
        <source>Information</source>
        <year>2016</year>
        <volume>7</volume>
        <elocation-id>56</elocation-id>
        <pub-id pub-id-type="doi">10.3390/info7040056</pub-id>
      </element-citation>
    </ref>
    <ref id="B36-entropy-21-01074">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>A novel compression tool for efficient storage of genome resequencing data</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2011</year>
        <volume>39</volume>
        <fpage>e45</fpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkr009</pub-id>
        <pub-id pub-id-type="pmid">21266471</pub-id>
      </element-citation>
    </ref>
    <ref id="B37-entropy-21-01074">
      <label>37.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Kuruppu</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Puglisi</surname>
            <given-names>S.J.</given-names>
          </name>
          <name>
            <surname>Zobel</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Optimized relative Lempel–Ziv compression of genomes</article-title>
        <source>Proceedings of the 34th Australian Computer Science Conference (ACSC-2011)</source>
        <conf-loc>Perth, Australia</conf-loc>
        <conf-date>17–20 January 2011</conf-date>
        <volume>Volume 11</volume>
        <fpage>91</fpage>
        <lpage>98</lpage>
      </element-citation>
    </ref>
    <ref id="B38-entropy-21-01074">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tembe</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Lowey</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Suh</surname>
            <given-names>E.</given-names>
          </name>
        </person-group>
        <article-title>G-SQZ: Compact encoding of genomic sequence and quality data</article-title>
        <source>Bioinformatics</source>
        <year>2010</year>
        <volume>26</volume>
        <fpage>2192</fpage>
        <lpage>2194</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq346</pub-id>
        <?supplied-pmid 20605925?>
        <pub-id pub-id-type="pmid">20605925</pub-id>
      </element-citation>
    </ref>
    <ref id="B39-entropy-21-01074">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fritz</surname>
            <given-names>M.H.Y.</given-names>
          </name>
          <name>
            <surname>Leinonen</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Cochrane</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Birney</surname>
            <given-names>E.</given-names>
          </name>
        </person-group>
        <article-title>Efficient storage of high throughput DNA sequencing data using reference-based compression</article-title>
        <source>Genome Res.</source>
        <year>2011</year>
        <volume>21</volume>
        <fpage>734</fpage>
        <lpage>740</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.114819.110</pub-id>
        <?supplied-pmid 21245279?>
        <pub-id pub-id-type="pmid">21245279</pub-id>
      </element-citation>
    </ref>
    <ref id="B40-entropy-21-01074">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kozanitis</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Saunders</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Kruglyak</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Bafna</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Varghese</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Compressing genomic sequence fragments using SlimGene</article-title>
        <source>J. Comput. Biol.</source>
        <year>2011</year>
        <volume>18</volume>
        <fpage>401</fpage>
        <lpage>413</lpage>
        <pub-id pub-id-type="doi">10.1089/cmb.2010.0253</pub-id>
        <?supplied-pmid 21385043?>
        <pub-id pub-id-type="pmid">21385043</pub-id>
      </element-citation>
    </ref>
    <ref id="B41-entropy-21-01074">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Pratas</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Garcia</surname>
            <given-names>S.P.</given-names>
          </name>
        </person-group>
        <article-title>GReEn: A tool for efficient compression of genome resequencing data</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2012</year>
        <volume>40</volume>
        <fpage>e27</fpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkr1124</pub-id>
        <?supplied-pmid 22139935?>
        <pub-id pub-id-type="pmid">22139935</pub-id>
      </element-citation>
    </ref>
    <ref id="B42-entropy-21-01074">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wandelt</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Leser</surname>
            <given-names>U.</given-names>
          </name>
        </person-group>
        <article-title>FRESCO: Referential compression of highly similar sequences</article-title>
        <source>IEEE/ACM Trans. Comput. Biol. Bioinform.</source>
        <year>2013</year>
        <volume>10</volume>
        <fpage>1275</fpage>
        <lpage>1288</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2013.122</pub-id>
        <pub-id pub-id-type="pmid">24524158</pub-id>
      </element-citation>
    </ref>
    <ref id="B43-entropy-21-01074">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deorowicz</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Danek</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Niemiec</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>GDC 2: Compression of large collections of genomes</article-title>
        <source>Sci. Rep.</source>
        <year>2015</year>
        <volume>5</volume>
        <fpage>1</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1038/srep11565</pub-id>
      </element-citation>
    </ref>
    <ref id="B44-entropy-21-01074">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ochoa</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Hernaez</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Weissman</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>iDoComp: A compression scheme for assembled genomes</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>31</volume>
        <fpage>626</fpage>
        <lpage>633</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu698</pub-id>
        <pub-id pub-id-type="pmid">25344501</pub-id>
      </element-citation>
    </ref>
    <ref id="B45-entropy-21-01074">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Wong</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>High-speed and high-ratio referential genome compression</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>33</volume>
        <fpage>3364</fpage>
        <lpage>3372</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx412</pub-id>
        <pub-id pub-id-type="pmid">28651329</pub-id>
      </element-citation>
    </ref>
    <ref id="B46-entropy-21-01074">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shi</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Luo</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>High efficiency referential genome compression algorithm</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>35</volume>
        <fpage>2058</fpage>
        <lpage>2065</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty934</pub-id>
      </element-citation>
    </ref>
    <ref id="B47-entropy-21-01074">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Saha</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Rajasekaran</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>NRGC: A novel referential genome compression algorithm</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <fpage>3405</fpage>
        <lpage>3412</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw505</pub-id>
        <pub-id pub-id-type="pmid">27485445</pub-id>
      </element-citation>
    </ref>
    <ref id="B48-entropy-21-01074">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>TRCMGene: A two-step referential compression method for the efficient storage of genetic data</article-title>
        <source>PLoS ONE</source>
        <year>2018</year>
        <volume>13</volume>
        <elocation-id>e0206521</elocation-id>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0206521</pub-id>
        <?supplied-pmid 30395579?>
        <pub-id pub-id-type="pmid">30395579</pub-id>
      </element-citation>
    </ref>
    <ref id="B49-entropy-21-01074">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kolmogorov</surname>
            <given-names>A.N.</given-names>
          </name>
        </person-group>
        <article-title>Three approaches to the quantitative definition of information</article-title>
        <source>Probl. Inf. Transm.</source>
        <year>1965</year>
        <volume>1</volume>
        <fpage>1</fpage>
        <lpage>7</lpage>
        <pub-id pub-id-type="doi">10.1080/00207166808803030</pub-id>
      </element-citation>
    </ref>
    <ref id="B50-entropy-21-01074">
      <label>50.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Pratas</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
        </person-group>
        <article-title>On the Approximation of the Kolmogorov Complexity for DNA Sequences</article-title>
        <source>Iberian Conference on Pattern Recognition and Image Analysis</source>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>Cham, Switzerland</publisher-loc>
        <year>2017</year>
        <fpage>259</fpage>
        <lpage>266</lpage>
      </element-citation>
    </ref>
    <ref id="B51-entropy-21-01074">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Goyal</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Tatwawadi</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Chandak</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Ochoa</surname>
            <given-names>I.</given-names>
          </name>
        </person-group>
        <article-title>DeepZip: Lossless Data Compression using Recurrent Neural Networks</article-title>
        <source>arXiv</source>
        <year>2018</year>
        <pub-id pub-id-type="arxiv">1811.08162</pub-id>
      </element-citation>
    </ref>
    <ref id="B52-entropy-21-01074">
      <label>52.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ziv</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Lempel</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>A universal algorithm for sequential data compression</article-title>
        <source>IEEE Trans. Inf. Theory</source>
        <year>1977</year>
        <volume>23</volume>
        <fpage>337</fpage>
        <lpage>343</lpage>
        <pub-id pub-id-type="doi">10.1109/TIT.1977.1055714</pub-id>
      </element-citation>
    </ref>
    <ref id="B53-entropy-21-01074">
      <label>53.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grumbach</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Tahi</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>A new challenge for compression algorithms: Genetic sequences</article-title>
        <source>Inf. Process. Manag.</source>
        <year>1994</year>
        <volume>30</volume>
        <fpage>875</fpage>
        <lpage>886</lpage>
        <pub-id pub-id-type="doi">10.1016/0306-4573(94)90014-0</pub-id>
      </element-citation>
    </ref>
    <ref id="B54-entropy-21-01074">
      <label>54.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Rivals</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Delahaye</surname>
            <given-names>J.P.</given-names>
          </name>
          <name>
            <surname>Dauchet</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Delgrange</surname>
            <given-names>O.</given-names>
          </name>
        </person-group>
        <article-title>A guaranteed compression scheme for repetitive DNA sequences</article-title>
        <source>Proceedings of the Data Compression Conference (DCC ’96)</source>
        <conf-loc>Snowbird, UT, USA</conf-loc>
        <conf-date>31 March–3 April 1996</conf-date>
        <fpage>453</fpage>
      </element-citation>
    </ref>
    <ref id="B55-entropy-21-01074">
      <label>55.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Loewenstern</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Yianilos</surname>
            <given-names>P.N.</given-names>
          </name>
        </person-group>
        <article-title>Significantly lower entropy estimates for natural DNA sequences</article-title>
        <source>Proceedings of the Data Compression Conference (DCC ’97)</source>
        <conf-loc>Snowbird, UT, USA</conf-loc>
        <conf-date>25–27 March 1997</conf-date>
        <fpage>151</fpage>
        <lpage>160</lpage>
      </element-citation>
    </ref>
    <ref id="B56-entropy-21-01074">
      <label>56.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Allison</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Edgoose</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Dix</surname>
            <given-names>T.I.</given-names>
          </name>
        </person-group>
        <article-title>Compression of strings with approximate repeats</article-title>
        <source>Proceedings of the Intelligent Systems in Molecular Biology (ISMB ’98)</source>
        <conf-loc>Montréal, QC, Canada</conf-loc>
        <conf-date>28 June–1 July 1998</conf-date>
        <fpage>8</fpage>
        <lpage>16</lpage>
      </element-citation>
    </ref>
    <ref id="B57-entropy-21-01074">
      <label>57.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Apostolico</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Lonardi</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Compression of biological sequences by greedy offline textual substitution</article-title>
        <source>Proceedings of the Data Compression Conference (DCC 2000)</source>
        <conf-loc>Snowbird, UT, USA</conf-loc>
        <conf-date>28–30 March 2000</conf-date>
        <fpage>143</fpage>
        <lpage>152</lpage>
      </element-citation>
    </ref>
    <ref id="B58-entropy-21-01074">
      <label>58.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Sullivan</surname>
            <given-names>G.J.</given-names>
          </name>
          <name>
            <surname>Puri</surname>
            <given-names>A.H.</given-names>
          </name>
        </person-group>
        <article-title>263 (including H.263+) and other ITU-T video coding standards</article-title>
        <source>Multimedia Systems, Standards, and Networks</source>
        <person-group person-group-type="editor">
          <name>
            <surname>Puri</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <publisher-name>Marcel Dekker</publisher-name>
        <publisher-loc>New York, NY, USA</publisher-loc>
        <year>2000</year>
        <fpage>55</fpage>
        <lpage>85</lpage>
      </element-citation>
    </ref>
    <ref id="B59-entropy-21-01074">
      <label>59.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Tromp</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>DNACompress: Fast and effective DNA sequence compression</article-title>
        <source>Bioinformatics</source>
        <year>2002</year>
        <volume>18</volume>
        <fpage>1696</fpage>
        <lpage>1698</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/18.12.1696</pub-id>
        <pub-id pub-id-type="pmid">12490460</pub-id>
      </element-citation>
    </ref>
    <ref id="B60-entropy-21-01074">
      <label>60.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ma</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Tromp</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>PatternHunter: Faster and more sensitive homology search</article-title>
        <source>Bioinformatics</source>
        <year>2002</year>
        <volume>18</volume>
        <fpage>440</fpage>
        <lpage>445</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/18.3.440</pub-id>
        <pub-id pub-id-type="pmid">11934743</pub-id>
      </element-citation>
    </ref>
    <ref id="B61-entropy-21-01074">
      <label>61.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Matsumoto</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Sadakane</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Imai</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <article-title>Biological sequence compression algorithms</article-title>
        <source>Genome Inform.</source>
        <year>2000</year>
        <volume>11</volume>
        <fpage>43</fpage>
        <lpage>52</lpage>
      </element-citation>
    </ref>
    <ref id="B62-entropy-21-01074">
      <label>62.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Tabus</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Korodi</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Rissanen</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>DNA sequence compression using the normalized maximum likelihood model for discrete regression</article-title>
        <source>Proceedings of the Data Compression Conference (DCC 2003)</source>
        <conf-loc>Snowbird, UT, USA</conf-loc>
        <conf-date>25–27 March 2003</conf-date>
        <fpage>253</fpage>
        <lpage>262</lpage>
      </element-citation>
    </ref>
    <ref id="B63-entropy-21-01074">
      <label>63.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Korodi</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Tabus</surname>
            <given-names>I.</given-names>
          </name>
        </person-group>
        <article-title>An efficient normalized maximum likelihood algorithm for DNA sequence compression</article-title>
        <source>ACM Trans. Inf. Sys.</source>
        <year>2005</year>
        <volume>23</volume>
        <fpage>3</fpage>
        <lpage>34</lpage>
        <pub-id pub-id-type="doi">10.1145/1055709.1055711</pub-id>
      </element-citation>
    </ref>
    <ref id="B64-entropy-21-01074">
      <label>64.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Cherniavsky</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Ladner</surname>
            <given-names>R.</given-names>
          </name>
        </person-group>
        <source>Grammar-Based Compression of DNA Sequences</source>
        <comment>Technical Report</comment>
        <publisher-name>University of Washington</publisher-name>
        <publisher-loc>Seattle, WA, USA</publisher-loc>
        <year>2004</year>
      </element-citation>
    </ref>
    <ref id="B65-entropy-21-01074">
      <label>65.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Manzini</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Rastero</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>A simple and fast DNA compressor</article-title>
        <source>Softw. Pract. Exp.</source>
        <year>2004</year>
        <volume>34</volume>
        <fpage>1397</fpage>
        <lpage>1411</lpage>
        <pub-id pub-id-type="doi">10.1002/spe.619</pub-id>
      </element-citation>
    </ref>
    <ref id="B66-entropy-21-01074">
      <label>66.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>A.J.T.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <source>DNAC: An Efficient Compression Algorithm for DNA Sequences</source>
        <publisher-name>National Taiwan University</publisher-name>
        <publisher-loc>Taipei, Taiwan</publisher-loc>
        <year>2004</year>
        <volume>Volume 1</volume>
      </element-citation>
    </ref>
    <ref id="B67-entropy-21-01074">
      <label>67.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Behzadi</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Le Fessant</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>DNA compression challenge revisited</article-title>
        <source>Combinatorial Pattern Matching: Proceedings of CPM-2005</source>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>Jeju Island, Korea</publisher-loc>
        <year>2005</year>
        <volume>Volume 3537</volume>
        <fpage>190</fpage>
        <lpage>200</lpage>
      </element-citation>
    </ref>
    <ref id="B68-entropy-21-01074">
      <label>68.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Cao</surname>
            <given-names>M.D.</given-names>
          </name>
          <name>
            <surname>Dix</surname>
            <given-names>T.I.</given-names>
          </name>
          <name>
            <surname>Allison</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Mears</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>A simple statistical algorithm for biological sequence compression</article-title>
        <source>Proceedings of the 2007 Data Compression Conference (DCC ’07)</source>
        <conf-loc>Snowbird, UT, USA</conf-loc>
        <conf-date>27–29 March 2007</conf-date>
        <fpage>43</fpage>
        <lpage>52</lpage>
      </element-citation>
    </ref>
    <ref id="B69-entropy-21-01074">
      <label>69.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vey</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Differential direct coding: A compression algorithm for nucleotide sequence data</article-title>
        <source>Database</source>
        <year>2009</year>
        <volume>2009</volume>
        <pub-id pub-id-type="doi">10.1093/database/bap013</pub-id>
        <?supplied-pmid 20157486?>
        <pub-id pub-id-type="pmid">20157486</pub-id>
      </element-citation>
    </ref>
    <ref id="B70-entropy-21-01074">
      <label>70.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mishra</surname>
            <given-names>K.N.</given-names>
          </name>
          <name>
            <surname>Aaggarwal</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Abdelhadi</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Srivastava</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>An efficient horizontal and vertical method for online dna sequence compression</article-title>
        <source>Int. J. Comput. Appl.</source>
        <year>2010</year>
        <volume>3</volume>
        <fpage>39</fpage>
        <lpage>46</lpage>
        <pub-id pub-id-type="doi">10.5120/757-954</pub-id>
      </element-citation>
    </ref>
    <ref id="B71-entropy-21-01074">
      <label>71.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rajeswari</surname>
            <given-names>P.R.</given-names>
          </name>
          <name>
            <surname>Apparao</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>GENBIT Compress-Algorithm for repetitive and non repetitive DNA sequences</article-title>
        <source>Int. J. Comput. Sci. Inf. Technol.</source>
        <year>2010</year>
        <volume>2</volume>
        <fpage>25</fpage>
        <lpage>29</lpage>
      </element-citation>
    </ref>
    <ref id="B72-entropy-21-01074">
      <label>72.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gupta</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Agarwal</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>A novel approach for compressing DNA sequences using semi-statistical compressor</article-title>
        <source>Int. J. Comput. Appl.</source>
        <year>2011</year>
        <volume>33</volume>
        <fpage>245</fpage>
        <lpage>251</lpage>
        <pub-id pub-id-type="doi">10.2316/Journal.202.2011.3.202-3114</pub-id>
      </element-citation>
    </ref>
    <ref id="B73-entropy-21-01074">
      <label>73.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gupta</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Agarwal</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>A scheme that facilitates searching and partial decompression of textual documents</article-title>
        <source>Int. J. Adv. Comput. Eng.</source>
        <year>2008</year>
        <volume>1</volume>
        <fpage>99</fpage>
        <lpage>109</lpage>
      </element-citation>
    </ref>
    <ref id="B74-entropy-21-01074">
      <label>74.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhu</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Ji</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>DNA sequence compression using adaptive particle swarm optimization-based memetic algorithm</article-title>
        <source>IEEE Trans. Evol. Comput.</source>
        <year>2011</year>
        <volume>15</volume>
        <fpage>643</fpage>
        <lpage>658</lpage>
        <pub-id pub-id-type="doi">10.1109/TEVC.2011.2160399</pub-id>
      </element-citation>
    </ref>
    <ref id="B75-entropy-21-01074">
      <label>75.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Pratas</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Ferreira</surname>
            <given-names>P.J.S.G.</given-names>
          </name>
        </person-group>
        <article-title>Bacteria DNA sequence compression using a mixture of finite-context models</article-title>
        <source>Proceedings of the 2011 IEEE Statistical Signal Processing Workshop (SSP)</source>
        <conf-loc>Nice, France</conf-loc>
        <conf-date>28–30 June 2011</conf-date>
      </element-citation>
    </ref>
    <ref id="B76-entropy-21-01074">
      <label>76.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Ferreira</surname>
            <given-names>P.J.S.G.</given-names>
          </name>
          <name>
            <surname>Neves</surname>
            <given-names>A.J.R.</given-names>
          </name>
          <name>
            <surname>Bastos</surname>
            <given-names>C.A.C.</given-names>
          </name>
        </person-group>
        <article-title>On the representability of complete genomes by multiple competing finite-context (Markov) models</article-title>
        <source>PLoS ONE</source>
        <year>2011</year>
        <volume>6</volume>
        <elocation-id>e21588</elocation-id>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0021588</pub-id>
        <pub-id pub-id-type="pmid">21738720</pub-id>
      </element-citation>
    </ref>
    <ref id="B77-entropy-21-01074">
      <label>77.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Roy</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Khatua</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Roy</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Bandyopadhyay</surname>
            <given-names>S.K.</given-names>
          </name>
        </person-group>
        <article-title>An efficient biological sequence compression technique using lut and repeat in the sequence</article-title>
        <source>arXiv</source>
        <year>2012</year>
        <pub-id pub-id-type="arxiv">1209.5905</pub-id>
        <pub-id pub-id-type="doi">10.9790/0661-0614250</pub-id>
      </element-citation>
    </ref>
    <ref id="B78-entropy-21-01074">
      <label>78.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Satyanvesh</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Balleda</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Padyana</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Baruah</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>GenCodex—A Novel Algorithm for Compressing DNA sequences on Multi-cores and GPUs</article-title>
        <source>Proceedings of the IEEE 19th International Conference on High Performance Computing (HiPC)</source>
        <conf-loc>Pune, India</conf-loc>
        <conf-date>18–22 December 2012</conf-date>
      </element-citation>
    </ref>
    <ref id="B79-entropy-21-01074">
      <label>79.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bose</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Mohammed</surname>
            <given-names>M.H.</given-names>
          </name>
          <name>
            <surname>Dutta</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Mande</surname>
            <given-names>S.S.</given-names>
          </name>
        </person-group>
        <article-title>BIND—An algorithm for loss-less compression of nucleotide sequence data</article-title>
        <source>J. Biosci.</source>
        <year>2012</year>
        <volume>37</volume>
        <fpage>785</fpage>
        <lpage>789</lpage>
        <pub-id pub-id-type="doi">10.1007/s12038-012-9230-6</pub-id>
        <pub-id pub-id-type="pmid">22922203</pub-id>
      </element-citation>
    </ref>
    <ref id="B80-entropy-21-01074">
      <label>80.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Ohno-Machado</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>X.</given-names>
          </name>
        </person-group>
        <article-title>DNA-COMPACT: DNA Compression Based on a Pattern-Aware Contextual Modeling Technique</article-title>
        <source>PLoS ONE</source>
        <year>2013</year>
        <volume>8</volume>
        <elocation-id>e80377</elocation-id>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0080377</pub-id>
        <pub-id pub-id-type="pmid">24282536</pub-id>
      </element-citation>
    </ref>
    <ref id="B81-entropy-21-01074">
      <label>81.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Pratas</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
        </person-group>
        <article-title>Exploring deep Markov models in genomic data compression using sequence pre-analysis</article-title>
        <source>Proceedings of the 22th European Signal Processing Conference (EUSIPCO 2014)</source>
        <conf-loc>Lisbon, Portugal</conf-loc>
        <conf-date>1–5 September 2014</conf-date>
        <fpage>2395</fpage>
        <lpage>2399</lpage>
      </element-citation>
    </ref>
    <ref id="B82-entropy-21-01074">
      <label>82.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sardaraz</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Tahir</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Ikram</surname>
            <given-names>A.A.</given-names>
          </name>
          <name>
            <surname>Bajwa</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <article-title>SeqCompress: An algorithm for biological sequence compression</article-title>
        <source>Genomics</source>
        <year>2014</year>
        <volume>104</volume>
        <fpage>225</fpage>
        <lpage>228</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ygeno.2014.08.007</pub-id>
        <?supplied-pmid 25173568?>
        <pub-id pub-id-type="pmid">25173568</pub-id>
      </element-citation>
    </ref>
    <ref id="B83-entropy-21-01074">
      <label>83.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Guo</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Xie</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Genome compression based on Hilbert space filling curve</article-title>
        <source>Proceedings of the 3rd International Conference on Management, Education, Information and Control (MEICI 2015)</source>
        <conf-loc> Shenyang, China</conf-loc>
        <conf-date>29–31 May 2015</conf-date>
        <fpage>29</fpage>
        <lpage>31</lpage>
      </element-citation>
    </ref>
    <ref id="B84-entropy-21-01074">
      <label>84.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xie</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Guan</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>CoGI: Towards compressing genomes as an image</article-title>
        <source>IEEE/ACM Trans. Comput. Biol. Bioinform.</source>
        <year>2015</year>
        <volume>12</volume>
        <fpage>1275</fpage>
        <lpage>1285</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2015.2430331</pub-id>
        <?supplied-pmid 26671800?>
        <pub-id pub-id-type="pmid">26671800</pub-id>
      </element-citation>
    </ref>
    <ref id="B85-entropy-21-01074">
      <label>85.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mohamed</surname>
            <given-names>S.A.</given-names>
          </name>
          <name>
            <surname>Fahmy</surname>
            <given-names>M.M.</given-names>
          </name>
        </person-group>
        <article-title>Binary image compression using efficient partitioning into rectanglar regions</article-title>
        <source>IEEE Trans. Commun.</source>
        <year>1995</year>
        <volume>43</volume>
        <fpage>1888</fpage>
        <lpage>1893</lpage>
        <pub-id pub-id-type="doi">10.1109/26.387415</pub-id>
      </element-citation>
    </ref>
    <ref id="B86-entropy-21-01074">
      <label>86.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Pratas</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Ferreira</surname>
            <given-names>P.J.S.G.</given-names>
          </name>
        </person-group>
        <article-title>Efficient compression of genomic sequences</article-title>
        <source>Proceedings of the 2016 Data Compression Conference (DCC 2016)</source>
        <conf-loc>Snowbird, UT, USA</conf-loc>
        <conf-date>30 March–1 April 2016</conf-date>
        <fpage>231</fpage>
        <lpage>240</lpage>
      </element-citation>
    </ref>
    <ref id="B87-entropy-21-01074">
      <label>87.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Pratas</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Hosseini</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
        </person-group>
        <article-title>Substitutional Tolerant Markov Models for Relative Compression of DNA Sequences</article-title>
        <source>11th International Conference on Practical Applications of Computational Biology &amp; Bioinformatics</source>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>Cham, Switzerland</publisher-loc>
        <year>2017</year>
        <fpage>265</fpage>
        <lpage>272</lpage>
      </element-citation>
    </ref>
    <ref id="B88-entropy-21-01074">
      <label>88.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Pratas</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Hosseini</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
        </person-group>
        <article-title>GeCo2: An optimized tool for lossless compression and analysis of DNA sequences</article-title>
        <source>13th International Conference on Practical Applications of Computational Biology and Bioinformatics</source>
        <person-group person-group-type="editor">
          <name>
            <surname>Fdez-Riverola</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Rocha</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Mohamad</surname>
            <given-names>M.S.</given-names>
          </name>
          <name>
            <surname>Zaki</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Castellanos-Garzón</surname>
            <given-names>J.A.</given-names>
          </name>
        </person-group>
        <publisher-name>Springer International Publishing</publisher-name>
        <publisher-loc>Cham, Switzerland</publisher-loc>
        <year>2019</year>
        <fpage>137</fpage>
        <lpage>145</lpage>
      </element-citation>
    </ref>
    <ref id="B89-entropy-21-01074">
      <label>89.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Shao</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Jia</surname>
            <given-names>X.</given-names>
          </name>
        </person-group>
        <article-title>Genome sequence compression based on optimized context weighting</article-title>
        <source>Genet. Mol. Res. GMR</source>
        <year>2017</year>
        <volume>16</volume>
        <pub-id pub-id-type="doi">10.4238/gmr16026784</pub-id>
      </element-citation>
    </ref>
    <ref id="B90-entropy-21-01074">
      <label>90.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Mansouri</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>X.</given-names>
          </name>
        </person-group>
        <article-title>One-Bit DNA Compression Algorithm</article-title>
        <source>International Conference on Neural Information Processing</source>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>Berlin, Germany</publisher-loc>
        <year>2018</year>
        <fpage>378</fpage>
        <lpage>386</lpage>
      </element-citation>
    </ref>
    <ref id="B91-entropy-21-01074">
      <label>91.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Pratas</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
        </person-group>
        <article-title>A DNA Sequence Corpus for Compression Benchmark</article-title>
        <source>International Conference on Practical Applications of Computational Biology &amp; Bioinformatics</source>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>Cham, Switzerland</publisher-loc>
        <year>2018</year>
        <fpage>208</fpage>
        <lpage>215</lpage>
      </element-citation>
    </ref>
    <ref id="B92-entropy-21-01074">
      <label>92.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Sayood</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <source>Introduction to Data Compression</source>
        <publisher-name>Morgan Kaufmann</publisher-name>
        <publisher-loc>Burlington, MA, USA</publisher-loc>
        <year>2017</year>
      </element-citation>
    </ref>
    <ref id="B93-entropy-21-01074">
      <label>93.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Bell</surname>
            <given-names>T.C.</given-names>
          </name>
          <name>
            <surname>Cleary</surname>
            <given-names>J.G.</given-names>
          </name>
          <name>
            <surname>Witten</surname>
            <given-names>I.H.</given-names>
          </name>
        </person-group>
        <source>Text Compression</source>
        <publisher-name>Prentice Hall</publisher-name>
        <publisher-loc>Upper Saddle River, NJ, USA</publisher-loc>
        <year>1990</year>
      </element-citation>
    </ref>
    <ref id="B94-entropy-21-01074">
      <label>94.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Neves</surname>
            <given-names>A.J.R.</given-names>
          </name>
          <name>
            <surname>Afreixo</surname>
            <given-names>V.</given-names>
          </name>
          <name>
            <surname>Bastos</surname>
            <given-names>C.A.C.</given-names>
          </name>
          <name>
            <surname>Ferreira</surname>
            <given-names>P.J.S.G.</given-names>
          </name>
        </person-group>
        <article-title>A three-state model for DNA protein-coding regions</article-title>
        <source>IEEE Trans. Biomed. Eng.</source>
        <year>2006</year>
        <volume>53</volume>
        <fpage>2148</fpage>
        <lpage>2155</lpage>
        <pub-id pub-id-type="doi">10.1109/TBME.2006.879477</pub-id>
        <pub-id pub-id-type="pmid">17073319</pub-id>
      </element-citation>
    </ref>
    <ref id="B95-entropy-21-01074">
      <label>95.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Hosseini</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Pratas</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
        </person-group>
        <article-title>On the role of inverted repeats in DNA sequence similarity</article-title>
        <source>International Conference on Practical Applications of Computational Biology &amp; Bioinformatics</source>
        <publisher-name>Springer</publisher-name>
        <publisher-loc>Cham, Switzerland</publisher-loc>
        <year>2017</year>
        <fpage>228</fpage>
        <lpage>236</lpage>
      </element-citation>
    </ref>
    <ref id="B96-entropy-21-01074">
      <label>96.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Neves</surname>
            <given-names>A.J.R.</given-names>
          </name>
          <name>
            <surname>Martins</surname>
            <given-names>D.A.</given-names>
          </name>
          <name>
            <surname>Bastos</surname>
            <given-names>C.A.C.</given-names>
          </name>
          <name>
            <surname>Ferreira</surname>
            <given-names>P.J.S.G.</given-names>
          </name>
        </person-group>
        <article-title>Finite-context models for DNA coding</article-title>
        <source>Signal Processing</source>
        <person-group person-group-type="editor">
          <name>
            <surname>Miron</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <publisher-name>INTECH</publisher-name>
        <publisher-loc>Rijeka, Croatia</publisher-loc>
        <year>2010</year>
        <fpage>117</fpage>
        <lpage>130</lpage>
      </element-citation>
    </ref>
    <ref id="B97-entropy-21-01074">
      <label>97.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Ferreira</surname>
            <given-names>P.J.S.G.</given-names>
          </name>
          <name>
            <surname>Pinho</surname>
            <given-names>A.J.</given-names>
          </name>
        </person-group>
        <article-title>Compression-based normal similarity measures for DNA sequences</article-title>
        <source>Proceedings of the 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2014)</source>
        <conf-loc>Florence, Italy</conf-loc>
        <conf-date>4–9 May 2014</conf-date>
        <fpage>419</fpage>
        <lpage>423</lpage>
      </element-citation>
    </ref>
    <ref id="B98-entropy-21-01074">
      <label>98.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Moffat</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Neal</surname>
            <given-names>R.M.</given-names>
          </name>
          <name>
            <surname>Witten</surname>
            <given-names>I.H.</given-names>
          </name>
        </person-group>
        <article-title>Arithmetic coding revisited</article-title>
        <source>ACM Trans. Inf. Syst.</source>
        <year>1998</year>
        <volume>16</volume>
        <fpage>256</fpage>
        <lpage>294</lpage>
        <pub-id pub-id-type="doi">10.1145/290159.290162</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig id="entropy-21-01074-f001" orientation="portrait" position="float">
    <label>Figure 1</label>
    <caption>
      <p>Timeline with the names of the proposed data compressors specifically for genomic sequences.</p>
    </caption>
    <graphic xlink:href="entropy-21-01074-g001"/>
  </fig>
  <fig id="entropy-21-01074-f002" orientation="portrait" position="float">
    <label>Figure 2</label>
    <caption>
      <p>An architecture example of a competitive prediction between five Weighted context models (at left, represented with prefix <italic>C</italic>) and three Weighted stochastic repeat models (at right, represented with prefix <italic>R</italic>). Each model has a weight (<italic>W</italic>) and associated probabilities (<italic>P</italic>) that are calculated according to the respective memory model (<italic>M</italic>), where the suffix complements the notation. The tolerant context model (<inline-formula><mml:math id="mm37"><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>W</mml:mi><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mi>P</mml:mi><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) uses the same memory of model four (<inline-formula><mml:math id="mm38"><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>W</mml:mi><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mi>P</mml:mi><mml:mn>4</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>), since they have the same context. Independently, the probabilities of the context models and repeat models are averaged according to the respective weight and redirected to the competitive prediction model. Finally, the probabilities of the model class with the highest probability (predicted) are redirected to the arithmetic encoder.</p>
    </caption>
    <graphic xlink:href="entropy-21-01074-g002"/>
  </fig>
  <fig id="entropy-21-01074-f003" orientation="portrait" position="float">
    <label>Figure 3</label>
    <caption>
      <p>Repeat model example with <italic>k</italic>-mer size of 8. The <italic>H</italic> is a hash function that encapsulates a <italic>k</italic>-mer into a natural number on the hash table. Positions 14,251 and 14,275 stand for identical <italic>k</italic>-mers seen in the past of the sequence. Number 14,295 stands for the current position of the base being coded.</p>
    </caption>
    <graphic xlink:href="entropy-21-01074-g003"/>
  </fig>
  <fig id="entropy-21-01074-f004" orientation="portrait" position="float">
    <label>Figure 4</label>
    <caption>
      <p>Competitive prediction context model (CPCM) example with context depth (<italic>k</italic>) of 5. The next symbol is <italic>S</italic>, and <italic>Z</italic> is the sequence with the best class of models estimated by the CPCM.</p>
    </caption>
    <graphic xlink:href="entropy-21-01074-g004"/>
  </fig>
  <fig id="entropy-21-01074-f005" orientation="portrait" position="float">
    <label>Figure 5</label>
    <caption>
      <p>Bits per base (BPS) of compressing four sequences applying a CPCM context order variation for the first twelve modes of Jarvis. The four datasets are sorted according to different sizes; namely, the largest is HoSa (<bold>left</bold>-<bold>top</bold>), then, EnIn (<bold>right</bold>-<bold>top</bold>), AeCa (<bold>left</bold>-<bold>bottom</bold>), and YeMi (<bold>right</bold>-<bold>bottom</bold>).</p>
    </caption>
    <graphic xlink:href="entropy-21-01074-g005"/>
  </fig>
  <fig id="entropy-21-01074-f006" orientation="portrait" position="float">
    <label>Figure 6</label>
    <caption>
      <p>Benchmark with size (<bold>a</bold>) and speed (<bold>b</bold>). For each sequence, the value of speed is calculated as compressed size (KB) divided by compression time (s). The mean of speed values for all datasets is calculated to obtain the average speed for each method. The CoGI compressor is not included because it is an outlier concerning this dataset.</p>
    </caption>
    <graphic xlink:href="entropy-21-01074-g006"/>
  </fig>
  <fig id="entropy-21-01074-f007" orientation="portrait" position="float">
    <label>Figure 7</label>
    <caption>
      <p>Comparison of the fifteen compression modes available in Jarvis for the three largest sequences in the dataset (HoSa, GaGa, and DaRe). Compression ratios are in Bits Per Symbol (BPS) and Time in seconds. Times may not agree precisely with <xref rid="entropy-21-01074-t002" ref-type="table">Table 2</xref> because we rerun the tool. Each number, corresponding to the blue dots, stands for the mode/level used in Jarvis. We recall that additional levels or specific configurations can be set.</p>
    </caption>
    <graphic xlink:href="entropy-21-01074-g007"/>
  </fig>
  <fig id="entropy-21-01074-f008" orientation="portrait" position="float">
    <label>Figure 8</label>
    <caption>
      <p>Comparison of the fifteen compression modes available in Jarvis and GeCo2 for the human chromosome Y sequence. Compression ratios are in Bits Per Symbol (BPS) and Time in seconds. Each number, corresponding to the blue dots, stands for the mode/level used in the respective compressor.</p>
    </caption>
    <graphic xlink:href="entropy-21-01074-g008"/>
  </fig>
  <table-wrap id="entropy-21-01074-t001" orientation="portrait" position="float">
    <object-id pub-id-type="pii">entropy-21-01074-t001_Table 1</object-id>
    <label>Table 1</label>
    <caption>
      <p>Number of bytes needed to represent each DNA sequence given the respective data compressor (LZMA -9, PAQ8 -8, CoGi, GeCo, XM and Jarvis). We ran LZMA with the -9 flag (best option), PAQ8 with the -8 (best option), GeCo using “-tm 1:1:0:0/0 -tm 3:1:0:0/0 -tm 6:1:0:0/0 -tm 9:10:0:0/0 -tm 11:10:0:0/0 -tm 13:50:1:0/0 -tm 18:100:1:3/10 -c 30 -g 0.9”, GeCo2 with parameters from [<xref rid="B88-entropy-21-01074" ref-type="bibr">88</xref>], and XM using 50 copy experts. The compression level used in Jarvis is depicted between parentheses, and it has been set according to the size of the sequence. The length of the sequences is present in <xref rid="entropy-21-01074-t002" ref-type="table">Table 2</xref>.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">ID</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LZMA-9</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">PAQ8-8</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">CoGI</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">GeCo</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">GeCo2</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">XM</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Jarvis (level)</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">HoSa</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">42,292,440</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">40,517,624</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">51,967,817</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">38,877,294</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">38,845,642</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">38,940,458</td>
          <td align="center" valign="middle" rowspan="1" colspan="1"><underline><bold>38,660,851</bold></underline> (7)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">GaGa</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">36,179,650</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">34,490,967</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">40,846,177</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">33,925,250</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">33,877,671</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">33,879,211</td>
          <td align="center" valign="middle" rowspan="1" colspan="1"><underline><bold>33,699,821</bold></underline> (6)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">DaRe</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">12,515,717</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">12,628,104</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">17,084,450</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">11,520,064</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">11,488,819</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">11,302,620</td>
          <td align="center" valign="middle" rowspan="1" colspan="1"><underline><bold>11,173,905</bold></underline> (5)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">OrSa</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">9,348,183</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">9,280,037</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">11,999,580</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">8,671,732</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">8,646,543</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">8,470,212</td>
          <td align="center" valign="middle" rowspan="1" colspan="1"><underline><bold>8,448,959</bold></underline> (5)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">DrMe</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">8,016,544</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">7,577,068</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">8,939,690</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">7,498,808</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
            <underline>
              <bold>7,481,093</bold>
            </underline>
          </td>
          <td align="center" valign="middle" rowspan="1" colspan="1">7,538,662</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">7,490,418 (5)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">EnIn</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5,785,343</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5,761,090</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">7,210,867</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5,196,083</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5,170,889</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5,150,309</td>
          <td align="center" valign="middle" rowspan="1" colspan="1"><underline><bold>5,087,286</bold></underline> (4)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">ScPo</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">2,722,233</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">2,557,988</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">2,921,247</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">2,536,457</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">2,518,963</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">2,524,147</td>
          <td align="center" valign="middle" rowspan="1" colspan="1"><underline><bold>2,517,535</bold></underline> (4)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">PlFa</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">2,097,979</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1,959,623</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">2,411,342</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1,944,036</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1,925,726</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1,925,841</td>
          <td align="center" valign="middle" rowspan="1" colspan="1"><underline><bold>1,924,430</bold></underline> (4)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">EsCo</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1,185,704</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1,107,929</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1,307,943</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1,109,823</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1,098,552</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1,110,092</td>
          <td align="center" valign="middle" rowspan="1" colspan="1"><underline><bold>1,095,606</bold></underline> (4)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">HaHi</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">985,096</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">904,074</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1,124,483</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">906,991</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">902,831</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">913,346</td>
          <td align="center" valign="middle" rowspan="1" colspan="1"><underline><bold>899,464</bold></underline> (3)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">AeCa</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">413,886</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">380,273</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">454,357</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">385,640</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
            <underline>
              <bold>380,115</bold>
            </underline>
          </td>
          <td align="center" valign="middle" rowspan="1" colspan="1">387,030</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">380,507 (3)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">HePy</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">415,161</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">385,096</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">457,859</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">381,545</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">375,481</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">384,071</td>
          <td align="center" valign="middle" rowspan="1" colspan="1"><underline><bold>374,362</bold></underline> (3)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">YeMi</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">19,262</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">16,835</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">19,805</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">17,167</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
            <underline>
              <bold>16,798</bold>
            </underline>
          </td>
          <td align="center" valign="middle" rowspan="1" colspan="1">16,861</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">16,861 (2)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">AgPh</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">12,183</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">10,754</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">12,243</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">10,882</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">
            <underline>
              <bold>10,708</bold>
            </underline>
          </td>
          <td align="center" valign="middle" rowspan="1" colspan="1">10,711</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">10,745 (2)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-bottom:solid thin;border-right: dotted thin" rowspan="1" colspan="1">BuEb</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5441</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4668</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5291</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4774</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4686</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
            <underline>
              <bold>4642</bold>
            </underline>
          </td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">4690 (1)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-bottom:solid thin;border-right: dotted thin" rowspan="1" colspan="1">Total</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">121,994,822</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">117,582,130</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">146,763,151</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">112,986,546</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">112,744,517</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">112,558,213</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
            <underline>
              <bold>111,785,440</bold>
            </underline>
          </td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap id="entropy-21-01074-t002" orientation="portrait" position="float">
    <object-id pub-id-type="pii">entropy-21-01074-t002_Table 2</object-id>
    <label>Table 2</label>
    <caption>
      <p>Computational time (in seconds) needed to represent each DNA sequence given the respective data compressor (LZMA, PAQ8, CoGi, GeCo, GeCo2, XM, and Jarvis). We ran LZMA with the -9 flag (best option), PAQ8 with the -8 (best option), GeCo using “-tm 1:1:0:0/0 -tm 3:1:0:0/0 -tm 6:1:0:0/0 -tm 9:10:0:0/0 -tm 11:10:0:0/0 -tm 13:50:1:0/0 -tm 18:100:1:3/10 -c 30 -g 0.9”, GeCo2 with parameters from [<xref rid="B88-entropy-21-01074" ref-type="bibr">88</xref>], and XM using 50 copy experts. The compression level used in Jarvis is depicted between parentheses and it has been set according to the size of the sequence. The length scale of the sequences is in bases.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">ID</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Length</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">LZMA</th>
          <th align="right" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">PAQ8</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">CoGI</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">GeCo</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">GeCo2</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">XM</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Jarvis</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">HoSa</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">189,752,667</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">552.5</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">85,269.1</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">25.2</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">648.6</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">652.4</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5,589.8</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">814.8 (7)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">GaGa</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">148,532,294</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">468.7</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">64,898.9</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">19.9</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">503.2</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">494.7</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">3,633.9</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">412.3 (6)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">DaRe</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">62,565,020</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">170.0</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">29,907.7</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">8.2</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">215.9</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">198.8</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">785.2</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">284.9 (5)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">OrSa</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">43,262,523</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">112.9</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">20,745.1</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.8</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">192.4</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">138.3</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">489.7</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">234.5 (5)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">DrMe</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">32,181,429</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">85.6</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">14,665.8</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">4.3</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">114.6</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">102.4</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">362.6</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">66.7 (5)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">EnIn</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">26,403,087</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">66.0</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">11,183.6</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">3.7</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">95.8</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">82.5</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">279.8</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">101.1 (4)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">ScPo</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">10,652,155</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">23.0</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">4,619.1</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1.5</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">45.2</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">34.2</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">96.5</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">28.7 (4)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">PlFa</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">8,986,712</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">18.3</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">4,133.9</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1.2</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">39.7</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">35.3</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">84.4</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">25.4 (4)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">EsCo</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">4,641,652</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">8.1</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">1,973.9</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.6</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">26.4</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">5.1</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">36.8</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">10.9 (4)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">HaHi</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">3,890,005</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">6.9</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">1,738.1</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.5</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">23.7</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">4.4</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">39.1</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">7.1 (3)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">AeCa</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">1,591,049</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">2.2</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">675.3</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.2</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">17.0</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1.9</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">10.3</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">2.2 (3)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">HePy</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">1,667,825</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">2.3</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">715.1</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.2</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">17.2</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">1.9</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">11.2</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">2.7 (3)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">YeMi</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">73,689</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.1</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">32.6</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">12.3</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.1</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.9</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.2 (2)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">AgPh</td>
          <td align="right" valign="middle" style="border-right: dotted thin" rowspan="1" colspan="1">43,970</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">20.1</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.0</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">12.1</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.1</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.9</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">0.1 (2)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-bottom:solid thin;border-right: dotted thin" rowspan="1" colspan="1">BuEb</td>
          <td align="right" valign="middle" style="border-bottom:solid thin;border-right: dotted thin" rowspan="1" colspan="1">18,940</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0</td>
          <td align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">9.1</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.0</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">12.2</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.1</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.7</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.1 (1)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-bottom:solid thin;border-right: dotted thin" rowspan="1" colspan="1">Total</td>
          <td align="right" valign="middle" style="border-bottom:solid thin;border-right: dotted thin" rowspan="1" colspan="1">534,263,017</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1516.6</td>
          <td align="right" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">240,587.4</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">71.3</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1976.3</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1742.2</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11,421.8</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1991.7</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</floats-group>
