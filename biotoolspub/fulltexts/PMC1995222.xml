<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Syst Biol</journal-id>
    <journal-title>BMC Systems Biology</journal-title>
    <issn pub-type="epub">1752-0509</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">1995222</article-id>
    <article-id pub-id-type="publisher-id">1752-0509-1-37</article-id>
    <article-id pub-id-type="pmid">17683609</article-id>
    <article-id pub-id-type="doi">10.1186/1752-0509-1-37</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Methodology Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>From correlation to causation networks: a simple approximate learning algorithm and its application to high-dimensional plant gene expression data</article-title>
    </title-group>
    <contrib-group>
      <contrib id="A1" corresp="yes" contrib-type="author">
        <name>
          <surname>Opgen-Rhein</surname>
          <given-names>Rainer</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <email>opgen-rhein@stat.uni-muenchen.de</email>
      </contrib>
      <contrib id="A2" contrib-type="author">
        <name>
          <surname>Strimmer</surname>
          <given-names>Korbinian</given-names>
        </name>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>strimmer@uni-leipzig.de</email>
      </contrib>
    </contrib-group>
    <aff id="I1"><label>1</label>Department of Statistics, Ludwig-Maximilians-Universität München, Ludwigstraße 33, D-80539 München, Germany</aff>
    <aff id="I2"><label>2</label>Institute for Medical Informatics, Statistics and Epidemiology (IMISE), University of Leipzig, Härtelstr. 16-18, 04107 Leipzig, Germany</aff>
    <pub-date pub-type="collection">
      <year>2007</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>6</day>
      <month>8</month>
      <year>2007</year>
    </pub-date>
    <volume>1</volume>
    <fpage>37</fpage>
    <lpage>37</lpage>
    <ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1752-0509/1/37"/>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>5</month>
        <year>2007</year>
      </date>
      <date date-type="accepted">
        <day>6</day>
        <month>8</month>
        <year>2007</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2007 Opgen-Rhein and Strimmer; licensee BioMed Central Ltd.</copyright-statement>
      <copyright-year>2007</copyright-year>
      <copyright-holder>Opgen-Rhein and Strimmer; licensee BioMed Central Ltd.</copyright-holder>
      <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0">
        <p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0"/>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</p>
        <!--<rdf xmlns="http://web.resource.org/cc/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1" xmlns:dcterms="http://purl.org/dc/terms"><Work xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" rdf:about=""><license rdf:resource="http://creativecommons.org/licenses/by/2.0"/><dc:type rdf:resource="http://purl.org/dc/dcmitype/Text"/><dc:author>
               Opgen-Rhein
               Rainer
               
               opgen-rhein@stat.uni-muenchen.de
            </dc:author><dc:title>
            From correlation to causation networks: a simple approximate learning algorithm and its application to high-dimensional plant gene expression data
         </dc:title><dc:date>2007</dc:date><dcterms:bibliographicCitation>BMC Systems Biology 1(1): 37-. (2007)</dcterms:bibliographicCitation><dc:identifier type="sici">1752-0509(2007)1:1&#x0003c;37&#x0003e;</dc:identifier><dcterms:isPartOf>urn:ISSN:1752-0509</dcterms:isPartOf><License rdf:about="http://creativecommons.org/licenses/by/2.0"><permits rdf:resource="http://web.resource.org/cc/Reproduction" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/Distribution" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Notice" xmlns=""/><requires rdf:resource="http://web.resource.org/cc/Attribution" xmlns=""/><permits rdf:resource="http://web.resource.org/cc/DerivativeWorks" xmlns=""/></License></Work></rdf>-->
      </license>
    </permissions>
    <abstract>
      <sec>
        <title>Background</title>
        <p>The use of correlation networks is widespread in the analysis of gene expression and proteomics data, even though it is known that correlations not only confound direct and indirect associations but also provide no means to distinguish between cause and effect. For "causal" analysis typically the inference of a directed graphical model is required. However, this is rather difficult due to the curse of dimensionality.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>We propose a simple heuristic for the statistical learning of a high-dimensional "causal" network. The method first converts a correlation network into a partial correlation graph. Subsequently, a partial ordering of the nodes is established by multiple testing of the log-ratio of standardized partial variances. This allows identifying a directed acyclic causal network as a subgraph of the partial correlation network. We illustrate the approach by analyzing a large <italic>Arabidopsis thaliana </italic>expression data set.</p>
      </sec>
      <sec>
        <title>Conclusion</title>
        <p>The proposed approach is a heuristic algorithm that is based on a number of approximations, such as substituting lower order partial correlations by full order partial correlations. Nevertheless, for small samples and for sparse networks the algorithm not only yield sensible first order approximations of the causal structure in high-dimensional genomic data but is also computationally highly efficient.</p>
      </sec>
      <sec>
        <title>Availability and Requirements</title>
        <p>The method is implemented in the "GeneNet" R package (version 1.2.0), available from CRAN and from <ext-link ext-link-type="uri" xlink:href="http://strimmerlab.org/software/genets/"/>. The software includes an R script for reproducing the network analysis of the <italic>Arabidopsis thaliana </italic>data.</p>
      </sec>
    </abstract>
  </article-meta>
</front>
<body>
  <sec>
    <title>Background</title>
    <p>Correlation networks are widely used to explore and visualize high-dimensional data, for instance in finance [<xref ref-type="bibr" rid="B1">1</xref>-<xref ref-type="bibr" rid="B3">3</xref>], ecology [<xref ref-type="bibr" rid="B4">4</xref>], gene expression analysis [<xref ref-type="bibr" rid="B5">5</xref>,<xref ref-type="bibr" rid="B6">6</xref>], or metabolomics [<xref ref-type="bibr" rid="B7">7</xref>]. Their popularity is owed to a large extent to the ease with which a correlation network can be constructed, as this requires only two simple steps: i) the computation of all pairwise correlations for the investigated variables, and ii) a thresholding or filtering procedure [<xref ref-type="bibr" rid="B8">8</xref>] to identify significant correlations, and hence edges, of the network.</p>
    <p>However, for shedding light on the causal processes underlying the observed data, correlation networks are only of limited use. This is due to the fact that correlations not only confound direct and indirect associations but also provide no means to distinguish between response variables and covariates (and thus between cause and effect).</p>
    <p>Therefore, causal analysis requires tools different from correlation networks: much of the work in this area has focused on Bayesian networks [<xref ref-type="bibr" rid="B9">9</xref>] or related regression models such as systems of recursive equations [<xref ref-type="bibr" rid="B10">10</xref>,<xref ref-type="bibr" rid="B11">11</xref>] or influence diagrams [<xref ref-type="bibr" rid="B12">12</xref>]. All of these models have in common that they describe causal relations by an underlying directed acyclic graph (DAG).</p>
    <p>There already exist numerous methods for learning DAGs from observational data – see for instance the summarizing review in [<xref ref-type="bibr" rid="B13">13</xref>] and the references therein. However, with few exceptions [e.g., the PC algorithm, [<xref ref-type="bibr" rid="B14">14</xref>,<xref ref-type="bibr" rid="B15">15</xref>]] virtually all of these methods have been devised for comparatively small numbers of variables and with large sample size in mind. For instance, the numerical example of the recently proposed algorithm described in [<xref ref-type="bibr" rid="B16">16</xref>] uses <italic>n </italic>= 10,000 observations for <italic>p </italic>= 7 variables. Unfortunately, the data that would be most interesting to explore with causal methods, namely those commonly visualized by correlation networks (see above), have completely different characteristics, in particular they are likely of high dimension.</p>
    <p>In this paper we follow [<xref ref-type="bibr" rid="B15">15</xref>] and focus on modeling large-scale linear recursive systems. Specifically, we present a simple discovery algorithm that enables the inference of causal relations from small sampled data and for large numbers of variables. It proceeds in two steps as follows:</p>
    <p>• First, the correlation network is transformed into a partial correlation network, which is essentially an undirected graph that displays the direct linear associations only. This type of network model is also known under the names of graphical Gaussian model (GGM), concentration graph, covariance selection graph, conditional independence graph (CIG), or Markov random field. Note that there is a simple relationship between correlation and partial correlation. Moreover, in recent years there has been much progress with regard to statistical methodology for learning large-scale partial correlation graphs from small samples [e.g., [<xref ref-type="bibr" rid="B17">17</xref>-<xref ref-type="bibr" rid="B22">22</xref>]]. Here we employ the approach described in [<xref ref-type="bibr" rid="B20">20</xref>].</p>
    <p>• Second, the undirected GGM is converted into a <italic>partially </italic>directed graph. This is done by estimating a pairwise ordering of the nodes from the data using multiple testing of the log-ratios of standardized partial variances, and by subsequent projection of this partial ordering onto the GGM. The inferred causal network is the subgraph containing all the directed edges.</p>
    <p>Note that this algorithm is similar to the PC algorithm in that edges are being removed from the independence graph to obtain the underlying DAG. However, our criterion for eliminating an edge is distinctly different from that of the PC algorithm.</p>
    <p>The remainder of the paper is organized as follows. First, we describe the methodology. Second we consider its statistical interpretation and further properties. Subsequently, we illustrate the approach by analyzing an 800 gene data set from a large-scale <italic>Arabidopsis thaliana </italic>gene expression experiment. Finally, we conclude with some discussion of the method, commenting also on the limitations of the approach.</p>
  </sec>
  <sec sec-type="methods">
    <title>Methods</title>
    <sec>
      <title>Theoretical basis</title>
      <p>Consider a linear regression with <italic>Y </italic>as response and <italic>X</italic><sub>1</sub>, ..., <italic>X</italic><sub><italic>k</italic></sub>, ..., <italic>X</italic><sub><italic>K </italic></sub>as covariates. We assume that <italic>X</italic><sub><italic>k </italic></sub>and <italic>Y </italic>are random variables with known variances var(<italic>Y</italic>) and var(<italic>X</italic><sub><italic>k</italic></sub>) and with covariance cov(<italic>Y</italic>, <italic>X</italic><sub><italic>k</italic></sub>). The best linear predictor of <italic>Y </italic>in terms of the <italic>X</italic><sub><italic>k </italic></sub>that minimizes the MSE of 
∑<sub><italic>k </italic></sub><italic>β</italic><sub><italic>k</italic></sub><italic>X</italic><sub><italic>k </italic></sub>- <italic>Y </italic>is given by [e.g. ref. [<xref ref-type="bibr" rid="B23">23</xref>], p. 206]</p>
      <p>
        <disp-formula id="bmcM1">
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M1" name="1752-0509-1-37-i1" overflow="scroll">
            <mml:semantics definitionURL="" encoding="">
              <mml:mrow>
                <mml:msubsup>
                  <mml:mi>β</mml:mi>
                  <mml:mi>k</mml:mi>
                  <mml:mi>y</mml:mi>
                </mml:msubsup>
                <mml:mo>=</mml:mo>
                <mml:msub>
                  <mml:mover accent="true">
                    <mml:mi>ρ</mml:mi>
                    <mml:mo>˜</mml:mo>
                  </mml:mover>
                  <mml:mrow>
                    <mml:mi>y</mml:mi>
                    <mml:mi>k</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:msqrt>
                  <mml:mrow>
                    <mml:mfrac>
                      <mml:mrow>
                        <mml:msubsup>
                          <mml:mover accent="true">
                            <mml:mi>σ</mml:mi>
                            <mml:mo>˜</mml:mo>
                          </mml:mover>
                          <mml:mi>y</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msubsup>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msubsup>
                          <mml:mover accent="true">
                            <mml:mi>σ</mml:mi>
                            <mml:mo>˜</mml:mo>
                          </mml:mover>
                          <mml:mi>k</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msubsup>
                      </mml:mrow>
                    </mml:mfrac>
                  </mml:mrow>
                </mml:msqrt>
                <mml:mo>,</mml:mo>
              </mml:mrow>
              <mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacqWFYoGydaqhaaWcbaGaem4AaSgabaGaemyEaKhaaOGaeyypa0Jaf8xWdiNbaGaadaWgaaWcbaGaemyEaKNaem4AaSgabeaakmaakaaabaWaaSaaaeaacuWFdpWCgaacamaaDaaaleaacqWG5bqEaeaacqaIYaGmaaaakeaacuWFdpWCgaacamaaDaaaleaacqWGRbWAaeaacqaIYaGmaaaaaaqabaGccqGGSaalaaa@410B@</mml:annotation>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>where <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M2" name="1752-0509-1-37-i2" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacuWFbpGCgaacamaaBaaaleaacqWG5bqEcqWGRbWAaeqaaaaa@3188@</mml:annotation></mml:semantics></mml:math></inline-formula> and is the <italic>partial </italic>correlation between <italic>Y </italic>and <italic>X</italic><sub><italic>k</italic></sub>, and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M3" name="1752-0509-1-37-i3" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacuWFdpWCgaacamaaDaaaleaacqWG5bqEaeaacqaIYaGmaaaaaa@311F@</mml:annotation></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M4" name="1752-0509-1-37-i4" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacuWFdpWCgaacamaaDaaaleaacqWGRbWAaeaacqaIYaGmaaaaaa@3103@</mml:annotation></mml:semantics></mml:math></inline-formula> are the respective <italic>partial </italic>variances. </p>
      <p>The partial correlation is the correlation that remains between two variables if the effect of the other variables has been regressed away. Likewise, the partial variance is the variance that remains if the influences of all other variables are taken into account. Table <xref ref-type="table" rid="T1">1</xref> lists the definitions and formulas for the computation of these quantities (note that in our notation a tilde on top of a symbol indicates ''partial'').</p>
      <table-wrap position="float" id="T1">
        <label>Table 1</label>
        <caption>
          <p>Formulas for computing partial variances and partial correlations</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <td/>
              <td align="left">Definition</td>
              <td align="left">True value</td>
              <td align="left">Estimate</td>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left">Covariance matrix:</td>
              <td align="left">cov(<italic>X</italic><sub><italic>k</italic></sub>, <italic>X</italic><sub><italic>l</italic></sub>) = <italic>σ</italic><sub><italic>kl</italic></sub></td>
              <td align="left"><bold>Σ </bold>= (<italic>σ</italic><sub><italic>kl</italic></sub>)</td>
              <td align="left"><bold><italic>S </italic></bold>= (<italic>s</italic><sub><italic>kl</italic></sub>)</td>
            </tr>
            <tr>
              <td align="left">Concentration matrix:</td>
              <td align="left"><bold>Ω </bold>= <bold>Σ</bold><sup>-1</sup></td>
              <td align="left"><bold>Ω </bold>= (<italic>ω</italic><sub><italic>kl</italic></sub>)</td>
              <td/>
            </tr>
            <tr>
              <td align="left">Variances:</td>
              <td align="left">var(<italic>X</italic><sub><italic>k</italic></sub>) = <italic>σ</italic><sub><italic>kk </italic></sub>= <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M5" name="1752-0509-1-37-i5" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacqWFdpWCdaqhaaWcbaGaem4AaSgabaGaeGOmaidaaaaa@30F4@</mml:annotation></mml:semantics></mml:math></inline-formula></td>
              <td align="left">
                <italic>σ</italic>
                <sub>
                  <italic>kk</italic>
                </sub>
              </td>
              <td align="left">
                <italic>s</italic>
                <sub>
                  <italic>kk</italic>
                </sub>
              </td>
            </tr>
            <tr>
              <td align="left">Partial variances</td>
              <td align="left">var(<italic>X</italic><sub><italic>k</italic></sub>|<italic>X</italic><sub>≠<italic>k</italic></sub>) = <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M6" name="1752-0509-1-37-i6" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacuWFdpWCgaacamaaBaaaleaacqWGRbWAcqWGRbWAaeqaaaaa@316F@</mml:annotation></mml:semantics></mml:math></inline-formula> = <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M7" name="1752-0509-1-37-i4" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacuWFdpWCgaacamaaDaaaleaacqWGRbWAaeaacqaIYaGmaaaaaa@3103@</mml:annotation></mml:semantics></mml:math></inline-formula> = <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M8" name="1752-0509-1-37-i7" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msubsup><mml:mi>ω</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacqWFjpWDdaqhaaWcbaGaem4AaSMaem4AaSgabaGaeyOeI0IaeGymaedaaaaa@3348@</mml:annotation></mml:semantics></mml:math></inline-formula></td>
              <td align="left">
                <inline-formula>
                  <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M9" name="1752-0509-1-37-i6" overflow="scroll">
                    <mml:semantics definitionURL="" encoding="">
                      <mml:mrow>
                        <mml:msub>
                          <mml:mover accent="true">
                            <mml:mi>σ</mml:mi>
                            <mml:mo>˜</mml:mo>
                          </mml:mover>
                          <mml:mrow>
                            <mml:mi>k</mml:mi>
                            <mml:mi>k</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                      <mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacuWFdpWCgaacamaaBaaaleaacqWGRbWAcqWGRbWAaeqaaaaa@316F@</mml:annotation>
                    </mml:semantics>
                  </mml:math>
                </inline-formula>
              </td>
              <td align="left">
                <inline-formula>
                  <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M10" name="1752-0509-1-37-i8" overflow="scroll">
                    <mml:semantics definitionURL="" encoding="">
                      <mml:mrow>
                        <mml:msub>
                          <mml:mover accent="true">
                            <mml:mi>s</mml:mi>
                            <mml:mo>˜</mml:mo>
                          </mml:mover>
                          <mml:mrow>
                            <mml:mi>k</mml:mi>
                            <mml:mi>k</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                      <mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaacuWGZbWCgaacamaaBaaaleaacqWGRbWAcqWGRbWAaeqaaaaa@3114@</mml:annotation>
                    </mml:semantics>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
            <tr>
              <td align="left">Correlations:</td>
              <td align="left">corr(<italic>X</italic><sub><italic>k</italic></sub>, <italic>X</italic><sub><italic>l</italic></sub>) = <italic>ρ</italic><sub><italic>kl </italic></sub>= <italic>σ</italic><sub><italic>kl </italic></sub>(<italic>σ</italic><sub><italic>kk </italic></sub><italic>σ</italic><sub><italic>ll</italic></sub>)<sup>-1/2</sup></td>
              <td align="left"><bold><italic>P </italic></bold>= (<italic>ρ</italic><sub><italic>kl</italic></sub>)</td>
              <td align="left"><bold><italic>R </italic></bold>= (<italic>r</italic><sub><italic>kl</italic></sub>)</td>
            </tr>
            <tr>
              <td align="left">Partial correlations:</td>
              <td align="left">corr(<italic>X</italic><sub><italic>k</italic></sub>, <italic>X</italic><sub><italic>l</italic></sub>|<italic>X</italic><sub>≠<italic>k</italic>, <italic>l</italic></sub>) = <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M11" name="1752-0509-1-37-i9" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ω</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacuWFbpGCgaacamaaBaaaleaacqWGRbWAcqWGSbaBaeqaaOGaeyypa0JaeyOeI0Iae8xYdC3aaSbaaSqaaiabdUgaRjabdYgaSbqabaGccqGGOaakcqWFjpWDdaWgaaWcbaGaem4AaSMaem4AaSgabeaakiab=L8a3naaBaaaleaacqWGSbaBcqWGSbaBaeqaaOGaeiykaKYaaWbaaSqabeaacqGHsislcqaIXaqmcqGGVaWlcqaIYaGmaaaaaa@4739@</mml:annotation></mml:semantics></mml:math></inline-formula></td>
              <td align="left">
                <inline-formula>
                  <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M12" name="1752-0509-1-37-i10" overflow="scroll">
                    <mml:semantics definitionURL="" encoding="">
                      <mml:mrow>
                        <mml:mover accent="true">
                          <mml:mi>P</mml:mi>
                          <mml:mo>˜</mml:mo>
                        </mml:mover>
                        <mml:mo>=</mml:mo>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mover accent="true">
                                <mml:mi>ρ</mml:mi>
                                <mml:mo>˜</mml:mo>
                              </mml:mover>
                              <mml:mrow>
                                <mml:mi>k</mml:mi>
                                <mml:mi>l</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mrow>
                          <mml:mo>)</mml:mo>
                        </mml:mrow>
                      </mml:mrow>
                      <mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaieWacuWFqbaugaacaiabg2da9maabmaabaacciGaf4xWdiNbaGaadaWgaaWcbaGaem4AaSMaemiBaWgabeaaaOGaayjkaiaawMcaaaaa@3546@</mml:annotation>
                    </mml:semantics>
                  </mml:math>
                </inline-formula>
              </td>
              <td align="left">
                <inline-formula>
                  <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M13" name="1752-0509-1-37-i11" overflow="scroll">
                    <mml:semantics definitionURL="" encoding="">
                      <mml:mrow>
                        <mml:mover accent="true">
                          <mml:mi>R</mml:mi>
                          <mml:mo>˜</mml:mo>
                        </mml:mover>
                        <mml:mo>=</mml:mo>
                        <mml:mrow>
                          <mml:mo>(</mml:mo>
                          <mml:mrow>
                            <mml:msub>
                              <mml:mover accent="true">
                                <mml:mi>r</mml:mi>
                                <mml:mo>˜</mml:mo>
                              </mml:mover>
                              <mml:mrow>
                                <mml:mi>k</mml:mi>
                                <mml:mi>l</mml:mi>
                              </mml:mrow>
                            </mml:msub>
                          </mml:mrow>
                          <mml:mo>)</mml:mo>
                        </mml:mrow>
                      </mml:mrow>
                      <mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaieWacuWFsbGugaacaiabg2da9maabmaabaGafmOCaiNbaGaadaWgaaWcbaGaem4AaSMaemiBaWgabeaaaOGaayjkaiaawMcaaaaa@34F1@</mml:annotation>
                    </mml:semantics>
                  </mml:math>
                </inline-formula>
              </td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>Index <italic>i </italic>runs from 1 to <italic>n </italic>(sample size), and indices <italic>k </italic>and <italic>l </italic>run from 1 to <italic>p </italic>(dimension). A tilde denotes a "partial" quantity.</p>
        </table-wrap-foot>
      </table-wrap>
      <p>From Equation 1 it is immediately clear that the complete linear system and thus all <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M14" name="1752-0509-1-37-i12" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msubsup><mml:mi>β</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msubsup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacqWFYoGydaqhaaWcbaGaem4AaSgabaGaemyEaKhaaaaa@315B@</mml:annotation></mml:semantics></mml:math></inline-formula> are determined by the joint covariance matrix of <italic>Y </italic>and <italic>X</italic><sub><italic>k </italic></sub>[see also, e.g., [<xref ref-type="bibr" rid="B24">24</xref>,<xref ref-type="bibr" rid="B24">24</xref>]]. For only a single dependent variable Equation 1 reduces to the well-known relation <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M15" name="1752-0509-1-37-i13" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msubsup><mml:mi>β</mml:mi><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacqWFYoGydaqhaaWcbaGaemiEaGhabaGaemyEaKhaaOGaeyypa0Jae8xWdi3aaSbaaSqaaiabdMha5jabdIha4bqabaGcdaGcaaqaaiab=n8aZnaaDaaaleaacqWG5bqEaeaacqaIYaGmaaGccqGGVaWlcqWFdpWCdaqhaaWcbaGaemiEaGhabaGaeGOmaidaaaqabaaaaa@4118@</mml:annotation></mml:semantics></mml:math></inline-formula>, which contains only the unconditioned correlation and variances (without the tilde).</p>
      <p>We emphasize that Equation 1 has a direct relation with the usual ordinary least squares (OLS) estimator for the regression coefficient. This is recovered if the empirical covariance matrix is plugged into Equation 1. However, note that Equation 1 also remains valid if other estimates of the covariance are used, such as penalized or shrinkage estimators (note that there is no hat on <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M16" name="1752-0509-1-37-i12" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msubsup><mml:mi>β</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msubsup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacqWFYoGydaqhaaWcbaGaem4AaSgabaGaemyEaKhaaaaa@315B@</mml:annotation></mml:semantics></mml:math></inline-formula>).</p>
      <p>For the following it is important that Equation 1 can be further rewritten by introducing a scale factor. Specifically, by abbreviating the standardized partial variance <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M17" name="1752-0509-1-37-i14" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>σ</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacuWFdpWCgaacamaaDaaaleaacqWGRbWAaeaacqaIYaGmaaGccqGGVaWlcqWFdpWCdaqhaaWcbaGaem4AaSgabaGaeGOmaidaaaaa@362F@</mml:annotation></mml:semantics></mml:math></inline-formula> by SPV<sub><italic>k</italic></sub>, we can decompose the regression coefficient into the simple product</p>
      <p>
        <disp-formula id="bmcM2">
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M18" name="1752-0509-1-37-i15" overflow="scroll">
            <mml:semantics definitionURL="" encoding="">
              <mml:mrow>
                <mml:msubsup>
                  <mml:mi>β</mml:mi>
                  <mml:mi>k</mml:mi>
                  <mml:mi>y</mml:mi>
                </mml:msubsup>
                <mml:mo>=</mml:mo>
                <mml:munder>
                  <mml:munder>
                    <mml:mrow>
                      <mml:msub>
                        <mml:mover accent="true">
                          <mml:mi>ρ</mml:mi>
                          <mml:mo>˜</mml:mo>
                        </mml:mover>
                        <mml:mrow>
                          <mml:mi>y</mml:mi>
                          <mml:mi>k</mml:mi>
                        </mml:mrow>
                      </mml:msub>
                    </mml:mrow>
                    <mml:mo stretchy="true">︸</mml:mo>
                  </mml:munder>
                  <mml:mi mathvariant="script">A</mml:mi>
                </mml:munder>
                <mml:munder>
                  <mml:munder>
                    <mml:mrow>
                      <mml:msqrt>
                        <mml:mrow>
                          <mml:mfrac>
                            <mml:mrow>
                              <mml:msub>
                                <mml:mrow>
                                  <mml:mtext>SPV</mml:mtext>
                                </mml:mrow>
                                <mml:mi>y</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:msub>
                                <mml:mrow>
                                  <mml:mtext>SPV</mml:mtext>
                                </mml:mrow>
                                <mml:mi>k</mml:mi>
                              </mml:msub>
                            </mml:mrow>
                          </mml:mfrac>
                        </mml:mrow>
                      </mml:msqrt>
                    </mml:mrow>
                    <mml:mo stretchy="true">︸</mml:mo>
                  </mml:munder>
                  <mml:mi>ℬ</mml:mi>
                </mml:munder>
                <mml:munder>
                  <mml:munder>
                    <mml:mrow>
                      <mml:msqrt>
                        <mml:mrow>
                          <mml:mfrac>
                            <mml:mrow>
                              <mml:msubsup>
                                <mml:mi>σ</mml:mi>
                                <mml:mi>y</mml:mi>
                                <mml:mn>2</mml:mn>
                              </mml:msubsup>
                            </mml:mrow>
                            <mml:mrow>
                              <mml:msubsup>
                                <mml:mi>σ</mml:mi>
                                <mml:mi>k</mml:mi>
                                <mml:mn>2</mml:mn>
                              </mml:msubsup>
                            </mml:mrow>
                          </mml:mfrac>
                        </mml:mrow>
                      </mml:msqrt>
                    </mml:mrow>
                    <mml:mo stretchy="true">︸</mml:mo>
                  </mml:munder>
                  <mml:mi mathvariant="script">C</mml:mi>
                </mml:munder>
                <mml:mo>.</mml:mo>
              </mml:mrow>
              <mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacqWFYoGydaqhaaWcbaGaem4AaSgabaGaemyEaKhaaOGaeyypa0ZaaGbaaeaacuWFbpGCgaacamaaBaaaleaacqWG5bqEcqWGRbWAaeqaaaqaamrtHrhAL1wy0L2yHvtyaeHbnfgDOvwBHrxAJfwnaGabaiab+bq8bbGccaGL44padaagaaqaamaakaaabaWaaSaaaeaacqqGtbWucqqGqbaucqqGwbGvdaWgaaWcbaGaemyEaKhabeaaaOqaaiabbofatjabbcfaqjabbAfawnaaBaaaleaacqWGRbWAaeqaaaaaaeqaaaqaaiab+XsicbGccaGL44padaagaaqaamaakaaabaWaaSaaaeaacqWFdpWCdaqhaaWcbaGaemyEaKhabaGaeGOmaidaaaGcbaGae83Wdm3aa0baaSqaaiabdUgaRbqaaiabikdaYaaaaaaabeaaaeaacqGFce=qaOGaayjo+dGaeiOla4caaa@5F66@</mml:annotation>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>Note that SPV<sub><italic>y </italic></sub>and SPV<sub><italic>k </italic></sub>take on values from 0 to 1. All three factors have an immediate and intuitive interpretation:</p>
      <p><inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M19" name="1752-0509-1-37-i16" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi mathvariant="script">A</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=bq8bbaa@382B@</mml:annotation></mml:semantics></mml:math></inline-formula> : This factor determines whether there is a direct association between <italic>Y </italic>and the covariate <italic>X</italic><sub><italic>k</italic></sub>. If the partial correlation between <italic>X</italic><sub><italic>k </italic></sub>and <italic>Y </italic>vanishes, so will also the two corresponding regression coefficients <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M20" name="1752-0509-1-37-i12" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msubsup><mml:mi>β</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msubsup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacqWFYoGydaqhaaWcbaGaem4AaSgabaGaemyEaKhaaaaa@315B@</mml:annotation></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M21" name="1752-0509-1-37-i17" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msubsup><mml:mi>β</mml:mi><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msubsup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacqWFYoGydaqhaaWcbaGaemyEaKhabaGaem4AaSgaaaaa@315B@</mml:annotation></mml:semantics></mml:math></inline-formula>. In a partial correlation graph an edge is drawn between two nodes <italic>Y </italic>and <italic>X</italic><sub><italic>k </italic></sub>if <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M22" name="1752-0509-1-37-i16" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi mathvariant="script">A</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=bq8bbaa@382B@</mml:annotation></mml:semantics></mml:math></inline-formula> ≠ 0.</p>
      <p><inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M23" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula> : This factor adjusts the regression coefficient for the relative reduction in variance of <italic>Y </italic>and <italic>X</italic><sub><italic>k </italic></sub>due to the respective other covariates. In the algorithm outlined below a test of log(<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M24" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula>) establishes the directionality of edges of a partially causal network.</p>
      <p><inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M25" name="1752-0509-1-37-i19" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi mathvariant="script">C</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=jq8dbaa@382F@</mml:annotation></mml:semantics></mml:math></inline-formula> : This is a scale factor correcting for different units in <italic>Y </italic>and <italic>X</italic><sub><italic>k</italic></sub>.</p>
      <p>The product <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M26" name="1752-0509-1-37-i20" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:mi mathvariant="script">A</mml:mi><mml:mi>ℬ</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msubsup><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaacqWFaeFqcqWFSeIqcqGH9aqpiiGacqGFYoGydaqhaaWcbaGaem4AaSgabaGaemyEaKhaaOWaaOaaaeaacqGFdpWCdaqhaaWcbaGaem4AaSgabaGaeGOmaidaaOGaei4la8Iae43Wdm3aa0baaSqaaiabdMha5bqaaiabikdaYaaaaeqaaaaa@4884@</mml:annotation></mml:semantics></mml:math></inline-formula> is also known as the standardized regression coefficient. Note that for computing both <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M27" name="1752-0509-1-37-i16" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi mathvariant="script">A</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=bq8bbaa@382B@</mml:annotation></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M28" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula> only the correlation matrix is needed, as the variance information is already accounted for by the third factor <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M29" name="1752-0509-1-37-i19" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi mathvariant="script">C</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=jq8dbaa@382F@</mml:annotation></mml:semantics></mml:math></inline-formula>.</p>
      <p>In this context it is also helpful to recall the diverse statistical interpretations of SPV:</p>
      <p>• SPV is the <italic>proportion </italic>of variance that remains (unexplained) after regressing against all other variables.</p>
      <p>• For the OLS estimator SPV is equal to 1 - <italic>R</italic><sup>2</sup>, where <italic>R </italic>is the usual coefficient of determination.</p>
      <p>• SPV is the inverse of the diagonal of the inverse of the <italic>correlation </italic>matrix. Thus, if there is no correlation (unit diagonal correlation matrix) the partial variance equals the variance, and hence SPV = 1.</p>
      <p>• SPV may also be estimated by 1/VIF, where VIF is the usual variance inflation factor [cf. [<xref ref-type="bibr" rid="B26">26</xref>]].</p>
    </sec>
    <sec>
      <title>Heuristic algorithm for discovering approximate causal networks</title>
      <p>The above decomposition (Equation 2) suggests the following simple strategy for statistical learning of causal networks. First, by multiple testing of <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M30" name="1752-0509-1-37-i16" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi mathvariant="script">A</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=bq8bbaa@382B@</mml:annotation></mml:semantics></mml:math></inline-formula> = 0 we determine the network topology, i.e. we identify those edges for which the corresponding partial correlation is not vanishing. Second, by subsequent multiple testing of log(<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M31" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula>) = 0 we establish a partial ordering of the nodes, which in turn imposes a partial directionality upon the edges.</p>
      <p>In more detail, we propose the following five-step algorithm:</p>
      <p>1. First, it is essential to determine an accurate and positive definite estimate <bold><italic>R </italic></bold>of the correlation matrix. Only if the sample size is large with many more observations than variables (<italic>n </italic>&gt; &gt; <italic>p</italic>) the usual empirical correlation estimate will be suitable. In all other instances, the use of a regularized estimator is absolutely vital (e.g., the Stein-type shrinkage estimator of [<xref ref-type="bibr" rid="B20">20</xref>]) in order to improve efficiency and to guarantee positive definiteness. In addition, if the samples are longitudinal it may be necessary to adjust for autocorrelation [<xref ref-type="bibr" rid="B27">27</xref>].</p>
      <p>2. From the estimated correlations we compute the partial variances and correlations (see Table <xref ref-type="table" rid="T1">1</xref>), and from those in turn plug-in estimates of the factors <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M32" name="1752-0509-1-37-i16" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi mathvariant="script">A</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=bq8bbaa@382B@</mml:annotation></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M33" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula> of Equation 2 for all possible edges. Note that in this calculation each variable assumes in turn the role of the response <italic>Y </italic>. An efficient way to calculate the various <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M34" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula> is given by taking the square root of the diagonal of the inverse of the estimated correlation matrix, and computing the corresponding pairwise ratios.</p>
      <p>3. Subsequently, we infer the partial correlation graph following the algorithm described in [<xref ref-type="bibr" rid="B19">19</xref>]. Essentially, we perform multiple testing of all partial correlation coefficients <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M35" name="1752-0509-1-37-i16" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi mathvariant="script">A</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=bq8bbaa@382B@</mml:annotation></mml:semantics></mml:math></inline-formula>. Note that for high dimensions (large <italic>p</italic>) the null distribution of partial correlations across edges can be determined from the data, which in turn allows the adaptive computation of corresponding false discovery rates [<xref ref-type="bibr" rid="B28">28</xref>].</p>
      <p>4. In a similar fashion we then conduct multiple testing of all log(<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M36" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula>). As <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M37" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula> is the ratio of two variances with the same degrees of freedom, it is implicit that log(<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M38" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula>) is approximately normally distributed [<xref ref-type="bibr" rid="B29">29</xref>], with an unknown variance parameter <italic>θ</italic>. Thus, the observed <italic>z </italic>= log(<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M39" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula>) across all edges follow a mixture distribution</p>
      <p>
        <disp-formula id="bmcM3"><italic>f</italic>(<italic>z</italic>) = <italic>η</italic><sub>0 </sub><italic>N</italic>(0, <italic>θ</italic>) + (1 - <italic>η</italic><sub>0</sub>) <italic>f</italic><sub><italic>A </italic></sub>(<italic>z</italic>).</disp-formula>
      </p>
      <p>Assuming that most <italic>z </italic>belong to the null model, i.e. that most edges are undirected, it is possible to infer non-parametrically the alternative distribution <italic>f</italic><sub><italic>A </italic></sub>(<italic>z</italic>), the proportion <italic>η</italic><sub>0</sub>, as well as the variance parameter <italic>θ </italic>– for an algorithm see [<xref ref-type="bibr" rid="B28">28</xref>]. From the resulting densities and distribution functions local and tail-area-based false discovery rates for the test log(<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M40" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula>) = 0 are computed. Note that in this procedure we include all edges, regardless of the corresponding value of <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M41" name="1752-0509-1-37-i16" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi mathvariant="script">A</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=bq8bbaa@382B@</mml:annotation></mml:semantics></mml:math></inline-formula> or the outcome of the test <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M42" name="1752-0509-1-37-i16" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi mathvariant="script">A</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=bq8bbaa@382B@</mml:annotation></mml:semantics></mml:math></inline-formula> = 0.</p>
      <p>5. Finally, a partially directed network is constructed as follows. All edges in the correlation graph with significant log(<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M43" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula>) ≠ 0 are directed in such a fashion that the direction of the arrow points from the node with the larger standardized partial variance (the more "exogenous" variable) to the node with the smaller standardized partial variance (the more "endogenous" variable). The other edges with log(<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M44" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula>) ≈ 0 remain undirected. The subgraph consisting of all directed edges constitutes the inferred causal network. Note that this does not necessarily include all nodes that are contained in the GGM network.</p>
    </sec>
  </sec>
  <sec>
    <title>Results and discussion</title>
    <sec>
      <title>Interpretation of the resulting graph</title>
      <p>The above algorithm returns a partially directed partial correlation graph, whose directed edges form a causal network.</p>
      <p>This procedure can be motivated by the following connection between partial correlation graph and a system of linear equations, where each node is in turn taken as a response variable and regressed against all other remaining nodes. In this setting the partial correlation coefficient is the geometric mean of <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M45" name="1752-0509-1-37-i12" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msubsup><mml:mi>β</mml:mi><mml:mi>k</mml:mi><mml:mi>y</mml:mi></mml:msubsup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacqWFYoGydaqhaaWcbaGaem4AaSgabaGaemyEaKhaaaaa@315B@</mml:annotation></mml:semantics></mml:math></inline-formula> and the corresponding reciprocal coefficient <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M46" name="1752-0509-1-37-i17" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mrow><mml:msubsup><mml:mi>β</mml:mi><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msubsup></mml:mrow><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaaiiGacqWFYoGydaqhaaWcbaGaemyEaKhabaGaem4AaSgaaaaa@315B@</mml:annotation></mml:semantics></mml:math></inline-formula>, i.e.</p>
      <p>
        <disp-formula id="bmcM4">
          <mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M47" name="1752-0509-1-37-i21" overflow="scroll">
            <mml:semantics definitionURL="" encoding="">
              <mml:mrow>
                <mml:msqrt>
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mi>β</mml:mi>
                      <mml:mi>y</mml:mi>
                      <mml:mi>k</mml:mi>
                    </mml:msubsup>
                    <mml:msubsup>
                      <mml:mi>β</mml:mi>
                      <mml:mi>k</mml:mi>
                      <mml:mi>y</mml:mi>
                    </mml:msubsup>
                  </mml:mrow>
                </mml:msqrt>
                <mml:mo>=</mml:mo>
                <mml:mrow>
                  <mml:mo>|</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mover accent="true">
                        <mml:mi>ρ</mml:mi>
                        <mml:mo>˜</mml:mo>
                      </mml:mover>
                      <mml:mrow>
                        <mml:mi>y</mml:mi>
                        <mml:mi>k</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mo>|</mml:mo>
                </mml:mrow>
              </mml:mrow>
              <mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaadaGcaaqaaGGaciab=j7aInaaDaaaleaacqWG5bqEaeaacqWGRbWAaaGccqWFYoGydaqhaaWcbaGaem4AaSgabaGaemyEaKhaaaqabaGccqGH9aqpdaabdaqaaiqb=f8aYzaaiaWaaSbaaSqaaiabdMha5jabdUgaRbqabaaakiaawEa7caGLiWoaaaa@3F24@</mml:annotation>
            </mml:semantics>
          </mml:math>
        </disp-formula>
      </p>
      <p>[see also equation 16 of ref. [<xref ref-type="bibr" rid="B20">20</xref>]]. In this light, an undirected edge between two nodes A and B in a partial correlation graph may also be interpreted as bidirected edge, in the sense that A influences B and vice versa in the underlying system of regression. Therefore, the test <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M48" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula> = 1 can be understood as <italic>removing </italic>one of these two directions, where Equation 2 suggests that only the relative variance reduction between the two involved nodes needs to be considered for establishing the final direction.</p>
    </sec>
    <sec>
      <title>Reconstruction efficiency and approximations underlying the algorithm</title>
      <sec>
        <title>Topology of the network</title>
        <p>The proposed algorithm is an extension of the GGM inference approach of [<xref ref-type="bibr" rid="B19">19</xref>,<xref ref-type="bibr" rid="B20">20</xref>]. Its accuracy of correctly recovering the <italic>topology </italic>of the partial correlation graph has been established, e.g., in [<xref ref-type="bibr" rid="B30">30</xref>]. </p>
        <p>However, it is well known that a directed Bayesian network and the corresponding undirected graph are not necessarily topologically identical: in the undirected graph for computing the partial correlations one conditions on all other nodes whereas in the directed graph one conditions only on a subset of nodes, in order to avoid conditioning "on the future" (i.e. on the dependent nodes). Therefore, it is critical to evaluate to what extent full order partial correlations are reasonable approximations for lower order partial correlations. This has already been investigated intensively by [<xref ref-type="bibr" rid="B31">31</xref>] who showed that in certain situations (sparse graphs, faithfulness assumption etc.) lower order partial correlations may be used as approximate substitute of full conditional correlations. Therefore, in the proposed algorithm we adopt the very same argument but apply it in the different direction, i.e. we approximate lower order partial correlation by full order partial correlation.</p>
      </sec>
      <sec>
        <title>Node ordering</title>
        <p>A second approximation implicit in our algorithm concerns the determination of the ordering of the nodes, which is done by multiple testing of pairwise ratios of standardized partial variances. We have conducted a number of numerical simulations (data not shown) that indicate that for randomly simulated DAGs the ordering of the nodes is indeed well reflected in the partial variances, as expected.</p>
        <p>However, from variable selection in linear models it is also known that the partial variance (or the related <italic>R</italic><sup>2</sup>) may not always be a reliable indicator for variable importance. Nevertheless, the partial ordering of nodes according to SPV and the implicit model selection in the underlying regressions is a very different procedure in comparison to the standard variable selection approaches, in which the increase or decrease of the <italic>R</italic><sup>2 </sup>is taken as indicator of whether or not a variable is to be included, or a decomposition of <italic>R</italic><sup>2 </sup>is sought [for a review see, e.g., [<xref ref-type="bibr" rid="B32">32</xref>]]. The distinctive feature of our procedure is that by performing all tests log(<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M49" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula>) ≠ 0 simultaneously we consider all <italic>p </italic>regression equations at once, even if the final feature selection occurs only locally on the level of an individual regression.</p>
        <p>It is also noteworthy that, as we impose directionality from the less well explained variable (large SPV, "exogenous", "independent") to the one with relatively lower SPV (well explained, "endogenous", "dependent" variable), we effectively choose the direction with the relatively <italic>smaller </italic>regression coefficient (conditional that the corresponding partial correlation is also significant).</p>
      </sec>
    </sec>
    <sec>
      <title>Further properties of the heuristic algorithm and of the resulting graphs</title>
      <p>The simple heuristic network discovery algorithm exhibits a number of further properties worth noting:</p>
      <p>1. The estimated partially directed network cannot contain any (partially) directed cycles. For instance, it is not possible for a graph to contain a pattern such as <italic>A </italic>→ <italic>B </italic>→ <italic>A</italic>. This example would imply SPV<sub><italic>A </italic></sub>&gt; SPV<sub><italic>B </italic></sub>&gt; SPV<sub><italic>A</italic></sub>, which is a contradiction. As a consequence, the subgraph containing the directed edges only is also acyclic (and hence a DAG).</p>
      <p>2. The assignment of directionality is transitive. If there is a directed edge from <italic>A </italic>to <italic>B </italic>and from <italic>B </italic>to <italic>C </italic>then there must also be a directed edge from <italic>A </italic>to <italic>C</italic>. Note however, that actual inclusion of a directed edge into the causal network is conditional on a non-zero partial correlation coefficient.</p>
      <p>3. As the algorithm relies on correlations as input, causal processes that produce the same correlation matrix lead to the same inferred graph, and hence are indistinguishable. The existence of such equivalence classes is well known for SEMs [<xref ref-type="bibr" rid="B33">33</xref>] and also for Bayesian belief networks [<xref ref-type="bibr" rid="B34">34</xref>].</p>
      <p>4. The proposed algorithm is scale-invariant by construction. Hence, a (linear) change in any of units of the data has no effect on the overall estimated partially directed network, and the implied causal relations.</p>
      <p>5. We emphasize that the partially directed network is <italic>not </italic>the chain graph representing the equivalence class of the causal network that is obtained by considering only its directed edges – see [<xref ref-type="bibr" rid="B34">34</xref>].</p>
      <p>6. The computational complexity of the algorithm is <italic>O</italic>(<italic>p</italic><sup>3</sup>). Hence, it is no more expensive than computing the partial correlation graph, and thus allows for estimation of networks containing in the order of thousands and more nodes.</p>
    </sec>
    <sec>
      <title>Analysis of a plant expression data set</title>
      <p>To illustrate our algorithm for discovering causal structure, we applied the approach to a real world data example. Specifically, we reanalyzed expression time series resulting from an experiment investigating the impact of the diurnal cycle on the starch metabolism of <italic>Arabidopsis thaliana </italic>[<xref ref-type="bibr" rid="B35">35</xref>]. This is the same data set we used in a sister paper concerning the estimation of a vector autoregressive model [<xref ref-type="bibr" rid="B36">36</xref>].</p>
      <p>The data are gene expression time series measurements collected at 11 different time points (0, 1, 2, 4, 8, 12, 13, 14, 16, 20, and 24 hours after the start of the experiment). The corresponding calibrated signal intensities for 22,814 genes/probe sets and for two biological replicates are available from the NASCArrays repository, experiment no. 60 [<xref ref-type="bibr" rid="B37">37</xref>]. After log-transforming the data we filtered out all genes containing missing values and whose maximum signal intensity value was lower than 5 on a log-base 2 scale. Subsequently, we applied the periodicity test of [<xref ref-type="bibr" rid="B38">38</xref>] to identify the probes associated with the day-night cycle. As a result, a subset of 800 genes remained for further analysis.</p>
      <p>In order to estimate the correlation matrix for the 800 genes described by the data set we employed the dynamical correlation shrinkage estimator of [<xref ref-type="bibr" rid="B39">39</xref>] as this takes account of the autocorrelation. The corresponding correlation graph is displayed in Figure <xref ref-type="fig" rid="F1">1</xref>. It shows the 150 edges with the largest absolute values of correlation. This graph is very hard to interpret, the branches do not have any immediate or intuitive meaning (a complete annotation of the nodes can be found along with the dataset itself in the R package "GeneNet" [<xref ref-type="bibr" rid="B40">40</xref>]). For instance, there are no hubs as typically observed in biological networks [<xref ref-type="bibr" rid="B41">41</xref>,<xref ref-type="bibr" rid="B42">42</xref>].</p>
      <fig position="float" id="F1">
        <label>Figure 1</label>
        <caption>
          <p>Correlation network inferred from the <italic>Arabidopsis thaliana </italic>data. The solid and dotted lines indicate positive and negative correlation coefficients, respectively, and the line intensity denotes their strength. The network displays the 150 edges with the largest absolute correlation. For annotation of the nodes in this graph see the electronic information contained in the R package "GeneNet" [40] and the original data paper [35].</p>
        </caption>
        <graphic xlink:href="1752-0509-1-37-1"/>
      </fig>
      <p>This is in great contrast to the partially directed partial correlation graph. For this specific data set, by multiple testing of the factor <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M50" name="1752-0509-1-37-i16" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi mathvariant="script">A</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=bq8bbaa@382B@</mml:annotation></mml:semantics></mml:math></inline-formula> we identified 6, 102 significant edges connecting 669 nodes. For the second factor <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M51" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula>, determined whether edges are directed, the distribution of log(<inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M52" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula>) is displayed in Figure <xref ref-type="fig" rid="F2">2</xref>. The null distribution (dashed line) follows a normal distribution and characterizes the edges that cannot be directed. The alternative distribution (solid line) coincides with the directed edges. In total, we found 15, 928 significant directions.</p>
      <fig position="float" id="F2">
        <label>Figure 2</label>
        <caption>
          <p>Distribution of log <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M53" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula> for the <italic>Arabidopsis thaliana </italic>data. The null distribution is depicted by the dashed line; it follows a normal distribution with zero mean and a standard deviation of 0.014. The solid line signifies the alternative distribution. The empirical distribution (indicated by the histogram) is composed of the null distribution (<italic>η</italic><sub>0 </sub>= 0.8995) and of the alternative distribution (<italic>η</italic><sub><italic>A </italic></sub>= 0.1005).</p>
        </caption>
        <graphic xlink:href="1752-0509-1-37-2"/>
      </fig>
      <p>To construct the network, we projected upon the significant edges (factor <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M54" name="1752-0509-1-37-i16" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi mathvariant="script">A</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=bq8bbaa@382B@</mml:annotation></mml:semantics></mml:math></inline-formula>) the significant directions (factor <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M55" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula>). In the network of significant associations, 1,216 directions were significant. Note that the fraction of significant directions is by far greater in the subset of the significant partial correlations than in the complete set of all partial correlations. This agrees with the intuitive notion, that causal influences can only be attributed to existing connections between variables.</p>
      <p>The resulting partially causal network is shown in Figure <xref ref-type="fig" rid="F3">3</xref>. For reasons of clarity we show only the subnetwork containing the 150 most significant edges, which connect 107 nodes. This graph exhibits a clear "hub" connectivity structure (nodes filled with red color). A prominent example for this is node 570, others are 81, 558, 783 and a few more genes. We see that many of the hub nodes have mostly outgoing arcs, which is indicative for key regulatory genes. This applies, e.g., to node 570, an AP2 transcription factor, or to node 81, a gene involved in DNA-directed RNA polymerase. An interesting aspect of the partially causal network is the web of highly connected genes (colored yellow in the lower right corner of Figure <xref ref-type="fig" rid="F3">3</xref>), which we hypothesize to constitute some form of a functional module. In this module, it is not possible to determine any directions, which could be due to complex interactions among the nodes of the module. Node 627 is another hub in the network that connects the functional module with the rest of the network and which according to the annotation of [<xref ref-type="bibr" rid="B35">35</xref>] encodes a protein of unknown function.</p>
      <fig position="float" id="F3">
        <label>Figure 3</label>
        <caption>
          <p>Partially causal network inferred from the <italic>Arabidopsis thaliana </italic>data by the method introduced in this paper – note the difference to the correlation network of Figure 1. The topology of the partially causal network is identical to that of a partial correlation graph (GGM, CIG). However, edges with significant directionality (as indicated by a factor <inline-formula><mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M56" name="1752-0509-1-37-i18" overflow="scroll"><mml:semantics definitionURL="" encoding=""><mml:mi>ℬ</mml:mi><mml:annotation encoding="MathType-MTEF">
 MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaaliab=Xsicbaa@3788@</mml:annotation></mml:semantics></mml:math></inline-formula> that is significantly smaller or larger than one) are oriented.</p>
        </caption>
        <graphic xlink:href="1752-0509-1-37-3"/>
      </fig>
      <p>We also see that the partially directed network contains both directed and undirected nodes. This is a distinct advantage of the present approach. Unlike, e.g., a vector autoregressive model [<xref ref-type="bibr" rid="B36">36</xref>], it does not <italic>force </italic>directions onto the edges.</p>
      <p>Finally, in order to investigate the stability of the inferred partial causal network, we randomly removed data points from the sample, and repeatedly reconstructed the network from the reduced data set. In all cases the general topological structure of the network remained intact, which indicates that this is a signal inherent in the data. This is also confirmed by the analysis using vector autoregressions [<xref ref-type="bibr" rid="B36">36</xref>].</p>
    </sec>
  </sec>
  <sec>
    <title>Conclusion</title>
    <p>Methods for exploring causal structures in high-dimensional data are growing in importance, particularly in the study of complex biological, medical and financial systems. As a first (and often only) analysis step these data are explored using correlation networks.</p>
    <p>Here we have suggested a simple heuristic algorithm that, starting from a (positive definite) correlation matrix, infers a partially directed network that in turn allows generating causal hypotheses of how the data were generated. Our approach is approximate, but it allows analysis of high-dimensional small sampled data, and its computational complexity is very modest. Thus, our heuristic is likely to be applicable whenever a correlation network is computed, and therefore is suitable for screening large-scale data set for causal structure.</p>
    <p>Nevertheless, there a several lines along which this method could be extended. For instance, non-linear effects could be accounted for by employing entropy criteria, or by using higher order moments [<xref ref-type="bibr" rid="B16">16</xref>]. Furthermore, more sophisticated algorithms may be used to enhance the approximation of lower order partial correlations or the inference of the ordering of the nodes. However, ultimately this would lead to a method similar to the PC algorithm [<xref ref-type="bibr" rid="B14">14</xref>,<xref ref-type="bibr" rid="B15">15</xref>].</p>
    <p>Note that the PC algorithm is more refined than our algorithm, primarily due to additional steps that aim at removing spurious edges (i.e. those edges that are induced between otherwise uncorrelated parent nodes by conditioning on a common child node). However, these iterative refinements may be very time consuming, in particular for high-dimensional graphs.</p>
    <p>In contrast, our procedure is non-iterative and therefore both computationally and algorithmically (nearly) as simple as a correlation network. Nevertheless, it still enables the discovery of partially directed processes underlying the data.</p>
    <p>In summary, we recommend our approach as a procedure for exploratory screening for causal mechanisms. Subsequently, the resulting hypotheses may then form the basis for more refined analyzes, such as full Bayesian network modeling.</p>
  </sec>
  <sec>
    <title>Authors' contributions</title>
    <p>Both authors participated in the development of the methodology and wrote the manuscript. RO carried out all analyzes. All authors approved of the final version of the manuscript.</p>
  </sec>
  <sec>
    <title>Availability and requirements</title>
    <p>The method is implemented in the "GeneNet" R package (version 1.2.0), available from CRAN and from <ext-link ext-link-type="uri" xlink:href="http://strimmerlab.org/software/genets/"/>. The software includes an R script for reproducing the network analysis of the <italic>Arabidopsis thaliana </italic>data.</p>
  </sec>
</body>
<back>
  <ack>
    <sec>
      <title>Acknowledgements</title>
      <p>This work was in part supported by an "Emmy Noether" excellence grant of the Deutsche Forschungsgemeinschaft (to K.S.).</p>
    </sec>
  </ack>
  <ref-list>
    <ref id="B1">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Mantegna</surname>
            <given-names>RN</given-names>
          </name>
          <name>
            <surname>Stanley</surname>
            <given-names>HE</given-names>
          </name>
        </person-group>
        <source>An Introduction to Econophysics: Correlations and Complexity in Finance</source>
        <year>2000</year>
        <publisher-name>Cambridge, UK: Cambridge University Press</publisher-name>
      </citation>
    </ref>
    <ref id="B2">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Onnela</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Kaski</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Kertész</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Clustering and information in correlation based financial networks</article-title>
        <source>Eur Phys J B</source>
        <year>2004</year>
        <volume>38</volume>
        <fpage>353</fpage>
        <lpage>362</lpage>
        <pub-id pub-id-type="doi">10.1140/epjb/e2004-00128-7</pub-id>
      </citation>
    </ref>
    <ref id="B3">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Boginski</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Butenko</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Pardalos</surname>
            <given-names>PM</given-names>
          </name>
        </person-group>
        <article-title>Statistical analysis of financial networks</article-title>
        <source>Comp Stat Data Anal</source>
        <year>2005</year>
        <volume>48</volume>
        <fpage>431</fpage>
        <lpage>443</lpage>
        <pub-id pub-id-type="doi">10.1016/j.csda.2004.02.004</pub-id>
      </citation>
    </ref>
    <ref id="B4">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Shipley</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <source>Cause and Correlation in Biology</source>
        <year>2000</year>
        <publisher-name>Cambridge University Press</publisher-name>
      </citation>
    </ref>
    <ref id="B5">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Butte</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Tamayo</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Slonim</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Golub</surname>
            <given-names>TR</given-names>
          </name>
          <name>
            <surname>Kohane</surname>
            <given-names>IS</given-names>
          </name>
        </person-group>
        <article-title>Discovering functional relationships between RNA expression and chemotherapeutic susceptibility using relevance networks</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2000</year>
        <volume>97</volume>
        <fpage>12182</fpage>
        <lpage>12186</lpage>
        <pub-id pub-id-type="pmid">11027309</pub-id>
        <pub-id pub-id-type="doi">10.1073/pnas.220392197</pub-id>
      </citation>
    </ref>
    <ref id="B6">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Oldham</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Horvath</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Geschwind</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Conservation and evolution of gene coexpression networks in human and chimpanzee brains</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2006</year>
        <fpage>17973</fpage>
        <lpage>17978</lpage>
        <pub-id pub-id-type="pmid">17101986</pub-id>
        <pub-id pub-id-type="doi">10.1073/pnas.0605938103</pub-id>
      </citation>
    </ref>
    <ref id="B7">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Steuer</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>On the analysis and interpretation of correlations in metabolomic data</article-title>
        <source>Brief Bioinform</source>
        <year>2006</year>
        <volume>151</volume>
        <fpage>151</fpage>
        <lpage>158</lpage>
        <pub-id pub-id-type="pmid">16772265</pub-id>
        <pub-id pub-id-type="doi">10.1093/bib/bbl009</pub-id>
      </citation>
    </ref>
    <ref id="B8">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tumminello</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Aste</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Di Matteo</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Mantegna</surname>
            <given-names>RN</given-names>
          </name>
        </person-group>
        <article-title>A tool for filtering information in complex systems</article-title>
        <source>Proc Natl Acad Sc USA</source>
        <year>2005</year>
        <volume>102</volume>
        <fpage>10421</fpage>
        <lpage>10426</lpage>
        <pub-id pub-id-type="pmid">16027373</pub-id>
        <pub-id pub-id-type="doi">10.1073/pnas.0500298102</pub-id>
      </citation>
    </ref>
    <ref id="B9">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Pearl</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <source>Causality: Models, Reasoning, and Inference</source>
        <year>2000</year>
        <publisher-name>Cambridge, UK: Cambridge University Press</publisher-name>
      </citation>
    </ref>
    <ref id="B10">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Freedman</surname>
            <given-names>DA</given-names>
          </name>
        </person-group>
        <source>Statistical Models: Theory and Practice</source>
        <year>2005</year>
        <publisher-name>Cambridge, UK: Cambridge University Press</publisher-name>
      </citation>
    </ref>
    <ref id="B11">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wermuth</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Linear recursive equations, covariance selection, and path analysis</article-title>
        <source>J Amer Statist Assoc</source>
        <year>1980</year>
        <volume>75</volume>
        <fpage>963</fpage>
        <lpage>972</lpage>
        <pub-id pub-id-type="doi">10.2307/2287189</pub-id>
      </citation>
    </ref>
    <ref id="B12">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schachter</surname>
            <given-names>RD</given-names>
          </name>
          <name>
            <surname>Kenley</surname>
            <given-names>CR</given-names>
          </name>
        </person-group>
        <article-title>Gaussian influence diagrams</article-title>
        <source>Management Sci</source>
        <year>1989</year>
        <volume>35</volume>
        <fpage>527</fpage>
        <lpage>550</lpage>
      </citation>
    </ref>
    <ref id="B13">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tsamardinos</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Brown</surname>
            <given-names>LE</given-names>
          </name>
          <name>
            <surname>Aliferis</surname>
            <given-names>CF</given-names>
          </name>
        </person-group>
        <article-title>The max-min hill-climbing Bayesian network structure learning algorithm</article-title>
        <source>Machine Learning</source>
        <year>2006</year>
        <volume>65</volume>
        <fpage>31</fpage>
        <lpage>78</lpage>
        <pub-id pub-id-type="doi">10.1007/s10994-006-6889-7</pub-id>
      </citation>
    </ref>
    <ref id="B14">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Spirtes</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Glymour</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Scheines</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <source>Causation, Prediction, and Search</source>
        <year>2000</year>
        <edition>2</edition>
        <publisher-name>MIT Press</publisher-name>
      </citation>
    </ref>
    <ref id="B15">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kalisch</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bühlmann</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Estimating high-dimensional directed acyclic graphs with the PC-algorithm</article-title>
        <source>J Machine Learn Res</source>
        <year>2007</year>
        <volume>8</volume>
        <fpage>613</fpage>
        <lpage>636</lpage>
      </citation>
    </ref>
    <ref id="B16">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shimizu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hoyer</surname>
            <given-names>PO</given-names>
          </name>
          <name>
            <surname>Hyvärinen</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kerminen</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>A linear non-Gaussian acyclic model for causal discovery</article-title>
        <source>J Machine Learn Res</source>
        <year>2006</year>
        <volume>7</volume>
        <fpage>2003</fpage>
        <lpage>2030</lpage>
      </citation>
    </ref>
    <ref id="B17">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de la Fuente</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bing</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hoeschele</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Mendes</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Discovery of meaningful associations in genomic data using partial correlation coefficients</article-title>
        <source>Bioinformatics</source>
        <year>2004</year>
        <volume>20</volume>
        <fpage>3565</fpage>
        <lpage>3574</lpage>
        <pub-id pub-id-type="pmid">15284096</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bth445</pub-id>
      </citation>
    </ref>
    <ref id="B18">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dobra</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hans</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Nevins</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>West</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Sparse graphical models for exploring gene expression data</article-title>
        <source>J Multiv Anal</source>
        <year>2004</year>
        <volume>90</volume>
        <fpage>196</fpage>
        <lpage>212</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmva.2004.02.009</pub-id>
      </citation>
    </ref>
    <ref id="B19">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schäfer</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Strimmer</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>An empirical Bayes approach to inferring large-scale gene association networks</article-title>
        <source>Bioinformatics</source>
        <year>2005</year>
        <volume>21</volume>
        <fpage>754</fpage>
        <lpage>764</lpage>
        <pub-id pub-id-type="pmid">15479708</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bti062</pub-id>
      </citation>
    </ref>
    <ref id="B20">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schäfer</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Strimmer</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics</article-title>
        <source>Statist Appl Genet Mol Biol</source>
        <year>2005</year>
        <volume>4</volume>
        <fpage>32</fpage>
      </citation>
    </ref>
    <ref id="B21">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wille</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bühlmann</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Low-order conditional independence graphs for inferring genetic networks</article-title>
        <source>Statist Appl Genet Mol Biol</source>
        <year>2006</year>
        <volume>5</volume>
        <fpage>1</fpage>
      </citation>
    </ref>
    <ref id="B22">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Gui</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Gradient directed regularization for sparse Gaussian concentration graphs, with applications to inference of genetic networks</article-title>
        <source>Biostatistics</source>
        <year>2006</year>
        <volume>7</volume>
        <fpage>302</fpage>
        <lpage>317</lpage>
        <pub-id pub-id-type="pmid">16326758</pub-id>
        <pub-id pub-id-type="doi">10.1093/biostatistics/kxj008</pub-id>
      </citation>
    </ref>
    <ref id="B23">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cox</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>Wermuth</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Linear dependencies represented by chain graphs</article-title>
        <source>Statistical Science</source>
        <year>1993</year>
        <volume>8</volume>
        <fpage>204</fpage>
        <lpage>218</lpage>
      </citation>
    </ref>
    <ref id="B24">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Whittaker</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <source>Graphical Models in Applied Multivariate Statistics</source>
        <year>1990</year>
        <publisher-name>New York: Wiley</publisher-name>
      </citation>
    </ref>
    <ref id="B25">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Studený</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <source>Probabilistic Conditional Independence Structures</source>
        <year>2005</year>
        <publisher-name>Springer</publisher-name>
      </citation>
    </ref>
    <ref id="B26">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stewart</surname>
            <given-names>GW</given-names>
          </name>
        </person-group>
        <article-title>Collinearity and least squares regression (with discussion)</article-title>
        <source>Statist Sci</source>
        <year>1987</year>
        <volume>2</volume>
        <fpage>68</fpage>
        <lpage>100</lpage>
      </citation>
    </ref>
    <ref id="B27">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Opgen-Rhein</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Strimmer</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Inferring gene dependency networks from genomic longitudinal data: a functional data approach</article-title>
        <source>REVSTAT</source>
        <year>2006</year>
        <volume>4</volume>
        <fpage>53</fpage>
        <lpage>65</lpage>
      </citation>
    </ref>
    <ref id="B28">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Efron</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Large-scale simultaneous hypothesis testing: the choice of a null hypothesis</article-title>
        <source>J Amer Statist Assoc</source>
        <year>2004</year>
        <volume>99</volume>
        <fpage>96</fpage>
        <lpage>104</lpage>
        <pub-id pub-id-type="doi">10.1198/016214504000000089</pub-id>
      </citation>
    </ref>
    <ref id="B29">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fisher</surname>
            <given-names>RA</given-names>
          </name>
        </person-group>
        <article-title>On a distribution yielding the error functions of several well known statistics</article-title>
        <source>Proc Intl Congr Math</source>
        <year>1924</year>
        <volume>2</volume>
        <fpage>805</fpage>
        <lpage>813</lpage>
      </citation>
    </ref>
    <ref id="B30">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Werhli</surname>
            <given-names>AV</given-names>
          </name>
          <name>
            <surname>Grzegorczyk</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Husmeier</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Comparative evaluation of reverse engineering gene regulatory networks with relevance networks, graphical Gaussian models and Bayesian networks</article-title>
        <source>Bioinformatics</source>
        <year>2006</year>
        <volume>22</volume>
        <fpage>2523</fpage>
        <lpage>2531</lpage>
        <pub-id pub-id-type="pmid">16844710</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btl391</pub-id>
      </citation>
    </ref>
    <ref id="B31">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Castelo</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Roverato</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>A robust procedure for Gaussian graphical model search from microarray data with <italic>p </italic>larger than <italic>n</italic></article-title>
        <source>J Machine Learn Res</source>
        <year>2006</year>
        <volume>7</volume>
      </citation>
    </ref>
    <ref id="B32">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Grömping</surname>
            <given-names>U</given-names>
          </name>
        </person-group>
        <article-title>Relative importance in linear regression in R: the package relaimpo</article-title>
        <source>J Statist Soft</source>
        <year>2006</year>
        <volume>17</volume>
        <fpage>1</fpage>
      </citation>
    </ref>
    <ref id="B33">
      <citation citation-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Bollen</surname>
            <given-names>KA</given-names>
          </name>
        </person-group>
        <source>Structural Equations With Latent Variables</source>
        <year>1989</year>
        <publisher-name>John Wiley &amp; Sons</publisher-name>
      </citation>
    </ref>
    <ref id="B34">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chickering</surname>
            <given-names>DM</given-names>
          </name>
        </person-group>
        <article-title>Learning equivalence classes of Bayesian-network structures</article-title>
        <source>J Machine Learn Res</source>
        <year>2002</year>
        <volume>2</volume>
        <fpage>445</fpage>
        <lpage>498</lpage>
        <pub-id pub-id-type="doi">10.1162/153244302760200696</pub-id>
      </citation>
    </ref>
    <ref id="B35">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Smith</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Fulton</surname>
            <given-names>DC</given-names>
          </name>
          <name>
            <surname>Chia</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Thorneycroft</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Chapple</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Dunstan</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Hylton</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>SCZAM</given-names>
          </name>
        </person-group>
        <article-title>Diurnal changes in the transcriptom encoding enzymes of starch metabolism provide evidence for both transcriptionaland posttranscriptional regulation of starch metabolism inArabidopsis leaves</article-title>
        <source>Plant Physiol</source>
        <year>2004</year>
        <volume>136</volume>
        <fpage>2687</fpage>
        <lpage>2699</lpage>
        <pub-id pub-id-type="pmid">15347792</pub-id>
        <pub-id pub-id-type="doi">10.1104/pp.104.044347</pub-id>
      </citation>
    </ref>
    <ref id="B36">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Opgen-Rhein</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Strimmer</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Learning causal networks from systems biology time course data: an effective model selection procedure for the vector autoregressive process</article-title>
        <source>BMC Bioinformatics</source>
        <year>2007</year>
        <volume>8</volume>
        <fpage>S3</fpage>
        <pub-id pub-id-type="pmid">17493252</pub-id>
        <pub-id pub-id-type="doi">10.1186/1471-2105-8-S2-S3</pub-id>
      </citation>
    </ref>
    <ref id="B37">
      <citation citation-type="other">
        <article-title>NASCArrays: the Nottingham Arabidopsis Stock Centre's microarray database</article-title>
        <ext-link ext-link-type="uri" xlink:href="http://affymetrix.arabidopsis.info/narrays/experimentbrowse.pl"/>
      </citation>
    </ref>
    <ref id="B38">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wichert</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Fokianos</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Strimmer</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Identifying periodically expressed transcripts in microarray time series data</article-title>
        <source>Bioinformatics</source>
        <year>2004</year>
        <volume>20</volume>
        <fpage>5</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="pmid">14693803</pub-id>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btg364</pub-id>
      </citation>
    </ref>
    <ref id="B39">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Opgen-Rhein</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Strimmer</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Using regularized dynamic correlation to infer gene dependency networks from time-series microarray data</article-title>
        <source>Proceedings of the 4th International Workshop on Computational Systems Biology (WCSB 2006), Tampere</source>
        <year>2006</year>
        <volume>4</volume>
        <fpage>73</fpage>
        <lpage>76</lpage>
      </citation>
    </ref>
    <ref id="B40">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Schäfer</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Opgen-Rhein</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Strimmer</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>Reverse engineering genetic networks using the "GeneNet" package</article-title>
        <source>R News</source>
        <year>2006</year>
        <volume>6/5</volume>
        <fpage>50</fpage>
        <lpage>53</lpage>
      </citation>
    </ref>
    <ref id="B41">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ravasz</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Somera</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Mongru</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Oltvai</surname>
            <given-names>ZN</given-names>
          </name>
          <name>
            <surname>Barabási</surname>
            <given-names>A-L</given-names>
          </name>
        </person-group>
        <article-title>Hierarchical organsation of modularity in metabolic networks</article-title>
        <source>Science</source>
        <year>2002</year>
        <volume>297</volume>
        <fpage>1551</fpage>
        <lpage>1555</lpage>
        <pub-id pub-id-type="pmid">12202830</pub-id>
        <pub-id pub-id-type="doi">10.1126/science.1073374</pub-id>
      </citation>
    </ref>
    <ref id="B42">
      <citation citation-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Barabási</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Oltvai</surname>
            <given-names>ZN</given-names>
          </name>
        </person-group>
        <article-title>Network biology: understanding the cell's functional organization</article-title>
        <source>Nature Rev Genetics</source>
        <year>2004</year>
        <volume>5</volume>
        <fpage>101</fpage>
        <lpage>113</lpage>
        <pub-id pub-id-type="pmid">14735121</pub-id>
        <pub-id pub-id-type="doi">10.1038/nrg1272</pub-id>
      </citation>
    </ref>
  </ref-list>
</back>
