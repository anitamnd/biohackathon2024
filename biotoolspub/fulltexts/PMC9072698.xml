<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Nat Commun</journal-id>
    <journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id>
    <journal-title-group>
      <journal-title>Nature Communications</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2041-1723</issn>
    <publisher>
      <publisher-name>Nature Publishing Group UK</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9072698</article-id>
    <article-id pub-id-type="publisher-id">29994</article-id>
    <article-id pub-id-type="doi">10.1038/s41467-022-29994-y</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>EPicker is an exemplar-based continual learning approach for knowledge accumulation in cryoEM particle picking</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Zhang</surname>
          <given-names>Xinyu</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Zhao</surname>
          <given-names>Tianfang</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2040-7938</contrib-id>
        <name>
          <surname>Chen</surname>
          <given-names>Jiansheng</given-names>
        </name>
        <address>
          <email>jschen@ustb.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9396-1964</contrib-id>
        <name>
          <surname>Shen</surname>
          <given-names>Yuan</given-names>
        </name>
        <address>
          <email>shenyuan_ee@tsinghua.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8451-9947</contrib-id>
        <name>
          <surname>Li</surname>
          <given-names>Xueming</given-names>
        </name>
        <address>
          <email>lixueming@tsinghua.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff4">4</xref>
        <xref ref-type="aff" rid="Aff5">5</xref>
        <xref ref-type="aff" rid="Aff6">6</xref>
        <xref ref-type="aff" rid="Aff7">7</xref>
        <xref ref-type="aff" rid="Aff8">8</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.12527.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 0662 3178</institution-id><institution>Department of Electronic Engineering, </institution><institution>Tsinghua University, </institution></institution-wrap>Beijing, 100084 China </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.12527.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 0662 3178</institution-id><institution>Beijing National Research Center for Information Science and Technology, </institution><institution>Tsinghua University, </institution></institution-wrap>Beijing, 100084 China </aff>
      <aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="GRID">grid.69775.3a</institution-id><institution-id institution-id-type="ISNI">0000 0004 0369 0705</institution-id><institution>School of Computer and Communication Engineering, </institution><institution>University of Science and Technology Beijing, </institution></institution-wrap>Beijing, 100083 China </aff>
      <aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="GRID">grid.12527.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 0662 3178</institution-id><institution>School of Life Sciences, </institution><institution>Tsinghua University, </institution></institution-wrap>Beijing, 100084 China </aff>
      <aff id="Aff5"><label>5</label><institution-wrap><institution-id institution-id-type="GRID">grid.452723.5</institution-id><institution-id institution-id-type="ISNI">0000 0004 7887 9190</institution-id><institution>Tsinghua-Peking Joint Center for Life Sciences, </institution></institution-wrap>Beijing, 100084 China </aff>
      <aff id="Aff6"><label>6</label>Beijing Frontier Research Center for Biological Structure, Beijing, 100084 China </aff>
      <aff id="Aff7"><label>7</label>Advanced Innovation Center for Structural Biology, Beijing, 100084 China </aff>
      <aff id="Aff8"><label>8</label><institution-wrap><institution-id institution-id-type="GRID">grid.12527.33</institution-id><institution-id institution-id-type="ISNI">0000 0001 0662 3178</institution-id><institution>Key Laboratory for Protein Sciences of Ministry of Education, School of Life Sciences, </institution><institution>Tsinghua University, </institution></institution-wrap>Beijing, 100084 China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>5</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>5</day>
      <month>5</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>13</volume>
    <elocation-id>2468</elocation-id>
    <history>
      <date date-type="received">
        <day>24</day>
        <month>4</month>
        <year>2021</year>
      </date>
      <date date-type="accepted">
        <day>10</day>
        <month>1</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Deep learning is a popular method for facilitating particle picking in single-particle cryo-electron microscopy (cryo-EM), which is essential for developing automated processing pipelines. Most existing deep learning algorithms for particle picking rely on supervised learning where the features to be identified must be provided through a training procedure. However, the generalization performance of these algorithms on unseen datasets with different features is often unpredictable. In addition, while they perform well on the latest training datasets, these algorithms often fail to maintain the knowledge of old particles. Here, we report an exemplar-based continual learning approach, which can accumulate knowledge from the new dataset into the model by training an existing model on only a few new samples without catastrophic forgetting of old knowledge, implemented in a program called EPicker. Therefore, the ability of EPicker to identify bio-macromolecules can be expanded by continuously learning new knowledge during routine particle picking applications. Powered by the improved training strategy, EPicker is designed to pick not only protein particles but also general biological objects such as vesicles and fibers.</p>
    </abstract>
    <abstract id="Abs2" abstract-type="web-summary">
      <p id="Par2">Many existing deep learning algorithms for particle picking are not predictable on unseen datasets. Here the authors report an exemplar-based continual learning approach, EPicker, enabling accumulation of new knowledge of cryoEM particle picking without catastrophic forgetting of old knowledge.</p>
    </abstract>
    <kwd-group kwd-group-type="npg-subject">
      <title>Subject terms</title>
      <kwd>Computational biophysics</kwd>
      <kwd>Data processing</kwd>
      <kwd>Cryoelectron microscopy</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1" sec-type="introduction">
    <title>Introduction</title>
    <p id="Par3">Single-particle cryo-electron microscopy (cryo-EM) is now a powerful tool for determining the atomic structure of bio-macromolecules in the solution. Single-particle cryo-EM processing involves a multistep workflow to obtain the structure by 3D reconstruction. Particle picking is a key step at the beginning of the workflow; it recognizes bio-macromolecular particles embedded in vitreous ice and determines their locations on micrographs. A cryoEM micrograph often contains multiple views of the target bio-macromolecules, degraded proteins, protein impurities, and ice contaminations. Particle picking is expected to precisely locate particles of protein complexes with a homogenous conformation and those with conformational or compositional heterogeneity. Owing to the requirement for efficiency of the cryoEM workflow, particle picking is also expected to be automated.</p>
    <p id="Par4">The basic concept of particle picking is to match given features to target images, which includes two steps: feature extraction and object detection. Traditional methods, such as FindEM<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>, Signature<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>, DoGpicker<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, gAutoMatch, and the picking subroutines in EMAN<sup><xref ref-type="bibr" rid="CR4">4</xref></sup> and RELION<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>, are based on matching given templates or specific features. The user should explicitly prepare and provide template images or specific feature descriptions of the target samples. However, these methods suffer from the dependency of template preparation, which often strongly depends on the user’s experience and can easily cause bias. As an alternative to template matching, several algorithms that do not require the user to provide templates have been developed, such as DeepCryoPicker<sup><xref ref-type="bibr" rid="CR6">6</xref></sup> and DRPNet<sup><xref ref-type="bibr" rid="CR7">7</xref></sup>, which automatically obtain features using clustering and unsupervised learning algorithms, respectively. In recent years, deep-learning-based methods, especially convolutional neural networks (CNNs), have shown great potential for particle picking. CNNs are more adaptable and automated than traditional methods. Rather than using intuitive and visible features, deep learning algorithms can automatically learn to extract abstract and hierarchical features from labeled samples via a multi-layer neural network and generate a parametric model. This process is called training. Then, based on the model, particle picking can be performed through the inference process.</p>
    <p id="Par5">Wang et al. employed a CNN in DeepPicker<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> for particle picking. By joint training on several datasets of diversified protein complexes, DeepPicker demonstrated the generalization capability of CNNs in the task of particle picking. Later, more particle picking approaches and programs, such as DeepEM<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>, Warp<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>, Topaz<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR12">12</xref></sup>, and crYOLO<sup><xref ref-type="bibr" rid="CR13">13</xref></sup>, used CNN or modified CNN. In these methods, joint training is applied to multiple datasets. For instance, crYOLO<sup><xref ref-type="bibr" rid="CR13">13</xref></sup> used 53 datasets; the developer of Warp<sup><xref ref-type="bibr" rid="CR10">10</xref></sup> suggested a central repository of training data and periodic training. Frequently adding new features is necessary to broaden the applicable range of a general model. However, joint training on an increasing number of datasets is computationally intensive and requires a large storage space. Alternatively, fine-tuning<sup><xref ref-type="bibr" rid="CR14">14</xref></sup> is used to quickly adapt to unseen features. However, fine-tuning can only generate a specific feature model rather than a general model, that is, the new model loses its ability to effectively pick old particles, known as catastrophic forgetting<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>.</p>
    <p id="Par6">A low-cost alternative to joint training is continual (or incremental) learning, which aims to adapt a new model for a new task while maintaining performance for old tasks<sup><xref ref-type="bibr" rid="CR16">16</xref>–<xref ref-type="bibr" rid="CR24">24</xref></sup>. Knowledge distillation<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> is a widely used technique for incremental object detection problems in natural images<sup><xref ref-type="bibr" rid="CR26">26</xref>–<xref ref-type="bibr" rid="CR28">28</xref></sup>, which transfers knowledge between neural networks using loss functions that minimize the difference between features extracted from the new and old models for old datasets. Continual learning enables the accumulation of knowledge in existing models. Hence, with an increasing amount of incorporated data, continual learning should be able to continuously enhance particle picking in a cryoEM pipeline.</p>
    <p id="Par7">Here, we report an EPicker program with an exemplar-based continual learning algorithm based on a CenterNet object detector<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> for particle picking in cryoEM. EPicker is shown to enhance the performance of particle picking continuously with more new knowledge of the features learned. EPicker also supports joint training and fine-tuning to meet the different requirements of particle picking. The characteristics and possible uses of different training modes are discussed. EPicker is designed to pick general biological objects, including protein particles, liposome vesicles, and fibers. All these features make EPicker highly advantageous for both automated cryoEM pipelines and single-user applications.</p>
  </sec>
  <sec id="Sec2" sec-type="results">
    <title>Results</title>
    <sec id="Sec3">
      <title>Continual learning for accumulating knowledge of features</title>
      <p id="Par8">A model for comprehending the features of bio-macromolecules using a deep learning approach is the basis of cryoEM particle picking and determines the particle picking performance. We implemented an exemplar-based continual learning approach in EPicker to enhance its ability to adapt to new features. Continual learning refers to the gradual addition of new knowledge to an old model through further training with new datasets. The exemplar is used to guide continual learning to avoid forgetting old knowledge when learning new knowledge (discussed later). EPicker uses a CenterNet detector<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> as the basic network. However, CenterNet alone does not support continual learning. We designed a dual-path network for continual learning in EPicker based on CenterNet. Theoretically, similar networks can also be adopted in the dual-path architecture to enable continual learning.</p>
      <p id="Par9">In the dual-path network of EPicker, the two paths have the same network structures, referred to as branches A and B, as shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>. Under the configuration of CenterNet, each branch is composed of a feature extraction sub-network and an object location sub-network. In the training process, both branches are initialized using the same parameters as in the old model. Branch A is fixed during training and is considered as a reference for old features, which preserves the old knowledge. Branch B is used to generate the new model by distilling the knowledge from branch A to avoid catastrophic forgetting. Based on this design, the parameters of the old model initially loaded into branch B are iteratively updated on the exemplar dataset and the new dataset. The exemplar dataset is a subset of the datasets used for training the old model. Empirically, an exemplar dataset contains approximately 200 labeled particles (distributed on one or multiple micrographs) for each particle dataset. Random flip and random cropping are used for data augmentation to improve the generalization ability of the network. After the training process, EPicker discards branch A and saves only the parameters of branch B as the new model.<fig id="Fig1"><label>Fig. 1</label><caption><title>Architecture of EPicker and schematic diagram of continual learning.</title><p> The input data includes an exemplar dataset of datasets <inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${E}_{1}\mbox{--}{E}_{t}$$\end{document}</tex-math><mml:math id="M2"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mstyle><mml:mtext>–</mml:mtext></mml:mstyle><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq1.gif"/></alternatives></inline-formula> and a new dataset <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{t+1}$$\end{document}</tex-math><mml:math id="M4"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq2.gif"/></alternatives></inline-formula>(highlighted by green boxes). A and B represent branches A and B of the dual path network, respectively. Each branch is composed of a feature extraction sub-network (two trapezoids) and an object location sub-network (two rectangles). The gradient descent direction on the exemplar dataset <inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{t}$$\end{document}</tex-math><mml:math id="M6"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq3.gif"/></alternatives></inline-formula>, the new dataset <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{t+1}^{{\prime} }$$\end{document}</tex-math><mml:math id="M8"><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq4.gif"/></alternatives></inline-formula>, and the combination of the two datasets <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{t+1}$$\end{document}</tex-math><mml:math id="M10"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq5.gif"/></alternatives></inline-formula> is indicated by blue, red, and purple arrows, respectively. The bottom panel shows the magnified details of the network, in which branch B distills knowledge of features and heatmaps (yellow squares) from the corresponding network blocks (cuboid) of branch A.</p></caption><graphic xlink:href="41467_2022_29994_Fig1_HTML" id="d32e555"/></fig></p>
      <p id="Par10">A loss function with three components was designed to determine the update of branch B (see Methods). An exemplar dataset of the old model was input into the two branches to extract the features. A knowledge distillation loss function, <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{Distill}}$$\end{document}</tex-math><mml:math id="M12"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq6.gif"/></alternatives></inline-formula>, was used as a constraint to minimize the difference between the extracted features and generated heatmaps from branches A and B. Joint training on the exemplar dataset and the new dataset was conducted with an object detection loss function, <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{OD}}$$\end{document}</tex-math><mml:math id="M14"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq7.gif"/></alternatives></inline-formula>, on branch B. The purpose of using the exemplar dataset is to avoid the gradient descent direction along the gradient of the new dataset (red arrow in Fig. <xref rid="Fig1" ref-type="fig">1</xref>). The latter is the reason for catastrophic forgetting. The joint training on the two datasets combined their gradient descent directions by balancing the loss on both the new and old datasets. Third, to avoid over-fitting on the exemplar dataset, a regularization loss function, <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{Reg}}$$\end{document}</tex-math><mml:math id="M16"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq8.gif"/></alternatives></inline-formula>, is calculated as a measure of the difference between the new and old models, which penalizes significant changes between the parameters of the new and old models. Finally, the total loss is calculated as follows:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{Total}}={L}_{{OD}}+{\lambda }_{d}* {L}_{{Distill}}+{\lambda }_{r}* {L}_{{Reg}},$$\end{document}</tex-math><mml:math id="M18"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq9"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\lambda }_{d}$$\end{document}</tex-math><mml:math id="M20"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq9.gif"/></alternatives></inline-formula> and <inline-formula id="IEq10"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\lambda }_{r}$$\end{document}</tex-math><mml:math id="M22"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq10.gif"/></alternatives></inline-formula> are hyper-parameters used to balance the importance of the corresponding loss terms. In all our experiments, we empirically set <inline-formula id="IEq11"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\lambda }_{d}=0.1$$\end{document}</tex-math><mml:math id="M24"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq11.gif"/></alternatives></inline-formula> and <inline-formula id="IEq12"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\lambda }_{r}=0.01$$\end{document}</tex-math><mml:math id="M26"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq12.gif"/></alternatives></inline-formula> (Supplementary Table <xref rid="MOESM1" ref-type="media">1</xref>).</p>
      <p id="Par11">The impact of each component in the loss function was evaluated (Supplementary Table <xref rid="MOESM1" ref-type="media">2</xref>), which demonstrated that a combination of the three components is necessary. We also compared the performance of the proposed method with that of other widely used incremental learning methods (see Methods, Supplementary Table <xref rid="MOESM1" ref-type="media">3</xref>). The exemplar-based method in EPicker exhibited the best stability on the evaluation datasets. The exemplar dataset and continual learning process of EPicker mimic human behavior. If the old model is imagined as a memory of the past, the exemplar dataset is a note and snapshot of past events.</p>
    </sec>
    <sec id="Sec4">
      <title>CenterNet detector in EPicker</title>
      <p id="Par12">CenterNet<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> was used as the basic network for particle picking in EPicker. CenterNet is an one-stage anchor-free object detection network based on keypoint detection, and has shown better performance than existing anchor-based methods, such as YOLO<sup><xref ref-type="bibr" rid="CR30">30</xref>–<xref ref-type="bibr" rid="CR32">32</xref></sup>, RetinaNet<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>, and Faster R-CNN<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>. The CenterNet detector can regress both the position and size of the object and is thus suitable for particle picking in cryoEM. Several feature extraction networks are available for CenterNet, such as ResNet<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> and DLA<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. Compared with ResNet, DLA improves the ability of feature representation by adding more skip connections and exhibits better performance for the particle picking task (see Methods, Supplementary Table <xref rid="MOESM1" ref-type="media">4</xref>). Hence, EPicker chose a DLA network with 34 convolutional layers (DLA-34) as the feature extraction sub-network (Fig. <xref rid="Fig2" ref-type="fig">2</xref>). The feature extraction network extracts feature maps from the input micrographs using a series of convolution operations and subsequent deconvolution operations. Then, the object location network processes the feature maps to generate heatmaps to predict the position and size of the particles. Each branch of the dual-path network for continual learning takes the same network configuration as described here.<fig id="Fig2"><label>Fig. 2</label><caption><title>Architecture of CenterNet detector in EPicker.</title><p>The feature extraction sub-network is a cascade of a convolutional network (green) and a deconvolutional network (red) to extract features. Both the convolutional and the deconvolutional networks are a combination of Convolution-Batch Normalization<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>-ReLU(Rectified Linear Unit)<sup><xref ref-type="bibr" rid="CR47">47</xref></sup> blocks. The object location sub-network (blue) of the detector generates the heatmaps of particle center and size. The heatmap regression network is a combination of Convolution-ReLU-Convolution blocks.</p></caption><graphic xlink:href="41467_2022_29994_Fig2_HTML" id="d32e852"/></fig></p>
    </sec>
    <sec id="Sec5">
      <title>Optimizations for the network settings</title>
      <p id="Par13">In addition to the network structure optimization described earlier, several additional settings were used to improve the overall performance of EPicker. Considering that particles of the same protein sample are homogenous in size, EPicker turns off the prediction of particle size, that is, it only regresses the particle position in the object location sub-network, which helps to reduce computing complexity and improve position estimation accuracy. For size-sensitive cases, such as liposomes (discussed later), size estimation can be turned on to output the particle radius together with position (Supplementary Fig. <xref rid="MOESM1" ref-type="media">1</xref>). To accelerate the computation, the input micrograph is down-sampled to a fixed width of 1024 pixels and a correspondingly scaled height to maintain the aspect ratio. For a typical particle size of 10–30 nm, particle picking is usually tolerant to a centering error of less than 1 nm, corresponding to 4–5 times the pixel size of the micrographs. Therefore, the reduced micrograph size does not have an obvious influence on the position accuracy. The scaled micrograph is then processed by histogram equalization and converted to an 8-bit format with 256 gray levels. The reduced image size accelerates the particle picking, typically, to less than 0.3 s for one micrograph (Supplementary Table <xref rid="MOESM1" ref-type="media">5</xref>).</p>
    </sec>
    <sec id="Sec6">
      <title>Training by continuously adding new datasets</title>
      <p id="Par14">The continual learning method implemented in EPicker supports the addition of one or a group of datasets during the training, which allows for the gradual enhancement of the automated pipeline system. We evaluated the picking performance by incrementally adding datasets to mimic the activities of a gradually enhanced system. The performance of EPicker was evaluated using average precision (AP) and average recall (AR) under a given threshold 0.5 of intersection over union (IoU, see Methods).</p>
      <p id="Par15">To demonstrate the reliability and robustness of continual learning on datasets with different features, we included particles as diverse as possible, considering the structural features, shape, and size (Supplementary Table <xref rid="MOESM1" ref-type="media">7</xref>). For the experiments, a basic model was first obtained by joint training on five datasets including 80S ribosome (EMPIAR-10028), 20S proteasome (EMPIAR-10025), apoferritin (EMPIAR-10146), TccA1 (EMPIAR-10089), and Nodavirus (EMPIAR-10203). Five new datasets, β-galactosidase (EMPIAR-10017), influenza hemagglutinin (EMPIAR-10097), phage MS2 (EMPIAR-10075), CNG (EMPIAR-10081), and phosphodiesterase (EMPIAR-10228) were used individually or in groups (Table <xref rid="Tab1" ref-type="table">1</xref>) for further training. From each dataset, we selected 15 micrographs, of which 10 were used as the training dataset and five as the test dataset (Supplementary Table <xref rid="MOESM1" ref-type="media">6</xref>). All particles were manually picked and used as ground truth.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Evaluation of particle picking (AP/AR) under different training modes.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Name</th><th>E10089</th><th>E10146</th><th>E10028</th><th>E10203</th><th>E10025</th><th>E10017</th><th>E10097</th><th>E10075</th><th>E10081</th><th>E10228</th><th><inline-formula id="IEq13"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${mAP}/{mAR}$$\end{document}</tex-math><mml:math id="M28"><mml:mi>m</mml:mi><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mo>/</mml:mo><mml:mi>m</mml:mi><mml:mi>A</mml:mi><mml:mi>R</mml:mi></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq13.gif"/></alternatives></inline-formula></th></tr><tr><th>NO.</th><th>(1)</th><th>(2)</th><th>(3)</th><th>(4)</th><th>(5)</th><th>(6)</th><th>(7)</th><th>(8)</th><th>(9)</th><th>(10)</th><th/></tr></thead><tbody><tr><td>JT(<inline-formula id="IEq14"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{1}$$\end{document}</tex-math><mml:math id="M30"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq14.gif"/></alternatives></inline-formula>–<inline-formula id="IEq15"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{10}$$\end{document}</tex-math><mml:math id="M32"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq15.gif"/></alternatives></inline-formula>)</td><td>97.1/99.1</td><td>96.3/97.2</td><td>96.8/97.5</td><td>93.5/98.3</td><td>92.1/96.7</td><td>96.8/99.4</td><td>92.7/97.2</td><td>96.0/96.4</td><td>95.3/97.6</td><td>92.5/97.4</td><td>94.9/97.7</td></tr><tr><td>JT(<inline-formula id="IEq16"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{1}$$\end{document}</tex-math><mml:math id="M34"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq16.gif"/></alternatives></inline-formula>–<inline-formula id="IEq17"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{5}$$\end{document}</tex-math><mml:math id="M36"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq17.gif"/></alternatives></inline-formula>)</td><td>97.5/99.1</td><td>96.4/97.2</td><td>96.7/97.5</td><td>93.1/98.9</td><td>92.0/96.6</td><td><bold>19.8/50.2</bold></td><td><bold>9.7/64.9</bold></td><td><bold>95.1/98.7</bold></td><td><bold>80.9/92.3</bold></td><td><bold>26.5/77.6</bold></td><td>95.1/97.9</td></tr><tr><td>JT(<italic>D</italic><sub><italic>1</italic></sub><italic>–D</italic><sub><italic>6</italic></sub>)</td><td>97.5/99.1</td><td>96.8/97.5</td><td>97.6/98.0</td><td>95.3/99.4</td><td>92.0/96.7</td><td>97.0/99.5</td><td><bold>19.6/77.9</bold></td><td><bold>95.0/96.7</bold></td><td><bold>83.4/95.2</bold></td><td><bold>37.0/86.9</bold></td><td>96.0/98.4</td></tr><tr><td>FT(<italic>D</italic><sub><italic>6</italic></sub>)</td><td>35.8/97.5</td><td>89.9/95.9</td><td>67.1/97.7</td><td>69.2/98.3</td><td>68.4/87.6</td><td><underline>96.6/99.0</underline></td><td><bold>61.6/96.5</bold></td><td><bold>27.0/94.4</bold></td><td><bold>51.6/97.7</bold></td><td><bold>36.8/95.9</bold></td><td>71.2/96.0</td></tr><tr><td>CL</td><td>96.4/99.2</td><td>94.9/97.2</td><td>96.4/97.7</td><td>90.2/98.3</td><td>90.3/95.5</td><td><underline>96.2/98.5</underline></td><td><bold>66.5/97.2</bold></td><td><bold>92.2/96.7</bold></td><td><bold>84.4/95.2</bold></td><td><bold>55.9/97.0</bold></td><td>94.1/97.7</td></tr><tr><td>(<italic>E</italic><sub><italic>1</italic></sub><italic>–E</italic><sub><italic>t</italic></sub> + <italic>D</italic><sub>t+1</sub><italic>)</italic></td><td>96.1/98.4</td><td>96.2/97.6</td><td>96.6/97.3</td><td>89.4/97.7</td><td>90.2/95.7</td><td>96.4/98.8</td><td><underline>93.9/98.5</underline></td><td><bold>92.2/96.4</bold></td><td><bold>88.6/96.9</bold></td><td><bold>84.1/97.4</bold></td><td>94.1/97.7</td></tr><tr><td><italic>t</italic> = 5–9.</td><td>96.1/98.8</td><td>96.7/97.9</td><td>96.6/97.3</td><td>92.6/98.9</td><td>89.9/95.3</td><td>96.4/99.0</td><td>91.9/96.8</td><td><underline>95.7/96.7</underline></td><td><bold>80.1/95.0</bold></td><td><bold>83.4/96.4</bold></td><td>94.5/97.6</td></tr><tr><td/><td>96.4/98.8</td><td>96.7/97.7</td><td>96.7/97.3</td><td>91.9/98.9</td><td>89.7/95.8</td><td>95.8/98.3</td><td>92.8/97.5</td><td>96.4/97.1</td><td><underline>94.9/97.7</underline></td><td><bold>80.8/96.8</bold></td><td>94.6/97.7</td></tr><tr><td/><td>96.4/98.8</td><td>96.8/97.6</td><td>96.6/97.3</td><td>90.1/98.9</td><td>89.6/95.6</td><td>94.6/97.9</td><td>91.8/97.5</td><td>95.8/96.7</td><td>93.1/96.9</td><td><underline>91.8/97.2</underline></td><td>93.7/97.4</td></tr><tr><td>CL</td><td>96.2/98.3</td><td>96.2/97.9</td><td>96.6/97.3</td><td>91.1/98.3</td><td>91.4/96.3</td><td><underline>97.6/99.4</underline></td><td><underline>91.5/97.0</underline></td><td><underline>96.1/97.7</underline></td><td><underline>94.9/97.4</underline></td><td><underline>93.8/98.0</underline></td><td>94.5/97.7</td></tr><tr><td>(<italic>E</italic><sub>1</sub>–<italic>E</italic><sub>5</sub> + <italic>D</italic><sub>6</sub>–<italic>D</italic><sub>10</sub>)</td><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/><td/></tr></tbody></table><table-wrap-foot><p>The 10 datasets are indicated by <inline-formula id="IEq18"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{1}$$\end{document}</tex-math><mml:math id="M38"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq18.gif"/></alternatives></inline-formula>–<inline-formula id="IEq19"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{10}$$\end{document}</tex-math><mml:math id="M40"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq19.gif"/></alternatives></inline-formula>, the corresponding exemplar dataset are indicated by <inline-formula id="IEq20"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${E}_{1}$$\end{document}</tex-math><mml:math id="M42"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq20.gif"/></alternatives></inline-formula>–<inline-formula id="IEq21"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${E}_{10}$$\end{document}</tex-math><mml:math id="M44"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq21.gif"/></alternatives></inline-formula>. The joint training (JT), fine-tuning (FT), and continual learning (CL) are tested with different datasets. The cells with bold values indicate that the corresponding dataset is unseen for the model. The cells with underlined values indicate that the corresponding dataset is newly added for the model. <italic>mAP</italic> and <italic>mAR</italic> indicate the mean of the average precision (AP) and the mean of the average recall (AR), respectively, of all columns in the corresponding row.</p></table-wrap-foot></table-wrap></p>
      <p id="Par16">Joint training was first conducted on all the aforementioned 10 training datasets. While these molecules have very different structural features, sizes, and molecular weights from 100 kDa to several MDa, the picking performance is maintained at a high level (Table <xref rid="Tab1" ref-type="table">1</xref>), which reflects the great generalization capability of the feature extraction sub-network. Generalization is the basis for adding new knowledge to an existing model. The picking results based on the joint-training model are considered to be the upper bound of the performance of the EPicker.</p>
      <p id="Par17">Continual learning was then performed based on the basic model of five datasets. Adding new datasets in a continual manner caused a 1–3 % decrease in AP value and little influence on AR value compared with the corresponding results of the joint-training model. Adding a group of five new datasets together was also evaluated, demonstrating nearly the same influence as adding the datasets successively. The dissimilarity of features between the old and new datasets may influence the effectiveness of merging different features, which is indicated by forgetting some old features. To measure this influence, we defined the complexity of a new dataset as how the features in the new dataset match the features in the old datasets and defined the forgetting rate as the reduction of AP and AR (see Methods). We then evaluated the relationship between complexity and forgetting rate (Supplementary Fig. <xref rid="MOESM1" ref-type="media">2</xref>). The experimental results show that adding new datasets with different features does not cause significant forgetting. Meanwhile, adding datasets with low complexity can improve the model. Therefore, the picking performance of the new model in picking old samples should be maintained and nearly not influenced after learning more features.</p>
      <p id="Par18">Moreover, the continual learning ability of EPicker significantly reduced both the time and storage costs of extending new features (Supplementary Fig. <xref rid="MOESM1" ref-type="media">3</xref>). The time spent on a single joint training with 5–10 datasets was 26–50 min and increased linearly with more datasets involved. For joint training, once a new dataset was added, the training was performed repeatedly on all previously involved datasets. All complete training datasets (10 micrographs per dataset for the current experiments) should be stored for future training. In contrast, for the continual learning process, the time to add a new dataset is usually significantly less than joint training and increases slightly with the accumulation of more features. In the situation of gradually adding new datasets, the joint training on adding the 10<sup>th</sup> dataset costs 50 min, while continual learning takes only 20 min. What’s more, only a small number of samples (typically 1–2 micrographs) in each dataset need to be stored in the exemplar dataset for future continual learning.</p>
    </sec>
    <sec id="Sec7">
      <title>Catastrophic forgetting in fine-tuning</title>
      <p id="Par19">In EPicker, the fine-tuning and joint training modes adopt the same training method and fine-tuning suffers from catastrophic forgetting problem. The difference between fine-tuning and joint training lies in whether to load a pre-trained model, that is, the former loads the parameters of an existing model and trains on one or multiple new datasets, whereas the latter trains on a combination of datasets from scratch. The network used for fine-tuning and joint training uses a single-path network compared with the dual-path network used for continual learning. The single-path network has the same structure as one branch of the continual-learning dual-path network and lacks a reference network for maintaining the old knowledge. During the fine-tuning process, the parameters of all network layers were greatly modified to ensure better performance on the new datasets. The fine-tuning model cannot extract and maintain old features from the old model.</p>
      <p id="Par20">Based on the basic model jointly trained on the five datasets mentioned in the previous section, we compared the fine-tuning mode with the continual learning mode on the β-galactosidase (EMPIAR-10017) dataset. A joint training model trained on all six datasets was also compared. Using the three new models, we selected a typical micrograph with 118 particles in the 80S ribosome dataset (EMPIAR-10028, considered as a dataset that appeared in the previous training) (Fig. <xref rid="Fig3" ref-type="fig">3a</xref>). The picking using the fine-tuning model missed 35% of the ground-truth particles (Fig. <xref rid="Fig3" ref-type="fig">3d</xref>), demonstrating catastrophic forgetting. The continual-learning and joint-training models pick 96–97% of the ground-truth particles (Fig. <xref rid="Fig3" ref-type="fig">3b, c</xref>). The fine-tuning model only achieved high performance on the new β-galactosidase dataset, and the other two models worked well on all six datasets (3<sup>rd</sup>–5<sup>th</sup> rows in Table <xref rid="Tab1" ref-type="table">1</xref>). Therefore, fine-tuning generates a specific model and forgets some old knowledge.<fig id="Fig3"><label>Fig. 3</label><caption><title>Illustration of the catastrophic forgetting.</title><p>The picked particles of 80S ribosome (EMPIAR-10028) are annotated by square boxes. The red, blue, and yellow boxes indicate the particles were correctly picked, wrongly picked, and missed, respectively. <bold>a</bold> The ground truth. <bold>b</bold> The results of the joint training model. <bold>c</bold> The results of the continual learning model. <bold>d</bold> The results of the fine-tuning model.</p></caption><graphic xlink:href="41467_2022_29994_Fig3_HTML" id="d32e1676"/></fig></p>
    </sec>
    <sec id="Sec8">
      <title>Biased and unbiased picking</title>
      <p id="Par21">Both continual learning and joint training based on a large number of datasets are unbiased to particles with different features and tend to generate a general model for extracting various features. In contrast, fine-tuning generates a model that is specific or biased to the features of the latest training datasets. Unbiased picking is often important, especially at the beginning of a new project, to find as many particles with unknown conformations or compositions as possible. Sometimes biased picking is also necessary, mostly to quickly find particles with specific features in order to improve the resolution of 3D reconstruction. EPicker supports three training modes to satisfy the requirements for different picking specifications.</p>
      <p id="Par22">We used micrographs of the 26S proteasome with mixed assembly states to test the picking specificity of the models from different training modes. The 26S proteasome (26S) is composed of a 20S core particle (CP) and two 19S regulatory particles (RP) that bind to CP. Because RP can disassemble from 26S, different complexes are often observed, including stand-alone CP, CP with two RPs (CP2RP), and CP with one RP (CP1RP). The diversity of the complexes provides an opportunity to test picking specificity. In the experiment, we regarded the side-view CP2RP as the positive sample; accordingly, all other impurities and complexes in different assembly states (CP and CP1RP) were considered as unknown or junk particles.</p>
      <p id="Par23">Before working on 26S, we assumed that 26S was unknown, and our general model was trained on 46 datasets without any 26S or its components. First, particles were picked from 200 micrographs in a dataset with a high-purity side-view 26S (EMPIAR-10090) using the general model. As expected, only a small number of CP2RP particles were picked because the general model has never seen 26S. Then, by performing a 2D classification on the poorly picked 26S particles (Supplementary Fig. <xref rid="MOESM1" ref-type="media">4</xref>), some side-view CP2RP particles were selected and used to train a general model in continual learning mode, a specific model in fine-tuning mode, and a model from scratch in joint training mode (simply called scratch model).</p>
      <p id="Par24">To compare the specificity of picking, the three models were applied to another 26S dataset (EMPIAR-10401) with many disassembled particles and much lower contrast. The continual learning model picked nearly all particles on the micrographs, as expected (Fig. <xref rid="Fig4" ref-type="fig">4a</xref>), including the circular top-view particles of 26S and the side-view particles of CP2RP, CP1RP, and CP. The picking by the fine-tuning model and the scratch model are more specific, mostly focused on the side-view CP2RP particles and a small number of side-view CP1RP particles (Fig. <xref rid="Fig4" ref-type="fig">4a</xref>). Further 2D classification analysis (Fig. <xref rid="Fig4" ref-type="fig">4b</xref>) showed that the three models picked nearly the same number of CP2RP particles (Fig. <xref rid="Fig4" ref-type="fig">4c</xref>), whereas the fine-tuning model was the most accurate for picking the specific CP2RP particles (Fig. <xref rid="Fig4" ref-type="fig">4b</xref>). The fine-tuning and scratch model missed many CP1RP particles and nearly all stand-alone CP particles (Fig. <xref rid="Fig4" ref-type="fig">4c</xref>).<fig id="Fig4"><label>Fig. 4</label><caption><title>Comparison of biased and unbiased picking on a 26S proteasome dataset.</title><p><bold>a</bold> The particle picking results (red boxes) of the three models. To improve the visualization, a small region of a typical micrograph is shown. The continual-learning model results in the picking of nearly all particles appearing on the micrograph. The results using the fine-tuning and scratch models are more specific on the side-view of CP2RP (a core particle with two regulatory particles) particles and ignore other particles. <bold>b</bold> Part of the 2D (two-dimensional) class averages with the highest occupancy, which are sorted in descending order of the occupancy. Different border colors specify CP2RP (blue), CP1RP (a core particle with one regulatory particles, orange), and CP (core particle, yellow) particles, respectively. In the results of the fine-tuning model, the CP2RP classes have higher occupancy than other particles. <bold>c</bold> Plot of the total number of particles picked with different models. The three models picked nearly the same number of CP2RP particles (blue bars). The fine-tuning and scratch model missed many CP1RP particles (orange bars) and nearly all CP particles (yellow bars), indicating biased picking.</p></caption><graphic xlink:href="41467_2022_29994_Fig4_HTML" id="d32e1728"/></fig></p>
      <p id="Par25">The aforementioned comparison provides a detailed insight into the different training modes and their behaviors on unseen particles. The general model is powerful in picking unseen particles and can be efficiently enhanced by incorporating more knowledge through continual learning.</p>
    </sec>
    <sec id="Sec9">
      <title>General object picking for cryoEM</title>
      <p id="Par26">Benefiting from the capability of continual learning, EPicker has the potential to pick more general objects by accumulating more knowledge during long-term applications. Currently, EPicker supports picking for three types of objects with different features, not only the aforementioned particles but also fibers and vesicles. The fibers were processed as a series of discrete points in EPicker. The picking and training algorithm for the fibers was the same as that for the particles. An internal algorithm (see Methods) was developed to link the picked points as lines tracing the fibers. EPicker can deal with both curved and straight fibers (Fig. <xref rid="Fig5" ref-type="fig">5a</xref>, Supplementary Fig. <xref rid="MOESM1" ref-type="media">5b</xref>). Vesicles are usually liposomes that have recently become popular in the study of membrane proteins<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>. Considering that some membrane proteins are sensitive to the curvature of membrane bilayers, that is, the radius of the liposome, EPicker predicts the size of vesicles (Supplementary Fig. <xref rid="MOESM1" ref-type="media">1</xref>). Tests on liposomes showed that EPicker can accurately estimate both the center coordinate and size of each vesicle, even for overlapped vesicles (Fig. <xref rid="Fig5" ref-type="fig">5b</xref>).<fig id="Fig5"><label>Fig. 5</label><caption><title>Picking of general biological objects and a workflow with continual learning.</title><p><bold>a</bold> Picking curved fibers. The picked fibers are labeled as lines tracing the fibers. <bold>b</bold> Picking liposomes with estimation of radius (indicated by size of the red box). Several overlapped vesicles (indicated by yellow arrows) are well identified. <bold>c</bold> A cryoEM processing workflow with continual learning. Particle annotations can be obtained from manual picking, sparse picking, and 2D/3D (two-dimensional/three dimensional) classification, which can be further used to train the model in a continual manner.</p></caption><graphic xlink:href="41467_2022_29994_Fig5_HTML" id="d32e1771"/></fig></p>
      <p id="Par27">EPicker is suitable for cryo-EM pipelines with continuous data input (Fig. <xref rid="Fig5" ref-type="fig">5c</xref>). Particle coordinates from 2D/3D classification of single-particle analysis and manual picking, which can be sparse (see Methods), are available for training. Pre-trained general models are available together with EPicker through the website <ext-link ext-link-type="uri" xlink:href="http://thuem.net">http://thuem.net</ext-link>.</p>
    </sec>
  </sec>
  <sec id="Sec10" sec-type="discussion">
    <title>Discussion</title>
    <p id="Par28">Particle picking is an important step in identifying bio-macromolecules preceding 3D reconstruction in the cryoEM processing workflow. Any particles missed during particle picking are excluded in the final 3D reconstruction, which affects the reconstruction of molecules with unknown features. The level of matching between the knowledge accumulated in a network model and the features of known or unseen protein particles are vital for particle picking. While a general model can be used to pick unseen particles, as in the cases of the EMPIAR-10090 dataset (Supplementary Fig. <xref rid="MOESM1" ref-type="media">4a</xref>) and the Fab dataset (the antigen binding fragment, ~60 kDa, Supplementary Fig. <xref rid="MOESM1" ref-type="media">6a</xref>), its performance is often not guaranteed.</p>
    <p id="Par29">We implemented a continual learning algorithm in EPicker to enhance the ability of feature extraction and generalization on more different particles, which is an efficient and convenient way to accumulate knowledge into an existing model. EPicker adopted a dual-path network to support knowledge distillation, used an exemplar dataset, and a specially designed loss function to avoid catastrophic forgetting.</p>
    <p id="Par30">Through experiments that mimicked real-world applications by gradually adding new datasets, the continual learning algorithm in EPicker successfully accumulated knowledge into an existing model, regardless of the complexity of the dataset; meanwhile, no obvious catastrophic forgetting was observed. We further compared the influence of several training modes for particle picking, including continual learning, joint training, and fine-tuning. The fine-tuning model was specific and biased to given features and suffered from catastrophic forgetting. The continual learning model achieved a performance similar to that of the joint training model. Furthermore, the continual learning strategy disperses the computationally intensive training on a large number of datasets into multiple training processes and thus it is not necessary to finish the training at one time as required by the joint training.</p>
    <p id="Par31">Enhanced by improving the capability to learn new features, EPicker is designed to pick more general objects in cryo-EM micrographs, including fibers and vesicles. To further improve the convenience of training, EPicker only requires positive annotations and supports sparse annotations by a specially designed loss function, that is, only a small part of the particles in the micrographs need to be annotated for training. Moreover, 5–10 micrographs from a dataset are usually sufficient for training. Based on these features, a small number of manually picked particles or particles selected by the 2D/3D classification can be used to build the training datasets. Finally, all these features make EPicker more reliable (Supplementary Fig. <xref rid="MOESM1" ref-type="media">6</xref>), easy to use, and suitable for most of the current requirements of object detection in single-particle cryoEM and automated workflow.</p>
  </sec>
  <sec id="Sec11">
    <title>Methods</title>
    <sec id="Sec12">
      <title>Continual learning algorithm</title>
      <p id="Par32">EPicker is an exemplar-based incremental particle picking program. Guided by the exemplar dataset, EPicker can be trained on the new dataset without forgetting old knowledge. EPicker uses CenterNet<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> for object detection and the object detection process can be seen as a function, denoted by <inline-formula id="IEq22"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{{OD}}$$\end{document}</tex-math><mml:math id="M46"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq22.gif"/></alternatives></inline-formula>. The CenterNet detector in EPicker (Fig. <xref rid="Fig2" ref-type="fig">2</xref>) consists of two components: a feature extraction sub-network, <inline-formula id="IEq23"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{{extract}}$$\end{document}</tex-math><mml:math id="M48"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq23.gif"/></alternatives></inline-formula>, which extracts the features of the input image, and an object location sub-network, <inline-formula id="IEq24"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{{loc}}$$\end{document}</tex-math><mml:math id="M50"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq24.gif"/></alternatives></inline-formula>, which regresses the center, local offset, and size of each particle. Let <inline-formula id="IEq25"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({D}_{1}\ldots {D}_{t})$$\end{document}</tex-math><mml:math id="M52"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq25.gif"/></alternatives></inline-formula> denote a set of old datasets sequentially added until time <italic>t</italic>. From each old dataset <inline-formula id="IEq26"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{i}$$\end{document}</tex-math><mml:math id="M54"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq26.gif"/></alternatives></inline-formula> we randomly choose 200 continuous annotations on one or multiple downsampled micrographs <inline-formula id="IEq27"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${E}_{i}\in {D}_{i}$$\end{document}</tex-math><mml:math id="M56"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq27.gif"/></alternatives></inline-formula>. All of these micrographs comprise an exemplar dataset <inline-formula id="IEq28"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({E}_{1}\ldots {E}_{t})$$\end{document}</tex-math><mml:math id="M58"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq28.gif"/></alternatives></inline-formula>. Assuming that at time <italic>t</italic>, the object detector <inline-formula id="IEq29"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{{OD}}^{t}$$\end{document}</tex-math><mml:math id="M60"><mml:msubsup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq29.gif"/></alternatives></inline-formula> is parameterized by <inline-formula id="IEq30"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{t}$$\end{document}</tex-math><mml:math id="M62"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq30.gif"/></alternatives></inline-formula>, EPicker incrementally adapts the parameter <inline-formula id="IEq31"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{t}$$\end{document}</tex-math><mml:math id="M64"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq31.gif"/></alternatives></inline-formula> toward <inline-formula id="IEq32"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{t+1}$$\end{document}</tex-math><mml:math id="M66"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq32.gif"/></alternatives></inline-formula> by training on a new dataset <inline-formula id="IEq33"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{t+1}$$\end{document}</tex-math><mml:math id="M68"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq33.gif"/></alternatives></inline-formula> with the guidance of the exemplar dataset <inline-formula id="IEq34"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({E}_{1}\ldots {E}_{t})$$\end{document}</tex-math><mml:math id="M70"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq34.gif"/></alternatives></inline-formula>.</p>
      <p id="Par33">Figure <xref rid="Fig1" ref-type="fig">1</xref> represents the involvement of exemplar in the training process. We use <inline-formula id="IEq35"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{Loss}}_{t}$$\end{document}</tex-math><mml:math id="M72"><mml:msub><mml:mrow><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq35.gif"/></alternatives></inline-formula> to represent the loss function of the network trained on old datasets <inline-formula id="IEq36"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({D}_{1}\ldots {D}_{t})$$\end{document}</tex-math><mml:math id="M74"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq36.gif"/></alternatives></inline-formula> and <inline-formula id="IEq37"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{Loss}}_{t+1}$$\end{document}</tex-math><mml:math id="M76"><mml:msub><mml:mrow><mml:mi>L</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq37.gif"/></alternatives></inline-formula> to represent the loss function of the network trained on the new datasets <inline-formula id="IEq38"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{t+1}$$\end{document}</tex-math><mml:math id="M78"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq38.gif"/></alternatives></inline-formula>. When the network is trained on <inline-formula id="IEq39"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({D}_{1}\ldots {D}_{t})$$\end{document}</tex-math><mml:math id="M80"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq39.gif"/></alternatives></inline-formula>, the gradient descent will be along the direction where the loss function decreases fastest for the old datasets (indicated by the blue arrow in Fig. <xref rid="Fig1" ref-type="fig">1</xref>). When the network is trained on <inline-formula id="IEq40"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{t+1}$$\end{document}</tex-math><mml:math id="M82"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq40.gif"/></alternatives></inline-formula>, the gradient descent follows the optimal direction for the new dataset (indicated by the red arrow in Fig. <xref rid="Fig1" ref-type="fig">1</xref>). Without the use of the exemplar, the optimal parameters of the network trained on <inline-formula id="IEq41"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{t+1}$$\end{document}</tex-math><mml:math id="M84"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq41.gif"/></alternatives></inline-formula> are <inline-formula id="IEq42"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{t+1}^{{\prime} }$$\end{document}</tex-math><mml:math id="M86"><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq42.gif"/></alternatives></inline-formula>, which often incurs a large loss on the old datasets, thus leading to catastrophic forgetting on the old datasets.</p>
      <p id="Par34">To mitigate the problem of forgetting, the exemplar <inline-formula id="IEq43"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({E}_{1}\ldots {E}_{t})$$\end{document}</tex-math><mml:math id="M88"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq43.gif"/></alternatives></inline-formula> that contains a set of images from each old dataset is introduced to the network; thus, EPicker can integrate the gradient information of the old datasets into the new model. When the model is training on the new dataset <inline-formula id="IEq44"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{t+1}$$\end{document}</tex-math><mml:math id="M90"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq44.gif"/></alternatives></inline-formula>, the instructive exemplar influences the gradient descent direction. Then, the final average gradient descent direction can be adjusted to a more appropriate direction (indicated by the purple arrow in Fig. <xref rid="Fig1" ref-type="fig">1</xref>), and the parameters of the model reach <inline-formula id="IEq45"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{t+1}$$\end{document}</tex-math><mml:math id="M92"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq45.gif"/></alternatives></inline-formula>, which balances the performance on all datasets. The exemplar dataset is advantageous in retaining knowledge from the old model to the new one. EPicker adopts the knowledge distillation method<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> to constrain the parameters of the new model by maintaining a certain similarity to the old model, and also finds the optimal parameters for the new datasets. In contrast to regularization methods<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR17">17</xref>,<xref ref-type="bibr" rid="CR21">21</xref></sup> that penalize the change of important parameters of the old model, EPicker treats each parameter equally and only constrains the discrepancy between the output feature maps of the new and the old models, which reduces the probability of having conflicting parameters between different tasks.</p>
      <p id="Par35">The corresponding loss functions used in the above process are discussed in the following two sections in detail.</p>
    </sec>
    <sec id="Sec13">
      <title>CenterNet detector and object detection loss function</title>
      <p id="Par36">EPicker uses a CenterNet<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> detector as the basic object detection framework to predict the central coordinate and particle size. There are many choices for the feature extraction network in CenterNet, such as ResNet<sup><xref ref-type="bibr" rid="CR35">35</xref></sup> and DLA<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. ResNet introduces a residual block to stabilize the training process and extract hierarchical features. The DLA network aggregates feature representations and fuses information across different layers by adding hierarchical and iterative skip connections. The DLA-based feature extraction network achieved better object detection accuracy than ResNet in our particle picking tests (Supplementary Table <xref rid="MOESM1" ref-type="media">4</xref>). We chose a fully convolutional upsampling version of DLA-34<sup><xref ref-type="bibr" rid="CR36">36</xref></sup> as the feature extraction network of CenterNet in EPicker and followed by an object location sub-nextwork<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> to predict the center <inline-formula id="IEq46"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{Y}$$\end{document}</tex-math><mml:math id="M94"><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq46.gif"/></alternatives></inline-formula>, local offset <inline-formula id="IEq47"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{O}$$\end{document}</tex-math><mml:math id="M96"><mml:mover accent="true"><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq47.gif"/></alternatives></inline-formula>, and size <inline-formula id="IEq48"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{S}$$\end{document}</tex-math><mml:math id="M98"><mml:mover accent="true"><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq48.gif"/></alternatives></inline-formula>. The final particle position is the sum of the center and offset. The object location network is composed of three convolution networks that generate downsampled heatmaps for the center, the local offset, and the size of each particle. Then, particle centers are predicted from a heatmap matrix, <inline-formula id="IEq49"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{Y}\in {[{{{{\mathrm{0,1}}}}}]}^{\frac{W}{R}\times \frac{H}{R}}$$\end{document}</tex-math><mml:math id="M100"><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="normal">0, 1</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo>×</mml:mo><mml:mfrac><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq49.gif"/></alternatives></inline-formula>, where <italic>W</italic> and <italic>H</italic> represent the width and height of the input image, respectively, and <italic>R</italic> is the output stride after a series of convolution operations and is set to 4 in EPicker. Each cell of the heatmap <inline-formula id="IEq50"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{Y}$$\end{document}</tex-math><mml:math id="M102"><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq50.gif"/></alternatives></inline-formula> records a score between [0, 1] to present the detection confidence, which is known as the confidence score. A higher confidence score indicates a higher probability of a particle being in the current cell. The peaks in the heatmap were predicted as particle centers <inline-formula id="IEq51"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(\hat{x},\hat{y})$$\end{document}</tex-math><mml:math id="M104"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq51.gif"/></alternatives></inline-formula>. The offset prediction, <inline-formula id="IEq52"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{O}=(\delta \hat{x},\delta \hat{y})$$\end{document}</tex-math><mml:math id="M106"><mml:mover accent="true"><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mo>,</mml:mo><mml:mi>δ</mml:mi><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq52.gif"/></alternatives></inline-formula>, and the size prediction, <inline-formula id="IEq53"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\hat{S}=(\hat{w},\hat{h})$$\end{document}</tex-math><mml:math id="M108"><mml:mover accent="true"><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq53.gif"/></alternatives></inline-formula>, together with the predicted particle centers, determine the bounding box of a particle represented as <inline-formula id="IEq54"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left(\hat{x}+\delta \hat{x},\hat{y}+\delta \hat{y},\frac{\hat{w}}{2},\frac{\hat{h}}{2}\right).$$\end{document}</tex-math><mml:math id="M110"><mml:mfenced close=")" open="("><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mover accent="true"><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mover accent="true"><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq54.gif"/></alternatives></inline-formula></p>
      <p id="Par37">The loss function of the object detector<sup><xref ref-type="bibr" rid="CR29">29</xref></sup> without continual learning strategies is defined as<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{OD}}={L}_{k}+{{\lambda }_{{off}}* L}_{{off}}+{{\lambda }_{{size}}* L}_{{size}},$$\end{document}</tex-math><mml:math id="M112"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq55"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\lambda }_{{off}}$$\end{document}</tex-math><mml:math id="M114"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq55.gif"/></alternatives></inline-formula> and <inline-formula id="IEq56"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\lambda }_{{size}}$$\end{document}</tex-math><mml:math id="M116"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq56.gif"/></alternatives></inline-formula> are weighting factors, and <inline-formula id="IEq57"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\lambda }_{{off}}=1$$\end{document}</tex-math><mml:math id="M118"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq57.gif"/></alternatives></inline-formula>, <inline-formula id="IEq58"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\lambda }_{{size}}=0.1$$\end{document}</tex-math><mml:math id="M120"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq58.gif"/></alternatives></inline-formula> are used in EPicker (Supplementary Table <xref rid="MOESM1" ref-type="media">8</xref>). The definitions of the three components are as follows.<list list-type="bullet"><list-item><p id="Par38"><inline-formula id="IEq59"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{k}$$\end{document}</tex-math><mml:math id="M122"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq59.gif"/></alternatives></inline-formula> is a pixel-wise focal loss<sup><xref ref-type="bibr" rid="CR33">33</xref></sup> that reduces the error between the predicted particle center, <inline-formula id="IEq60"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{Y}}_{{xy}}$$\end{document}</tex-math><mml:math id="M124"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq60.gif"/></alternatives></inline-formula>, and the ground truth particle center, <inline-formula id="IEq61"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${Y}_{{xy}}$$\end{document}</tex-math><mml:math id="M126"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq61.gif"/></alternatives></inline-formula>; <inline-formula id="IEq62"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{k}$$\end{document}</tex-math><mml:math id="M128"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq62.gif"/></alternatives></inline-formula> is defined as</p></list-item></list><disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{k}=-\frac{1}{N}\mathop{\sum}\limits_{{xy}}\left\{\begin{array}{cc}{(1-{\hat{Y}}_{{xy}})}^{\alpha }{{\log }}({\hat{Y}}_{{xy}}) &amp; {if}\,{Y}_{{xy}}=1\\ {(1-{Y}_{{xy}})}^{\beta}{({\hat{Y}}_{{xy}})}^{\alpha }{{\log }}({1-\hat{Y}}_{{xy}}) &amp; {otherwise}\end{array}\right.,$$\end{document}</tex-math><mml:math id="M130"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:munder><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msup><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msup><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq63"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N$$\end{document}</tex-math><mml:math id="M132"><mml:mi>N</mml:mi></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq63.gif"/></alternatives></inline-formula> is the number of particle in the input image, <italic>α</italic> and <italic>β</italic> are two hyperparameters, and <inline-formula id="IEq64"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha =2$$\end{document}</tex-math><mml:math id="M134"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq64.gif"/></alternatives></inline-formula> and <inline-formula id="IEq65"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\beta =4$$\end{document}</tex-math><mml:math id="M136"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq65.gif"/></alternatives></inline-formula> are used in EPicker.<list list-type="bullet"><list-item><p id="Par39"><inline-formula id="IEq66"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{off}}$$\end{document}</tex-math><mml:math id="M138"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq66.gif"/></alternatives></inline-formula> is the loss of the local offset for each particle center caused by the output stride and is defined as<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{off}}=\frac{1}{N}\mathop{\sum}\limits_{p}\left|{\hat{O}}_{\tilde{p}}-\left(\frac{p}{R}-\tilde{p}\right)\right|,$$\end{document}</tex-math><mml:math id="M140"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:munder><mml:mfenced close="∣" open="∣"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>~</mml:mo></mml:mrow></mml:mover></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfenced close=")" open="("><mml:mrow><mml:mfrac><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>~</mml:mo></mml:mrow></mml:mover></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <italic>R</italic> represents the output stride, <inline-formula id="IEq67"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{O}}_{\tilde{p}}$$\end{document}</tex-math><mml:math id="M142"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>O</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>~</mml:mo></mml:mrow></mml:mover></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq67.gif"/></alternatives></inline-formula> represents the predicted offset at the low-resolution center point <inline-formula id="IEq68"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\tilde{p}$$\end{document}</tex-math><mml:math id="M144"><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>~</mml:mo></mml:mrow></mml:mover></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq68.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq69"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(\frac{p}{R}-\tilde{p})$$\end{document}</tex-math><mml:math id="M146"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>~</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq69.gif"/></alternatives></inline-formula> represents the ground truth center offset.</p></list-item><list-item><p id="Par40"><inline-formula id="IEq70"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{size}}$$\end{document}</tex-math><mml:math id="M148"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq70.gif"/></alternatives></inline-formula> is the loss of the particle size, which is optional in EPicker, and is defined as</p></list-item></list><disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{size}}=\frac{1}{N}\mathop{\sum }\limits_{k=1}^{N}|{\hat{S}}_{{p_{k}}}-{s}_{k}|,$$\end{document}</tex-math><mml:math id="M150"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mo>∣</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq71"><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\hat{S}}_{{p}_{k}}$$\end{document}</tex-math><mml:math id="M152"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq71.gif"/></alternatives></inline-formula> represents the predicted particle size at the center point <inline-formula id="IEq72"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{k}$$\end{document}</tex-math><mml:math id="M154"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq72.gif"/></alternatives></inline-formula>, and <inline-formula id="IEq73"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${s}_{k}$$\end{document}</tex-math><mml:math id="M156"><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq73.gif"/></alternatives></inline-formula> represents the ground truth size of particle <italic>k</italic>.</p>
    </sec>
    <sec id="Sec14">
      <title>Loss functions used in different training modes</title>
      <p id="Par41">EPicker supports three training modes: joint training, fine-tuning, and continual learning. The loss functions of joint training and fine-tuning are the same and consist of only one object detection loss term, given by<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{Total}}={L}_{{OD}}.$$\end{document}</tex-math><mml:math id="M158"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par42">The loss function of continual learning consists of three loss terms, given by<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{Total}}={L}_{{OD}}+{{\lambda }_{d}* L}_{{Distill}}{{+\lambda }_{r}* L}_{{Reg}},$$\end{document}</tex-math><mml:math id="M160"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq74"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\lambda }_{d}$$\end{document}</tex-math><mml:math id="M162"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq74.gif"/></alternatives></inline-formula> and <inline-formula id="IEq75"><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\lambda }_{r}$$\end{document}</tex-math><mml:math id="M164"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq75.gif"/></alternatives></inline-formula> are hyperparameters. EPicker empirically sets <inline-formula id="IEq76"><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\lambda }_{d}=0.1$$\end{document}</tex-math><mml:math id="M166"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq76.gif"/></alternatives></inline-formula> and <inline-formula id="IEq77"><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\lambda }_{r}=0.01$$\end{document}</tex-math><mml:math id="M168"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq77.gif"/></alternatives></inline-formula> in all experiments (Supplementary Table <xref rid="MOESM1" ref-type="media">1</xref>). The details of each loss term are discussed below.<list list-type="bullet"><list-item><p id="Par43">The object-detection loss <inline-formula id="IEq78"><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{OD}}$$\end{document}</tex-math><mml:math id="M170"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq78.gif"/></alternatives></inline-formula>, defined in Eq. <xref rid="Equ2" ref-type="">2</xref> minimizes the particle center location error, offset regression error, and size regression error based on the ground truth and the prediction from the object location network, <inline-formula id="IEq79"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{{loc}}$$\end{document}</tex-math><mml:math id="M172"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq79.gif"/></alternatives></inline-formula>.</p></list-item><list-item><p id="Par44">The knowledge distillation loss, <inline-formula id="IEq80"><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{Distill}}$$\end{document}</tex-math><mml:math id="M174"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq80.gif"/></alternatives></inline-formula>, distills features generated by the feature extraction network, and the particle position heatmaps predicted by the object location network from the old model. For continual learning on model <inline-formula id="IEq81"><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${t}+1$$\end{document}</tex-math><mml:math id="M176"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq81.gif"/></alternatives></inline-formula>, EPicker only distills knowledge on the exemplar <inline-formula id="IEq82"><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({E}_{1}\ldots {E}_{t})$$\end{document}</tex-math><mml:math id="M178"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq82.gif"/></alternatives></inline-formula> and does not involve that on the new dataset <inline-formula id="IEq83"><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{t+1}$$\end{document}</tex-math><mml:math id="M180"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq83.gif"/></alternatives></inline-formula>. We use <inline-formula id="IEq84"><alternatives><tex-math id="M181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{2}$$\end{document}</tex-math><mml:math id="M182"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq84.gif"/></alternatives></inline-formula> loss for knowledge distillation, which is formulated as follows:<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M183">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{Distill}=\frac{1}{{M}_{f}}\sum {\Vert {f}_{t+1}-{f}_{t}\Vert }_{2}^{2}+\frac{1}{{M}_{y}}\sum {\Vert {y}_{t+1}-{y}_{t}\Vert }_{2}^{2}+\frac{1}{{M}_{o}}\sum {\Vert {o}_{t+1}-{o}_{t}\Vert }_{2}^{2},$$\end{document}</tex-math><mml:math id="M184"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo mathsize="big"> ∑</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo mathsize="big"> ∑</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo mathsize="big"> ∑</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq85"><alternatives><tex-math id="M185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f}_{t+1}$$\end{document}</tex-math><mml:math id="M186"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq85.gif"/></alternatives></inline-formula> and <inline-formula id="IEq86"><alternatives><tex-math id="M187">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${f}_{t}$$\end{document}</tex-math><mml:math id="M188"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq86.gif"/></alternatives></inline-formula> are the feature maps generated from the new feature extraction network <inline-formula id="IEq87"><alternatives><tex-math id="M189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{{extract}}^{t+1}$$\end{document}</tex-math><mml:math id="M190"><mml:msubsup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq87.gif"/></alternatives></inline-formula> and the old frozen network <inline-formula id="IEq88"><alternatives><tex-math id="M191">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{{extract}}^{t}$$\end{document}</tex-math><mml:math id="M192"><mml:msubsup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq88.gif"/></alternatives></inline-formula>, respectively; (<inline-formula id="IEq89"><alternatives><tex-math id="M193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${y}_{t+1}$$\end{document}</tex-math><mml:math id="M194"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq89.gif"/></alternatives></inline-formula>,<inline-formula id="IEq90"><alternatives><tex-math id="M195">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\,{y}_{t}$$\end{document}</tex-math><mml:math id="M196"><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq90.gif"/></alternatives></inline-formula>) and (<inline-formula id="IEq91"><alternatives><tex-math id="M197">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${o}_{t+1}$$\end{document}</tex-math><mml:math id="M198"><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq91.gif"/></alternatives></inline-formula>,<inline-formula id="IEq92"><alternatives><tex-math id="M199">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\,{o}_{t}$$\end{document}</tex-math><mml:math id="M200"><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>o</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq92.gif"/></alternatives></inline-formula>) are the center and offset heatmaps predicted by the object location networks <inline-formula id="IEq93"><alternatives><tex-math id="M201">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{{loc}}^{t+1}$$\end{document}</tex-math><mml:math id="M202"><mml:msubsup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq93.gif"/></alternatives></inline-formula> and <inline-formula id="IEq94"><alternatives><tex-math id="M203">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{{loc}}^{t}$$\end{document}</tex-math><mml:math id="M204"><mml:msubsup><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq94.gif"/></alternatives></inline-formula> for new and old datasets, respectively; and (<inline-formula id="IEq95"><alternatives><tex-math id="M205">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${M}_{f}$$\end{document}</tex-math><mml:math id="M206"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq95.gif"/></alternatives></inline-formula>, <inline-formula id="IEq96"><alternatives><tex-math id="M207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${M}_{y}$$\end{document}</tex-math><mml:math id="M208"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq96.gif"/></alternatives></inline-formula>, <inline-formula id="IEq97"><alternatives><tex-math id="M209">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${M}_{o}$$\end{document}</tex-math><mml:math id="M210"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq97.gif"/></alternatives></inline-formula>) refers to the number of activation values in the feature map and prediction outputs.</p></list-item><list-item><p id="Par45">The regularization loss, <inline-formula id="IEq98"><alternatives><tex-math id="M211">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{{Reg}}$$\end{document}</tex-math><mml:math id="M212"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq98.gif"/></alternatives></inline-formula>, is adopted in EPicker to avoid overfitting to the old datasets <inline-formula id="IEq99"><alternatives><tex-math id="M213">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({D}_{1}\ldots {D}_{t})$$\end{document}</tex-math><mml:math id="M214"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq99.gif"/></alternatives></inline-formula> in the process of repeatedly minimizing the object detection loss on the exemplar <inline-formula id="IEq100"><alternatives><tex-math id="M215">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$({E}_{1}\ldots {E}_{t})$$\end{document}</tex-math><mml:math id="M216"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq100.gif"/></alternatives></inline-formula>. The regularization loss term is formulated as follows:</p></list-item></list><disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M217">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{Reg}=\sum {\Vert {\theta }_{t+1}-{\theta }_{t}\Vert }_{2}^{2},$$\end{document}</tex-math><mml:math id="M218"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo mathsize="big"> ∑</mml:mo><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq101"><alternatives><tex-math id="M219">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{t}$$\end{document}</tex-math><mml:math id="M220"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq101.gif"/></alternatives></inline-formula> represents the frozen parameters of the old model <italic>t</italic>, and <inline-formula id="IEq102"><alternatives><tex-math id="M221">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{t+1}$$\end{document}</tex-math><mml:math id="M222"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq102.gif"/></alternatives></inline-formula> represents the parameters of the new model <inline-formula id="IEq103"><alternatives><tex-math id="M223">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t+1$$\end{document}</tex-math><mml:math id="M224"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq103.gif"/></alternatives></inline-formula>. Overtraining on the exemplar is avoided by penalizing significant changes in the parameters between the new and old models, and the general knowledge from the old task is remembered.</p>
    </sec>
    <sec id="Sec15">
      <title>Sparse annotation in EPicker</title>
      <p id="Par46">Sparse annotation means that only a small number of particles are required to pick for building the training dataset, that is, many positive particles are unlabeled, which can significantly reduce the difficulty and workload of labeling. As in some challenging datasets with extremely small particles, there are often more than 1000 particles on one micrograph, which makes it difficult or impossible to annotate all the positive particles, either by manual picking or 2D classification. However, the unlabeled positive particles can mislead the training process and restrain the detection of good particles, which finally results in the absence of some positive particles. To address the problem of sparse annotation, Topaz<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> proposed the GE-binomial algorithm, which is based on the generalized expectation (GE) criteria. However, Topaz tended to pick a large number of particles, many of which were located on contamination (Supplementary Fig. <xref rid="MOESM1" ref-type="media">6</xref>). Some previous works dealing with sparse annotation in natural images solved this problem by reweighting the importance of region proposals generated by the two-stage object detector Faster RCNN<sup><xref ref-type="bibr" rid="CR38">38</xref>,<xref ref-type="bibr" rid="CR39">39</xref></sup> or recalibrating the loss of the anchors used by the one-stage object detector YOLO<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>. To solve the problem of sparse annotation in EPicker, we need to reduce the penalty on the loss function of these potentially positive unlabeled particles and try to generate more positive labels to enhance the prediction ability of the detector. On the one hand, we followed the concept of GHM loss<sup><xref ref-type="bibr" rid="CR41">41</xref></sup> and ignored some hard examples that can be seen as outliers. These hard examples are negative samples, however, with high confidence scores in the prediction results of the detector. Ignoring them can reduce the possibility of mistaking unlabeled positive particles as negative particles. On the other hand, we obtained some pseudo labels from the prediction results of the detector with very high confidence scores. Particles with very high confidence scores in the prediction were likely to be unlabeled particles. EPicker automatically generates pseudo labels for these particles and treats them as positive samples. Finally, the final prediction loss of the particle center in the object detection loss of the EPicker is defined as<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M225">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{k}=-\frac{1}{N}\mathop{\sum}\limits_{{xy}}\left\{\begin{array}{cc}{(1-{\hat{Y}}_{{xy}})}^{\alpha }{{\log }}({\hat{Y}}_{{xy}}) &amp; {if}\,{Y}_{{xy}}=1\,{or}\,{\hat{Y}}_{{xy}} &gt; \,{\tau }_{1}\\ {(1-{Y}_{{xy}})}^{\beta }{({\hat{Y}}_{{xy}})}^{\alpha }{{\log }}({1-\hat{Y}}_{{xy}}) &amp; {if}\,{Y}_{{xy}}=0\,{and}\,{\hat{Y}}_{{xy}} &lt; \,{\tau }_{2}\end{array}\right.,$$\end{document}</tex-math><mml:math id="M226"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:munder><mml:mfenced open="{"><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msup><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mspace width="0.25em"/><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msup><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="center"><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.25em"/><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>where<inline-formula id="IEq104"><alternatives><tex-math id="M227">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\,{\tau }_{1}$$\end{document}</tex-math><mml:math id="M228"><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq104.gif"/></alternatives></inline-formula> is the threshold for controlling the confidence of the detector to reverse negative particles with high confidence scores into unlabeled positive particles, and <inline-formula id="IEq105"><alternatives><tex-math id="M229">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\tau }_{2}$$\end{document}</tex-math><mml:math id="M230"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq105.gif"/></alternatives></inline-formula> is the threshold for controlling the confidence of the detector to reduce the substantial penalty on the loss function for the potential unlabeled positive particles, which reduces the detection of particles with high confidence scores as negative samples or background in the training process. EPicker empirically sets <inline-formula id="IEq106"><alternatives><tex-math id="M231">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\tau }_{1}=0.7$$\end{document}</tex-math><mml:math id="M232"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq106.gif"/></alternatives></inline-formula> and <inline-formula id="IEq107"><alternatives><tex-math id="M233">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\tau }_{2}=0.5$$\end{document}</tex-math><mml:math id="M234"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq107.gif"/></alternatives></inline-formula> in the experiments.</p>
    </sec>
    <sec id="Sec16">
      <title>Evaluation of particle picking</title>
      <p id="Par47">EPicker uses average precision (AP) and average recall (AR) to evaluate the performance of particle picking, which has been widely adopted in the field of object detection<sup><xref ref-type="bibr" rid="CR42">42</xref></sup>. A brief introduction and the settings used in the present work are as follows.</p>
      <p id="Par48">EPicker generates a score for each picked particle to present confidence. When the confidence score was greater than a given threshold, the picked particle was considered correct. Precision and recall were used to evaluate picking. Precision is defined as the ratio of the number of correctly picked particles to the number of all picked particles,<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M235">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${precision}=\frac{{TP}}{{TP}+{FP}}.$$\end{document}</tex-math><mml:math id="M236"><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par49">Recall is defined as the ratio of the number of correctly picked particles to the number of all correct particles,<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M237">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${recall}=\frac{{TP}}{{TP}+{FN}}.$$\end{document}</tex-math><mml:math id="M238"><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par50">Here, true positive (TP) denotes the correctly picked particles, false positive (FP) denotes the incorrectly picked particles, and false negative (FN) denotes the correct particles that are not picked. The intersection over union (IoU) is a measure of the overlapped area between the detected particle and the ground truth,<disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M239">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${IoU}=\frac{{area}\left({P}_{D}{\,\cap \,P}_{G}\right)}{{area}\left({P}_{D}{\cup P}_{G}\right)},$$\end{document}</tex-math><mml:math id="M240"><mml:mi>I</mml:mi><mml:mi>o</mml:mi><mml:mi>U</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mspace width="0.25em"/><mml:mo>∩</mml:mo><mml:mspace width="0.25em"/><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mo>∪</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq108"><alternatives><tex-math id="M241">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${P}_{D}$$\end{document}</tex-math><mml:math id="M242"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq108.gif"/></alternatives></inline-formula> represents the detected particles, and <inline-formula id="IEq109"><alternatives><tex-math id="M243">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${P}_{G}$$\end{document}</tex-math><mml:math id="M244"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq109.gif"/></alternatives></inline-formula> represents the ground truth. In all our tests, we used an IoU threshold of 0.5, which means that the detected particles with IoU less than 0.5, are incorrect. When the prediction of particle size was turned off, we assigned a constant particle size for each sample.</p>
      <p id="Par51">Based on the definitions above, precision and recall vary with the setting of the score threshold. To avoid the influence of the threshold setting, AP is calculated as the average precision of all recall values:<disp-formula id="Equ14"><label>14</label><alternatives><tex-math id="M245">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${AP}={\int }_{0}^{1}P\left(R\right){dR},$$\end{document}</tex-math><mml:math id="M246"><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>∫</mml:mo></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mi>P</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi>R</mml:mi><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ14.gif" position="anchor"/></alternatives></disp-formula>where precision, P, is considered a function of recall R. The final AP is the average of the AP values for all the testing micrographs. AR is the average of the recall values for all the testing micrographs.</p>
      <p id="Par52">When EPicker is trained in a continual manner, adding more training datasets means merging more features into an old model. The dissimilarity of features between the old and new datasets may influence the effectiveness of merging different features, which is indicated by forgetting some old features. To evaluate this influence, we defined the complexity of a new dataset as how the features in the new dataset match the features in the old datasets. The higher the complexity, the greater the differences. We then tested the relationship between complexity and forgetting rate.</p>
      <p id="Par53">To assess the complexity of a new dataset, we used an old general model to pick new particles. The complexity of the new dataset is inversely proportional to the picking accuracy and is empirically defined as:<disp-formula id="Equ15"><label>15</label><alternatives><tex-math id="M247">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C=\frac{100}{{10}^{\left({AP}+{AR}\right)}},$$\end{document}</tex-math><mml:math id="M248"><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>100</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mi>A</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>R</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ15.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq110"><alternatives><tex-math id="M249">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$C\in [{{{{\mathrm{1,100}}}}}]$$\end{document}</tex-math><mml:math id="M250"><mml:mi>C</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="normal">1, 100</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq110.gif"/></alternatives></inline-formula> is the complexity of the new dataset, and AP and AR refer to the average precision and average recall when directly using the old general model to pick new particles. When the features of new particles are significantly different from those in the old datasets, the picking may fail and lead to low AP and AR, and consequently, a high complexity.</p>
      <p id="Par54">The reduction in AP and AR indicates forgetting. We defined the forgetting rate for AP and AR, respectively, as the average reduction in AP and AR of all old datasets before and after training on a new dataset.</p>
    </sec>
    <sec id="Sec17">
      <title>Comparison with other continual learning algorithms</title>
      <p id="Par55">We compared the continual learning method in EPicker with other widely used continual learning methods.</p>
      <p id="Par56">The method in EPicker was compared with memory-aware synapses (MAS)<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>, which is a regularization method that computes the importance of the parameters of a neural network and constrains the changes in important weights. We adapted MAS to EPicker, and the importance weight <inline-formula id="IEq111"><alternatives><tex-math id="M251">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varOmega }_{{ij}}$$\end{document}</tex-math><mml:math id="M252"><mml:msub><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq111.gif"/></alternatives></inline-formula> for parameter <inline-formula id="IEq112"><alternatives><tex-math id="M253">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\theta }_{{ij}}$$\end{document}</tex-math><mml:math id="M254"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq112.gif"/></alternatives></inline-formula> is defined as:<disp-formula id="Equ16"><label>16</label><alternatives><tex-math id="M255">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\varOmega }_{ij}=\frac{1}{N}\mathop{\sum }\limits_{k=1}^{N}\Vert {g}_{ij}({x}_{k})\Vert =\frac{1}{N}\mathop{\sum }\limits_{k=1}^{N}\left\Vert \frac{\partial {\Vert F({x}_{k},\theta )\Vert }_{2}^{2}}{\partial {\theta }_{ij}}\right\Vert ,$$\end{document}</tex-math><mml:math id="M256"><mml:msub><mml:mrow><mml:mi>Ω</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mo>∥</mml:mo><mml:msub><mml:mrow><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∥</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:munderover accent="false" accentunder="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mfenced close="∥" open="∥"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi>∂</mml:mi><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2022_29994_Article_Equ16.gif" position="anchor"/></alternatives></disp-formula>where <italic>x</italic> is the input image, <italic>N</italic> is the total number of input images, <italic>θ</italic> is the parameter of the current model, and <inline-formula id="IEq113"><alternatives><tex-math id="M257">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F\left({x}_{k},\theta \right)$$\end{document}</tex-math><mml:math id="M258"><mml:mi>F</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq113.gif"/></alternatives></inline-formula> represents the multi-dimensional output function defined in MAS<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>. We evaluated the experimental results by considering the function of the feature extraction network <inline-formula id="IEq114"><alternatives><tex-math id="M259">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{{extract}}(\theta )$$\end{document}</tex-math><mml:math id="M260"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq114.gif"/></alternatives></inline-formula> and the function of the whole object detection network <inline-formula id="IEq115"><alternatives><tex-math id="M261">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${F}_{{OD}}(\theta )$$\end{document}</tex-math><mml:math id="M262"><mml:msub><mml:mrow><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq115.gif"/></alternatives></inline-formula> as the output function <inline-formula id="IEq116"><alternatives><tex-math id="M263">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F(\theta )$$\end{document}</tex-math><mml:math id="M264"><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq116.gif"/></alternatives></inline-formula>.</p>
      <p id="Par57">Additionally, the method was compared with Faster ILOD<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>, which uses Faster R-CNN<sup><xref ref-type="bibr" rid="CR34">34</xref></sup> as the base object detector. Peng et al. used Faster ILOD<sup><xref ref-type="bibr" rid="CR28">28</xref></sup> and proposed an adaptive distillation method to properly train previous knowledge. Because the framework of our network is completely different from that of Faster ILOD, we only adopted the idea of the multi-network adaptive distillation (AD) proposed by Peng et al<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>.</p>
      <p id="Par58">As shown in Supplementary Table <xref rid="MOESM1" ref-type="media">3</xref>, our method performed better than MAS and Faster ILOD. For MAS, the introduction of important weights led to serious conflicts between the parameters of the old and new models. For Faster ILOD, which dealt with class-incremental learning problems in natural images, the adaptive knowledge distillation method was used on all datasets. Because the particles in a new dataset are often significantly dissimilar to those in old datasets, constraining the new and old models to extract similar features on the new datasets is problematic.</p>
    </sec>
    <sec id="Sec18">
      <title>Fiber picking and tracing algorithm</title>
      <p id="Par59">EPicker also supports the picking of fibers. For an input micrograph with fibers, EPicker first picks fibers as normal particles, and then places the coordinates of the picked particles into a point set. We developed a line tracing algorithm (LTA) to link the discrete points of the fibers as lines (Supplementary Fig. <xref rid="MOESM1" ref-type="media">5</xref>). The fiber bending angle parameter, <inline-formula id="IEq117"><alternatives><tex-math id="M265">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${ang}$$\end{document}</tex-math><mml:math id="M266"><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq117.gif"/></alternatives></inline-formula>, was used to set an acceptable maximum curvature.</p>
      <p id="Par60">A particle is first randomly selected as the starting point, and then LTA identifies the closest point and connects the two points into a line segment. LTA sets the second point as the starting point, ignores any selected points, and places all the points whose distance from the new starting point is less than a radius, <italic>r</italic>, into a candidate point set. EPicker empirically sets <inline-formula id="IEq118"><alternatives><tex-math id="M267">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$r=100$$\end{document}</tex-math><mml:math id="M268"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:math><inline-graphic xlink:href="41467_2022_29994_Article_IEq118.gif"/></alternatives></inline-formula> at a reduced micrograph with a width of 1024 pixels. Then, LTA finds the closest point in the candidate point set and connects it to the new starting point. If the angle between the current line segment and the previous line segment is larger than the angle threshold, the current candidate point is removed from the candidate point set, and the next candidate point is identified and tested. This procedure is repeated until a candidate point satisfying the angle constriction is obtained. If the angle calculated at all candidate points is larger than the angle threshold, a new fiber is initiated. LTA is repeated until no eligible points are in the point set.</p>
      <p id="Par61">The tracing result of the fibers is further smoothed by removing some points on the lines when the angle between the adjacent line segments is less than a certain threshold and is set to 0.1 rad in EPicker.</p>
    </sec>
    <sec id="Sec19">
      <title>Image processing and 2D classification</title>
      <p id="Par62">The datasets downloaded from EMPIAR were processed using MotionCor2<sup><xref ref-type="bibr" rid="CR43">43</xref></sup> to generate single-frame micrographs, if applicable. The defocus of the micrographs was determined using the CTFFind4<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>. All 2D classifications were performed using the THUNDER<sup><xref ref-type="bibr" rid="CR45">45</xref></sup>.</p>
    </sec>
    <sec id="Sec20">
      <title>Reporting summary</title>
      <p id="Par63">Further information on research design is available in the <xref rid="MOESM2" ref-type="media">Nature Research Reporting Summary</xref> linked to this article.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec21">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="41467_2022_29994_MOESM1_ESM.pdf">
            <caption>
              <p>Supplementary Information</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="41467_2022_29994_MOESM2_ESM.pdf">
            <caption>
              <p>Reporting Summary</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="41467_2022_29994_MOESM3_ESM.pdf">
            <caption>
              <p>Peer Review File</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p><bold>Publisher’s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>These authors contributed equally: Xinyu Zhang, Tianfang Zhao.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p>The online version contains supplementary material available at 10.1038/s41467-022-29994-y.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>This work was supported by funds from The National Key Research and Development Program (2016YFA0501102 to X.L.), National Natural Science Foundation of China (61871256 to Y.S., and 61673234 to J.C.), Advanced Innovation Center for Structural Biology (to X. L., and Y. S.), Beijing Frontier Research Center for Biological Structure (to X.L.), Tsinghua-Peking Joint Center for Life Sciences (to X. L.). We acknowledge Chao Lin from Tsinghua University for providing the Fab and liposome datasets. We acknowledge Tsinghua University Branch of China National Center for Protein Sciences Beijing for providing facility supports in computation.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>X.L., Y.S., and J.C. initialized the project. X.Z. developed the continual learning algorithm. T.Z. implemented the CenterNet algorithm. X.Z. and T.Z. wrote the program. T.Z. prepared the release package with an integrated Python environment. X.Z., T.Z., and X.L. performed the tests. X.L. developed the graphic user interface. X.L., X.Z., and T.Z. wrote the manuscript. All authors revised the manuscript.</p>
  </notes>
  <notes notes-type="peer-review">
    <title>Peer review</title>
    <sec id="FPar1">
      <title>Peer review information</title>
      <p id="Par64"><italic>Nature Communications</italic> thanks Adil Al-Azzawi, Mikel Hernaez and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. <xref rid="MOESM3" ref-type="media">Peer reviewer reports</xref> are available.</p>
    </sec>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>Datasets used for the continual learning study are from EMPIAR with entry codes: EMPIAR-10017, EMPIAR-10025, EMPIAR-10028, EMPIAR-10075, EMPIAR-10081, EMPIAR-10089, EMPIAR-10097, EMPIAR-10146, EMPIAR-10203, EMPIAR-10228. The according annotations used for the continual learning is deposited in a public database <ext-link ext-link-type="uri" xlink:href="https://dataverse.harvard.edu/dataverse/EPicker">https://dataverse.harvard.edu/dataverse/EPicker</ext-link>. Dataset used to test biased and unbiased picking are from EMPIAR with entry codes: EMPIAR-10401, EMPIAR-10090. The Fab and liposome dataset is available for downloaded from 10.7910/DVN/I92FFJ and 10.7910/DVN/ZMN57Q, respectively. The remaining datasets used in this study are from EMPIAR with entry codes: EMPIAR-10004, EMPIAR-10033, EMPIAR-10057, EMPIAR-10058, EMPIAR-10093, EMPIAR-10096, EMPIAR-10122, EMPIAR-10168, EMPIAR-10175, EMPIAR-10190, EMPIAR-10192, EMPIAR-10197, EMPIAR-10202, EMPIAR-10205, EMPIAR-10216, EMPIAR-10590, EMPIAR-10406, EMPIAR-10470, EMPIAR-10429, EMPIAR-10241, EMPIAR-10270, EMPIAR-10420, EMPIAR-10407, EMPIAR-10059, EMPIAR-10402, EMPIAR-10399, EMPIAR-10454, EMPIAR-10443, EMPIAR-10379, EMPIAR-10456, EMPIAR-10350, EMPIAR-10335, EMPIAR-10217, EMPIAR-10291, EMPIAR-10290, EMPIAR-10289.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Code availability</title>
    <p>The program code is available for downloading from our project website <ext-link ext-link-type="uri" xlink:href="http://thuem.net">http://thuem.net</ext-link> and the Github repository <ext-link ext-link-type="uri" xlink:href="https://github.com/thuem/EPicker">https://github.com/thuem/EPicker</ext-link>. Detailed information about software installation and usage can be found at: <ext-link ext-link-type="uri" xlink:href="http://thuem.net">http://thuem.net</ext-link>.</p>
  </notes>
  <notes id="FPar2" notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par65">The authors declare no competing interests.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Roseman</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Find</surname>
            <given-names>EM</given-names>
          </name>
        </person-group>
        <article-title>FindEM–a fast, efficient program for automatic selection of particles from electron micrographs</article-title>
        <source>J. Struct. Biol.</source>
        <year>2004</year>
        <volume>145</volume>
        <fpage>91</fpage>
        <lpage>99</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jsb.2003.11.007</pub-id>
        <pub-id pub-id-type="pmid">15065677</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>JZ</given-names>
          </name>
          <name>
            <surname>Grigorieff</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>SIGNATURE: A single-particle selection system for molecular electron microscopy</article-title>
        <source>J. Struct. Biol.</source>
        <year>2007</year>
        <volume>157</volume>
        <fpage>168</fpage>
        <lpage>173</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jsb.2006.06.001</pub-id>
        <pub-id pub-id-type="pmid">16870473</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Voss</surname>
            <given-names>NR</given-names>
          </name>
          <name>
            <surname>Yoshioka</surname>
            <given-names>CK</given-names>
          </name>
          <name>
            <surname>Radermacher</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Potter</surname>
            <given-names>CS</given-names>
          </name>
          <name>
            <surname>Carragher</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>DoG. DoG Picker and TiltPicker: Software tools to facilitate particle selection in single particle electron microscopy</article-title>
        <source>J. Struct. Biol.</source>
        <year>2009</year>
        <volume>166</volume>
        <fpage>205</fpage>
        <lpage>213</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jsb.2009.01.004</pub-id>
        <pub-id pub-id-type="pmid">19374019</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ludtke</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Baldwin</surname>
            <given-names>PR</given-names>
          </name>
          <name>
            <surname>Chiu</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>EMAN: Semiautomated software for high-resolution single-particle reconstructions</article-title>
        <source>J. Struct. Biol.</source>
        <year>1999</year>
        <volume>128</volume>
        <fpage>82</fpage>
        <lpage>97</lpage>
        <pub-id pub-id-type="doi">10.1006/jsbi.1999.4174</pub-id>
        <pub-id pub-id-type="pmid">10600563</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scheres</surname>
            <given-names>SHW</given-names>
          </name>
        </person-group>
        <article-title>RELION: Implementation of a Bayesian approach to cryo-EM structure determination</article-title>
        <source>J. Struct. Biol.</source>
        <year>2012</year>
        <volume>180</volume>
        <fpage>519</fpage>
        <lpage>530</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jsb.2012.09.006</pub-id>
        <pub-id pub-id-type="pmid">23000701</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Al-Azzawi</surname>
            <given-names>A</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DeepCryoPicker: fully automated deep neural network for single protein particle picking in cryo-EM</article-title>
        <source>BMC Bioinform.</source>
        <year>2020</year>
        <volume>21</volume>
        <fpage>509</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-020-03809-7</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nguyen</surname>
            <given-names>NP</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DRPnet: automated particle picking in cryo-electron micrographs using deep regression</article-title>
        <source>BMC Bioinform.</source>
        <year>2021</year>
        <volume>22</volume>
        <fpage>55</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-020-03948-x</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>F</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DeepPicker: A deep learning approach for fully automated particle picking in cryo-EM</article-title>
        <source>J. Struct. Biol.</source>
        <year>2016</year>
        <volume>195</volume>
        <fpage>325</fpage>
        <lpage>336</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jsb.2016.07.006</pub-id>
        <pub-id pub-id-type="pmid">27424268</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Ouyang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Mao</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>A deep convolutional neural network approach to single-particle recognition in cryo-electron microscopy</article-title>
        <source>BMC Bioinforma.</source>
        <year>2017</year>
        <volume>18</volume>
        <fpage>348</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-017-1757-y</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tegunov</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Cramer</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Real-time cryo-electron microscopy data preprocessing with Warp</article-title>
        <source>Nat. Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <fpage>1146</fpage>
        <lpage>1152</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-019-0580-y</pub-id>
        <pub-id pub-id-type="pmid">31591575</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bepler</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Positive-unlabeled convolutional neural networks for particle picking in cryo-electron micrographs</article-title>
        <source>Nat. Methods</source>
        <year>2019</year>
        <volume>16</volume>
        <fpage>1153</fpage>
        <lpage>1160</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-019-0575-8</pub-id>
        <pub-id pub-id-type="pmid">31591578</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bepler</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Kelley</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Noble</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Berger</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Topaz-denoise: General deep denoising models for cryoEM and cryoET</article-title>
        <source>Nat. Commun.</source>
        <year>2020</year>
        <volume>11</volume>
        <fpage>5208</fpage>
        <pub-id pub-id-type="doi">10.1038/s41467-020-18952-1</pub-id>
        <pub-id pub-id-type="pmid">33060581</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wagner</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>SPHIRE-crYOLO is a fast and accurate fully automated particle picker for cryo-EM</article-title>
        <source>Commun. Biol.</source>
        <year>2019</year>
        <volume>2</volume>
        <fpage>218</fpage>
        <lpage>218</lpage>
        <pub-id pub-id-type="doi">10.1038/s42003-019-0437-z</pub-id>
        <pub-id pub-id-type="pmid">31240256</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Girshick, R., Donahue, J., Darrell, T. &amp; Malik, J. Rich feature hierarchies for accurate object detection and semantic segmentation. in <italic>IEEE Conference on Computer Vision and Pattern Recognition</italic> 580-587 (2014).</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mccloskey</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Cohen</surname>
            <given-names>NJ</given-names>
          </name>
        </person-group>
        <article-title>Catastrophic interference in connectionist networks: The sequential learning problem</article-title>
        <source>Psychol. Learn. Motiv.</source>
        <year>1989</year>
        <volume>24</volume>
        <fpage>109</fpage>
        <lpage>165</lpage>
        <pub-id pub-id-type="doi">10.1016/S0079-7421(08)60536-8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kirkpatrick</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Overcoming catastrophic forgetting in neural networks</article-title>
        <source>Proc. Natl Acad. Sci. USA</source>
        <year>2017</year>
        <volume>114</volume>
        <fpage>3521</fpage>
        <lpage>3526</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1611835114</pub-id>
        <pub-id pub-id-type="pmid">28292907</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zenke</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Poole</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Ganguli</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Continual learning through synaptic intelligence</article-title>
        <source>Proc. Mach. Learn. Res.</source>
        <year>2017</year>
        <volume>70</volume>
        <fpage>3987</fpage>
        <lpage>3995</lpage>
        <?supplied-pmid 31909397?>
        <pub-id pub-id-type="pmid">31909397</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">Rajasegaran, J., Hayat, M., Khan, S., Khan, F. &amp; Shao, L. Random path selection for incremental learning. in <italic>Advances in Neural Information Processing Systems</italic> (2019).</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Mallya, A. &amp; Lazebnik, S. PackNet: Adding multiple tasks to a single network by iterative pruning. in <italic>IEEE Conference on Computer Vision and Pattern Recognition</italic> 7765-7773 (2018).</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <mixed-citation publication-type="other">Rebuffi, S., Kolesnikov, A., Sperl, G. &amp; Lampert, C. H. iCaRL: Incremental classifier and representation learning. in <italic>IEEE Conference on Computer Vision and Pattern Recognition</italic> 5533-5542 (2017).</mixed-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Aljundi, R., Babiloni, F., Elhoseiny, M., Rohrbach, M. &amp; Tuytelaars, T. Memory Aware Synapses: Learning what (not) to forget. in <italic>Lecture Notes in Computer Science Proceedings of the European Conference on Computer Vision</italic> 139-154 (2017), 144-161 (2018).</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Hoiem</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Learning without forgetting</article-title>
        <source>IEEE Trans. Pattern Anal. Mach. Intell.</source>
        <year>2018</year>
        <volume>40</volume>
        <fpage>2935</fpage>
        <lpage>2947</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2017.2773081</pub-id>
        <pub-id pub-id-type="pmid">29990101</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Wu, Y. et al. Large scale incremental learning. in <italic>IEEE Conference on Computer Vision and Pattern Recognition</italic> 374-382 (2019).</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mermillod</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bugaiska</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bonin</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>The stability-plasticity dilemma: Investigating the continuum from catastrophic forgetting to age-limited learning effects</article-title>
        <source>Front. Psychol.</source>
        <year>2013</year>
        <volume>4</volume>
        <fpage>504</fpage>
        <pub-id pub-id-type="doi">10.3389/fpsyg.2013.00504</pub-id>
        <pub-id pub-id-type="pmid">23935590</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Vinyals</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Dean</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Distilling the knowledge in a neural network</article-title>
        <source>Computer Ence</source>
        <year>2015</year>
        <volume>14</volume>
        <fpage>38</fpage>
        <lpage>39</lpage>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Shmelkov, K., Schmid, C. &amp; Alahari, K. Incremental learning of object detectors without catastrophic forgetting. in <italic>IEEE International Conference on Computer Vision</italic> 3420-3429 (2017).</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Li, C., Chunyan, Y. &amp; Lvcai, C. A new knowledge distillation for incremental object detection. in <italic>International Joint Conference on Neural Networks</italic> (2019).</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Peng</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Lovell</surname>
            <given-names>BC</given-names>
          </name>
          <name>
            <surname>Faster</surname>
            <given-names>ILOD</given-names>
          </name>
        </person-group>
        <article-title>Faster ILOD: Incremental learning for object detectors based on faster RCNN</article-title>
        <source>Pattern Recognit. Lett.</source>
        <year>2020</year>
        <volume>140</volume>
        <fpage>109</fpage>
        <lpage>115</lpage>
        <pub-id pub-id-type="doi">10.1016/j.patrec.2020.09.030</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <mixed-citation publication-type="other">Zhou, X., Wang, D. &amp; Krhenbühl, P. Objects as Points (2019).</mixed-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Redmon, J. &amp; Farhadi, A. YOLOv3: An Incremental Improvement (2018).</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Redmon, J., Divvala, S., Girshick, R. &amp; Farhadi, A. You only look once: Unified, real-time object detection. in <italic>IEEE Conference on Computer Vision and Pattern Recognition</italic> 779-788 (2016).</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">Redmon, J. &amp; Farhadi, A. YOLO9000: Better, faster, stronger. in <italic>IEEE Conference on Computer Vision &amp; Pattern Recognition</italic> 6517–6525 (2017).</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>T-Y</given-names>
          </name>
          <name>
            <surname>Goyal</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Girshick</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Dollar</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Focal loss for dense object detection</article-title>
        <source>IEEE Trans. Pattern Anal. Mach. Intell.</source>
        <year>2020</year>
        <volume>42</volume>
        <fpage>318</fpage>
        <lpage>327</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2018.2858826</pub-id>
        <pub-id pub-id-type="pmid">30040631</pub-id>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ren</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Girshick</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Faster</surname>
            <given-names>R-CNN</given-names>
          </name>
        </person-group>
        <article-title>Faster R-CNN: Towards real-time object detection with region proposal networks</article-title>
        <source>IEEE Trans. Pattern Anal. Mach. Intell.</source>
        <year>2017</year>
        <volume>39</volume>
        <fpage>1137</fpage>
        <lpage>1149</lpage>
        <pub-id pub-id-type="doi">10.1109/TPAMI.2016.2577031</pub-id>
        <pub-id pub-id-type="pmid">27295650</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Kaiming, H., Xiangyu Z., Shaoqing R., Jian S. Deep residual learning for image recognition. In <italic>IEEE</italic><italic>in Conference on Computer Vision and Pattern Recognition (CVPR)</italic> 770–778 (2016).</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Yu, F., Wang, D., Shelhamer, E. &amp; Darrell, T. Deep Layer Aggregation. in <italic>NIPS Workshop</italic> (2017).</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Fan</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Cryo-EM analysis of a membrane protein embedded in the liposome</article-title>
        <source>Proc. Natl Acad. Sci. USA</source>
        <year>2020</year>
        <volume>117</volume>
        <fpage>18497</fpage>
        <lpage>18503</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.2009385117</pub-id>
        <pub-id pub-id-type="pmid">32680969</pub-id>
      </element-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Wu, Z. et al. Soft Sampling for Robust Object Detection. in BMVC (2018).</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <mixed-citation publication-type="other">Niitani, Y. et al. Sampling Techniques for Large-Scale Object Detection from Sparsely Annotated Objects. in <italic>IEEE Conference on Computer Vision and Pattern Recognition</italic> (2019).</mixed-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">Zhang, H. et al. Solving Missing-Annotation Object Detection with Background Recalibration Loss. in <italic>ICASSP</italic> (2020).</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <mixed-citation publication-type="other">Li, B. et al. Gradient Harmonized Single-stage Detector. in <italic>AAAI</italic> (2019).</mixed-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <mixed-citation publication-type="other">Lin, T. Y., Maire, M., Belongie, S., Hays, J. &amp; Zitnick, C. L. Microsoft COCO: Common objects in context. <italic>European Conference on Computer Vision</italic> (2014).</mixed-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>SQ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MotionCor2: Anisotropic correction of beam-induced motion for improved cryo-electron microscopy</article-title>
        <source>Nat. Methods</source>
        <year>2017</year>
        <volume>14</volume>
        <fpage>331</fpage>
        <lpage>332</lpage>
        <pub-id pub-id-type="doi">10.1038/nmeth.4193</pub-id>
        <pub-id pub-id-type="pmid">28250466</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rohou</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Grigorieff</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>CTFFIND4: Fast and accurate defocus estimation from electron micrographs</article-title>
        <source>J. Struct. Biol.</source>
        <year>2015</year>
        <volume>192</volume>
        <fpage>216</fpage>
        <lpage>221</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jsb.2015.08.008</pub-id>
        <pub-id pub-id-type="pmid">26278980</pub-id>
      </element-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>M</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A particle-filter framework for robust cryo-EM 3D reconstruction</article-title>
        <source>Nat. Methods</source>
        <year>2018</year>
        <volume>15</volume>
        <fpage>1083</fpage>
        <lpage>1089</lpage>
        <pub-id pub-id-type="doi">10.1038/s41592-018-0223-8</pub-id>
        <pub-id pub-id-type="pmid">30504871</pub-id>
      </element-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ioffe</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Szegedy</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Batch normalization: Accelerating deep network training by reducing internal covariate shift</article-title>
        <source>Proc. 32nd Int. Conf. Int. Conf. Mach. Learn.</source>
        <year>2015</year>
        <volume>37</volume>
        <fpage>448</fpage>
        <lpage>456</lpage>
      </element-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Glorot</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Bordes</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y</given-names>
          </name>
        </person-group>
        <article-title>Deep Sparse Rectifier Neural Networks</article-title>
        <source>J. Mach. Learn. Res.</source>
        <year>2011</year>
        <volume>15</volume>
        <fpage>315</fpage>
        <lpage>323</lpage>
      </element-citation>
    </ref>
  </ref-list>
</back>
