<?DTDIdentifier.IdentifierValue article.dtd?>
<?DTDIdentifier.IdentifierType system?>
<?SourceDTD.DTDName article.dtd?>
<?SourceDTD.Version 1.0?>
<?ConverterInfo.XSLTName bmc2nlmx2.xsl?>
<?ConverterInfo.Version 2?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Genomics</journal-id>
    <journal-title-group>
      <journal-title>BMC Genomics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2164</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">3287581</article-id>
    <article-id pub-id-type="publisher-id">1471-2164-12-S4-S12</article-id>
    <article-id pub-id-type="doi">10.1186/1471-2164-12-S4-S12</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Proceedings</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Cutoff Scanning Matrix (CSM): structural classification and function prediction by protein inter-residue distance patterns</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes" id="A1">
        <name>
          <surname>Pires</surname>
          <given-names>Douglas EV</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>dpires@dcc.ufmg.br</email>
      </contrib>
      <contrib contrib-type="author" id="A2">
        <name>
          <surname>de Melo-Minardi</surname>
          <given-names>Raquel C</given-names>
        </name>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>raquelcm@dcc.ufmg.br</email>
      </contrib>
      <contrib contrib-type="author" id="A3">
        <name>
          <surname>dos Santos</surname>
          <given-names>Marcos A</given-names>
        </name>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>marcos@dcc.ufmg.br</email>
      </contrib>
      <contrib contrib-type="author" id="A4">
        <name>
          <surname>da Silveira</surname>
          <given-names>Carlos H</given-names>
        </name>
        <xref ref-type="aff" rid="I3">3</xref>
        <email>carlos.silveira@unifei.edu.br</email>
      </contrib>
      <contrib contrib-type="author" id="A5">
        <name>
          <surname>Santoro</surname>
          <given-names>Marcelo M</given-names>
        </name>
        <xref ref-type="aff" rid="I1">1</xref>
        <email>santoro@icb.ufmg.br</email>
      </contrib>
      <contrib contrib-type="author" id="A6">
        <name>
          <surname>Meira</surname>
          <given-names>Wagner</given-names>
          <suffix>Jr.</suffix>
        </name>
        <xref ref-type="aff" rid="I2">2</xref>
        <email>meira@dcc.ufmg.br</email>
      </contrib>
    </contrib-group>
    <aff id="I1"><label>1</label>Department of Biochemistry and Immunology, Universidade Federal de Minas Gerais, Belo Horizonte, 31270-901, Brazil</aff>
    <aff id="I2"><label>2</label>Department of Computer Science, Universidade Federal de Minas Gerais, Belo Horizonte, 31270-901, Brazil</aff>
    <aff id="I3"><label>3</label>Advanced Campus at Itabira, Universidade Federal de Itajubá, Itabira, 37500-903, Brazil</aff>
    <pub-date pub-type="collection">
      <year>2011</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>12</month>
      <year>2011</year>
    </pub-date>
    <volume>12</volume>
    <issue>Suppl 4</issue>
    <supplement>
      <named-content content-type="supplement-title">Proceedings of the 6th International Conference of the Brazilian Association for Bioinformatics and Computational Biology (X-meeting 2010)</named-content>
      <named-content content-type="supplement-editor">R. A. P. Nagem (Co-ordinating Editor), A. M. Durham, A. T. R. Vasconcelos, C. B. Monteiro-Vitorello, E. Dias-Neto, G. B. Domont, G. C. Oliveira, L. Felicori, L. Bleicher, J. M. Ortega, M. S. Skaf, O. Norberto de Souza, P. R. Kuser-Falcão, R. Guerra-Sá, R. DeMarco, T. M. Venancio and T. Koide</named-content>
      <named-content content-type="supplement-sponsor">The organizers would like to thank the following agencies for their financial support of the conference: CNPq (Conselho Nacional de Desenvolvimento Científico e Tecnológico) and FAPEMIG (Fundação de Amparo à Pesquisa do Estado de Minas Gerais).</named-content>
    </supplement>
    <fpage>S12</fpage>
    <lpage>S12</lpage>
    <permissions>
      <copyright-statement>Copyright ©2011 Pires et al; licensee BioMed Central Ltd.</copyright-statement>
      <copyright-year>2011</copyright-year>
      <copyright-holder>Pires et al; licensee BioMed Central Ltd.</copyright-holder>
      <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/2.0">
        <license-p>This is an open access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/2.0">http://creativecommons.org/licenses/by/2.0</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="http://www.biomedcentral.com/1471-2164/12/S4/S12"/>
    <abstract>
      <sec>
        <title>Background</title>
        <p>The unforgiving pace of growth of available biological data has increased the demand for efficient and scalable paradigms, models and methodologies for automatic annotation. In this paper, we present a novel structure-based protein function prediction and structural classification method: Cutoff Scanning Matrix (CSM). CSM generates feature vectors that represent distance patterns between protein residues. These feature vectors are then used as evidence for classification. Singular value decomposition is used as a preprocessing step to reduce dimensionality and noise. The aspect of protein function considered in the present work is enzyme activity. A series of experiments was performed on datasets based on Enzyme Commission (EC) numbers and mechanistically different enzyme superfamilies as well as other datasets derived from SCOP release 1.75.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p>CSM was able to achieve a precision of up to 99% after SVD preprocessing for a database derived from manually curated protein superfamilies and up to 95% for a dataset of the 950 most-populated EC numbers. Moreover, we conducted experiments to verify our ability to assign SCOP class, superfamily, family and fold to protein domains. An experiment using the whole set of domains found in last SCOP version yielded high levels of precision and recall (up to 95%). Finally, we compared our structural classification results with those in the literature to place this work into context. Our method was capable of significantly improving the recall of a previous study while preserving a compatible precision level.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p>We showed that the patterns derived from CSMs could effectively be used to predict protein function and thus help with automatic function annotation. We also demonstrated that our method is effective in structural classification tasks. These facts reinforce the idea that the pattern of inter-residue distances is an important component of family structural signatures. Furthermore, singular value decomposition provided a consistent increase in precision and recall, which makes it an important preprocessing step when dealing with noisy data.</p>
      </sec>
    </abstract>
    <conference>
      <conf-date>15-18 November 2010</conf-date>
      <conf-name>6th International Conference of the Brazilian Association for Bioinformatics and Computational Biology (X-meeting 2010)</conf-name>
      <conf-loc>Ouro Preto, Brazil</conf-loc>
    </conference>
  </article-meta>
</front>
<body>
  <sec>
    <title>Background</title>
    <p>With the increasing number of genome and metagenome projects, sequence databases have grown exponentially. On the one hand, the August 2010 release of the UniprotKB/TrEMBL database [<xref ref-type="bibr" rid="B1">1</xref>] contains about 12,000,000 protein sequences. In the last month, more than 300,000 new sequences have been added to that repository, and about 6,000,000 entry annotations have been revised. On the other hand, the Pfam database of protein families [<xref ref-type="bibr" rid="B2">2</xref>] represents about 12,000 families, and about 20% of these are domains of unknown function (DUFs), revealing that state-of-the-art sequence similarity-based and even profile-based annotation methods have had limited success in assigning functions to novel proteins.</p>
    <p>Protein structural classification databases, such as SCOP [<xref ref-type="bibr" rid="B3">3</xref>], also present difficulties in keeping up with the increasing number of protein structures solved and deposited in public repositories. Approximately 53% of the Protein Data Bank (PDB) [<xref ref-type="bibr" rid="B4">4</xref>] entries are classified by the current release of SCOP (1.75) as of April 2011, and after removing redundancy (sequence similarity at 90%), the coverage drops to about 41%. As international structural genomics initiatives have produced a huge number of structures of unknown function, attempting to automatically assign functions to these proteins is becoming even more necessary, and significant efforts have been devoted to this task [<xref ref-type="bibr" rid="B5">5</xref>-<xref ref-type="bibr" rid="B8">8</xref>].</p>
    <p>In this context, novel paradigms, models and methodologies for automatic annotation must be investigated. Because protein structure and function are more conserved than protein sequence [<xref ref-type="bibr" rid="B9">9</xref>], the identification of similarities between novel sequences and known structures would greatly improve the characterization of these sequences. Fold recognition refers to identifying main structural features by the connections and positions of secondary structure elements. Conversely, according to Murzin et al. [<xref ref-type="bibr" rid="B3">3</xref>], structural classification is conducted at hierarchical levels (class, fold, superfamily and family) that embody evolutionary and structural relationships. In this work, we focused on structural classification, which encompasses the problem of fold recognition. Both fold recognition and structural classification are important steps toward function prediction.</p>
    <p>Over the years, protein fold recognition has been addressed through different approaches. The authors of [<xref ref-type="bibr" rid="B10">10</xref>] extracted a series of features from protein sequences and used support vector machines and neural network learning methods as the base classifiers in a dataset composed of SCOP folds. Later, ensemble classifiers [<xref ref-type="bibr" rid="B11">11</xref>] were applied to these same feature vectors, improving the success rate. The use of a combination of sequence and structure information brought an improvement to fold recognition, as mentioned in the information retrieval approach introduced in [<xref ref-type="bibr" rid="B12">12</xref>].</p>
    <p>Likewise, several efforts toward structure-based protein function prediction have been made. We can quote, for instance, the search for structural motifs [<xref ref-type="bibr" rid="B13">13</xref>-<xref ref-type="bibr" rid="B15">15</xref>] and functional residues (such as DNA [<xref ref-type="bibr" rid="B16">16</xref>] and metal [<xref ref-type="bibr" rid="B17">17</xref>] binding sites), the use of 3D templates [<xref ref-type="bibr" rid="B5">5</xref>] and the comparison of protein folds by structure alignments [<xref ref-type="bibr" rid="B18">18</xref>,<xref ref-type="bibr" rid="B19">19</xref>]. There have also been attempts to infer function from structure without the use of alignment algorithms, such as in enzyme classification [<xref ref-type="bibr" rid="B20">20</xref>,<xref ref-type="bibr" rid="B21">21</xref>]. Similarly, in the present work, we do not use alignment techniques or any sequence information in our method, relying only on structural grounds. A primary problem faced when dealing with protein function, as pointed out in [<xref ref-type="bibr" rid="B22">22</xref>], s defining the scope and function. Protein function prediction may be understood from different perspectives. It could mean the prediction of the cellular process in which a protein is involved, its enzymatic activity or even its physiological role. For instance, a protein’s enzymatic activity could be described by EC numbers, while its physiological role might be related to its subcellular localization. In this work, the aspect of protein function considered is enzyme activity. However, the study might be extended, without loss of generality, to other functional features, like the terms of the Gene Ontology (GO) [<xref ref-type="bibr" rid="B23">23</xref>] annotation.</p>
    <p>Even though function cannot be directly implied from the specific fold adopted by a certain protein, structural data can be used to detect proteins with similar functions whose sequences have diverged during evolution [<xref ref-type="bibr" rid="B24">24</xref>]. In this context, one possible strategy is the definition of structural signatures, which are sets of features that are able to unequivocally identify a protein fold and the nature of interactions it can establish with other proteins and ligands. These feature sets are concise representations of protein structures, and we believe that their discovery and comprehension will be an important milestone in the protein function prediction field, being a step beyond sequence homology-based methods.</p>
    <p>In this paper, we investigate a special type of feature that might be part of structural signatures: the patterns in inter-residue distances (or contacts). Proteins with different folds and functions present significant differences in the distribution of distances among residues as a consequence of the underlying interaction and packing of the atomic network, which is fundamental for defining protein folding [<xref ref-type="bibr" rid="B25">25</xref>]. In [<xref ref-type="bibr" rid="B26">26</xref>], we have used these distribution distances to compare and correlate different methodologies of protein inter-residue contacts. We found, surprisingly, that the traditional cutoff-dependent approach was a simpler, more complete and more reliable technique for contact definition than other cutoff-independent methods, such as Delaunay tessellation [<xref ref-type="bibr" rid="B27">27</xref>], especially when the target is the discrimination of first-order contacts. In this work, we propose using inter-residue distance patterns for protein classification.</p>
    <p>The structural data we used are the cumulative contact distributions based on the Euclidean distances among alpha carbons, the Cutoff Scanning Matrix (CSM). The motivation for the use of this kind of information lies in the fact that proteins with different folds and functions have significantly different distributions of distances between their residues, and protein similarity is reflected in these distance distributions, information that is captured in the CSM. After generating this structural data, we apply singular value decomposition (SVD) to reduce dimensionality and noise. The processed matrix is finally submitted to different, previously described classification algorithms. Therefore, the main innovation of this work relies more on the powerful combination of the new structural feature of inter-residue contacts used as a discriminator and principal components selection by SVD rather than in the creation of a new classification method per se. Indeed, we showed our methodology to be, in general, independent of the classifiers utilized, giving even results for different classification heuristics.</p>
    <p>Having in mind these considerations, we showed that the patterns derived from CSMs might effectively be used in automatic protein function prediction and structural classification. At first glance, in the case of enzyme function prediction, the proposed method achieved (over the superfamilies) an average precision of 98.2% (sd = 1.6) and average recall of 97.9% (sd = 2.0), using a gold-standard dataset of enzymes [<xref ref-type="bibr" rid="B28">28</xref>]. Using a much larger set of enzymes with their respective EC numbers (the 950 most-populated EC numbers in terms of available structures), CSM was able to achieve up to 95.1% precision and recall results. For the recall results, considering the levels of hierarchical structure of SCOP [<xref ref-type="bibr" rid="B3">3</xref>], we were able to accomplish an average precision of 93.5% (sd = 1.4) and average recall of 93.6% (sd = 1.4). In comparison to the state-of-the-art methods used in this context, such as that given by Jain and Hirst [<xref ref-type="bibr" rid="B29">29</xref>], using very similar database input (SCOP release 1.75), our methodology presented more robust and homogeneous results, with an average precision a bit below that of those authors: 90.7% versus 93.6%, but with less dispersion (sd of 3.0 versus 6.4). We had remarkably better recall results: an average of 90.7% versus 77.0%, with significantly lower dispersion (sd of 2.9 versus 18.4). Further details are discussed in the next section.</p>
  </sec>
  <sec>
    <title>Results and discussion</title>
    <p>To test the ability of our method to successfully predict functions and recognize folds, we performed two sets of experiments with datasets designed for these different tasks.</p>
    <p>For function prediction, as mentioned in the Methods section, we built one database based on manually curated protein superfamilies and another based on EC numbers to test if the present structure-based method could help in protein function annotation.</p>
    <p>For structural classification, we performed experiments to verify our ability to assign SCOP class, superfamily, family and fold to protein domains. Furthermore, to place this work into the context of the literature, we also tested a superset of the dataset used by Jain and Hirst in [<xref ref-type="bibr" rid="B29">29</xref>]. As far as we know, their work presents the highest precision in protein fold recognition published thus far.</p>
    <p>Finally, we relate some experiments that aimed to evaluate an SVD-based noise reduction strategy.</p>
    <sec>
      <title>Function prediction</title>
      <p>In the function prediction experiments, our goal was to assess how well three different classification algorithms predict protein function according to protein EC numbers and a mechanistically diverse gold-standard database of functional family classes [<xref ref-type="bibr" rid="B28">28</xref>]. We used 10-fold cross validation for all the experiments.</p>
      <p>For the dataset of the top 950 most-populated EC numbers, CSM was able to achieve 95.1% precision and recall after SVD processing using the KNN (K-Nearest Neighbors) algorithm. The four levels of the EC number were used together as the classes to train and test the classifier. Additional file <xref ref-type="supplementary-material" rid="S1">1</xref>, Figure S1 shows the variation in the performance metrics for each EC number class considered. Even though the number of proteins assigned to each EC number is very unbalanced, the majority of classes were classified properly, with high quality according to the metrics extracted.</p>
      <p>Considering the gold-standard dataset, without SVD and using KNN, our method achieved an average precision of 94.2% (sd = 5.5) and a recall of 94.5% (sd = 5.5) (Table <xref ref-type="table" rid="T1">1</xref>). For naive Bayes, it achieved 82.3% (sd = 13.8) precision and 79.2% (sd = 15.4) recall (Additional file <xref ref-type="supplementary-material" rid="S1">1</xref>, Table S1), and for random forest, it achieved 92.0% (sd = 6.9) precision and 91.6% (sd = 7.2) recall (Additional file <xref ref-type="supplementary-material" rid="S1">1</xref>, Table S2). We also showed that by using SVD, we may significantly improve these results, and in the worst case, we had 94.6% precision and 93.1% recall for the enolase superfamily using naive Bayes. The KNN and random forest methods were able to detect isoprenoid synthase type I with 100% precision and recall. Additionally, we performed experiments using all six superfamilies to train a single classifier. In this scenario, even with a greater number of families in the training and testing phases, we were still able to achieve up to 99.0% precision with KNN and random forest after SVD preprocessing.</p>
      <table-wrap id="T1" position="float">
        <label>Table 1</label>
        <caption>
          <p>Function prediction performance using KNN for the gold-standard dataset</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left">Superfamily</th>
              <th align="center" colspan="2">Before SVD</th>
              <th align="center" colspan="2">After SVD</th>
              <th align="center">∆Prec.</th>
              <th align="center">∆Rec.</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left"/>
              <td align="center">
                <italic>Precision</italic>
              </td>
              <td align="center">
                <italic>Recall</italic>
              </td>
              <td align="center">
                <italic>Precision</italic>
              </td>
              <td align="center">
                <italic>Recall</italic>
              </td>
              <td align="center"/>
              <td align="center"/>
            </tr>
            <tr>
              <td align="left">Amidohydrolase</td>
              <td align="center">0.983</td>
              <td align="center">0.983</td>
              <td align="center">1.000</td>
              <td align="center">1.000</td>
              <td align="center">+1.7%</td>
              <td align="center">+1.7%</td>
            </tr>
            <tr>
              <td align="left">Crotonase</td>
              <td align="center">0.955</td>
              <td align="center">0.953</td>
              <td align="center">0.979</td>
              <td align="center">0.977</td>
              <td align="center">+2.4%</td>
              <td align="center">+2.4%</td>
            </tr>
            <tr>
              <td align="left">Enolase</td>
              <td align="center">0.876</td>
              <td align="center">0.853</td>
              <td align="center">0.971</td>
              <td align="center">0.967</td>
              <td align="center">+9.5%</td>
              <td align="center">+11.4%</td>
            </tr>
            <tr>
              <td align="left">Haloacid Dehalogenase</td>
              <td align="center">0.881</td>
              <td align="center">0.925</td>
              <td align="center">0.984</td>
              <td align="center">0.981</td>
              <td align="center">+10.3%</td>
              <td align="center">+5.6%</td>
            </tr>
            <tr>
              <td align="left">Isoprenoid Synthase Type I</td>
              <td align="center">1.000</td>
              <td align="center">1.000</td>
              <td align="center">1.000</td>
              <td align="center">1.000</td>
              <td align="center">+0.0%</td>
              <td align="center">+0.0%</td>
            </tr>
            <tr>
              <td align="left">Vicinal Oxygen Chelate</td>
              <td align="center">1.000</td>
              <td align="center">1.000</td>
              <td align="center">1.000</td>
              <td align="center">1.000</td>
              <td align="center">+0.0%</td>
              <td align="center">+0.0%</td>
            </tr>
            <tr>
              <td align="left">All</td>
              <td align="center">0.901</td>
              <td align="center">0.903</td>
              <td align="center">0.991</td>
              <td align="center">0.989</td>
              <td align="center">+9.0%</td>
              <td align="center">+8.6%</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>Prediction performance for the gold-standard dataset using KNN. The experiment was performed in an intra-superfamily fashion, and the <italic>classes</italic> for prediction represent the enzyme’s families. The precision and recall metrics are weighted averages. Ten-fold cross validation was employed.</p>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>Protein structural classification</title>
      <p>To the best of our knowledge, no test of the structural classification of very large databases, such as the entire SCOP containing about 110,000 domains, has been published. Due to SVD dimensionality reduction ability and the possibility of representing protein instances by a few significant attributes, we present a method that can efficiently handle such volume of data.</p>
      <p>We may recognize protein folds at a 92.2% precision and 92.3% recall using KNN (Table <xref ref-type="table" rid="T2">2</xref>). Even broad proteins categories, such as the SCOP class level, can be separated using CSM with very significant precision and recall (95.4% for both). The proposed method was able to classify proteins in the four levels of SCOP hierarchy with very high precision and recall, showing that CSM is a suitable method for fold recognition and also that CSMs are a very promising component of protein structural signatures. Additionally, we verified the impact of imposing a minimum number of entities per node of the SCOP hierarchy on the precision of the prediction. Additional file <xref ref-type="supplementary-material" rid="S1">1</xref>, Figure S2 shows an approximately linear correlation between these variables for the fold, superfamily and family levels with and without the SVD processing. This correlation was not analyzed for the class level because all of the classes have more than 100 entities.</p>
      <table-wrap id="T2" position="float">
        <label>Table 2</label>
        <caption>
          <p>Structural classification performance using KNN for the Full-SCOP dataset</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left">SCOP Level</th>
              <th align="center" colspan="2">Before SVD</th>
              <th align="center" colspan="2">After SVD</th>
              <th align="center">∆Prec.</th>
              <th align="center">∆Rec.</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left"/>
              <td align="center">
                <italic>Precision</italic>
              </td>
              <td align="center">
                <italic>Recall</italic>
              </td>
              <td align="center">
                <italic>Precision</italic>
              </td>
              <td align="center">
                <italic>Recall</italic>
              </td>
              <td align="center"/>
              <td align="center"/>
            </tr>
            <tr>
              <td align="left">Class</td>
              <td align="center">0.927</td>
              <td align="center">0.926</td>
              <td align="center">0.954</td>
              <td align="center">0.954</td>
              <td align="center">+2.7%</td>
              <td align="center">+2.8%</td>
            </tr>
            <tr>
              <td align="left">Fold</td>
              <td align="center">0.868</td>
              <td align="center">0.869</td>
              <td align="center">0.922</td>
              <td align="center">0.923</td>
              <td align="center">+5.4%</td>
              <td align="center">+5.4%</td>
            </tr>
            <tr>
              <td align="left">Superfamily</td>
              <td align="center">0.871</td>
              <td align="center">0.872</td>
              <td align="center">0.926</td>
              <td align="center">0.927</td>
              <td align="center">+5.5%</td>
              <td align="center">+5.5%</td>
            </tr>
            <tr>
              <td align="left">Family</td>
              <td align="center">0.888</td>
              <td align="center">0.889</td>
              <td align="center">0.938</td>
              <td align="center">0.938</td>
              <td align="center">+5.0%</td>
              <td align="center">+4.9%</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>Prediction performance for the full-SCOP dataset using KNN. The experiment was performed for each classification level of SCOP. The precision and recall metrics are weighted averages. A 10-fold cross validation was employed.</p>
        </table-wrap-foot>
      </table-wrap>
    </sec>
    <sec>
      <title>Performance comparison</title>
      <p>In [<xref ref-type="bibr" rid="B29">29</xref>], the authors presented a random forest-based method to predict the SCOP class, fold, superfamily and family levels based on secondary structure element descriptors that achieved precisions of up to 99.0%. Using a similar dataset, we tried to compare our results to theirs. As far as we are concerned, this was the state-of-art method for automatic structural classification. They used a subset of SCOP database as they aimed to recognize protein folds. In our comparison of results, we were able to achieve similar precision levels but with higher recall (overcoming in up to 50.0%) in most of the cases. In only 3 of the 16 experiments, we obtained a lower recall value with our method and our F1 scores were also superior. The complete set of information regarding this experiment is available in Table <xref ref-type="table" rid="T3">3</xref>. Figure <xref ref-type="fig" rid="F1">1</xref> shows the performance comparison for each experiment in terms of precision and recall. CSM significantly overcomes the recall of the aforementioned study while preserving a compatible precision level. We stress that our method is not limited to small proteins. These results show that our method is not only comparable to [<xref ref-type="bibr" rid="B29">29</xref>] but also presents a considerable gain in terms of recall.</p>
      <table-wrap id="T3" position="float">
        <label>Table 3</label>
        <caption>
          <p>Comparison of prediction performance</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th align="left">Dataset</th>
              <th align="left">SCOP level</th>
              <th align="center" colspan="3">CSM+SVD</th>
              <th align="center" colspan="3">Jain et al.</th>
              <th align="center">∆Prec.</th>
              <th align="center">∆Rec.</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="left"/>
              <td align="left"/>
              <td align="center">
                <italic>Prec .</italic>
              </td>
              <td align="center">
                <italic>Recall</italic>
              </td>
              <td align="center">
                <italic>F1</italic>
              </td>
              <td align="center">
                <italic>Prec .</italic>
              </td>
              <td align="center">
                <italic>Recall</italic>
              </td>
              <td align="center">
                <italic>F1</italic>
              </td>
              <td align="center"/>
              <td align="center"/>
            </tr>
            <tr>
              <td align="left">3SSE</td>
              <td align="left">Class</td>
              <td align="center">0.991</td>
              <td align="center">0.991</td>
              <td align="center">0.991</td>
              <td align="center">0.890</td>
              <td align="center">0.840</td>
              <td align="center">0.864</td>
              <td align="center">+10.1%</td>
              <td align="center">+15.1%</td>
            </tr>
            <tr>
              <td align="left"/>
              <td align="left">Fold</td>
              <td align="center">0.956</td>
              <td align="center">0.957</td>
              <td align="center">0.956</td>
              <td align="center">0.860</td>
              <td align="center">0.450</td>
              <td align="center">0.591</td>
              <td align="center">+9.6%</td>
              <td align="center">+50.7%</td>
            </tr>
            <tr>
              <td align="left"/>
              <td align="left">Superfamily</td>
              <td align="center">0.956</td>
              <td align="center">0.957</td>
              <td align="center">0.956</td>
              <td align="center">0.800</td>
              <td align="center">0.550</td>
              <td align="center">0.652</td>
              <td align="center">+15.6%</td>
              <td align="center">+40.7%</td>
            </tr>
            <tr>
              <td align="left"/>
              <td align="left">Family</td>
              <td align="center">0.935</td>
              <td align="center">0.935</td>
              <td align="center">0.935</td>
              <td align="center">0.820</td>
              <td align="center">0.870</td>
              <td align="center">0.844</td>
              <td align="center">+11.5%</td>
              <td align="center">+6.5%</td>
            </tr>
            <tr>
              <td align="left">4SSE</td>
              <td align="left">Class</td>
              <td align="center">0.961</td>
              <td align="center">0.962</td>
              <td align="center">0.961</td>
              <td align="center">0.990</td>
              <td align="center">0.990</td>
              <td align="center">0.990</td>
              <td align="center">-2.9%</td>
              <td align="center">-2.8%</td>
            </tr>
            <tr>
              <td align="left"/>
              <td align="left">Fold</td>
              <td align="center">0.939</td>
              <td align="center">0.939</td>
              <td align="center">0.938</td>
              <td align="center">0.960</td>
              <td align="center">0.830</td>
              <td align="center">0.890</td>
              <td align="center">-2.1%</td>
              <td align="center">+10.9%</td>
            </tr>
            <tr>
              <td align="left"/>
              <td align="left">Superfamily</td>
              <td align="center">0.938</td>
              <td align="center">0.937</td>
              <td align="center">0.937</td>
              <td align="center">0.880</td>
              <td align="center">0.690</td>
              <td align="center">0.774</td>
              <td align="center">+5.8%</td>
              <td align="center">+24.7%</td>
            </tr>
            <tr>
              <td align="left"/>
              <td align="left">Family</td>
              <td align="center">0.935</td>
              <td align="center">0.934</td>
              <td align="center">0.933</td>
              <td align="center">0.980</td>
              <td align="center">0.920</td>
              <td align="center">0.949</td>
              <td align="center">-4.5%</td>
              <td align="center">+1.4%</td>
            </tr>
            <tr>
              <td align="left">5SSE</td>
              <td align="left">Class</td>
              <td align="center">0.985</td>
              <td align="center">0.985</td>
              <td align="center">0.985</td>
              <td align="center">0.980</td>
              <td align="center">1.000</td>
              <td align="center">0.990</td>
              <td align="center">+0.5%</td>
              <td align="center">-1.5%</td>
            </tr>
            <tr>
              <td align="left"/>
              <td align="left">Fold</td>
              <td align="center">0.969</td>
              <td align="center">0.969</td>
              <td align="center">0.969</td>
              <td align="center">1.000</td>
              <td align="center">0.690</td>
              <td align="center">0.817</td>
              <td align="center">-3.1%</td>
              <td align="center">+27.9%</td>
            </tr>
            <tr>
              <td align="left"/>
              <td align="left">Superfamily</td>
              <td align="center">0.970</td>
              <td align="center">0.969</td>
              <td align="center">0.969</td>
              <td align="center">0.980</td>
              <td align="center">0.650</td>
              <td align="center">0.782</td>
              <td align="center">-1.0%</td>
              <td align="center">+31.9%</td>
            </tr>
            <tr>
              <td align="left"/>
              <td align="left">Family</td>
              <td align="center">0.967</td>
              <td align="center">0.965</td>
              <td align="center">0.965</td>
              <td align="center">0.980</td>
              <td align="center">0.920</td>
              <td align="center">0.949</td>
              <td align="center">-1.3%</td>
              <td align="center">+4.5%</td>
            </tr>
            <tr>
              <td align="left">6SSE</td>
              <td align="left">Class</td>
              <td align="center">0.966</td>
              <td align="center">0.965</td>
              <td align="center">0.965</td>
              <td align="center">0.970</td>
              <td align="center">1.000</td>
              <td align="center">0.985</td>
              <td align="center">-0.4%</td>
              <td align="center">-3.5%</td>
            </tr>
            <tr>
              <td align="left"/>
              <td align="left">Fold</td>
              <td align="center">0.943</td>
              <td align="center">0.943</td>
              <td align="center">0.942</td>
              <td align="center">0.950</td>
              <td align="center">0.510</td>
              <td align="center">0.664</td>
              <td align="center">-0.7%</td>
              <td align="center">+43.3%</td>
            </tr>
            <tr>
              <td align="left"/>
              <td align="left">Superfamily</td>
              <td align="center">0.937</td>
              <td align="center">0.939</td>
              <td align="center">0.937</td>
              <td align="center">0.950</td>
              <td align="center">0.570</td>
              <td align="center">0.713</td>
              <td align="center">-1.3%</td>
              <td align="center">+36.9%</td>
            </tr>
            <tr>
              <td align="left"/>
              <td align="left">Family</td>
              <td align="center">0.932</td>
              <td align="center">0.932</td>
              <td align="center">0.930</td>
              <td align="center">0.980</td>
              <td align="center">0.840</td>
              <td align="center">0.905</td>
              <td align="center">-4.8%</td>
              <td align="center">+9.2%</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p>A comparison of prediction performance between the current study and the method introduced by [<xref ref-type="bibr" rid="B29">29</xref>]. The precision and recall metrics are weighted averages. This result comprises a 10-fold cross validation in KNN.</p>
        </table-wrap-foot>
      </table-wrap>
      <fig id="F1" position="float">
        <label>Figure 1</label>
        <caption>
          <p><bold>Comparison of precision and recall.</bold> A comparison of the prediction performance of the CSM+SVD approach and the work of Jain and colleagues in terms of precision and recall. CSM, while achieving a compatible level of precision, presents a significant improvement in recall.</p>
        </caption>
        <graphic xlink:href="1471-2164-12-S4-S12-1"/>
      </fig>
    </sec>
    <sec>
      <title>Noise reduction strategy</title>
      <p>As we mentioned, SVD-based noise reduction was able to improve the precision and recall levels. We obtained a gain of up to 10.3% with the KNN classifier, 35.0% with naive Bayes and 16.2% with random forest. Interestingly, we verified that the different classifiers achieved comparable results after the use of SVD for dimensionality reduction (all levels remained above 90%). Dimension reduction ability is important for scalability in this scenario because many protein domains are experiencing exponential growth. There are about 110,000 domains, i.e., instances to classify, in the SCOP database. Each of these instances can be represented by 151 attributes (dimensions) in the case of the CSM with a cut-off of up to 30Å.</p>
      <p>To find the point that maximizes the noise reduction, we studied the singular value distribution obtained for the gold-standard dataset. Figure <xref ref-type="fig" rid="F2">2</xref> shows the elbow of the curve of the contribution of each singular value to represent the original information. Using about 9 dimensions we can represent the same information (reducing the noise) and obtain very high precision in classification with a considerably smaller dataset. As shown in Figure <xref ref-type="fig" rid="F3">3</xref>, maximum precision can be achieved with about 9 singular values for all experiments.</p>
      <fig id="F2" position="float">
        <label>Figure 2</label>
        <caption>
          <p><bold>Singular value distribution.</bold> Singular value distribution obtained after the execution of the SVD routine for each superfamily considered in the gold-standard dataset. A sudden drop in the singular values denotes the cutoff point for dimensionality reduction. The Y-axes have a logarithmic scale.</p>
        </caption>
        <graphic xlink:href="1471-2164-12-S4-S12-2"/>
      </fig>
      <fig id="F3" position="float">
        <label>Figure 3</label>
        <caption>
          <p><bold>Influence of the number of singular values chosen in precision.</bold> Influence of the cutoff point for dimensionality reduction in the average weighted precision for the superfamilies considered in the gold-standard dataset. A drop in the precision after a certain number of singular values might indicate the point where noisy components start to appear.</p>
        </caption>
        <graphic xlink:href="1471-2164-12-S4-S12-3"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>Conclusions</title>
    <p>Function and fold prediction, while means of understanding the composition, operation, interaction and evolution of proteins, are still great challenges in the face of the explosive growth of protein data generation and storage in public databases. To keep up with the frenetic pace imposed by this increasing data availability, novel, efficient methods for automatic and semi-supervised annotation are needed. As a mechanism to exploit the close relationship between protein structure and function, we developed a structure-based method for function prediction and fold recognition based on protein inter-residue distance patterns. The motivation for this approach arose from the hypothesis that proteins with different structures would show different inter-residue distance patterns, and structural similarity would be reflected in these distances.</p>
    <p>One of the most remarkable advantages of the CSM-based structural signature is its generality, as we successfully instantiated it in different problem domains, such as function and fold prediction. Also, as a requirement and demand for its application to databases that are continuously growing, it is scalable for real-world scenarios, such as whole-SCOP classification tasks, as shown in previous sections, and it shows an efficacy comparable or superior to state-of-the-art protein folding and function predictors. We would like to stress that our method is probably the first to present a full-SCOP automatic classification in acceptable time (a few hours in a quad-core machine).</p>
    <p>The interpretation and understanding of the intrinsic distance patterns generated by CSM demand further investigation. As part of future studies, we intend to explore the generality of CSMs in other aspects of protein function, such as subcellular localization prediction and prediction of GO terms, as well as under different structural classification databases, such as CATH [<xref ref-type="bibr" rid="B30">30</xref>]. We also plan to contrast SVD with feature selection as methods for discriminant information discovery in CSMs.</p>
    <p>Furthermore, the significant gain in prediction power provided by SVD processing might imply that there is room to improve in terms of the data input, indicating that other cutoff ranges and granularities should also be tested, which is a study already in progress in our group.</p>
  </sec>
  <sec sec-type="methods">
    <title>Methods</title>
    <sec>
      <title>CSM-based approach</title>
      <p>Figure <xref ref-type="fig" rid="F4">4</xref> gives a schematic view of the CSM-based approach for protein function prediction and fold recognition employed in this work, which can be divided into data preprocessing, CSM generation, SVD-based dimensionality reduction and classification steps.</p>
      <fig id="F4" position="float">
        <label>Figure 4</label>
        <caption>
          <p><bold>CSM-based function prediction and fold recognition workflow.</bold> A schematic view of the CSM-based function prediction and fold recognition approach is shown. The workflow is divided into steps of data preprocessing, CSM generation, SVD dimensionality reduction, classification and evaluation.</p>
        </caption>
        <graphic xlink:href="1471-2164-12-S4-S12-4"/>
      </fig>
      <p>After the data acquisition and filtering steps for a certain dataset (designed either for function prediction or fold recognition purposes), the CSMs are generated (the details of the procedure are explained later in this section). The CSM defines a feature vector that is then processed with SVD. To define a threshold value for dimensionality reduction, the singular values distribution is analyzed. The elbow of this distribution is used as a threshold for data approximation and recomposition (the explanation of the SVD procedure is detailed in the next subsections) and indicates that the contribution of the other singular values to describing the matrix is insignificant, and thus they might be seen as noise.</p>
      <p>These singular values are then discarded. Finally, the processed CSM is submitted for classification tasks under different algorithms. Metrics such as precision and recall are calculated to assess the prediction power of the classifiers.</p>
    </sec>
    <sec>
      <title>Cutoff scanning matrices</title>
      <p>In a previous work [<xref ref-type="bibr" rid="B26">26</xref>], we conductedd a comparative analysis between two classical methodologies to prospect residue contacts in proteins, one based on geometric aspects, and the other based on a distance threshold or cutoff, by varying (scanning) this distance to find a robust and reliable way to define these contacts. In the present work, we used the cutoff scanning approach for classification purposes, which is the basis of the CSMs. The motivation for the use of this kind of information relies on the fact that proteins with different folds and functions present significant differences in the distribution of distances between their residues. On the other hand, one can expect that proteins with similar structures would also have similar distance distributions between their residues, information that is captured in a CSM.</p>
      <p>The CSMs were generated as follows: for each protein of the datasets, we generated a feature vector. First, we calculated the Euclidean distance between all pairs of <italic>C<sub>α</sub></italic> and defined a range of distances (cutoffs) to be considered and a distance step. We scanned through these distances, computing the frequency of pairs of residues, each represented by its <italic>C<sub>α</sub></italic>, that are close according to this distance threshold. Algorithm 1 shows the function that calculates the CSM.<disp-formula><graphic xlink:href="1471-2164-12-S4-S12-i1.gif"/></disp-formula></p>
      <p>In this work, we vary the distance threshold from 0.0 Å to 30.0 Å, with a 0.2-Å step, which generates a vector of 151 entries for each protein. Together, these vectors compose the CSM. In short, each line of the matrix represents one protein, and each column represents the frequency of residue pairs within a certain distance. Alternatively, this frequency might be seen as the number of contacts in the protein for a certain cutoff distance or the edge count of the contact graph defined using that distance threshold. This step was implemented in the Perl programming language.</p>
      <p>It is important to mentioned that other centroids could be chosen instead of the <italic>C<sub>α</sub></italic>, such as the <italic>C<sub>β</sub></italic> or the last heavy atom (LHA) of the side chain. Additional file <xref ref-type="supplementary-material" rid="S1">1</xref>, Figure S3 shows the performance comparison between the <italic>C<sub>α</sub></italic> and <italic>C<sub>β</sub></italic> for the EC number dataset. The <italic>C<sub>α</sub></italic> performed better in all experiments, a fact that demands further investigation.</p>
      <p>The motivation for using CSMs comes from the differences in the contact distributions for proteins of different structural classes, as can be seen in Additional file <xref ref-type="supplementary-material" rid="S1">1</xref>, Figure S4, which shows the normalized edge count density distribution per cutoff for proteins from different SCOP classes, namely: <italic>all alpha</italic>, <italic>all beta</italic>, <italic>alpha</italic>+<italic>beta</italic> and <italic>alpha/beta</italic>. It is possible to see that the differences between the distributions emerged at different cutoff ranges. For example, the first peaks for the alpha proteins indicate first-order contacts of their helices and the differences at higher cutoffs might happen due to the diameter and density of the proteins. We stress that these variations in the edge count are not only a phenomenon of the secondary structure composition of the proteins but a phenomenon of the protein packing itself. It is important to explain the cutoff variation. The cutoff variation (scanning) aggregates important information related to the packing of the protein and captures, implicitly, the protein shape. We believe that pockets on the surface and even core cavities are well accounted for by this novel type of structure data we proposed. Another example of contact distributions is shown in Figure <xref ref-type="fig" rid="F5">5</xref>. Three proteins with very different shapes were selected (a globin, PDB:1A6M; a porin, PDB:2ZFG; and a collagen, PDB:1BKV), and the topology of the contact graph obtained with different cutoffs is shown (6.0 Å, 9.0 Å and 12.0 Å). The cumulative and normalized density distributions for the CSM feature vectors for these representatives are also plotted. We can see from these examples that an expressive difference in shape is accounted for in the CSM. In the contact profile, the peaks indicate high frequency of recurrent distance patterns present in proteins structures. A higher peak under 3.8-4.0 Å provides evidence for the distances given by consecutive <italic>C<sub>α</sub></italic>s. These distances will tend to be independent of the protein structural class in face of the planar property that characterize the peptide link intermediating two contiguous <italic>C<sub>α</sub></italic>s in the chain. In addition to this pattern, in proteins rich in helices, we will find new suggestive peaks between 5.0 Å and 7.0 Å, representing mainly the recurrent distances between the local (in sequence) <italic>C<sub>α</sub></italic>s positions (<italic>i</italic>, <italic>i</italic> + 2), (<italic>i</italic>, <italic>i</italic> + 3) and (<italic>i</italic>, <italic>i</italic> + 4) that compose turns of a helix, and also some nonlocal contacts. Conversely, in proteins rich in beta strands, important peaks will be noted around 6.0 Å and 5.0 Å, referring not only the distances in local <italic>C<sub>α</sub></italic> positions (<italic>i</italic>, <italic>i</italic> + 2) but also nonlocal <italic>C<sub>α</sub></italic> contacts (<italic>i</italic>, <italic>i</italic> + <italic>k</italic>) present in companion strands. This implies that CSM is manipulating two essential structural information levels: local and nonlocal relevant contacts. We also can see that the shapes of the proteins directly interfere in the underlying contact network, which is reflected in the protein folding, as pointed by [<xref ref-type="bibr" rid="B25">25</xref>]. These properties make the CSM a rich and important source of information when dealing with problems like protein function prediction and structural classification.</p>
      <fig id="F5" position="float">
        <label>Figure 5</label>
        <caption>
          <p><bold>Contact graphs topology per cutoff for proteins with different folds.</bold> The topologies of the contact graphs of three distinct structures (from top to bottom: globin, porin and collagen) at different cutoff values: 6.0Å, 9.0Å and 12.0Å are shown. The edge count for each graph represents an entry in the cutoff scanning feature vector. The normalized cumulative distribution and density distribution of the cutoff scanning profile of these proteins are also shown.</p>
        </caption>
        <graphic xlink:href="1471-2164-12-S4-S12-5"/>
      </fig>
    </sec>
    <sec>
      <title>Noise reduction with SVD</title>
      <p>To reduce the inherent noise in the generated data and also reduce the cost of the classification algorithms in terms of execution time and memory requirements, we used an SVD-based dimensionality reduction. SVD establishes non-obvious, relevant relationships among clustered elements [<xref ref-type="bibr" rid="B31">31</xref>-<xref ref-type="bibr" rid="B33">33</xref>]. The rationale behind SVD is that a matrix <italic>A</italic>, composed of <italic>m</italic> rows by <italic>n</italic> columns, can be represented by a set of derived matrices [<xref ref-type="bibr" rid="B33">33</xref>] that allows for a numerically different representation of data without loss in semantic meaning. That is:<disp-formula><graphic xlink:href="1471-2164-12-S4-S12-i2.gif"/></disp-formula></p>
      <p>Where <italic>T</italic> is an orthonormal matrix of dimensions <italic>m</italic> x <italic>m</italic>, <italic>S</italic> is a diagonal matrix of dimensions <italic>m</italic> x <italic>n</italic> and <italic>D</italic> is an orthonormal matrix with dimensions <italic>n</italic> x <italic>n</italic>. The diagonal values of <italic>S</italic> are the singular values of <italic>A</italic>, and they are ordered from the most to the least significant values.</p>
      <p>When considering only a subset of singular values of size <italic>k</italic> &lt;<italic>p</italic>, where <italic>p</italic> is the rank of <italic>A</italic>, we can achieve <italic>A<sub>k</sub></italic>, an approximate matrix of the original matrix <italic>A</italic>:<disp-formula><graphic xlink:href="1471-2164-12-S4-S12-i3.gif"/></disp-formula></p>
      <p>Thus, data approximation depends on how many singular values are used [<xref ref-type="bibr" rid="B34">34</xref>]. In this case, the <italic>k</italic> number of singular values is also the rank of the matrix <italic>A<sub>k</sub></italic>. The possibility of extraction of information with less data is part of this technique’s success, as it can permit data compression/decompression within a non-exponential execution time, making analysis viable [<xref ref-type="bibr" rid="B34">34</xref>]. A dataset represented by a smaller number of singular values than the full-size original dataset has a tendency to group together certain data items that would not be grouped if we used the original dataset [<xref ref-type="bibr" rid="B33">33</xref>]. This grouping could explain why clusters derived from SVD can expose non-trivial relationships between the original dataset items [<xref ref-type="bibr" rid="B35">35</xref>]. In this paper, we use <italic>A<sub>k</sub></italic>, the product’s factorization by SVD, to rank <italic>k</italic>, but with only two arrays of SVD, the matrix <italic>V<sub>k</sub></italic>[<xref ref-type="bibr" rid="B32">32</xref>] can be represented in the context of the matrix:<disp-formula><graphic xlink:href="1471-2164-12-S4-S12-i4.gif"/></disp-formula></p>
      <p>The justification for using only <italic>V<sub>k</sub></italic> is that the relationships among the columns of <italic>A<sub>k</sub></italic> are preserved in <italic>V<sub>k</sub></italic> because <italic>T<sub>k</sub></italic> is a base for the columns of <italic>A<sub>k</sub></italic>.</p>
      <p>We evaluated the singular values distribution in an effort to find a good threshold to reduce the number of dimensions without losing information. This step, as well as the generation of all graphics, was performed via R programming language scripts.</p>
    </sec>
    <sec>
      <title>Evaluation methodology</title>
      <p>An extensive series of experiments was designed to evaluate the efficacy of CSMs as a source of information for protein fold recognition and function prediction.</p>
      <p>In the classification tasks, the Weka Toolkit [<xref ref-type="bibr" rid="B36">36</xref>], developer version 3.7.2 was used. For the gold-standard dataset, three classification algorithms were used, and their performances were compared: KNN, random forest and naive Bayes. For the other datasets, KNN was used. The algorithms’ parameters, when applicable, were varied and the best result computed. In all scenarios, 10-fold cross validation was applied. The classification performance was evaluated using metrics such as <italic>precision</italic> (<italic>Precision</italic> = <italic>TP/</italic>(<italic>TP</italic> + <italic>FP</italic>)), <italic>recall</italic> (<italic>Recall</italic> = <italic>TP/</italic>(<italic>TP</italic> + <italic>FN</italic>)), <italic>F1 score</italic> (the harmonic mean between precision and recall: <inline-formula><inline-graphic xlink:href="1471-2164-12-S4-S12-i5.gif"/></inline-formula>) and the Area Under the ROC Curve (AUC). The variation in precision was used to measure the gain obtained with SVD processing, and the recall variation was evaluated to compare the results with those for the dataset derived from [<xref ref-type="bibr" rid="B29">29</xref>].</p>
      <p>We also correlated the precision obtained by the classifiers and the number of singular values considered and compared it with the results using the whole CSM.</p>
    </sec>
    <sec>
      <title>Datasets</title>
      <p>Our datasets consisted of proteins structures available in the Protein Data Bank [<xref ref-type="bibr" rid="B4">4</xref>]. The domains covered by SCOP release 1.75 were obtained through the ASTRAL compendium [<xref ref-type="bibr" rid="B37">37</xref>]. The protein structures were grouped according to the purpose of the experiment, namely, function prediction or fold recognition. For structures solved by NMR, we only considered the first model. The chains were split into separate files and the <italic>C<sub>α</sub></italic> co-ordinates extracted using PDBEST toolkit.</p>
      <p>The first dataset concerns a gold-standard of mechanistically diverse enzyme superfamilies [<xref ref-type="bibr" rid="B28">28</xref>]. We consider <italic>six superfamilies</italic> (amidohydrolase, crotonase, haloacid dehalogenase, isoprenoid synthase type I and vicinal oxygen chelate), comprising 47 families distributed among 566 different <italic>chains</italic>. The list of PDB IDs as well as the family and superfamily assignments are available in Additional file <xref ref-type="supplementary-material" rid="S2">2</xref>.</p>
      <p>The second dataset contains enzymes with EC numbers. We considered the top 950 most-populated EC numbers in terms of available structures, with at least 9 representatives per class, in a total of 55,474 chains, which covered 95% of the reviewed enzymes from Uniprot [<xref ref-type="bibr" rid="B1">1</xref>], i.e., the experimentally validated annotations from that database.</p>
      <p>The third dataset originated from SCOP version 1.75 for fold recognition tasks. We selected all PDB IDs covered by SCOP with at least 10 residues and 10 representatives per node in the SCOP classification hierarchy. These IDs represented a total of 110,799, 108,332, 106,657 and 102,100 domains at the class, fold, superfamily and family levels, respectively. We would like to emphasize that this is a very large dataset and that we found no other paper relating the use of such a complete dataset in strutcural classification tasks. The last dataset was derived from [<xref ref-type="bibr" rid="B29">29</xref>] for comparison in fold recognition tasks. We selected all domains described in its additional files with a minimum of 10 representatives per node in the SCOP classification hierarchy. It was not possible to identify exactly the domains they used from the additional files and only those pairs of domains with a sequence identify below 35% were retained. It is important to stress that the work of Jain and colleagues only contemplate structures with 3, 4, 5 or 6 secondary structure elements.</p>
    </sec>
  </sec>
  <sec>
    <title>List of abbreviations used</title>
    <p>EC: Enzyme Commission; CSM: Cutoff Scanning Matrix; DUF: Domain of Unknown Function; SVD: Singular Value Decomposition; PDB: Protein Data Bank; SCOP: Structural Classification of Proteins; GO: Gene Ontology; LHA: Last Heavy Atom; KNN: K-Nearest Neighbors; AUC: Area Under the ROC Curve.</p>
  </sec>
  <sec>
    <title>Competing interests</title>
    <p>The authors declare that they have no competing interests.</p>
  </sec>
  <sec>
    <title>Authors' contributions</title>
    <p>DEVP conceived of the study, developed the algorithms, performed the experiments and drafted the manuscript. RCMM participated in the design of the study, helped with presenting and analyzing the results and drafted the manuscript. MAS participated in the design of the study, provided advice on the SVD analysis and helped draft the manuscript. CHS helped with presenting the results, provided advice on its analysis and helped draft the manuscript. MMS helped draft the manuscript and provided advice on analyzing the results. WM participated in the coordination of the study and helped draft the manuscript. All authors read and approved the final manuscript.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="S1">
      <caption>
        <title>Additional file 1</title>
        <p><bold>Additional figures and tables.</bold> Figure S1 - Performance metrics across EC classes. Figure S2 - Correlation between precision and minimum number of representatives. Figure S3 - The influence of <italic>C<sub>α</sub></italic> and <italic>C<sub>β</sub></italic> distances in the performance. Figure S4 - Feature vector density distribution for proteins of different SCOP classes. Table S1 - Function prediction performance using naive Bayes for gold-standard dataset. Table S2 - Function prediction performance using random forest for the gold-standard dataset.</p>
      </caption>
      <media xlink:href="1471-2164-12-S4-S12-S1.pdf" mimetype="application" mime-subtype="pdf">
        <caption>
          <p>Click here for file</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="S2">
      <caption>
        <title>Additional 2</title>
        <p><bold>Enzyme gold-standard dataset.</bold> List of PDB identifiers that compose the enzyme gold-standard dataset and its family and superfamily assignments.</p>
      </caption>
      <media xlink:href="1471-2164-12-S4-S12-S2.csv" mimetype="text" mime-subtype="plain">
        <caption>
          <p>Click here for file</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Acknowledgements</title>
    <p>This work was supported by the Brazilian agencies: CAPES, CNPq, FAPEMIG and FINEP. The EC number dataset was kindly provided by Elisa Lima.</p>
    <p>This article has been published as part of <italic>BMC Genomics</italic> Volume 12 Supplement 4, 2011: Proceedings of the 6th International Conference of the Brazilian Association for Bioinformatics and Computational Biology (X-meeting 2010). The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="http://www.biomedcentral.com/1471-2164/12?issue=S4">http://www.biomedcentral.com/1471-2164/12?issue=S4</ext-link></p>
  </sec>
  <ref-list>
    <ref id="B1">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Consortium</surname>
          <given-names>TU</given-names>
        </name>
        <article-title>The Universal Protein Resource (UniProt) in 2010</article-title>
        <source>Nucleic Acids Research</source>
        <year>2010</year>
        <volume>38</volume>
        <issue>Database issue</issue>
        <fpage>D142</fpage>
        <lpage>D148</lpage>
        <pub-id pub-id-type="pmid">19843607</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Finn</surname>
          <given-names>RD</given-names>
        </name>
        <name>
          <surname>Mistry</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Coggill</surname>
          <given-names>P</given-names>
        </name>
        <name>
          <surname>Heger</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Pollington</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Gavin</surname>
          <given-names>OL</given-names>
        </name>
        <name>
          <surname>Gunasekaran</surname>
          <given-names>P</given-names>
        </name>
        <name>
          <surname>Ceric</surname>
          <given-names>G</given-names>
        </name>
        <name>
          <surname>Forslund</surname>
          <given-names>K</given-names>
        </name>
        <name>
          <surname>Holm</surname>
          <given-names>L</given-names>
        </name>
        <name>
          <surname>Sohhhammer</surname>
          <given-names>ELL</given-names>
        </name>
        <name>
          <surname>Eddy</surname>
          <given-names>SR</given-names>
        </name>
        <name>
          <surname>Bateman</surname>
          <given-names>A</given-names>
        </name>
        <article-title>The Pfam protein families database</article-title>
        <source>Nucleic Acids Research</source>
        <year>2010</year>
        <volume>38</volume>
        <issue>Database issue</issue>
        <fpage>D211</fpage>
        <lpage>D222</lpage>
        <pub-id pub-id-type="pmid">19920124</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Murzin</surname>
          <given-names>AG</given-names>
        </name>
        <name>
          <surname>Brenner</surname>
          <given-names>SE</given-names>
        </name>
        <name>
          <surname>Hubbard</surname>
          <given-names>T</given-names>
        </name>
        <name>
          <surname>Chothia</surname>
          <given-names>C</given-names>
        </name>
        <article-title>SCOP: a structural classification of proteins database for the investigation of sequences and structures</article-title>
        <source>Journal of Molecular Biology</source>
        <year>1995</year>
        <volume>247</volume>
        <issue>4</issue>
        <fpage>536</fpage>
        <lpage>40</lpage>
        <pub-id pub-id-type="pmid">7723011</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Berman</surname>
          <given-names>HM</given-names>
        </name>
        <name>
          <surname>Battistuz</surname>
          <given-names>T</given-names>
        </name>
        <name>
          <surname>Bhat</surname>
          <given-names>TN</given-names>
        </name>
        <name>
          <surname>Bluhm</surname>
          <given-names>WF</given-names>
        </name>
        <name>
          <surname>Bourne</surname>
          <given-names>PE</given-names>
        </name>
        <name>
          <surname>Burkhardt</surname>
          <given-names>K</given-names>
        </name>
        <name>
          <surname>Feng</surname>
          <given-names>Z</given-names>
        </name>
        <name>
          <surname>Gilliland</surname>
          <given-names>GL</given-names>
        </name>
        <name>
          <surname>Iype</surname>
          <given-names>L</given-names>
        </name>
        <name>
          <surname>Jain</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Fagan</surname>
          <given-names>P</given-names>
        </name>
        <name>
          <surname>Marvin</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Padilla</surname>
          <given-names>D</given-names>
        </name>
        <name>
          <surname>Ravichandran</surname>
          <given-names>V</given-names>
        </name>
        <name>
          <surname>Schneider</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Thanki</surname>
          <given-names>N</given-names>
        </name>
        <name>
          <surname>Weissig</surname>
          <given-names>H</given-names>
        </name>
        <name>
          <surname>Westbrook</surname>
          <given-names>JD</given-names>
        </name>
        <name>
          <surname>Zardecki</surname>
          <given-names>C</given-names>
        </name>
        <article-title>The Protein Data Bank</article-title>
        <source>Acta Crystallogr D Biol Crystallogr</source>
        <year>2002</year>
        <volume>58</volume>
        <issue>Pt 6 No 1</issue>
        <fpage>899</fpage>
        <lpage>907</lpage>
        <pub-id pub-id-type="pmid">12037327</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Laskowski</surname>
          <given-names>RA</given-names>
        </name>
        <name>
          <surname>Watson</surname>
          <given-names>JD</given-names>
        </name>
        <name>
          <surname>Thornton</surname>
          <given-names>JM</given-names>
        </name>
        <article-title>Protein function prediction using local 3D templates</article-title>
        <source>Journal of Molecular Biology</source>
        <year>2005</year>
        <volume>351</volume>
        <issue>3</issue>
        <fpage>614</fpage>
        <lpage>626</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmb.2005.05.067</pub-id>
        <pub-id pub-id-type="pmid">16019027</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Laskowski</surname>
          <given-names>RA</given-names>
        </name>
        <name>
          <surname>Watson</surname>
          <given-names>JD</given-names>
        </name>
        <name>
          <surname>Thornton</surname>
          <given-names>JM</given-names>
        </name>
        <article-title>ProFunc: a server for predicting protein function from 3D structure</article-title>
        <source>Nucleic Acids Research</source>
        <year>2005</year>
        <volume>33</volume>
        <issue>Web Server issue</issue>
        <fpage>W89</fpage>
        <lpage>93</lpage>
        <pub-id pub-id-type="pmid">15980588</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Watson</surname>
          <given-names>JD</given-names>
        </name>
        <name>
          <surname>Roman</surname>
          <given-names>AL</given-names>
        </name>
        <name>
          <surname>Thornton</surname>
          <given-names>JM</given-names>
        </name>
        <article-title>Predicting protein function from sequence and structural data</article-title>
        <source>Current Opinion in Structural Biology</source>
        <year>2005</year>
        <volume>15</volume>
        <issue>3</issue>
        <fpage>275</fpage>
        <lpage>284</lpage>
        <pub-id pub-id-type="doi">10.1016/j.sbi.2005.04.003</pub-id>
        <pub-id pub-id-type="pmid">15963890</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Watson</surname>
          <given-names>JD</given-names>
        </name>
        <name>
          <surname>Sanderson</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Ezersky</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Savchenko</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Edwards</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Orengo</surname>
          <given-names>C</given-names>
        </name>
        <name>
          <surname>Joachimiak</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Laskowski</surname>
          <given-names>RA</given-names>
        </name>
        <name>
          <surname>Thornton</surname>
          <given-names>JM</given-names>
        </name>
        <article-title>Towards fully automated structure-based function prediction in structural genomics: a case study</article-title>
        <source>Journal of Molecular Biology</source>
        <year>2007</year>
        <volume>367</volume>
        <issue>5</issue>
        <fpage>1511</fpage>
        <lpage>1522</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmb.2007.01.063</pub-id>
        <pub-id pub-id-type="pmid">17316683</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Chothia</surname>
          <given-names>C</given-names>
        </name>
        <name>
          <surname>Lesk</surname>
          <given-names>AM</given-names>
        </name>
        <article-title>The relation between the divergence of sequence and structure in proteins</article-title>
        <source>EMBO J</source>
        <year>1986</year>
        <volume>5</volume>
        <issue>4</issue>
        <fpage>823</fpage>
        <lpage>6</lpage>
        <pub-id pub-id-type="pmid">3709526</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Ding</surname>
          <given-names>CH</given-names>
        </name>
        <name>
          <surname>Dubchak</surname>
          <given-names>I</given-names>
        </name>
        <article-title>Multi-class protein fold recognition using support vector machines and neural networks</article-title>
        <source>Bioinformatics</source>
        <year>2001</year>
        <volume>17</volume>
        <issue>4</issue>
        <fpage>349</fpage>
        <lpage>58</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/17.4.349</pub-id>
        <pub-id pub-id-type="pmid">11301304</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Shen</surname>
          <given-names>HB</given-names>
        </name>
        <name>
          <surname>Chou</surname>
          <given-names>KC</given-names>
        </name>
        <article-title>Ensemble classifier for protein fold pattern recognition</article-title>
        <source>Bioinformatics</source>
        <year>2006</year>
        <volume>22</volume>
        <issue>14</issue>
        <fpage>1717</fpage>
        <lpage>22</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btl170</pub-id>
        <pub-id pub-id-type="pmid">16672258</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Cheng</surname>
          <given-names>J</given-names>
        </name>
        <name>
          <surname>Baldi</surname>
          <given-names>P</given-names>
        </name>
        <article-title>A machine learning information retrieval approach to protein fold recognition</article-title>
        <source>Bioinformatics</source>
        <year>2006</year>
        <volume>22</volume>
        <issue>12</issue>
        <fpage>1456</fpage>
        <lpage>63</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btl102</pub-id>
        <pub-id pub-id-type="pmid">16547073</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Barker</surname>
          <given-names>JA</given-names>
        </name>
        <name>
          <surname>Thornton</surname>
          <given-names>JM</given-names>
        </name>
        <article-title>An algorithm for constraint-based structural template matching: application to 3D templates with statistical analysis</article-title>
        <source>Bioinformatics</source>
        <year>2003</year>
        <volume>19</volume>
        <issue>13</issue>
        <fpage>1644</fpage>
        <lpage>9</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btg226</pub-id>
        <pub-id pub-id-type="pmid">12967960</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Goyal</surname>
          <given-names>K</given-names>
        </name>
        <name>
          <surname>Mohanty</surname>
          <given-names>D</given-names>
        </name>
        <name>
          <surname>Mande</surname>
          <given-names>SC</given-names>
        </name>
        <article-title>PAR-3D: a server to predict protein active site residues</article-title>
        <source>Nucleic Acids Research</source>
        <year>2007</year>
        <volume>35</volume>
        <issue>Web Server issue</issue>
        <fpage>W503</fpage>
        <lpage>5</lpage>
        <pub-id pub-id-type="pmid">17478506</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Stark</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Russell</surname>
          <given-names>RB</given-names>
        </name>
        <article-title>Annotation in three dimensions. PINTS: Patterns in Non-homologous Tertiary Structures</article-title>
        <source>Nucleic Acids Research</source>
        <year>2003</year>
        <volume>31</volume>
        <issue>13</issue>
        <fpage>3341</fpage>
        <lpage>4</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkg506</pub-id>
        <pub-id pub-id-type="pmid">12824322</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Shazman</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Celniker</surname>
          <given-names>G</given-names>
        </name>
        <name>
          <surname>Haber</surname>
          <given-names>O</given-names>
        </name>
        <name>
          <surname>Glaser</surname>
          <given-names>F</given-names>
        </name>
        <name>
          <surname>Mandel-Gutfreund</surname>
          <given-names>Y</given-names>
        </name>
        <article-title>Patch Finder Plus (PFplus): a web server for extracting and displaying positive electrostatic patches on protein surfaces</article-title>
        <source>Nucleic Acids Research</source>
        <year>2007</year>
        <volume>35</volume>
        <issue>Web Server issue</issue>
        <fpage>W526</fpage>
        <lpage>30</lpage>
        <pub-id pub-id-type="pmid">17537808</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Babor</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Gerzon</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Raveh</surname>
          <given-names>B</given-names>
        </name>
        <name>
          <surname>Sobolev</surname>
          <given-names>V</given-names>
        </name>
        <name>
          <surname>Edelman</surname>
          <given-names>M</given-names>
        </name>
        <article-title>Prediction of transition metal-binding sites from apo protein structures</article-title>
        <source>Proteins</source>
        <year>2008</year>
        <volume>70</volume>
        <fpage>208</fpage>
        <lpage>217</lpage>
        <pub-id pub-id-type="pmid">17657805</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Holm</surname>
          <given-names>L</given-names>
        </name>
        <name>
          <surname>Sander</surname>
          <given-names>C</given-names>
        </name>
        <article-title>Protein structure comparison by alignment of distance matrices</article-title>
        <source>Journal of Molecular Biology</source>
        <year>1993</year>
        <volume>233</volume>
        <fpage>123</fpage>
        <lpage>38</lpage>
        <pub-id pub-id-type="doi">10.1006/jmbi.1993.1489</pub-id>
        <pub-id pub-id-type="pmid">8377180</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Kolodny</surname>
          <given-names>R</given-names>
        </name>
        <name>
          <surname>Koehl</surname>
          <given-names>P</given-names>
        </name>
        <name>
          <surname>Levitt</surname>
          <given-names>M</given-names>
        </name>
        <article-title>Comprehensive evaluation of protein structure alignment methods: scoring by geometric measures</article-title>
        <source>Journal of Molecular Biology</source>
        <year>2005</year>
        <volume>346</volume>
        <issue>4</issue>
        <fpage>1173</fpage>
        <lpage>88</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmb.2004.12.032</pub-id>
        <pub-id pub-id-type="pmid">15701525</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Dobson</surname>
          <given-names>PD</given-names>
        </name>
        <name>
          <surname>Doig</surname>
          <given-names>AJ</given-names>
        </name>
        <article-title>Predicting enzyme class from protein structure without alignments</article-title>
        <source>Journal of Molecular Biology</source>
        <year>2005</year>
        <volume>345</volume>
        <fpage>187</fpage>
        <lpage>199</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmb.2004.10.024</pub-id>
        <pub-id pub-id-type="pmid">15567421</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="other">
        <name>
          <surname>Alvarez</surname>
          <given-names>MA</given-names>
        </name>
        <name>
          <surname>Yan</surname>
          <given-names>C</given-names>
        </name>
        <article-title>Exploring structural modeling of proteins for kernel-based enzyme discrimination</article-title>
        <source>IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)</source>
        <year>2010</year>
        <fpage>1</fpage>
        <lpage>5</lpage>
      </mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Punta</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Ofran</surname>
          <given-names>Y</given-names>
        </name>
        <article-title>The rough guide to in silico function prediction, or how to use sequence and structure information to predict protein function</article-title>
        <source>PLoS Computational Biology</source>
        <year>2008</year>
        <volume>4</volume>
        <issue>10</issue>
        <fpage>e1000160</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1000160</pub-id>
        <pub-id pub-id-type="pmid">18974821</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Ashburner</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Ball</surname>
          <given-names>CA</given-names>
        </name>
        <name>
          <surname>Blake</surname>
          <given-names>JA</given-names>
        </name>
        <name>
          <surname>Botstein</surname>
          <given-names>D</given-names>
        </name>
        <name>
          <surname>Butler</surname>
          <given-names>H</given-names>
        </name>
        <name>
          <surname>Cherry</surname>
          <given-names>JM</given-names>
        </name>
        <name>
          <surname>Davis</surname>
          <given-names>AP</given-names>
        </name>
        <name>
          <surname>Dolinski</surname>
          <given-names>K</given-names>
        </name>
        <name>
          <surname>Dwight</surname>
          <given-names>SS</given-names>
        </name>
        <name>
          <surname>Eppig</surname>
          <given-names>JT</given-names>
        </name>
        <name>
          <surname>Harris</surname>
          <given-names>MA</given-names>
        </name>
        <name>
          <surname>Hill</surname>
          <given-names>DP</given-names>
        </name>
        <name>
          <surname>Issel-Tarver</surname>
          <given-names>L</given-names>
        </name>
        <name>
          <surname>Kasarskis</surname>
          <given-names>A</given-names>
        </name>
        <name>
          <surname>Lewis</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Matese</surname>
          <given-names>JC</given-names>
        </name>
        <name>
          <surname>Richardson</surname>
          <given-names>JE</given-names>
        </name>
        <name>
          <surname>Ringwald</surname>
          <given-names>M</given-names>
        </name>
        <name>
          <surname>Rubin</surname>
          <given-names>GM</given-names>
        </name>
        <name>
          <surname>Sherlock</surname>
          <given-names>G</given-names>
        </name>
        <article-title>Gene ontology: tool for the unification of biology. The Gene Ontology Consortium</article-title>
        <source>Nature Genetics</source>
        <year>2000</year>
        <volume>25</volume>
        <fpage>25</fpage>
        <lpage>29</lpage>
        <pub-id pub-id-type="doi">10.1038/75556</pub-id>
        <pub-id pub-id-type="pmid">10802651</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Lee</surname>
          <given-names>D</given-names>
        </name>
        <name>
          <surname>Redfen</surname>
          <given-names>O</given-names>
        </name>
        <name>
          <surname>C</surname>
          <given-names>O</given-names>
        </name>
        <article-title>Predicting protein function from sequence and structure</article-title>
        <source>Nature Reviews: Molecular Cell Biology</source>
        <year>2007</year>
        <volume>8</volume>
        <issue>12</issue>
        <fpage>995</fpage>
        <lpage>1005</lpage>
        <pub-id pub-id-type="doi">10.1038/nrm2281</pub-id>
        <pub-id pub-id-type="pmid">18037900</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Soundararajan</surname>
          <given-names>V</given-names>
        </name>
        <name>
          <surname>Raman</surname>
          <given-names>R</given-names>
        </name>
        <name>
          <surname>Raguram</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Sasisekharan</surname>
          <given-names>V</given-names>
        </name>
        <name>
          <surname>Sasisekharan</surname>
          <given-names>R</given-names>
        </name>
        <article-title>Atomic interaction networks in the core of protein domains and their native folds</article-title>
        <source>PLoS One</source>
        <year>2010</year>
        <volume>5</volume>
        <issue>2</issue>
        <fpage>e9391</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0009391</pub-id>
        <pub-id pub-id-type="pmid">20186337</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal">
        <name>
          <surname>da Silveira</surname>
          <given-names>CH</given-names>
        </name>
        <name>
          <surname>Pires</surname>
          <given-names>DE</given-names>
        </name>
        <name>
          <surname>Minardi</surname>
          <given-names>RC</given-names>
        </name>
        <name>
          <surname>Ribeiro</surname>
          <given-names>C</given-names>
        </name>
        <name>
          <surname>Veloso</surname>
          <given-names>CJ</given-names>
        </name>
        <name>
          <surname>Lopes</surname>
          <given-names>JC</given-names>
        </name>
        <name>
          <surname>Meira</surname>
          <given-names>W</given-names>
          <suffix>Jr</suffix>
        </name>
        <name>
          <surname>Neshich</surname>
          <given-names>G</given-names>
        </name>
        <name>
          <surname>Ramos</surname>
          <given-names>CH</given-names>
        </name>
        <name>
          <surname>Habesch</surname>
          <given-names>R</given-names>
        </name>
        <name>
          <surname>Santoro</surname>
          <given-names>MM</given-names>
        </name>
        <article-title>Protein cutoff scanning: a comparative analysis of cutoff dependent and cutoff free methods for prospecting contacts in proteins</article-title>
        <source>Proteins</source>
        <year>2009</year>
        <volume>74</volume>
        <issue>3</issue>
        <fpage>727</fpage>
        <lpage>743</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.22187</pub-id>
        <pub-id pub-id-type="pmid">18704933</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Delaunay</surname>
          <given-names>B</given-names>
        </name>
        <article-title>Sur la sphere vide. A la memoire de Georges Voronoi</article-title>
        <source>Izv Akad Nauk SSSR</source>
        <year>1934</year>
        <volume>7</volume>
        <fpage>793</fpage>
        <lpage>800</lpage>
      </mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Brown</surname>
          <given-names>SD</given-names>
        </name>
        <name>
          <surname>Gerlt</surname>
          <given-names>JA</given-names>
        </name>
        <name>
          <surname>Seffernick</surname>
          <given-names>JL</given-names>
        </name>
        <name>
          <surname>Babbitt</surname>
          <given-names>PC</given-names>
        </name>
        <article-title>A gold standard set of mechanistically diverse enzyme superfamilies</article-title>
        <source>Genome Biology</source>
        <year>2006</year>
        <volume>7</volume>
        <fpage>R8</fpage>
        <pub-id pub-id-type="doi">10.1186/gb-2006-7-1-r8</pub-id>
        <pub-id pub-id-type="pmid">16507141</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Jain</surname>
          <given-names>P</given-names>
        </name>
        <name>
          <surname>Hirst</surname>
          <given-names>JD</given-names>
        </name>
        <article-title>Automatic structure classification of small proteins using random forest</article-title>
        <source>BMC Bioinformatics</source>
        <year>2010</year>
        <volume>11</volume>
        <issue>364</issue>
        <fpage>1</fpage>
        <lpage>14</lpage>
        <pub-id pub-id-type="pmid">20043860</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Orengo</surname>
          <given-names>CA</given-names>
        </name>
        <name>
          <surname>Michie</surname>
          <given-names>AD</given-names>
        </name>
        <name>
          <surname>Jones</surname>
          <given-names>S</given-names>
        </name>
        <name>
          <surname>Jones</surname>
          <given-names>DT</given-names>
        </name>
        <name>
          <surname>Swindells</surname>
          <given-names>MB</given-names>
        </name>
        <name>
          <surname>Thornton</surname>
          <given-names>JM</given-names>
        </name>
        <article-title>CATH - a hierarchic classification of protein domain structures</article-title>
        <source>Structure</source>
        <year>1997</year>
        <volume>5</volume>
        <issue>8</issue>
        <fpage>1093</fpage>
        <lpage>108</lpage>
        <pub-id pub-id-type="doi">10.1016/S0969-2126(97)00260-8</pub-id>
        <pub-id pub-id-type="pmid">9309224</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="other">
        <name>
          <surname>Eldén</surname>
          <given-names>L</given-names>
        </name>
        <article-title>Matrix Methods in Data Mining and Pattern Recognition (Fundamentals of Algorithms)</article-title>
        <source>Society for Industrial and Applied Mathematics</source>
        <year>2007</year>
      </mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Eldén</surname>
          <given-names>L</given-names>
        </name>
        <article-title>Numerical linear algebra in data mining</article-title>
        <source>Acta Numerica</source>
        <year>2006</year>
        <volume>15</volume>
        <fpage>327</fpage>
        <lpage>384</lpage>
      </mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Berry</surname>
          <given-names>MW</given-names>
        </name>
        <name>
          <surname>Dumais</surname>
          <given-names>ST</given-names>
        </name>
        <name>
          <surname>O’Brien</surname>
          <given-names>GW</given-names>
        </name>
        <article-title>Using linear algebra for intelligent information retrieval</article-title>
        <source>SIAM review</source>
        <year>1995</year>
        <volume>37</volume>
        <issue>4</issue>
        <fpage>573</fpage>
        <lpage>595</lpage>
        <pub-id pub-id-type="doi">10.1137/1037127</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="journal">
        <name>
          <surname>del Castillo-Negrete</surname>
          <given-names>D</given-names>
        </name>
        <name>
          <surname>Hirshman</surname>
          <given-names>SP</given-names>
        </name>
        <name>
          <surname>Spong</surname>
          <given-names>DA</given-names>
        </name>
        <name>
          <surname>D’Azevedo</surname>
          <given-names>EF</given-names>
        </name>
        <article-title>Compression of magnetohydrodynamic simulation data using singular value decomposition</article-title>
        <source>Journal of Computational Physics</source>
        <year>2007</year>
        <volume>222</volume>
        <fpage>265</fpage>
        <lpage>286</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jcp.2006.07.022</pub-id>
      </mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="other">
        <name>
          <surname>Deerwester</surname>
          <given-names>SC</given-names>
        </name>
        <name>
          <surname>Dumais</surname>
          <given-names>ST</given-names>
        </name>
        <name>
          <surname>Furnas</surname>
          <given-names>GW</given-names>
        </name>
        <name>
          <surname>Harshman</surname>
          <given-names>RA</given-names>
        </name>
        <name>
          <surname>Landauer</surname>
          <given-names>TK</given-names>
        </name>
        <name>
          <surname>Lochbaum</surname>
          <given-names>KE</given-names>
        </name>
        <name>
          <surname>Streeter</surname>
          <given-names>LA</given-names>
        </name>
        <article-title>Computer information retrieval using latent semantic structure</article-title>
        <year>1989</year>
      </mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="book">
        <name>
          <surname>Witten</surname>
          <given-names>IH</given-names>
        </name>
        <name>
          <surname>Frank</surname>
          <given-names>E</given-names>
        </name>
        <source>Data Mining: Practical Machine Learning Tools and Techniques</source>
        <year>2005</year>
        <edition>second</edition>
        <publisher-name>Morgan Kaufmann</publisher-name>
      </mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="journal">
        <name>
          <surname>Brenner</surname>
          <given-names>SE</given-names>
        </name>
        <name>
          <surname>Koehl</surname>
          <given-names>P</given-names>
        </name>
        <name>
          <surname>Levitt</surname>
          <given-names>M</given-names>
        </name>
        <article-title>The ASTRAL compendium for sequence and structure analysis</article-title>
        <source>Nucleic Acids Research</source>
        <year>2000</year>
        <volume>28</volume>
        <fpage>254</fpage>
        <lpage>256</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/28.1.254</pub-id>
        <pub-id pub-id-type="pmid">10592239</pub-id>
      </mixed-citation>
    </ref>
  </ref-list>
</back>
