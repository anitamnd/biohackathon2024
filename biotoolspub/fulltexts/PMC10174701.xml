<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Biol Methods Protoc</journal-id>
    <journal-id journal-id-type="iso-abbrev">Biol Methods Protoc</journal-id>
    <journal-id journal-id-type="publisher-id">biomethods</journal-id>
    <journal-title-group>
      <journal-title>Biology Methods &amp; Protocols</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2396-8923</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10174701</article-id>
    <article-id pub-id-type="doi">10.1093/biomethods/bpad007</article-id>
    <article-id pub-id-type="publisher-id">bpad007</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Special Collection: Covid19 Methods &amp; Protocols</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Methods Article</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="category-taxonomy-collection">
        <subject>AcademicSubjects/SCI00960</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>CurSa: scripts to curate metadata and sample genomes from GISAID for analysis and display in nextstrain and microreact</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0000-0003-4193-2720</contrib-id>
        <name>
          <surname>Delaye</surname>
          <given-names>Luis</given-names>
        </name>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/conceptualization" degree-contribution="lead">Conceptualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Data curation" vocab-term-identifier="http://credit.niso.org/contributor-roles/data-curation" degree-contribution="lead">Data curation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="http://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="lead">Formal analysis</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Funding acquisition" vocab-term-identifier="http://credit.niso.org/contributor-roles/funding-acquisition" degree-contribution="lead">Funding acquisition</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="http://credit.niso.org/contributor-roles/investigation" degree-contribution="lead">Investigation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="http://credit.niso.org/contributor-roles/methodology" degree-contribution="lead">Methodology</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Project administration" vocab-term-identifier="http://credit.niso.org/contributor-roles/project-administration" degree-contribution="lead">Project administration</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Resources" vocab-term-identifier="http://credit.niso.org/contributor-roles/resources" degree-contribution="lead">Resources</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Software" vocab-term-identifier="http://credit.niso.org/contributor-roles/software" degree-contribution="lead">Software</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Supervision" vocab-term-identifier="http://credit.niso.org/contributor-roles/supervision" degree-contribution="lead">Supervision</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Validation" vocab-term-identifier="http://credit.niso.org/contributor-roles/validation" degree-contribution="lead">Validation</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="http://credit.niso.org/contributor-roles/visualization" degree-contribution="lead">Visualization</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="" degree-contribution="lead">Writing - original draft</role>
        <role vocab="credit" vocab-identifier="http://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="" degree-contribution="lead">Writing - review &amp; editing</role>
        <aff><institution>Department of Genetic Engineering, CINVESTAV-Irapuato</institution>, Irapuato, Guanajuato 36824, <country country="MX">Mexico</country></aff>
        <!--luis.delaye@cinvestav.mx-->
        <xref rid="bpad007-cor1" ref-type="corresp"/>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="bpad007-cor1">Correspondence address. Tel: +52 (462) 623 9600; E-mail: <email>luis.delaye@cinvestav.mx</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2023-04-17">
      <day>17</day>
      <month>4</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>17</day>
      <month>4</month>
      <year>2023</year>
    </pub-date>
    <volume>8</volume>
    <issue>1</issue>
    <elocation-id>bpad007</elocation-id>
    <history>
      <date date-type="received">
        <day>23</day>
        <month>12</month>
        <year>2022</year>
      </date>
      <date date-type="rev-recd">
        <day>26</day>
        <month>3</month>
        <year>2023</year>
      </date>
      <date date-type="editorial-decision">
        <day>11</day>
        <month>4</month>
        <year>2023</year>
      </date>
      <date date-type="accepted">
        <day>11</day>
        <month>4</month>
        <year>2023</year>
      </date>
      <date date-type="corrected-typeset">
        <day>11</day>
        <month>5</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2023. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2023</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="bpad007.pdf"/>
    <abstract>
      <title>Abstract</title>
      <p>The coronavirus SARS-CoV-2 is the most sequenced pathogen ever, with several million genome copies deposited in the GISAID database. This large amount of genomic information poses non-trivial bioinformatic challenges for those interested in studying the evolution of SARS-CoV-2. One common problem when studying the phylogeny of the coronavirus in its geographical context is to count with accurate information of the location of the samples. However, this information is filled by hand by research groups all over the world and sometimes typos and inconsistencies are introduced in the metadata when submitting the sequences to GISAID. Correcting these errors is laborious and time-consuming. Here, we provide a suite of Perl scripts designated to facilitate the curation of this vital information and perform a random sampling of genome sequences if necessary. The scripts provided here can be used to curate geographic information in the metadata and sample the sequences from any country of interest to ease the preparation of files for Nextstrain and Microreact, thus accelerating evolutionary studies of this important pathogen. CurSa scripts are accessible via: <ext-link xlink:href="https://github.com/luisdelaye/CurSa/" ext-link-type="uri">https://github.com/luisdelaye/CurSa/</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>coronavirus</kwd>
      <kwd>SARS-CoV-2</kwd>
      <kwd>phylogenomics</kwd>
    </kwd-group>
    <counts>
      <page-count count="7"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro">
    <title>Introduction</title>
    <p>Current sequencing technologies allowed the scientific community to describe the evolution of SARS-CoV-2 with unprecedented detail [<xref rid="bpad007-B1" ref-type="bibr">1</xref>]. At the time of writing, there are more than 15 million SARS-CoV-2 genome sequences deposited in GISAID (<ext-link xlink:href="https://www.gisaid.org" ext-link-type="uri">https://www.gisaid.org</ext-link>). This large amount of genomic information is at the same time a milestone and a millstone for those interested in studying the evolution of SARS-CoV-2.</p>
    <p>The scientific community all over the world has developed powerful bioinformatic tools to facilitate the evolutionary analysis of large quantities of genome sequences [<xref rid="bpad007-B2" ref-type="bibr">2</xref>]. Nextstrain and Microreact are two popular and fine platforms used by the community to study and visualize the evolution of pathogens in a geographical context [<xref rid="bpad007-B3" ref-type="bibr">3</xref>, <xref rid="bpad007-B4" ref-type="bibr">4</xref>]. The two main components of Nextstrain are Augur and Auspice. The first one is a pipeline that connects several tools via Snakemake to analyze genomic data and the second is used to visualize the results. Microreact is a platform to visualize the evolution of pathogens through time in a geographical context.</p>
    <p>One of the challenges that are faced when attempting a phylogeographic study of SARS-CoV-2 is to count with accurate information regarding the geographic localization of the samples. This information is found in the metadata associated with genome sequences in the GISAID database and is fulfilled by research groups all over the world. This process is not error proof and sometimes typos are introduced as well as inconsistencies. For instance, the name of the same city can be written in more than one way; like ‘Mexico City’ which is sometimes written as ‘CDMX’ and in other occasions as ‘Ciudad de Mexico’ or ‘Mexico DF’ (not to mention typos like ‘CMX’).</p>
    <p>These inconsistencies impair the performance of Nextstrain because geographic localities showing varying names in metadata and reference files from Augur will not be properly georeferenced. A similar situation may apply to Microreact. Correcting these errors is laborious and time-consuming, however crucial for proper phylogenetic analysis in a geographical context. Here, we provide a suite of Perl scripts designated to facilitate the curation of this vital information.</p>
    <p>Another problem faced by researchers is how to sample an appropriate subset of genome sequences to study the phylogeny of SARS-CoV-2 in a focal country? This is particularly important for countries where large amounts of genomes have been sequenced. Auspice can properly display ∼5000 sequences, however up to November 2022, there are 55 countries with more than 10 000 genome sequences available and 26 of them have more than 50 000 sequences (<ext-link xlink:href="https://www.gisaid.org" ext-link-type="uri">https://www.gisaid.org</ext-link>). And this number has grown ever since.</p>
    <p>Moreover, running a Nextstrain analysis with 4500 sequences on a personal computer (MacPro 3.5 GHz 6-Core Intel Xeon E5, 16 GB 1866 MHz DDR3) takes about 28 h to complete. Attempting a comprehensive Nextstrain analysis in a personal computer is impractical if not impossible for those countries with a large number of sequences. Therefore, scientists attempting an evolutionary study of SARS-CoV-2 face the problem of how to adequately sample a set of input sequences for practical Nextstrain analysis.</p>
    <p>Nextstrain, via Augur and accompanying Python scripts, offers strategies to (i) filter and then (ii) sample genome sequences at different geographic resolutions. These are fine strategies that work well and are very practical for a moderate number of sequences. Here, we also provide a script designated to facilitate the sampling of SARS-CoV-2 genome sequences downloaded from GISAID to make a phylogenomic analysis in Nextstrain and their display in Microreact. Our sampling strategy can be used instead of or in combination with the strategies provided by Augur.</p>
  </sec>
  <sec>
    <title>Materials and methods</title>
    <p>To overcome the above problems, we developed CurSa which consists of a suite of Perl scripts that are used sequentially: first, to curate the inconsistencies between the names of the geographic localities in the <monospace>metadata.tsv</monospace> file downloaded from GISAID and the reference files <monospace>color_ordering.tsv</monospace> and <monospace>lat_longs.tsv</monospace> from Augur and second, to sample genome sequences for phylogenetic analysis in Augur and their display in Auspice and Microreact. In <xref rid="bpad007-T1" ref-type="table">Table 1</xref>, we show the scripts that comprise CurSa and a brief description of their function.</p>
    <table-wrap position="float" id="bpad007-T1">
      <label>Table 1:</label>
      <caption>
        <p>The suite of scripts comprising CurSa</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="left" span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="1" colspan="1">Script</th>
            <th rowspan="1" colspan="1">Function</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>concatenate_tsv_files.pl</monospace>
            </td>
            <td rowspan="1" colspan="1">
              <list list-type="simple">
                <list-item>
                  <p>Concatenate all files downloaded from GISAID</p>
                </list-item>
                <list-item>
                  <p>
                    <monospace>$</monospace>
                    <monospace>perl</monospace>
                    <monospace>concatenate_tsv_files.pl</monospace>
                  </p>
                </list-item>
                <list-item>
                  <p>outfiles: outfile.tsv, outfile.fasta</p>
                </list-item>
              </list>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>compare_names.pl</monospace>
            </td>
            <td rowspan="1" colspan="1">
              <list list-type="simple">
                <list-item>
                  <p>Find inconsistencies between metadata.tsv and color_ordering.tsv files</p>
                </list-item>
                <list-item>
                  <p>
                    <monospace>$</monospace>
                    <monospace>perl</monospace>
                    <monospace>compare_names.pl</monospace>
                    <monospace>color_ordering.tsv</monospace>
                    <monospace>metadata.tsv</monospace>
                    <monospace>Mexico</monospace>
                  </p>
                </list-item>
                <list-item>
                  <p>outfile: substitute_proposal.tsv</p>
                </list-item>
              </list>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>substitute_names.pl</monospace>
            </td>
            <td rowspan="1" colspan="1">
              <list list-type="simple">
                <list-item>
                  <p>Creates a new metadata.tsv file by using the information in substitute_proposal.tsv to correct the inconsistencies</p>
                </list-item>
                <list-item>
                  <p>
                    <monospace>$</monospace>
                    <monospace>perl</monospace>
                    <monospace>substitute_names.pl</monospace>
                    <monospace>metadata.tsv</monospace>
                    <monospace> substitute_proposal_round1.tsv</monospace>
                  </p>
                </list-item>
                <list-item>
                  <p>outfile: outfile.tsv</p>
                </list-item>
              </list>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>check_coordinates.pl</monospace>
            </td>
            <td rowspan="1" colspan="1">
              <list list-type="simple">
                <list-item>
                  <p>Checks whether all localities in color_ordering.tsv have an associated coordinate in lat_longs.tsv</p>
                </list-item>
                <list-item>
                  <p>
                    <monospace>$</monospace>
                    <monospace>perl</monospace>
                    <monospace>check_coordinates.pl</monospace>
                    <monospace>metadata.tsv</monospace>
                    <monospace>color_ordering.tsv</monospace>
                    <monospace>lat_longs.tsv</monospace>
                    <monospace>Mexico</monospace>
                  </p>
                </list-item>
                <list-item>
                  <p>outfile: names_lacking_coordinates.txt</p>
                </list-item>
              </list>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>format.pl</monospace>
            </td>
            <td rowspan="1" colspan="1">
              <list list-type="simple">
                <list-item>
                  <p>Formats metadata and sequence files for Augur analysis and Auspice display</p>
                </list-item>
                <list-item>
                  <p>
                    <monospace>$</monospace>
                    <monospace>perl</monospace>
                    <monospace>format.pl</monospace>
                    <monospace>substituted.metadata.tsv</monospace>
                    <monospace>sequences.fasta</monospace>
                  </p>
                </list-item>
                <list-item>
                  <p>outfiles: formated_metadata.tsv, formated_sequences.fasta</p>
                </list-item>
              </list>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>sample.pl</monospace>
            </td>
            <td rowspan="1" colspan="1">
              <list list-type="simple">
                <list-item>
                  <p>Sample genome sequences for Augur analysis and Auspice display</p>
                </list-item>
                <list-item>
                  <p>
                    <monospace>$</monospace>
                    <monospace>perl</monospace>
                    <monospace>sample.pl</monospace>
                    <monospace>formated_metadata.tsv</monospace>
                    <monospace>formated_sequences.fasta</monospace>
                    <monospace>2718 10 2020-01-01 2023-01-01</monospace>
                  </p>
                </list-item>
                <list-item>
                  <p>outfiles: sampled_metadata.tsv, sampled_sequencies.fasta, sampled_report.txt</p>
                </list-item>
              </list>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>create_microreact.pl</monospace>
            </td>
            <td rowspan="1" colspan="1">
              <list list-type="simple">
                <list-item>
                  <p>Create files for Microreact display</p>
                </list-item>
                <list-item>
                  <p>
                    <monospace>$</monospace>
                    <monospace>perl</monospace>
                    <monospace>create_microreact.pl lat_longs.e1.tsv </monospace>
                    <monospace>aligned.fasta</monospace>
                    <monospace>metadata.tsv</monospace>
                    <monospace>Mexico</monospace>
                  </p>
                </list-item>
                <list-item>
                  <p>outfile: outfile_for_microreact.tsv</p>
                </list-item>
              </list>
            </td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <p>Next, we describe the rationale behind each one of the scripts that conform CurSa.</p>
    <p>
      <monospace>concatenate_tsv_files.pl</monospace>
    </p>
    <p>GISAID allows users to download a maximum of 5000 sequences (and their associated metadata) at once. Depending on the focal country, the number of sequences can be much larger. If the number of sequences from the focal country is larger than 5000, the sequences have to be downloaded in several different batches. This script concatenates all the sequence and metadata files into a single metadata file named <monospace>outfile.tsv</monospace> and a single sequence file named <monospace>outfile.fasta</monospace>. It also checks that all fasta headers are represented in the metadata.</p>
    <p><monospace>compare_names.pl</monospace> and <monospace>substitute_names.pl</monospace></p>
    <p>These scripts are used to curate the names from the geographic localities. Basically, all the geographic localities in the metadata file downloaded from GISAID (<monospace>metadata.tsv</monospace>) have to be contained in the reference files <monospace>color_ordering.tsv</monospace> and <monospace>lat_longs.tsv</monospace> from Augur (<xref rid="bpad007-F1" ref-type="fig">Fig. 1</xref>).</p>
    <fig position="float" id="bpad007-F1">
      <label>Figure 1:</label>
      <caption>
        <p>All geographic localities in <monospace>metadata.tsv</monospace> from the focal country (in this case, Mexico) have to be found in the reference files <monospace>color_ordering.tsv</monospace> and <monospace>lat_long.tsv</monospace>. As an example, the city of Sombrerete in the state of Zacatecas is shown.</p>
      </caption>
      <graphic xlink:href="bpad007f1" position="float"/>
    </fig>
    <p>The first script (<monospace>compare_names.pl</monospace>) checks whether the geographic localities in <monospace>metadata.tsv</monospace> are contained within <monospace>color_ordering.tsv</monospace>. This script outputs a file named <monospace>substitute_proposal.tsv</monospace> with the detected inconsistencies. The user then corrects the inconsistencies in this file and then runs the second script (<monospace>substitute_names.pl</monospace>) to create a new metadata file without the inconsistencies. The second script uses the information in <monospace>substitute_proposal.tsv</monospace> to create the new corrected metadata file (<xref rid="bpad007-F2" ref-type="fig">Fig. 2</xref>). These scripts can be used cyclically until there are no more inconsistencies.</p>
    <fig position="float" id="bpad007-F2">
      <label>Figure 2:</label>
      <caption>
        <p>The scripts <monospace>compare_names.pl</monospace> and <monospace>substitute_names.pl</monospace> are used cyclically until there are no more inconsistencies between <monospace>metadata.tsv</monospace> and <monospace>color_ordering.tsv</monospace> files. Then, once there are no more inconsistencies, another script (<monospace>check_coordinates.pl</monospace>) is used to check if all names from the geographic localities found in <monospace>color_ordering.tsv</monospace> have an associate coordinate in <monospace>lat_longs.tsv</monospace>.</p>
      </caption>
      <graphic xlink:href="bpad007f2" position="float"/>
    </fig>
    <p>
      <monospace>check_coordinates.pl</monospace>
    </p>
    <p>This script checks whether all geographic localities within <monospace>color_ordering.tsv</monospace> are also found in <monospace>lat_longs.tsv</monospace> file. This is done only for the focal country.</p>
    <p>
      <monospace>format.pl</monospace>
    </p>
    <p>This script deletes the prefix hCoV-19/ from the field strain (in the metadata) and in the header of the FASTA sequence files. It also checks whether there are no duplicate records with the same strain. If there are, it keeps the most recent one. This script is similar to <monospace>sanitize_metadata.py</monospace> that comes with Augur.</p>
    <p>
      <monospace>sample.pl</monospace>
    </p>
    <p>Nextstrain provides via Augur a method to filter sequences from specific regions and/or dates. Here, we provide a simple alternative to the method provided by Augur to subsample sequences for Nextstrain analysis. The script <monospace>sample.pl</monospace> requires a percentage of genomes to sample on a monthly basis, and the date ranges (<xref rid="bpad007-F3" ref-type="fig">Fig. 3</xref>). The script also requires a seed to generate random numbers to sample the sequences. This allows the user to have control over the sampling process (i.e. if the same seed is provided, the same set of genomes will be sampled each time the script is executed on the same files, facilitating repeatability).</p>
    <fig position="float" id="bpad007-F3">
      <label>Figure 3:</label>
      <caption>
        <p>The script <monospace>sample.pl</monospace> samples a percentage of genomes (specified by the user) on a monthly basis. The script requires a data range and a seed to generate random numbers to sample the genomes. The sample is taken on a monthly basis irrespective of the coronavirus variant.</p>
      </caption>
      <graphic xlink:href="bpad007f3" position="float"/>
    </fig>
    <p>
      <monospace>create_microreact.pl</monospace>
    </p>
    <p>Once the genome sequences have been analyzed with Nextstrain (via Augur) and a multiple sequence alignment and a phylogenetic tree are generated, the script <monospace>create_microreact.pl</monospace> can be used to generate the file that is required by Microreact to display the sequences in a geographical context.</p>
    <p>CurSa scripts can be used in combination with those provided by Nextstrain/Augur (<xref rid="bpad007-F4" ref-type="fig">Fig. 4</xref>). For instance, if sequence files and metadata are downloaded in several different batches from GISAID, it is possible to use the script <monospace>concatenate_tsv_files.pl</monospace> to concatenate them and then proceed to curate the metadata and reference files via CurSa or move directly to the Augur pipeline (number 1 in <xref rid="bpad007-F4" ref-type="fig">Fig. 4</xref>). It is also possible to curate the metadata and reference files via CurSa and then proceed to sanitize the metadata and sequence files in the Augur pipeline (number 2 in <xref rid="bpad007-F4" ref-type="fig">Fig. 4</xref>). Another possibility is to sanitize the metadata and sequence files with format.pl and then index and sample the genomes with Augur (number 3 in <xref rid="bpad007-F4" ref-type="fig">Fig. 4</xref>). Finally, it is possible to go all the way through CurSa and then perform the phylogenetic analysis in Augur. This flexibility allows to combine the functionalities provided by CurSa with those of Augur.</p>
    <fig position="float" id="bpad007-F4">
      <label>Figure 4:</label>
      <caption>
        <p>Roadmap of CurSa scripts and how they can be used in combination with Augur. Functionalities provided by CurSa not present in Augur are shown in orange. Gray arrows show the three optional paths that connect CurSa with Augur pipelines. *Sequences will have to be indexed prior phylogenetic analysis.</p>
      </caption>
      <graphic xlink:href="bpad007f4" position="float"/>
    </fig>
  </sec>
  <sec sec-type="results">
    <title>Results</title>
    <p>Next, we show an example of how we used CurSa scripts to create Mexstrain (<ext-link xlink:href="https://ira.cinvestav.mx/mexstrain/" ext-link-type="uri">https://ira.cinvestav.mx/mexstrain/</ext-link>). We provide a detailed description of each one of the steps in <xref rid="sup1" ref-type="supplementary-material">Supplementary File S1</xref>.</p>
    <sec>
      <title>Download data</title>
      <p>On 3 February 2023, we downloaded all complete, high coverage and ‘collection date complete’ sequences sampled in Mexico from GISAID database (<ext-link xlink:href="https://gisaid.org" ext-link-type="uri">https://gisaid.org</ext-link>). The sequences and their associated metadata were downloaded in the format required by Augur (i.e. input for the Augur pipeline). Because GISAID allows to download a maximum of 5000 entries at once, and there were 35 633 sequences from Mexico, we downloaded the information from each Mexican state separately and then used the script <monospace>concatenate_tsv_files.pl</monospace> to concatenate all the information into a single metadata and sequence files (<xref rid="sup1" ref-type="supplementary-material">Supplementary File S1</xref>, Result S1).</p>
    </sec>
    <sec>
      <title>Curate metadata and reference files</title>
      <p>Next, we proceeded to curate the <monospace>metadata.tsv</monospace> and the reference files <monospace>color_ordering.tsv</monospace> and <monospace>lat_longs.tsv</monospace>. As a first step, we manually check the <monospace>color_ordering.tsv</monospace> file to identify simple typos in the names of localities from Mexico. This is important because the names in <monospace>color_ordering.tsv</monospace> will be used as gold-standards when compared with those in <monospace>metadata.tsv</monospace> and <monospace>lat_longs.tsv</monospace> files.</p>
      <p>Once the names in <monospace>color_ordering.tsv</monospace> were manually checked, we proceeded to run <monospace>compare_names.pl</monospace> to identify inconsistencies between <monospace>metadata.tsv</monospace> and <monospace>color_ordering.tsv</monospace> (<xref rid="sup1" ref-type="supplementary-material">Supplementary File S1</xref>, Result S2). By this we identified 27 localities in <monospace>metadata.tsv</monospace> without a correspondence in <monospace>color_ordering.tsv</monospace>. These 27 inconsistencies mapped to 2445 entries/genomes in the <monospace>metadata.tsv</monospace> file (∼7% of all sequences from Mexico). Most of the inconsistencies were from ‘Estado de Mexico’ that in <monospace>metadata.tsv</monospace> is written as ‘State of Mexico’ (2188 out of 2290 times).</p>
      <p>The script <monospace>compare_names.pl</monospace> outputs a file named <monospace>substitute_proposal.tsv</monospace>. This file contains all detected inconsistencies. We renamed this outfile to <monospace>substitute_proposal_round1.tsv</monospace> and manually modified it by using a simple text editor to correct the inconsistencies (see <xref rid="sup1" ref-type="supplementary-material">Supplementary File S1</xref>).</p>
      <p>Once all inconsistencies have been corrected in <monospace>substitute_proposal_round1.tsv</monospace>, we used the script <monospace>substitute_names.pl</monospace> to create a new metadata file without detected errors. This script reads the content of <monospace>substitute_proposal_round1.tsv</monospace> and uses it to create the new metadata file named <monospace>outfile.tsv</monospace>. This new metadata file is temporarily renamed as <monospace>metadata_round1.tsv</monospace>.</p>
      <p>A second run of <italic toggle="yes">compare_names.pl</italic> revealed that there are no more inconsistencies in the new metadata file <monospace>metadata_round1.tsv</monospace>. We renamed the <monospace>metadata_round1.tsv</monospace> to <monospace>substituted.metadata.tsv</monospace>.</p>
      <p>Finally, we used the script <monospace>check_coordinates.pl</monospace> to check if all geographic localities in <monospace>color_ordering.tsv</monospace> have a coordinate in <monospace>lat_logns.tsv</monospace>. By this, we identified 16 localities from Mexico in <monospace>color_ordering.tsv</monospace> (that were also in <monospace>substituted.metadata.tsv</monospace>) without coordinates in <monospace>lat_logns.tsv</monospace> file. We manually added the lacking coordinates to <monospace>lat_logns.tsv</monospace> file.</p>
    </sec>
    <sec>
      <title>Formatting metadata and genome sequences</title>
      <p>The script <monospace>format.pl</monospace> strips the prefix “hCov-19/” from the strain id in the <monospace>substituted.metadata.tsv</monospace> file and from the headers of the sequence FASTA file (<xref rid="sup1" ref-type="supplementary-material">Supplementary File S1</xref>, Result S3). The script also resolves duplicate entries sharing the same strain id in the metadata file by keeping the most recent one.</p>
    </sec>
    <sec>
      <title>Sampling genomes</title>
      <p>As described above, the script <monospace>sample.pl</monospace> samples a custom percentage of genomes on a monthly basis. For instance, we asked for a 10% sample of genomes from each month since the first record in Mexico (<xref rid="sup1" ref-type="supplementary-material">Supplementary File S1</xref>, Result S4). By this, we sampled 3564 genomes out of 35 633. This script outputs two files <monospace>sampled_metadata.tsv</monospace> and <monospace>sampled_sequences.fasta</monospace>.</p>
    </sec>
    <sec>
      <title>Nextstrain analysis via Augur and display with Auspice</title>
      <p>Finally, we copied the outfiles obtained with <monospace>sample.pl</monospace> to the <monospace>data/</monospace> directory and the curated files <monospace>color_ordering.tsv</monospace> and <monospace>lat_longs.tsv</monospace> to the <monospace>defaults/</monospace> directory within the local Nextstrain build. And we configured Auspice to contextualize the genome sequences from Mexico with those GenBank sequences of the Global sample provided by Nextstrain (<xref rid="sup1" ref-type="supplementary-material">Supplementary File S1</xref>, Result S5). The result is shown in <xref rid="bpad007-F5" ref-type="fig">Fig. 5</xref>.</p>
      <fig position="float" id="bpad007-F5">
        <label>Figure 5:</label>
        <caption>
          <p>Phylogenetic analysis of sampled sequences inferred with Nextstrain. Sequences from Mexico are indicated with circles.</p>
        </caption>
        <graphic xlink:href="bpad007f5" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>Visualize analysis in Microreact</title>
      <p>To display the phylogenetic analysis performed with Nextstrain in Microreact, we executed the script <monospace>create_microreact.pl</monospace> (<xref rid="sup1" ref-type="supplementary-material">Supplementary File S1</xref>, Result S6). This script runs on the files: <monospace>lat_longs.tsv</monospace>, <monospace>aligned.fasta</monospace><monospace>,</monospace> and <monospace>sampled_metadata.tsv</monospace>. The <monospace>lat_longs.tsv</monospace> and <monospace>sampled_metadata.tsv</monospace> files were described previously. The <monospace>aligned.fasta</monospace> file is the result of running Nextstrain on the sampled set of sequences and is found in <monospace>ncov</monospace><monospace>/results/</monospace><monospace>yourconfigfile</monospace><monospace>/</monospace> within the local Nextstrain build. This script will create the files: <monospace>outfile_for_microreact.tsv</monospace>. This file contains the table required by Microreact with all the sequences found in <monospace>metadata.sampled.tsv</monospace>. The tree file <monospace>tree_raw.nwk</monospace> required by Microreact is found in <monospace>ncov</monospace><monospace>/results/</monospace><monospace>yourconfigfile</monospace><monospace>/</monospace>. We uploaded the <monospace>sampled_metadata.tsv</monospace> and the <monospace>tree_raw.nwk</monospace> to Microreact (<ext-link xlink:href="https://microreact.org" ext-link-type="uri">https://microreact.org</ext-link>) to visualize the data with its phylogeny (<xref rid="bpad007-F6" ref-type="fig">Fig. 6</xref>).</p>
      <fig position="float" id="bpad007-F6">
        <label>Figure 6:</label>
        <caption>
          <p>Sampled sequences can be visualized in Microreact all together with the phylogeny inferred with Nextstrain.</p>
        </caption>
        <graphic xlink:href="bpad007f6" position="float"/>
      </fig>
    </sec>
    <sec>
      <title>Applications</title>
      <p>Phylogenetic analyses in Nextstrain assisted by CurSa scripts were used to describe the diversity of SARS-CoV-2 prior vaccination stages in Mexico [<xref rid="bpad007-B5" ref-type="bibr">5</xref>]; and are used to maintain Mexstrain (<ext-link xlink:href="https://ira.cinvestav.mx/mexstrain/" ext-link-type="uri">https://ira.cinvestav.mx/mexstrain/</ext-link>) a web page designated to facilitate the visualization of the phylogeny of SARS-CoV-2 in Mexico. Here, we make CurSa available to the scientific community by carefully describing its functionality and how it can be used to extend and complement those of Augur to improve the accuracy of phylogenomic analysis in a geographical context.</p>
    </sec>
  </sec>
  <sec>
    <title>Conclusions</title>
    <p>CurSa is a suite of Perl scripts designated to curate metadata files and sample genome sequences from SARS-CoV-2 (that were downloaded from GISAID) for phylogenomic analysis in Nextstrain and display in Microreact. CurSa scripts allow the user to sample a moderate number of sequences to run Nextstrain on a personal computer and to correct inconsistencies in metadata files regarding the geographic location of the samples. As far as we know, there is no other software designed to facilitate the curation of geographic localities in metadata from SARS-CoV-2. The set of sequences sampled with CurSa are a starting point to more sophisticated subsampling methods implemented in Nextstrain if desired. All CurSa scripts are properly commented and should be crystal clear to any Perl programmer. Overall, CurSa is aimed to facilitate and accelerate evolutionary studies in SARS-CoV-2.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Material</title>
    <supplementary-material id="sup1" position="float" content-type="local-data">
      <label>bpad007_Supplementary_Data</label>
      <media xlink:href="bpad007_supplementary_data.txt">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <sec>
    <title>Supplementary data</title>
    <p><xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Biology Methods and Protocols</italic> online.</p>
  </sec>
  <sec sec-type="data-availability">
    <title>Data availability</title>
    <p>CurSa scripts are accessible via Github at: <ext-link xlink:href="https://github.com/luisdelaye/CurSa/" ext-link-type="uri">https://github.com/luisdelaye/CurSa/</ext-link>. Detailed instructions on how to use CurSa scripts are provided via GitHub.</p>
  </sec>
  <sec>
    <title>Author contributions</title>
    <p>Luis Delaye (Conceptualization [lead], Data curation [lead], Formal analysis [lead], Funding acquisition [lead], Investigation [lead], Methodology [lead], Project administration [lead], Resources [lead], Software [lead], Supervision [lead], Validation [lead], Visualization [lead], Writing—original draft [lead], Writing—review &amp; editing [lead])</p>
    <p><italic toggle="yes">Conflict of interest statement</italic>. None declared.</p>
  </sec>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="bpad007-B1">
      <label>1</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Attwood</surname><given-names>SW</given-names></string-name>, <string-name><surname>Hill</surname><given-names>SC</given-names></string-name>, <string-name><surname>Aanensen</surname><given-names>DM</given-names></string-name></person-group><etal>et al</etal><article-title>Phylogenetic and phylodynamic approaches to understanding and combating the early SARS-CoV-2 pandemic</article-title>. <source>Nat Rev Genet</source><year>2022</year>;<volume>23</volume>:<fpage>547</fpage>–<lpage>62</lpage>. <pub-id pub-id-type="doi">10.1038/s41576-022-00483-8</pub-id><pub-id pub-id-type="pmid">35459859</pub-id></mixed-citation>
    </ref>
    <ref id="bpad007-B2">
      <label>2</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hu</surname><given-names>T</given-names></string-name>, <string-name><surname>Li</surname><given-names>J</given-names></string-name>, <string-name><surname>Zhou</surname><given-names>H</given-names></string-name></person-group><etal>et al</etal><article-title>Bioinformatics resources for SARS-CoV-2 discovery and surveillance</article-title>. <source>Brief Bioinform</source><year>2021</year>;<volume>22</volume>:<fpage>631</fpage>–<lpage>41</lpage>. <pub-id pub-id-type="doi">10.1093/bib/bbaa386</pub-id><pub-id pub-id-type="pmid">33416890</pub-id></mixed-citation>
    </ref>
    <ref id="bpad007-B3">
      <label>3</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hadfield</surname><given-names>J</given-names></string-name>, <string-name><surname>Megill</surname><given-names>C</given-names></string-name>, <string-name><surname>Bell</surname><given-names>SM</given-names></string-name></person-group><etal>et al</etal><article-title>Nextstrain: real-time tracking of pathogen evolution</article-title>. <source>Bioinformatics</source><year>2018</year>;<volume>134</volume>:<fpage>4121</fpage>–<lpage>3</lpage>. doi:<pub-id pub-id-type="doi">10.1093/bioinformatics/bty407</pub-id></mixed-citation>
    </ref>
    <ref id="bpad007-B4">
      <label>4</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Argimón</surname><given-names>S</given-names></string-name>, <string-name><surname>Abudahab</surname><given-names>K</given-names></string-name>, <string-name><surname>Goater</surname><given-names>RJE</given-names></string-name></person-group><etal>et al</etal><article-title>Microreact: visualizing and sharing data for genomic epidemiology and phylogeography</article-title>. <source>Microb Genom</source><year>2016</year>;<volume>302</volume>:<fpage>e000093</fpage>.doi:<pub-id pub-id-type="doi">10.1099/mgen.0.000093</pub-id></mixed-citation>
    </ref>
    <ref id="bpad007-B5">
      <label>5</label>
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barona-Gómez</surname><given-names>F</given-names></string-name>, <string-name><surname>Delaye</surname><given-names>L</given-names></string-name>, <string-name><surname>Díaz-Valenzuela</surname><given-names>E</given-names></string-name></person-group><etal>et al</etal><article-title>Phylogenomics and population genomics of SARS-CoV-2 in Mexico during the pre-vaccination stage reveals variants of interest B.1.1.28.4 and B.1.1.222 or B.1.1.519 and the nucleocapsid mutation S194L associated with symptoms</article-title>. <source>Microb Genom</source><year>2021</year>;<volume>7</volume>:<fpage>000684</fpage>. doi:<pub-id pub-id-type="doi">10.1099/mgen.0.000684</pub-id><pub-id pub-id-type="pmid">34846283</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
