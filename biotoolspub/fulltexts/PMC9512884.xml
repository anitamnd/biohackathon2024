<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Comput Aided Mol Des</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Comput Aided Mol Des</journal-id>
    <journal-title-group>
      <journal-title>Journal of Computer-Aided Molecular Design</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0920-654X</issn>
    <issn pub-type="epub">1573-4951</issn>
    <publisher>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9512884</article-id>
    <article-id pub-id-type="pmid">36008698</article-id>
    <article-id pub-id-type="publisher-id">471</article-id>
    <article-id pub-id-type="doi">10.1007/s10822-022-00471-4</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Prot2Prot: a deep learning model for rapid, photorealistic macromolecular visualization</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Durrant</surname>
          <given-names>Jacob D.</given-names>
        </name>
        <address>
          <email>durrantj@pitt.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1"/>
      </contrib>
      <aff id="Aff1"><institution-wrap><institution-id institution-id-type="GRID">grid.21925.3d</institution-id><institution-id institution-id-type="ISNI">0000 0004 1936 9000</institution-id><institution>Department of Biological Sciences, </institution><institution>University of Pittsburgh, </institution></institution-wrap>Pittsburgh, PA 15260 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>26</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>26</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <year>2022</year>
    </pub-date>
    <volume>36</volume>
    <issue>9</issue>
    <fpage>677</fpage>
    <lpage>686</lpage>
    <history>
      <date date-type="received">
        <day>13</day>
        <month>7</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>1</day>
        <month>8</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">Molecular visualization is a cornerstone of structural biology, providing insights into the form and function of biomolecules that are difficult to achieve any other way. Scientific analysis, publication, education, and outreach often benefit from photorealistic molecular depictions rendered using advanced computer-graphics programs such as Maya, 3ds Max, and Blender. However, setting up molecular scenes in these programs is laborious even for expert users, and rendering often requires substantial time and computer resources. We have created a deep-learning model called Prot2Prot that quickly imitates photorealistic visualization styles, given a much simpler, easy-to-generate molecular representation. The resulting images are often indistinguishable from images rendered using industry-standard 3D graphics programs, but they can be created in a fraction of the time, even when running in a web browser. To the best of our knowledge, Prot2Prot is the first example of image-to-image translation applied to macromolecular visualization. Prot2Prot is available free of charge, released under the terms of the Apache License, Version 2.0. Users can access a Prot2Prot-powered web app without registration at <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/prot2prot">http://durrantlab.com/prot2prot</ext-link>.</p>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1007/s10822-022-00471-4.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Prot2Prot</kwd>
      <kwd>Molecular visualization</kwd>
      <kwd>Web app</kwd>
      <kwd>Machine learning</kwd>
      <kwd>Proteins</kwd>
      <kwd>Style transfer</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000057</institution-id>
            <institution>National Institute of General Medical Sciences</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01GM132353</award-id>
        <principal-award-recipient>
          <name>
            <surname>Durrant</surname>
            <given-names>Jacob D.</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© Springer Nature Switzerland AG 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par2">Molecular visualization is a critical structural-biology tool that provides valuable insights into the form and function of biomolecules. Artistically rendered photorealistic images can also inspire students and the public via education and outreach. Though well-known desktop programs such as VMD [<xref ref-type="bibr" rid="CR1">1</xref>], UCSF Chimera [<xref ref-type="bibr" rid="CR2">2</xref>], ChimeraX [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR4">4</xref>], and PyMOL [<xref ref-type="bibr" rid="CR5">5</xref>] were conceived principally as analysis tools, these programs can also produce striking images. But they understandably lack many of the advanced rendering techniques commonly used in the video game and film industries, and they are not designed to run in a web browser. Browser-based JavaScript molecular-visualization libraries such as Mol* [<xref ref-type="bibr" rid="CR6">6</xref>], NGL Viewer [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>], 3Dmol.js [<xref ref-type="bibr" rid="CR9">9</xref>], and Molmil [<xref ref-type="bibr" rid="CR10">10</xref>] are also visually impressive, but they too are not designed to produce photorealistic renderings.</p>
    <p id="Par3">Several desktop computer-graphics programs implement industry-standard rendering techniques, including Maya, 3ds Max, and Blender. Among these, Blender is notable because it is free and open source. However, none of these programs are designed for molecular visualization specifically. Several programs and plugins seek to address this shortcoming, including our BlendMol plugin [<xref ref-type="bibr" rid="CR11">11</xref>], which allows users to easily import molecular models into the Blender environment. Though BlendMol greatly simplifies photorealistic molecular rendering, it still requires a good understanding of Blender, a program with a notoriously steep learning curve. And to produce high quality images and videos, even knowledgeable users must undertake the laborious process of setting up lighting, creating materials, positioning the camera, etc. Rendering itself is also computationally intensive, further limiting use.
</p>
    <p id="Par4">We here describe a deep-learning model called Prot2Prot that imitates a Blender-rendered molecular image given a much simpler and easier-to-generate representation (“sketch”) of a protein surface. Prot2Prot outputs an image that is often indistinguishable from a BlendMol-based visualization in a fraction of the time, allowing image “rendering” even in a web browser. Unlike the desktop tools for molecular analysis described above [<xref ref-type="bibr" rid="CR1">1</xref>–<xref ref-type="bibr" rid="CR5">5</xref>], Prot2Prot is primarily a browser-based tool for generating photorealistic molecular renderings. Similarly, Prot2Prot is not meant to compete with desktop programs such as Blender/BlendMol [<xref ref-type="bibr" rid="CR11">11</xref>], which are more difficult to use but provide exquisite control over lighting, materials, etc. Finally, Prot2Prot does not replace JavaScript libraries for browser-based molecular visualization [<xref ref-type="bibr" rid="CR6">6</xref>–<xref ref-type="bibr" rid="CR10">10</xref>], which display schematic (not photorealistic) renderings at high frame rates to enable smooth rotation and zooming. Rather, Prot2Prot aims to simply the process of generating photorealistic visualizations by abstracting away the complex settings typical of such a task while simultaneously offering the convenience of browser-based use.</p>
    <p id="Par5">The success of the Prot2Prot approach demonstrates how machine learning can serve as a valuable tool for enhancing scientific communication, with potential applications to fields beyond molecular visualization. We release Prot2Prot free of charge under the terms of the Apache License, Version 2.0. Users can access a Prot2Prot-powered web app without registration at <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/prot2prot">http://durrantlab.com/prot2prot</ext-link>.</p>
  </sec>
  <sec id="Sec2">
    <title>Materials and methods</title>
    <sec id="Sec3">
      <title>Simplified protein-surface “sketches”</title>
      <p id="Par6">We first developed a simple 2D molecular representation that is easy to generate, even in slow and memory-limited environments such as web browsers (Fig. <xref rid="Fig1" ref-type="fig">1</xref>A). We represent each atom as a simple circle, sized according to the van der Waals radius and distance from the virtual “camera” (i.e., depth). Each circle is outlined in black to gray depending on its depth to emphasize atomic boundaries.<fig id="Fig1"><label>Fig. 1</label><caption><p>Prot2Prot image mapping. Proliferating cell nuclear antigen (PCNA) bound to the PCNA-interacting motif (PIP box) of the DNA-dependent metalloprotease SPRTN (DVC1; 6099 atoms; PDB ID: 5IY4). A) The input image is a simplified 2D molecular representation that is straightforward to generate. B) The output image mimics the appearance of a photorealistic rendering of the same protein, as if created using Blender/BlendMol</p></caption><graphic xlink:href="10822_2022_471_Fig1_HTML" id="MO1"/></fig></p>
      <p id="Par7">The circles are colored according to carefully selected red, green, and blue (RGB) values. The red and green channels encode the atomic element. R/G values corresponding to carbon, nitrogen, oxygen, hydrogen, and phosphorus atoms are set at 100/100%, 100/0%, 0/100%, 0/50%, and 50/50%, respectively. All other atoms are encoded as carbons. Depth is encoded on the blue (B) channel. It is set at 100% for those atoms close to the camera and 0% for those atoms that are distant. A subtle three-step gradient is applied to each atom to capture its three-dimensional (spherical) shape.</p>
      <p id="Par8">To provide data sufficient for training a machine-learning model, we generated hundreds of representative protein-surface sketches (1024 × 1024). We first assembled a set of 49 diverse proteins from the Protein Data Bank [<xref ref-type="bibr" rid="CR12">12</xref>] and added hydrogens to each of these proteins using <italic>Reduce</italic> [<xref ref-type="bibr" rid="CR13">13</xref>]. To further augment the dataset, we used the 49 proteins to generate additional models. In some cases, we removed water molecules (if present) to generate new, water-free models. In other cases, we removed hydrogen atoms (important given that most models in the PDB lack hydrogens). When hydrogen atoms were retained, we randomly replaced occasional hydrogen atoms with rarer elements (e.g., sulfur, phosphorus, metals, halides). And we randomly rotated and scaled the models to capture proteins at many different angles and distances.</p>
    </sec>
    <sec id="Sec4">
      <title>Blender/BlendMol-rendered molecular visualizations</title>
      <p id="Par9">For each protein-surface sketch, we rendered a matching photorealistic image (1024 × 1024) using Blender 3.0.0, an open-source computer-graphics toolset. We created custom Python scripts that load a PDB file into Blender using the BlendMol plugin [<xref ref-type="bibr" rid="CR11">11</xref>]; automatically adjust the focal point of the Blender camera; create a fog-to-white effect; set the surface materials, lighting, and other parameters; and render a photorealistic image to disk using the Cycles path-tracing render engine.</p>
    </sec>
    <sec id="Sec5">
      <title>Training a Prot2Prot model to map input sketches to rendered images</title>
      <p id="Par10">We trained Pix2Pix, a generative adversarial network (GAN) [<xref ref-type="bibr" rid="CR14">14</xref>], to translate molecular sketches into the corresponding photorealistic protein images (Fig. <xref rid="Fig1" ref-type="fig">1</xref>; PyTorch Pix2Pix implementation available on GitHub [<xref ref-type="bibr" rid="CR15">15</xref>]). In the context of this project, we call the model Prot2Prot rather than Pix2Pix. We used the default values for training, except we selected U-Net 128 as the generator architecture and used instance rather than batch normalization. For each of three photorealistic styles, we trained separate Prot2Prot models to generate 1024 × 1024, 512 × 512, and 256 × 256 output images, respectively. To generate 512 × 512 and 256 × 256 images for training, we used ImageMagick [<xref ref-type="bibr" rid="CR16">16</xref>] to scale the original 1024 × 1024 images. In all cases, we trained on roughly 1000 sketch/render pairs for 1000 epochs using the default initial learning rate, and then for another 1000 epochs as the learning rate decayed linearly to zero.</p>
      <p id="Par11">To further augment the data set available for training, we scaled the images by ~112% and then randomly cropped them at the original size (e.g., 256 × 256 images were scaled to 286 × 286 and then randomly cropped to produce 256 × 256 images). To allow the models to learn to mimic the consistent directional lighting of the rendered target images, we did not rotate or flip images, an otherwise common technique used for further data augmentation.</p>
      <p id="Par12">Because Prot2Prot is a GAN, there is no intuitive metric to monitor training progress or performance in an absolute sense (i.e., there is no straightforward loss function). Rather, a generator model learns to mimic real Blender-rendered images, while a discriminator model simultaneously learns to distinguish between the real and mimicked images. The performance of each model is always relative to the performance of its opponent. But visual inspection, albeit subjective, suggests the fully trained generator model mimics the actual Blender-rendered images surprisingly successfully.</p>
    </sec>
    <sec id="Sec6">
      <title>Model conversion for use with tensorflow.js</title>
      <p id="Par13">We exported the trained PyTorch models to the ONNX format using the <italic>torch.onnx.export</italic> function. We then converted the ONNX files to the TensorFlow SavedModel format using the TensorFlow Backend for ONNX [<xref ref-type="bibr" rid="CR17">17</xref>]. Finally, we converted the SavedModel files to the TensorFlow.js graph-model format using the <italic>tensorflowjs_converter</italic> command [<xref ref-type="bibr" rid="CR18">18</xref>]. In this last step, we also applied 1-byte affine quantization to multiple nodes, which substantially reduced the file size without substantial impact on image quality.</p>
    </sec>
    <sec id="Sec7">
      <title>Colorization</title>
      <p id="Par14">Prot2Prot produces images with consistent, predetermined color schemes. However, users can modify the color palette after inference, allowing some degree of customizability. A color-intensity matrix, <italic>w</italic>, determines how much a user-specified color influences various portions of the output image. The entries of the matrix range from 0.0 (no influence on the output image) to 1.0 (full influence).</p>
      <p id="Par15">The color-intensity matrix is calculated via element-wise multiplication of four image-derived matrices. First, to leave non-protein-surface regions unmodified, we convert the input “sketch” to a binary mask, where entries corresponding to the protein surface are set to 1.0, and other entries are set to 0.0 (Fig. <xref rid="Fig2" ref-type="fig">2</xref>A). Second, to influence well-lit protein-surface regions more than shadowed areas, we separately convert the output “rendered” image to a grayscale matrix whose values correspond to averaged red, green, and blue values, scaled from 0.0 to 1.0 (Fig. <xref rid="Fig2" ref-type="fig">2</xref>B). Third, to preserve the fade-to-white fog effect, we create a third matrix from the blue channel of the input sketch image, which encodes depth (i.e., distance from the virtual camera). The values of this matrix range from 0.0 (most distant) to 1.0 (closest; Fig. <xref rid="Fig2" ref-type="fig">2</xref>C). Fourth, to allow the user to control the colorization effect’s global strength, we create a matrix with identical entries equal to a user-defined color-strength parameter (Fig. <xref rid="Fig2" ref-type="fig">2</xref>D). After the element-wise multiplication of these four matrixes, the final matrix (Fig. <xref rid="Fig2" ref-type="fig">2</xref>E) can be optionally blurred to remove any sharp edges, per the user-defined color-blend parameter.<fig id="Fig2"><label>Fig. 2</label><caption><p>Prot2Prot colorization procedure. <bold>A</bold> The mask matrix indicates which image regions include the protein surface. <bold>B</bold> The grayscale matrix distinguishes well-lit and in-shadow protein-surface regions. <bold>C</bold> The depth matrix indicates how far a protein region is from the virtual camera. <bold>D</bold> The color-strength matrix allows the user to further modify the strength of the colorization effect. <bold>E</bold> The final color-intensity matrix, called <italic>w</italic>, is calculated via element-wise multiplication of the four preceding matrices. <bold>F</bold> The original Prot2Prot output image. <bold>G</bold> A solid, user-specified color. <bold>H</bold> The final image, created by averaging the images in (<bold>F</bold>) and (<bold>G</bold>), weighting by the color-intensity matrix, <italic>w</italic></p></caption><graphic xlink:href="10822_2022_471_Fig2_HTML" id="MO2"/></fig></p>
      <p id="Par16">We use this color-intensity matrix to adjust the original Prot2Prot output image (Fig. <xref rid="Fig2" ref-type="fig">2</xref>F). A weighted average combines each pixel’s red, green, and blue values with those of a solid, user-defined color (Fig. <xref rid="Fig2" ref-type="fig">2</xref>G). The pixel’s color is unchanged if the corresponding color-intensity-matrix value is 0.0 and replaced by the user-defined color entirely if the corresponding value is 1.0 (Fig. <xref rid="Fig2" ref-type="fig">2</xref>H).</p>
    </sec>
    <sec id="Sec8">
      <title>Browser implementation</title>
      <p id="Par17">We created a browser-based version of Prot2Prot following our established open-source approach [<xref ref-type="bibr" rid="CR19">19</xref>–<xref ref-type="bibr" rid="CR21">21</xref>]. The graphical user interface (GUI) is written in TypeScript using the Vue.js framework [<xref ref-type="bibr" rid="CR22">22</xref>], the BootstrapVue CSS library [<xref ref-type="bibr" rid="CR23">23</xref>], the TensorFlow.js machine-learning library [<xref ref-type="bibr" rid="CR18">18</xref>], the Webpack module bundler [<xref ref-type="bibr" rid="CR24">24</xref>], and Google’s Closure Compiler [<xref ref-type="bibr" rid="CR25">25</xref>].</p>
      <p id="Par18">The “Input PDB File” panel (Fig. <xref rid="Fig3" ref-type="fig">3</xref>A) allows users to load a PDB file into their web browser’s memory by selecting a file on their local computer or providing a PDB ID for remote download. Alternatively, clicking the “Use Example File” button automatically loads an example (PDB ID: 5IY4 [<xref ref-type="bibr" rid="CR26">26</xref>]). Once the PDB file is loaded, the Prot2Prot user interface provides limited structure-editing options (e.g., users can remove ligands, water molecules, chains, etc.).<fig id="Fig3"><label>Fig. 3</label><caption><p>Browser-app user interface. <bold>A</bold> The “Input PDB File” panel allows users to load and edit molecular structures. <bold>B</bold> The “Prot2Prot Renderer” panel allows users to specify the rendering style and image size. <bold>C</bold> The “Molecular Viewer” panel shows the rendered structure. <bold>D</bold> Colorize options allow the user to adjust the protein color. <bold>E</bold> The Viewport information can be copied and pasted to restore the rotation/zoom settings</p></caption><graphic xlink:href="10822_2022_471_Fig3_HTML" id="MO3"/></fig></p>
      <p id="Par19">The “Prot2Prot Renderer” panel (Fig. <xref rid="Fig3" ref-type="fig">3</xref>B) allows users to choose from various rendering styles and image dimensions (see “Results and discussion” for a description). It also briefly explains the visual features of the selected style.</p>
      <p id="Par20">Users can position and display their molecules in the “Molecular Viewer” panel (Fig. <xref rid="Fig3" ref-type="fig">3</xref>C). Structures are initially shown in “Preview” mode as fields of atomic spheres that can be easily rotated and scaled using the mouse, mouse wheel, or touch gestures. Once ready, the user clicks the “Prot2Prot” button to generate the corresponding photorealistic image in the browser. The “Save” button allows users to save the viewer image. Users can also toggle the “Colorize Prot2Prot Render” setting to specify color, color-strength, and color-blending options (Fig. <xref rid="Fig3" ref-type="fig">3</xref>C, where green is selected). Finally, the app provides “Viewport” information that can be copied and pasted to restore the rotation/zoom settings (Fig. <xref rid="Fig3" ref-type="fig">3</xref>D).</p>
    </sec>
    <sec id="Sec9">
      <title>Command-line-interface implementation</title>
      <p id="Par21">Aside from running Prot2Prot in a web browser, users can also access the model via a command-line interface (CLI) powered by the Node.js JavaScript runtime environment. CLI Prot2Prot is well-suited for rendering single images and image sequences, which can be combined into videos. CLI Prot2Prot provides several default animations, including “still,” “rock,” “turntable” (rotation about a user-specified axis), and “zoom.” If a PDB file contains multiple frames, CLI Prot2Prot will also render protein dynamics, allowing users to visualize molecular dynamics simulations or interpolated protein structures (Online Resource 1).</p>
    </sec>
  </sec>
  <sec id="Sec10">
    <title>Results and discussion</title>
    <p id="Par22">The Prot2Prot machine-learning model effectively renders photorealistic molecular representations via image-to-image translation of much simpler, easy-to-generate, molecular-surface “sketches.” Prot2Prot illustrations are well suited for scientific publication, outreach, and education. CLI Prot2Prot can also generate animations of protein motions (Online Resource 1 and 2).
</p>
    <sec id="Sec11">
      <title>Description of rendering styles</title>
      <p id="Par23">We trained Prot2Prot models to mimic three distinctive rendering styles, which we call “Simple Surface,” “Chalky,” and “Chalky Shadow.”</p>
      <sec id="Sec12">
        <title>Simple surface</title>
        <p id="Par24">In the “Simple Surface” rendering style, carbon, oxygen, nitrogen, sulfur, and hydrogen atoms are light silver, red, blue, yellow, and white. Color support for other elements is limited. When rendering the photorealistic Blender images used for training, we applied two effects to give the final images a better sense of depth. First, we used Blender’s mist pass to render more distant protein regions in lighter colors, producing a “fade-to-white” fog effect. Second, we used Blender’s depth-of-field effect to focus the virtual camera on the protein surface directly in front of it, such that regions distant from that focal point appear slightly blurred or out of focus.</p>
        <p id="Par25">We also used several advanced lighting techniques to enhance photorealism. First, we applied a slight subsurface-scattering effect to all surfaces using Blender’s Principled BSDF shader. When light hits many natural materials, it penetrates the surface and is scattered in the object’s interior. After a light ray makes its way back to the surface, it leaves the object at a random angle, not the predictable angle typical of a perfectly reflective (“glossy”) surface. Second, rather than light the scene with a single point or directional light, we used a public-domain, high dynamic range image (HDRI [<xref ref-type="bibr" rid="CR27">27</xref>]) to surround and light the surfaces. High-dynamic-range (HDR) lighting prevents the darkest and lightest regions of the image from being saturated as perfectly black or white, allowing the viewer to see full detail across the entire image. Third, we applied ambient occlusion to the scene. This non-physical rendering technique approximates global illumination by darkening surfaces that are only partially accessible to the broader environment (e.g., enclosed pockets). After rendering the image using Blender’s Cycles path-tracing render engine, we adjusted the color level using ImageMagick to ensure the background was precisely white, as typically required for publication-quality images.</p>
        <p id="Par26">We successfully trained our Prot2Prot models to mimic these Blender-rendered output images given a corresponding input “sketch image.” When converted to the TensorFlow.js graph-model format, the final model takes up roughly 40 MB. Figure <xref rid="Fig4" ref-type="fig">4</xref>A, B show how the model has learned to mimic the fade-to-white-fog (*), depth-of-field (†), and ambient-occlusion (‡) effects of the Blender-rendered training images.<fig id="Fig4"><label>Fig. 4</label><caption><p>An atomic resolution model of the human apoptosome obtained via electron microscopy (70,189 atoms; PDB ID 3J2T), visualized using Prot2Prot. <bold>A</bold>, <bold>B</bold> Simple Surface rendering style. <bold>C</bold> Chalky rendering style, colorized with a green tint. <bold>D</bold> Chalky Shadow rendering style. Examples of fade-to-white fog, depth of field, and ambient occlusion are marked with *, †, and ‡, respectively</p></caption><graphic xlink:href="10822_2022_471_Fig4_HTML" id="MO4"/></fig></p>
      </sec>
      <sec id="Sec13">
        <title>Chalky</title>
        <p id="Par27">The “Chalky” rendering style also has fade-to-white fog, ambient occlusion, and depth-of-field blur. Unlike Simple Surface, Chalky shows all atoms in the same white material, without subsurface scattering. Instead, we set the “Roughness” and “Clearcoat Roughness” settings on the Principled BSDF shader to their maximum values to give the surface a highly diffuse appearance. Chalky uses a public-domain studio lighting setup obtained from blendswap.com [<xref ref-type="bibr" rid="CR28">28</xref>] to light the proteins rather than an HDRI. After rendering the training images, we again adjusted the color levels using ImageMagick.</p>
        <p id="Par28">Trained Prot2Prot models successfully mimic these Blender-rendered output images as well. The Chalky models also take up ~40 MB, with similar run times in the browser. Figure <xref rid="Fig4" ref-type="fig">4</xref>C shows how Chalky images are particularly well suited to the custom colorization procedure (in this case, with a green tint) described in the Materials and Methods.</p>
      </sec>
      <sec id="Sec14">
        <title>Chalky shadow</title>
        <p id="Par29">The “Chalky Shadow” rendering style is the same as the “Chalky” style, except the virtual studio lights are allowed to cast a shadow onto a pure-white floor below. The trained Prot2Prot models successfully mimic the shadows computed using advanced path tracing in Blender (Fig. <xref rid="Fig4" ref-type="fig">4</xref>D). Online Resource 2 (bottom row) illustrates how these shadows even convincingly change according to the protein orientation. These models are also roughly 40 MB.</p>
      </sec>
    </sec>
    <sec id="Sec15">
      <title>Video rendering via the command line interface</title>
      <p id="Par30">Command-line-interface (CLI) Prot2Prot also accepts multi-frame PDB files as input, allowing users to create animations of molecular dynamics simulations, conformational transitions, etc. Prot2Prot provides four different animation styles via its CLI (Online Resource 1). A “still” animation captures only the frame-by-frame motions of individual atoms without imparting any large-scale rotations to the entire protein. Alternatively, three whole-scene rotation animations can further facilitate visualization: “rock,” “turn table,” and “zoom.”</p>
      <p id="Par31">To demonstrate these animation styles, we first used UCSF Chimera [<xref ref-type="bibr" rid="CR2">2</xref>] to generate a multi-frame PDB file of <italic>S. cerevisiae</italic> hexokinase 2 (<italic>Sc</italic>Hxk2). Specifically, we used Chimera’s “Morph Conformations” tool to capture the transition between open and closed <italic>Sc</italic>Hxk2 structures extracted from a recent molecular dynamics simulation [<xref ref-type="bibr" rid="CR29">29</xref>]. We created video animations of this transition from image sequences of 48 Prot2Prot-rendered trajectory frames (Online Resource 1).</p>
      <p id="Par32">These animations convincingly capture the <italic>Sc</italic>Hxk2 open-to-close transition, but the protein surfaces appear to “flicker.” This subtle artifact arises because Prot2Prot renders each frame without regard for adjacent frames (i.e., the resulting animations lack temporal coherence). To address this issue, we used Prot2Prot to re-render the <italic>Sc</italic>Hxk2 trajectory to only twelve images. We then used the Real-time Intermediate Flow Estimation (RIFE) 3.1 algorithm [<xref ref-type="bibr" rid="CR30">30</xref>], as implemented in the Flowframes software package [<xref ref-type="bibr" rid="CR31">31</xref>], to interpolate between these twelve images. The resulting animations capture the same open-to-close transition but without the flicker (Online Resource 2). We had similar success using the commercial frame interpolation algorithm implemented in Adobe After Effects.</p>
    </sec>
    <sec id="Sec16">
      <title>Compatibility and run times</title>
      <p id="Par33">We have tested the Prot2Prot Web App on all major operating systems and web browsers (Table <xref rid="Tab1" ref-type="table">1</xref>), including some mobile devices. The Prot2Prot model is memory intensive, and the web app will crash if run on a device with a less capable graphical processing unit (GPU). Where possible, the app detects any crash and asks the user to (1) select a smaller output-image size or (2) use the central processing unit (CPU) rather than the GPU. Rendering on the CPU is slower but also less memory restrained.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Prot2Prot compatibility</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="2">Prot2Prot web app</th></tr><tr><th align="left">Operating system</th><th align="left">Browser</th></tr></thead><tbody><tr><td align="left">macOS MONTEREY 12.1</td><td align="left">Chrome 100.0.4896.30</td></tr><tr><td align="left">macOS Monterey 12.1</td><td align="left">Firefox 98.0</td></tr><tr><td align="left">macOS Monterey 12.1</td><td align="left">Safari 15.2</td></tr><tr><td align="left">Microsoft Windows 10 Enterprise 10.0.19042</td><td align="left">Chrome 99.0.4844.51</td></tr><tr><td align="left">Microsoft Windows 10 Enterprise 10.0.19042</td><td align="left">Edge 99.0.1150.39</td></tr><tr><td align="left">Microsoft Windows 10 Enterprise 10.0.19042</td><td align="left">Firefox 98.0</td></tr><tr><td align="left">Ubuntu Linux 20.04.4 LTS</td><td align="left">Chrome 99.0.4844.51</td></tr><tr><td align="left">Ubuntu Linux 20.04.4 LTS</td><td align="left">Firefox 98.0</td></tr><tr><td align="left">Android 12</td><td align="left">Chrome 99.0.4844.58</td></tr><tr><td align="left">Android 12</td><td align="left">Firefox 98.1.1</td></tr><tr><td align="left">iOS 15.3.1</td><td align="left">Safari 15</td></tr></tbody></table><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="2">Command-line-interface (CLI) Prot2Prot</th></tr><tr><th align="left">Operating System</th><th align="left">Node.js</th></tr></thead><tbody><tr><td align="left">Ubuntu 20.04.3 LTS</td><td align="left">Node 16.13.2</td></tr></tbody></table><table-wrap-foot><p>We tested Prot2Prot on multiple operating systems, browsers, and Node.js versions</p></table-wrap-foot></table-wrap></p>
      <p id="Par34">Prot2Prot currently runs fastest on Chromium-based browsers (e.g., Google Chrome, Microsoft Edge, etc.) because these browsers support OffscreenCanvas. On other browsers (e.g., Firefox), TensorFlow.js must use the CPU to run inference rather than the GPU. Users can already enable OffscreenCanvas in Firefox via the advanced configuration preferences, suggesting future versions will enable it by default.</p>
      <p id="Par35">We tested CLI Prot2Prot on Ubuntu Linux running Node.js 16.13.2. The Node.js runtime environment is available on all major desktop operating systems, so we expect CLI Prot2Prot to be broadly compatible as well.</p>
      <p id="Par36">Aside from benefiting from broad compatibility, Prot2Prot also produces high-quality images much faster than dedicated 3D modeling programs such as Blender. Prot2Prot does not require users to set up lights, cameras, materials, etc.—setup activities that typically take much longer than rendering the image itself. But beyond eliminating the need for this laborious setup, Prot2Prot also has improved render times. To demonstrate, we rendered a test scene using Blender 3.2.0 on a MacBook Pro with an Apple X chip. The Blender Cycles path-tracing engine took roughly one minute to generate a 1024 × 1024 image using the GPU Compute device (Apple M1 Max GPU). In contrast, the Prot2Prot web app running on the same machine (Chrome browser) generated a similar image in only 1.2 s once the WebGL shaders had compiled (~6 s). Rendering times vary substantially depending on the available software and hardware (e.g., GPU vs. CPU). For example, older versions of Blender (e.g., 3.0.0) do not support GPU rendering on Apple hardware, and Prot2Prot does not run as quickly when using the CPU version of TensorFlow.js (as required, for example, in Firefox and Safari). But this comparison nevertheless demonstrates that Prot2Prot can dramatically accelerate photorealistic molecular visualization without requiring expertise in 3D modeling.</p>
    </sec>
    <sec id="Sec17">
      <title>Visual comparison with other software packages</title>
      <p id="Par37">Figure <xref rid="Fig5" ref-type="fig">5</xref> compares a Prot2Prot rendering to renderings produced by other popular molecular-visualization packages. Prot2Prot has learned advanced rendering techniques such as lighting and subsurface scattering, so users need not undertake the laborious process of setting these techniques up themselves. Rendering a Prot2Prot image is thus as simple as loading the protein, rotating and zooming, and pressing the “Prot2Prot” render button. In contrast, other molecular-visualization programs have many settings that users must adjust to modify the presentation. To normalize the effort invested in producing each image, we sought the path of least resistance when creating comparable renderings using other programs. We changed only those settings needed to set the protein representation to surface, to match atom coloring to the extent possible, and to set the background color to white. Figure <xref rid="Fig5" ref-type="fig">5</xref>A shows a Prot2Prot image rendered using the Simple Surface style. Figure <xref rid="Fig5" ref-type="fig">5</xref>B, D show renderings generated using the popular desktop molecular-visualization programs PyMOL [<xref ref-type="bibr" rid="CR5">5</xref>], UCSF Chimera [<xref ref-type="bibr" rid="CR2">2</xref>], and VMD [<xref ref-type="bibr" rid="CR1">1</xref>], respectively. Figure <xref rid="Fig5" ref-type="fig">5</xref>E, <xref rid="Fig5" ref-type="fig">F</xref> show renderings generated using two popular web-based visualization programs, Mol* [<xref ref-type="bibr" rid="CR6">6</xref>] and 3Dmol.js [<xref ref-type="bibr" rid="CR9">9</xref>].<fig id="Fig5"><label>Fig. 5</label><caption><p>Renderings produced by select molecular-visualization software packages. <bold>A</bold> Prot2Prot using the Simple Surface style. <bold>B</bold> PyMOL, a desktop program. <bold>C</bold> UCSF Chimera, a desktop program. <bold>D</bold> VMD, a desktop program. <bold>E</bold> Mol*, a web-based program. <bold>F</bold> 3Dmol.js, a web-based program. In all cases, we changed only those settings required to set the protein representation to surface, to match atom coloring to the extent possible, and to set the background color to white</p></caption><graphic xlink:href="10822_2022_471_Fig5_HTML" id="MO5"/></fig></p>
    </sec>
    <sec id="Sec18">
      <title>Limitations</title>
      <p id="Par38">Prot2Prot is a powerful, easy-to-use tool for photorealistic protein rendering, but it has several notable limitations. First, it is generally useful only for rendering protein surfaces. We attempted to train a Prot2Prot model to generate a cartoon-like image of protein tertiary structure given a sketch of the protein backbone atoms (Fig. <xref rid="Fig6" ref-type="fig">6</xref>A–C). Prot2Prot often correctly identified alpha helices and beta sheets, but misclassifications were frequent. Furthermore, it depicted alpha helices as elongated blobs rather than perfect cylinders.<fig id="Fig6"><label>Fig. 6</label><caption><p>Examples of Prot2Prot shortcomings. <bold>A</bold>–<bold>C</bold> Prot2Prot is best suited for rendering protein surfaces. It cannot accurately render a cartoon representation given a sketch of the protein backbone atoms. <bold>D</bold> The Chalky Shadow rendering style sometimes generates shadows that are excessively wavy (†). An artifactual shadow “blob” sometimes appears in the lower-left-hand corner (‡). <bold>E</bold> Viewing protein surfaces up close can produce artifacts (*). <bold>F</bold> Viewing protein surfaces at great distances tends to overrepresent carbon atoms (white). <bold>G</bold> On rare occasions protein surfaces may be subtly checkered even at intermediate distances (§)</p></caption><graphic xlink:href="10822_2022_471_Fig6_HTML" id="MO6"/></fig></p>
      <p id="Par39">The shadows rendered when using the Chalky Shadow style are generally impressive. Still, occasionally they appear to be more wavy than appropriate given the actual contours of the protein’s profile (Fig. <xref rid="Fig6" ref-type="fig">6</xref>D, marked with †). Prot2Prot also sometimes renders a shadow “blob” in the lower-left-hand corner of its Chalky-Shadow output images (Fig. <xref rid="Fig6" ref-type="fig">6</xref>D, marked with ‡). Fortunately, image cropping can easily remove this small artifact.</p>
      <p id="Par40">Prot2Prot also often struggles to correctly render protein surfaces with positioning that differs substantially from that depicted in the training images. Artifacts typically occur when proteins are very close to the virtual camera (Fig. <xref rid="Fig6" ref-type="fig">6</xref>E, marked with *) or very distant (Fig. <xref rid="Fig6" ref-type="fig">6</xref>F). In the case of distant proteins, Prot2Prot appears to overemphasize the contribution of carbon atoms (Fig. <xref rid="Fig6" ref-type="fig">6</xref>F, colored in light silver). Finally, subtle checkered (“waffle”) patterns occasionally appear when rendering proteins even at intermediate distances (Fig. <xref rid="Fig6" ref-type="fig">6</xref>G, marked with §). Rotating or scaling the molecule slightly generally eliminates these patterns.</p>
      <p id="Par41">Finally, Prot2Prot is trained to render protein surfaces, which are comprised primarily of carbon, oxygen, nitrogen, sulfur, and hydrogen atoms. The model is not trained to render macromolecules containing atoms of other elements (e.g., nucleic acids, which contain phosphorus). In practice, Prot2Prot can successfully render non-proteins when run using the Chalky and Chalky Shadow styles, which depend more on atomic positions that atom types. But running Prot2Prot using the Simple Surface style, which colors atoms by element, is sometimes problematic. Fortunately, in many cases the offending atom is obscured by other less problematic atoms (e.g., oxygen atoms, which often obscure an offending phosphorus).</p>
    </sec>
  </sec>
  <sec id="Sec19">
    <title>Conclusion</title>
    <p id="Par42">The literature describes several other applications of image-to-image translation in medicine and biology. Examples include enhancing medical [<xref ref-type="bibr" rid="CR32">32</xref>] and histopathological [<xref ref-type="bibr" rid="CR33">33</xref>] images to facilitate diagnosis. Others have applied similar approaches to images obtained from electron [<xref ref-type="bibr" rid="CR34">34</xref>] and fluorescence [<xref ref-type="bibr" rid="CR35">35</xref>–<xref ref-type="bibr" rid="CR37">37</xref>] microscopy with the goal of detecting gold nanoparticles or subcellular components. Still others have experimented with translating amorphous shapes to 3D representations [<xref ref-type="bibr" rid="CR38">38</xref>]. But to the best of our knowledge, these approaches have never been applied to macromolecular visualization with the goal of producing photorealistic images for publication, outreach, and education.</p>
    <p id="Par43">Though the present work focuses on molecular visualization, it also suggests how machine learning algorithms can rapidly and effectively enhance scientific visualization generally. Blender specifically has been used to visualize many scientific phenomena, ranging from quantum wave functions [<xref ref-type="bibr" rid="CR39">39</xref>] to tsunami hydrodynamics [<xref ref-type="bibr" rid="CR40">40</xref>] to astrophysical data [<xref ref-type="bibr" rid="CR41">41</xref>, <xref ref-type="bibr" rid="CR42">42</xref>]. A similar approach—generating simple representations of scientific data and converting those representations to higher-quality images—could be fruitfully applied in these other domains as well.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec20">
      <p>Below is the link to the electronic supplementary material.<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="10822_2022_471_MOESM1_ESM.mp4"><caption><p>Supplementary file1 (MP4 6954 kb)—Online Resource 1. Prot2Prot-generated animations (video). Animations depict the transition of ScHxk2 between open and closed states (3,671 atoms). A multi-frame PDB file was first generated by “morphing” between two conformations extracted from a molecular dynamics simulation. This file was then used to render 48 Prot2Prot images, which were looped when composing the video. The video also illustrates Prot2Prot’s still, rock, turntable, and zoom animations. All proteins were rendered in the Simple Surface style.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="10822_2022_471_MOESM2_ESM.mp4"><caption><p>Supplementary file2 (MP4 12626 kb)—Online Resource 2. Prot2Prot animations with frame interpolation (video). These animations were generated by applying frame interpolation (RIFE 3.1) to twelve Prot2Prot-generated images of the same ScHxk2 trajectory (3,671 atoms per frame). Top row: Proteins rendered in the Simple Surface style. Bottom row: Proteins rendered in the Chalky Shadow style. Note that the shadows update dynamically as the protein moves and that the colorization post-processing filter imparts a green tint to the protein surface.</p></caption></media></supplementary-material></p>
    </sec>
  </sec>
</body>
<back>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>We thank the University of Pittsburgh’s Center for Research Computing for computer resources and Harrison Green for help with the browser implementation.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>JDD is the sole author and is responsible for all aspects of the study design and execution. He also wrote the present manuscript describing the work.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported by the National Institute of General Medical Sciences of the National Institutes of Health [R01GM132353 to J.D.D.]. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data availability</title>
    <p>The computer software and trained models that support the findings of this study are available free of charge, without registration, at <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/prot2prot-download/">http://durrantlab.com/prot2prot-download/</ext-link> (Apache License, Version 2.0). Users can access the ready-to-use Prot2Prot-powered web app without registration at <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/prot2prot">http://durrantlab.com/prot2prot</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar2" notes-type="COI-statement">
      <title>Conflict of interest</title>
      <p id="Par45">The author declares that he has no conflict of interest. The author declares that he has no financial interests.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Humphrey</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Dalke</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Schulten</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <article-title>VMD: visual molecular dynamics</article-title>
        <source>J Mol Graph</source>
        <year>1996</year>
        <volume>14</volume>
        <issue>1</issue>
        <fpage>33</fpage>
        <lpage>38</lpage>
        <pub-id pub-id-type="doi">10.1016/0263-7855(96)00018-5</pub-id>
        <pub-id pub-id-type="pmid">8744570</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pettersen</surname>
            <given-names>EF</given-names>
          </name>
          <name>
            <surname>Goddard</surname>
            <given-names>TD</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Couch</surname>
            <given-names>GS</given-names>
          </name>
          <name>
            <surname>Greenblatt</surname>
            <given-names>DM</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>EC</given-names>
          </name>
          <name>
            <surname>Ferrin</surname>
            <given-names>TE</given-names>
          </name>
        </person-group>
        <article-title>UCSF chimera–a visualization system for exploratory research and analysis</article-title>
        <source>J Comput Chem</source>
        <year>2004</year>
        <volume>25</volume>
        <issue>13</issue>
        <fpage>1605</fpage>
        <lpage>1612</lpage>
        <pub-id pub-id-type="doi">10.1002/jcc.20084</pub-id>
        <pub-id pub-id-type="pmid">15264254</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Goddard</surname>
            <given-names>TD</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>EC</given-names>
          </name>
          <name>
            <surname>Pettersen</surname>
            <given-names>EF</given-names>
          </name>
          <name>
            <surname>Couch</surname>
            <given-names>GS</given-names>
          </name>
          <name>
            <surname>Morris</surname>
            <given-names>JH</given-names>
          </name>
          <name>
            <surname>Ferrin</surname>
            <given-names>TE</given-names>
          </name>
        </person-group>
        <article-title>UCSF ChimeraX: meeting modern challenges in visualization and analysis</article-title>
        <source>Protein Sci</source>
        <year>2018</year>
        <volume>27</volume>
        <issue>1</issue>
        <fpage>14</fpage>
        <lpage>25</lpage>
        <pub-id pub-id-type="doi">10.1002/pro.3235</pub-id>
        <pub-id pub-id-type="pmid">28710774</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pettersen</surname>
            <given-names>EF</given-names>
          </name>
          <name>
            <surname>Goddard</surname>
            <given-names>TD</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>EC</given-names>
          </name>
          <name>
            <surname>Couch</surname>
            <given-names>GS</given-names>
          </name>
          <name>
            <surname>Croll</surname>
            <given-names>TI</given-names>
          </name>
          <name>
            <surname>Morris</surname>
            <given-names>JH</given-names>
          </name>
          <name>
            <surname>Ferrin</surname>
            <given-names>TE</given-names>
          </name>
        </person-group>
        <article-title>UCSF ChimeraX: structure visualization for researchers, educators, and developers</article-title>
        <source>Protein Sci</source>
        <year>2021</year>
        <volume>30</volume>
        <issue>1</issue>
        <fpage>70</fpage>
        <lpage>82</lpage>
        <pub-id pub-id-type="doi">10.1002/pro.3943</pub-id>
        <pub-id pub-id-type="pmid">32881101</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Delano</surname>
            <given-names>WL</given-names>
          </name>
        </person-group>
        <article-title>Pymol: An open-source molecular graphics tool</article-title>
        <source>CCP4 Newslett Protein Crystallogr</source>
        <year>2002</year>
        <volume>40</volume>
        <issue>1</issue>
        <fpage>82</fpage>
        <lpage>92</lpage>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sehnal</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Bittrich</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Deshpande</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Svobodova</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Berka</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Bazgier</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Velankar</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Burley</surname>
            <given-names>SK</given-names>
          </name>
          <name>
            <surname>Koca</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Rose</surname>
            <given-names>AS</given-names>
          </name>
        </person-group>
        <article-title>Mol* viewer: modern web app for 3D visualization and analysis of large biomolecular structures</article-title>
        <source>Nucleic Acids Res</source>
        <year>2021</year>
        <volume>49</volume>
        <issue>W1</issue>
        <fpage>W431</fpage>
        <lpage>W437</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkab314</pub-id>
        <pub-id pub-id-type="pmid">33956157</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rose</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>Bradley</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Valasatava</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Duarte</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Prlic</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Rose</surname>
            <given-names>PW</given-names>
          </name>
        </person-group>
        <article-title>NGL viewer: web-based molecular graphics for large complexes</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>21</issue>
        <fpage>3755</fpage>
        <lpage>3758</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty419</pub-id>
        <pub-id pub-id-type="pmid">29850778</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rose</surname>
            <given-names>AS</given-names>
          </name>
          <name>
            <surname>Hildebrand</surname>
            <given-names>PW</given-names>
          </name>
        </person-group>
        <article-title>NGL Viewer: a web application for molecular visualization</article-title>
        <source>Nucleic Acids Res</source>
        <year>2015</year>
        <volume>43</volume>
        <issue>W1</issue>
        <fpage>W576</fpage>
        <lpage>579</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkv402</pub-id>
        <pub-id pub-id-type="pmid">25925569</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rego</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Koes</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>3Dmol.js: molecular visualization with WebGL</article-title>
        <source>Bioinformatics</source>
        <year>2015</year>
        <volume>31</volume>
        <issue>8</issue>
        <fpage>1322</fpage>
        <lpage>1324</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btu829</pub-id>
        <pub-id pub-id-type="pmid">25505090</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bekker</surname>
            <given-names>GJ</given-names>
          </name>
          <name>
            <surname>Nakamura</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Kinjo</surname>
            <given-names>AR</given-names>
          </name>
        </person-group>
        <article-title>Molmil: a molecular viewer for the PDB and beyond</article-title>
        <source>J Cheminform</source>
        <year>2016</year>
        <volume>8</volume>
        <issue>1</issue>
        <fpage>42</fpage>
        <pub-id pub-id-type="doi">10.1186/s13321-016-0155-1</pub-id>
        <pub-id pub-id-type="pmid">27570544</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Durrant</surname>
            <given-names>JD</given-names>
          </name>
        </person-group>
        <article-title>BlendMol: advanced macromolecular visualization in blender</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <issue>13</issue>
        <fpage>2323</fpage>
        <lpage>2325</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty968</pub-id>
        <pub-id pub-id-type="pmid">30481283</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Burley</surname>
            <given-names>SK</given-names>
          </name>
          <name>
            <surname>Bhikadiya</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Bi</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Bittrich</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Crichlow</surname>
            <given-names>GV</given-names>
          </name>
          <name>
            <surname>Duarte</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Dutta</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Fayazi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Flatt</surname>
            <given-names>JW</given-names>
          </name>
          <name>
            <surname>Ganesan</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Goodsell</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Ghosh</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kramer Green</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Guranovic</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Henry</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hudson</surname>
            <given-names>BP</given-names>
          </name>
          <name>
            <surname>Lawson</surname>
            <given-names>CL</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Lowe</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Peisach</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Persikova</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Piehl</surname>
            <given-names>DW</given-names>
          </name>
          <name>
            <surname>Rose</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Sali</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Segura</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sekharan</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Shao</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Vallat</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Voigt</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Westbrook</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>Whetstone</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Young</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Zardecki</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>RCSB protein data bank: celebrating 50 years of the PDB with new tools for understanding and visualizing biological macromolecules in 3D</article-title>
        <source>Protein Sci</source>
        <year>2022</year>
        <volume>31</volume>
        <issue>1</issue>
        <fpage>187</fpage>
        <lpage>208</lpage>
        <pub-id pub-id-type="doi">10.1002/pro.4213</pub-id>
        <pub-id pub-id-type="pmid">34676613</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Word</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Lovell</surname>
            <given-names>SC</given-names>
          </name>
          <name>
            <surname>Richardson</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Richardson</surname>
            <given-names>DC</given-names>
          </name>
        </person-group>
        <article-title>Asparagine and glutamine: using hydrogen atom contacts in the choice of side-chain amide orientation</article-title>
        <source>J Mol Biol</source>
        <year>1999</year>
        <volume>285</volume>
        <issue>4</issue>
        <fpage>1735</fpage>
        <lpage>1747</lpage>
        <pub-id pub-id-type="doi">10.1006/jmbi.1998.2401</pub-id>
        <pub-id pub-id-type="pmid">9917408</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Isola P, Zhu J-Y, Zhou T, Efros AA (2017) Image-to-image translation with conditional adversarial networks. Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR). pp 1125–1134</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <mixed-citation publication-type="other">Zhu J-Y (2022) Image-to-image translation in pytorch <ext-link ext-link-type="uri" xlink:href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix">https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix</ext-link>. Accessed 11 Mar 2022</mixed-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <mixed-citation publication-type="other">Team TID (2021) ImageMagick &lt;<ext-link ext-link-type="uri" xlink:href="https://imagemagick.org">https://imagemagick.org</ext-link>&gt;. Accessed 5 July 2022</mixed-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <mixed-citation publication-type="other">onnx/onnx-tensorflow (2022) Tensorflow backend for ONNX <ext-link ext-link-type="uri" xlink:href="https://github.com/onnx/onnx-tensorflow">https://github.com/onnx/onnx-tensorflow</ext-link>. Accessed 11 Mar 2022</mixed-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <mixed-citation publication-type="other">TensorFlow.js (2022) Machine learning for javascript developers <ext-link ext-link-type="uri" xlink:href="https://www.tensorflow.org/js">https://www.tensorflow.org/js</ext-link>. Accessed 11 Mar 2022</mixed-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Green</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Durrant</surname>
            <given-names>JD</given-names>
          </name>
        </person-group>
        <article-title>DeepFrag: an open-source browser app for deep-learning lead optimization</article-title>
        <source>J Chem Inf Model</source>
        <year>2021</year>
        <volume>61</volume>
        <issue>6</issue>
        <fpage>2523</fpage>
        <lpage>2529</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.1c00103</pub-id>
        <pub-id pub-id-type="pmid">34029094</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kochnev</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hellemann</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Cassidy</surname>
            <given-names>KC</given-names>
          </name>
          <name>
            <surname>Durrant</surname>
            <given-names>JD</given-names>
          </name>
        </person-group>
        <article-title>Webina: an open-source library and web app that runs AutoDock Vina entirely in the web browser</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>16</issue>
        <fpage>4513</fpage>
        <lpage>4515</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btaa579</pub-id>
        <pub-id pub-id-type="pmid">32559277</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Young</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Garikipati</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Durrant</surname>
            <given-names>JD</given-names>
          </name>
        </person-group>
        <article-title>BINANA 2: characterizing receptor/ligand interactions in python and javascript</article-title>
        <source>J Chem Inf Model</source>
        <year>2022</year>
        <volume>62</volume>
        <issue>4</issue>
        <fpage>753</fpage>
        <lpage>760</lpage>
        <pub-id pub-id-type="doi">10.1021/acs.jcim.1c01461</pub-id>
        <pub-id pub-id-type="pmid">35129332</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <mixed-citation publication-type="other">You E (2022) Vue.js—the progressive javascript framework. <ext-link ext-link-type="uri" xlink:href="https://vuejs.org/">https://vuejs.org/</ext-link>. Accessed 11 Mar 2022</mixed-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">BootstrapVue (2020) <ext-link ext-link-type="uri" xlink:href="https://bootstrap-vue.org/">https://bootstrap-vue.org/</ext-link>. Accessed 11 Mar 2022</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <mixed-citation publication-type="other">Koppers T (2022) Webpack. <ext-link ext-link-type="uri" xlink:href="https://webpack.js.org/">https://webpack.js.org/</ext-link>. Accessed 11 Mar 2022</mixed-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <mixed-citation publication-type="other">Google (2022) Closure compiler: Google developers. <ext-link ext-link-type="uri" xlink:href="https://developers.google.com/closure/compiler">https://developers.google.com/closure/compiler</ext-link>. Accessed 11 Mar 2022</mixed-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Crystal structure of human PCNA in complex with the PIP box of DVC1</article-title>
        <source>Biochem Biophys Res Commun</source>
        <year>2016</year>
        <volume>474</volume>
        <issue>2</issue>
        <fpage>264</fpage>
        <lpage>270</lpage>
        <pub-id pub-id-type="doi">10.1016/j.bbrc.2016.04.053</pub-id>
        <pub-id pub-id-type="pmid">27084448</pub-id>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <mixed-citation publication-type="other">Majboroda S (2020) Photo Studio 01 HDRI. <ext-link ext-link-type="uri" xlink:href="https://polyhaven.com/a/photo_studio_01">https://polyhaven.com/a/photo_studio_01</ext-link>. Accessed 11 Mar 2020</mixed-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Blend Swap (2021) SomeDude (2021) Studio lighting setup. <ext-link ext-link-type="uri" xlink:href="https://blendswap.com/blend/28426">https://blendswap.com/blend/28426</ext-link>. Accessed 11 Mar 2022</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hellemann</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Walker</surname>
            <given-names>JL</given-names>
          </name>
          <name>
            <surname>Lesko</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Chandrashekarappa</surname>
            <given-names>DG</given-names>
          </name>
          <name>
            <surname>Schmidt</surname>
            <given-names>MC</given-names>
          </name>
          <name>
            <surname>O'Donnell</surname>
            <given-names>AF</given-names>
          </name>
          <name>
            <surname>Durrant</surname>
            <given-names>JD</given-names>
          </name>
        </person-group>
        <article-title>Novel mutation in hexokinase 2 confers resistance to 2-deoxyglucose by altering protein dynamics</article-title>
        <source>PLoS Comput Biol</source>
        <year>2022</year>
        <volume>18</volume>
        <issue>3</issue>
        <fpage>e1009929</fpage>
        <pub-id pub-id-type="doi">10.1371/journal.pcbi.1009929</pub-id>
        <pub-id pub-id-type="pmid">35235554</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <mixed-citation publication-type="other">Huang Z, Zhang T, Heng W, Shi B, Zhou S (2020) Rife: real-time intermediate flow estimation for video frame interpolation. arXiv preprint arXiv:201106294</mixed-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">N00MKRAD (2022) Flowframes—Fast Video Interpolation for any GPU. <ext-link ext-link-type="uri" xlink:href="https://nmkd.itch.io/flowframes">https://nmkd.itch.io/flowframes</ext-link>. Accessed 11 Mar 2022</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Shin</surname>
            <given-names>H-C</given-names>
          </name>
          <name>
            <surname>Ihsani</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Mandava</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sreenivas</surname>
            <given-names>ST</given-names>
          </name>
          <name>
            <surname>Forster</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Cha</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <source>Alzheimer’s disease neuroimaging I. GANDALF: generative adversarial networks with discriminator-adaptive loss fine-tuning for Alzheimer’s disease diagnosis from MRI</source>
        <year>2020</year>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>Springer</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Burlingame</surname>
            <given-names>EA</given-names>
          </name>
          <name>
            <surname>Margolin</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Gray</surname>
            <given-names>JW</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>YH</given-names>
          </name>
        </person-group>
        <article-title>SHIFT: speedy histopathological-to-immunofluorescent translation of whole slide images using conditional generative adversarial networks</article-title>
        <source>Proc SPIE Int Soc Opt Eng</source>
        <year>2018</year>
        <volume>10581</volume>
        <fpage>29</fpage>
        <lpage>35</lpage>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jerez</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Stuart</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Schmitt</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Guerrero-Given</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Christie</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Hahn</surname>
            <given-names>WE</given-names>
          </name>
          <name>
            <surname>Kamasawa</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Smirnov</surname>
            <given-names>MS</given-names>
          </name>
        </person-group>
        <article-title>A deep learning approach to identifying immunogold particles in electron microscopy images</article-title>
        <source>Sci Rep</source>
        <year>2021</year>
        <volume>11</volume>
        <issue>1</issue>
        <fpage>7771</fpage>
        <pub-id pub-id-type="doi">10.1038/s41598-021-87015-2</pub-id>
        <pub-id pub-id-type="pmid">33833289</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shigene</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Hiasa</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Otake</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Soufi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Janewanthanakul</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Nishimura</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Sato</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Suetsugu</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Translation of cellular protein localization using convolutional networks</article-title>
        <source>Front Cell Develop Biol</source>
        <year>2021</year>
        <volume>9</volume>
        <fpage>635231</fpage>
        <pub-id pub-id-type="doi">10.3389/fcell.2021.635231</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>HC</given-names>
          </name>
          <name>
            <surname>Cherng</surname>
            <given-names>ST</given-names>
          </name>
          <name>
            <surname>Miotto</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Dudley</surname>
            <given-names>JT</given-names>
          </name>
        </person-group>
        <source>Enhancing high-content imaging for studying microtubule networks at large-scale</source>
        <year>2019</year>
        <publisher-loc>New York</publisher-loc>
        <publisher-name>PMLR</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Catchpole D, Shkeir N, Smith A (2020) Using generative adversarial networks to create multi-channel images of cells undergoing macropinocytosis</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <mixed-citation publication-type="other">Horvath R (2019) Image-space metaballs using deep learning</mixed-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Figueiras</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Olivieri</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Paredes</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Michinel</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>QMBlender: particle-based visualization of 3D quantum wave function dynamics</article-title>
        <source>J Comput Sci</source>
        <year>2019</year>
        <volume>35</volume>
        <fpage>44</fpage>
        <lpage>56</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jocs.2019.06.001</pub-id>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <mixed-citation publication-type="other">Giannakidis A, Giakoumidakis G, Mania K (2014) 3D photorealistic scientific visualization of tsunami waves and sea level rise. IEEE, pp. 167–172</mixed-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Naiman</surname>
            <given-names>JP</given-names>
          </name>
        </person-group>
        <article-title>AstroBlend: an astrophysical visualization package for blender</article-title>
        <source>Astro Comput</source>
        <year>2016</year>
        <volume>15</volume>
        <fpage>50</fpage>
        <lpage>60</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ascom.2016.02.002</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kent</surname>
            <given-names>BR</given-names>
          </name>
        </person-group>
        <article-title>Visualizing astronomical data with blender</article-title>
        <source>Publ Astron Soc Pac</source>
        <year>2013</year>
        <volume>125</volume>
        <issue>928</issue>
        <fpage>731</fpage>
        <pub-id pub-id-type="doi">10.1086/671412</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
