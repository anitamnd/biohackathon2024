<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName journalpublishing.dtd?>
<?SourceDTD.Version 2.3?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Front Neurosci</journal-id>
    <journal-id journal-id-type="iso-abbrev">Front Neurosci</journal-id>
    <journal-id journal-id-type="publisher-id">Front. Neurosci.</journal-id>
    <journal-title-group>
      <journal-title>Frontiers in Neuroscience</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1662-4548</issn>
    <issn pub-type="epub">1662-453X</issn>
    <publisher>
      <publisher-name>Frontiers Media S.A.</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7783408</article-id>
    <article-id pub-id-type="doi">10.3389/fnins.2020.610239</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Neuroscience</subject>
        <subj-group>
          <subject>Original Research</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>RatLesNetv2: A Fully Convolutional Network for Rodent Brain Lesion Segmentation</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Valverde</surname>
          <given-names>Juan Miguel</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="c001">
          <sup>*</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/1075866/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Shatillo</surname>
          <given-names>Artem</given-names>
        </name>
        <xref ref-type="aff" rid="aff2">
          <sup>2</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/1152666/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>De Feo</surname>
          <given-names>Riccardo</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff3">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff4">
          <sup>4</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Gröhn</surname>
          <given-names>Olli</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/380021/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sierra</surname>
          <given-names>Alejandra</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/102487/overview"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Tohka</surname>
          <given-names>Jussi</given-names>
        </name>
        <xref ref-type="aff" rid="aff1">
          <sup>1</sup>
        </xref>
        <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/4010/overview"/>
      </contrib>
    </contrib-group>
    <aff id="aff1"><sup>1</sup><institution>A.I. Virtanen Institute for Molecular Sciences, University of Eastern Finland</institution>, <addr-line>Kuopio</addr-line>, <country>Finland</country></aff>
    <aff id="aff2"><sup>2</sup><institution>Charles River Discovery Services</institution>, <addr-line>Kuopio</addr-line>, <country>Finland</country></aff>
    <aff id="aff3"><sup>3</sup><institution>Centro Fermi-Museo Storico della Fisica e Centro Studi e Ricerche Enrico Fermi</institution>, <addr-line>Rome</addr-line>, <country>Italy</country></aff>
    <aff id="aff4"><sup>4</sup><institution>Sapienza Università di Roma</institution>, <addr-line>Rome</addr-line>, <country>Italy</country></aff>
    <author-notes>
      <fn fn-type="edited-by">
        <p>Edited by: Tim B. Dyrby, Technical University of Denmark, Denmark</p>
      </fn>
      <fn fn-type="edited-by">
        <p>Reviewed by: Yi Zhang, Zhejiang University, China; Shanshan Jiang, Johns Hopkins Medicine, United States</p>
      </fn>
      <corresp id="c001">*Correspondence: Juan Miguel Valverde <email>juanmiguel.valverde@uef.fi</email></corresp>
      <fn fn-type="other" id="fn001">
        <p>This article was submitted to Brain Imaging Methods, a section of the journal Frontiers in Neuroscience</p>
      </fn>
    </author-notes>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>12</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>14</volume>
    <elocation-id>610239</elocation-id>
    <history>
      <date date-type="received">
        <day>25</day>
        <month>9</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>25</day>
        <month>11</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>Copyright © 2020 Valverde, Shatillo, De Feo, Gröhn, Sierra and Tohka.</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Valverde, Shatillo, De Feo, Gröhn, Sierra and Tohka</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
      </license>
    </permissions>
    <abstract>
      <p>We present a fully convolutional neural network (ConvNet), named RatLesNetv2, for segmenting lesions in rodent magnetic resonance (MR) brain images. RatLesNetv2 architecture resembles an autoencoder and it incorporates residual blocks that facilitate its optimization. RatLesNetv2 is trained end to end on three-dimensional images and it requires no preprocessing. We evaluated RatLesNetv2 on an exceptionally large dataset composed of 916 T2-weighted rat brain MRI scans of 671 rats at nine different lesion stages that were used to study focal cerebral ischemia for drug development. In addition, we compared its performance with three other ConvNets specifically designed for medical image segmentation. RatLesNetv2 obtained similar to higher Dice coefficient values than the other ConvNets and it produced much more realistic and compact segmentations with notably fewer holes and lower Hausdorff distance. The Dice scores of RatLesNetv2 segmentations also exceeded inter-rater agreement of manual segmentations. In conclusion, RatLesNetv2 could be used for automated lesion segmentation, reducing human workload and improving reproducibility. RatLesNetv2 is publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/jmlipman/RatLesNetv2">https://github.com/jmlipman/RatLesNetv2</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>ischemic stroke</kwd>
      <kwd>lesion segmentation</kwd>
      <kwd>deep learning</kwd>
      <kwd>rat brain</kwd>
      <kwd>magnetic resonance imaging</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source id="cn001">H2020 Marie Sklodowska-Curie Actions<named-content content-type="fundref-id">10.13039/100010665</named-content></funding-source>
        <award-id rid="cn001">691110</award-id>
        <award-id rid="cn001">740264</award-id>
      </award-group>
      <award-group>
        <funding-source id="cn002">Academy of Finland<named-content content-type="fundref-id">10.13039/501100002341</named-content></funding-source>
        <award-id rid="cn002">275453</award-id>
        <award-id rid="cn002">316258</award-id>
      </award-group>
    </funding-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="4"/>
      <equation-count count="6"/>
      <ref-count count="41"/>
      <page-count count="11"/>
      <word-count count="8353"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="s1">
    <title>1. Introduction</title>
    <p>Rodents frequently serve as models for human brain diseases. They account for more than 80% of the animals used in research in recent years (Dutta and Sengupta, <xref rid="B13" ref-type="bibr">2016</xref>). In addition to basic research, rodent models are important in, for example, drug discovery and the development of new treatments. <italic>In vivo</italic> imaging of rodents is used for monitoring disease progression and therapeutic response in longitudinal studies. In particular, magnetic resonance imaging (MRI) is essential in pre-clinical studies for conducting quantitative analyses due to its non-invasiveness and versatility. As an example, the quantification of brain lesions requires segmenting the lesions, and the lack of reliable tools to automate rodent brain lesion segmentation forces researchers to segment these images manually.</p>
    <p>Manual segmentation can be prohibitively time-consuming as studies involving animals may acquire hundreds of three-dimensional (3D) images. Furthermore, the difficulty of defining lesion boundaries leads to moderate inter- and intra-rater agreement; previous studies have reported that Dice coefficients (Dice, <xref rid="B9" ref-type="bibr">1945</xref>) between annotations made by two humans can be as low as 0.73 (Valverde et al., <xref rid="B37" ref-type="bibr">2019</xref>) or 0.79 (Mulder et al., <xref rid="B26" ref-type="bibr">2017a</xref>). Moderate inter-rater agreement is caused by several factors that affect the segmentation quality, including partial volume effect, image contrast and annotator's knowledge and experience. Despite these liabilities, manual segmentation is the gold standard and a common practice among researchers who use animal models (Moraga et al., <xref rid="B25" ref-type="bibr">2016</xref>; De Feo and Giove, <xref rid="B8" ref-type="bibr">2019</xref>).</p>
    <p>Semi-automatic methods are a faster alternative to manual segmentation. However, they fail to overcome the subjectivity of the manual segmentation, as human interaction is required. To the best of the authors' knowledge, there are only two studies that introduce and evaluate semi-automatic algorithms for rodent brain lesion segmentation. Wang et al. (<xref rid="B40" ref-type="bibr">2007</xref>) evaluated a combination of thresholding operations commonly used in the literature to segment lesions on apparent diffusion coefficient (ADC) maps and T2-weighted images. Choi et al. (<xref rid="B6" ref-type="bibr">2018</xref>) first normalized the intensity values of each image with respect to the contralateral hemisphere of the brain, and they performed a series of thresholding operations to segment permanent middle cerebral artery occlusion ischemic lesions in 31 diffusion-weighted images (DWIs) of the rat brain. Both methods require the manual segmentation of the contralateral hemisphere. Additionally, these thresholding-based and other voxel-wise approaches disregard the spatial and contextual information of the images, and they are sensitive to the image modality, contrast, and possible artifacts. Pipelines that rely on thresholding operations may result in poor and inconsistent segmentation results in the form of holes within and outside the lesion mask (<xref ref-type="fig" rid="F1">Figure 1</xref>).</p>
    <fig id="F1" position="float">
      <label>Figure 1</label>
      <caption>
        <p>(Left) Representative lesion with its ground truth. (Right) Segmentation of the lesion using thresholding where the threshold was found by maximizing the Dice coefficient with respect to the manual segmentation. The arrows indicate the presence of holes and islands (independently connected components) within and outside the mask, respectively. The hippocampus and ventricles were entirely misclassified as lesion.</p>
      </caption>
      <graphic xlink:href="fnins-14-610239-g0001"/>
    </fig>
    <p>For lesion segmentation in rodent MRI, researchers have proposed a few fully-automated methods in recent years. Mulder et al. (<xref rid="B26" ref-type="bibr">2017a</xref>) developed a level-set-based algorithm that was tested on 121 T2-weighted mouse brain scans. However, the accuracy of their method heavily relies on the performance of other independent steps, such as registration, skull-stripping and contralateral ventricle segmentation. Arnaud et al. (<xref rid="B1" ref-type="bibr">2018</xref>) derived a pipeline that detects voxels that are anomalous with respect to a reference model of healthy animals, and they evaluated the pipeline on 53 rat brain MRI maps. Nonetheless, this pipeline was specifically designed for quantitative MRI, and it expects sham-operated animals in the data set, a requirement that is not always feasible.</p>
    <p>Deep learning, and more specifically convolutional neural networks (ConvNets), has become increasingly popular due to its competitive performance in medical image segmentation. Literature on brain lesion segmentation in MR images with ConvNets is dominated by approaches tested on human-derived data (e.g., Duong et al., <xref rid="B12" ref-type="bibr">2019</xref>; Gabr et al., <xref rid="B15" ref-type="bibr">2019</xref>; Yang et al., <xref rid="B41" ref-type="bibr">2019</xref>). Despite using ConvNets, typical brain lesion segmentation approaches are multi-step, i.e., they rely on preprocessing procedures, such as noise reduction, registration, skull-stripping and inhomogeneity correction. Therefore, the performance of the preprocessing steps influences the quality of the final segmentation. In contrast to human-derived data, rodent segmentation data sets are scarce and smaller in size (Mulder et al., <xref rid="B27" ref-type="bibr">2017b</xref>); consequently, ConvNet-based segmentation methods benchmarked on rodent MR images are rare. An exception—not in the lesion segmentation—is Roy et al. (<xref rid="B33" ref-type="bibr">2018</xref>)'s work, which introduced a framework to extract brain tissue (i.e., skull-stripping) on human and mice MRI scans after traumatic brain injury.</p>
    <p>We present RatLesNetv2, the first 3D ConvNet for segmenting rodent brain lesions in pre-clinical MR images. Our fully-automatic approach is trained end to end, requires no preprocessing, and it was validated on a large and diverse data set composed by 916 MRI rat brain scans at nine different lesion stages from 671 rats utilized to study focal cerebral ischemia. We extend our earlier conference paper (Valverde et al., <xref rid="B37" ref-type="bibr">2019</xref>) by (1) improving our previous ConvNet (Valverde et al., <xref rid="B37" ref-type="bibr">2019</xref>) with a deeper and different architecture and providing an ablation study (Meyes et al., <xref rid="B23" ref-type="bibr">2019</xref>) justifying certain architectural choices; (2) evaluating the generalization capability of our model on a considerably larger and more heterogeneous data set via Dice coefficient, compactness and Hausdorff distance under different training settings (training set size and different ground truth); and (3) making RatLesNetv2 publicly available.</p>
    <p>We show that RatLesNetv2 generates more realistic segmentations than our previous RatLesNet, and than 3D U-Net (Çiçek et al., <xref rid="B7" ref-type="bibr">2016</xref>) and VoxResNet (Chen et al., <xref rid="B3" ref-type="bibr">2018a</xref>), two state-of-the-art ConvNets specifically designed for medical image segmentation. Additionally, the Dice coefficients of the segmentations derived with RatLesNetv2 exceeded inter-rater agreement scores.</p>
  </sec>
  <sec sec-type="materials and methods" id="s2">
    <title>2. Materials and Methods</title>
    <sec>
      <title>2.1. Data</title>
      <p>The data set consisted of 916 MR T2-weighted brain scans of 671 adult male Wistar rats weighting between 250 and 300 g. The data, provided by Discovery Services site of Charles River Laboratories,<xref ref-type="fn" rid="fn0001"><sup>1</sup></xref> were derived from 12 different studies. Transient (120 min) focal cerebral ischemia was produced by middle cerebral artery occlusion in the right hemisphere of the brain (Koizumi et al., <xref rid="B21" ref-type="bibr">1986</xref>). MR data acquisitions were performed at different time-points after the occlusion (for details, see <xref rid="T1" ref-type="table">Table 1</xref>). Some studies also had sham-operated animals that underwent identical surgical procedures, but without the actual occlusion. All animal experiments were conducted according to the National Institute of Health (NIH) guidelines for the care and use of laboratory animals, and approved by the National Animal Experiment Board, Finland. Multi-slice multi-echo sequence was used with the following parameters; TR =2.5 s, 12 echo times (10–120 ms in 10 ms steps), and 4 averages in a horizontal 7T magnet. T2-weighted images were calculated as the sum of the all echoes. Eighteen coronal slices of 1 mm thickness were acquired using a field-of-view of 30 × 30 mm<sup>2</sup> producing 256 × 256 imaging matrices of resolution 117 × 117 μm. No MRI preprocessing steps, such as inhomogeneity correction, artifact removal, registration or skull stripping, were applied to the T2-weighted images. Images were zero-centered and their variance was normalized to one.</p>
      <table-wrap id="T1" position="float">
        <label>Table 1</label>
        <caption>
          <p>Number of scans per study segregated by lesion stage, including sham-operated animals.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Study</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>2 h</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>24 h</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>D3</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>D7</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>D14</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>D21</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>D28</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>D35</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Shams</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">A</td>
              <td valign="top" align="center" rowspan="1" colspan="1">12</td>
              <td valign="top" align="center" rowspan="1" colspan="1">12</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">24</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">B</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">46</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">C</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">59</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">D</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">162</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">4</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">E</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">20</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">F</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">33</td>
              <td valign="top" align="center" rowspan="1" colspan="1">30</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">30</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">27</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">46</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">G</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">53</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">12</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">H</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">45</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">I</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">64</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">62</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">J</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">32</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">K</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">17</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">L</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">41</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">40</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0</td>
              <td valign="top" align="center" rowspan="1" colspan="1">40</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Total</td>
              <td valign="top" align="center" rowspan="1" colspan="1">12</td>
              <td valign="top" align="center" rowspan="1" colspan="1">406</td>
              <td valign="top" align="center" rowspan="1" colspan="1">135</td>
              <td valign="top" align="center" rowspan="1" colspan="1">53</td>
              <td valign="top" align="center" rowspan="1" colspan="1">30</td>
              <td valign="top" align="center" rowspan="1" colspan="1">40</td>
              <td valign="top" align="center" rowspan="1" colspan="1">89</td>
              <td valign="top" align="center" rowspan="1" colspan="1">20</td>
              <td valign="top" align="center" rowspan="1" colspan="1">131</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <p>The provided lesion segmentations were annotated by several trained technicians employed by Charles River. We performed an additional independent manual segmentation of the lesions on the first study that was acquired (study A, <xref rid="T1" ref-type="table">Table 1</xref>) to approximate inter-rater variability. The average Dice coefficient (Dice, <xref rid="B9" ref-type="bibr">1945</xref>) between the two manual segmentations was 0.67 with a standard deviation of 0.12 on 2 h lesions and 0.79 with a standard deviation of 0.08 on 24 h lesions. The overall average was 0.73 ± 0.12. Unless stated otherwise, we used our independent segmentation as the ground truth for study A.</p>
      <p>We produced two different train/test set divisions. (1) In the first one, the training set contained the 48 scans of the study which was used to approximate inter-rater variability (study A, <xref rid="T1" ref-type="table">Table 1</xref>) and the test set contained the remaining 868 images. The training set was further divided to training (36 images) and validation sets (12 images). This train/test division is referred to as “<bold>homogeneous</bold>” and its train/validation split has the same ratio 2/24 h time-points and sham/no-sham animals. (2) The second division also contained 48 training scans and the test set contained 868 scans, but the training set was different from the homogeneous division. This division is referred to as “<bold>heterogeneous</bold>” because the training set was more diverse. The training set was divided into training (40 images) and validation (8 images) set. The training and the validation sets were formed by 5 and 1 images per lesion time-point, respectively, with no images from sham-operated animals. The size of our training set was deliberately much smaller than the test set for two reasons: (1) to replicate the typical pre-clinical setting in which rodent MR images are few and (2) to create a large and representative test set.</p>
    </sec>
    <sec>
      <title>2.2. Convolutional Neural Networks</title>
      <p>Convolutional neural networks (ConvNets) use stacks of convolutions to transform spatially correlated data, such as images, to extract their features. The first layers of the network capture low-level information, such as edges and corners, and the final layers extract more abstract features. The number of convolutions adjusts two attributes of ConvNets: parameter number and network depth. An excessive number of parameters leads to overfitting—memorizing the training data; an insufficient number of parameters constrains the learning capability of the model. Model depth is associated with the number of times the input data is transformed, and this depth also adjusts the area that influences the prediction—the receptive field (RF). Recent approaches reduce model parameters while maintaining the RF by using more stacked convolutions of smaller kernel size (Szegedy et al., <xref rid="B36" ref-type="bibr">2016</xref>).</p>
      <p>Model architectures based on U-Net (Ronneberger et al., <xref rid="B31" ref-type="bibr">2015</xref>) are popular in medical image segmentation tasks. In contrast to patch-based models, the input images and the generated masks are the same size, which makes U-Nets computationally more efficient to train and to evaluate. The U-Net architecture resembles an autoencoder with skip connections between the same levels of the encoder and decoder. The encoder transforms and reduces the dimensionality of the input images, and the decoder recovers the spatial information with the help of skip connections.</p>
      <p>Skip connections also facilitate the gradient flow during back-propagation (Drozdzal et al., <xref rid="B11" ref-type="bibr">2016</xref>), but they are not sufficient to prevent the gradient of the loss to vanish, which makes the network harder to train. This is also referred as the vanishing gradient problem (He et al., <xref rid="B16" ref-type="bibr">2016</xref>), and it particularly affects the final layers of the encoder part. Adding residual connections (He et al., <xref rid="B16" ref-type="bibr">2016</xref>) along the network alleviates the vanishing gradient problem and it also yields in faster convergence rates during the optimization (Drozdzal et al., <xref rid="B11" ref-type="bibr">2016</xref>).</p>
    </sec>
    <sec>
      <title>2.3. RatLesNetv2 Architecture</title>
      <p>RatLesNetv2 (<xref ref-type="fig" rid="F2">Figure 2</xref>) has three downsampling and three upsampling stages connected via skip connections. Maxpooling downsamples the data with a window size and strides of 2, and trilinear interpolation upsamples the feature maps. Bottleneck layers (<xref ref-type="fig" rid="F2">Figure 2</xref>, green blocks) stack a ReLU activation function, a batch normalization (BatchNorm) layer (Ioffe and Szegedy, <xref rid="B18" ref-type="bibr">2015</xref>) and a 3D convolution with kernel size of 1 that combines and modifies the number of channels of the feature maps from <italic>in</italic> to <italic>out</italic>. ResNetBlock layers (<xref ref-type="fig" rid="F2">Figure 2</xref>, orange blocks) contain two stacks of ReLU activations, BatchNorm, and 3D convolutions with kernel size of 3. Similarly to VoxResNet (Chen et al., <xref rid="B3" ref-type="bibr">2018a</xref>), the input and output of each block is summed in a ResNet-style (He et al., <xref rid="B16" ref-type="bibr">2016</xref>). The width of the blocks in the decoder is twice (64) with respect to the encoder part (32) due to the concatenation of previous layers in the same stage of the network.</p>
      <fig id="F2" position="float">
        <label>Figure 2</label>
        <caption>
          <p>RatLesNetv2 network architecture. See the text for the detailed explanation of the blocks.</p>
        </caption>
        <graphic xlink:href="fnins-14-610239-g0002"/>
      </fig>
      <p>At the end of the network, the probabilities <bold>z</bold> = [<italic>z</italic><sub>1</sub>, <italic>z</italic><sub>2</sub>] (corresponding to non-lesion and lesion labels) for each voxel are normalized by the Softmax function</p>
      <disp-formula id="E1">
        <label>(1)</label>
        <mml:math id="M1">
          <mml:mtable class="eqnarray" columnalign="left">
            <mml:mtr>
              <mml:mtd>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>q</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mi>S</mml:mi>
                <mml:mi>o</mml:mi>
                <mml:mi>f</mml:mi>
                <mml:mi>t</mml:mi>
                <mml:mi>m</mml:mi>
                <mml:mi>a</mml:mi>
                <mml:mi>x</mml:mi>
                <mml:msub>
                  <mml:mrow>
                    <mml:mrow>
                      <mml:mo stretchy="false">(</mml:mo>
                      <mml:mrow>
                        <mml:mstyle mathvariant="bold">
                          <mml:mtext>z</mml:mtext>
                        </mml:mstyle>
                      </mml:mrow>
                      <mml:mo stretchy="false">)</mml:mo>
                    </mml:mrow>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>e</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>z</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>i</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msup>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mstyle displaystyle="true">
                      <mml:msubsup>
                        <mml:mrow>
                          <mml:mo>∑</mml:mo>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>j</mml:mi>
                          <mml:mtext> </mml:mtext>
                          <mml:mo>=</mml:mo>
                          <mml:mtext> </mml:mtext>
                          <mml:mn>1</mml:mn>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mn>2</mml:mn>
                        </mml:mrow>
                      </mml:msubsup>
                    </mml:mstyle>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>e</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:msub>
                          <mml:mrow>
                            <mml:mi>z</mml:mi>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>j</mml:mi>
                          </mml:mrow>
                        </mml:msub>
                      </mml:mrow>
                    </mml:msup>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>,</mml:mo>
              </mml:mtd>
            </mml:mtr>
          </mml:mtable>
        </mml:math>
      </disp-formula>
      <p>and the segmentation label is argmax<sub><italic>i</italic></sub>(<italic>q</italic><sub><italic>i</italic></sub>), <italic>i</italic> = 1, 2.</p>
      <p>RatLesNetv2 architecture differs from our previous RatLesNet (Valverde et al., <xref rid="B37" ref-type="bibr">2019</xref>) in two aspects. First, RatLesNetv2 has one additional downsampling and upsampling level, increasing the receptive field to 76 × 76 × 76 voxels. These extra levels allows RatLesNetv2 to consider more information from a larger volume. Second, RatLesNetv2 replaces unpooling (Noh et al., <xref rid="B29" ref-type="bibr">2015</xref>) and DenseNetBlocks (Huang et al., <xref rid="B17" ref-type="bibr">2017</xref>) with trilinear upsampling and ResNetBlocks, respectively, reducing memory usage and execution time. In contrast to VoxResNet (Chen et al., <xref rid="B3" ref-type="bibr">2018a</xref>), RatLesNetv2 architecture resembles an autoencoder, and RatLesNetv2 employs no transposed convolutions, reducing the number of parameters. Additionally, unlike 3D U-Net (Çiçek et al., <xref rid="B7" ref-type="bibr">2016</xref>), RatLesNetv2 uses residual blocks that reutilize previous computed feature maps and facilitate the optimization.</p>
    </sec>
    <sec>
      <title>2.4. Loss Function</title>
      <p>ConvNets' parameters are optimized by minimizing a loss function that describes the difference between the predictions and the ground truth. RatLesNetv2 was optimized with Adam (Kingma and Ba, <xref rid="B20" ref-type="bibr">2014</xref>) by minimizing cross entropy and Dice loss functions <italic>L</italic><sub><italic>total</italic></sub> = <italic>L</italic><sub><italic>BCE</italic></sub> + <italic>L</italic><sub><italic>Dice</italic></sub>. Cross entropy measures the error as the difference between distributions. Since our annotations consist of only two classes (lesion and non-lesion) we used binary cross entropy</p>
      <disp-formula id="E2">
        <label>(2)</label>
        <mml:math id="M2">
          <mml:mtable class="eqnarray" columnalign="left">
            <mml:mtr>
              <mml:mtd>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>L</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>B</mml:mi>
                    <mml:mi>C</mml:mi>
                    <mml:mi>E</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mo>-</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>N</mml:mi>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mstyle displaystyle="true">
                  <mml:munderover accentunder="false" accent="false">
                    <mml:mrow>
                      <mml:mo>∑</mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>i</mml:mi>
                      <mml:mtext> </mml:mtext>
                      <mml:mo>=</mml:mo>
                      <mml:mtext> </mml:mtext>
                      <mml:mn>1</mml:mn>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mi>N</mml:mi>
                    </mml:mrow>
                  </mml:munderover>
                </mml:mstyle>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>p</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>·</mml:mo>
                <mml:mo class="qopname">log</mml:mo>
                <mml:mrow>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mrow>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>q</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mrow>
                <mml:mo>+</mml:mo>
                <mml:mrow>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                    <mml:mo>-</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>p</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mrow>
                <mml:mo>·</mml:mo>
                <mml:mo class="qopname">log</mml:mo>
                <mml:mrow>
                  <mml:mo stretchy="false">(</mml:mo>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                    <mml:mo>-</mml:mo>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>q</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mo stretchy="false">)</mml:mo>
                </mml:mrow>
                <mml:mo>,</mml:mo>
              </mml:mtd>
            </mml:mtr>
          </mml:mtable>
        </mml:math>
      </disp-formula>
      <p>where <italic>p</italic><sub><italic>i</italic></sub> ∈ {0, 1} represents whether voxel <italic>i</italic> is lesion in the ground truth and <italic>q</italic><sub><italic>i</italic></sub> ∈ [0, 1] is the predicted Softmax probability of lesion class. Dice loss (Milletari et al., <xref rid="B24" ref-type="bibr">2016</xref>) is defined as:</p>
      <disp-formula id="E3">
        <label>(3)</label>
        <mml:math id="M3">
          <mml:mtable class="eqnarray" columnalign="left">
            <mml:mtr>
              <mml:mtd>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>L</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>D</mml:mi>
                    <mml:mi>i</mml:mi>
                    <mml:mi>c</mml:mi>
                    <mml:mi>e</mml:mi>
                  </mml:mrow>
                </mml:msub>
                <mml:mo>=</mml:mo>
                <mml:mn>1</mml:mn>
                <mml:mo>-</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mn>2</mml:mn>
                    <mml:mstyle displaystyle="true">
                      <mml:msubsup>
                        <mml:mrow>
                          <mml:mo>∑</mml:mo>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>i</mml:mi>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>N</mml:mi>
                        </mml:mrow>
                      </mml:msubsup>
                    </mml:mstyle>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>p</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                    <mml:msub>
                      <mml:mrow>
                        <mml:mi>q</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                      </mml:mrow>
                    </mml:msub>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mstyle displaystyle="true">
                      <mml:msubsup>
                        <mml:mrow>
                          <mml:mo>∑</mml:mo>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>i</mml:mi>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>N</mml:mi>
                        </mml:mrow>
                      </mml:msubsup>
                    </mml:mstyle>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>p</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:mrow>
                    </mml:msubsup>
                    <mml:mo>+</mml:mo>
                    <mml:mstyle displaystyle="true">
                      <mml:msubsup>
                        <mml:mrow>
                          <mml:mo>∑</mml:mo>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>i</mml:mi>
                        </mml:mrow>
                        <mml:mrow>
                          <mml:mi>N</mml:mi>
                        </mml:mrow>
                      </mml:msubsup>
                    </mml:mstyle>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>q</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mi>i</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mn>2</mml:mn>
                      </mml:mrow>
                    </mml:msubsup>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>.</mml:mo>
              </mml:mtd>
            </mml:mtr>
          </mml:mtable>
        </mml:math>
      </disp-formula>
      <p>The rationale behind using Dice loss is to directly maximize the Dice coefficient, one of the metrics to assess image segmentation performance. Although the derivative of Dice loss can be unstable when its denominator is very small, the use of BatchNorm and skip connections helps during the optimization by smoothing the loss landscape (Li et al., <xref rid="B22" ref-type="bibr">2018</xref>; Santurkar et al., <xref rid="B34" ref-type="bibr">2018</xref>).</p>
    </sec>
    <sec>
      <title>2.5. Post-processing</title>
      <p>Since our model optimizes a per-voxel loss function, small undesirable clusters of voxels may appear disconnected from the main predicted mask. These spurious clusters may be referred as “islands” when they are separated from the largest connected component and “holes” when they are inside the lesion mask. <xref ref-type="fig" rid="F1">Figure 1</xref> illustrates these terms.</p>
      <p>Small islands and holes can be removed in a final post-processing operation, yielding more realistic segmentations. Determining the maximum size of these holes and islands is, however, challenging in practice: A very small threshold will not eliminate enough small islands and a too large threshold may remove small lesions. In our experiments, we chose a threshold such that 90% of the holes and islands in the training data were removed. More specifically, we removed holes and islands of 20 voxels or less, inside and outside the lesion masks.</p>
    </sec>
    <sec>
      <title>2.6. Evaluation Metrics</title>
      <p>We assessed the performance of each ConvNet by measuring the Dice coefficient, Hausdorff distance and compactness. In agreement with the literature (Fenster and Chiu, <xref rid="B14" ref-type="bibr">2005</xref>), we argue that Dice coefficient alone is not an effective measure in rodent lesion segmentation, which is why we complemented it with the two other metrics.</p>
      <sec>
        <title>2.6.1. Dice Coefficient</title>
        <p>Dice coefficient (Dice, <xref rid="B9" ref-type="bibr">1945</xref>) is one of the most popular metrics in the field of image segmentation. It measures the overlap volume between two binary masks, typically the prediction of the model and the manually-annotated ground truth. Dice coefficient is formally described as:</p>
        <disp-formula id="E4">
          <label>(4)</label>
          <mml:math id="M4">
            <mml:mtable class="eqnarray" columnalign="left">
              <mml:mtr>
                <mml:mtd>
                  <mml:mi>D</mml:mi>
                  <mml:mi>i</mml:mi>
                  <mml:mi>c</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:mrow>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mrow>
                      <mml:mi>A</mml:mi>
                      <mml:mo>,</mml:mo>
                      <mml:mi>B</mml:mi>
                    </mml:mrow>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                  <mml:mo>=</mml:mo>
                  <mml:mfrac>
                    <mml:mrow>
                      <mml:mn>2</mml:mn>
                      <mml:mo>|</mml:mo>
                      <mml:mi>A</mml:mi>
                      <mml:mo>∩</mml:mo>
                      <mml:mi>B</mml:mi>
                      <mml:mo>|</mml:mo>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mo>|</mml:mo>
                      <mml:mi>A</mml:mi>
                      <mml:mo>|</mml:mo>
                      <mml:mo>+</mml:mo>
                      <mml:mo>|</mml:mo>
                      <mml:mi>B</mml:mi>
                      <mml:mo>|</mml:mo>
                    </mml:mrow>
                  </mml:mfrac>
                  <mml:mo>,</mml:mo>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:math>
        </disp-formula>
        <p>where <italic>A</italic> and <italic>B</italic> are the segmentation masks.</p>
      </sec>
      <sec>
        <title>2.6.2. Compactness</title>
        <p>Compact lesion masks are realistic and resemble human-made annotations. Compactness can be defined as the ratio between surface area (<italic>area</italic>) and volume of the mask (<italic>volume</italic>) (Bribiesca, <xref rid="B2" ref-type="bibr">2008</xref>). More specifically, we define compactness as:</p>
        <disp-formula id="E5">
          <label>(5)</label>
          <mml:math id="M5">
            <mml:mtable class="eqnarray" columnalign="left">
              <mml:mtr>
                <mml:mtd>
                  <mml:mi>C</mml:mi>
                  <mml:mi>o</mml:mi>
                  <mml:mi>m</mml:mi>
                  <mml:mi>p</mml:mi>
                  <mml:mi>a</mml:mi>
                  <mml:mi>c</mml:mi>
                  <mml:mi>t</mml:mi>
                  <mml:mi>n</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:mi>s</mml:mi>
                  <mml:mi>s</mml:mi>
                  <mml:mo>=</mml:mo>
                  <mml:mi>a</mml:mi>
                  <mml:mi>r</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:msup>
                    <mml:mrow>
                      <mml:mi>a</mml:mi>
                    </mml:mrow>
                    <mml:mrow>
                      <mml:mn>1</mml:mn>
                      <mml:mo>.</mml:mo>
                      <mml:mn>5</mml:mn>
                    </mml:mrow>
                  </mml:msup>
                  <mml:mo>/</mml:mo>
                  <mml:mi>v</mml:mi>
                  <mml:mi>o</mml:mi>
                  <mml:mi>l</mml:mi>
                  <mml:mi>u</mml:mi>
                  <mml:mi>m</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:mo>,</mml:mo>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:math>
        </disp-formula>
        <p>which has a constant minimum value of <inline-formula><mml:math id="M6"><mml:mn>6</mml:mn><mml:msqrt><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:msqrt></mml:math></inline-formula> for any sphere. Compactness measure penalizes holes, islands and non-smooth borders because these increase the surface area with respect to the volume. Therefore, low compactness values that describe compact segmentations are desirable.</p>
      </sec>
      <sec>
        <title>2.6.3. Hausdorff Distance</title>
        <p>Hausdorff distance (HD) (Rote, <xref rid="B32" ref-type="bibr">1991</xref>) is defined as:</p>
        <disp-formula id="E6">
          <label>(6)</label>
          <mml:math id="M7">
            <mml:mtable class="eqnarray" columnalign="left">
              <mml:mtr>
                <mml:mtd>
                  <mml:mi>d</mml:mi>
                  <mml:mrow>
                    <mml:mo stretchy="false">(</mml:mo>
                    <mml:mrow>
                      <mml:mi>A</mml:mi>
                      <mml:mo>,</mml:mo>
                      <mml:mi>B</mml:mi>
                    </mml:mrow>
                    <mml:mo stretchy="false">)</mml:mo>
                  </mml:mrow>
                  <mml:mo>=</mml:mo>
                  <mml:mo class="qopname">max</mml:mo>
                  <mml:mrow>
                    <mml:mo>{</mml:mo>
                    <mml:mrow>
                      <mml:mstyle displaystyle="true">
                        <mml:munder class="msub">
                          <mml:mrow>
                            <mml:mo class="qopname">max</mml:mo>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>a</mml:mi>
                            <mml:mo>∈</mml:mo>
                            <mml:mo>∂</mml:mo>
                            <mml:mi>A</mml:mi>
                          </mml:mrow>
                        </mml:munder>
                      </mml:mstyle>
                      <mml:mstyle displaystyle="true">
                        <mml:munder class="msub">
                          <mml:mrow>
                            <mml:mo class="qopname">min</mml:mo>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>b</mml:mi>
                            <mml:mo>∈</mml:mo>
                            <mml:mo>∂</mml:mo>
                            <mml:mi>B</mml:mi>
                          </mml:mrow>
                        </mml:munder>
                      </mml:mstyle>
                      <mml:mo stretchy="false">|</mml:mo>
                      <mml:mi>b</mml:mi>
                      <mml:mo>-</mml:mo>
                      <mml:mi>a</mml:mi>
                      <mml:mo stretchy="false">|</mml:mo>
                      <mml:mo>,</mml:mo>
                      <mml:mstyle displaystyle="true">
                        <mml:munder class="msub">
                          <mml:mrow>
                            <mml:mo class="qopname">max</mml:mo>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>b</mml:mi>
                            <mml:mo>∈</mml:mo>
                            <mml:mo>∂</mml:mo>
                            <mml:mi>B</mml:mi>
                          </mml:mrow>
                        </mml:munder>
                      </mml:mstyle>
                      <mml:mstyle displaystyle="true">
                        <mml:munder class="msub">
                          <mml:mrow>
                            <mml:mo class="qopname">min</mml:mo>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:mi>a</mml:mi>
                            <mml:mo>∈</mml:mo>
                            <mml:mo>∂</mml:mo>
                            <mml:mi>A</mml:mi>
                          </mml:mrow>
                        </mml:munder>
                      </mml:mstyle>
                      <mml:mo stretchy="false">|</mml:mo>
                      <mml:mi>a</mml:mi>
                      <mml:mo>-</mml:mo>
                      <mml:mi>b</mml:mi>
                      <mml:mo stretchy="false">|</mml:mo>
                    </mml:mrow>
                    <mml:mo>}</mml:mo>
                  </mml:mrow>
                  <mml:mo>,</mml:mo>
                </mml:mtd>
              </mml:mtr>
            </mml:mtable>
          </mml:math>
        </disp-formula>
        <p>where <italic>A</italic> and <italic>B</italic> are the segmentation masks, and ∂<italic>A</italic> and ∂<italic>B</italic> are their respective boundary voxels. It measures the maximum distance of the ground truth surface to the closest voxel of the prediction, i.e, the largest segmentation error. Measuring Hausdorff distance in brain lesion segmentation studies is crucial since misclassifications far from the lesion boundaries are more severe. The reported Hausdorff distances were in millimeters.</p>
        <p>Hausdorff distance and compactness values were calculated exclusively in animals with lesions. Hausdorff distance values on slightly imperfect segmentations of sham-operated animals are excessively large and distort the overall statistics. Additionally, compactness can not be calculated on empty volumes derived from scans without lesions. Voxel anisotropy was accounted for when computing HD and compactness. Finally, we assessed significance of performance difference through a paired permutation test with 10,000 random iterations on the post-processed segmentations with 0.05 as the significance threshold.</p>
      </sec>
    </sec>
    <sec>
      <title>2.7. Experimental Setup</title>
      <sec>
        <title>2.7.1. Training</title>
        <p>RatLesNetv2, 3D U-Net (Çiçek et al., <xref rid="B7" ref-type="bibr">2016</xref>), VoxResNet (Chen et al., <xref rid="B3" ref-type="bibr">2018a</xref>) and RatLesNet (Valverde et al., <xref rid="B37" ref-type="bibr">2019</xref>) were optimized with Adam (Kingma and Ba, <xref rid="B20" ref-type="bibr">2014</xref>) (<inline-formula><mml:math id="M8"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>9</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:mn>999</mml:mn><mml:mo>,</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>), starting with a learning rate of 10<sup>−5</sup> for 700 epochs. A small set of learning rates were tested on each architecture to ensure that we used the best performing learning rate in each model. Models were randomly initialized and trained three times separately, and their performance was evaluated from the lesion masks derived with majority voting across these three independent runs. In other words, for each architecture we ensembled three independently trained models. We confirmed that this strategy, typical to remove uncorrelated errors (Dietterich, <xref rid="B10" ref-type="bibr">2000</xref>), improves performance.</p>
      </sec>
      <sec>
        <title>2.7.2. Experiments</title>
        <sec>
          <title>2.7.2.1. Performance Comparison</title>
          <p>We optimized RatLesNetv2, 3D U-Net (Çiçek et al., <xref rid="B7" ref-type="bibr">2016</xref>), VoxResNet (Chen et al., <xref rid="B3" ref-type="bibr">2018a</xref>) and RatLesNet (Valverde et al., <xref rid="B37" ref-type="bibr">2019</xref>) on both the homogeneous and heterogeneous data set divisions (section 2.1) and compared their performance.</p>
        </sec>
        <sec>
          <title>2.7.2.2. Ablation Study</title>
          <p>We conducted an ablation study (Meyes et al., <xref rid="B23" ref-type="bibr">2019</xref>) in which we changed or removed certain parts of the model to comprehend the effects of the characteristics of RatLesNetv2 architecture. More specifically, we modified the interconnections between layers within each block, changed the number of downsampling/upsampling blocks, and increased and decreased the number of filters.</p>
        </sec>
        <sec>
          <title>2.7.2.3. Ground Truth Disparity Effect</title>
          <p>We trained two separate RatLesNetv2 models on segmentations annotated by two different operators. This can be seen as an inter-rater variability study of the same ConvNet with disparate knowledge. We run RatLesNetv2 three times for each ground truth on the homogeneous training data, which come exclusively from the study with the two annotations (Study A, <xref rid="T1" ref-type="table">Table 1</xref>). RatLesNetv2 produced six sets of 868 masks <italic>ŷ</italic><sub><italic>g,r</italic></sub> where <italic>g</italic> ∈ {1, 2} refers to the annotator segmenting the training data and <italic>r</italic> ∈ {1, 2, 3} refers to the run. First, we approximated the intra-rater variability of RatLesNetv2 by calculating the Dice coefficients among the three runs for each ground truth separately, i.e., {<italic>dice</italic>(<italic>ŷ</italic><sub><italic>g</italic>,1</sub>, <italic>ŷ</italic><sub><italic>g</italic>,2</sub>), <italic>dice</italic>(<italic>ŷ</italic><sub><italic>g</italic>,2</sub>, <italic>ŷ</italic><sub><italic>g</italic>,3</sub>), <italic>dice</italic>(<italic>ŷ</italic><sub><italic>g</italic>,1</sub>, <italic>ŷ</italic><sub><italic>g</italic>,3</sub>)} for <italic>g</italic> = 1, 2. This led to two sets of three Dice coefficients per mask. Second, we calculated the Dice coefficient of the masks across the different ground truths {<italic>dice</italic>(<italic>ŷ</italic><sub>1,<italic>i</italic></sub>, <italic>ŷ</italic><sub>2,<italic>j</italic></sub>)} for <italic>i,j</italic> = 1, 2, 3 to approximate inter-rater similarity, leading to nine Dice coefficients per mask.</p>
        </sec>
        <sec>
          <title>2.7.2.4. Training Set Size</title>
          <p>We optimized RatLesNetv2 with training sets of different sizes to understand the relation between training set size and generalization capability. The training sets had the same ratio of time-points, i.e., we enlarged the training sets by 1 sample per time-point. Since the lowest number of samples across time-points corresponds to 12 (2 h lesions) and we want to keep at least 1 image per time-point in the test set, we produced 11 training sets <italic>T</italic><sub><italic>i</italic></sub> of size |<italic>T</italic><sub><italic>i</italic></sub>| = 8<italic>i</italic> for <italic>i</italic> = 1, …, 11, where 8 is the number of lesion stages.</p>
        </sec>
      </sec>
      <sec>
        <title>2.7.3. Implementation</title>
        <p>RatLesNetv2 was implemented in Pytorch (Paszke et al., <xref rid="B30" ref-type="bibr">2019</xref>) and it was run on Ubuntu 16.04 with an Intel Xeon W-2125 CPU @ 4.00 GHz processor, 64 GB of memory and an NVidia GeForce GTX 1080 Ti with 11 GB of memory. RatLesNetv2 is publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/jmlipman/RatLesNetv2">https://github.com/jmlipman/RatLesNetv2</ext-link>.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results" id="s3">
    <title>3. Results</title>
    <sec>
      <title>3.1. Performance of RatLesNetv2</title>
      <p><xref rid="T2" ref-type="table">Table 2</xref> lists the quantitative validation results on the test set excluding sham-operated animals that typically yield Dice coefficients of 1.0. As can be seen in <xref rid="T2" ref-type="table">Table 2</xref>, RatLesNetv2 produced similar or better Dice coefficients and Hausdorff distances, and more compact segmentations than the other ConvNets. The average Dice coefficients varied from 0.784 (homogeneous division) to 0.813 (heterogeneous division). Dice coefficients had a large standard deviation regardless of the architecture (from 0.15 to 0.20). However, note that the sample-wise difference between the Dice coefficients of RatLesNetv2 and VoxResNet had a smaller standard deviation of 0.05, i.e., the Dice values between different networks were correlated. <xref rid="T2" ref-type="table">Table 2</xref> shows that RatLesNetv2 achieved significantly better compactness values (all <italic>p</italic>-values &lt; 0.011) than 3D U-Net, VoxResNet and RatLesNet. Remarkably, 3D U-Net and VoxResNet produced masks with non-smooth borders and several more holes and islands, leading to less compact segmentations (see <xref ref-type="fig" rid="F3">Figure 3</xref> and Figures in the <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref>). The average compactness values of RatLesNetv2 were higher than the ground truth (20.98 ± 3.28, <italic>p</italic> = 0.003); this was expected as human annotators are likely to produce segmentations with excessively rounded boundaries.</p>
      <table-wrap id="T2" position="float">
        <label>Table 2</label>
        <caption>
          <p>Performance evaluation on the test set before and after post-processing.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Model</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Dice (no shams)</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Compactness</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>HD</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RatLesNetv2-post</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.784</bold>
                <bold>±</bold>
                <bold>0.18</bold>
                <sup>*<italic>a</italic></sup>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>29.332</bold>
                <bold>±</bold>
                <bold>7.86</bold>
                <sup>*<italic>b</italic></sup>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.522 ± 3.64</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RatLesNetv2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.784 ± 0.18</td>
              <td valign="top" align="center" rowspan="1" colspan="1">29.609 ± 8.12</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.687 ± 3.30</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">3D U-Net-post</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.769 ± 0.20</td>
              <td valign="top" align="center" rowspan="1" colspan="1">36.741 ± 11.41</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.665 ± 3.81</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">3D U-Net</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.768 ± 0.20</td>
              <td valign="top" align="center" rowspan="1" colspan="1">37.599 ± 11.77</td>
              <td valign="top" align="center" rowspan="1" colspan="1">4.097 ± 3.69</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">VoxResNet-post</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.757 ± 0.19</td>
              <td valign="top" align="center" rowspan="1" colspan="1">37.096 ± 13.00</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.692 ± 3.46</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">VoxResNet</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.757 ± 0.19</td>
              <td valign="top" align="center" rowspan="1" colspan="1">38.161 ± 13.62</td>
              <td valign="top" align="center" rowspan="1" colspan="1">4.943 ± 3.38</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RatLesNet-post</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.742 ± 0.18</td>
              <td valign="top" align="center" rowspan="1" colspan="1">35.045 ± 10.71</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.892 ± 2.54</td>
            </tr>
            <tr style="border-bottom: thin solid #000000;">
              <td valign="top" align="left" rowspan="1" colspan="1">RatLesNet</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.741 ± 0.18</td>
              <td valign="top" align="center" rowspan="1" colspan="1">35.888 ± 10.76</td>
              <td valign="top" align="center" rowspan="1" colspan="1">4.679 ± 2.55</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RatLesNetv2-post</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.813 ± 0.16</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>23.105</bold>
                <bold>±</bold>
                <bold>4.58</bold>
                <sup>*<italic>c</italic></sup>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.334 ± 3.34</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RatLesNetv2</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.813 ± 0.16</td>
              <td valign="top" align="center" rowspan="1" colspan="1">23.177 ± 4.64</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.512 ± 3.31</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">3D U-Net-post</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.813 ± 0.15</td>
              <td valign="top" align="center" rowspan="1" colspan="1">28.247 ± 5.92</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.099 ± 2.47</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">3D U-Net</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.812 ± 0.15</td>
              <td valign="top" align="center" rowspan="1" colspan="1">28.639 ± 5.99</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.221 ± 2.47</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">VoxResNet-post</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.806 ± 0.14</td>
              <td valign="top" align="center" rowspan="1" colspan="1">32.937 ± 10.05</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.585 ± 3.27</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">VoxResNet</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.805 ± 0.14</td>
              <td valign="top" align="center" rowspan="1" colspan="1">33.634 ± 10.53</td>
              <td valign="top" align="center" rowspan="1" colspan="1">4.535 ± 3.46</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RatLesNet-post</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.764 ± 0.15</td>
              <td valign="top" align="center" rowspan="1" colspan="1">31.348 ± 9.66</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.218 ± 2.79</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">RatLesNet</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.764 ± 0.15</td>
              <td valign="top" align="center" rowspan="1" colspan="1">31.669 ± 9.86</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.384 ± 2.56</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p><italic>Average Dice coefficients were reported in images of animals with lesions. Top: Homogeneous division. Bottom: Heterogeneous division. Bold: Values significantly better than the other architectures (<sup>*a</sup>p = 0.007, <sup>*b</sup>p = 0.011,<sup>*c</sup>p = 0.005)</italic>.</p>
        </table-wrap-foot>
      </table-wrap>
      <fig id="F3" position="float">
        <label>Figure 3</label>
        <caption>
          <p>Comparison of the segmentation masks of four consecutive slices. The depicted T2-weighted image corresponds to a typical scan, i.e., the volume whose segmentation achieved the median Dice coefficient in the test set (heterogeneous division). Segmentations were not post-processed.</p>
        </caption>
        <graphic xlink:href="fnins-14-610239-g0003"/>
      </fig>
      <p>Post-processing had little to no effect on the average Dice coefficients, but it enhanced the final segmentation quality as it removed spurious clusters of voxels. This improvement was reflected in the reduction of compactness values and the considerable decrease of Hausdorff distances. Remarkably, the difference in the Hausdorff distances before and after post-processing was more pronounced in 3D U-Net, VoxResNet and RatLesNet.</p>
      <p><xref rid="T3" ref-type="table">Table 3</xref> lists the quantitative results by lesion stage to understand the performance of RatLesNetv2 in detail. Training RatLesNetv2 on the homogeneous data division, whose training set included almost twice as many 24 h lesion scans as the heterogeneous division (9 scans vs. 5 scans), led to a slight increase in the average Dice coefficient and Hausdorff distance in 24 h lesion scans. However, there was no significant difference between either the Dice coefficients (<italic>p</italic>= 0.057) nor Hausdorff distances (<italic>p</italic>= 0.08) of the segmentations derived in the two cases. Dice coefficients, compactness values and Hausdorff distances of the segmentations produced after training on the homogeneous division deteriorated as the time-point was farther from 2 and 24 h.</p>
      <table-wrap id="T3" position="float">
        <label>Table 3</label>
        <caption>
          <p>Performance evaluation on the test set after post-processing segregated by lesion stage.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Time-point (scans)</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Dice</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Compactness</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>HD</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">24 h (394)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.831 ± 0.15</td>
              <td valign="top" align="center" rowspan="1" colspan="1">26.539 ± 4.86</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.691 ± 3.53</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">D3 (135)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.782 ± 0.12</td>
              <td valign="top" align="center" rowspan="1" colspan="1">29.705 ± 8.01</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.067 ± 2.31</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">D7 (53)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.790 ± 0.11</td>
              <td valign="top" align="center" rowspan="1" colspan="1">40.742 ± 10.65</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2.580 ± 2.63</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">D14 (30)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.735 ± 0.21</td>
              <td valign="top" align="center" rowspan="1" colspan="1">36.018 ± 11.07</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.329 ± 5.06</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">D21 (40)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.800 ± 0.11</td>
              <td valign="top" align="center" rowspan="1" colspan="1">33.797 ± 6.50</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2.546 ± 0.92</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">D28 (89)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.593 ± 0.28</td>
              <td valign="top" align="center" rowspan="1" colspan="1">29.598 ± 7.46</td>
              <td valign="top" align="center" rowspan="1" colspan="1">4.238 ± 5.22</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">D35 (20)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.751 ± 0.23</td>
              <td valign="top" align="center" rowspan="1" colspan="1">31.203 ± 4.72</td>
              <td valign="top" align="center" rowspan="1" colspan="1">4.831 ± 5.76</td>
            </tr>
            <tr style="border-bottom: thin solid #000000;">
              <td valign="top" align="left" rowspan="1" colspan="1">Shams (107)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1.000 ± 0.00</td>
              <td valign="top" align="center" rowspan="1" colspan="1">—</td>
              <td valign="top" align="center" rowspan="1" colspan="1">—</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">2 h (6)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.719 ± 0.11</td>
              <td valign="top" align="center" rowspan="1" colspan="1">23.111 ± 2.27</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1.920 ± 0.16</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">24 h (400)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.826 ± 0.15</td>
              <td valign="top" align="center" rowspan="1" colspan="1">23.218 ± 4.67</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.919 ± 3.79</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">D3 (129)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.809 ± 0.10</td>
              <td valign="top" align="center" rowspan="1" colspan="1">23.376 ± 5.15</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2.796 ± 2.24</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">D7 (47)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.860 ± 0.09</td>
              <td valign="top" align="center" rowspan="1" colspan="1">23.555 ± 3.99</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2.439 ± 2.83</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">D14 (24)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.827 ± 0.19</td>
              <td valign="top" align="center" rowspan="1" colspan="1">21.705 ± 3.36</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.015 ± 5.69</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">D21 (34)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.877 ± 0.10</td>
              <td valign="top" align="center" rowspan="1" colspan="1">23.874 ± 2.38</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2.002 ± 0.70</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">D28 (83)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.692 ± 0.25</td>
              <td valign="top" align="center" rowspan="1" colspan="1">22.147 ± 4.65</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2.875 ± 1.93</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">D35 (14)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.886 ± 0.07</td>
              <td valign="top" align="center" rowspan="1" colspan="1">22.037 ± 2.55</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1.700 ± 0.67</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Shams (131)</td>
              <td valign="top" align="center" rowspan="1" colspan="1">1.000 ± 0.00</td>
              <td valign="top" align="center" rowspan="1" colspan="1">—</td>
              <td valign="top" align="center" rowspan="1" colspan="1">—</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p><italic>Top: Homogeneous division. Bottom: Heterogeneous division</italic>.</p>
        </table-wrap-foot>
      </table-wrap>
      <p>Training on the heterogeneous training set notably improved the average Dice coefficients and compactness values of every model (<xref rid="T2" ref-type="table">Table 2</xref>) and every time-point (<xref rid="T3" ref-type="table">Table 3</xref>) with respect to homogeneous division, except on 24 h lesions. Furthermore, it decreased the standard deviation of the Dice coefficients and compactness values. RatLesNetv2 recognized animals without lesions notably well even if they were not part of the training set, providing average Dice coefficients of 1.0 on sham-operated animals even without post-processing. Additionally, Dice coefficients on 2 h lesions, 24 h lesions, and overall were higher than inter-rater agreement.</p>
      <p>Ensembling three ConvNets of the same architecture optimized on the same training set led to significantly better performance scores in all cases (all <italic>p</italic>-values &lt; 0.007) as it discarded small segmentation inconsistencies. This strategy increased Dice coefficients by an average of 2% and decreased compactness and Hausdorff distances by an average of 5 and 23% with respect to the first run. The Dice coefficients, compactness values and Hausdorff distances from the individual images used for calculating the reported statistics are also included in the <xref ref-type="supplementary-material" rid="SM1">Supplementary Materials</xref> as CSV files.</p>
    </sec>
    <sec>
      <title>3.2. Ablation Studies</title>
      <p>The performance scores of RatLesNetv2 after modifying its architecture during the ablation studies are reported in <xref rid="T4" ref-type="table">Table 4</xref>.</p>
      <table-wrap id="T4" position="float">
        <label>Table 4</label>
        <caption>
          <p>Ablation study.</p>
        </caption>
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th valign="top" align="left" rowspan="1" colspan="1">
                <bold>Study</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Dice (no shams)</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>Compactness</bold>
              </th>
              <th valign="top" align="center" rowspan="1" colspan="1">
                <bold>HD</bold>
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Baseline</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.784 ± 0.18</td>
              <td valign="top" align="center" rowspan="1" colspan="1">29.332 ± 7.86</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.522 ± 3.64</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">DenseNetBlock<xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref></td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.771</bold>
                <bold>±</bold>
                <bold>0.20</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>30.094</bold>
                <bold>±</bold>
                <bold>8.86</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.692 ± 3.96</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Halving RF</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.754</bold>
                <bold>±</bold>
                <bold>0.20</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">30.766 ± 10.57</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.340 ± 3.91</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Halving RF<xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref></td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.765</bold>
                <bold>±</bold>
                <bold>0.19</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>31.867</bold>
                <bold>±</bold>
                <bold>10.41</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.464 ± 3.53</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Width-28</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.781 ± 0.18</td>
              <td valign="top" align="center" rowspan="1" colspan="1">30.095 ± 8.42</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.423 ± 2.84</td>
            </tr>
            <tr style="border-bottom: thin solid #000000;">
              <td valign="top" align="left" rowspan="1" colspan="1">Width-36</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.765</bold>
                <bold>±</bold>
                <bold>0.19</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>31.620</bold>
                <bold>±</bold>
                <bold>10.09</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.557 ± 3.73</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Baseline</td>
              <td valign="top" align="center" rowspan="1" colspan="1">0.813 ± 0.16</td>
              <td valign="top" align="center" rowspan="1" colspan="1">23.105 ± 4.58</td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.334 ± 3.34</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">DenseNetBlock<xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref></td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.801</bold>
                <bold>±</bold>
                <bold>0.16</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>23.313</bold>
                <bold>±</bold>
                <bold>5.13</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">3.093 ± 2.70</td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Halving RF</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <italic>0.819 ± 0.15</italic>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>25.226</bold>
                <bold>±</bold>
                <bold>5.34</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>3.679</bold>
                <bold>±</bold>
                <bold>3.12</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Halving RF<xref ref-type="table-fn" rid="TN1"><sup>*</sup></xref></td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <italic>0.820 ± 0.15</italic>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>25.394</bold>
                <bold>±</bold>
                <bold>5.51</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>3.719</bold>
                <bold>±</bold>
                <bold>3.40</bold>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Width-28</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.803</bold>
                <bold>±</bold>
                <bold>0.17</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">22.861 ± 4.63</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <italic>2.892 ± 2.94</italic>
              </td>
            </tr>
            <tr>
              <td valign="top" align="left" rowspan="1" colspan="1">Width-36</td>
              <td valign="top" align="center" rowspan="1" colspan="1">
                <bold>0.801</bold>
                <bold>±</bold>
                <bold>0.16</bold>
              </td>
              <td valign="top" align="center" rowspan="1" colspan="1">24.036 ± 5.04</td>
              <td valign="top" align="center" rowspan="1" colspan="1">2.900 ± 2.84</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <p><italic>Top: Homogeneous task. Bottom: Heterogeneous task. Bold: baseline significantly better. Italic: baseline significantly worse (p-values &lt; 0.05)</italic>.</p>
          <fn id="TN1">
            <label>*</label>
            <p><italic>Equal number of parameters as Baseline</italic>.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <sec>
        <title>3.2.1. DenseNetBlock</title>
        <p>Similarly to RatLesNet (Valverde et al., <xref rid="B37" ref-type="bibr">2019</xref>), DenseNet-style (Huang et al., <xref rid="B17" ref-type="bibr">2017</xref>) blocks were implemented in RatLesNetv2 while keeping the same number of parameters of the baseline RatLesNetv2 model. Dice coefficients and compactness values were significantly deteriorated with respect to RatLesNetv2 baseline (all <italic>p</italic>-values &lt; 0.037), and Hausdorff distances increased slightly in homogeneous data division, whereas they decreased in heterogeneous division. Additionally, DenseNetBlocks demanded notably more memory due to the concatenation operation.</p>
      </sec>
      <sec>
        <title>3.2.2. Halving the Receptive Field (RF)</title>
        <p>The third downsampling stage of RatLesNetv2 was eliminated in order to reduce the receptive field from 72 voxels down to 36. An additional test (marked in <xref rid="T4" ref-type="table">Table 4</xref> with an <sup>*</sup>) matched the number of parameters to the baseline. The reduction of the receptive field yielded in significant improvements of the Dice coefficient and a significant deterioration of the compactness and Hausdorff distance in the heterogeneous division (all <italic>p</italic>-values &lt; 0.028). On the other hand, in the homogeneous division Dice coefficients and compactness values were worse than RatLesNetv2 baseline.</p>
      </sec>
      <sec>
        <title>3.2.3. Network Width</title>
        <p>We increased and decreased the number of filters of RatLesNetv2 by 4 (<xref rid="T4" ref-type="table">Table 4</xref>, Width-28 and Width-36). This modification decreased the Dice coefficients with respect to RatLesNetv2 and led to no significant difference in the Hausdorff distances. Compactness values showed contradictory results; they deteriorated in homogeneous division whereas they remained similar or slightly worse in heterogeneous division.</p>
      </sec>
    </sec>
    <sec>
      <title>3.3. On the Influence of Disparate Ground Truths</title>
      <p>As expected, optimizing separate RatLesNetv2 models with segmentations from different annotators produced more different segmentation masks than when optimizing with segmentations from the same annotator. In other words, the three sets of predictions <italic>ŷ</italic><sub>1,1</sub>, <italic>ŷ</italic><sub>1,2</sub>, <italic>ŷ</italic><sub>1,3</sub> were similar among themselves in the same manner as <italic>ŷ</italic><sub>2,1</sub>, <italic>ŷ</italic><sub>2,2</sub>, <italic>ŷ</italic><sub>2,3</sub> (<xref ref-type="fig" rid="F4">Figure 4B</xref>, Annotation 1 and 2), and their differences arise from the stochasticity of ConvNets optimization. In contrast, the shape of the distribution of the Dice coefficients that compare masks derived from RatLesNetv2 models optimized with different annotations (<xref ref-type="fig" rid="F4">Figure 4B</xref>, Mixed) was notably different. Also, Annotation 1 and Mixed Dice coefficients as well as Annotation 2 and Mixed Dice coefficients were significantly different (<italic>p</italic>-values &lt; 0.002).</p>
      <fig id="F4" position="float">
        <label>Figure 4</label>
        <caption>
          <p><bold>(A)</bold> (Top row): Scan with the most disparate annotations between operators 1 and 2. <bold>(A)</bold> (Bottom row): A randomly selected scan of the test set (left), segmentations of the scan with RatLesNetv2 trained on Annotator 1 ground truth (middle), and Annotator 2 ground truth (right). <bold>(B)</bold> Kernel density estimation of three sets of Dice coefficients. Red (dashed line) and blue (solid line) estimations were calculated between the predictions of the model optimized for the same ground truth. Green (thick solid line) estimation was computed between the predictions whose model was optimized for different ground truths. The predictions generated when the same model is optimized for different ground truths are notably different.</p>
        </caption>
        <graphic xlink:href="fnins-14-610239-g0004"/>
      </fig>
      <p>In a visual inspection, we observed that Annotation 2 was more approximate, with simpler contours, than Annotation 1. <xref ref-type="fig" rid="F4">Figure 4A</xref> (top row) shows the manual segmentations of the scan with the most disparate annotations and <xref ref-type="fig" rid="F4">Figure 4A</xref> (bottom row) shows the predictions on a scan with the highest Dice coefficient on our baseline study when RatLesNetv2 was trained on the different annotations.</p>
    </sec>
    <sec>
      <title>3.4. The Impact of the Training Set Size on the Performance</title>
      <p><xref ref-type="fig" rid="F5">Figure 5</xref> illustrates the evolution of the Dice coefficients, compactness values and Hausdorff distances as the training set increases in size. Dice coefficients (<xref ref-type="fig" rid="F5">Figure 5</xref>, left) were remarkably different across time-points and almost every time-point reached a performance plateau with large data sets. Time-points 24 h and D3—which composed the majority of the test set scans by 56.7 and 17.8% of the total, respectively—reached their plateaus later. This effect can be a consequence of the variability within samples. On the contrary, the time-points with the lowest number of samples (2 h and D35 lesions with 1 and 9 image, respectively) exhibited fluctuations.</p>
      <fig id="F5" position="float">
        <label>Figure 5</label>
        <caption>
          <p>RatLesNetv2 performance when optimizing for training sets of multiple sizes. Metrics (from left to right: Dice coefficient, compactness and Hausdorff distance) were processed from the masks derived with the majority voting across three runs on a fixed test set (828 images). Averages (dashed lines) were segregated by time-point. Compactness graph includes the average compactness of the ground truth (dotted line).</p>
        </caption>
        <graphic xlink:href="fnins-14-610239-g0005"/>
      </fig>
      <p>Compactness values (<xref ref-type="fig" rid="F5">Figure 5</xref>, center) and Hausdorff distances (<xref ref-type="fig" rid="F5">Figure 5</xref>, right) oscillated considerably regardless of the time-point. Hausdorff distances were higher in the time-points with the largest number of samples (24 h and D3), likely due to the existence of outliers. Compactness values, including the average (dashed line), increased analogously to the training set size, i.e., enlarging the training set yielded less compact segmentations. Yet, these compactness values were markedly lower than the compactness values derived from segmentations produced by 3D U-Net, VoxResNet, and RatLesNet (section 3.1).</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="s4">
    <title>4. Discussion</title>
    <p>We showed that RatLesNetv2 yielded similar or better Dice coefficients and Hausdorff distances, and notably more compact segmentations than other convolutional neural networks (Çiçek et al., <xref rid="B7" ref-type="bibr">2016</xref>; Chen et al., <xref rid="B3" ref-type="bibr">2018a</xref>; Valverde et al., <xref rid="B37" ref-type="bibr">2019</xref>). These measurements indicate that the segmentations derived from RatLesNetv2 were more similar to the ground truth, had less large segmentation errors and were more realistic. Additionally, the smaller differences between Hausdorff distances before and after post-processing derived from RatLesNetv2 also indicate that RatLesNetv2 produced fewer segmentation errors far from the lesion surface.</p>
    <p>RatLesNetv2 produced more compact segmentations than the other ConvNets without directly minimizing compactness (see <xref rid="T2" ref-type="table">Table 2</xref>), indicating that RatLesNetv2 architecture favors segmentations with smooth borders without holes. Although optimizing compactness (and Hausdorff distance) directly might further improve the results, incorporating these terms to the loss function leads to additional hyper-parameters that require costly tuning. Dice coefficients had large standard deviations and were lower than in existing human brain tumor segmentation studies (Jiang et al., <xref rid="B19" ref-type="bibr">2019</xref>; Myronenko and Hatamizadeh, <xref rid="B28" ref-type="bibr">2019</xref>). These results may arise due to the subjectivity of the segmentation task caused by low image contrast in certain lesions and its consequent high inter- and intra-rater disagreement. However, this is not unexpected as relatively low Dice coefficients and large standard deviations are typical in rodent (Mulder et al., <xref rid="B26" ref-type="bibr">2017a</xref>; Valverde et al., <xref rid="B37" ref-type="bibr">2019</xref>) and human brain lesion segmentation studies (Chen et al., <xref rid="B4" ref-type="bibr">2017</xref>; Valverde et al., <xref rid="B39" ref-type="bibr">2017</xref>; Subbanna et al., <xref rid="B35" ref-type="bibr">2019</xref>), even when studying inter-rater disagreement of manual annotations relying on a semi-automatic segmentation pipeline (Mulder et al., <xref rid="B26" ref-type="bibr">2017a</xref>). We also argued that Dice coefficient alone is not sufficient to measure the segmentation performance. To illustrate the importance of providing additional measurements, consider a brain with a very large and a very small lesion. If the segmentation accurately predicts the large lesion and ignores the small one, Dice coefficients will have a high value not reflecting the segmentation error, but Hausdorff distance is high capturing the segmentation error. Likewise, a lesion segmentation mask with non-smooth surface and several small holes and islands (i.e., a high compactness value) may have a high Dice coefficient despite being unrealistic.</p>
    <p>The difference in the performance between homogeneous and heterogeneous data set divisions indicates that although few 24 h lesion volumes were needed to generalize well, adding more 24 h lesion volumes to the training data (homogeneous division) made RatLesNetv2 specialize on that time-point (<xref rid="T3" ref-type="table">Table 3</xref>). On the other hand, increasing data diversity (heterogeneous division) improved performance, demonstrating that RatLesNetv2 is capable of learning from a heterogeneous data set. Thus, training on this heterogeneous division increased RatLesNetv2 capability to extrapolate to different-looking ischemic brain lesions. However, without optimizing on additional data, RatLesNetv2 performance on images with other types of lesions, such as tumor lesions, is limited by the lesions' appearance.</p>
    <p>The ablation experiments showed that modifications of RatLesNetv2 architecture yielded similar or worse performance, justifying RatLesNetv2's architectural choices. Despite both residual connections (He et al., <xref rid="B16" ref-type="bibr">2016</xref>) and DenseNetBlocks (Huang et al., <xref rid="B17" ref-type="bibr">2017</xref>) facilitate gradient propagation (Drozdzal et al., <xref rid="B11" ref-type="bibr">2016</xref>), residual connections were preferred over DenseNetBlocks due to their notably higher performance and lower memory requirements. Additionally, a large receptive field empirically demonstrated to increase compactness and reduce large segmentation errors possibly because RatLesNetv2 considers a larger context. The choice of a large receptive field is in agreement with other state-of-the-art ConvNets that achieve large receptive fields by stacking several convolutional layers and/or utilizing dilated convolutions (Chen et al., <xref rid="B5" ref-type="bibr">2018b</xref>).</p>
    <p>Our ground-truth disparity experiment confirmed that predictions generated when the same model is optimized for different ground truths are different. Consequently, the quality of the manually-annotated ground truth has a direct impact on the quality of the lesion masks generated automatically. As there is no unique definition of “lesion,” it may be advantageous for an algorithm to perform differently depending on the labels of the training set. On the other hand, it may also be desirable to design a robust algorithm that performs consistently regardless of some changes in the annotations.</p>
    <p>The experiment of training RatLesNetv2 on several training sets of different sizes showed that even with few available training data RatLesNetv2 can generalize well and, despite increasing its performance when optimizing on larger training sets, such improvement is small and compactness values and Hausdorff distances fluctuate considerably.</p>
  </sec>
  <sec sec-type="conclusions" id="s5">
    <title>5. Conclusion</title>
    <p>We presented and made publicly available RatLesNetv2, a 3D ConvNet to segment rodent brain lesions. RatLesNetv2 has been evaluated on an exceptionally large and diverse data set of 916 rat brain MR images, validating RatLesNetv2 reliability on a wide variety of lesion stages with lesions of different appearance. Additionally, RatLesNetv2 produced segmentations that exceeded overall inter-rater agreement Dice coefficients (inter-rater: 0.73 ± 0.12, RatLesNetv2: 0.81 ± 0.16). This enhancement indicates that RatLesNetv2 produces segmentations that are remarkably more consistent with the ground truth than the similarity between different human-made annotations. This consistency is of special importance for research reproducibility, crucial in preclinical studies.</p>
    <p>Based on our experiments and, more specifically, the accuracy greater than inter-rater agreement and than of other ConvNets, RatLesNetv2 can be used to automate lesion segmentation in preclinical MRI studies on rats.</p>
  </sec>
  <sec sec-type="data-availability" id="s6">
    <title>Data Availability Statement</title>
    <p>The data analyzed in this study is subject to the following licenses/restrictions: the software and the trained models are publicly available from <ext-link ext-link-type="uri" xlink:href="https://github.com/jmlipman/RatLesNetv2">https://github.com/jmlipman/RatLesNetv2</ext-link>. All the quantitative segmentation measures are <xref ref-type="supplementary-material" rid="SM1">Supplementary Material</xref> of this manuscript. The MR image dataset cannot be shared due to ownership and intellectual property restrictions.</p>
  </sec>
  <sec id="s7">
    <title>Ethics Statement</title>
    <p>The animal study was reviewed and approved by National Animal Experiment Board, Finland.</p>
  </sec>
  <sec id="s8">
    <title>Author Contributions</title>
    <p>JV and JT designed the study and analyzed the data. JV conceptualized the algorithm design, developed RatLesNetv2, and wrote the draft. JV, RD, and JT developed the methodology. ASh collected the data. ASh, OG, and ASi interpreted the data. All authors contributed to manuscript revision, proofreading, and approved the submitted version.</p>
  </sec>
  <sec sec-type="COI-statement" id="conf1">
    <title>Conflict of Interest</title>
    <p>As disclosed in the affiliation section, ASh is a full-time payroll employee of the Charles River Discovery Services, Finland—a commercial pre-clinical contract research organization (CRO), which participated in the project and provided raw data as a part of company's R&amp;D initiative. The remaining authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
  </sec>
</body>
<back>
  <ack>
    <p>Part of the computational analysis was run on the servers provided by Bioinformatics Center, University of Eastern Finland, Finland. This manuscript has been released as a pre-print at arXiv (Valverde et al., <xref rid="B38" ref-type="bibr">2020</xref>).</p>
  </ack>
  <fn-group>
    <fn id="fn0001">
      <p>
        <sup>1</sup>
        <ext-link ext-link-type="uri" xlink:href="https://www.criver.com/products-services/discovery-services">https://www.criver.com/products-services/discovery-services</ext-link>
      </p>
    </fn>
  </fn-group>
  <fn-group>
    <fn fn-type="financial-disclosure">
      <p><bold>Funding.</bold> The work of JV was funded from the European Union's Horizon 2020 Framework Programme [Marie Skłodowska Curie grant agreement #740264 (GENOMMED)] and RD's work was funded from Marie Skłodowska Curie grant agreement #691110 (MICROBRADAM). We also acknowledge the Academy of Finland grants (#275453 to ASi and #316258 to JT).</p>
    </fn>
  </fn-group>
  <sec sec-type="supplementary-material" id="s9">
    <title>Supplementary Material</title>
    <p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fnins.2020.610239/full#supplementary-material">https://www.frontiersin.org/articles/10.3389/fnins.2020.610239/full#supplementary-material</ext-link></p>
    <supplementary-material content-type="local-data" id="SM1">
      <media xlink:href="Data_Sheet_1.ZIP">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="SM2">
      <media xlink:href="Image_1.PNG">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="SM3">
      <media xlink:href="Image_2.PNG">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="SM4">
      <media xlink:href="Image_3.PNG">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
  <ref-list>
    <title>References</title>
    <ref id="B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arnaud</surname><given-names>A.</given-names></name><name><surname>Forbes</surname><given-names>F.</given-names></name><name><surname>Coquery</surname><given-names>N.</given-names></name><name><surname>Collomb</surname><given-names>N.</given-names></name><name><surname>Lemasson</surname><given-names>B.</given-names></name><name><surname>Barbier</surname><given-names>E. L.</given-names></name></person-group> (<year>2018</year>). <article-title>Fully automatic lesion localization and characterization: application to brain tumors using multiparametric quantitative mri data</article-title>. <source>IEEE Trans. Med. Imaging</source>
<volume>37</volume>, <fpage>1678</fpage>–<lpage>1689</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2018.2794918</pub-id><?supplied-pmid 29969418?><pub-id pub-id-type="pmid">29969418</pub-id></mixed-citation>
    </ref>
    <ref id="B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bribiesca</surname><given-names>E.</given-names></name></person-group> (<year>2008</year>). <article-title>An easy measure of compactness for 2D and 3D shapes</article-title>. <source>Pattern Recogn</source>. <volume>41</volume>, <fpage>543</fpage>–<lpage>554</lpage>. <pub-id pub-id-type="doi">10.1016/j.patcog.2007.06.029</pub-id></mixed-citation>
    </ref>
    <ref id="B3">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>H.</given-names></name><name><surname>Dou</surname><given-names>Q.</given-names></name><name><surname>Yu</surname><given-names>L.</given-names></name><name><surname>Qin</surname><given-names>J.</given-names></name><name><surname>Heng</surname><given-names>P.-A.</given-names></name></person-group> (<year>2018a</year>). <article-title>Voxresnet: deep voxelwise residual networks for brain segmentation from 3D MR images</article-title>. <source>Neuroimage</source>
<volume>170</volume>, <fpage>446</fpage>–<lpage>455</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.04.041</pub-id><?supplied-pmid 28445774?><pub-id pub-id-type="pmid">28445774</pub-id></mixed-citation>
    </ref>
    <ref id="B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>L.</given-names></name><name><surname>Bentley</surname><given-names>P.</given-names></name><name><surname>Rueckert</surname><given-names>D.</given-names></name></person-group> (<year>2017</year>). <article-title>Fully automatic acute ischemic lesion segmentation in DWI using convolutional neural networks</article-title>. <source>Neuroimage Clin</source>. <volume>15</volume>, <fpage>633</fpage>–<lpage>643</lpage>. <pub-id pub-id-type="doi">10.1016/j.nicl.2017.06.016</pub-id><?supplied-pmid 28664034?><pub-id pub-id-type="pmid">28664034</pub-id></mixed-citation>
    </ref>
    <ref id="B5">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>L.-C.</given-names></name><name><surname>Zhu</surname><given-names>Y.</given-names></name><name><surname>Papandreou</surname><given-names>G.</given-names></name><name><surname>Schroff</surname><given-names>F.</given-names></name><name><surname>Adam</surname><given-names>H.</given-names></name></person-group> (<year>2018b</year>). <article-title>“Encoder-decoder with atrous separable convolution for semantic image segmentation,”</article-title> in <source>Proceedings of the European Conference on Computer Vision (ECCV)</source> (<publisher-loc>Munich</publisher-loc>), <fpage>801</fpage>–<lpage>818</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-01234-2_49</pub-id></mixed-citation>
    </ref>
    <ref id="B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Choi</surname><given-names>C.-H.</given-names></name><name><surname>Yi</surname><given-names>K. S.</given-names></name><name><surname>Lee</surname><given-names>S.-R.</given-names></name><name><surname>Lee</surname><given-names>Y.</given-names></name><name><surname>Jeon</surname><given-names>C.-Y.</given-names></name><name><surname>Hwang</surname><given-names>J.</given-names></name><etal/></person-group>. (<year>2018</year>). <article-title>A novel voxel-wise lesion segmentation technique on 3.0-T diffusion MRI of hyperacute focal cerebral ischemia at 1 h after permanent MCAO in rats</article-title>. <source>J. Cereb. Blood Flow Metab</source>. <volume>38</volume>, <fpage>1371</fpage>–<lpage>1383</lpage>. <pub-id pub-id-type="doi">10.1177/0271678X17714179</pub-id><?supplied-pmid 28598225?><pub-id pub-id-type="pmid">28598225</pub-id></mixed-citation>
    </ref>
    <ref id="B7">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Çiçek</surname><given-names>Ö.</given-names></name><name><surname>Abdulkadir</surname><given-names>A.</given-names></name><name><surname>Lienkamp</surname><given-names>S. S.</given-names></name><name><surname>Brox</surname><given-names>T.</given-names></name><name><surname>Ronneberger</surname><given-names>O.</given-names></name></person-group> (<year>2016</year>). <article-title>“3D U-net: learning dense volumetric segmentation from sparse annotation,”</article-title> in <source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source> (<publisher-loc>Athens</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>424</fpage>–<lpage>432</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-319-46723-8_49</pub-id></mixed-citation>
    </ref>
    <ref id="B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Feo</surname><given-names>R.</given-names></name><name><surname>Giove</surname><given-names>F.</given-names></name></person-group> (<year>2019</year>). <article-title>Towards an efficient segmentation of small rodents brain: a short critical review</article-title>. <source>J. Neurosci. Methods</source>
<volume>323</volume>, <fpage>82</fpage>–<lpage>89</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2019.05.003</pub-id><?supplied-pmid 31102669?><pub-id pub-id-type="pmid">31102669</pub-id></mixed-citation>
    </ref>
    <ref id="B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dice</surname><given-names>L. R.</given-names></name></person-group> (<year>1945</year>). <article-title>Measures of the amount of ecologic association between species</article-title>. <source>Ecology</source>
<volume>26</volume>, <fpage>297</fpage>–<lpage>302</lpage>. <pub-id pub-id-type="doi">10.2307/1932409</pub-id></mixed-citation>
    </ref>
    <ref id="B10">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dietterich</surname><given-names>T. G.</given-names></name></person-group> (<year>2000</year>). <article-title>“Ensemble methods in machine learning,”</article-title> in <source>International Workshop on Multiple Classifier Systems</source> (<publisher-loc>Cagliari</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>1</fpage>–<lpage>15</lpage>. <pub-id pub-id-type="doi">10.1007/3-540-45014-9_1</pub-id></mixed-citation>
    </ref>
    <ref id="B11">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Drozdzal</surname><given-names>M.</given-names></name><name><surname>Vorontsov</surname><given-names>E.</given-names></name><name><surname>Chartrand</surname><given-names>G.</given-names></name><name><surname>Kadoury</surname><given-names>S.</given-names></name><name><surname>Pal</surname><given-names>C.</given-names></name></person-group> (<year>2016</year>). <article-title>“The importance of skip connections in biomedical image segmentation,”</article-title> in <source>Deep Learning and Data Labeling for Medical Applications</source>, eds G. Carneiro, D. Mateus, P. Loïc, A. Bradley, J. M. R. S. Tavares, V. Belagiannis, J. P. Papa, J. C. Nascimento, M. Loog, Z. Lu, J. S. Cardoso, and J. Cornebise (<publisher-loc>Athens</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>179</fpage>–<lpage>187</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-319-46976-8_19</pub-id></mixed-citation>
    </ref>
    <ref id="B12">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duong</surname><given-names>M. T.</given-names></name><name><surname>Rudie</surname><given-names>J. D.</given-names></name><name><surname>Wang</surname><given-names>J.</given-names></name><name><surname>Xie</surname><given-names>L.</given-names></name><name><surname>Mohan</surname><given-names>S.</given-names></name><name><surname>Gee</surname><given-names>J. C.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Convolutional neural network for automated flair lesion segmentation on clinical brain mr imaging</article-title>. <source>Am. J. Neuroradiol</source>. <volume>40</volume>, <fpage>1282</fpage>–<lpage>1290</lpage>. <pub-id pub-id-type="doi">10.3174/ajnr.A6138</pub-id><?supplied-pmid 31345943?><pub-id pub-id-type="pmid">31345943</pub-id></mixed-citation>
    </ref>
    <ref id="B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dutta</surname><given-names>S.</given-names></name><name><surname>Sengupta</surname><given-names>P.</given-names></name></person-group> (<year>2016</year>). <article-title>Men and mice: relating their ages</article-title>. <source>Life Sci</source>. <volume>152</volume>, <fpage>244</fpage>–<lpage>248</lpage>. <pub-id pub-id-type="doi">10.1016/j.lfs.2015.10.025</pub-id><?supplied-pmid 26596563?><pub-id pub-id-type="pmid">26596563</pub-id></mixed-citation>
    </ref>
    <ref id="B14">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fenster</surname><given-names>A.</given-names></name><name><surname>Chiu</surname><given-names>B.</given-names></name></person-group> (<year>2005</year>). <article-title>“Evaluation of segmentation algorithms for medical imaging,”</article-title> in <source>2005 IEEE Engineering in Medicine and Biology 27th Annual Conference</source> (<publisher-loc>Shanghai</publisher-loc>), <fpage>7186</fpage>–<lpage>7189</lpage>. <pub-id pub-id-type="doi">10.1109/IEMBS.2005.1616166</pub-id></mixed-citation>
    </ref>
    <ref id="B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gabr</surname><given-names>R. E.</given-names></name><name><surname>Coronado</surname><given-names>I.</given-names></name><name><surname>Robinson</surname><given-names>M.</given-names></name><name><surname>Sujit</surname><given-names>S. J.</given-names></name><name><surname>Datta</surname><given-names>S.</given-names></name><name><surname>Sun</surname><given-names>X.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Brain and lesion segmentation in multiple sclerosis using fully convolutional neural networks: a large-scale study</article-title>. <source>Mult. Scler. J</source>. <volume>26</volume>, <fpage>1217</fpage>–<lpage>1226</lpage>. <pub-id pub-id-type="doi">10.1177/1352458519856843</pub-id><?supplied-pmid 31190607?><pub-id pub-id-type="pmid">31190607</pub-id></mixed-citation>
    </ref>
    <ref id="B16">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>He</surname><given-names>K.</given-names></name><name><surname>Zhang</surname><given-names>X.</given-names></name><name><surname>Ren</surname><given-names>S.</given-names></name><name><surname>Sun</surname><given-names>J.</given-names></name></person-group> (<year>2016</year>). <article-title>“Deep residual learning for image recognition,”</article-title> in <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source> (<publisher-loc>Las Vegas, NV</publisher-loc>), <fpage>770</fpage>–<lpage>778</lpage>. <pub-id pub-id-type="doi">10.1109/CVPR.2016.90</pub-id></mixed-citation>
    </ref>
    <ref id="B17">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>G.</given-names></name><name><surname>Liu</surname><given-names>Z.</given-names></name><name><surname>Van Der Maaten</surname><given-names>L.</given-names></name><name><surname>Weinberger</surname><given-names>K. Q.</given-names></name></person-group> (<year>2017</year>). <article-title>“Densely connected convolutional networks,”</article-title> in <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source> (<publisher-loc>Honolulu, HI</publisher-loc>), <fpage>4700</fpage>–<lpage>4708</lpage>. <pub-id pub-id-type="doi">10.1109/CVPR.2017.243</pub-id></mixed-citation>
    </ref>
    <ref id="B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ioffe</surname><given-names>S.</given-names></name><name><surname>Szegedy</surname><given-names>C.</given-names></name></person-group> (<year>2015</year>). <article-title>Batch normalization: accelerating deep network training by reducing internal covariate shift</article-title>. <source>arXiv</source> 1502.03167.</mixed-citation>
    </ref>
    <ref id="B19">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>Z.</given-names></name><name><surname>Ding</surname><given-names>C.</given-names></name><name><surname>Liu</surname><given-names>M.</given-names></name><name><surname>Tao</surname><given-names>D.</given-names></name></person-group> (<year>2019</year>). <article-title>“Two-stage cascaded U-net: 1st place solution to brats challenge 2019 segmentation task,”</article-title> in <source>International MICCAI Brainlesion Workshop</source> (<publisher-loc>Shenzhen</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>231</fpage>–<lpage>241</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-46640-4_22</pub-id></mixed-citation>
    </ref>
    <ref id="B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>D. P.</given-names></name><name><surname>Ba</surname><given-names>J.</given-names></name></person-group> (<year>2014</year>). <article-title>Adam: a method for stochastic optimization</article-title>. <source>CoRR</source> abs/1412.6980.</mixed-citation>
    </ref>
    <ref id="B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koizumi</surname><given-names>J.</given-names></name><name><surname>Yoshida</surname><given-names>Y.</given-names></name><name><surname>Nakazawa</surname><given-names>T.</given-names></name><name><surname>Ooneda</surname><given-names>G.</given-names></name></person-group> (<year>1986</year>). <article-title>Experimental studies of ischemic brain edema. 1. A new experimental model of cerebral embolism in rats in which recirculation can be introduced in the ischemic area</article-title>. <source>Jpn. J. Stroke</source>
<volume>8</volume>, <fpage>1</fpage>–<lpage>8</lpage>. <pub-id pub-id-type="doi">10.3995/jstroke.8.1</pub-id></mixed-citation>
    </ref>
    <ref id="B22">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H.</given-names></name><name><surname>Xu</surname><given-names>Z.</given-names></name><name><surname>Taylor</surname><given-names>G.</given-names></name><name><surname>Studer</surname><given-names>C.</given-names></name><name><surname>Goldstein</surname><given-names>T.</given-names></name></person-group> (<year>2018</year>). <article-title>“Visualizing the loss landscape of neural nets,”</article-title> in <source>Advances in Neural Information Processing Systems</source>, eds S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (<publisher-loc>Montreal, QC</publisher-loc>), <fpage>6389</fpage>–<lpage>6399</lpage>.</mixed-citation>
    </ref>
    <ref id="B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyes</surname><given-names>R.</given-names></name><name><surname>Lu</surname><given-names>M.</given-names></name><name><surname>de Puiseau</surname><given-names>C. W.</given-names></name><name><surname>Meisen</surname><given-names>T.</given-names></name></person-group> (<year>2019</year>). <article-title>Ablation studies in artificial neural networks</article-title>. <source>arXiv</source> abs/1901.08644.</mixed-citation>
    </ref>
    <ref id="B24">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Milletari</surname><given-names>F.</given-names></name><name><surname>Navab</surname><given-names>N.</given-names></name><name><surname>Ahmadi</surname><given-names>S.-A.</given-names></name></person-group> (<year>2016</year>). <article-title>“V-net: fully convolutional neural networks for volumetric medical image segmentation,”</article-title> in <source>2016 Fourth International Conference on 3D Vision (3DV)</source> (<publisher-loc>Stanford, CA</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>565</fpage>–<lpage>571</lpage>. <pub-id pub-id-type="doi">10.1109/3DV.2016.79</pub-id></mixed-citation>
    </ref>
    <ref id="B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moraga</surname><given-names>A.</given-names></name><name><surname>Gómez-Vallejo</surname><given-names>V.</given-names></name><name><surname>Cuartero</surname><given-names>M. I.</given-names></name><name><surname>Szczupak</surname><given-names>B.</given-names></name><name><surname>San Sebastián</surname><given-names>E.</given-names></name><name><surname>Markuerkiaga</surname><given-names>I.</given-names></name><etal/></person-group>. (<year>2016</year>). <article-title>Imaging the role of toll-like receptor 4 on cell proliferation and inflammation after cerebral ischemia by positron emission tomography</article-title>. <source>J. Cereb. Blood Flow Metab</source>. <volume>36</volume>, <fpage>702</fpage>–<lpage>708</lpage>. <pub-id pub-id-type="doi">10.1177/0271678X15627657</pub-id><?supplied-pmid 26787106?><pub-id pub-id-type="pmid">26787106</pub-id></mixed-citation>
    </ref>
    <ref id="B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mulder</surname><given-names>I. A.</given-names></name><name><surname>Khmelinskii</surname><given-names>A.</given-names></name><name><surname>Dzyubachyk</surname><given-names>O.</given-names></name><name><surname>de Jong</surname><given-names>S.</given-names></name><name><surname>Rieff</surname><given-names>N.</given-names></name><name><surname>Wermer</surname><given-names>M. J.</given-names></name><etal/></person-group>. (<year>2017a</year>). <article-title>Automated ischemic lesion segmentation in mri mouse brain data after transient middle cerebral artery occlusion</article-title>. <source>Front. Neuroinform</source>. <volume>11</volume>:<fpage>3</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2017.00003</pub-id><?supplied-pmid 28197090?><pub-id pub-id-type="pmid">28197090</pub-id></mixed-citation>
    </ref>
    <ref id="B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mulder</surname><given-names>I. A.</given-names></name><name><surname>Khmelinskii</surname><given-names>A.</given-names></name><name><surname>Dzyubachyk</surname><given-names>O.</given-names></name><name><surname>De Jong</surname><given-names>S.</given-names></name><name><surname>Wermer</surname><given-names>M. J.</given-names></name><name><surname>Hoehn</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2017b</year>). <article-title>MRI mouse brain data of ischemic lesion after transient middle cerebral artery occlusion</article-title>. <source>Front. Neuroinform</source>. <volume>11</volume>:<fpage>51</fpage>
<pub-id pub-id-type="doi">10.3389/fninf.2017.00051</pub-id><pub-id pub-id-type="pmid">28932191</pub-id></mixed-citation>
    </ref>
    <ref id="B28">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Myronenko</surname><given-names>A.</given-names></name><name><surname>Hatamizadeh</surname><given-names>A.</given-names></name></person-group> (<year>2019</year>). <article-title>“Robust semantic segmentation of brain tumor regions from 3D MRIs,”</article-title> in <source>International MICCAI Brainlesion Workshop</source> (<publisher-loc>Shenzhen</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>82</fpage>–<lpage>89</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-46643-5_8</pub-id></mixed-citation>
    </ref>
    <ref id="B29">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Noh</surname><given-names>H.</given-names></name><name><surname>Hong</surname><given-names>S.</given-names></name><name><surname>Han</surname><given-names>B.</given-names></name></person-group> (<year>2015</year>). <article-title>“Learning deconvolution network for semantic segmentation,”</article-title> in <source>Proceedings of the IEEE International Conference on Computer Vision</source> (<publisher-loc>Santiago</publisher-loc>), <fpage>1520</fpage>–<lpage>1528</lpage>. <pub-id pub-id-type="doi">10.1109/ICCV.2015.178</pub-id></mixed-citation>
    </ref>
    <ref id="B30">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A.</given-names></name><name><surname>Gross</surname><given-names>S.</given-names></name><name><surname>Massa</surname><given-names>F.</given-names></name><name><surname>Lerer</surname><given-names>A.</given-names></name><name><surname>Bradbury</surname><given-names>J.</given-names></name><name><surname>Chanan</surname><given-names>G.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>“Pytorch: an imperative style, high-performance deep learning library,”</article-title> in <source>Advances in Neural Information Processing Systems</source>, eds H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett (<publisher-loc>Vancouver, BC</publisher-loc>), <fpage>8024</fpage>–<lpage>8035</lpage>.</mixed-citation>
    </ref>
    <ref id="B31">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ronneberger</surname><given-names>O.</given-names></name><name><surname>Fischer</surname><given-names>P.</given-names></name><name><surname>Brox</surname><given-names>T.</given-names></name></person-group> (<year>2015</year>). <article-title>“U-net: convolutional networks for biomedical image segmentation,”</article-title> in <source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source> (<publisher-loc>Munich</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>234</fpage>–<lpage>241</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-319-24574-4_28</pub-id></mixed-citation>
    </ref>
    <ref id="B32">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rote</surname><given-names>G.</given-names></name></person-group> (<year>1991</year>). <article-title>Computing the minimum hausdorff distance between two point sets on a line under translation</article-title>. <source>Inform. Process. Lett</source>. <volume>38</volume>, <fpage>123</fpage>–<lpage>127</lpage>. <pub-id pub-id-type="doi">10.1016/0020-0190(91)90233-8</pub-id></mixed-citation>
    </ref>
    <ref id="B33">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Roy</surname><given-names>S.</given-names></name><name><surname>Knutsen</surname><given-names>A.</given-names></name><name><surname>Korotcov</surname><given-names>A.</given-names></name><name><surname>Bosomtwi</surname><given-names>A.</given-names></name><name><surname>Dardzinski</surname><given-names>B.</given-names></name><name><surname>Butman</surname><given-names>J. A.</given-names></name><etal/></person-group> (<year>2018</year>). <article-title>“A deep learning framework for brain extraction in humans and animals with traumatic brain injury,”</article-title> in <source>2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)</source> (<publisher-loc>Washington, DC</publisher-loc>: <publisher-name>IEEE</publisher-name>), <fpage>687</fpage>–<lpage>691</lpage>. <pub-id pub-id-type="doi">10.1109/ISBI.2018.8363667</pub-id></mixed-citation>
    </ref>
    <ref id="B34">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Santurkar</surname><given-names>S.</given-names></name><name><surname>Tsipras</surname><given-names>D.</given-names></name><name><surname>Ilyas</surname><given-names>A.</given-names></name><name><surname>Madry</surname><given-names>A.</given-names></name></person-group> (<year>2018</year>). <article-title>“How does batch normalization help optimization?”</article-title> in <source>Advances in Neural Information Processing Systems</source>, eds S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (<publisher-loc>Montreal, QC</publisher-loc>), <fpage>2483</fpage>–<lpage>2493</lpage>.</mixed-citation>
    </ref>
    <ref id="B35">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Subbanna</surname><given-names>N. K.</given-names></name><name><surname>Rajashekar</surname><given-names>D.</given-names></name><name><surname>Cheng</surname><given-names>B.</given-names></name><name><surname>Thomalla</surname><given-names>G.</given-names></name><name><surname>Fiehler</surname><given-names>J.</given-names></name><name><surname>Arbel</surname><given-names>T.</given-names></name><etal/></person-group>. (<year>2019</year>). <article-title>Stroke lesion segmentation in flair MRI datasets using customized markov random fields</article-title>. <source>Front. Neurol</source>. <volume>10</volume>:<fpage>541</fpage>. <pub-id pub-id-type="doi">10.3389/fneur.2019.00541</pub-id><?supplied-pmid 31178820?><pub-id pub-id-type="pmid">31178820</pub-id></mixed-citation>
    </ref>
    <ref id="B36">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Szegedy</surname><given-names>C.</given-names></name><name><surname>Vanhoucke</surname><given-names>V.</given-names></name><name><surname>Ioffe</surname><given-names>S.</given-names></name><name><surname>Shlens</surname><given-names>J.</given-names></name><name><surname>Wojna</surname><given-names>Z.</given-names></name></person-group> (<year>2016</year>). <article-title>“Rethinking the inception architecture for computer vision,”</article-title> in <source>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</source> (<publisher-loc>Las Vegas, NV</publisher-loc>), <fpage>2818</fpage>–<lpage>2826</lpage>. <pub-id pub-id-type="doi">10.1109/CVPR.2016.308</pub-id></mixed-citation>
    </ref>
    <ref id="B37">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Valverde</surname><given-names>J. M.</given-names></name><name><surname>Shatillo</surname><given-names>A.</given-names></name><name><surname>De Feo</surname><given-names>R.</given-names></name><name><surname>Gröhn</surname><given-names>O.</given-names></name><name><surname>Sierra</surname><given-names>A.</given-names></name><name><surname>Tohka</surname><given-names>J.</given-names></name></person-group> (<year>2019</year>). <article-title>“Automatic rodent brain mri lesion segmentation with fully convolutional networks,”</article-title> in <source>International Workshop on Machine Learning in Medical Imaging</source> (<publisher-loc>Shenzhen</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>195</fpage>–<lpage>202</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-32692-0_23</pub-id></mixed-citation>
    </ref>
    <ref id="B38">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Valverde</surname><given-names>J. M.</given-names></name><name><surname>Shatillo</surname><given-names>A.</given-names></name><name><surname>De Feo</surname><given-names>R.</given-names></name><name><surname>Gröhn</surname><given-names>O.</given-names></name><name><surname>Sierra</surname><given-names>A.</given-names></name><name><surname>Tohka</surname><given-names>J.</given-names></name></person-group> (<year>2020</year>). <article-title>Ratlesnetv2: a fully convolutional network for rodent brain lesion segmentation</article-title>. <source>arXiv</source> 2001.09138.</mixed-citation>
    </ref>
    <ref id="B39">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Valverde</surname><given-names>S.</given-names></name><name><surname>Cabezas</surname><given-names>M.</given-names></name><name><surname>Roura</surname><given-names>E.</given-names></name><name><surname>González-Villà</surname><given-names>S.</given-names></name><name><surname>Pareto</surname><given-names>D.</given-names></name><name><surname>Vilanova</surname><given-names>J. C.</given-names></name><etal/></person-group>. (<year>2017</year>). <article-title>Improving automated multiple sclerosis lesion segmentation with a cascaded 3D convolutional neural network approach</article-title>. <source>Neuroimage</source><volume>155</volume>:<fpage>159</fpage>–<lpage>168</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.04.034</pub-id><?supplied-pmid 28435096?><pub-id pub-id-type="pmid">28435096</pub-id></mixed-citation>
    </ref>
    <ref id="B40">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Y.</given-names></name><name><surname>Cheung</surname><given-names>P.-T.</given-names></name><name><surname>Shen</surname><given-names>G. X.</given-names></name><name><surname>Bhatia</surname><given-names>I.</given-names></name><name><surname>Wu</surname><given-names>E. X.</given-names></name><name><surname>Qiu</surname><given-names>D.</given-names></name><etal/></person-group>. (<year>2007</year>). <article-title>Comparing diffusion-weighted and T2-weighted mr imaging for the quantification of infarct size in a neonatal rat hypoxic-ischemic model at 24 h post-injury</article-title>. <source>Int. J. Deve. Neurosci</source>. <volume>25</volume>, <fpage>1</fpage>–<lpage>5</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijdevneu.2006.12.003</pub-id><?supplied-pmid 17229540?><pub-id pub-id-type="pmid">17229540</pub-id></mixed-citation>
    </ref>
    <ref id="B41">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>H.</given-names></name><name><surname>Huang</surname><given-names>W.</given-names></name><name><surname>Qi</surname><given-names>K.</given-names></name><name><surname>Li</surname><given-names>C.</given-names></name><name><surname>Liu</surname><given-names>X.</given-names></name><name><surname>Wang</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2019</year>). <article-title>“CLCI-net: cross-level fusion and context inference networks for lesion segmentation of chronic stroke,”</article-title> in <source>International Conference on Medical Image Computing and Computer-Assisted Intervention</source> (<publisher-loc>Shenzhen</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>266</fpage>–<lpage>274</lpage>. <pub-id pub-id-type="doi">10.1007/978-3-030-32248-9_30</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
