<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD with MathML3 v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1-mathml3.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?all-math-mml yes?>
<?use-mml?>
<?properties open_access?>
<?properties manuscript?>
<?origin nihpa?>
<?iso-abbr J Mach Learn Biomed Imaging?>
<?submitter-system nihms?>
<?submitter-userid 15381591?>
<?submitter-authority eRA?>
<?submitter-login malteh?>
<?submitter-name Malte Hoffmann?>
<?domain nihpa?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-journal-id">9918400085306676</journal-id>
    <journal-id journal-id-type="pubmed-jr-id">51610</journal-id>
    <journal-id journal-id-type="nlm-ta">J Mach Learn Biomed Imaging</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Mach Learn Biomed Imaging</journal-id>
    <journal-title-group>
      <journal-title>The journal of machine learning for biomedical imaging</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2766-905X</issn>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9491317</article-id>
    <article-id pub-id-type="pmid">36147449</article-id>
    <article-id pub-id-type="manuscript">nihpa1835691</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Learning the Effect of Registration Hyperparameters with HyperMorph</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Hoopes</surname>
          <given-names>Andrew</given-names>
        </name>
        <aff id="A1">Martinos Center for Biomedical Imaging, Massachusetts General Hospital</aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Hoffmann</surname>
          <given-names>Malte</given-names>
        </name>
        <aff id="A2">Martinos Center for Biomedical Imaging, Massachusetts General Hospital</aff>
        <aff id="A3">Department of Radiology, Harvard Medical School</aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Greve</surname>
          <given-names>Douglas N.</given-names>
        </name>
        <aff id="A4">Martinos Center for Biomedical Imaging, Massachusetts General Hospital</aff>
        <aff id="A5">Department of Radiology, Harvard Medical School</aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Fischl</surname>
          <given-names>Bruce</given-names>
        </name>
        <aff id="A6">Martinos Center for Biomedical Imaging, Massachusetts General Hospital</aff>
        <aff id="A7">Department of Radiology, Harvard Medical School</aff>
        <aff id="A8">Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology</aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Guttag</surname>
          <given-names>John</given-names>
        </name>
        <aff id="A9">Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology</aff>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Dalca</surname>
          <given-names>Adrian V.</given-names>
        </name>
        <aff id="A10">Martinos Center for Biomedical Imaging, Massachusetts General Hospital</aff>
        <aff id="A11">Department of Radiology, Harvard Medical School</aff>
        <aff id="A12">Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology</aff>
      </contrib>
    </contrib-group>
    <author-notes>
      <corresp id="CR1">
        <email>ahoopes@mgh.harvard.edu</email>
      </corresp>
    </author-notes>
    <pub-date pub-type="nihms-submitted">
      <day>17</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <month>3</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>07</day>
      <month>4</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>21</day>
      <month>9</month>
      <year>2022</year>
    </pub-date>
    <volume>1</volume>
    <elocation-id>003</elocation-id>
    <permissions>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>License: <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</ext-link>.</license-p>
      </license>
    </permissions>
    <abstract id="ABS1">
      <p id="P1">We introduce HyperMorph, a framework that facilitates efficient hyperparameter tuning in learning-based deformable image registration. Classical registration algorithms perform an iterative pair-wise optimization to compute a deformation field that aligns two images. Recent learning-based approaches leverage large image datasets to learn a function that rapidly estimates a deformation for a given image pair. In both strategies, the accuracy of the resulting spatial correspondences is strongly influenced by the choice of certain hyperparameter values. However, an effective hyperparameter search consumes substantial time and human effort as it often involves training multiple models for different fixed hyperparameter values and may lead to suboptimal registration. We propose an amortized hyperparameter learning strategy to alleviate this burden by <italic toggle="yes">learning</italic> the impact of hyperparameters on deformation fields. We design a meta network, or hypernetwork, that predicts the parameters of a registration network for input hyperparameters, thereby comprising a single model that generates the optimal deformation field corresponding to given hyperparameter values. This strategy enables fast, high-resolution hyperparameter search at test-time, reducing the inefficiency of traditional approaches while increasing flexibility. We also demonstrate additional benefits of HyperMorph, including enhanced robustness to model initialization and the ability to rapidly identify optimal hyperparameter values specific to a dataset, image contrast, task, or even anatomical region, all without the need to retrain models. We make our code publicly available at <ext-link xlink:href="http://hypermorph.voxelmorph.net" ext-link-type="uri">http://hypermorph.voxelmorph.net</ext-link>.</p>
    </abstract>
    <kwd-group>
      <kwd>Hyperparameter Search</kwd>
      <kwd>Deformable Image Registration</kwd>
      <kwd>Deep Learning</kwd>
      <kwd>Weight Sharing</kwd>
      <kwd>Amortized Learning</kwd>
      <kwd>Regularization</kwd>
      <kwd>Hypernetworks</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="S1">
    <label>1.</label>
    <title>Introduction</title>
    <p id="P2">In deformable image registration, dense correspondences are sought to align two images. Classical iterative registration techniques have been thoroughly studied, leading to mature mathematical frameworks and widely used software packages (<xref rid="R3" ref-type="bibr">Ashburner, 2007</xref>; <xref rid="R5" ref-type="bibr">Avants et al., 2008</xref>; <xref rid="R9" ref-type="bibr">Beg et al., 2005</xref>; <xref rid="R31" ref-type="bibr">Fischl et al., 1999</xref>; <xref rid="R78" ref-type="bibr">Rueckert et al., 1999</xref>; <xref rid="R86" ref-type="bibr">Vercauteren et al., 2009</xref>). More recent learning-based registration strategies use image datasets to learn a function that rapidly produces a deformation field for a given image pair (<xref rid="R8" ref-type="bibr">Balakrishnan et al., 2019</xref>; <xref rid="R76" ref-type="bibr">Roh√© et al., 2017</xref>; <xref rid="R82" ref-type="bibr">Sokooti et al., 2017</xref>; <xref rid="R24" ref-type="bibr">de Vos et al., 2019</xref>; <xref rid="R90" ref-type="bibr">Wu et al., 2015</xref>; <xref rid="R91" ref-type="bibr">Yang et al., 2017</xref>). These techniques necessitate the tuning of registration hyperparameters that have dramatic impacts on the estimated deformation field. For example, optimal hyperparameter choices can differ substantially across model implementation or even image contrast and anatomy, and even small changes can have large influences on accuracy. Choosing hyperparameter values is therefore an important step in developing, testing, and distributing registration methods.</p>
    <p id="P3">Tuning hyperparameters often involves random or grid search strategies to evaluate separate models for specific discrete hyperparameter values (<xref rid="F1" ref-type="fig">Figure 1</xref>). In practice, researchers or model users typically go through an iterative process of optimizing and validating models using a small subset of hyperparameter values and repeatedly adapting this subset based on the observed results. An optimal value for each hyperparameter is usually selected based on model performance, most often determined by human evaluation or additional validation data, such as anatomical annotations. This approach necessitates considerable computational and human effort, which, in turn, may lead to suboptimal parameter choices, misleading negative results, and impeded progress, especially when researchers resort to using values from the literature that are not appropriate for their specific dataset or registration task. For example, cross-subject registration of neuroimaging data from Alzheimer‚Äôs Disease patients with significant atrophy will require a substantially different optimal regularization hyperparameter than longitudinal same-subject registration, as we illustrate in our experiments.</p>
    <p id="P4">We present HyperMorph, a markedly different strategy for tuning registration hyperparameters. Our contributions are:</p>
    <sec id="S3">
      <title>Method.</title>
      <p id="P5">HyperMorph involves the end-to-end training of a single, rich model that <italic toggle="yes">learns</italic> the influence of registration hyperparameters on deformation fields, in contrast to traditional hyperparameter search (<xref rid="F1" ref-type="fig">Figure 1</xref>). A HyperMorph model comprises a meta network, or a hypernetwork, that estimates a spectrum of registration models by learning a continuous function of the hyperparameters and only needs to be trained once, facilitating rapid image registration for any hyperparameter value at test-time. This avoids the need to repeatedly train a set of models for separate, fixed hyperparameters, since HyperMorph can correctly predict their outputs in substantially less computational time. Consequently, HyperMorph facilitates rapid optimization of hyperparameters for a set of validation data. This is even more important for tasks involving more than one important hyperparameter, in which the computational complexity renders traditional search strategies inadequate.</p>
    </sec>
    <sec id="S4">
      <title>Properties.</title>
      <p id="P6">By capitalizing on the similarity of networks with similar hyperparameters, an individual HyperMorph model employs weight-sharing to optimize efficiently relative to the time required to train the multiple registration models it is able to encompass. Furthermore, we demonstrate that HyperMorph registration accuracy is less variable across multiple random network initializations compared to conventional registration models, reducing the need to retrain.</p>
    </sec>
    <sec id="S5">
      <title>Utility.</title>
      <p id="P7">HyperMorph facilitates rapid <italic toggle="yes">test-time</italic> search of optimal hyperparameter values through automatic optimization or visual evaluation for a continuous range of hyperparameters. We show the benefit of this technique by employing a <italic toggle="yes">single</italic> HyperMorph model to identify optimal hyperparameter values for different loss metrics, datasets, anatomical regions, or tasks with substantially more precision than grid search methods.</p>
      <p id="P8">This paper extends work presented at the 2021 International Conference on Information Processing in Medical Imaging (<xref rid="R42" ref-type="bibr">Hoopes et al., 2021</xref>). This extension introduces and analyzes an alternative approach to learning the effect of registration hyperparameters by integrating an additional hyperparameter input within monolithic registration networks, as an alternative to using hypernetworks. We contrast the hypernetwork-based HyperMorph approach with this integrative approach. In addition, we also improve the hypernetwork-based HyperMorph architecture. In our experiments, we add additional analyses for the effect of network size and hyperparameter sampling strategy on HyperMorph accuracy, and evaluate the ability of HyperMorph to learn the effect of multiple hyperparameters in semi-supervised training using 3D images (as opposed to 2D slices). We also introduce a thorough discussion of this paradigm.</p>
    </sec>
  </sec>
  <sec id="S6">
    <label>2.</label>
    <title>Related Work</title>
    <p id="P9">In this section, we introduce the techniques and common hyperparameters involved in modern image registration, and we provide an overview of hyperparameter tuning methods and hypernetwork-based architectures in machine learning.</p>
    <sec id="S7">
      <label>2.1</label>
      <title>Image Registration</title>
      <p id="P10">Image registration is widely studied in many formulations. Classical registration methods find a deformation field by optimizing an energy function independently for each image pair. This often involves maximizing an image-matching term that measures similarity between aligned images while enforcing a regularization on the deformation field to encourage topological correctness or smoothness on the resulting warp. Methods include B-spline based deformations (<xref rid="R78" ref-type="bibr">Rueckert et al., 1999</xref>), discrete optimization methods (<xref rid="R21" ref-type="bibr">Dalca et al., 2016</xref>; <xref rid="R36" ref-type="bibr">Glocker et al., 2008</xref>), elastic models (<xref rid="R7" ref-type="bibr">Bajcsy and Kovacic, 1989</xref>), SPM (<xref rid="R4" ref-type="bibr">Ashburner and Friston, 2000</xref>), LDDMM (<xref rid="R9" ref-type="bibr">Beg et al., 2005</xref>; <xref rid="R16" ref-type="bibr">Cao et al., 2005</xref>; <xref rid="R40" ref-type="bibr">Hernandez et al., 2009</xref>; <xref rid="R45" ref-type="bibr">Joshi and Miller, 2000</xref>; <xref rid="R66" ref-type="bibr">Miller et al., 2005</xref>; <xref rid="R92" ref-type="bibr">Zhang et al., 2017</xref>), symmetric normalization (<xref rid="R5" ref-type="bibr">Avants et al., 2008</xref>), Demons (<xref rid="R86" ref-type="bibr">Vercauteren et al., 2009</xref>), DARTEL (<xref rid="R3" ref-type="bibr">Ashburner, 2007</xref>), and spherical registration (<xref rid="R31" ref-type="bibr">Fischl et al., 1999</xref>). These techniques are robust and yield precise alignments, but iterative pairwise registration is typically computationally costly, often requiring tens of minutes or more to align image volumes (with size 256<sup>3</sup>) on a CPU. More recent GPU-based implementations are faster and operate on the order of minutes or even seconds, but require access to a GPU for each registration (<xref rid="R15" ref-type="bibr">Brunn et al., 2021</xref>; <xref rid="R68" ref-type="bibr">Modat et al., 2010</xref>; <xref rid="R80" ref-type="bibr">Shamonin et al., 2014</xref>).</p>
      <p id="P11">Recent learning-based approaches to registration use convolutional neural networks (CNNs) to learn a function that computes the deformation field for a given image pair in seconds on a CPU or faster on a GPU. Supervised models are trained to predict deformation fields that have been been simulated or computed by other techniques (<xref rid="R51" ref-type="bibr">Krebs et al., 2017</xref>; <xref rid="R76" ref-type="bibr">Roh√© et al., 2017</xref>; <xref rid="R82" ref-type="bibr">Sokooti et al., 2017</xref>; <xref rid="R91" ref-type="bibr">Yang et al., 2017</xref>), whereas unsupervised, or self-supervised, strategies are trained end-to-end and optimize an energy function similar to classical cost functions (<xref rid="R8" ref-type="bibr">Balakrishnan et al., 2019</xref>; <xref rid="R22" ref-type="bibr">Dalca et al., 2019b</xref>; <xref rid="R52" ref-type="bibr">Krebs et al., 2019</xref>; <xref rid="R70" ref-type="bibr">Mok and Chung, 2020</xref>; <xref rid="R24" ref-type="bibr">de Vos et al., 2019</xref>; <xref rid="R93" ref-type="bibr">Zhao et al., 2019</xref>). Semi-supervised strategies leverage auxiliary information, like anatomical annotations, in the loss function to improve test registration accuracy (<xref rid="R8" ref-type="bibr">Balakrishnan et al., 2019</xref>; <xref rid="R39" ref-type="bibr">Hering et al., 2019</xref>; <xref rid="R41" ref-type="bibr">Hoffmann et al., 2021</xref>; <xref rid="R43" ref-type="bibr">Hu et al., 2018</xref>).</p>
      <p id="P12">Commonly, these methods depend on at least one influential hyperparameter that balances the weight of the image-matching term with that of the deformation-regularization term. Semi-supervised losses might require an additional hyperparameter to weight an auxiliary term. Furthermore, the loss terms themselves often contain important hyperparameters, like the number of bins in mutual information (<xref rid="R87" ref-type="bibr">Viola and Wells III, 1997</xref>) or the neighborhood size (window size) of local normalized cross-correlation (<xref rid="R6" ref-type="bibr">Avants et al., 2011</xref>). Unfortunately, tuning hyperparameters in classical registration is an inefficient procedure since it typically requires tens of minutes to hours to compute pair-wise registrations. Although learning-based methods facilitate rapid registration at test-time, training individual models for different hyperparameter values is computationally expensive and can take days or even weeks to converge, resulting in hyperparameter searches that consume hundreds of GPU-hours (<xref rid="R8" ref-type="bibr">Balakrishnan et al., 2019</xref>; <xref rid="R41" ref-type="bibr">Hoffmann et al., 2021</xref>; <xref rid="R24" ref-type="bibr">de Vos et al., 2019</xref>).</p>
    </sec>
    <sec id="S8">
      <label>2.2</label>
      <title>Hyperparameter Optimization</title>
      <p id="P13">Hyperparameter tuning is a fundamental component of general learning-based model development that aims to jointly optimize a validation objective conditioned on model hyperparameters and a training objective conditioned on model weights (<xref rid="R34" ref-type="bibr">Franceschi et al., 2018</xref>). In common hyperparameter optimization methods, model training is considered a black-box function. Standard, popular approaches include random, grid, and sequential search (<xref rid="R11" ref-type="bibr">Bergstra and Bengio, 2012</xref>). More sample-efficient approaches involve Bayesian optimization techniques, which adopt a probabilistic model of the objective function to seek optimal hyperparameter values (<xref rid="R12" ref-type="bibr">Bergstra et al., 2011</xref>; <xref rid="R67" ref-type="bibr">Mockus et al., 1978</xref>; <xref rid="R81" ref-type="bibr">Snoek et al., 2012</xref>). These methods are often time-consuming because they require multiple model optimizations for each assessment of the hyperparameter. Various adaptations of Bayesian strategies improve efficiency by extrapolating model potential from learning curves (<xref rid="R27" ref-type="bibr">Domhan et al., 2015</xref>; <xref rid="R48" ref-type="bibr">Klein et al., 2016</xref>), prioritizing resources to promising models with bandit-based methods (<xref rid="R44" ref-type="bibr">Jamieson and Talwalkar, 2016</xref>; <xref rid="R54" ref-type="bibr">Li et al., 2017</xref>), and evaluating cheap approximations of the black-box function of interest (<xref rid="R46" ref-type="bibr">Kandasamy et al., 2017</xref>).</p>
      <p id="P14">Unlike black-box methods, gradient-based hyperparameter tuning strategies compute gradients of the validation error as a function of the hyperparameters by differentiating through the nested learning procedure. Reverse-mode automatic differentiation facilitates the optimization of thousands of hyperparameters, but reversing the entire training procedure is exceedingly memory intensive (<xref rid="R10" ref-type="bibr">Bengio, 2000</xref>; <xref rid="R28" ref-type="bibr">Domke, 2012</xref>; <xref rid="R60" ref-type="bibr">Maclaurin et al., 2015</xref>). To conserve overhead, DrMAD (<xref rid="R35" ref-type="bibr">Fu et al., 2016</xref>) approximates the training procedure reversal by accounting for the parameter trajectory, and other approaches consider only the last parameter update for each optimization iteration (<xref rid="R58" ref-type="bibr">Luketina et al., 2016</xref>). Alternative approaches compute the hyperparameter gradient by deriving an implicit equation for the gradient under certain conditions (<xref rid="R73" ref-type="bibr">Pedregosa, 2016</xref>) or in real-time through forward-mode differentiation (<xref rid="R33" ref-type="bibr">Franceschi et al., 2017</xref>).</p>
      <p id="P15">All of these automatic hyperparameter tuning methods require optimization for an explicit validation objective. However, a comprehensive set of annotated validation data might not be available for every registration task, and in some cases registration accuracy must be evaluated visually or through a non-differentiable downstream measure. Furthermore, hyperparameters are generally optimized once for single set of validation data, and it is not easy to modify hyperparameter values rapidly (e.g. for a new task) without retraining models.</p>
    </sec>
    <sec id="S9">
      <label>2.3</label>
      <title>Hypernetworks</title>
      <p id="P16">Hypernetworks are meta neural networks that output the weights of a primary network (<xref rid="R38" ref-type="bibr">Ha et al., 2016</xref>; <xref rid="R79" ref-type="bibr">Schmidhuber, 1993</xref>), and these two networks comprise a single model that is trained end-to-end. Hypernetworks were originally introduced to compress model size (<xref rid="R38" ref-type="bibr">Ha et al., 2016</xref>), but they have been used in a variety of applications across other domains, including posterior estimation in Bayesian neural networks (<xref rid="R53" ref-type="bibr">Krueger et al., 2017</xref>; <xref rid="R85" ref-type="bibr">Ukai et al., 2018</xref>), automatic network pruning (<xref rid="R55" ref-type="bibr">Li et al., 2020</xref>; <xref rid="R56" ref-type="bibr">Liu et al., 2019</xref>), functional representation (<xref rid="R49" ref-type="bibr">Klocek et al., 2019</xref>; <xref rid="R83" ref-type="bibr">Spurek et al., 2020</xref>), multi-task learning (<xref rid="R64" ref-type="bibr">Meyerson and Miikkulainen, 2019</xref>), and generative models (<xref rid="R75" ref-type="bibr">Ratzlaff and Fuxin, 2019</xref>). The influence of hypernetwork initialization strategies has also been explored extensively (<xref rid="R17" ref-type="bibr">Chang et al., 2019</xref>).</p>
      <p id="P17">Additionally, hypernetworks have drawn recent attention as a promising tool for gradient-based hyperparameter optimization, as they facilitate direct differentiation through the entire learning procedure with respect to the hyperparameters of interest. For example, SMASH (<xref rid="R14" ref-type="bibr">Brock et al., 2017</xref>) employs a hypernetwork to estimate model parameters for a given architecture. Other frameworks use hypernetworks to tune regularization hyperparameters for image classification models and demonstrate that hypernetworks are capable of approximating the overall effect of these hyperparameters (<xref rid="R57" ref-type="bibr">Lorraine and Duvenaud, 2018</xref>; <xref rid="R59" ref-type="bibr">MacKay et al., 2019</xref>). HyperMorph employs hypernetworks in the context of learning-based registration to learn how hyperparameter values impact predicted deformation fields, similar to recent work for <italic toggle="yes">k</italic>-space reconstruction (<xref rid="R88" ref-type="bibr">Wang et al., 2021</xref>). A parallel, independent work also investigates learning the effect of regularization weights in registration models. The proposed method presents a different mechanism that emphasizes conditional instance normalization (<xref rid="R29" ref-type="bibr">Dumoulin et al., 2016</xref>) and employs an MLP, conditioned on the regularization parameter, to shift the feature statistics of each internal feature map (<xref rid="R69" ref-type="bibr">Mok and Chung, 2021</xref>).</p>
    </sec>
  </sec>
  <sec id="S10">
    <label>3.</label>
    <title>Methods</title>
    <sec id="S12">
      <title>Registration.</title>
      <p id="P18">Deformable registration methods align a moving image <italic toggle="yes">m</italic> and a fixed image <italic toggle="yes">f</italic> by computing a correspondence <italic toggle="yes">œï</italic>. We build on unsupervised learning-based registration approaches, which establish a standard registration network <inline-formula><mml:math id="M6" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>œï</mml:mi></mml:mrow></mml:math></inline-formula>, with trainable parameters <italic toggle="yes">Œ∏</italic><sub><italic toggle="yes">g</italic></sub>, that predicts the optimal deformation <italic toggle="yes">œï</italic> for the input image pair {<italic toggle="yes">m</italic>, <italic toggle="yes">f</italic>}. The deformation map <italic toggle="yes">œï</italic> is often implemented by adding a predicted displacement field to the identity map of the <italic toggle="yes">n</italic>-dimensional spatial domain <inline-formula><mml:math id="M7" display="inline"><mml:mrow><mml:mi>Œ©</mml:mi><mml:mo>‚àà</mml:mo><mml:msup><mml:mi>‚Ñù</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
      <p id="P19">These models contain a variety of hyperparameters, and the underlying objective of HyperMorph is to learn the effect of <italic toggle="yes">loss</italic> hyperparameters Œõ on the deformation field <italic toggle="yes">œï</italic>. We propose two fundamentally different ways of achieving this. In the first, we employ a hypernetwork to modify the registration function <inline-formula><mml:math id="M8" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> as a function of hyperparameters Œõ. In the second, we extend the existing registration function <inline-formula><mml:math id="M9" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> to take in hyperparameters Œõ as input. We focus our development on the former, hypernetwork-based approach, which is substantially easier to optimize and yields better results.</p>
    </sec>
    <sec id="S13">
      <label>3.1</label>
      <title>HyperMorph</title>
      <p id="P20">We propose a nested registration function, in which a hypernetwork <inline-formula><mml:math id="M10" display="inline"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Œõ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, with parameters <italic toggle="yes">Œ∏</italic><sub><italic toggle="yes">h</italic></sub>, estimates the parameters of the primary registration network <italic toggle="yes">Œ∏</italic><sub><italic toggle="yes">g</italic></sub> for input sample values of Œõ (<xref rid="F2" ref-type="fig">Figure 2</xref>). We use stochastic gradient methods to optimize hypernetwork parameters <italic toggle="yes">Œ∏</italic><sub><italic toggle="yes">h</italic></sub> with the loss function:
<disp-formula id="FD1"><label>(1)</label><mml:math id="M11" display="block"><mml:mrow><mml:msub><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi mathvariant="script">ùíü</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mi>Œõ</mml:mi><mml:mo>~</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Œõ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi mathvariant="script">ùíü</mml:mi><mml:mo>,</mml:mo><mml:mi>Œõ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="M12" display="inline"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Œõ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, ùíü is a training dataset of images, ‚Ñí(¬∑) is a registration loss function with hyperparameters Œõ, and <italic toggle="yes">p</italic>(Œõ) is a prior probability over the hyperparameters of interest. This distribution <italic toggle="yes">p</italic>(Œõ) can be uniform over a defined range or tailored to match assumptions. For each optimization step, we sample values from <italic toggle="yes">p</italic>(Œõ) and use these in the loss function ‚Ñí(¬∑) and as input to the network <inline-formula><mml:math id="M13" display="inline"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>‚ãÖ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Introducing a level of abstraction, the hypernetwork <inline-formula><mml:math id="M14" display="inline"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> allows the convolutional kernels <italic toggle="yes">Œ∏</italic><sub><italic toggle="yes">g</italic></sub> of the registration network <inline-formula><mml:math id="M15" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> to flexibly adapt to varying hyperparameter values.</p>
      <sec id="S14">
        <title>Unsupervised Model Instantiation.</title>
        <p id="P21">We build on unsupervised approaches to learning-based registration, which commonly involve optimizing a loss of the form:
<disp-formula id="FD2"><label>(2)</label><mml:math id="M16" display="block"><mml:mrow><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>œï</mml:mi><mml:mo>;</mml:mo><mml:mi>Œõ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>‚àò</mml:mo><mml:mi>œï</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>Œª</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>Œª</mml:mi><mml:msub><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>œï</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>Œª</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">m</italic> ‚ó¶ <italic toggle="yes">œï</italic> represents <italic toggle="yes">m</italic> warped by <italic toggle="yes">œï</italic>. The ‚Ñí<sub><italic toggle="yes">sim</italic></sub> loss term quantifies the similarity between <italic toggle="yes">m</italic> ‚ó¶ <italic toggle="yes">œï</italic> and <italic toggle="yes">f</italic> and includes potential hyperparameters <italic toggle="yes">Œª</italic><sub><italic toggle="yes">sim</italic></sub>, whereas the ‚Ñí<sub><italic toggle="yes">reg</italic></sub> term measures the spatial regularity of the estimated deformation field <italic toggle="yes">œï</italic> and includes potential hyperparameters <italic toggle="yes">Œª</italic><sub><italic toggle="yes">reg</italic></sub>. The hyperparameter <italic toggle="yes">Œª</italic> regulates the weight of ‚Ñí<sub><italic toggle="yes">reg</italic></sub>, and we define Œõ = {<italic toggle="yes">Œª</italic>, <italic toggle="yes">Œª</italic><sub><italic toggle="yes">sim</italic></sub>, <italic toggle="yes">Œª</italic><sub><italic toggle="yes">reg</italic></sub>}. One limitation of this formulation is that <italic toggle="yes">p</italic>(<italic toggle="yes">Œª</italic>) is challenging to define as the range of <italic toggle="yes">Œª</italic> is infinite. We constrain <italic toggle="yes">Œª</italic> to [0, 1] by scaling ‚Ñí<italic toggle="yes"><sub>sim</sub></italic> by (1 ‚àí <italic toggle="yes">Œª</italic>). We thus optimize HyperMorph using:
<disp-formula id="FD3"><label>(3)</label><mml:math id="M17" display="block"><mml:mrow><mml:msub><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi mathvariant="script">ùíü</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mi>Œõ</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:munder><mml:mstyle><mml:mo>‚àë</mml:mo></mml:mstyle><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>‚àà</mml:mo><mml:mi mathvariant="script">ùíü</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>‚àí</mml:mo><mml:mi>Œª</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>‚àò</mml:mo><mml:mi>œï</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>Œª</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>Œª</mml:mi><mml:msub><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>œï</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>Œª</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="M18" display="inline"><mml:mrow><mml:mi>œï</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="M19" display="inline"><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Œõ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
        <p id="P22">In our experiments, we use mean-squared error (MSE) and <italic toggle="yes">local</italic> normalized cross-correlation (NCC) as the similarity metrics for ‚Ñí<sub><italic toggle="yes">sim</italic></sub> when registering images of the same contrast, and we use mutual information (MI) for multi-contrast registration. Local NCC involves a hyperparameter that defines the local neighborhood (window) size, and MI involves a hyperparameter that controls the number of histogram bins (<xref rid="R87" ref-type="bibr">Viola and Wells III, 1997</xref>). In some cases, MSE is scaled by estimated image noise <italic toggle="yes">œÉ</italic><sup>‚àí2</sup>.</p>
        <p id="P23">To encourage diffeomorphic deformations, which are invertible by design, we spatially integrate the vectors of a stationary velocity field (SVF) <italic toggle="yes">v</italic> using <italic toggle="yes">scaling and squaring</italic> (<xref rid="R2" ref-type="bibr">Arsigny et al., 2006</xref>; <xref rid="R3" ref-type="bibr">Ashburner, 2007</xref>; <xref rid="R22" ref-type="bibr">Dalca et al., 2019b</xref>) to obtain <italic toggle="yes">œï</italic>, which is regularized using
<disp-formula id="FD4"><label>(4)</label><mml:math id="M20" display="block"><mml:mrow><mml:msub><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>œï</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munderover><mml:mo>‚àë</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mrow><mml:mo>‚Äñ</mml:mo><mml:mrow><mml:mo>‚àá</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>‚Äñ</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">i</italic> is an axis in the <italic toggle="yes">n</italic>-dimensional image and ‚àá<italic toggle="yes">v</italic><sub><italic toggle="yes">i</italic></sub>(<italic toggle="yes">p</italic>) defines the spatial gradient of <italic toggle="yes">v</italic><sub><italic toggle="yes">i</italic></sub> at location <italic toggle="yes">p</italic> ‚àà Œ©. The regularization term ‚Ñí<sub><italic toggle="yes">reg</italic></sub> can take a variety of forms and might include multiple specific hyperparameters <italic toggle="yes">Œª</italic><sub><italic toggle="yes">reg</italic></sub>.</p>
      </sec>
      <sec id="S15">
        <title>Semi-supervised Model Instantiation.</title>
        <p id="P24">Following recent strategies that exploit supplemental information during training, we extend HyperMorph to semi-supervised learning by incorporating segmentation maps in the loss function:
<disp-formula id="FD5"><label>(5)</label><mml:math id="M21" display="block"><mml:mrow><mml:msub><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi mathvariant="script">ùíü</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="double-struck">E</mml:mi><mml:mi>Œõ</mml:mi></mml:msub><mml:munder><mml:mstyle><mml:mo>‚àë</mml:mo></mml:mstyle><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>‚àà</mml:mo><mml:mi mathvariant="script">ùíü</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>‚àí</mml:mo><mml:mi>Œª</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>‚àí</mml:mo><mml:mi>Œ≥</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>‚àò</mml:mo><mml:mi>œï</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>Œª</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>Œª</mml:mi><mml:msub><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mrow><mml:mtext>reg¬†</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>œï</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>Œª</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>Œ≥</mml:mi><mml:msub><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>‚àò</mml:mo><mml:mi>œï</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <italic toggle="yes">s</italic><sub><italic toggle="yes">m</italic></sub> and <italic toggle="yes">s</italic><sub><italic toggle="yes">f</italic></sub> are segmentation maps corresponding to the moving and fixed images, respectively, and ‚Ñí<sub><italic toggle="yes">seg</italic></sub> is a measure of segmentation overlap, often the Dice coefficient (<xref rid="R26" ref-type="bibr">Dice, 1945</xref>), weighted by the hyperparameter <italic toggle="yes">Œ≥</italic>. As with the unsupervised loss, we constrain the range of <italic toggle="yes">Œ≥</italic> within [0, 1] by scaling the similarity term ‚Ñí<sub><italic toggle="yes">sim</italic></sub> by (1 ‚àí <italic toggle="yes">Œª</italic>)(1 ‚àí <italic toggle="yes">Œ≥</italic>).</p>
      </sec>
    </sec>
    <sec id="S16">
      <label>3.2</label>
      <title>Hyperparameter Tuning</title>
      <p id="P25">An optimized HyperMorph model can rapidly register a test image pair {<italic toggle="yes">m</italic>, <italic toggle="yes">f</italic>} as a function of important hyperparameters. If external annotation data is not available, hyperparameters may be efficiently tuned in an interactive fashion. In some cases, landmarks, functional data, or segmentation maps are present, facilitating fast automatic hyperparameter optimization for a validation dataset.</p>
      <sec id="S17">
        <title>Interactive.</title>
        <p id="P26">Users can manually adjust hyperparameter values in close to real-time using interactive sliders until they are visually satisfied with the alignment of a given image pair. Sometimes, the user might adopt different settings when focusing on particular domains of the image. For instance, the optimal value of the <italic toggle="yes">Œª</italic> hyperparameter, which balances image-similarity and regularization, can differ substantially across anatomical regions of the brain (see <xref rid="F10" ref-type="fig">Figure 10</xref>). Interactive tuning is feasible since HyperMorph can efficiently estimate the influence of <italic toggle="yes">Œª</italic> values on the deformation field <italic toggle="yes">œï</italic> without necessitating further training.</p>
      </sec>
      <sec id="S18">
        <title>Automatic.</title>
        <p id="P27">If additional information, such as segmentation maps {<italic toggle="yes">s</italic><sub><italic toggle="yes">m</italic></sub>, <italic toggle="yes">s</italic><sub><italic toggle="yes">f</italic></sub>}, are present for validation, an individual trained HyperMorph model facilitates rapid optimization of hyperparameter values using
<disp-formula id="FD6"><label>(6)</label><mml:math id="M22" display="block"><mml:mrow><mml:msup><mml:mi>Œõ</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mtext>arg¬†min</mml:mtext></mml:mrow><mml:mi>Œõ</mml:mi></mml:munder><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Œõ</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="script">ùíü</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">ùí±</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mtext>arg¬†min</mml:mtext></mml:mrow><mml:mi>Œõ</mml:mi></mml:munder><mml:munder><mml:mstyle><mml:mo>‚àë</mml:mo></mml:mstyle><mml:mrow><mml:munder><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>‚àà</mml:mo><mml:mi mathvariant="script">ùíü</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>‚àà</mml:mo><mml:mi mathvariant="script">ùí±</mml:mi></mml:mrow></mml:munder></mml:mrow></mml:munder><mml:msub><mml:mi mathvariant="script">‚Ñí</mml:mi><mml:mrow><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>‚àò</mml:mo><mml:mi>œï</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where ùí± is a set of validation segmentations and ‚Ñí<sub><italic toggle="yes">val</italic></sub> is a validation loss to be minimized. To carry out this hyperparameter optimization, we freeze the hypernetwork parameters <italic toggle="yes">Œ∏</italic><sub><italic toggle="yes">h</italic></sub> so that the input Œõ represents the sole set of trainable parameters. We rapidly optimize (<xref rid="FD6" ref-type="disp-formula">6</xref>) using stochastic gradient descent strategies.</p>
      </sec>
    </sec>
    <sec id="S19">
      <label>3.3</label>
      <title>Implementation</title>
      <p id="P28">We implement HyperMorph with the open-source VoxelMorph registration library (<xref rid="R8" ref-type="bibr">Balakrishnan et al., 2019</xref>), modeling the base registration network <inline-formula><mml:math id="M23" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> with a U-Net-like architecture (<xref rid="R77" ref-type="bibr">Ronneberger et al., 2015</xref>). In our experiments, this comprises a four-layer convolutional encoder-like part, with 16, 32, 32, and 32 respective channels per layer, followed by a seven-layer convolutional decoder-like part, with 32, 32, 32, 32, 32, 16, and 16 respective channels per layer. The convolutional layers have a kernel size of 3, a stride of 1, and are activated using LeakyReLU with <italic toggle="yes">Œ±</italic> parameter 0.2. After each convolution in the encoder, we reduce the spatial dimensions using max pooling with a window size of 2, and in the decoder, each convolution is followed by an upsampling layer until the volume is returned to full resolution. Skip connections concatenate features of the encoder with features of the first decoder layer of equal resolution. A final, linearly-activated convolutional layer outputs an SVF, which is integrated with five scaling and squaring steps to obtain <italic toggle="yes">œï</italic> (<xref rid="R3" ref-type="bibr">Ashburner, 2007</xref>; <xref rid="R22" ref-type="bibr">Dalca et al., 2019b</xref>). In total, this base model <inline-formula><mml:math id="M24" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> contains 313,507 trainable parameters.</p>
      <p id="P29">In the hypernetwork-based HyperMorph models used throughout our experiments, <inline-formula><mml:math id="M25" display="inline"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> consists of five fully-connected layers, each with 32, 64, 64, 128, and 128 respective units and ReLu activations, followed by a final linearly-activated layer with output units corresponding to the number of trainable parameters in <inline-formula><mml:math id="M26" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. This is improved from the previous HyperMorph implementation (<xref rid="R42" ref-type="bibr">Hoopes et al., 2021</xref>), which yielded slightly worse accuracy compared to some baseline models and used a hypernetwork consisting of four fully-connected layers, each with 64 units and a tanh-activated final layer. Together, the registration network and hypernetwork constitute a single network with approximately 40.5 million trainable parameters (<italic toggle="yes">Œ∏</italic><sub><italic toggle="yes">h</italic></sub>) that exist entirely in the hypernetwork. Since the large majority of trainable parameters exist in the final layer of the hypernetwork, the model size increases substantially with the number of parameters in <inline-formula><mml:math id="M27" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, but this increase does not lead to substantial memory footprint, as this is dominated by the convolutional tensors. We emphasize that the proposed strategy pertains to any learning-based registration architecture, not just VoxelMorph.</p>
      <p id="P30">We train all HyperMorph and baseline models with the Adam optimizer (<xref rid="R47" ref-type="bibr">Kingma and Ba, 2014</xref>), a batch size of 1, and an initial learning rate of 10<sup>‚àí4</sup>, employing a decay strategy that reduces the learning rate by a factor of two for every 5 √ó 10<sup>4</sup> optimization steps without improvement in the training loss. Continuous hyperparameter values are randomly sampled from a uniform distribution during training. Based on our experiments, the agreement of HyperMorph with baselines at the boundary hyperparameter values {0, 1} of <italic toggle="yes">Œª</italic> can be improved if values are slightly over-sampled during training. We let <italic toggle="yes">r</italic> be the fraction of hyperparameters sampled from this end-point distribution <italic toggle="yes">Œª</italic> ‚àà {0, 1} and set it to 0.2 in our experiments. Discrete hyperparameters, like the local NCC window size, are sampled from a <italic toggle="yes">discrete</italic> uniform distribution during training, and we normalize the sampled values in this range to [0, 1] when used as input to the hypernetwork. We observe that HyperMorph learns a continuous function for these hyperparameters by interpolating weights across discrete values, enabling their direct optimization at test-time using gradient strategies. We implement HyperMorph in Python, using the TensorFlow (<xref rid="R1" ref-type="bibr">Abadi et al., 2016</xref>) and Keras (<xref rid="R18" ref-type="bibr">Chollet et al., 2015</xref>) packages, and release HyperMorph as a component of the broader VoxelMorph registration package, with plans to support a PyTorch (<xref rid="R71" ref-type="bibr">Paszke et al., 2019</xref>) implementation. We train and evaluate all models on Nvidia Quadro RTX 8000 GPUs.</p>
    </sec>
    <sec id="S20">
      <label>3.4</label>
      <title>Alternative Models</title>
      <p id="P31">We also analyze a fundamentally different approach to amortized hyperparameter learning by extending the <italic toggle="yes">inputs</italic> to the registration function as opposed to changing the registration function using hypernetworks. We build on architectures that combine scalar or non-image inputs with convolutional networks used in other tasks, such as probabilistic segmentation (<xref rid="R50" ref-type="bibr">Kohl et al., 2018</xref>) or conditional template construction (<xref rid="R20" ref-type="bibr">Dalca et al., 2019a</xref>).</p>
      <p id="P32">We examine three alternative implementations, in which hyperparameters are provided as input to a small auxiliary convolutional sub-network <inline-formula><mml:math id="M28" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, with parameters <italic toggle="yes">Œ∏</italic><sub><italic toggle="yes">d</italic></sub>, that is joined directly with the primary registration network (<xref rid="F3" ref-type="fig">Figure 3</xref>). In the first two alternative architectures, input hyperparameters are repeated and reshaped to an 8√ó8√ó8 multi-channel volume, with one channel for each input hyperparameter, and provided as input to a series of six convolutional layers in <inline-formula><mml:math id="M29" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, each with 32 channels. The output of each layer in <inline-formula><mml:math id="M30" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is upsampled until the target image resolution is reached. In the first alternative architecture, the pre-integrative network, <inline-formula><mml:math id="M31" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> takes the output of <inline-formula><mml:math id="M32" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> as an additional input (<xref rid="R20" ref-type="bibr">Dalca et al., 2019a</xref>). In the second architecture, the post-integrative network, the output of <inline-formula><mml:math id="M33" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is concatenated with the input to the <italic toggle="yes">final</italic> upsampling layer of the U-Net (<xref rid="R50" ref-type="bibr">Kohl et al., 2018</xref>). In the third alternative architecture, <inline-formula><mml:math id="M34" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> comprises five fully-connected layers, each with 256 units and ReLu activations, followed by a linearly-activated layer with output units equal to the total number of channels across all layers in <inline-formula><mml:math id="M35" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. We refer to this architecture as the full-integrative network, and each value estimated by <inline-formula><mml:math id="M36" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is added to its corresponding convolutional output channel in the base network.</p>
    </sec>
  </sec>
  <sec id="S21">
    <label>4.</label>
    <title>Experiments</title>
    <p id="P33">We conduct experiments evaluating how well a single HyperMorph model captures the behavior and matches the performance of individually trained registration networks with separate hyperparameter values. We show that our approach substantially reduces the computational and human effort required for a search with one or two registration hyperparameters. We present considerable improvements in robustness to model initialization. We also illustrate the utility of HyperMorph for efficient hyperparameter optimization across different subpopulations of data, image contrasts, registration types, and individual anatomical structures. Additionally, we compare hypernetwork-based HyperMorph with the proposed alternative models that expand the input space, and we provide a framework analysis exploring the effect of hypernetwork size and hyperparameter sampling on HyperMorph performance.</p>
    <sec id="S23">
      <title>Datasets.</title>
      <p id="P34">We use three groups of 3D brain magnetic resonance imaging (MRI) data gathered across multiple public datasets, as summarized in <xref rid="T1" ref-type="table">Table 1</xref>. The first group includes a series of within-contrast T1-weighted (T1w) scans, and the second group is a multi-contrast collection of T1w and T2-weighted (T2w) images, FLASH scans acquired with various flip angles, and MPRAGE scans with different inversion times. We also employ a group of longitudinal images for comparisons between within-subject and cross-subject registration tasks, in which we consider two T1w scans, acquired at least one year apart for each individual.</p>
      <p id="P35">Using FreeSurfer 7.2 (<xref rid="R30" ref-type="bibr">Fischl, 2012</xref>), all MR images are resampled as 256√ó256√ó256 volumes with 1-mm isotropic resolution, bias-corrected, brain-extracted, and automatically anatomically segmented for evaluation. We affinely align all images to the FreeSurfer Talairach atlas and uniformly crop them to size 160√ó192√ó224. When evaluating registration accuracy with segmentation data, we consider standard anatomical labels provided by FreeSurfer: the thalamus, caudate, putamen, pallidum, hippocampus, amygdala, accumbens area, ventral diencephalon, choroid plexus, cerebral cortex, cerebral white matter, cerebellar cortex, cerebellar white matter, brain stem, cerebrospinal fluid, and the 3rd, 4th, and lateral ventricles. FreeSurfer generates accurate segmentations that are often considered a silver-standard for automatic brain labeling (<xref rid="R23" ref-type="bibr">Dalca et al., 2019c</xref>; <xref rid="R74" ref-type="bibr">Puonti et al., 2016</xref>), but we also employ an auxiliary set of 30 manually-labeled T1w images from the Buckner40 cohort to evaluate registration accuracy using gold-standard annotations. This dataset was not used during training.</p>
    </sec>
    <sec id="S24">
      <title>Evaluation metrics.</title>
      <p id="P36">For evaluation, we compute the volumetric Dice overlap coefficient (reported as percentage points between 0 and 100) as well as the 95th percentile surface distance in millimeters for corresponding anatomical labels of the moved and fixed segmentation maps. To quantify regularity of the deformation <italic toggle="yes">œï</italic>, we report the standard deviation of the Jacobian determinant |<italic toggle="yes">J</italic><sub><italic toggle="yes">œï</italic></sub>|, where <italic toggle="yes">J</italic><sub><italic toggle="yes">œï</italic></sub>(<italic toggle="yes">p</italic>) = ‚àá<italic toggle="yes">œï</italic>(<italic toggle="yes">p</italic>) for each displacement voxel <italic toggle="yes">p</italic> ‚àà Œ©.</p>
    </sec>
    <sec id="S25">
      <title>Baseline Models.</title>
      <p id="P37">HyperMorph can be applied to any learning-based registration architecture. To analyze how accurately it captures the effect of hyperparameters on the inner registration network <inline-formula><mml:math id="M37" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>‚ãÖ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, we train baseline VoxelMorph models with architectures identical to <inline-formula><mml:math id="M38" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mo>‚ãÖ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, each with a different set of fixed hyperparameter values.</p>
    </sec>
    <sec id="S26">
      <label>4.1</label>
      <title>Experiment 1: HyperMorph Efficiency and Capacity</title>
      <p id="P38">The goal of this experiment is to assess the extent to which a single HyperMorph model captures a landscape of baseline models trained with different hyperparameter values. We emphasize that we do not focus on comparing HyperMorph with the latest registration architecture but rather on evaluating how HyperMorph can be combined with any framework.</p>
      <sec id="S27">
        <title>Setup.</title>
        <p id="P39">We first compare the accuracy and computational cost of a single HyperMorph model to standard grid hyperparameter search for the regularization weight <italic toggle="yes">Œª</italic>. In separate analyses, we train HyperMorph and the VoxelMorph baselines using the MSE (<italic toggle="yes">œÉ</italic> = 0.05) and NCC (window size = 9<sup>3</sup>) similarity metrics for within-contrast registration, as well as the MI metric (32 fixed bins) for cross-contrast registration. For each metric, we train 12 baseline models and compare network performance across 50 randomly selected image pairs from the test set. To analyze HyperMorph in the context of domain-shift scenarios, we further evaluate models (trained with ‚Ñí<sub><italic toggle="yes">sim</italic></sub> = <italic toggle="yes">MSE</italic>) on 20 image pairs from the manually-labeled Buckner40 cohort, held out entirely from training.</p>
        <p id="P40">Additionally, we assess the ability of HyperMorph to learn the effect of multiple hyperparameters simultaneously. First, we train a semi-supervised HyperMorph model using a subset of six labels, holding out a further six labels for evaluation, to simulate partially annotated data. In this experiment, we choose <italic toggle="yes">Œª</italic> and the relative weight <italic toggle="yes">Œ≥</italic> of the semi-supervised loss (<xref rid="FD5" ref-type="disp-formula">5</xref>) as the hyperparameters of interest. Second, we train a HyperMorph model treating <italic toggle="yes">Œª</italic> and the local NCC window size <italic toggle="yes">w</italic> as hyperparameters. Since the computation of local NCC is computationally prohibitive for large window sizes in 3D data, we conduct the experiment in 2D on mid-coronal slices. These slices are not bias-corrected during preprocessing, since the local NCC metric is most useful for aligning images with strong intensity inhomogeneities. We train semi-supervised baseline models for 25 hyperparameter combinations, performing a discrete search on a 5 √ó 5 two-dimensional grid.</p>
      </sec>
      <sec id="S28">
        <title>Results.</title>
        <sec id="S29">
          <title>Computational Cost.</title>
          <p id="P41">A single HyperMorph model converges considerably faster than the baseline grid search. For single-hyperparameter tests, HyperMorph requires 6.1 times fewer GPU-hours than the 1D grid search with 12 baseline models (<xref rid="T2" ref-type="table">Table 2</xref>). For two hyperparameters, the difference is even more striking, with HyperMorph requiring 12.3 times fewer GPU-hours than a grid search with 25 baseline models. Furthermore, a 5√ó5 grid search is coarse, especially if the scale of the evaluated hyperparameters is unknown. While the time required for grid search is proportional to the number of grid points, HyperMorph enables arbitrarily fine resolution between grid points, at no increase in training time.</p>
        </sec>
        <sec id="S30">
          <title>Representation accuracy.</title>
          <p id="P42">Along with the computational advantage, <xref rid="F4" ref-type="fig">Figures 4</xref>, <xref rid="F5" ref-type="fig">5</xref>, <xref rid="F7" ref-type="fig">7</xref>, and <xref rid="F8" ref-type="fig">8</xref> show that HyperMorph yields optimal hyperparameter values similar to those determined through the baseline-model grid search. For each image pair, an average difference in the optimal hyperparameter value <italic toggle="yes">Œª</italic>* of only 0.04 ¬± 0.06 across single-hyperparameter experiments results in a negligible maximum Dice difference of 0.06 ¬± 0.42 (on a scale of 0 to 100) and a minimum surface distance of 0.01 ¬± 0.02 millimeters. Even when evaluated on the held-out, manually-labeled dataset, HyperMorph similarly matches the baseline registration accuracy, differing in maximum Dice by 0.02 ¬± 0.09 and in minimum surface distance by 0.01 ¬± 0.03 millimeters (<xref rid="SD2" ref-type="supplementary-material">Figure S1</xref>). Furthermore, the deformation field regularity at <italic toggle="yes">Œª</italic>*, measured by standard deviation of the Jacobian determinant, is 0.31 ¬± 0.14 and differs by only 0.01 ¬± 0.01 across HyperMorph and baseline models. We visualize these deformation fields and HyperMorph channel activations in <xref rid="F6" ref-type="fig">Figures 6</xref> and <xref rid="SD1" ref-type="supplementary-material">S2</xref>.</p>
          <p id="P43">Semi-supervised experiments yield a maximum Dice difference of only 0.02 ¬± 0.27 and minimum surface distance of 0.01¬±0.01. <xref rid="F8" ref-type="fig">Figure 8</xref> showcases an example in which the optimal pair of {<italic toggle="yes">Œª</italic>, <italic toggle="yes">w</italic>} values identified by HyperMorph lies far from the points of the coarse search grid, resulting in a 0.78 ¬± 0.98 decrease in maximum Dice for the traditional approach. In practice, even fewer baselines might be trained for a coarser hyperparameter search, resulting in either suboptimal hyperparameter choice or sequential search with substantial manual overhead.</p>
        </sec>
      </sec>
    </sec>
    <sec id="S31">
      <label>4.2</label>
      <title>Experiment 2: Robustness to Initialization</title>
      <p id="P44">The goal of this experiment is to analyze the robustness of each hyperparameter search strategy to different network weight initialization.</p>
      <sec id="S32">
        <title>Setup.</title>
        <p id="P45">We repeat the previous single-hyperparameter experiment with MSE and MI, retraining five HyperMorph models from scratch. For each of four different <italic toggle="yes">Œª</italic> values, we also train five baseline models. Each training run re-initializes the kernel weights with a different randomization seed, and we compare the variability across initializations in terms of the standard deviation (SD) of Dice accuracy for the HyperMorph and baseline networks, in a set of 50 image pairs.</p>
      </sec>
      <sec id="S33">
        <title>Results.</title>
        <p id="P46"><xref rid="F9" ref-type="fig">Figure 9</xref> shows that HyperMorph is considerably more robust (lower SD) to differential initialization than the baselines. Across the entire range of <italic toggle="yes">Œª</italic>, the average Dice SD for HyperMorph models trained with MSE is 1.7 times lower (<italic toggle="yes">P</italic> &lt; .001 via paired <italic toggle="yes">t</italic>-test) than the baseline SD and 2.6 times lower for MI (<italic toggle="yes">P</italic> &lt; .001) (<xref rid="T2" ref-type="table">Table 2</xref>).</p>
      </sec>
    </sec>
    <sec id="S34">
      <label>4.3</label>
      <title>Experiment 3: Hyperparameter-Tuning Utility</title>
      <p id="P47">This experiment aims to validate HyperMorph as a powerful tool for hyperparameter tuning across a number of registration tasks, with or without annotated validation data.</p>
      <sec id="S35">
        <title>Setup.</title>
        <sec id="S36">
          <title>Interactive Tuning.</title>
          <p id="P48">We demonstrate the utility of HyperMorph through an interactive tool that enables visual optimization of hyperparameters even if no annotated data are available. The user can explore the effect of <italic toggle="yes">continuously varying</italic> hyperparameter values using a single trained model and manually select a preferred optimal deformation. We provide an interactive HyperMorph demonstration with associated code at <ext-link xlink:href="http://hypermorph.voxelmorph.net" ext-link-type="uri">http://hypermorph.voxelmorph.net</ext-link>.</p>
        </sec>
        <sec id="S37">
          <title>Automatic Tuning.</title>
          <p id="P49">When annotations are available for validation, we can efficiently optimize the hyperparameter <italic toggle="yes">Œª</italic> in an automated fashion. For a variety of applications, we identify the optimal regularization weight <italic toggle="yes">Œª</italic>* for sets of 50 registration pairs. First, we investigate how <italic toggle="yes">Œª</italic>* differs across subject subpopulations and anatomical regions: we train HyperMorph on a subset of our T1w training data, and optimize <italic toggle="yes">Œª</italic> separately for sets of ABIDE, GSP, MCIC, and UK Biobank (UKB) subjects at test time. With this single HyperMorph model, we also identify separate values of <italic toggle="yes">Œª</italic>* for a range of neuroanatomical regions. Second, we train HyperMorph on a subset of the multi-contrast image pairs and determine <italic toggle="yes">Œª</italic>* separately for T1w-to-T2w, T2w-to-T2w, and multi-flip-angle (multi-FA) registration tasks. Last, we analyze the extent to which <italic toggle="yes">Œª</italic>* differs between cross-sectional and longitudinal registration: we train HyperMorph on a combination of within-subject and cross-subject pairs from OASIS-2 and separately optimize <italic toggle="yes">Œª</italic> for test pairs within and across subjects.</p>
        </sec>
      </sec>
      <sec id="S38">
        <title>Results.</title>
        <p id="P50"><xref rid="F10" ref-type="fig">Figure 10</xref> shows that <italic toggle="yes">Œª</italic>* varies substantially across subpopulations, image contrasts, tasks, and anatomical regions. Importantly, in some cases using the <italic toggle="yes">Œª</italic>* computed for one subset of data on another results in considerably reduced accuracy. For example, using <italic toggle="yes">Œª</italic>* determined for GSP on ABIDE data decreases the maximum attainable Dice score by 1.86 ¬± 2.87. We hypothesize that the observed variability in optimal hyperparameter values is caused by differences in image quality and anatomy between the datasets. Similarly, using the multi-FA <italic toggle="yes">Œª</italic>* for T1w-to-T2w registration and the within-subject <italic toggle="yes">Œª</italic>* for cross-subject registration causes the respective maximum Dice scores to drop by 3.16¬±2.14 and 1.73¬±1.20. Lastly, <xref rid="F10" ref-type="fig">Figure 10D</xref> illustrates that the optimal <italic toggle="yes">Œª</italic> value varies broadly across anatomical regions, suggesting that it is desirable to choose regularization weights depending on the downstream task and focus of a given study. In our experiments, automatic hyperparameter optimization takes just 12.3 ¬± 1.8 seconds on average per test pair and requires 10 GB of memory, while interactive tuning requires only 2 GB. We emphasize that these metrics are influenced substantially by the size of the image data being registered.</p>
      </sec>
    </sec>
    <sec id="S39">
      <label>4.4</label>
      <title>Experiment 4: Hypernetwork Size</title>
      <p id="P51">We also measure the importance of hypernetwork capacity for accurate representation of individually trained baseline models.</p>
      <sec id="S40">
        <title>Setup.</title>
        <p id="P52">We train separate HyperMorph models for three hypernetwork sizes: small (with 16, 16, 16, and 16 units per layer), medium (with 32, 32, 64, 64, and 64 units per layer), and large (with 32, 64, 64, 128, and 128 units per layer). We carry out these and all subsequent experiments using MSE for ‚Ñí<sub><italic toggle="yes">sim</italic></sub> and evaluate model accuracy against baselines results for 50 image pairs.</p>
      </sec>
      <sec id="S41">
        <title>Results.</title>
        <p id="P53"><xref rid="F11" ref-type="fig">Figure 11A</xref> shows that the capability of HyperMorph to match baseline registration accuracy increases with hypernetwork size. The large hypernetwork is appropriate for learning the effect of the regularization weight <italic toggle="yes">Œª</italic> in 3D registration. Although the large hypernetwork contains approximately 7.6 times more trainable weights than the small network, we find no substantial difference (&lt; 0.4%) in total training or inference time across hypernetwork sizes, likely because the significant bottleneck is caused by convolutional operations.</p>
      </sec>
    </sec>
    <sec id="S42">
      <label>4.5</label>
      <title>Experiment 5: Hyperparameter Sampling</title>
      <p id="P54">This experiment evaluates how different hyperparameter sampling methods affect HyperMorph accuracy. In previous tests, we observe that sampling regularization weights <italic toggle="yes">Œª</italic> from a uniform distribution during HyperMorph training results in registration accuracy comparable to baseline models across most of the hyperparameter range, especially near <italic toggle="yes">Œª</italic>*, but less comparable estimations very close to the boundaries <italic toggle="yes">Œª</italic> ‚àà {0, 1}functions. corresponding to similarity-only or regularization-only loss functions.</p>
      <sec id="S43">
        <title>Setup.</title>
        <p id="P55">To investigate whether these boundaries can also be captured by HyperMorph, we over-sample the end-point values {0, 1} of the hyperparameter <italic toggle="yes">Œª</italic> at a fixed rate <italic toggle="yes">r</italic>. We train and evaluate three separate models for different values of <italic toggle="yes">r</italic> (0.0, 0.2, and 0.8) and compare the final accuracy against baselines, to asses the influence of this rate on registration accuracy.</p>
      </sec>
      <sec id="S44">
        <title>Results.</title>
        <p id="P56">HyperMorph models trained for large values of <italic toggle="yes">r</italic> closely match the expected registration accuracy at end-point values of <italic toggle="yes">Œª</italic> but sacrifice registration accuracy across all values of <italic toggle="yes">Œª</italic> (<xref rid="F11" ref-type="fig">Figure 11B</xref>). For example, when training HyperMorph with <italic toggle="yes">r</italic> = 0.0 (no over-sampling), the mean deviation from the baseline Dice is 0.08 ¬± 0.26 at <italic toggle="yes">Œª</italic>*, compared to 2.96 ¬± 1.57 at <italic toggle="yes">Œª</italic> ‚àà {0, 1}. However, with <italic toggle="yes">r</italic> = 0.8, the mean deviation from baseline Dice is 0.87 ¬± 0.40 at <italic toggle="yes">Œª</italic>* and 0.49 ¬± 0.51 at <italic toggle="yes">Œª</italic> ‚àà {0, 1}. We emphasize that over-sampling is only necessary estimate appropriate representations at the extreme hyperparameter boundaries. As similarity-only or regularization-only loss functions are not desirable for the majority of applications, uniform sampling will suffice in most cases. Throughout all experiments presented in this study, we choose an intermediate value of <italic toggle="yes">r</italic> = 0.2, which facilitates the most consistent matching of baseline registration accuracy for all values of <italic toggle="yes">Œª</italic>.</p>
      </sec>
    </sec>
    <sec id="S45">
      <label>4.6</label>
      <title>Experiment 6: Alternative Models</title>
      <p id="P57">While hypernetworks facilitate learning the effect of hyperparameters on registration networks, we also investigate the alternative HyperMorph strategy of adding an input to the standard registration network.</p>
      <sec id="S46">
        <title>Setup.</title>
        <p id="P58">We train the pre-integrative, post-integrative, and full-integrative architectures defined in <xref rid="S20" ref-type="sec">Section 3.4</xref> and compare the resulting registration accuracy and computational cost with the individual baseline models.</p>
      </sec>
      <sec id="S47">
        <title>Results.</title>
        <p id="P59">None of the three alternative networks yield the accuracy achieved by baseline and hypernetwork-based HyperMorph models (<xref rid="F11" ref-type="fig">Figure 11C</xref>). While the pre-integrative and full-integrative networks broadly encapsulates the effect of <italic toggle="yes">Œª</italic>, identifying the baseline <italic toggle="yes">Œª</italic>* with an average error of 0.07 ¬± 0.08 and 0.05 ¬± 0.07, respectively, they deviate from peak baseline accuracy by 0.48 ¬± 0.25 and 0.23 ¬± 0.46. The post-integrative network struggles to learn the accurate effect of <italic toggle="yes">Œª</italic>, deviating from the baseline <italic toggle="yes">Œª</italic>* by 0.19¬±0.12 and peak accuracy by 0.71¬±0.61. The total train time for the full-integrative model is 1.1√ó longer than that of the hypernetwork-based HyperMorph, while the pre-integrative and post-integrative models require 1.8√ó more time, likely due to the added convolutional operations in the network.</p>
      </sec>
    </sec>
  </sec>
  <sec id="S48">
    <label>5.</label>
    <title>Discussion and Conclusion</title>
    <p id="P60">The accuracy of learning-based deformable registration algorithms largely hinges on the choice of adequate hyperparameter values, which might differ substantially across registration targets, data types, model architectures, and loss implementations. Consequently, accurate and high-resolution hyperparameter search is an essential component of registration model development.</p>
    <p id="P61">In this work, we present HyperMorph, a learning strategy for registration that eliminates the need to repeatedly train the same model with different hyperparameter values to evaluate their effect on performance. HyperMorph employs a hypernetwork that takes the desired hyperparameter values as input and predicts the corresponding parameters, or weights, of a registration network. We show that training a <italic toggle="yes">single</italic> HyperMorph model is sufficient to capture the behavior of a range of baseline models individually optimized for different hyperparameter values. This enables <italic toggle="yes">precise</italic> hyperparameter optimization at test-time, because the optimal value may be located between the limited number of discrete grid points evaluated by traditional approaches.</p>
    <p id="P62">We explore two alternatives for choosing optimum regularization weights: one interactive, based jointly on image matching and visual smoothness, and one automatic, based on registration accuracy. The automatic method optimizes Dice overlap, which in itself does not take field regularity into account. We ensure that this parameterization yields regular deformations by analyzing voxel-wise Jacobian determinants. However, we emphasize that HyperMorph enables efficient optimization of hyperparameter values at test-time using any desired metric of choice.</p>
    <sec id="S50">
      <title>Function vs. Input Space.</title>
      <p id="P63">We explore two paradigms for learning the effect of registration hyperparameters on the deformation field: a hypernetwork-based function that returns an appropriate registration function given a hyperparameter value or a modification of the registration function to accept an addition hyperparameter value as input (pre-integrative, post-integrative, or full-integrative). In the analysis, the latter approach under-performs in registration quality, and thus, modelling the effect of hyperparameters in this manner presents a more challenging optimization problem. We hypothesize that this effect could be due to the fact that the convolutional filters are fixed once training is complete, requiring them to perform a substantially more difficult task than simple registration. In contrast, the hypernetwork approach enables the convolutional filters to flexibly adapt to specific hyperparameter values, suggesting a more powerful mechanism. Further analysis of these effects is an interesting future direction but is beyond the scope of this work.</p>
      <p id="P64">We emphasize that a hypernetwork is not the only effective mechanism for learning the effects of hyperparameters on registration networks, and we investigate this group of alternative architectures in an attempt to gain and provide insight across approaches. For example, parallel, independent work (<xref rid="R69" ref-type="bibr">Mok and Chung, 2021</xref>) explores conditional registration networks. These learn regularization effects by leveraging instance normalization and employing an MLP to scale and shift hidden features as a function of the regularization weight <italic toggle="yes">Œª</italic>. This strategy is similar to the full-integrative implementation, suggesting another promising alternative strategy. The approach is also similar to hypernetwork-based HyperMorph since it employs an MLP to learn the hyperparameter effect, but it differs in how this MLP is coupled with the registration network. It is likely that with sufficient architectural optimization, both hypernetworks and specifically-designed conditional CNNs are powerful solutions for a variety of hyperparameter learning tasks.</p>
    </sec>
    <sec id="S51">
      <title>Computational efficiency.</title>
      <p id="P65">By exploiting the similarity of networks across a range of hyperparameter values, a single HyperMorph model uses weight-sharing to efficiently learn to estimate optimal deformation fields for arbitrary image pairs and <italic toggle="yes">any</italic> hyperparameter value from a continuous interval. This enables fast, automated tuning of hyperparameters at test time and represents a substantial advantage over traditional search techniques: to identify an optimal configuration, these techniques typically optimize a number of registration networks across a sparse, discrete grid of hyperparameter values, which requires dramatically more compute and human time than HyperMorph.</p>
    </sec>
    <sec id="S52">
      <title>Initialization robustness.</title>
      <p id="P66">Experiment 2 demonstrates that HyperMorph is substantially more robust to network weight initialization than individually trained networks, exhibiting 43 to 61% reduced variability over training runs, likely because the combined hypernetwork and registration-network stack can take advantage of weight-sharing across a landscape of hyperparameter values. This result further underlines the computational efficiency provided by HyperMorph, since traditional tuning approaches often resort to training models multiple times at each grid point to remove potential bias due to initialization variability.</p>
    </sec>
    <sec id="S53">
      <title>Test-time adaptation.</title>
      <p id="P67">Existing registration models are often trained using a single hyperparameter value optimized globally for a set of validation data. However, the frequently overlooked reality is that hyperparameter optima can differ substantially across individual image pairs and applications, whereas most, if not all, registration-based analysis pipelines assume the existence of a single optimal hyperparameter value (<xref rid="R72" ref-type="bibr">Patenaude et al., 2011</xref>; <xref rid="R89" ref-type="bibr">Wang et al., 2012</xref>; <xref rid="R30" ref-type="bibr">Fischl, 2012</xref>). For example, a pair of images with very different anatomies would benefit from weak regularization, permitting warps of high non-linearity. This implies that learning-based methods capable of adapting hyperparameters on the fly are essential. We demonstrate that a single HyperMorph model enables rapid discovery of optimal hyperparameter values for different dataset subpopulations, image contrasts, registration tasks, and even individual anatomical regions, facilitating the future development of models that learn to estimate ideal hyperparameter values for individual registration pairs.</p>
    </sec>
    <sec id="S54">
      <title>Further work.</title>
      <p id="P68">HyperMorph can be used with hyperparameters beyond those evaluated in this work. For example, it could be applied to the number of bins in the MI metric, the choice of form of the regularization term <italic toggle="yes">Œª</italic><sub><italic toggle="yes">reg</italic></sub>, the hyperparameters used in the regularization term(s), the level of dropout, or even architectural hyperparameters, similarly to the SMASH method (<xref rid="R14" ref-type="bibr">Brock et al., 2017</xref>). However, the effects of certain hyperparameters, especially those related to model architecture, might be substantially more difficult for a hypernetwork to learn. Additionally, for HyperMorph to learn the effects of some optimization-specific parameters, like learning rate and batch size, it would likely require substantial modifications.</p>
      <p id="P69">The identification of <italic toggle="yes">Œª</italic>* for different brain regions promotes a potential future direction of estimating a spatially-varying field of regularization hyperparameters for simultaneously optimal registration of all anatomical structures. Additionally, while we evaluate HyperMorph for one and two hyperparameters, we expect this strategy to readily adapt to more hyperparameters and are eager to explore hypernetworks in this context, in which grid search is impractical. We are also interested in investigating how the benefits of implicit weight-sharing in hypernetworks might differ across categories of loss hyperparameters.</p>
      <p id="P70">We also plan to expand this work by exploring more complex distributions of <italic toggle="yes">p</italic>(Œõ) and how they affect hyperparameter search. For example, in registration formulations where the image similarity term is re-weighted by estimated image noise <italic toggle="yes">œÉ</italic><sup>‚àí2</sup>, the range of the hyperparameter space that should be searched can vary substantially. With a suboptimal choice of <italic toggle="yes">œÉ</italic>, a grid search is often even more challenging, as the range of hyperparameter values that perform well can be very narrow. In a preliminary experiment, we found that HyperMorph performed well for a variety of noise estimates <italic toggle="yes">œÉ</italic>, even with a uniform distribution <italic toggle="yes">p</italic>(<italic toggle="yes">Œª</italic>) = <italic toggle="yes">ùí∞</italic>(0, 1) used throughout our experiments (<xref rid="F12" ref-type="fig">Figure 12</xref>). However, the result also simultaneously highlights the more dramatic Dice score sensitivity to hyperparameter choice for some <italic toggle="yes">œÉ</italic> values, suggesting that non-uniform distributions might lead to even better HyperMorph performance.</p>
    </sec>
    <sec id="S55">
      <title>Conclusion.</title>
      <p id="P71">We believe HyperMorph has the potential to drastically alleviate the burden of retraining networks with different hyperparameter values, thereby enabling efficient development of finely optimized models for image registration. While the training strategy described in this paper is well-suited for tuning a visually-driven workflow like image registration, the technique can be used to improve other applications within and beyond the domain of medical imaging analysis.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material" id="SM1">
    <title>Supplementary Material</title>
    <supplementary-material id="SD1" position="float" content-type="local-data">
      <label>Figure S2</label>
      <caption>
        <p id="P73">Figure S2: Changes in feature activations of the final HyperMorph U-Net layer across different values for <italic toggle="yes">Œª</italic>.</p>
      </caption>
      <media xlink:href="NIHMS1835691-supplement-Figure_S2.pdf" id="d64e2560" position="anchor"/>
    </supplementary-material>
    <supplementary-material id="SD2" position="float" content-type="local-data">
      <label>Figure S1</label>
      <caption>
        <p id="P72">Figure S1: Left: mean Dice scores achieved by a single HyperMorph model and baselines evaluated on the held-out, manually-labeled Buckner40 dataset. Right: image and label-based qualitative changes in HyperMorph alignment across different regularization weights for a given subject pair.</p>
      </caption>
      <media xlink:href="NIHMS1835691-supplement-Figure_S1.pdf" id="d64e2566" position="anchor"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="S56">
    <title>Acknowledgments</title>
    <p id="P74">Support for this research was provided in part by the BRAIN Initiative Cell Census Network (U01 MH117023), the National Institute for Biomedical Imaging and Bioengineering (P41 EB015896, 1R01 EB023281, R01 EB006758, R21 EB018907, R01 EB019956, P41 EB030006), the National Institute on Aging (1R56 AG064027, 1R01 AG064027, 5R01 AG008122, R01 AG016495, 1R01 AG070988), the National Institute of Mental Health (R01 MH123195, R01 MH121885, 1RF1 MH123195), the National Institute for Neurological Disorders and Stroke (R01 NS0525851, R21 NS072652, R01 NS070963, R01 NS083534, 5U01 NS086625, 5U24 NS10059103, R01 NS105820), the NIH Blueprint for Neuroscience Research (5U01 MH093765), the multi-institutional Human Connectome Project, the National Institute of Child Health and Human Development (K99 HD101553), and the Wistron Corporation. This research was made possible through resources provided by Shared Instrumentation Grants 1S10 RR023401, 1S10 RR019307, and 1S10 RR023043.</p>
  </ack>
  <fn-group>
    <fn id="FN1">
      <p id="P75">Ethical Standards</p>
      <p id="P76">The work follows the highest ethical standards in conducting research and writing the manuscript. All models were trained using publicly available data, with the exception of the FSM data. We believe that HyperMorph can substantially improve the use of image registration in medical image analysis, and we use the UK Biobank data in accordance with this interest in public health.</p>
    </fn>
    <fn fn-type="COI-statement" id="FN2">
      <p id="P77">Conflicts of Interest</p>
      <p id="P78">Bruce Fischl has a financial interest in CorticoMetrics, and his interests are reviewed and managed by Massachusetts General Hospital and Mass General Brigham in accordance with their conflict of interest policies.</p>
    </fn>
  </fn-group>
  <ref-list>
    <title>References</title>
    <ref id="R1">
      <mixed-citation publication-type="journal"><name><surname>Abadi</surname><given-names>Mart√≠n</given-names></name>, <name><surname>Agarwal</surname><given-names>Ashish</given-names></name>, <name><surname>Barham</surname><given-names>Paul</given-names></name>, <name><surname>Brevdo</surname><given-names>Eugene</given-names></name>, <name><surname>Chen</surname><given-names>Zhifeng</given-names></name>, <name><surname>Citro</surname><given-names>Craig</given-names></name>, <name><surname>Greg S Corrado</surname><given-names>Andy Davis</given-names></name>, <name><surname>Dean</surname><given-names>Jeffrey</given-names></name>, <name><surname>Devin</surname><given-names>Matthieu</given-names></name>, <etal/><article-title>Tensorflow: Large-scale machine learning on heterogeneous distributed systems</article-title>. <source>arXiv</source><comment>preprint arXiv:1603.04467</comment>, <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="R2">
      <mixed-citation publication-type="book"><name><surname>Arsigny</surname><given-names>Vincent</given-names></name>, <name><surname>Commowick</surname><given-names>Olivier</given-names></name>, <name><surname>Pennec</surname><given-names>Xavier</given-names></name>, and <name><surname>Ayache</surname><given-names>Nicholas</given-names></name>. <part-title>A log-euclidean framework for statistics on diffeomorphisms</part-title>. In <source>MICCAI: Medical Image Computing and Computer Assisted Interventions</source>, pages <fpage>924</fpage>‚Äì<lpage>31</lpage>. <publisher-name>Springer</publisher-name>, <year>2006</year>.</mixed-citation>
    </ref>
    <ref id="R3">
      <mixed-citation publication-type="journal"><name><surname>Ashburner</surname><given-names>J</given-names></name>. <article-title>A fast diffeomorphic image registration algorithm</article-title>. <source>Neuroimage</source>, <volume>38</volume>(<issue>1</issue>):<fpage>95</fpage>‚Äì<lpage>113</lpage>, <year>2007</year>.<pub-id pub-id-type="pmid">17761438</pub-id></mixed-citation>
    </ref>
    <ref id="R4">
      <mixed-citation publication-type="journal"><name><surname>Ashburner</surname><given-names>John</given-names></name> and <name><surname>Friston</surname><given-names>Karl J</given-names></name>. <article-title>Voxel-based morphometry-the methods</article-title>. <source>Neuroimage</source>. <volume>11</volume>:<fpage>805</fpage>‚Äì<lpage>821</lpage>, <year>2000</year>.<pub-id pub-id-type="pmid">10860804</pub-id></mixed-citation>
    </ref>
    <ref id="R5">
      <mixed-citation publication-type="journal"><name><surname>Avants</surname><given-names>Brian B</given-names></name>, <name><surname>Epstein</surname><given-names>Charles L</given-names></name>, <name><surname>Grossman</surname><given-names>Murray</given-names></name>, and <name><surname>Gee</surname><given-names>James C</given-names></name>. <article-title>Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain</article-title>. <source>Medical Image Analysis</source>, <volume>12</volume>(<issue>1</issue>):<fpage>26</fpage>‚Äì<lpage>41</lpage>, <year>2008</year>.<pub-id pub-id-type="pmid">17659998</pub-id></mixed-citation>
    </ref>
    <ref id="R6">
      <mixed-citation publication-type="journal"><name><surname>Avants</surname><given-names>Brian B</given-names></name>, <name><surname>Tustison</surname><given-names>Nicholas J</given-names></name>, <name><surname>Song</surname><given-names>Gang</given-names></name>, <name><surname>Cook</surname><given-names>Philip A</given-names></name>, <name><surname>Klein</surname><given-names>Arno</given-names></name>, and <name><surname>Gee</surname><given-names>James C</given-names></name>. <article-title>A reproducible evaluation of ants similarity metric performance in brain image registration</article-title>. <source>Neuroimage</source>, <volume>54</volume>(<issue>3</issue>):<fpage>2033</fpage>‚Äì<lpage>2044</lpage>, <year>2011</year>.<pub-id pub-id-type="pmid">20851191</pub-id></mixed-citation>
    </ref>
    <ref id="R7">
      <mixed-citation publication-type="journal"><name><surname>Bajcsy</surname><given-names>R</given-names></name> and <name><surname>Kovacic</surname><given-names>S</given-names></name>. <article-title>Multiresolution elastic matching</article-title>. <source>Computer Vision, Graphics, and Image Processing</source>, <volume>46</volume>:<fpage>1</fpage>‚Äì<lpage>21</lpage>, <year>1989</year>.</mixed-citation>
    </ref>
    <ref id="R8">
      <mixed-citation publication-type="journal"><name><surname>Balakrishnan</surname><given-names>Guha</given-names></name>, <name><surname>Zhao</surname><given-names>Amy</given-names></name>, <name><surname>Sabuncu</surname><given-names>Mert R</given-names></name>, <name><surname>Guttag</surname><given-names>John</given-names></name>, and <name><surname>Dalca</surname><given-names>Adrian V</given-names></name>. <article-title>Voxelmorph: a learning framework for deformable medical image registration</article-title>. <source>IEEE Transactions on Medical Imaging</source>, <volume>38</volume>(<issue>8</issue>):<fpage>1788</fpage>‚Äì<lpage>1800</lpage>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="R9">
      <mixed-citation publication-type="journal"><name><surname>Beg</surname><given-names>M Faisal</given-names></name>, <name><surname>Miller</surname><given-names>Michael I</given-names></name>, <name><surname>Trouv√©</surname><given-names>Alain</given-names></name>, and <name><surname>Younes</surname><given-names>Laurent</given-names></name>. <article-title>Computing large deformation metric mappings via geodesic flows of diffeomorphisms</article-title>. <source>International Journal of Computer Vision</source>, <volume>61</volume>(<issue>2</issue>):<fpage>139</fpage>‚Äì<lpage>157</lpage>, <year>2005</year>.</mixed-citation>
    </ref>
    <ref id="R10">
      <mixed-citation publication-type="journal"><name><surname>Bengio</surname><given-names>Yoshua</given-names></name>. <article-title>Gradient-based optimization of hyperparameters</article-title>. <source>Neural Computation</source>, <volume>12</volume> (<issue>8</issue>):<fpage>1889</fpage>‚Äì<lpage>1900</lpage>, <year>2000</year>.<pub-id pub-id-type="pmid">10953243</pub-id></mixed-citation>
    </ref>
    <ref id="R11">
      <mixed-citation publication-type="journal"><name><surname>Bergstra</surname><given-names>James</given-names></name> and <name><surname>Bengio</surname><given-names>Yoshua</given-names></name>. <article-title>Random search for hyper-parameter optimization</article-title>. <source>Journal of Machine Learning Research</source>, <volume>13</volume>(<issue>1</issue>):<fpage>281</fpage>‚Äì<lpage>305</lpage>, <year>2012</year>.</mixed-citation>
    </ref>
    <ref id="R12">
      <mixed-citation publication-type="journal"><name><surname>Bergstra</surname><given-names>James</given-names></name>, <name><surname>Bardenet</surname><given-names>R√©mi</given-names></name>, <name><surname>Bengio</surname><given-names>Yoshua</given-names></name>, and <name><surname>K√©gl</surname><given-names>Bal√°zs</given-names></name>. <article-title>Algorithms for hyperparameter optimization</article-title>. <source>Advances in neural information processing systems</source>, <volume>24</volume>, <year>2011</year>.</mixed-citation>
    </ref>
    <ref id="R13">
      <mixed-citation publication-type="journal"><name><surname>Bookheimer</surname><given-names>Susan Y</given-names></name>, <name><surname>Salat</surname><given-names>David H</given-names></name>, <name><surname>Terpstra</surname><given-names>Melissa</given-names></name>, <name><surname>Ances</surname><given-names>Beau M</given-names></name>, <name><surname>Barch</surname><given-names>Deanna M</given-names></name>, <name><surname>Buckner</surname><given-names>Randy L</given-names></name>, <name><surname>Burgess</surname><given-names>Gregory C</given-names></name>, <name><surname>Curtiss</surname><given-names>Sandra W</given-names></name>, <name><surname>Diaz-Santos</surname><given-names>Mirella</given-names></name>, <name><surname>Elam</surname><given-names>Jennifer Stine</given-names></name>, <etal/><article-title>The lifespan human connectome project in aging: an overview</article-title>. <source>NeuroImage</source>, <volume>185</volume>:<fpage>335</fpage>‚Äì<lpage>348</lpage>, <year>2019</year>.<pub-id pub-id-type="pmid">30332613</pub-id></mixed-citation>
    </ref>
    <ref id="R14">
      <mixed-citation publication-type="journal"><name><surname>Brock</surname><given-names>Andrew</given-names></name>, <name><surname>Lim</surname><given-names>Theodore</given-names></name>, <name><surname>Ritchie</surname><given-names>James M</given-names></name>, and <name><surname>Weston</surname><given-names>Nick</given-names></name>. <article-title>Smash: one-shot model architecture search through hypernetworks</article-title>. <source>arXiv</source><comment>preprint arXiv:1708.05344</comment>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="R15">
      <mixed-citation publication-type="journal"><name><surname>Brunn</surname><given-names>Malte</given-names></name>, <name><surname>Himthani</surname><given-names>Naveen</given-names></name>, <name><surname>Biros</surname><given-names>George</given-names></name>, <name><surname>Mehl</surname><given-names>Miriam</given-names></name>, and <name><surname>Mang</surname><given-names>Andreas</given-names></name>. <article-title>Fast gpu 3d diffeomorphic image registration</article-title>. <source>Journal of Parallel and Distributed Computing</source>, <volume>149</volume>: <fpage>149</fpage>‚Äì<lpage>162</lpage>, <year>2021</year>.<pub-id pub-id-type="pmid">33380769</pub-id></mixed-citation>
    </ref>
    <ref id="R16">
      <mixed-citation publication-type="journal"><name><surname>Cao</surname><given-names>Yan</given-names></name>, <name><surname>Miller</surname><given-names>Michael I</given-names></name>, <name><surname>Winslow</surname><given-names>Raimond L</given-names></name>, and <name><surname>Younes</surname><given-names>Laurent</given-names></name>. <article-title>Large deformation diffeomorphic metric mapping of vector fields</article-title>. <source>IEEE Transactions on Medical Imaging</source>, <volume>24</volume>(<issue>9</issue>):<fpage>1216</fpage>‚Äì<lpage>1230</lpage>, <year>2005</year>.<pub-id pub-id-type="pmid">16156359</pub-id></mixed-citation>
    </ref>
    <ref id="R17">
      <mixed-citation publication-type="confproc"><name><surname>Chang</surname><given-names>Oscar</given-names></name>, <name><surname>Flokas</surname><given-names>Lampros</given-names></name>, and <name><surname>Lipson</surname><given-names>Hod</given-names></name>. <article-title>Principled weight initialization for hypernetworks</article-title>. In <conf-name>International Conference on Learning Representations</conf-name>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="R18">
      <mixed-citation publication-type="webpage"><name><surname>Chollet</surname><given-names>Fran√ßois</given-names></name><etal/><source>Keras</source>. <comment><ext-link xlink:href="https://keras.io" ext-link-type="uri">https://keras.io</ext-link></comment>, <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="R19">
      <mixed-citation publication-type="journal"><name><surname>Dagley</surname><given-names>Alexander</given-names></name>, <name><surname>LaPoint</surname><given-names>Molly</given-names></name>, <name><surname>Huijbers</surname><given-names>Willem</given-names></name>, <name><surname>Hedden</surname><given-names>Trey</given-names></name>, <name><surname>McLaren</surname><given-names>Donald G</given-names></name>, <name><surname>Chatwal</surname><given-names>Jasmeer P</given-names></name>, <name><surname>Papp</surname><given-names>Kathryn V</given-names></name>, <name><surname>Amariglio</surname><given-names>Rebecca E</given-names></name>, <name><surname>Blacker</surname><given-names>Deborah</given-names></name>, <name><surname>Rentz</surname><given-names>Dorene M</given-names></name>, <etal/><article-title>Harvard aging brain study: dataset and accessibility</article-title>. <source>NeuroImage</source>, <volume>144</volume>: <fpage>255</fpage>‚Äì<lpage>258</lpage>, <year>2017</year>.<pub-id pub-id-type="pmid">25843019</pub-id></mixed-citation>
    </ref>
    <ref id="R20">
      <mixed-citation publication-type="journal"><name><surname>Dalca</surname><given-names>Adrian</given-names></name>, <name><surname>Rakic</surname><given-names>Marianne</given-names></name>, <name><surname>Guttag</surname><given-names>John</given-names></name>, and <name><surname>Sabuncu</surname><given-names>Mert</given-names></name>. <article-title>Learning conditional deformable templates with convolutional networks</article-title>. <source>Advances in neural information processing systems</source>, <volume>32</volume>, <year>2019a</year>.</mixed-citation>
    </ref>
    <ref id="R21">
      <mixed-citation publication-type="book"><name><surname>Dalca</surname><given-names>Adrian V</given-names></name>, <name><surname>Bobu</surname><given-names>Andreea</given-names></name>, <name><surname>Rost</surname><given-names>Natalia S</given-names></name>, and <name><surname>Golland</surname><given-names>Polina</given-names></name>. <part-title>Patch-based discrete registration of clinical brain images</part-title>. In <source>MICCAI: Medical Image Computing and Computer Assisted Interventions</source>, pages <fpage>60</fpage>‚Äì<lpage>67</lpage>. <publisher-name>Springer</publisher-name>, <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="R22">
      <mixed-citation publication-type="journal"><name><surname>Dalca</surname><given-names>Adrian V.</given-names></name>, <name><surname>Balakrishnan</surname><given-names>Guha</given-names></name>, <name><surname>Guttag</surname><given-names>John</given-names></name>, and <name><surname>Sabuncu</surname><given-names>Mert</given-names></name>. <article-title>Unsupervised learning of probabilistic diffeomorphic registration for images and surfaces</article-title>. <source>Medical Image Analysis</source>, <volume>57</volume>:<fpage>226</fpage>‚Äì<lpage>236</lpage>, <year>2019b</year>.<pub-id pub-id-type="pmid">31351389</pub-id></mixed-citation>
    </ref>
    <ref id="R23">
      <mixed-citation publication-type="book"><name><surname>Dalca</surname><given-names>Adrian V</given-names></name>, <name><surname>Yu</surname><given-names>Evan</given-names></name>, <name><surname>Golland</surname><given-names>Polina</given-names></name>, <name><surname>Fischl</surname><given-names>Bruce</given-names></name>, <name><surname>Sabuncu</surname><given-names>Mert R</given-names></name>, and <name><surname>Iglesias</surname><given-names>Juan Eugenio</given-names></name>. <part-title>Unsupervised deep learning for bayesian brain mri segmentation</part-title>. In <source>MICCAI: Medical Image Computing and Computer Assisted Interventions</source>, pages <fpage>356</fpage>‚Äì<lpage>365</lpage>. <publisher-name>Springer</publisher-name>, <year>2019c</year>.</mixed-citation>
    </ref>
    <ref id="R24">
      <mixed-citation publication-type="journal"><name><surname>de Vos</surname><given-names>Bob D</given-names></name>, <name><surname>Berendsen</surname><given-names>Floris F</given-names></name>, <name><surname>Viergever</surname><given-names>Max A</given-names></name>, <name><surname>Sokooti</surname><given-names>Hessam</given-names></name>, <name><surname>Staring</surname><given-names>Marius</given-names></name>, and <name><surname>I≈°gum</surname><given-names>Ivana</given-names></name>. <article-title>A deep learning framework for unsupervised affine and deformable image registration</article-title>. <source>Medical Image Analysis</source>, <volume>52</volume>:<fpage>128</fpage>‚Äì<lpage>143</lpage>, <year>2019</year>.<pub-id pub-id-type="pmid">30579222</pub-id></mixed-citation>
    </ref>
    <ref id="R25">
      <mixed-citation publication-type="journal"><name><surname>Di Martino</surname><given-names>Adriana</given-names></name>, <name><surname>Yan</surname><given-names>Chao-Gan</given-names></name>, <name><surname>Li</surname><given-names>Qingyang</given-names></name>, <name><surname>Denio</surname><given-names>Erin</given-names></name>, <name><surname>Castellanos</surname><given-names>Francisco X</given-names></name>, <name><surname>Alaerts</surname><given-names>Kaat</given-names></name>, <name><surname>Anderson</surname><given-names>Jeffrey S</given-names></name>, <name><surname>Assaf</surname><given-names>Michal</given-names></name>, <name><surname>Bookheimer</surname><given-names>Susan Y</given-names></name>, <name><surname>Dapretto</surname><given-names>Mirella</given-names></name>, <etal/><article-title>The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism</article-title>. <source>Molecular psychiatry</source>, <volume>19</volume>(<issue>6</issue>):<fpage>659</fpage>‚Äì<lpage>667</lpage>, <year>2014</year>.<pub-id pub-id-type="pmid">23774715</pub-id></mixed-citation>
    </ref>
    <ref id="R26">
      <mixed-citation publication-type="journal"><name><surname>Dice</surname><given-names>Lee R</given-names></name>. <article-title>Measures of the amount of ecologic association between species</article-title>. <source>Ecology</source>, <volume>26</volume> (<issue>3</issue>):<fpage>297</fpage>‚Äì<lpage>302</lpage>, <year>1945</year>.</mixed-citation>
    </ref>
    <ref id="R27">
      <mixed-citation publication-type="confproc"><name><surname>Domhan</surname><given-names>Tobias</given-names></name>, <name><surname>Springenberg</surname><given-names>Jost Tobias</given-names></name>, and <name><surname>Hutter</surname><given-names>Frank</given-names></name>. <article-title>Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves</article-title>. In <source>Twenty-Fourth International Joint Conference on Artificial Intelligence</source>, <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="R28">
      <mixed-citation publication-type="confproc"><name><surname>Domke</surname><given-names>Justin</given-names></name>. <article-title>Generic methods for optimization-based modeling</article-title>. In <conf-name>AISTATS</conf-name>, pages <fpage>318</fpage>‚Äì<lpage>326</lpage>, <year>2012</year>.</mixed-citation>
    </ref>
    <ref id="R29">
      <mixed-citation publication-type="journal"><name><surname>Dumoulin</surname><given-names>Vincent</given-names></name>, <name><surname>Shlens</surname><given-names>Jonathon</given-names></name>, and <name><surname>Kudlur</surname><given-names>Manjunath</given-names></name>. <article-title>A learned representation for artistic style</article-title>. <source>arXiv</source><comment>preprint arXiv:1610.07629</comment>, <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="R30">
      <mixed-citation publication-type="journal"><name><surname>Fischl</surname><given-names>Bruce</given-names></name>. <article-title>Freesurfer</article-title>. <source>Neuroimage</source>, <volume>62</volume>(<issue>2</issue>):<fpage>774</fpage>‚Äì<lpage>781</lpage>, <year>2012</year>.<pub-id pub-id-type="pmid">22248573</pub-id></mixed-citation>
    </ref>
    <ref id="R31">
      <mixed-citation publication-type="journal"><name><surname>Fischl</surname><given-names>Bruce</given-names></name>, <name><surname>Sereno</surname><given-names>Martin I</given-names></name>, <name><surname>Tootell</surname><given-names>Roger BH</given-names></name>, and <name><surname>Dale</surname><given-names>Anders M</given-names></name>. <article-title>High-resolution intersubject averaging and a coordinate system for the cortical surface</article-title>. <source>Human brain mapping</source>, <volume>8</volume>(<issue>4</issue>):<fpage>272</fpage>‚Äì<lpage>284</lpage>, <year>1999</year>.<pub-id pub-id-type="pmid">10619420</pub-id></mixed-citation>
    </ref>
    <ref id="R32">
      <mixed-citation publication-type="journal"><name><surname>Fischl</surname><given-names>Bruce</given-names></name>, <name><surname>Salat</surname><given-names>David H</given-names></name>, <name><surname>Busa</surname><given-names>Evelina</given-names></name>, <name><surname>Albert</surname><given-names>Marilyn</given-names></name>, <name><surname>Dieterich</surname><given-names>Megan</given-names></name>, <name><surname>Haselgrove</surname><given-names>Christian</given-names></name>, <name><surname>Van Der Kouwe</surname><given-names>Andre</given-names></name>, <name><surname>Killiany</surname><given-names>Ron</given-names></name>, <name><surname>Kennedy</surname><given-names>David</given-names></name>, <name><surname>Klaveness</surname><given-names>Shuna</given-names></name>, <etal/><article-title>Whole brain segmentation: automated labeling of neuroanatomical structures in the human brain</article-title>. <source>Neuron</source>, <volume>33</volume>(<issue>3</issue>):<fpage>341</fpage>‚Äì<lpage>355</lpage>, <year>2002</year>.<pub-id pub-id-type="pmid">11832223</pub-id></mixed-citation>
    </ref>
    <ref id="R33">
      <mixed-citation publication-type="book"><name><surname>Franceschi</surname><given-names>Luca</given-names></name>, <name><surname>Donini</surname><given-names>Michele</given-names></name>, <name><surname>Frasconi</surname><given-names>Paolo</given-names></name>, and <name><surname>Pontil</surname><given-names>Massimiliano</given-names></name>. <part-title>Forward and reverse gradient-based hyperparameter optimization</part-title>. In <source>International Conference on Machine Learning</source>, pages <fpage>1165</fpage>‚Äì<lpage>1173</lpage>. <publisher-name>PMLR</publisher-name>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="R34">
      <mixed-citation publication-type="journal"><name><surname>Franceschi</surname><given-names>Luca</given-names></name>, <name><surname>Frasconi</surname><given-names>Paolo</given-names></name>, <name><surname>Salzo</surname><given-names>Saverio</given-names></name>, <name><surname>Grazzi</surname><given-names>Riccardo</given-names></name>, and <name><surname>Pontil</surname><given-names>Massimilano</given-names></name>. <article-title>Bilevel programming for hyperparameter optimization and meta-learning</article-title>. <source>arXiv</source><comment>preprint arXiv:1806.04910</comment>, <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="R35">
      <mixed-citation publication-type="journal"><name><surname>Fu</surname><given-names>Jie</given-names></name>, <name><surname>Luo</surname><given-names>Hongyin</given-names></name>, <name><surname>Feng</surname><given-names>Jiashi</given-names></name>, <name><surname>Low</surname><given-names>Kian Hsiang</given-names></name>, and <name><surname>Chua</surname><given-names>Tat-Seng</given-names></name>. <article-title>Drmad: distilling reverse-mode automatic differentiation for optimizing hyperparameters of deep neural networks</article-title>. <source>arXiv</source><comment>preprint arXiv:1601.00917</comment>, <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="R36">
      <mixed-citation publication-type="journal"><name><surname>Glocker</surname><given-names>Ben</given-names></name>, <name><surname>Komodakis</surname><given-names>Nikos</given-names></name>, <name><surname>Tziritas</surname><given-names>Georgios</given-names></name>, <name><surname>Navab</surname><given-names>Nassir</given-names></name>, and <name><surname>Paragios</surname><given-names>Nikos</given-names></name>. <article-title>Dense image registration through mrfs and efficient linear programming</article-title>. <source>Medical Image Analysis</source>, <volume>12</volume>(<issue>6</issue>):<fpage>731</fpage>‚Äì<lpage>741</lpage>, <year>2008</year>.<pub-id pub-id-type="pmid">18482858</pub-id></mixed-citation>
    </ref>
    <ref id="R37">
      <mixed-citation publication-type="journal"><name><surname>Gollub</surname><given-names>Randy L</given-names></name>, <name><surname>Shoemaker</surname><given-names>Jody M</given-names></name>, <name><surname>King</surname><given-names>Margaret D</given-names></name>, <name><surname>White</surname><given-names>Tonya</given-names></name>, <name><surname>Ehrlich</surname><given-names>Stefan</given-names></name>, <name><surname>Sponheim</surname><given-names>Scott R</given-names></name>, <name><surname>Clark</surname><given-names>Vincent P</given-names></name>, <name><surname>Turner</surname><given-names>Jessica A</given-names></name>, <name><surname>Mueller</surname><given-names>Bryon A</given-names></name>, <name><surname>Magnotta</surname><given-names>Vince</given-names></name>, <etal/><article-title>The mcic collection: a shared repository of multi-modal, multi-site brain image data from a clinical investigation of schizophrenia</article-title>. <source>Neuroinformatics</source>, <volume>11</volume>(<issue>3</issue>):<fpage>367</fpage>‚Äì<lpage>388</lpage>, <year>2013</year>.<pub-id pub-id-type="pmid">23760817</pub-id></mixed-citation>
    </ref>
    <ref id="R38">
      <mixed-citation publication-type="journal"><name><surname>Ha</surname><given-names>David</given-names></name>, <name><surname>Dai</surname><given-names>Andrew</given-names></name>, and <name><surname>Le</surname><given-names>Quoc V</given-names></name>. <article-title>Hypernetworks</article-title>. <source>arXiv</source><comment>preprint arXiv:1609.09106</comment>, <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="R39">
      <mixed-citation publication-type="book"><name><surname>Hering</surname><given-names>Alessa</given-names></name>, <name><surname>Kuckertz</surname><given-names>Sven</given-names></name>, <name><surname>Heldmann</surname><given-names>Stefan</given-names></name>, and <name><surname>Heinrich</surname><given-names>Mattias P</given-names></name>. <part-title>Enhancing label-driven deep deformable image registration with local distance metrics for state-of-the-art cardiac motion tracking</part-title>. In <source>Bildverarbeitung f√ºr die Medizin 2019</source>, pages <fpage>309</fpage>‚Äì<lpage>314</lpage>. <publisher-name>Springer</publisher-name>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="R40">
      <mixed-citation publication-type="journal"><name><surname>Hernandez</surname><given-names>Monica</given-names></name>, <name><surname>Bossa</surname><given-names>Matias N</given-names></name>, and <name><surname>Olmos</surname><given-names>Salvador</given-names></name>. <article-title>Registration of anatomical images using paths of diffeomorphisms parameterized with stationary vector field flows</article-title>. <source>IJCV</source>, <volume>85</volume>(<issue>3</issue>):<fpage>291</fpage>‚Äì<lpage>306</lpage>, <year>2009</year>.</mixed-citation>
    </ref>
    <ref id="R41">
      <mixed-citation publication-type="book"><name><surname>Hoffmann</surname><given-names>Malte</given-names></name>, <name><surname>Billot</surname><given-names>Benjamin</given-names></name>, <name><surname>Iglesias</surname><given-names>Juan E</given-names></name>, <name><surname>Fischl</surname><given-names>Bruce</given-names></name>, and <name><surname>Dalca</surname><given-names>Adrian V</given-names></name>. <part-title>Learning mri contrast-agnostic registration</part-title>. In <source>2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)</source>, pages <fpage>899</fpage>‚Äì<lpage>903</lpage>. <publisher-name>IEEE</publisher-name>, <year>2021</year>.</mixed-citation>
    </ref>
    <ref id="R42">
      <mixed-citation publication-type="book"><name><surname>Hoopes</surname><given-names>Andrew</given-names></name>, <name><surname>Hoffmann</surname><given-names>Malte</given-names></name>, <name><surname>Fischl</surname><given-names>Bruce</given-names></name>, <name><surname>Guttag</surname><given-names>John</given-names></name>, and <name><surname>Dalca</surname><given-names>Adrian V</given-names></name>. <part-title>Hypermorph: Amortized hyperparameter learning for image registration</part-title>. In <source>International Conference on Information Processing in Medical Imaging</source>, pages <fpage>3</fpage>‚Äì<lpage>17</lpage>. <publisher-name>Springer</publisher-name>, <year>2021</year>.</mixed-citation>
    </ref>
    <ref id="R43">
      <mixed-citation publication-type="journal"><name><surname>Hu</surname><given-names>Yipeng</given-names></name>, <name><surname>Modat</surname><given-names>Marc</given-names></name>, <name><surname>Gibson</surname><given-names>Eli</given-names></name>, <name><surname>Li</surname><given-names>Wenqi</given-names></name>, <name><surname>Ghavami</surname><given-names>Nooshin</given-names></name>, <name><surname>Bonmati</surname><given-names>Ester</given-names></name>, <name><surname>Wang</surname><given-names>Guotai</given-names></name>, <name><surname>Bandula</surname><given-names>Steven</given-names></name>, <name><surname>Moore</surname><given-names>Caroline M</given-names></name>, <name><surname>Emberton</surname><given-names>Mark</given-names></name>, <etal/><article-title>Weakly-supervised convolutional neural networks for multimodal image registration</article-title>. <source>Medical Image Analysis</source>, <volume>49</volume>:<fpage>1</fpage>‚Äì<lpage>13</lpage>, <year>2018</year>.<pub-id pub-id-type="pmid">30007253</pub-id></mixed-citation>
    </ref>
    <ref id="R44">
      <mixed-citation publication-type="confproc"><name><surname>Jamieson</surname><given-names>Kevin</given-names></name> and <name><surname>Talwalkar</surname><given-names>Ameet</given-names></name>. <article-title>Non-stochastic best arm identification and hyperparameter optimization</article-title>. In <conf-name>AISTATS</conf-name>, pages <fpage>240</fpage>‚Äì<lpage>248</lpage>, <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="R45">
      <mixed-citation publication-type="journal"><name><surname>Joshi</surname><given-names>Sarang C</given-names></name> and <name><surname>Miller</surname><given-names>Michael I</given-names></name>. <article-title>Landmark matching via large deformation diffeomorphisms</article-title>. <source>IEEE Transactions on Image Processing</source>, <volume>9</volume>(<issue>8</issue>):<fpage>1357</fpage>‚Äì<lpage>1370</lpage>, <year>2000</year>.<pub-id pub-id-type="pmid">18262973</pub-id></mixed-citation>
    </ref>
    <ref id="R46">
      <mixed-citation publication-type="journal"><name><surname>Kandasamy</surname><given-names>Kirthevasan</given-names></name>, <name><surname>Dasarathy</surname><given-names>Gautam</given-names></name>, <name><surname>Schneider</surname><given-names>Jeff</given-names></name>, and <name><surname>P√≥czos</surname><given-names>Barnab√°s</given-names></name>. <article-title>Multi-fidelity bayesian optimisation with continuous approximations</article-title>. <source>arXiv</source><comment>preprint arXiv:1703.06240</comment>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="R47">
      <mixed-citation publication-type="journal"><name><surname>Kingma</surname><given-names>Diederik P</given-names></name> and <name><surname>Ba</surname><given-names>Jimmy</given-names></name>. <article-title>Adam: A method for stochastic optimization</article-title>. <source>arXiv</source>
<comment>preprint arXiv:1412.6980</comment>, <year>2014</year>.</mixed-citation>
    </ref>
    <ref id="R48">
      <mixed-citation publication-type="confproc"><name><surname>Klein</surname><given-names>Aaron</given-names></name>, <name><surname>Falkner</surname><given-names>Stefan</given-names></name>, <name><surname>Springenberg</surname><given-names>Jost Tobias</given-names></name>, and <name><surname>Hutter</surname><given-names>Frank</given-names></name>. <article-title>Learning curve prediction with bayesian neural networks</article-title>. In <conf-name>ICLR: International Conference on Learning Representations</conf-name>, <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="R49">
      <mixed-citation publication-type="book"><name><surname>Klocek</surname><given-names>Sylwester</given-names></name>, <name><surname>Maziarka</surname><given-names>≈Åukasz</given-names></name>, <name><surname>lczyk</surname><given-names>Maciej Wo≈Çczyk</given-names></name>, <name><surname>Tabor</surname><given-names>Jacek</given-names></name>, <name><surname>Nowak</surname><given-names>Jakub</given-names></name>, and <name><surname>≈ömieja</surname><given-names>Marek</given-names></name>. <part-title>Hypernetwork functional image representation</part-title>. In <source>International Conference on Artificial Neural Networks</source>, pages <fpage>496</fpage>‚Äì<lpage>510</lpage>. <publisher-name>Springer</publisher-name>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="R50">
      <mixed-citation publication-type="journal"><name><surname>Kohl</surname><given-names>Simon</given-names></name>, <name><surname>Romera-Paredes</surname><given-names>Bernardino</given-names></name>, <name><surname>Meyer</surname><given-names>Clemens</given-names></name>, <name><surname>De Fauw</surname><given-names>Jeffrey</given-names></name>, <name><surname>Ledsam</surname><given-names>Joseph R</given-names></name>, <name><surname>Maier-Hein</surname><given-names>Klaus</given-names></name>, <name><surname>Eslami</surname><given-names>SM</given-names></name>, <name><surname>Rezende</surname><given-names>Danilo Jimenez</given-names></name>, and <name><surname>Ronneberger</surname><given-names>Olaf</given-names></name>. <article-title>A probabilistic u-net for segmentation of ambiguous images</article-title>. <source>Advances in neural information processing systems</source>, <volume>31</volume>, <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="R51">
      <mixed-citation publication-type="book"><name><surname>Krebs</surname><given-names>Julian</given-names></name>, <name><surname>Mansi</surname><given-names>Tommaso</given-names></name>, <name><surname>Delingette</surname><given-names>Herv√©</given-names></name>, <name><surname>Zhang</surname><given-names>Li</given-names></name>, <name><surname>Ghesu</surname><given-names>Florin C</given-names></name>, <name><surname>Miao</surname><given-names>Shun</given-names></name>, <name><surname>Maier</surname><given-names>Andreas K</given-names></name>, <name><surname>Ayache</surname><given-names>Nicholas</given-names></name>, <name><surname>Liao</surname><given-names>Rui</given-names></name>, and <name><surname>Kamen</surname><given-names>Ali</given-names></name>. <part-title>Robust non-rigid registration through agent-based action learning</part-title>. In <source>MICCAI: Medical Image Computing and Computer Assisted Interventions</source>, pages <fpage>344</fpage>‚Äì<lpage>352</lpage>. <publisher-name>Springer</publisher-name>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="R52">
      <mixed-citation publication-type="journal"><name><surname>Krebs</surname><given-names>Julian</given-names></name>, <name><surname>Delingette</surname><given-names>Herv√©</given-names></name>, <name><surname>Mailh√©</surname><given-names>Boris</given-names></name>, <name><surname>Ayache</surname><given-names>Nicholas</given-names></name>, and <name><surname>Mansi</surname><given-names>Tommaso</given-names></name>. <article-title>Learning a probabilistic model for diffeomorphic registration</article-title>. <source>IEEE Transactions on Medical Imaging</source>, <volume>38</volume>(<issue>9</issue>):<fpage>2165</fpage>‚Äì<lpage>2176</lpage>, <year>2019</year>.<pub-id pub-id-type="pmid">30716033</pub-id></mixed-citation>
    </ref>
    <ref id="R53">
      <mixed-citation publication-type="journal"><name><surname>Krueger</surname><given-names>David</given-names></name>, <name><surname>Huang</surname><given-names>Chin-Wei</given-names></name>, <name><surname>Islam</surname><given-names>Riashat</given-names></name>, <name><surname>Turner</surname><given-names>Ryan</given-names></name>, <name><surname>Lacoste</surname><given-names>Alexandre</given-names></name>, and <name><surname>Courville</surname><given-names>Aaron</given-names></name>. <article-title>Bayesian hypernetworks</article-title>. <source>arXiv</source><comment>preprint arXiv:1710.04759</comment>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="R54">
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>Lisha</given-names></name>, <name><surname>Jamieson</surname><given-names>Kevin</given-names></name>, <name><surname>DeSalvo</surname><given-names>Giulia</given-names></name>, <name><surname>Rostamizadeh</surname><given-names>Afshin</given-names></name>, and <name><surname>Talwalkar</surname><given-names>Ameet</given-names></name>. <article-title>Hyperband: A novel bandit-based approach to hyperparameter optimization</article-title>. <source>Journal of Machine Learning Research</source>, <volume>18</volume>(<issue>1</issue>):<fpage>6765</fpage>‚Äì<lpage>6816</lpage>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="R55">
      <mixed-citation publication-type="book"><name><surname>Li</surname><given-names>Yawei</given-names></name>, <name><surname>Gu</surname><given-names>Shuhang</given-names></name>, <name><surname>Zhang</surname><given-names>Kai</given-names></name>, <name><surname>Van Gool</surname><given-names>Luc</given-names></name>, and <name><surname>Timofte</surname><given-names>Radu</given-names></name>. <part-title>Dhp: Differentiable meta pruning via hypernetworks</part-title>. In <source>Computer Vision‚ÄìECCV 2020: 16th European Conference, Glasgow, UK, August 23‚Äì28, 2020, Proceedings, Part VIII 16</source>, pages <fpage>608</fpage>‚Äì<lpage>624</lpage>. <publisher-name>Springer</publisher-name>, <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="R56">
      <mixed-citation publication-type="confproc"><name><surname>Liu</surname><given-names>Zechun</given-names></name>, <name><surname>Mu</surname><given-names>Haoyuan</given-names></name>, <name><surname>Zhang</surname><given-names>Xiangyu</given-names></name>, <name><surname>Guo</surname><given-names>Zichao</given-names></name>, <name><surname>Yang</surname><given-names>Xin</given-names></name>, <name><surname>Cheng</surname><given-names>Kwang-Ting</given-names></name>, and <name><surname>Sun</surname><given-names>Jian</given-names></name>. <article-title>Metapruning: Meta learning for automatic neural network channel pruning</article-title>. In <conf-name>Proceedings of the IEEE/CVF International Conference on Computer Vision</conf-name>, pages <fpage>3296</fpage>‚Äì<lpage>3305</lpage>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="R57">
      <mixed-citation publication-type="journal"><name><surname>Lorraine</surname><given-names>Jonathan</given-names></name> and <name><surname>Duvenaud</surname><given-names>David</given-names></name>. <article-title>Stochastic hyperparameter optimization through hypernetworks</article-title>. <source>arXiv</source>
<comment>preprint arXiv:1802.09419</comment>, <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="R58">
      <mixed-citation publication-type="confproc"><name><surname>Luketina</surname><given-names>Jelena</given-names></name>, <name><surname>Berglund</surname><given-names>Mathias</given-names></name>, <name><surname>Greff</surname><given-names>Klaus</given-names></name>, and <name><surname>Raiko</surname><given-names>Tapani</given-names></name>. <article-title>Scalable gradient-based tuning of continuous regularization hyperparameters</article-title>. In <conf-name>ICML</conf-name>, pages <fpage>2952</fpage>‚Äì<lpage>2960</lpage>, <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="R59">
      <mixed-citation publication-type="journal"><name><surname>MacKay</surname><given-names>Matthew</given-names></name>, <name><surname>Vicol</surname><given-names>Paul</given-names></name>, <name><surname>Lorraine</surname><given-names>Jon</given-names></name>, <name><surname>Duvenaud</surname><given-names>David</given-names></name>, and <name><surname>Grosse</surname><given-names>Roger</given-names></name>. <article-title>Self-tuning networks: Bilevel optimization of hyperparameters using structured best-response functions</article-title>. <source>arXiv</source><comment>preprint arXiv:1903.03088</comment>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="R60">
      <mixed-citation publication-type="confproc"><name><surname>Maclaurin</surname><given-names>Dougal</given-names></name>, <name><surname>Duvenaud</surname><given-names>David</given-names></name>, and <name><surname>Adams</surname><given-names>Ryan</given-names></name>. <article-title>Gradient-based hyperparameter optimization through reversible learning</article-title>. In <conf-name>ICML</conf-name>, pages <fpage>2113</fpage>‚Äì<lpage>2122</lpage>, <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="R61">
      <mixed-citation publication-type="journal"><name><surname>Marcus</surname><given-names>Daniel S</given-names></name>, <name><surname>Wang</surname><given-names>Tracy H</given-names></name>, <name><surname>Parker</surname><given-names>Jamie</given-names></name>, <name><surname>Csernansky</surname><given-names>John G</given-names></name>, <name><surname>Morris</surname><given-names>John C</given-names></name>, and <name><surname>Buckner</surname><given-names>Randy L</given-names></name>. <article-title>Open access series of imaging studies (oasis): cross-sectional mri data in young, middle aged, nondemented, and demented older adults</article-title>. <source>Journal of cognitive neuroscience</source>, <volume>19</volume>(<issue>9</issue>):<fpage>1498</fpage>‚Äì<lpage>1507</lpage>, <year>2007</year>.<pub-id pub-id-type="pmid">17714011</pub-id></mixed-citation>
    </ref>
    <ref id="R62">
      <mixed-citation publication-type="journal"><name><surname>Marcus</surname><given-names>Daniel S</given-names></name>, <name><surname>Fotenos</surname><given-names>Anthony F</given-names></name>, <name><surname>Csernansky</surname><given-names>John G</given-names></name>, <name><surname>Morris</surname><given-names>John C</given-names></name>, and <name><surname>Buckner</surname><given-names>Randy L</given-names></name>. <article-title>Open access series of imaging studies: longitudinal mri data in nondemented and demented older adults</article-title>. <source>Journal of cognitive neuroscience</source>, <volume>22</volume>(<issue>12</issue>):<fpage>2677</fpage>‚Äì<lpage>2684</lpage>, <year>2010</year>.<pub-id pub-id-type="pmid">19929323</pub-id></mixed-citation>
    </ref>
    <ref id="R63">
      <mixed-citation publication-type="journal"><name><surname>Marek</surname><given-names>Kenneth</given-names></name>, <name><surname>Jennings</surname><given-names>Danna</given-names></name>, <name><surname>Lasch</surname><given-names>Shirley</given-names></name>, <name><surname>Siderowf</surname><given-names>Andrew</given-names></name>, <name><surname>Tanner</surname><given-names>Caroline</given-names></name>, <name><surname>Simuni</surname><given-names>Tanya</given-names></name>, <name><surname>Coffey</surname><given-names>Chris</given-names></name>, <name><surname>Kieburtz</surname><given-names>Karl</given-names></name>, <name><surname>Flagg</surname><given-names>Emily</given-names></name>, <name><surname>Chowdhury</surname><given-names>Sohini</given-names></name>, <etal/><article-title>The parkinson progression marker initiative (ppmi)</article-title>. <source>Progress in neurobiology</source>, <volume>95</volume>(<issue>4</issue>):<fpage>629</fpage>‚Äì<lpage>635</lpage>, <year>2011</year>.<pub-id pub-id-type="pmid">21930184</pub-id></mixed-citation>
    </ref>
    <ref id="R64">
      <mixed-citation publication-type="journal"><name><surname>Meyerson</surname><given-names>Elliot</given-names></name> and <name><surname>Miikkulainen</surname><given-names>Risto</given-names></name>. <article-title>Modular universal reparameterization: Deep multi-task learning across diverse domains</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>32</volume>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="R65">
      <mixed-citation publication-type="journal"><name><surname>Milham</surname><given-names>Michael P</given-names></name>, <name><surname>Fair</surname><given-names>Damien</given-names></name>, <name><surname>Mennes</surname><given-names>Maarten</given-names></name>, <name><surname>Mostofsky</surname><given-names>Stewart HMD</given-names></name>, <etal/><article-title>The adhd-200 consortium: a model to advance the translational potential of neuroimaging in clinical neuroscience</article-title>. <source>Frontiers in systems neuroscience</source>, <volume>6</volume>:<fpage>62</fpage>, <year>2012</year>.<pub-id pub-id-type="pmid">22973200</pub-id></mixed-citation>
    </ref>
    <ref id="R66">
      <mixed-citation publication-type="journal"><name><surname>Miller</surname><given-names>Michael I</given-names></name>, <name><surname>Beg</surname><given-names>M Faisal</given-names></name>, <name><surname>Ceritoglu</surname><given-names>Can</given-names></name>, and <name><surname>Stark</surname><given-names>Craig</given-names></name>. <article-title>Increasing the power of functional maps of the medial temporal lobe by using large deformation diffeomorphic metric mapping</article-title>. <source>PNAS</source>, <volume>102</volume>(<issue>27</issue>):<fpage>9685</fpage>‚Äì<lpage>9690</lpage>, <year>2005</year>.<pub-id pub-id-type="pmid">15980148</pub-id></mixed-citation>
    </ref>
    <ref id="R67">
      <mixed-citation publication-type="journal"><name><surname>Mockus</surname><given-names>Jonas</given-names></name>, <name><surname>Tiesis</surname><given-names>Vytautas</given-names></name>, and <name><surname>Zilinskas</surname><given-names>Antanas</given-names></name>. <article-title>The application of bayesian methods for seeking the extremum</article-title>. <source>Towards Global Optimization</source>, <volume>2</volume>(<issue>117‚Äì129</issue>):<fpage>2</fpage>, <year>1978</year>.</mixed-citation>
    </ref>
    <ref id="R68">
      <mixed-citation publication-type="journal"><name><surname>Modat</surname><given-names>Marc</given-names></name>, <name><surname>Ridgway</surname><given-names>Gerard R</given-names></name>, <name><surname>Taylor</surname><given-names>Zeike A</given-names></name>, <name><surname>Lehmann</surname><given-names>Manja</given-names></name>, <name><surname>Barnes</surname><given-names>Josephine</given-names></name>, <name><surname>Hawkes</surname><given-names>David J</given-names></name>, <name><surname>Fox</surname><given-names>Nick C</given-names></name>, and <name><surname>Ourselin</surname><given-names>S√©bastien</given-names></name>. <article-title>Fast free-form deformation using graphics processing units</article-title>. <source>Computer methods and programs in biomedicine</source>, <volume>98</volume>(<issue>3</issue>):<fpage>278</fpage>‚Äì<lpage>284</lpage>, <year>2010</year>.<pub-id pub-id-type="pmid">19818524</pub-id></mixed-citation>
    </ref>
    <ref id="R69">
      <mixed-citation publication-type="book"><name><surname>Mok</surname><given-names>Tony CW</given-names></name> and <name><surname>Chung</surname><given-names>Albert</given-names></name>. <part-title>Conditional deformable image registration with convolutional neural network</part-title>. In <source>MICCAI: Medical Image Computing and Computer Assisted Interventions</source>, pages <fpage>35</fpage>‚Äì<lpage>45</lpage>. <publisher-name>Springer</publisher-name>, <year>2021</year>.</mixed-citation>
    </ref>
    <ref id="R70">
      <mixed-citation publication-type="confproc"><name><surname>Mok</surname><given-names>Tony CW</given-names></name> and <name><surname>Chung</surname><given-names>Albert CS</given-names></name>. <article-title>Large deformation diffeomorphic image registration with laplacian pyramid networks</article-title>. In <conf-name>MICCAI: Medical Image Computing and Computer Assisted Interventions</conf-name>, pages <fpage>211</fpage>‚Äì<lpage>221</lpage>, <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="R71">
      <mixed-citation publication-type="journal"><name><surname>Paszke</surname><given-names>Adam</given-names></name>, <name><surname>Gross</surname><given-names>Sam</given-names></name>, <name><surname>Massa</surname><given-names>Francisco</given-names></name>, <name><surname>Lerer</surname><given-names>Adam</given-names></name>, <name><surname>Bradbury</surname><given-names>James</given-names></name>, <name><surname>Chanan</surname><given-names>Gregory</given-names></name>, <name><surname>Killeen</surname><given-names>Trevor</given-names></name>, <name><surname>Lin</surname><given-names>Zeming</given-names></name>, <name><surname>Gimelshein</surname><given-names>Natalia</given-names></name>, <name><surname>Antiga</surname><given-names>Luca</given-names></name>, <etal/><article-title>Pytorch: An imperative style, high-performance deep learning library</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>32</volume>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="R72">
      <mixed-citation publication-type="journal"><name><surname>Patenaude</surname><given-names>Brian</given-names></name>, <name><surname>Smith</surname><given-names>Stephen M</given-names></name>, <name><surname>Kennedy</surname><given-names>David N</given-names></name>, and <name><surname>Jenkinson</surname><given-names>Mark</given-names></name>. <article-title>A bayesian model of shape and appearance for subcortical brain segmentation</article-title>. <source>Neuroimage</source>, <volume>56</volume>(<issue>3</issue>): <fpage>907</fpage>‚Äì<lpage>922</lpage>, <year>2011</year>.<pub-id pub-id-type="pmid">21352927</pub-id></mixed-citation>
    </ref>
    <ref id="R73">
      <mixed-citation publication-type="journal"><name><surname>Pedregosa</surname><given-names>Fabian</given-names></name>. <article-title>Hyperparameter optimization with approximate gradient</article-title>. <source>arXiv</source><comment>preprint arXiv:1602.02355</comment>, <year>2016</year>.</mixed-citation>
    </ref>
    <ref id="R74">
      <mixed-citation publication-type="journal"><name><surname>Puonti</surname><given-names>Oula</given-names></name>, <name><surname>Iglesias</surname><given-names>Juan Eugenio</given-names></name>, and <name><surname>Van Leemput</surname><given-names>Koen</given-names></name>. <article-title>Fast and sequence-adaptive whole-brain segmentation using parametric bayesian modeling</article-title>. <source>NeuroImage</source>, <volume>143</volume>:<fpage>235</fpage>‚Äì<lpage>249</lpage>, <year>2016</year>.<pub-id pub-id-type="pmid">27612647</pub-id></mixed-citation>
    </ref>
    <ref id="R75">
      <mixed-citation publication-type="book"><name><surname>Ratzlaff</surname><given-names>Neale</given-names></name> and <name><surname>Fuxin</surname><given-names>Li</given-names></name>. <part-title>Hypergan: A generative model for diverse, performant neural networks</part-title>. In <source>International Conference on Machine Learning</source>, pages <fpage>5361</fpage>‚Äì<lpage>5369</lpage>. <publisher-name>PMLR</publisher-name>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="R76">
      <mixed-citation publication-type="book"><name><surname>Roh√©</surname><given-names>Marc-Michel</given-names></name>, <name><surname>Datar</surname><given-names>Manasi</given-names></name>, <name><surname>Heimann</surname><given-names>Tobias</given-names></name>, <name><surname>Sermesant</surname><given-names>Maxime</given-names></name>, and <name><surname>Pennec</surname><given-names>Xavier</given-names></name>. <part-title>Svf-net: Learning deformable image registration using shape matching</part-title>. In <source>MICCAI: Medical Image Computing and Computer Assisted Interventions</source>, pages <fpage>266</fpage>‚Äì<lpage>274</lpage>. <publisher-name>Springer</publisher-name>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="R77">
      <mixed-citation publication-type="book"><name><surname>Ronneberger</surname><given-names>Olaf</given-names></name>, <name><surname>Fischer</surname><given-names>Philipp</given-names></name>, and <name><surname>Brox</surname><given-names>Thomas</given-names></name>. <part-title>U-net: Convolutional networks for biomedical image segmentation</part-title>. In <source>MICCAI: Medical Image Computing and Computer Assisted Interventions</source>, pages <fpage>234</fpage>‚Äì<lpage>241</lpage>. <publisher-name>Springer</publisher-name>, <year>2015</year>.</mixed-citation>
    </ref>
    <ref id="R78">
      <mixed-citation publication-type="journal"><name><surname>Rueckert</surname><given-names>Daniel</given-names></name>, <name><surname>Sonoda</surname><given-names>Luke I</given-names></name>, <name><surname>Hayes</surname><given-names>Carmel</given-names></name>, <name><surname>Hill</surname><given-names>Derek LG</given-names></name>, <name><surname>Leach</surname><given-names>Martin O</given-names></name>, and <name><surname>Hawkes</surname><given-names>David J</given-names></name>. <article-title>Nonrigid registration using free-form deformation: Application to breast mr images</article-title>. <source>IEEE Transactions on Medical Imaging</source>, <volume>18</volume>(<issue>8</issue>):<fpage>712</fpage>‚Äì<lpage>721</lpage>, <year>1999</year>.<pub-id pub-id-type="pmid">10534053</pub-id></mixed-citation>
    </ref>
    <ref id="R79">
      <mixed-citation publication-type="confproc"><name><surname>Schmidhuber</surname><given-names>J√ºrgen</given-names></name>. <article-title>A self-referential weight matrix</article-title>. In <conf-name>International Conference on Artificial Neural Networks</conf-name>, pages <fpage>446</fpage>‚Äì<lpage>450</lpage>, <year>1993</year>.</mixed-citation>
    </ref>
    <ref id="R80">
      <mixed-citation publication-type="journal"><name><surname>Shamonin</surname><given-names>Denis</given-names></name>, <name><surname>Bron</surname><given-names>Esther</given-names></name>, <name><surname>Lelieveldt</surname><given-names>Boudewijn</given-names></name>, <name><surname>Smits</surname><given-names>Marion</given-names></name>, <name><surname>Klein</surname><given-names>Stefan</given-names></name>, and <name><surname>Staring</surname><given-names>Marius</given-names></name>. <article-title>Fast parallel image registration on cpu and gpu for diagnostic classification of alzheimer‚Äôs disease</article-title>. <source>Frontiers in Neuroinformatics</source>, <volume>7</volume>:<fpage>50</fpage>, <year>2014</year>.<pub-id pub-id-type="pmid">24474917</pub-id></mixed-citation>
    </ref>
    <ref id="R81">
      <mixed-citation publication-type="journal"><name><surname>Snoek</surname><given-names>Jasper</given-names></name>, <name><surname>Larochelle</surname><given-names>Hugo</given-names></name>, and <name><surname>Adams</surname><given-names>Ryan P</given-names></name>. <article-title>Practical bayesian optimization of machine learning algorithms</article-title>. <source>Advances in neural information processing systems</source>, <volume>25</volume>, <year>2012</year>.</mixed-citation>
    </ref>
    <ref id="R82">
      <mixed-citation publication-type="book"><name><surname>Sokooti</surname><given-names>Hessam</given-names></name>, <name><surname>de Vos</surname><given-names>Bob</given-names></name>, <name><surname>Berendsen</surname><given-names>Floris</given-names></name>, <name><surname>Lelieveldt</surname><given-names>Boudewijn PF</given-names></name>, <name><surname>I≈°gum</surname><given-names>Ivana</given-names></name>, and <name><surname>Staring</surname><given-names>Marius</given-names></name>. <part-title>Nonrigid image registration using multi-scale 3d convolutional neural networks</part-title>. In <source>MICCAI: Medical Image Computing and Computer Assisted Interventions</source>, pages <fpage>232</fpage>‚Äì<lpage>239</lpage>. <publisher-name>Springer</publisher-name>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="R83">
      <mixed-citation publication-type="journal"><name><surname>Spurek</surname><given-names>Przemys law</given-names></name>, <name><surname>Winczowski</surname><given-names>Sebastian</given-names></name>, <name><surname>Tabor</surname><given-names>Jacek</given-names></name>, <name><surname>Zamorski</surname><given-names>Maciej</given-names></name>, <name><surname>Zieba</surname><given-names>Maciej</given-names></name>, and <name><surname>Trzci≈Ñski</surname><given-names>Tomasz</given-names></name>. <article-title>Hypernetwork approach to generating point clouds</article-title>. <source>arXiv</source><comment>preprint arXiv:2003.00802</comment>, <year>2020</year>.</mixed-citation>
    </ref>
    <ref id="R84">
      <mixed-citation publication-type="journal"><name><surname>Sudlow</surname><given-names>Cathie</given-names></name>, <name><surname>Gallacher</surname><given-names>John</given-names></name>, <name><surname>Allen</surname><given-names>Naomi</given-names></name>, <name><surname>Beral</surname><given-names>Valerie</given-names></name>, <name><surname>Burton</surname><given-names>Paul</given-names></name>, <name><surname>Danesh</surname><given-names>John</given-names></name>, <name><surname>Downey</surname><given-names>Paul</given-names></name>, <name><surname>Elliott</surname><given-names>Paul</given-names></name>, <name><surname>Green</surname><given-names>Jane</given-names></name>, <name><surname>Landray</surname><given-names>Martin</given-names></name>, <etal/><article-title>Uk biobank: an open access resource for identifying the causes of a wide range of complex diseases of middle and old age</article-title>. <source>PLOS Medicine</source>, <volume>12</volume>(<issue>3</issue>):<fpage>e1001779</fpage>, <year>2015</year>.<pub-id pub-id-type="pmid">25826379</pub-id></mixed-citation>
    </ref>
    <ref id="R85">
      <mixed-citation publication-type="book"><name><surname>Ukai</surname><given-names>Kenya</given-names></name>, <name><surname>Matsubara</surname><given-names>Takashi</given-names></name>, and <name><surname>Uehara</surname><given-names>Kuniaki</given-names></name>. <part-title>Hypernetwork-based implicit posterior estimation and model averaging of cnn</part-title>. In <source>Asian Conference on Machine Learning</source>, pages <fpage>176</fpage>‚Äì<lpage>191</lpage>. <publisher-name>PMLR</publisher-name>, <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="R86">
      <mixed-citation publication-type="journal"><name><surname>Vercauteren</surname><given-names>Tom</given-names></name>, <name><surname>Pennec</surname><given-names>Xavier</given-names></name>, <name><surname>Perchant</surname><given-names>Aymeric</given-names></name>, and <name><surname>Ayache</surname><given-names>Nicholas</given-names></name>. <article-title>Diffeomorphic demons: Efficient non-parametric image registration</article-title>. <source>NeuroImage</source>, <volume>45</volume>(<issue>1</issue>):<fpage>S61</fpage>‚Äì<lpage>S72</lpage>, <year>2009</year>.<pub-id pub-id-type="pmid">19041946</pub-id></mixed-citation>
    </ref>
    <ref id="R87">
      <mixed-citation publication-type="journal"><name><surname>Viola</surname><given-names>Paul</given-names></name> and <name><surname>Wells</surname><given-names>William M</given-names><suffix>III</suffix></name>. <article-title>Alignment by maximization of mutual information</article-title>. <source>International Journal of Computer Vision</source>, <volume>24</volume>(<issue>2</issue>):<fpage>137</fpage>‚Äì<lpage>54</lpage>, <year>1997</year>.</mixed-citation>
    </ref>
    <ref id="R88">
      <mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>Alan Q</given-names></name>, <name><surname>Dalca</surname><given-names>Adrian V</given-names></name>, and <name><surname>Sabuncu</surname><given-names>Mert R</given-names></name>. <article-title>Hyperrecon: Regularization-agnostic cs-mri reconstruction with hypernetworks</article-title>. <source>Machine Learning for Medical Image Reconstruction</source>, pages <fpage>3</fpage>‚Äì<lpage>13</lpage>, <year>2021</year>.</mixed-citation>
    </ref>
    <ref id="R89">
      <mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>Hongzhi</given-names></name>, <name><surname>Suh</surname><given-names>Jung W</given-names></name>, <name><surname>Das</surname><given-names>Sandhitsu R</given-names></name>, <name><surname>Pluta</surname><given-names>John B</given-names></name>, <name><surname>Craige</surname><given-names>Caryne</given-names></name>, and <name><surname>Yushkevich</surname><given-names>Paul A</given-names></name>. <article-title>Multi-atlas segmentation with joint label fusion</article-title>. <source>IEEE transactions on pattern analysis and machine intelligence</source>, <volume>35</volume>(<issue>3</issue>):<fpage>611</fpage>‚Äì<lpage>623</lpage>, <year>2012</year>.<pub-id pub-id-type="pmid">22732662</pub-id></mixed-citation>
    </ref>
    <ref id="R90">
      <mixed-citation publication-type="journal"><name><surname>Wu</surname><given-names>Guorong</given-names></name>, <name><surname>Kim</surname><given-names>Minjeong</given-names></name>, <name><surname>Wang</surname><given-names>Qian</given-names></name>, <name><surname>Munsell</surname><given-names>Brent C</given-names></name>, and <name><surname>Shen</surname><given-names>Dinggang</given-names></name>. <article-title>Scalable high-performance image registration framework by unsupervised deep feature representations learning</article-title>. <source>IEEE Transactions on Biomedical Engineering</source>, <volume>63</volume>(<issue>7</issue>):<fpage>1505</fpage>‚Äì<lpage>1516</lpage>, <year>2015</year>.<pub-id pub-id-type="pmid">26552069</pub-id></mixed-citation>
    </ref>
    <ref id="R91">
      <mixed-citation publication-type="journal"><name><surname>Yang</surname><given-names>Xiao</given-names></name>, <name><surname>Kwitt</surname><given-names>Roland</given-names></name>, <name><surname>Styner</surname><given-names>Martin</given-names></name>, and <name><surname>Niethammer</surname><given-names>Marc</given-names></name>. <article-title>Quicksilver: Fast predictive image registration ‚Äì a deep learning approach</article-title>. <source>NeuroImage</source>, <volume>158</volume>:<fpage>378</fpage>‚Äì<lpage>396</lpage>, <year>2017</year>.<pub-id pub-id-type="pmid">28705497</pub-id></mixed-citation>
    </ref>
    <ref id="R92">
      <mixed-citation publication-type="book"><name><surname>Zhang</surname><given-names>Miaomiao</given-names></name>, <name><surname>Liao</surname><given-names>Ruizhi</given-names></name>, <name><surname>Dalca</surname><given-names>Adrian V</given-names></name>, <name><surname>Turk</surname><given-names>Esra A</given-names></name>, <name><surname>Luo</surname><given-names>Jie</given-names></name>, <name><surname>Grant</surname><given-names>P Ellen</given-names></name>, and <name><surname>Golland</surname><given-names>Polina</given-names></name>. <part-title>Frequency diffeomorphisms for efficient image registration</part-title>. In <source>IPMI: Information Processing in Medical Imaging</source>, pages <fpage>559</fpage>‚Äì<lpage>570</lpage>. <publisher-name>Springer</publisher-name>, <year>2017</year>.</mixed-citation>
    </ref>
    <ref id="R93">
      <mixed-citation publication-type="confproc"><name><surname>Zhao</surname><given-names>Shengyu</given-names></name>, <name><surname>Dong</surname><given-names>Yue</given-names></name>, <name><surname>Eric I Chang</surname><given-names>Yan Xu</given-names></name>, <etal/><article-title>Recursive cascaded networks for unsupervised medical image registration</article-title>. In <conf-name>Proceedings of the IEEE/CVF International Conference on Computer Vision</conf-name>, pages <fpage>10600</fpage>‚Äì<lpage>10610</lpage>, <year>2019</year>.</mixed-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig position="float" id="F1">
    <label>Figure 1:</label>
    <caption>
      <p id="P79">Traditional hyperparameter search strategies (left) involve the optimization of multiple registration models (that predict a deformation <italic toggle="yes">œï</italic> for an input image pair <italic toggle="yes">m</italic>, <italic toggle="yes">f</italic>) using different hyperparameter values (<italic toggle="yes">Œª</italic>) and often require repeating the search for finer hyperparameter resolutions or different ranges. The HyperMorph strategy (right) trains a <italic toggle="yes">single</italic> network that approximates a landscape of traditional models and can be evaluated for any hyperparameter value at test-time.</p>
    </caption>
    <graphic xlink:href="nihms-1835691-f0001" position="float"/>
  </fig>
  <fig position="float" id="F2">
    <label>Figure 2:</label>
    <caption>
      <p id="P80">The HyperMorph architecture comprises a hypernetwork <inline-formula><mml:math id="M1" display="inline"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>Œõ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> that takes registration hyperparameters Œõ as input and estimates the parameters of a primary registration network <inline-formula><mml:math id="M2" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. HyperMorph is trained end-to-end as a single model with a continuous range of hyperparameter values, capitalizing on the implicit weight-sharing that captures the redundancy that exists amongst a landscape of registration networks.</p>
    </caption>
    <graphic xlink:href="nihms-1835691-f0002" position="float"/>
  </fig>
  <fig position="float" id="F3">
    <label>Figure 3:</label>
    <caption>
      <p id="P81">Alternative model architectures for learning the effect of registration hyperparameters. In these approaches, the hyperparameters Œõ are provided as input to an auxiliary convolutional network <inline-formula><mml:math id="M3" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (blue), which is integrated directly with the primary registration network <inline-formula><mml:math id="M4" display="inline"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>g</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (grey). The output of <inline-formula><mml:math id="M5" display="inline"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:msub><mml:mi>Œ∏</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is either added to the output channels of the registration U-Net (full-integrative model) or provided as an additional input to the first layer (pre-integrative model) or last upsampling layer (post-integrative model).</p>
    </caption>
    <graphic xlink:href="nihms-1835691-f0003" position="float"/>
  </fig>
  <fig position="float" id="F4">
    <label>Figure 4:</label>
    <caption>
      <p id="P82">Mean Dice scores achieved by a single HyperMorph model (blue) and baselines trained for different regularization weights <italic toggle="yes">Œª</italic> (grey) when using MSE, NCC, or MI similarity metrics.</p>
    </caption>
    <graphic xlink:href="nihms-1835691-f0004" position="float"/>
  </fig>
  <fig position="float" id="F5">
    <label>Figure 5:</label>
    <caption>
      <p id="P83">Mean 95th percentile surface distances achieved by a single HyperMorph model (blue) and baselines trained for different regularization weights <italic toggle="yes">Œª</italic> (grey) when using MSE, NCC, or MI similarity metrics.</p>
    </caption>
    <graphic xlink:href="nihms-1835691-f0005" position="float"/>
  </fig>
  <fig position="float" id="F6">
    <label>Figure 6:</label>
    <caption>
      <p id="P84">Left: visual comparison of HyperMorph (HM) and baseline model registration deformations on a mesh grid, illustrating similar changes in regularity across <italic toggle="yes">Œª</italic> values. Right: representative changes in feature activations of the final layer in the HyperMorph U-Net for different regularization weights.</p>
    </caption>
    <graphic xlink:href="nihms-1835691-f0006" position="float"/>
  </fig>
  <fig position="float" id="F7">
    <label>Figure 7:</label>
    <caption>
      <p id="P85">Two-dimensional hyperparameter search for semi-supervised registration with regularization hyperparameter <italic toggle="yes">Œª</italic> and segmentation weight <italic toggle="yes">Œ≥</italic>. For a set of 50 test pairs, the cross markers indicate the optimal <italic toggle="yes">Œª</italic>, <italic toggle="yes">Œ≥</italic> values determined by HyperMorph and a baseline grid search. We compute total Dice using both sets of training and held-out labels. While the left hyperparameter space is illustrated on a discrete grid for visualization, HyperMorph enables evaluating the effect of hyperparameter values at arbitrarily fine resolution.</p>
    </caption>
    <graphic xlink:href="nihms-1835691-f0007" position="float"/>
  </fig>
  <fig position="float" id="F8">
    <label>Figure 8:</label>
    <caption>
      <p id="P86">Two-dimensional hyperparameter search for unsupervised registration with regularization weight <italic toggle="yes">Œª</italic> and local NCC window size <italic toggle="yes">w</italic>. For a set of 50 test pairs, the cross markers indicate the optimal <italic toggle="yes">Œª</italic>, <italic toggle="yes">w</italic> values determined by HyperMorph and a baseline grid search. HyperMorph is able to identify the optimal <italic toggle="yes">Œª</italic>, <italic toggle="yes">w</italic> value pair missed by a traditional grid search.</p>
    </caption>
    <graphic xlink:href="nihms-1835691-f0008" position="float"/>
  </fig>
  <fig position="float" id="F9">
    <label>Figure 9:</label>
    <caption>
      <p id="P87">Variability across several training initializations for HyperMorph and baseline models. Error bars and fill regions span a 2-<italic toggle="yes">œÉ</italic> range around the mean registration accuracy, which is substantially tighter for HyperMorph.</p>
    </caption>
    <graphic xlink:href="nihms-1835691-f0009" position="float"/>
  </fig>
  <fig position="float" id="F10">
    <label>Figure 10:</label>
    <caption>
      <p id="P88">Registration accuracy across dataset subpopulations (A), image contrasts (B), tasks (C), and neuroanatomical regions (D). The cross markers indicate the optimal value <italic toggle="yes">Œª</italic>* as identified by automatic hyperparameter optimization.</p>
    </caption>
    <graphic xlink:href="nihms-1835691-f0010" position="float"/>
  </fig>
  <fig position="float" id="F11">
    <label>Figure 11:</label>
    <caption>
      <p id="P89">Analysis showing registration accuracy in terms of Dice overlap for HyperMorph models trained with different hypernetwork sizes (A), end-point sampling rates <italic toggle="yes">r</italic> (B), and HyperMorph strategies (C).</p>
    </caption>
    <graphic xlink:href="nihms-1835691-f0011" position="float"/>
  </fig>
  <fig position="float" id="F12">
    <label>Figure 12:</label>
    <caption>
      <p id="P90">Registration accuracy (Dice) achieved by HyperMorph models trained for different values of estimated image noise <italic toggle="yes">œÉ</italic><sup>‚àí2</sup>.</p>
    </caption>
    <graphic xlink:href="nihms-1835691-f0012" position="float"/>
  </fig>
  <table-wrap position="float" id="T1">
    <label>Table 1:</label>
    <caption>
      <p id="P91">Three groups of image datasets are used throughout the experiments and split into train, validate, and test subsets of specified size.</p>
    </caption>
    <table frame="hsides" rules="cols">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr style="border-bottom: solid 1px">
          <th align="center" valign="top" rowspan="1" colspan="1">Group</th>
          <th align="center" valign="top" rowspan="1" colspan="1">Train</th>
          <th align="center" valign="top" rowspan="1" colspan="1">Validate</th>
          <th align="center" valign="top" rowspan="1" colspan="1">Test</th>
          <th align="center" valign="top" rowspan="1" colspan="1">Datasets</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Within-contrast</td>
          <td align="center" valign="top" rowspan="1" colspan="1">7,400</td>
          <td align="center" valign="top" rowspan="1" colspan="1">5,000</td>
          <td align="center" valign="top" rowspan="1" colspan="1">5,030</td>
          <td align="left" valign="top" rowspan="1" colspan="1">ABIDE (<xref rid="R25" ref-type="bibr">Di Martino et al., 2014</xref>)</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">ADHD-200 (<xref rid="R65" ref-type="bibr">Milham et al., 2012</xref>)</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">GSP (<xref rid="R19" ref-type="bibr">Dagley et al., 2017</xref>)</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">MCIC (<xref rid="R37" ref-type="bibr">Gollub et al., 2013</xref>)</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">OASIS-1 (<xref rid="R61" ref-type="bibr">Marcus et al., 2007</xref>)</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">PPMI (<xref rid="R63" ref-type="bibr">Marek et al., 2011</xref>)</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">UK Biobank (<xref rid="R84" ref-type="bibr">Sudlow et al., 2015</xref>)</td>
        </tr>
        <tr style="border-bottom: solid 1px">
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">Buckner40 (<xref rid="R32" ref-type="bibr">Fischl et al., 2002</xref>)</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Multi-contrast</td>
          <td align="center" valign="top" rowspan="1" colspan="1">496</td>
          <td align="center" valign="top" rowspan="1" colspan="1">496</td>
          <td align="center" valign="top" rowspan="1" colspan="1">496</td>
          <td align="left" valign="top" rowspan="1" colspan="1">HCP (<xref rid="R13" ref-type="bibr">Bookheimer et al., 2019</xref>)</td>
        </tr>
        <tr style="border-bottom: solid 1px">
          <td align="left" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="center" valign="top" rowspan="1" colspan="1"/>
          <td align="left" valign="top" rowspan="1" colspan="1">FSM (in-house data)</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="1" colspan="1">Longitudinal</td>
          <td align="center" valign="top" rowspan="1" colspan="1">48</td>
          <td align="center" valign="top" rowspan="1" colspan="1">48</td>
          <td align="center" valign="top" rowspan="1" colspan="1">48</td>
          <td align="left" valign="top" rowspan="1" colspan="1">OASIS-2 (<xref rid="R62" ref-type="bibr">Marcus et al., 2010</xref>)</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="T2">
    <label>Table 2:</label>
    <caption>
      <p id="P92">Total train time (left) and model variability across random initializations (right) for HyperMorph and baseline grid search techniques. Train time for the 2 hyp. (<italic toggle="yes">Œª</italic>,<italic toggle="yes">w</italic>) experiment is substantially faster as it was conducted using 2D image slices as opposed to 3D volumes.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <colgroup span="1">
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
        <col align="left" valign="middle" span="1"/>
      </colgroup>
      <thead>
        <tr>
          <th align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1"/>
          <th colspan="3" align="center" valign="top" style="border-right: solid 1px" rowspan="1">Train time (total GPU-hours)</th>
          <th colspan="2" align="center" valign="top" rowspan="1">Variability (SD)</th>
        </tr>
        <tr>
          <th align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1"/>
          <th align="center" valign="top" rowspan="1" colspan="1">1 hyp. (<italic toggle="yes">Œª</italic>)</th>
          <th align="center" valign="top" rowspan="1" colspan="1">2 hyp. (<italic toggle="yes">Œª</italic>, <italic toggle="yes">Œ≥</italic>)</th>
          <th align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">2 hyp. (<italic toggle="yes">Œª</italic>,<italic toggle="yes">w</italic>)</th>
          <th align="center" valign="top" rowspan="1" colspan="1">MSE</th>
          <th align="center" valign="top" rowspan="1" colspan="1">MI</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">HyperMorph</td>
          <td align="center" valign="top" rowspan="1" colspan="1">
            <bold>192.5 ¬± 23.1</bold>
          </td>
          <td align="center" valign="top" rowspan="1" colspan="1">
            <bold>321.9 ¬± 16.1</bold>
          </td>
          <td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">
            <bold>4.0 ¬± 0.1</bold>
          </td>
          <td align="center" valign="top" rowspan="1" colspan="1">
            <bold>0.100</bold>
          </td>
          <td align="center" valign="top" rowspan="1" colspan="1">
            <bold>0.127</bold>
          </td>
        </tr>
        <tr>
          <td align="left" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">Baseline</td>
          <td align="center" valign="top" rowspan="1" colspan="1">1,174.9 ¬± 196.1</td>
          <td align="center" valign="top" rowspan="1" colspan="1">4,120.5 ¬± 295.4</td>
          <td align="center" valign="top" style="border-right: solid 1px" rowspan="1" colspan="1">46.8 ¬± 5.7</td>
          <td align="center" valign="top" rowspan="1" colspan="1">0.176</td>
          <td align="center" valign="top" rowspan="1" colspan="1">0.325</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</floats-group>
