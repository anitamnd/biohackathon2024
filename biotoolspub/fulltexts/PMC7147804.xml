<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS Comput. Biol</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-id journal-id-type="pmc">ploscomp</journal-id>
    <journal-title-group>
      <journal-title>PLoS Computational Biology</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1553-734X</issn>
    <issn pub-type="epub">1553-7358</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7147804</article-id>
    <article-id pub-id-type="pmid">32231351</article-id>
    <article-id pub-id-type="publisher-id">PCOMPBIOL-D-19-02007</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pcbi.1007747</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Human Factors Engineering</subject>
          <subj-group>
            <subject>Man-Computer Interface</subject>
            <subj-group>
              <subject>Virtual Reality</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Computer Architecture</subject>
          <subj-group>
            <subject>User Interfaces</subject>
            <subj-group>
              <subject>Virtual Reality</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Computer Software</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Chemistry</subject>
          <subj-group>
            <subject>Chemical Physics</subject>
            <subj-group>
              <subject>Molecular Structure</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Physics</subject>
          <subj-group>
            <subject>Chemical Physics</subject>
            <subj-group>
              <subject>Molecular Structure</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Computer Architecture</subject>
          <subj-group>
            <subject>Computer Hardware</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Computer Software</subject>
          <subj-group>
            <subject>Open Source Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Science Policy</subject>
        <subj-group>
          <subject>Open Science</subject>
          <subj-group>
            <subject>Open Source Software</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Protein Interactions</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Engineering and Technology</subject>
        <subj-group>
          <subject>Mechanical Engineering</subject>
          <subj-group>
            <subject>Engines</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Molecular Biology</subject>
          <subj-group>
            <subject>Macromolecular Structure Analysis</subject>
            <subj-group>
              <subject>Protein Structure</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Protein Structure</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>ProteinVR: Web-based molecular visualization in virtual reality</article-title>
      <alt-title alt-title-type="running-head">ProteinVR</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Cassidy</surname>
          <given-names>Kevin C.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Investigation</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Visualization</role>
        <role content-type="http://credit.casrai.org/">Writing – original draft</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Šefčík</surname>
          <given-names>Jan</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Visualization</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-1285-6397</contrib-id>
        <name>
          <surname>Raghav</surname>
          <given-names>Yogindra</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-3822-0469</contrib-id>
        <name>
          <surname>Chang</surname>
          <given-names>Alexander</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5808-4097</contrib-id>
        <name>
          <surname>Durrant</surname>
          <given-names>Jacob D.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Data curation</role>
        <role content-type="http://credit.casrai.org/">Formal analysis</role>
        <role content-type="http://credit.casrai.org/">Funding acquisition</role>
        <role content-type="http://credit.casrai.org/">Investigation</role>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Project administration</role>
        <role content-type="http://credit.casrai.org/">Resources</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Visualization</role>
        <role content-type="http://credit.casrai.org/">Writing – original draft</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Department of Biological Sciences, University of Pittsburgh, Pittsburgh, Pennsylvania, United States of America</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Faculty of Information Technology, Czech Technical University in Prague, Prague, Czech Republic</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Schneidman-Duhovny</surname>
          <given-names>Dina</given-names>
        </name>
        <role>Editor</role>
        <xref ref-type="aff" rid="edit1"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Hebrew University of Jerusalem, ISRAEL</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>durrantj@pitt.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>3</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>31</day>
      <month>3</month>
      <year>2020</year>
    </pub-date>
    <volume>16</volume>
    <issue>3</issue>
    <elocation-id>e1007747</elocation-id>
    <history>
      <date date-type="received">
        <day>25</day>
        <month>11</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>25</day>
        <month>2</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2020 Cassidy et al</copyright-statement>
      <copyright-year>2020</copyright-year>
      <copyright-holder>Cassidy et al</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pcbi.1007747.pdf"/>
    <abstract>
      <p>Protein structure determines biological function. Accurately conceptualizing 3D protein/ligand structures is thus vital to scientific research and education. Virtual reality (VR) enables protein visualization in stereoscopic 3D, but many VR molecular-visualization programs are expensive and challenging to use; work only on specific VR headsets; rely on complicated model-preparation software; and/or require the user to install separate programs or plugins. Here we introduce ProteinVR, a web-based application that works on various VR setups and operating systems. ProteinVR displays molecular structures within 3D environments that give useful biological context and allow users to situate themselves in 3D space. Our web-based implementation is ideal for hypothesis generation and education in research and large-classroom settings. We release ProteinVR under the open-source BSD-3-Clause license. A copy of the program is available free of charge from <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/protein-vr/">http://durrantlab.com/protein-vr/</ext-link>, and a working version can be accessed at <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/pvr/">http://durrantlab.com/pvr/</ext-link>.</p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>Proteins are microscopic machines that help maintain, defend, and regulate cells. Properly understanding the three-dimensional structures of these machines–as well as the small molecules that interact with them–can advance scientific fields ranging from basic molecular biology to drug discovery. Virtual reality (VR) is a powerful tool for studying protein structures. But many current systems for viewing molecules in VR, though effective, have challenging usability limitations. We have created a new web application called ProteinVR that overcomes these challenges. ProteinVR enables VR molecular visualization in users’ browsers, without requiring them to install a separate program or plugin. It runs on a broad range of desktop, laptop, and mobile devices. For users without VR headsets, ProteinVR leverages mobile-device orientation sensors or video-game-style keyboard navigation to provide an immersive experience. We release ProteinVR as open-source software and have posted a working version at <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/pvr/">http://durrantlab.com/pvr/</ext-link>.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000002</institution-id>
            <institution>National Institutes of Health</institution>
          </institution-wrap>
        </funding-source>
        <award-id>R01GM132353</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5808-4097</contrib-id>
          <name>
            <surname>Durrant</surname>
            <given-names>Jacob Devin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <award-group id="award002">
        <funding-source>
          <institution>University of Pittsburgh</institution>
        </funding-source>
        <award-id>2017 Innovation in Education Award</award-id>
        <principal-award-recipient>
          <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5808-4097</contrib-id>
          <name>
            <surname>Durrant</surname>
            <given-names>Jacob Devin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
      <funding-statement>We acknowledge the University of Pittsburgh’s Center for Research Computing (<ext-link ext-link-type="uri" xlink:href="https://crc.pitt.edu/">https://crc.pitt.edu/</ext-link>) for providing valuable computer resources. This work was funded in part through the University of Pittsburgh (2017 Innovation in Education Award, <ext-link ext-link-type="uri" xlink:href="http://www.pitt.edu/~facaffs/acie/awards.html">http://www.pitt.edu/~facaffs/acie/awards.html</ext-link>, to J.D.D.) and the National Institute of General Medical Sciences of the National Institutes of Health (R01GM132353, <ext-link ext-link-type="uri" xlink:href="https://www.nigms.nih.gov/">https://www.nigms.nih.gov/</ext-link>, to J.D.D.). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="4"/>
      <table-count count="1"/>
      <page-count count="17"/>
    </counts>
    <custom-meta-group>
      <custom-meta>
        <meta-name>PLOS Publication Stage</meta-name>
        <meta-value>vor-update-to-uncorrected-proof</meta-value>
      </custom-meta>
      <custom-meta>
        <meta-name>Publication Update</meta-name>
        <meta-value>2020-04-10</meta-value>
      </custom-meta>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>The source code of our program can be downloaded anonymously from our public repository (<ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/protein-vr/">http://durrantlab.com/protein-vr/</ext-link>). The accompanying documentation includes instructions for using and compiling the software. Most users will prefer to simply access the working version we have posted at <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/pvr/">http://durrantlab.com/pvr/</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>The source code of our program can be downloaded anonymously from our public repository (<ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/protein-vr/">http://durrantlab.com/protein-vr/</ext-link>). The accompanying documentation includes instructions for using and compiling the software. Most users will prefer to simply access the working version we have posted at <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/pvr/">http://durrantlab.com/pvr/</ext-link>.</p>
  </notes>
</front>
<body>
  <disp-quote>
    <p>This is a <italic>PLOS Computational Biology</italic> Software paper.</p>
  </disp-quote>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Molecular visualization can provide structural, biological, and pharmacological insights that cannot be obtained in any other way. Traditionally, researchers and educators have used 2D schema (e.g., images in a scientific article or textbook) to represent molecular structures [<xref rid="pcbi.1007747.ref001" ref-type="bibr">1</xref>]. Carefully shaded 2D images can convey some 3D information, but the depth, size, and placement of structural motifs are missing, making it difficult to accurately discern protein active sites, binding domains, and functions. Standard molecular-visualization computer programs, e.g., VMD [<xref rid="pcbi.1007747.ref002" ref-type="bibr">2</xref>] and PyMOL [<xref rid="pcbi.1007747.ref003" ref-type="bibr">3</xref>], improve 3D understanding by projecting 3D models onto 2D screens, allowing users to rotate and examine them in a faux 3D environment [<xref rid="pcbi.1007747.ref002" ref-type="bibr">2</xref>–<xref rid="pcbi.1007747.ref006" ref-type="bibr">6</xref>]. But these visualizations are still only approximations of the true 3D structures—pictures of things, rather than the things themselves [<xref rid="pcbi.1007747.ref007" ref-type="bibr">7</xref>]. Perceiving the spatial arrangements of interacting moieties continues to be challenging in some contexts.</p>
    <p>Virtual reality (VR) overcomes these limitations by displaying models in stereoscopic 3D. Users are thus able to better perceive the spatial arrangements of protein binding pockets and protein/ligand interactions [<xref rid="pcbi.1007747.ref008" ref-type="bibr">8</xref>–<xref rid="pcbi.1007747.ref013" ref-type="bibr">13</xref>]. Compared to traditional visualization approaches, VR 1) provides a wider field of view, 2) allows users to observe molecules from within without requiring the use of clip planes, and 3) requires only head movements to change the viewpoint [<xref rid="pcbi.1007747.ref007" ref-type="bibr">7</xref>, <xref rid="pcbi.1007747.ref010" ref-type="bibr">10</xref>].</p>
    <p>In the past, the high cost of VR hindered efforts to popularize true 3D visualization systems (i.e., systems that deliver different images to each eye) [<xref rid="pcbi.1007747.ref014" ref-type="bibr">14</xref>, <xref rid="pcbi.1007747.ref015" ref-type="bibr">15</xref>]. But with recent advances, low-end VR headsets now work with popular smartphones and are available for under $10, making VR technology broadly accessible [<xref rid="pcbi.1007747.ref016" ref-type="bibr">16</xref>]. Even high-end headsets that allow users to walk about the room in a simulated 3D environment cost less than $500.</p>
    <p>We here present ProteinVR, a new open-source system that leverages these recent advances in VR to better visualize proteins and protein/ligand complexes (<xref ref-type="supplementary-material" rid="pcbi.1007747.s001">S1 Video</xref>). ProteinVR is unique among VR-based molecular-visualization programs in that it is entirely web based. Modern web browsers run on many operating systems and computing devices, so web-based visualization systems are immediately accessible on a broad range of desktops, laptops, and mobile devices, without requiring the installation of any third-party programs or plugins. ProteinVR also supports a number of low- and high-end VR headsets. Where VR is not available, it leverages mobile-device orientation sensors or video-game-style keyboard navigation to provide users with as engaging and immersive an experience as possible.</p>
    <p>ProteinVR will be a useful tool for both the research and educational community. It allows researchers to better examine molecular structures and to collaboratively share molecular visualizations via convenient public URLs. It also allows educators and outreach-program coordinators to easily share instructive 3D scenes with students and the broader public. We release ProteinVR under the terms of the open-source BSD-3-Clause license. A copy is available free of charge from <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/protein-vr/">http://durrantlab.com/protein-vr/</ext-link>, and a working version of the app can be accessed at <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/pvr/">http://durrantlab.com/pvr/</ext-link>.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>Design and implementation</title>
    <sec id="sec003">
      <title>ProteinVR viewer</title>
      <p>ProteinVR leverages new and emerging technologies such as 3D web graphics and VR headsets to display relationships between molecular components in full 3D (<xref ref-type="fig" rid="pcbi.1007747.g001">Fig 1</xref> and <xref ref-type="supplementary-material" rid="pcbi.1007747.s002">S1 Fig</xref>). It is written in TypeScript, a programming language that can be compiled to JavaScript for use in web browsers. The WebVR JavaScript application programming interface (API) allows ProteinVR to access the hardware necessary to render content in VR (e.g., the graphical processing unit, connected VR headsets, etc.). To date, WebVR is supported on a number of browsers, e.g., Chrome (Android), Firefox (Windows), and Oculus Browser. Given the rising popularity of VR, support will certainly broaden in the coming years.</p>
      <fig id="pcbi.1007747.g001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1007747.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>An illustration of a ProteinVR scene with the default NanoKid molecule visualized.</title>
          <p>The molecule is positioned within a skybox. Several buttons are available from the main screen. A) Load a new molecule and environment. B) Open the 2D menu. C) Provide help. D) Enter follow-the-leader mode. E) View in full screen. F) Enter VR mode.</p>
        </caption>
        <graphic xlink:href="pcbi.1007747.g001"/>
      </fig>
      <p>ProteinVR uses 3Dmol.js [<xref rid="pcbi.1007747.ref005" ref-type="bibr">5</xref>] to generate molecular models for VR viewing. 3Dmol.js is a JavaScript library that displays molecular structures on a 2D HTML canvas. To do so it must store those structures as 3D models in memory. Importantly, 3Dmol.js includes the ability to export these internal models in the Virtual Reality Modeling Language (VRML) format [<xref rid="pcbi.1007747.ref017" ref-type="bibr">17</xref>]. Though newer formats have superseded VRML [<xref rid="pcbi.1007747.ref018" ref-type="bibr">18</xref>], we use VRML only to enable internal communication between libraries, so the user need not be concerned with these details. ProteinVR hides 3Dmol.js in the background and instead reads the 3D VRML data directly. It uses this data to render the molecular models within its own VR viewport. This approach enables quick, on-the-fly molecular-style changes involving any of the many representations available through 3Dmol.js (e.g., cartoon, stick, surface, etc.).</p>
    </sec>
    <sec id="sec004">
      <title>3D environments</title>
      <p>To provide context and to orient the user in 3D space, ProteinVR positions molecular models within 3D environments (<xref ref-type="fig" rid="pcbi.1007747.g001">Fig 1</xref>). We used Blender, an open-source 3D modeling program, to generate these environments. Blender’s Cycles renderer is particularly useful for pre-calculating the photorealistic shadows and textures associated with unmoving/unchanging objects. Pre-rendering environments improves performance in the browser. Rather than calculate all environment shadows, ProteinVR needs only (optionally) calculate the shadows cast by the molecular models themselves.</p>
      <p>To accommodate a broad range of devices, several simple default environments are included in the ProteinVR download. These environments ensure that ProteinVR can operate “out of the box” on even low-powered (e.g., mobile-phone-based) devices and VR headsets. The scenes consist of only a skybox (i.e., a large cube that surrounds the virtual camera, regardless of its position). Two-dimensional pictures of distant objects are projected onto the cube faces to suggest a larger surrounding environment. ProteinVR includes skybox-based environments that depict the inside of a blood vessel, the lipid-bilayer surface of a cell, and the intracellular space (<xref ref-type="fig" rid="pcbi.1007747.g001">Fig 1</xref>). For cases where none of these environments are biologically appropriate, users can also select two different “blank” skyboxes containing only decorative clouds.</p>
    </sec>
  </sec>
  <sec sec-type="results" id="sec005">
    <title>Results</title>
    <sec id="sec006">
      <title>Advantages of web-based VR</title>
      <p>ProteinVR’s web-based approach has many advantages. First, ProteinVR uses native web technologies, so it does not require users to download or install any programs or plugins beyond the web browser itself. In this sense it differs from other VR molecular-visualization programs [<xref rid="pcbi.1007747.ref007" ref-type="bibr">7</xref>, <xref rid="pcbi.1007747.ref008" ref-type="bibr">8</xref>, <xref rid="pcbi.1007747.ref010" ref-type="bibr">10</xref>, <xref rid="pcbi.1007747.ref011" ref-type="bibr">11</xref>, <xref rid="pcbi.1007747.ref019" ref-type="bibr">19</xref>–<xref rid="pcbi.1007747.ref022" ref-type="bibr">22</xref>], which require users to download a stand-alone program that may not be compatible with all operating systems. Aside from easing scientific collaboration, this installation-free approach is particularly helpful in educational settings, where expecting students to install a separate program is impractical. Sharing ProteinVR molecular scenes is as simple as sending collaborators or students a convenient URL.</p>
      <p>Second, our web-based approach ensures broad compatibility. ProteinVR is built using BabylonJS, a free, open-source game engine compatible with all modern web browsers. Such web browsers are available on all major platforms, including various operating systems (e.g., Windows, macOS, Linux, Android, iOS). BabylonJS also ensures compatibility with a broad range of computer-hardware setups (e.g., laptop/desktop computers, mobile devices, VR headsets). Where VR is available, ProteinVR uses BabylonJS to leverage many different kinds of VR headsets. Where VR is not available, ProteinVR uses other hardware (e.g., an orientation sensor, a 2D monitor, etc.) to provide as immersive an experience as possible.</p>
      <p>Beyond ensuring broad compatibility, BabylonJS also helps future-proof ProteinVR. ProteinVR uses BabylonJS to access the underlying WebVR API. This API is subject to ongoing changes—so much so that it may soon be replaced by an entirely new API (WebXR) that additionally enables augmented reality (AR). The BabylonJS community actively updates the game-engine code so that BabylonJS-powered software such as ProteinVR need not be entirely rewritten every time the API changes.</p>
    </sec>
    <sec id="sec007">
      <title>Basic usage</title>
      <p>When users first open ProteinVR, the application displays the default molecule NanoKid [<xref rid="pcbi.1007747.ref023" ref-type="bibr">23</xref>] (<xref ref-type="fig" rid="pcbi.1007747.g001">Fig 1</xref>). After a few seconds, a simple popup form appears where users can type the PDB ID or URL of the molecular model they wish to visualize. The same form also allows users to indicate the 3D environment in which to place the molecular model, as well as whether the molecule should cast shadows. After clicking the “Load Molecule” button, NanoKid is replaced with the desired molecular structure.</p>
      <p>Several 2D buttons appear on the right of the screen that are only accessible when not in VR mode (<xref ref-type="fig" rid="pcbi.1007747.g001">Fig 1A–1F</xref>). The first allows users to load a new molecule/environment; the second opens a menu for changing the molecular style and rotation (<xref ref-type="fig" rid="pcbi.1007747.g002">Fig 2</xref>); the third provides a useful help system; the fourth generates a sharable URL that others can use to mirror the ProteinVR scene on their own devices (see “Leader Mode” below); and the fifth and sixth put ProteinVR into full-screen and VR mode, respectively.</p>
      <fig id="pcbi.1007747.g002" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1007747.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>A schematic of the ProteinVR menu.</title>
          <p>A) Open the menu system using either the 2D or 3D button. B) Access the “Rotate” submenu. C) Access the “Styles” submenu. D) Change the style of common, pre-defined molecular components. E) Change the style of selected atoms specific to the loaded molecule itself. F) Change the representation and/or color of the selected atoms/components. G) Remove previously specified styles.</p>
        </caption>
        <graphic xlink:href="pcbi.1007747.g002"/>
      </fig>
      <p>The same menu for changing the molecular style and rotation (<xref ref-type="fig" rid="pcbi.1007747.g001">Fig 1B</xref>) is also accessible from within VR (<xref ref-type="fig" rid="pcbi.1007747.g002">Fig 2</xref> and <xref ref-type="supplementary-material" rid="pcbi.1007747.s001">S1 Video</xref>). ProteinVR places a 3D button at the user’s feet with the text “Show Menu” (<xref ref-type="fig" rid="pcbi.1007747.g002">Fig 2A</xref>). Clicking the button opens a 3D version of the menu, embedded in the VR scene itself. Users on laptop/desktop computers can click the button using a mouse or keyboard (space bar); users on mobile devices without VR headsets can simply tap their screens; and users with VR headsets can pull the VR-headset or VR-controller trigger button.</p>
      <p>At the top-most level, the ProteinVR menu is divided into two broad categories (<xref ref-type="fig" rid="pcbi.1007747.g002">Fig 2B and 2C</xref>). The “Rotate” submenu allows users to rotate the molecule about the X, Y, or Z axis. The “Styles” submenu contains further submenus that allow users to change how the molecule is displayed, both in terms of the molecular representation (e.g., cartoon, sphere, stick, surface) and the color (e.g., white, color by element, etc.) (<xref ref-type="fig" rid="pcbi.1007747.g002">Fig 2D–2F</xref>). “Styles &gt; Components” applies these changes to common, pre-defined molecular components (e.g., proteins, ligands, nucleic acids, water molecules). “Styles &gt; Selections” applies changes to the model using characteristics specific to the loaded molecule itself (e.g., specific residues, elements, chains, etc.). And “Styles &gt; Remove Existing” allows users to remove previously specified representations/colors (<xref ref-type="fig" rid="pcbi.1007747.g002">Fig 2G</xref>).</p>
      <p>ProteinVR also makes it easy to save molecular scenes with custom visualizations such as these. Every time a molecular representation is loaded, rotated, or otherwise altered, ProteinVR updates the browser URL to track the change. Copying the URL at any point into a new browser tab–even on a different device–recreates the exact same ProteinVR scene.</p>
      <p>Interested readers may wish to view <xref ref-type="supplementary-material" rid="pcbi.1007747.s001">S1 Video</xref>, which illustrates many of the ProteinVR features described in this section.</p>
    </sec>
    <sec id="sec008">
      <title>Display modes</title>
      <p>To accommodate a broad range of devices, ProteinVR runs in four modes: VR mode, device-orientation mode, desktop mode, and leader mode. In all four, ProteinVR uses video-game-style navigation. Objects reside at fixed positions in a 3D environment, and the camera moves (or teleports) to different locations in the scene.</p>
      <sec id="sec009">
        <title>VR mode</title>
        <p>VR mode is ideal when users have access to a VR headset (e.g., an Oculus Rift, Oculus Quest, Oculus Go, HTC Vive, or Google-Cardboard compatible viewer). This mode provides a fully immersive experience wherein users can view their molecular structures in stereoscopic 3D. The 3D environments are particularly useful in VR mode, as they improve the sense of immersion. By allowing viewers to orient themselves spatially, 3D environments may also reduce VR sickness [<xref rid="pcbi.1007747.ref024" ref-type="bibr">24</xref>], which is thought to result from a perceived disconnect between the 3D scene presented to the eyes and the movement/orientation of the head. To enter VR mode, users must first attach a VR headset as well as any hand controllers. They then click the VR button in the main ProteinVR screen (<xref ref-type="fig" rid="pcbi.1007747.g001">Fig 1F</xref>).</p>
        <p>In VR mode, users can look about the scene by physically moving their heads. Some VR headsets also allow users to navigate to nearby locations by physically moving about the room. Teleportation navigation enables movement to distant points in the virtual world (<xref ref-type="supplementary-material" rid="pcbi.1007747.s001">S1 Video</xref>). A simple navigation sphere indicates the current teleport destination. When using a VR headset that lacks hand controllers (e.g., Google Cardboard), this sphere appears on the object immediately in front of the user’s gaze. When using a headset with hand controllers (e.g., the HTC Vive, Oculus Rift, Oculus Quest, or Oculus Go), the sphere appears at the location where the user is pointing. To teleport to the location of the sphere, the user simply presses the VR-headset button, the VR-controller trigger (<xref ref-type="fig" rid="pcbi.1007747.g003">Fig 3A</xref>), the keyboard space bar, or the mouse click button.</p>
        <fig id="pcbi.1007747.g003" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1007747.g003</object-id>
          <label>Fig 3</label>
          <caption>
            <title>Illustrations of the controller buttons that enable navigation in VR mode.</title>
            <p>Different VR controllers have different physical configurations, but most include a trigger button (marked with a double dagger) and a trackpad or joystick (marked with an asterisk). A) HTC Vive controller (model 2PR7100). B) Oculus Touch controller (first generation).</p>
          </caption>
          <graphic xlink:href="pcbi.1007747.g003"/>
        </fig>
        <p>VR controllers with trackpads or joysticks enable more fine-grained movements (<xref ref-type="fig" rid="pcbi.1007747.g003">Fig 3B</xref>). To slowly move forward or backward in the direction of the navigation sphere, users can simply press up or down on the trackpad/joystick. To rotate without having to rotate the head (e.g., to reset the view), users can press left or right.</p>
        <p>We have specifically tested VR-mode on the operating-system, web-browser, and VR-headset setups indicated in <xref rid="pcbi.1007747.t001" ref-type="table">Table 1</xref>. In some cases, it was necessary to explicitly enable the WebVR API and/or browser access to the device-orientation sensors. VR technology is rapidly evolving; a web search can reveal the steps necessary (if any) to fully enable VR in a given browser of choice.</p>
        <table-wrap id="pcbi.1007747.t001" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1007747.t001</object-id>
          <label>Table 1</label>
          <caption>
            <title>ProteinVR compatibility.</title>
          </caption>
          <alternatives>
            <graphic id="pcbi.1007747.t001g" xlink:href="pcbi.1007747.t001"/>
            <table frame="box" rules="all" border="0">
              <colgroup span="1">
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th align="left" style="border-bottom:thick" rowspan="1" colspan="1">OS</th>
                  <th align="left" style="border-bottom:thick" rowspan="1" colspan="1">Browser</th>
                  <th align="left" style="border-bottom:thick" rowspan="1" colspan="1">VR</th>
                  <th align="left" style="border-bottom:thick" rowspan="1" colspan="1">Orientation</th>
                  <th align="left" style="border-bottom:thick" rowspan="1" colspan="1">Desktop</th>
                  <th align="left" style="border-bottom:thick" rowspan="1" colspan="1">Leader</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Windows</td>
                  <td align="left" rowspan="1" colspan="1">Chrome 77.0.3865</td>
                  <td align="left" rowspan="1" colspan="1">No</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                  <td align="left" rowspan="1" colspan="1">Desktop</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Windows</td>
                  <td align="left" rowspan="1" colspan="1">Firefox 69.0.1</td>
                  <td align="left" rowspan="1" colspan="1">Vive / Rift</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                  <td align="left" rowspan="1" colspan="1">Vive / Rift / Desktop</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">macOS</td>
                  <td align="left" rowspan="1" colspan="1">Chrome 78.0.3904</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                  <td align="left" rowspan="1" colspan="1">Desktop</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">macOS</td>
                  <td align="left" rowspan="1" colspan="1">Firefox 68.0.2</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                  <td align="left" rowspan="1" colspan="1">Desktop</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">macOS</td>
                  <td align="left" rowspan="1" colspan="1">Safari 12</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                  <td align="left" rowspan="1" colspan="1">No</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Linux</td>
                  <td align="left" rowspan="1" colspan="1">Chromium 77.0.3865</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                  <td align="left" rowspan="1" colspan="1">Desktop</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Linux</td>
                  <td align="left" rowspan="1" colspan="1">Firefox 69.0.1</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                  <td align="left" rowspan="1" colspan="1">Desktop</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Android</td>
                  <td align="left" rowspan="1" colspan="1">Chrome 77.0.3865</td>
                  <td align="left" rowspan="1" colspan="1">Cardboard</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">Cardboard / Orientation</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Android</td>
                  <td align="left" rowspan="1" colspan="1">Firefox 68.1.1</td>
                  <td align="left" rowspan="1" colspan="1">Cardboard</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">Cardboard / Orientation</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">iOS</td>
                  <td align="left" rowspan="1" colspan="1">Safari 12 (PWA)</td>
                  <td align="left" rowspan="1" colspan="1">Cardboard</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">No</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Oculus Quest</td>
                  <td align="left" rowspan="1" colspan="1">Oculus Browser 7.1.3</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">Oculus Go</td>
                  <td align="left" rowspan="1" colspan="1">Oculus Browser 7.0.13</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">—</td>
                  <td align="left" rowspan="1" colspan="1">Yes</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="t001fn001">
              <p>We have tested ProteinVR on several operating-system/web-browser/VR-headset combinations. Operating systems (OS) include Windows (Windows 10 Pro 1809), macOS (macOS Mojave 10.14.5), Linux (Ubuntu Linux 18.04.2 LTS), Android (Android 9), iOS (iOS 12.4.1), Oculus Quest (Android 7.1.1), and Oculus Go (Android 8.0.0). “—” indicates not applicable or not tested. PWA stands for progressive web application. Select hardware specifications are listed in <xref ref-type="supplementary-material" rid="pcbi.1007747.s003">S1 Table</xref>.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p><italic>Desktop computers</italic>.</p>
        <p>We have verified that VR mode works well on Windows 10. We currently recommend the Firefox web browser. We have struggled to enable VR on Windows 10 Google Chrome, though we expect continued improvements in future versions given the expanding popularity of VR. Fortunately, Firefox provides a stable WebVR implementation that is enabled by default.</p>
        <p>VR support in macOS is currently limited, though Apple has plans to expand support in the future. In preliminary tests, we did once manage to get WebVR working (albeit with a very low frame rate) on an HTC Vive connected to a MacBook Pro with an external graphics card. But we have not been able to reproduce that preliminary success and so cannot currently recommend macOS for VR.</p>
        <p><italic>Mobile devices</italic>.</p>
        <p>VR mode also works well on most mobile devices. The WebVR API on Android is easy to access. In contrast, WebVR access on iOS is currently challenging. iOS mobile Safari does not allow webpages to hide the browser address bar, as required for VR visualization using mobile (e.g., Google Cardboard) headsets. Additionally, iOS does not allow the mobile Safari browser to access the device’s orientation sensors by default, making it impossible for ProteinVR to respond to head movements. Apple requires all third-party browsers on iOS (e.g., Chrome, Firefox) to use the same WebKit framework and JavaScript engine that Safari does, so it is not currently possible to overcome these challenges by switching to another browser.</p>
        <p>To eliminate the address bar on iOS, users should install ProteinVR as a progressive web app (PWA). PWA installation places a ProteinVR icon on the device’s home screen and allows ProteinVR to run in full-screen mode. Simply visit the ProteinVR website via mobile Safari and use the browser’s “Share &gt; Add to Home Screen” menu item. Additionally, users must enable access to the device-orientation sensors (even if running ProteinVR as a PWA) via Settings &gt; Safari &gt; Motion &amp; Orientation Access. We are hopeful that Apple will simplify this process in the future as it expands its VR support.</p>
        <p><italic>VR controllers</italic>.</p>
        <p>We have found that WebVR occasionally fails to recognize connected VR controllers. Users who struggle with the controllers may find the following tips helpful:</p>
        <list list-type="order">
          <list-item>
            <p>Turn on the controllers <italic>before</italic> entering VR.</p>
          </list-item>
          <list-item>
            <p>On VR systems with multiple controllers (e.g., one for each hand), turn on all controllers, even though teleportation navigation requires only one.</p>
          </list-item>
          <list-item>
            <p>When using the Oculus Go headset (Oculus Browser), enter VR mode, press the Oculus button, and select the “Resume” menu item to force controller recognition.</p>
          </list-item>
        </list>
      </sec>
      <sec id="sec010">
        <title>Device-orientation mode</title>
        <p>Device-orientation mode is ideal when viewing ProteinVR scenes on mobile devices with orientation sensors. If ProteinVR detects such sensors, it automatically updates its viewport to match the orientation of the device itself. Users can thus view their molecular structures from different angles by physically reorienting their devices. ProteinVR also uses teleportation navigation in device-orientation mode. A navigation sphere (placed in the direction the mobile device is pointing) indicates the current teleport destination. To teleport to the location of the sphere, the user simply taps on the mobile-device screen.</p>
        <p>We have specifically tested device-orientation mode on the operating-system/web-browser combinations indicated in <xref rid="pcbi.1007747.t001" ref-type="table">Table 1</xref>. In our experience, Google Chrome on Android provides the easiest device-orientation experience. On iOS, users must explicitly enable access to the device-orientation sensors via Settings &gt; Safari &gt; Motion &amp; Orientation Access.</p>
      </sec>
      <sec id="sec011">
        <title>Desktop mode</title>
        <p>If neither a VR headset nor an orientation sensor is available, ProteinVR runs in desktop mode. Desktop mode uses a standard keyboard-and-mouse navigation system similar to that commonly used in video games. The arrow keys (or WASD keys) move forward, backward, and sideways. Clicking and dragging with the mouse changes the viewing angle. If the user clicks on the full-screen button in the main window (<xref ref-type="fig" rid="pcbi.1007747.g001">Fig 1E</xref>), ProteinVR instead changes the viewing angle whenever the mouse moves, without requiring an accompanying click. Teleportation navigation is also available for those who wish to use it. To teleport to the navigation sphere, the user need only press the space bar.</p>
        <p>We have specifically tested desktop mode on the operating-system/web-browser combinations indicated in <xref rid="pcbi.1007747.t001" ref-type="table">Table 1</xref>. As desktop mode uses only well-established web technologies, it runs on virtually any modern desktop browser.</p>
      </sec>
      <sec id="sec012">
        <title>Leader mode</title>
        <p>Finally, ProteinVR can run in “leader mode.” This mode transforms the program into a powerful presentation tool. In many scenarios, multiple users may wish to visualize the same ProteinVR scene together. For example, a presenter may wish to use VR navigation to illustrate a specific molecular structure while simultaneously projecting the same view onto the screen behind her. Similarly, a teacher may wish to visualize a specific protein/ligand interaction using an advanced VR headset (e.g., the Oculus Rift) while his students view the same interaction on their phones.</p>
        <p>A technology called WebRTC enables direct communication between leader and follower instances. When running in “leader” mode, ProteinVR broadcasts the user’s location in the 3D scene, as well as information about how the molecule of interest is currently represented. Broadcasting is available from VR headsets, Android phones, laptops, and desktops (<xref rid="pcbi.1007747.t001" ref-type="table">Table 1</xref>). Safari and iOS are not currently supported. In contrast, when running in “follower” mode, ProteinVR receives this information from the designated leader and automatically updates the scene to match whatever the leader is currently seeing. Only 2D (desktop-mode-style) viewing is available in follower mode because VR viewing-angle updates independent of head movements may cause VR sickness [<xref rid="pcbi.1007747.ref024" ref-type="bibr">24</xref>].</p>
      </sec>
    </sec>
    <sec id="sec013">
      <title>Examples of use</title>
      <p>It is challenging to fully grasp the advantages of VR without entering the virtual world. Fortunately, the ProteinVR web app is easily accessible (<ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/pvr/">http://durrantlab.com/pvr/</ext-link>). We encourage users to explore the app directly to better appreciate the benefits of our approach.</p>
      <p>Though descriptions and figures cannot do full justice to the VR experience, we nevertheless describe two ProteinVR test cases. These examples illustrate how our VR implementation provides insights that are difficult to obtain via traditional, non-VR methods.</p>
      <sec id="sec014">
        <title>Small-molecule docking poses</title>
        <p>First, we considered applications to rational ligand design. We examined <italic>T. brucei</italic> RNA editing ligase 1 (REL1) bound to compound V2, a low-micromolar naphthalene-based inhibitor [<xref rid="pcbi.1007747.ref025" ref-type="bibr">25</xref>]. REL1 is essential for the survival of the unicellular parasite <italic>Trypanosoma brucei</italic> [<xref rid="pcbi.1007747.ref026" ref-type="bibr">26</xref>]. It is a component of the parasitic editosome that religates the RNA nicks caused by extensive uridylate insertions and deletions [<xref rid="pcbi.1007747.ref027" ref-type="bibr">27</xref>–<xref rid="pcbi.1007747.ref031" ref-type="bibr">31</xref>]. REL1 has a deep ATP-binding pocket where compound V2 likely binds [<xref rid="pcbi.1007747.ref025" ref-type="bibr">25</xref>].</p>
        <p>We used Gypsum-DL [<xref rid="pcbi.1007747.ref032" ref-type="bibr">32</xref>], MGLTools (<ext-link ext-link-type="uri" xlink:href="http://mgltools.scripps.edu/">http://mgltools.scripps.edu/</ext-link>), and AutoDock Vina [<xref rid="pcbi.1007747.ref033" ref-type="bibr">33</xref>] to dock a model of V2 into the REL1 pocket. We then used VMD [<xref rid="pcbi.1007747.ref002" ref-type="bibr">2</xref>] and ProteinVR to separately examine the protein-ligand interactions characteristic of the top Vina-predicted pose. To make the comparison as fair as possible, we used fog and perspective view in VMD to simulate depth (<xref ref-type="fig" rid="pcbi.1007747.g004">Fig 4A</xref>). Even so, it was at times challenging to perceive the critical interactions. Because the REL1 pocket is so deep, closer atoms often pass in front of more buried features, leading to some confusion in the absence of true depth perception. Non-VR programs such as VMD and PyMOL [<xref rid="pcbi.1007747.ref003" ref-type="bibr">3</xref>] cannot provide the same natural-feeling experience that is typical of observing objects in the physical world.</p>
        <fig id="pcbi.1007747.g004" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1007747.g004</object-id>
          <label>Fig 4</label>
          <caption>
            <title>Two examples that show the advantages of ProteinVR use.</title>
            <p>A) An illustration of compound V2 docked into the REL1 ATP-binding pocket, visualized using VMD. Despite the use of fog and perspective view, perceiving critical protein/ligand interactions without true stereoscopic 3D is at times challenging. B) An illustration of the space between open- and closed-pocket LARP1 surfaces, visualized using ProteinVR in non-VR mode. Prior to entering VR mode, camera-adjacent sections of the surfaces are often clipped (highlighted with a white dotted line), as is typical of non-VR programs. Clipping is easier to avoid in VR because the camera position is finely controlled by simple head movements, and VR provides a wider field of view.</p>
          </caption>
          <graphic xlink:href="pcbi.1007747.g004"/>
        </fig>
        <p>Viewing the same protein/ligand complex in ProteinVR with an HTC Vive VR headset was more intuitive. The molecular structure had presence. With almost no effort, the tester was able to see that the two phosphate groups of the ligand flank a positively charged arginine residue, that other positively charged residues may contribute to molecular recognition via electrostatic interactions, that ligand hydroxyl groups form hydrogen bonds with the protein, etc. It was also immediately clear that the Vina-predicted ligand pose may be incorrect. One of the naphthalene moieties could more optimally participate in a π-π stacking interaction with the protein if rotated slightly, and a buried amino moiety appears to have no hydrogen-bond partner. The ability to look around obstructing atoms with simple head movements, together with true stereoscopic depth perception, made obtaining these kinds of insights particularly intuitive.</p>
        <p>This test case illustrates how ProteinVR can benefit both researchers and educators. We have spent many hours analyzing protein/ligand complexes using non-VR programs. These programs are effective, but they require users to trick their brains into a kind of faux depth perception by using fog and perspective view, and by rocking the molecular structures about carefully selected pivot points. Seeing the structures in stereoscopic 3D substantially reduces the cognitive load required to appreciate these interactions, ultimately speeding analysis. Students in particular stand to benefit from the VR approach. Perceiving the 3D geometry of the bound ligand pose becomes intuitive, allowing students to focus on the meaning of the interactions rather than the presentation.</p>
      </sec>
      <sec id="sec015">
        <title>Conformations extracted from molecular-dynamics simulations</title>
        <p>As a second test case, we used ProteinVR to reexamine a previously published molecular-dynamics (MD) simulation [<xref rid="pcbi.1007747.ref034" ref-type="bibr">34</xref>]. The simulation captured the dynamics of La-related protein 1 (LARP1), an RNA-binding protein that regulates ribosome production, cell growth, and proliferation. Our previous work showed that a LARP1 pocket known to bind mRNA caps is highly dynamic. Using the POVME algorithm [<xref rid="pcbi.1007747.ref035" ref-type="bibr">35</xref>, <xref rid="pcbi.1007747.ref036" ref-type="bibr">36</xref>], we identified the MD-sampled conformations with both the largest and smallest pocket volumes. This analysis, together with careful examination of the structures in VMD, was critical for characterizing pocket dynamics [<xref rid="pcbi.1007747.ref034" ref-type="bibr">34</xref>].</p>
        <p>Reexamining these pocket conformations with ProteinVR on an HTC Vive VR headset allowed for a far more intuitive analysis. ProteinVR does not yet support MD-trajectory visualization, but it was not difficult to concatenate the largest- and smallest-pocket conformations into a single PDB file and to assign different chain IDs to each. We loaded this two-structure PDB file into ProteinVR and applied a differently colored surface representation to each conformation. To better appreciate the pocket-volume difference, we attempted to position the ProteinVR camera between the surfaces of the smallest-volume (collapsed) and largest-volume (open) pockets.</p>
        <p>Before entering VR mode, it was difficult to observe this inter-surface space (i.e., the space corresponding to the pocket-volume difference) from within. As with other non-VR programs, camera-adjacent surface sections were often clipped (<xref ref-type="fig" rid="pcbi.1007747.g004">Fig 4B</xref>). In contrast, appreciating the space was much easier in VR mode. The tester simply used ProteinVR’s teleportation navigation system to move immediately adjacent to the surface of the smallest-volume (collapsed) pocket. By pushing his head forward through this outer surface, he was able to easily examine the size and contours of the space between the two surfaces. This type of experience cannot replace objective numerical analyses such as those that POVME provides, but it certainly can yield insights to guide future research. The tester himself, despite extensive experience with both VR and LARP1, had a gleeful “eureka” moment when first observing the pocket-volume difference in VR.</p>
        <p>This test case similarly illustrates how ProteinVR can benefit both researchers and educators. Rational ligand design often requires a thorough appreciation of the 3D volume that a binding pocket occupies. But visualizing narrow and/or buried pockets is sometimes difficult without VR. In contrast, ProteinVR in VR mode enables minute movements by tracking head motions. Both researchers and students can easily avoid clipping while looking about pocket interiors. The stereoscopic vision possible in VR also give a better sense of the pocket dimensions.</p>
      </sec>
    </sec>
    <sec id="sec016">
      <title>Comparison with other programs</title>
      <sec id="sec017">
        <title>Molecule-to-mesh pipelines</title>
        <p>ProteinVR makes setting up VR molecular visualizations particularly easy. In contrast, some other VR programs rely on complex software pipelines that require users to install (and master) third-party modeling programs such as Blender (Blender Foundation) and Unity (Unity Technologies). Users must setup molecular representations (e.g., ribbon, stick, surface) during the initial modeling stage, making it impossible to change the representation in real-time VR.</p>
        <p>The open-source BlendMol [<xref rid="pcbi.1007747.ref037" ref-type="bibr">37</xref>] plugin for Blender [<xref rid="pcbi.1007747.ref038" ref-type="bibr">38</xref>] is one example of this effective but difficult-to-manage approach. BlendMol/Blender can produce photorealistic images of protein structures that are well suited for scientific publication and educational outreach. Third-party Blender plugins can also export BlendMol models to VR-compatible formats. But the BlendMol method for preparing VR models is far from automated and requires some expertise in 3D modeling.</p>
        <p>RealityConvert [<xref rid="pcbi.1007747.ref039" ref-type="bibr">39</xref>], like BlendMol, provides a molecule-to-mesh pipeline that generates molecular meshes for VR and AR scenes. An easy-to-use web app helps overcome some barriers to use. But the web app only accepts very small molecules (&lt; 200 lines). Processing larger molecules requires the command-line version and its four dependencies: PyMOL [<xref rid="pcbi.1007747.ref003" ref-type="bibr">3</xref>], Blender [<xref rid="pcbi.1007747.ref038" ref-type="bibr">38</xref>], Open Babel [<xref rid="pcbi.1007747.ref040" ref-type="bibr">40</xref>], and Molconvert (ChemAxon). Many other VR and AR approaches for molecular visualization involve similarly challenging software pipelines [<xref rid="pcbi.1007747.ref019" ref-type="bibr">19</xref>, <xref rid="pcbi.1007747.ref021" ref-type="bibr">21</xref>, <xref rid="pcbi.1007747.ref041" ref-type="bibr">41</xref>]. In contrast, ProteinVR requires no download or dependencies and so is more accessible.</p>
      </sec>
      <sec id="sec018">
        <title>Desktop applications</title>
        <p>A number of desktop applications enable VR molecular visualization directly, without requiring a complex pipeline. These desktop programs often limit their compatibility to high-end VR devices [<xref rid="pcbi.1007747.ref007" ref-type="bibr">7</xref>, <xref rid="pcbi.1007747.ref011" ref-type="bibr">11</xref>, <xref rid="pcbi.1007747.ref041" ref-type="bibr">41</xref>, <xref rid="pcbi.1007747.ref042" ref-type="bibr">42</xref>]. In contrast, ProteinVR is generally more accessible because it supports a broad range of VR headsets as well as non-VR fallback approaches such as device-orientation-based viewing. This broad support is possible because ProteinVR relies on the WebVR API, which standardizes the way VR-enabled websites interact with various devices, as well as the BabylonJS JavaScript game engine, which provides a broad range of video-game-style navigation schemes. As a web-based app, ProteinVR also requires no download or installation, further improving accessibility.</p>
        <p>That having been said, desktop programs that cater to high-end VR headsets are able to implement useful features that ProteinVR currently lacks. Molecular Rift [<xref rid="pcbi.1007747.ref007" ref-type="bibr">7</xref>] is a good example of such a desktop program. This innovative, open-source VR application allows users to navigate molecular structures without VR controllers, using hand gestures. The commercial program Nanome (Nanome Inc.) is a second notable example. Nanome’s easy-to-use and detailed user interface permits not only molecular visualization, but also molecular manipulation (e.g., <italic>in silico</italic> mutagenesis). The free version of Nanome does come with some important limitations, however. For example, VR molecular scenes created with the free version are entirely public. In fact, as we were testing Nanome, another user joined our room and was able to observe our activities.</p>
      </sec>
      <sec id="sec019">
        <title>Other web applications</title>
        <p>Recognizing the advantages of the web-based approach, others have also explored online VR molecular-visualization systems [<xref rid="pcbi.1007747.ref020" ref-type="bibr">20</xref>, <xref rid="pcbi.1007747.ref043" ref-type="bibr">43</xref>]. One example is iview [<xref rid="pcbi.1007747.ref020" ref-type="bibr">20</xref>]. Though the iview website includes a “virtual reality” button, this button was not functional on any of the browsers we tested. The iview source code does make reference to WebVR, so perhaps it is the user interface, rather than the underlying codebase, that is broken. We note also that the iview server went offline after our initial tests, though the connectivity problem may be temporary. Regardless, ProteinVR provides additional features—including 3D environments and device-orientation mode—that iview and other programs currently lack.</p>
      </sec>
      <sec id="sec020">
        <title>Unity game engine</title>
        <p>The Unity game engine (Unity Technologies) warrants specific mention because it powers several desktop VR applications, including Molecular Rift [<xref rid="pcbi.1007747.ref007" ref-type="bibr">7</xref>], described above, and Molecular Zoo [<xref rid="pcbi.1007747.ref010" ref-type="bibr">10</xref>], a program for teaching young students about biomolecules. The open-source library UnityMol [<xref rid="pcbi.1007747.ref044" ref-type="bibr">44</xref>] even enables on-the-fly molecular-mesh generation in Unity apps, much as 3Dmol.js does for ProteinVR.</p>
        <p>Unity has several advantages over the BabylonJS game engine behind ProteinVR. Its advanced editor greatly simplifies development, and its online community has developed many add-ons (both free and commercial) that allow developers to easily add the specific features that their application requires. If desktop Unity applications are properly optimized, their performance also surpasses that of any web-based app because most browsers cap graphics updates at 60 frames per second. Finally, because the WebVR standard is still evolving, Unity applications are arguably more stable, at least for the time being.</p>
        <p>Despite these advantages, we built ProteinVR using BabylonJS because it is particularly well suited for web apps. Unity applications can be compiled to run in the browser, but they are almost always far larger than the equivalent BabylonJS app, requiring more time and bandwidth to download. Unity also lacks official support for browser-based apps on mobile devices, and the BabylonJS approach to WebVR is much more straightforward than its Unity counterpart. Because BabylonJS is itself written in JavaScript, integration with web technologies such as WebRTC and the HTML5 DOM (e.g., buttons, popups, menus, etc.) is also much easier. Finally, the Unity engine is closed source, and free use requires Unity-specific branding.</p>
      </sec>
    </sec>
  </sec>
  <sec id="sec021">
    <title>Availability</title>
    <p>We release ProteinVR under the open-source BSD-3-Clause license. The source code can be downloaded anonymously from our public repository at <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/protein-vr/">http://durrantlab.com/protein-vr/</ext-link>. The accompanying documentation includes instructions for using and compiling the software. Most users will prefer to simply access the working version we have posted at <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/pvr/">http://durrantlab.com/pvr/</ext-link>. Users may also report bugs or other issues via the online forum at <ext-link ext-link-type="uri" xlink:href="http://durrantlab.com/forums/forum/protein-vr/">http://durrantlab.com/forums/forum/protein-vr/</ext-link>.</p>
  </sec>
  <sec id="sec022">
    <title>Future directions</title>
    <sec id="sec023">
      <title>Features</title>
      <p>ProteinVR’s strength lies in its simplicity. We are eager to avoid “feature creep,” wherein excessive software updates add only minor benefit while complicating use. Other programs exist for model building and analysis. ProteinVR is meant to be a molecular viewer. Future improvements will further enhance that core functionality.</p>
      <p>For example, several related programs display molecules using AR. Unlike VR, AR positions virtual objects in the context of the actual world (e.g., virtual protein structures digitally superimposed on an actual, physical table). Some studies suggest that AR helps mitigate VR sickness [<xref rid="pcbi.1007747.ref024" ref-type="bibr">24</xref>, <xref rid="pcbi.1007747.ref045" ref-type="bibr">45</xref>, <xref rid="pcbi.1007747.ref046" ref-type="bibr">46</xref>], so AR may be more accessible to some users. On the other hand, to the best of our knowledge, current advanced AR approaches for molecular visualization work only with the expensive Microsoft HoloLens headset and require users to download separate software to prepare the molecular models [<xref rid="pcbi.1007747.ref019" ref-type="bibr">19</xref>, <xref rid="pcbi.1007747.ref021" ref-type="bibr">21</xref>]. It may be that ProteinVR’s 3D environments, teleportation navigation system, and device-orientation/desktop modes will allow even sensitive users to avoid VR sickness. If not, future versions of ProteinVR will incorporate AR viewing. The BabylonJS game engine that powers ProteinVR has preliminary AR support that will likely expand in the coming years.</p>
      <p>One desktop VR program called NarupaXR allows users to interact with real-time atomic-resolution MD simulations running on remote computer resources [<xref rid="pcbi.1007747.ref011" ref-type="bibr">11</xref>, <xref rid="pcbi.1007747.ref047" ref-type="bibr">47</xref>–<xref rid="pcbi.1007747.ref049" ref-type="bibr">49</xref>]. This interactive approach is remarkably intuitive. Unfortunately, because ProteinVR is web based, it cannot interact with a local server streaming MD data to the viewer. Enabling interactive MD would thus require us to maintain a public server backed by the substantial remote computer infrastructure required to run MD simulations. But we are certainly interested in enabling non-interactive MD-trajectory visualization in future versions of ProteinVR. We have already published two browser-based tools for MD-trajectory playback in a non-VR context [<xref rid="pcbi.1007747.ref050" ref-type="bibr">50</xref>, <xref rid="pcbi.1007747.ref051" ref-type="bibr">51</xref>]. Incorporating components of these programs into future versions of ProteinVR could be a productive future direction.</p>
      <p>Additional planned features include 1) improved chain and residue labeling, 2) automatic detection and visualization of protein/ligand interactions via our BINANA algorithm [<xref rid="pcbi.1007747.ref052" ref-type="bibr">52</xref>], and 3) expanded methods for loading molecular data.</p>
    </sec>
    <sec id="sec024">
      <title>Further testing</title>
      <p>Further user testing will evaluate how best to deploy ProteinVR in research and educational settings. Continued use in our lab–together with feedback from our users–will help us further evaluate ProteinVR’s utility in a research context. Members of well funded research labs with dedicated space for VR visualization may prefer desktop applications running on powerful computers with high-end VR headsets. These programs offer an impressive array of features that are difficult to deliver over the web. But in many situations, ProteinVR’s convenience (e.g., compatibility with mobile VR headsets such as the Oculus Quest, easy web access, etc.) may make it the preferred choice.</p>
      <p>We expect that ProteinVR’s portability, broad hardware compatibility, and ease of deployment will be particularly useful in an educational context. Lecturers are rarely able to bring an expensive gaming computer with a high-end VR headset to class. And even when such a system is available, it cannot reasonably accommodate large classrooms. In contrast, purchasing low-end VR headsets (e.g., Google Cardboard) so students can view VR scenes on their mobile devices is feasible. A limited number of medium-quality headsets (e.g., the Oculus Quest) can then supplement the mobile-based devices.</p>
      <p>Published studies have shown that VR enhances science education generally [<xref rid="pcbi.1007747.ref053" ref-type="bibr">53</xref>] and chemistry education specifically [<xref rid="pcbi.1007747.ref054" ref-type="bibr">54</xref>]. We are currently designing a study that will evaluate how ProteinVR improves learning outcomes in both high-school and undergraduate classrooms.</p>
    </sec>
  </sec>
  <sec sec-type="supplementary-material" id="sec025">
    <title>Supporting information</title>
    <supplementary-material content-type="local-data" id="pcbi.1007747.s001">
      <label>S1 Video</label>
      <caption>
        <title>A video that illustrates ProteinVR’s basic features.</title>
        <p>(MP4)</p>
      </caption>
      <media xlink:href="pcbi.1007747.s001.mp4">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1007747.s002">
      <label>S1 Fig</label>
      <caption>
        <title>A flowchart diagram representing the main steps of the ProteinVR algorithm.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1007747.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pcbi.1007747.s003">
      <label>S1 Table</label>
      <caption>
        <title>A few of the devices used to test ProteinVR in VR mode, together with the associated hardware specifications.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pcbi.1007747.s003.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack>
    <p>We thank Raanan Weber and David Catuhe for help using the BabylonJS game engine, and Zuzana Swigonova and the late Karen Curto for discussions regarding how best to use ProteinVR as an active-learning educational tool.</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pcbi.1007747.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Nakano</surname><given-names>CM</given-names></name>, <name><surname>Moen</surname><given-names>E</given-names></name>, <name><surname>Byun</surname><given-names>HS</given-names></name>, <name><surname>Ma</surname><given-names>H</given-names></name>, <name><surname>Newman</surname><given-names>B</given-names></name>, <name><surname>McDowell</surname><given-names>A</given-names></name>, <etal>et al</etal><article-title>iBET: Immersive visualization of biological electron-transfer dynamics</article-title>. <source>J Mol Graph Model</source>. <year>2016</year>;<volume>65</volume>:<fpage>94</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1016/j.jmgm.2016.02.009</pub-id><?supplied-pmid 26955008?><pub-id pub-id-type="pmid">26955008</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Humphrey</surname><given-names>W</given-names></name>, <name><surname>Dalke</surname><given-names>A</given-names></name>, <name><surname>Schulten</surname><given-names>K</given-names></name>. <article-title>VMD: visual molecular dynamics</article-title>. <source>Journal of Molecular Graphics</source>. <year>1996</year>;<volume>14</volume>(<issue>1</issue>):<fpage>33</fpage>–<lpage>38</lpage>. <pub-id pub-id-type="doi">10.1016/0263-7855(96)00018-5</pub-id><?supplied-pmid 8744570?><pub-id pub-id-type="pmid">8744570</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>DeLano</surname><given-names>WL</given-names></name>. <article-title>Pymol: An open-source molecular graphics tool</article-title>. <source>CCP4 Newsletter On Protein Crystallography</source>. <year>2002</year>;<volume>40</volume>:<fpage>82</fpage>–<lpage>92</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Pettersen</surname><given-names>EF</given-names></name>, <name><surname>Goddard</surname><given-names>TD</given-names></name>, <name><surname>Huang</surname><given-names>CC</given-names></name>, <name><surname>Couch</surname><given-names>GS</given-names></name>, <name><surname>Greenblatt</surname><given-names>DM</given-names></name>, <name><surname>Meng</surname><given-names>EC</given-names></name>, <etal>et al</etal><article-title>UCSF chimera—A visualization system for exploratory research and analysis</article-title>. <source>Journal of Computational Chemistry</source>. <year>2004</year>;<volume>25</volume>(<issue>13</issue>):<fpage>1605</fpage>–<lpage>1612</lpage>. <pub-id pub-id-type="doi">10.1002/jcc.20084</pub-id><?supplied-pmid 15264254?><pub-id pub-id-type="pmid">15264254</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Rego</surname><given-names>N</given-names></name>, <name><surname>Koes</surname><given-names>D</given-names></name>. <article-title>3Dmol.js: molecular visualization with WebGL</article-title>. <source>Bioinformatics</source>. <year>2015</year>;<volume>31</volume>(<issue>8</issue>):<fpage>1322</fpage>–<lpage>4</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btu829</pub-id><?supplied-pmid 25505090?><pub-id pub-id-type="pmid">25505090</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Rose</surname><given-names>AS</given-names></name>, <name><surname>Hildebrand</surname><given-names>PW</given-names></name>. <article-title>NGL Viewer: a web application for molecular visualization</article-title>. <source>Nucleic Acids Res</source>. <year>2015</year>;<volume>43</volume>(<issue>W1</issue>):<fpage>W576</fpage>–<lpage>9</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkv402</pub-id><?supplied-pmid 25925569?><pub-id pub-id-type="pmid">25925569</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Norrby</surname><given-names>M</given-names></name>, <name><surname>Grebner</surname><given-names>C</given-names></name>, <name><surname>Eriksson</surname><given-names>J</given-names></name>, <name><surname>Bostrom</surname><given-names>J</given-names></name>. <article-title>Molecular Rift: Virtual Reality for Drug Designers</article-title>. <source>Journal of Chemical Information and Modeling</source>. <year>2015</year>;<volume>55</volume>(<issue>11</issue>):<fpage>2475</fpage>–<lpage>2484</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jcim.5b00544</pub-id><?supplied-pmid 26558887?><pub-id pub-id-type="pmid">26558887</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Ratamero</surname><given-names>EM</given-names></name>, <name><surname>Bellini</surname><given-names>D</given-names></name>, <name><surname>Dowson</surname><given-names>CG</given-names></name>, <name><surname>Romer</surname><given-names>RA</given-names></name>. <article-title>Touching proteins with virtual bare hands: Visualizing protein-drug complexes and their dynamics in self-made virtual reality using gaming hardware</article-title>. <source>J Comput Aided Mol Des</source>. <year>2018</year>;<volume>32</volume>(<issue>6</issue>):<fpage>703</fpage>–<lpage>709</lpage>. <pub-id pub-id-type="doi">10.1007/s10822-018-0123-0</pub-id><?supplied-pmid 29882064?><pub-id pub-id-type="pmid">29882064</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Grebner</surname><given-names>C</given-names></name>, <name><surname>Norrby</surname><given-names>M</given-names></name>, <name><surname>Enstrom</surname><given-names>J</given-names></name>, <name><surname>Nilsson</surname><given-names>I</given-names></name>, <name><surname>Hogner</surname><given-names>A</given-names></name>, <name><surname>Henriksson</surname><given-names>J</given-names></name>, <etal>et al</etal><article-title>3D-Lab: a collaborative web-based platform for molecular modeling</article-title>. <source>Future Med Chem</source>. <year>2016</year>;<volume>8</volume>(<issue>14</issue>):<fpage>1739</fpage>–<lpage>52</lpage>. <pub-id pub-id-type="doi">10.4155/fmc-2016-0081</pub-id><?supplied-pmid 27577860?><pub-id pub-id-type="pmid">27577860</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Goddard</surname><given-names>TD</given-names></name>, <name><surname>Brilliant</surname><given-names>AA</given-names></name>, <name><surname>Skillman</surname><given-names>TL</given-names></name>, <name><surname>Vergenz</surname><given-names>S</given-names></name>, <name><surname>Tyrwhitt-Drake</surname><given-names>J</given-names></name>, <name><surname>Meng</surname><given-names>EC</given-names></name>, <etal>et al</etal><article-title>Molecular Visualization on the Holodeck</article-title>. <source>J Mol Biol</source>. <year>2018</year>;<volume>430</volume>(<issue>21</issue>):<fpage>3982</fpage>–<lpage>3996</lpage>. <pub-id pub-id-type="doi">10.1016/j.jmb.2018.06.040</pub-id><?supplied-pmid 29964044?><pub-id pub-id-type="pmid">29964044</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>O’Connor</surname><given-names>M</given-names></name>, <name><surname>Deeks</surname><given-names>HM</given-names></name>, <name><surname>Dawn</surname><given-names>E</given-names></name>, <name><surname>Metatla</surname><given-names>O</given-names></name>, <name><surname>Roudaut</surname><given-names>A</given-names></name>, <name><surname>Sutton</surname><given-names>M</given-names></name>, <etal>et al</etal><article-title>Sampling molecular conformations and dynamics in a multiuser virtual reality framework</article-title>. <source>Sci Adv</source>. <year>2018</year>;<volume>4</volume>(<issue>6</issue>):<fpage>eaat2731</fpage><pub-id pub-id-type="doi">10.1126/sciadv.aat2731</pub-id><?supplied-pmid 29963636?><pub-id pub-id-type="pmid">29963636</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref012">
      <label>12</label>
      <mixed-citation publication-type="book"><name><surname>Tan</surname><given-names>S</given-names></name>, <name><surname>Waugh</surname><given-names>R</given-names></name>. In: <source>Use of virtual-reality in teaching and learning molecular biology</source>. <publisher-name>Springer</publisher-name>; <year>2013</year> p. <fpage>17</fpage>–<lpage>43</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Al-Balushi</surname><given-names>SM</given-names></name>, <name><surname>Al-Hajri</surname><given-names>SH</given-names></name>. <article-title>Associating animations with concrete models to enhance students’ comprehension of different visual representations in organic chemistry</article-title>. <source>Chemistry Education Research and Practice</source>. <year>2014</year>;<volume>15</volume>(<issue>1</issue>):<fpage>47</fpage>–<lpage>58</lpage>. <pub-id pub-id-type="doi">10.1039/C3RP00074E</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref014">
      <label>14</label>
      <mixed-citation publication-type="other">Cruz-Neira C, Sandin DJ, DeFanti TA. Surround-screen projection-based virtual reality: the design and implementation of the CAVE. Citeseer;. p. 135–142.</mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Cruz-Neira</surname><given-names>C</given-names></name>, <name><surname>Sandin</surname><given-names>DJ</given-names></name>, <name><surname>DeFanti</surname><given-names>TA</given-names></name>, <name><surname>Kenyon</surname><given-names>RV</given-names></name>, <name><surname>Hart</surname><given-names>JC</given-names></name>. <article-title>The CAVE: audio visual experience automatic virtual environment</article-title>. <source>Communications of the ACM</source>. <year>1992</year>;<volume>35</volume>(<issue>6</issue>):<fpage>64</fpage>–<lpage>73</lpage>. <pub-id pub-id-type="doi">10.1145/129888.129892</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref016">
      <label>16</label>
      <mixed-citation publication-type="other">Oigara JN. In: Keengwe J, editor. Integrating Virtual Reality Tools Into Classroom Instruction. Hershey, PA, USA: IGI Global; 2018. p. 147–159.</mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Taubin</surname><given-names>G</given-names></name>, <name><surname>Horn</surname><given-names>WP</given-names></name>, <name><surname>Lazarus</surname><given-names>F</given-names></name>, <name><surname>Rossignac</surname><given-names>J</given-names></name>. <article-title>Geometry coding and VRML</article-title>. <source>Proceedings of the IEEE</source>. <year>1998</year>;<volume>86</volume>(<issue>6</issue>):<fpage>1228</fpage>–<lpage>1243</lpage>. <pub-id pub-id-type="doi">10.1109/5.687837</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Daly</surname><given-names>L</given-names></name>, <name><surname>Brutzman</surname><given-names>D</given-names></name>. <article-title>X3D: Extensible 3D graphics standard [standards in a nutshell]</article-title>. <source>IEEE Signal Processing Magazine</source>. <year>2007</year>;<volume>24</volume>(<issue>6</issue>):<fpage>130</fpage>–<lpage>135</lpage>. <pub-id pub-id-type="doi">10.1109/MSP.2007.4317479</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Hoffman</surname><given-names>MA</given-names></name>, <name><surname>Provance</surname><given-names>JB</given-names></name>. <article-title>Visualization of molecular structures using HoloLens-based augmented reality</article-title>. <source>AMIA Jt Summits Transl Sci Proc</source>. <year>2017</year>;<volume>2017</volume>:<fpage>68</fpage>–<lpage>74</lpage>. <?supplied-pmid 28815109?><pub-id pub-id-type="pmid">28815109</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>H</given-names></name>, <name><surname>Leung</surname><given-names>KS</given-names></name>, <name><surname>Nakane</surname><given-names>T</given-names></name>, <name><surname>Wong</surname><given-names>MH</given-names></name>. <article-title>iview: an interactive WebGL visualizer for protein-ligand complex</article-title>. <source>BMC Bioinformatics</source>. <year>2014</year>;<volume>15</volume>:<fpage>56</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-15-56</pub-id><?supplied-pmid 24564583?><pub-id pub-id-type="pmid">24564583</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Muller</surname><given-names>C</given-names></name>, <name><surname>Krone</surname><given-names>M</given-names></name>, <name><surname>Huber</surname><given-names>M</given-names></name>, <name><surname>Biener</surname><given-names>V</given-names></name>, <name><surname>Herr</surname><given-names>D</given-names></name>, <name><surname>Koch</surname><given-names>S</given-names></name>, <etal>et al</etal><article-title>Interactive Molecular Graphics for Augmented Reality Using HoloLens</article-title>. <source>J Integr Bioinform</source>. <year>2018</year>;<volume>15</volume>(<issue>2</issue>). <pub-id pub-id-type="doi">10.1515/jib-2018-0005</pub-id><?supplied-pmid 29897886?><pub-id pub-id-type="pmid">29897886</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Zheng</surname><given-names>M</given-names></name>, <name><surname>Waller</surname><given-names>MP</given-names></name>. <article-title>ChemPreview: an augmented reality-based molecular interface</article-title>. <source>J Mol Graph Model</source>. <year>2017</year>;<volume>73</volume>:<fpage>18</fpage>–<lpage>23</lpage>. <pub-id pub-id-type="doi">10.1016/j.jmgm.2017.01.019</pub-id><?supplied-pmid 28214437?><pub-id pub-id-type="pmid">28214437</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Chanteau</surname><given-names>SH</given-names></name>, <name><surname>Tour</surname><given-names>JM</given-names></name>. <article-title>Synthesis of anthropomorphic molecules: the NanoPutians</article-title>. <source>J Org Chem</source>. <year>2003</year>;<volume>68</volume>(<issue>23</issue>):<fpage>8750</fpage>–<lpage>66</lpage>. <pub-id pub-id-type="doi">10.1021/jo0349227</pub-id><?supplied-pmid 14604341?><pub-id pub-id-type="pmid">14604341</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>Cobb</surname><given-names>SVG</given-names></name>, <name><surname>Nichols</surname><given-names>S</given-names></name>, <name><surname>Ramsey</surname><given-names>A</given-names></name>, <name><surname>Wilson</surname><given-names>JR</given-names></name>. <article-title>Virtual Reality-Induced Symptoms and Effects (VRISE)</article-title>. <source>Presence: Teleoperators and Virtual Environments</source>. <year>1999</year>;<volume>8</volume>(<issue>2</issue>):<fpage>169</fpage>–<lpage>186</lpage>. <pub-id pub-id-type="doi">10.1162/105474699566152</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Durrant</surname><given-names>JD</given-names></name>, <name><surname>Hall</surname><given-names>L</given-names></name>, <name><surname>Swift</surname><given-names>RV</given-names></name>, <name><surname>Landon</surname><given-names>M</given-names></name>, <name><surname>Schnaufer</surname><given-names>A</given-names></name>, <name><surname>Amaro</surname><given-names>RE</given-names></name>. <article-title>Novel Naphthalene-Based Inhibitors of Trypanosoma brucei RNA Editing Ligase 1</article-title>. <source>PLOS Neglected Tropical Diseases</source>. <year>2010</year>;<volume>4</volume>(<issue>8</issue>):<fpage>e803</fpage><pub-id pub-id-type="doi">10.1371/journal.pntd.0000803</pub-id><?supplied-pmid 20808768?><pub-id pub-id-type="pmid">20808768</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Schnaufer</surname><given-names>A</given-names></name>, <name><surname>Panigrahi</surname><given-names>AK</given-names></name>, <name><surname>Panicucci</surname><given-names>B</given-names></name>, <name><surname>Igo J Robert</surname><given-names>P</given-names></name>, <name><surname>Salavati</surname><given-names>R</given-names></name>, <name><surname>Stuart</surname><given-names>K</given-names></name>. <article-title>An RNA Ligase Essential for RNA Editing and Survival of the Bloodstream Form of Trypanosoma brucei</article-title>. <source>Science</source>. <year>2001</year>;<volume>291</volume>(<issue>5511</issue>):<fpage>2159</fpage>–<lpage>2162</lpage>. <?supplied-pmid 11251122?><pub-id pub-id-type="pmid">11251122</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref027">
      <label>27</label>
      <mixed-citation publication-type="journal"><name><surname>Lukes</surname><given-names>J</given-names></name>, <name><surname>Hashimi</surname><given-names>H</given-names></name>, <name><surname>Zikova</surname><given-names>A</given-names></name>. <article-title>Unexplained complexity of the mitochondrial genome and transcriptome in kinetoplastid flagellates</article-title>. <source>Curr Genet</source>. <year>2005</year>;<volume>48</volume>(<issue>5</issue>):<fpage>277</fpage>–<lpage>99</lpage>. <pub-id pub-id-type="doi">10.1007/s00294-005-0027-0</pub-id><?supplied-pmid 16215758?><pub-id pub-id-type="pmid">16215758</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Stuart</surname><given-names>KD</given-names></name>, <name><surname>Schnaufer</surname><given-names>A</given-names></name>, <name><surname>Ernst</surname><given-names>NL</given-names></name>, <name><surname>Panigrahi</surname><given-names>AK</given-names></name>. <article-title>Complex management: RNA editing in trypanosomes</article-title>. <source>Trends in biochemical sciences</source>. <year>2005</year>;<volume>30</volume>(<issue>2</issue>):<fpage>97</fpage>–<lpage>105</lpage>. <pub-id pub-id-type="doi">10.1016/j.tibs.2004.12.006</pub-id><?supplied-pmid 15691655?><pub-id pub-id-type="pmid">15691655</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Simpson</surname><given-names>L</given-names></name>, <name><surname>Sbicego</surname><given-names>S</given-names></name>, <name><surname>Aphasizhev</surname><given-names>R</given-names></name>. <article-title>Uridine insertion/deletion RNA editing in trypanosome mitochondria: a complex business</article-title>. <source>RNA (New York, NY)</source>. <year>2003</year>;<volume>9</volume>(<issue>3</issue>):<fpage>265</fpage>–<lpage>276</lpage>. <pub-id pub-id-type="doi">10.1261/rna.2178403</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>McManus</surname><given-names>MT</given-names></name>, <name><surname>Shimamura</surname><given-names>M</given-names></name>, <name><surname>Grams</surname><given-names>J</given-names></name>, <name><surname>Hajduk</surname><given-names>SL</given-names></name>. <article-title>Identification of candidate mitochondrial RNA editing ligases from Trypanosoma brucei</article-title>. <source>RNA</source>. <year>2001</year>;<volume>7</volume>(<issue>2</issue>):<fpage>167</fpage>–<lpage>75</lpage>. <pub-id pub-id-type="doi">10.1017/s1355838201002072</pub-id><?supplied-pmid 11233974?><pub-id pub-id-type="pmid">11233974</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Swift</surname><given-names>RV</given-names></name>, <name><surname>Durrant</surname><given-names>J</given-names></name>, <name><surname>Amaro</surname><given-names>RE</given-names></name>, <name><surname>McCammon</surname><given-names>JA</given-names></name>. <article-title>Toward understanding the conformational dynamics of RNA ligation</article-title>. <source>Biochemistry</source>. <year>2009</year>;<volume>48</volume>(<issue>4</issue>):<fpage>709</fpage>–<lpage>19</lpage>. <pub-id pub-id-type="doi">10.1021/bi8018114</pub-id><?supplied-pmid 19133737?><pub-id pub-id-type="pmid">19133737</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Ropp</surname><given-names>PJ</given-names></name>, <name><surname>Spiegel</surname><given-names>JO</given-names></name>, <name><surname>Walker</surname><given-names>JL</given-names></name>, <name><surname>Green</surname><given-names>H</given-names></name>, <name><surname>Morales</surname><given-names>GA</given-names></name>, <name><surname>Milliken</surname><given-names>KA</given-names></name>, <etal>et al</etal><article-title>Gypsum-DL: an open-source program for preparing small-molecule libraries for structure-based virtual screening</article-title>. <source>J Cheminform</source>. <year>2019</year>;<volume>11</volume>(<issue>1</issue>):<fpage>34</fpage><pub-id pub-id-type="doi">10.1186/s13321-019-0358-3</pub-id><?supplied-pmid 31127411?><pub-id pub-id-type="pmid">31127411</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Trott</surname><given-names>O</given-names></name>, <name><surname>Olson</surname><given-names>AJ</given-names></name>. <article-title>AutoDock Vina: Improving the speed and accuracy of docking with a new scoring function, efficient optimization, and multithreading</article-title>. <source>Journal of Computational Chemistry</source>. <year>2009</year>;<volume>31</volume>(<issue>2</issue>):<fpage>455</fpage>–<lpage>461</lpage>.</mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Cassidy</surname><given-names>KC</given-names></name>, <name><surname>Lahr</surname><given-names>R</given-names></name>, <name><surname>Kaminsky</surname><given-names>JC</given-names></name>, <name><surname>Mack</surname><given-names>S</given-names></name>, <name><surname>Fonseca</surname><given-names>BD</given-names></name>, <name><surname>Das</surname><given-names>SR</given-names></name>, <etal>et al</etal><article-title>Capturing the Mechanism Underlying TOP mRNA Binding to LARP1</article-title>. <source>Structure</source>. <year>2019</year><pub-id pub-id-type="doi">10.1016/j.str.2019.10.006</pub-id><?supplied-pmid 31676287?><pub-id pub-id-type="pmid">31676287</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Durrant</surname><given-names>JD</given-names></name>, <name><surname>de Oliveira</surname><given-names>CA</given-names></name>, <name><surname>McCammon</surname><given-names>JA</given-names></name>. <article-title>POVME: An algorithm for measuring binding-pocket volumes</article-title>. <source>Journal of Molecular Graphics and Modelling</source>. <year>2011</year>;<volume>29</volume>(<issue>5</issue>):<fpage>773</fpage>–<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1016/j.jmgm.2010.10.007</pub-id><?supplied-pmid 21147010?><pub-id pub-id-type="pmid">21147010</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Durrant</surname><given-names>JD</given-names></name>, <name><surname>Votapka</surname><given-names>L</given-names></name>, <name><surname>Sorensen</surname><given-names>J</given-names></name>, <name><surname>Amaro</surname><given-names>RE</given-names></name>. <article-title>POVME 2.0: An Enhanced Tool for Determining Pocket Shape and Volume Characteristics</article-title>. <source>Journal of Chemical Theory and Computation</source>. <year>2014</year>;<volume>10</volume>(<issue>11</issue>):<fpage>5047</fpage>–<lpage>5056</lpage>. <pub-id pub-id-type="doi">10.1021/ct500381c</pub-id><?supplied-pmid 25400521?><pub-id pub-id-type="pmid">25400521</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Durrant</surname><given-names>JD</given-names></name>. <article-title>BlendMol: Advanced Macromolecular Visualization in Blender</article-title>. <source>Bioinformatics</source>. <year>2018</year>;<volume>35</volume>(<issue>13</issue>):<fpage>2323</fpage>–<lpage>2325</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bty968</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref038">
      <label>38</label>
      <mixed-citation publication-type="book"><name><surname>Kent</surname><given-names>BR</given-names></name>. <source>3D scientific visualization with blender</source>. <publisher-name>Morgan &amp; Claypool Publishers</publisher-name>; <year>2014</year>.</mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Borrel</surname><given-names>A</given-names></name>, <name><surname>Fourches</surname><given-names>D</given-names></name>. <article-title>RealityConvert: a tool for preparing 3D models of biochemical structures for augmented and virtual reality</article-title>. <source>Bioinformatics</source>. <year>2017</year>;<volume>33</volume>(<issue>23</issue>):<fpage>3816</fpage>–<lpage>3818</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btx485</pub-id><?supplied-pmid 29036294?><pub-id pub-id-type="pmid">29036294</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>O’Boyle</surname><given-names>NM</given-names></name>, <name><surname>Banck</surname><given-names>M</given-names></name>, <name><surname>James</surname><given-names>CA</given-names></name>, <name><surname>Morley</surname><given-names>C</given-names></name>, <name><surname>Vandermeersch</surname><given-names>T</given-names></name>, <name><surname>Hutchison</surname><given-names>GR</given-names></name>. <article-title>Open Babel: An open chemical toolbox</article-title>. <source>J Cheminf</source>. <year>2011</year>;<volume>3</volume>:<fpage>33</fpage><pub-id pub-id-type="doi">10.1186/1758-2946-3-33</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>JF</given-names></name>, <name><surname>Paciorkowski</surname><given-names>AR</given-names></name>, <name><surname>Craig</surname><given-names>PA</given-names></name>, <name><surname>Cui</surname><given-names>F</given-names></name>. <article-title>BioVR: a platform for virtual reality assisted biological data integration and visualization</article-title>. <source>BMC Bioinformatics</source>. <year>2019</year>;<volume>20</volume>(<issue>1</issue>):<fpage>78</fpage><pub-id pub-id-type="doi">10.1186/s12859-019-2666-z</pub-id><?supplied-pmid 30767777?><pub-id pub-id-type="pmid">30767777</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref042">
      <label>42</label>
      <mixed-citation publication-type="journal"><name><surname>Goddard</surname><given-names>TD</given-names></name>, <name><surname>Huang</surname><given-names>CC</given-names></name>, <name><surname>Meng</surname><given-names>EC</given-names></name>, <name><surname>Pettersen</surname><given-names>EF</given-names></name>, <name><surname>Couch</surname><given-names>GS</given-names></name>, <name><surname>Morris</surname><given-names>JH</given-names></name>, <etal>et al</etal><article-title>UCSF ChimeraX: Meeting modern challenges in visualization and analysis</article-title>. <source>Protein Science</source>. <year>2018</year>;<volume>27</volume>(<issue>1</issue>):<fpage>14</fpage>–<lpage>25</lpage>. <pub-id pub-id-type="doi">10.1002/pro.3235</pub-id><?supplied-pmid 28710774?><pub-id pub-id-type="pmid">28710774</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Balo</surname><given-names>AR</given-names></name>, <name><surname>Wang</surname><given-names>M</given-names></name>, <name><surname>Ernst</surname><given-names>OP</given-names></name>. <article-title>Accessible virtual reality of biomolecular structural models using the Autodesk Molecule Viewer</article-title>. <source>Nature methods</source>. <year>2017</year>;<volume>14</volume>(<issue>12</issue>):<fpage>1122</fpage><pub-id pub-id-type="doi">10.1038/nmeth.4506</pub-id><?supplied-pmid 29190274?><pub-id pub-id-type="pmid">29190274</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref044">
      <label>44</label>
      <mixed-citation publication-type="journal"><name><surname>Lv</surname><given-names>Z</given-names></name>, <name><surname>Tek</surname><given-names>A</given-names></name>, <name><surname>Da Silva</surname><given-names>F</given-names></name>, <name><surname>Empereur-Mot</surname><given-names>C</given-names></name>, <name><surname>Chavent</surname><given-names>M</given-names></name>, <name><surname>Baaden</surname><given-names>M</given-names></name>. <article-title>Game on, science-how video game technology may help biologists tackle visualization challenges</article-title>. <source>PloS one</source>. <year>2013</year>;<volume>8</volume>(<issue>3</issue>). <pub-id pub-id-type="doi">10.1371/journal.pone.0057990</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref045">
      <label>45</label>
      <mixed-citation publication-type="other">Vovk A, Wild F, Guest W, Kuula T. Simulator Sickness in Augmented Reality Training Using the Microsoft HoloLens. In: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. CHI’18. New York, NY, USA: ACM; 2018. p. 209:1–209:9. Available from: <ext-link ext-link-type="uri" xlink:href="http://doi.acm.org/10.1145/3173574.3173783">http://doi.acm.org/10.1145/3173574.3173783</ext-link>.</mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref046">
      <label>46</label>
      <mixed-citation publication-type="other">Steptoe W, Julier S, Steed A. Presence and discernability in conventional and non-photorealistic immersive augmented reality. In: 2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR); 2014. p. 213–218.</mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref047">
      <label>47</label>
      <mixed-citation publication-type="journal"><name><surname>Bennie</surname><given-names>SJ</given-names></name>, <name><surname>Ranaghan</surname><given-names>KE</given-names></name>, <name><surname>Deeks</surname><given-names>H</given-names></name>, <name><surname>Goldsmith</surname><given-names>HE</given-names></name>, <name><surname>O’Connor</surname><given-names>MB</given-names></name>, <name><surname>Mulholland</surname><given-names>AJ</given-names></name>, <etal>et al</etal><article-title>Teaching enzyme catalysis using interactive molecular dynamics in virtual reality</article-title>. <source>Journal of Chemical Education</source>. <year>2019</year>;<volume>96</volume>(<issue>11</issue>):<fpage>2488</fpage>–<lpage>2496</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jchemed.9b00181</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref048">
      <label>48</label>
      <mixed-citation publication-type="journal"><name><surname>Ferrell</surname><given-names>JB</given-names></name>, <name><surname>Campbell</surname><given-names>JP</given-names></name>, <name><surname>McCarthy</surname><given-names>DR</given-names></name>, <name><surname>McKay</surname><given-names>KT</given-names></name>, <name><surname>Hensinger</surname><given-names>M</given-names></name>, <name><surname>Srinivasan</surname><given-names>R</given-names></name>, <etal>et al</etal><article-title>Chemical Exploration with Virtual Reality in Organic Teaching Laboratories</article-title>. <source>Journal of Chemical Education</source>. <year>2019</year>;<volume>96</volume>(<issue>9</issue>):<fpage>1961</fpage>–<lpage>1966</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jchemed.9b00036</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref049">
      <label>49</label>
      <mixed-citation publication-type="journal"><name><surname>O’Connor</surname><given-names>MB</given-names></name>, <name><surname>Bennie</surname><given-names>SJ</given-names></name>, <name><surname>Deeks</surname><given-names>HM</given-names></name>, <name><surname>Jamieson-Binnie</surname><given-names>A</given-names></name>, <name><surname>Jones</surname><given-names>AJ</given-names></name>, <name><surname>Shannon</surname><given-names>RJ</given-names></name>, <etal>et al</etal><article-title>Interactive molecular dynamics in virtual reality from quantum chemistry to drug binding: An open-source multi-person framework</article-title>. <source>The Journal of chemical physics</source>. <year>2019</year>;<volume>150</volume>(<issue>22</issue>):<fpage>220901</fpage><pub-id pub-id-type="doi">10.1063/1.5092590</pub-id><?supplied-pmid 31202243?><pub-id pub-id-type="pmid">31202243</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref050">
      <label>50</label>
      <mixed-citation publication-type="journal"><name><surname>Rajendiran</surname><given-names>N</given-names></name>, <name><surname>Durrant</surname><given-names>JD</given-names></name>. <article-title>Pyrite: A blender plugin for visualizing molecular dynamics simulations using industry-standard rendering techniques</article-title>. <source>Journal of Computational Chemistry</source>. <year>2018</year>;<volume>39</volume>(<issue>12</issue>):<fpage>748</fpage>–<lpage>755</lpage>. <pub-id pub-id-type="doi">10.1002/jcc.25155</pub-id><?supplied-pmid 29280166?><pub-id pub-id-type="pmid">29280166</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref051">
      <label>51</label>
      <mixed-citation publication-type="journal"><name><surname>Pacheco</surname><given-names>S</given-names></name>, <name><surname>Kaminsky</surname><given-names>JC</given-names></name>, <name><surname>Kochnev</surname><given-names>IK</given-names></name>, <name><surname>Durrant</surname><given-names>JD</given-names></name>. <article-title>PCAViz: An Open-Source Python/JavaScript Toolkit for Visualizing Molecular Dynamics Simulations in the Web Browser</article-title>. <source>Journal of Chemical Information and Modeling</source>. <year>2019</year>;<volume>59</volume>(<issue>10</issue>):<fpage>4087</fpage>–<lpage>4092</lpage>. <pub-id pub-id-type="doi">10.1021/acs.jcim.9b00703</pub-id><?supplied-pmid 31580061?><pub-id pub-id-type="pmid">31580061</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref052">
      <label>52</label>
      <mixed-citation publication-type="journal"><name><surname>Durrant</surname><given-names>JD</given-names></name>, <name><surname>McCammon</surname><given-names>JA</given-names></name>. <article-title>BINANA: A novel algorithm for ligand-binding characterization</article-title>. <source>Journal of Molecular Graphics and Modelling</source>. <year>2011</year>;<volume>29</volume>(<issue>6</issue>):<fpage>888</fpage>–<lpage>893</lpage>. <pub-id pub-id-type="doi">10.1016/j.jmgm.2011.01.004</pub-id><?supplied-pmid 21310640?><pub-id pub-id-type="pmid">21310640</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref053">
      <label>53</label>
      <mixed-citation publication-type="journal"><name><surname>Mikropoulos</surname><given-names>TA</given-names></name>, <name><surname>Natsis</surname><given-names>A</given-names></name>. <article-title>Educational virtual environments: A ten-year review of empirical research (1999–2009)</article-title>. <source>Computers &amp; Education</source>. <year>2011</year>;<volume>56</volume>(<issue>3</issue>):<fpage>769</fpage>–<lpage>780</lpage>. <pub-id pub-id-type="doi">10.1016/j.compedu.2010.10.020</pub-id></mixed-citation>
    </ref>
    <ref id="pcbi.1007747.ref054">
      <label>54</label>
      <mixed-citation publication-type="journal"><name><surname>Trindade</surname><given-names>J</given-names></name>, <name><surname>Fiolhais</surname><given-names>C</given-names></name>, <name><surname>Almeida</surname><given-names>L</given-names></name>. <article-title>Science learning in virtual environments: a descriptive study</article-title>. <source>British Journal of Educational Technology</source>. <year>2002</year>;<volume>33</volume>(<issue>4</issue>):<fpage>471</fpage>–<lpage>488</lpage>. <pub-id pub-id-type="doi">10.1111/1467-8535.00283</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
