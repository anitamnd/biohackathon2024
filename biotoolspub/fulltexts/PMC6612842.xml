<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id>
    <journal-id journal-id-type="publisher-id">bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">1367-4803</issn>
    <issn pub-type="epub">1367-4811</issn>
    <publisher>
      <publisher-name>Oxford University Press</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6612842</article-id>
    <article-id pub-id-type="doi">10.1093/bioinformatics/btz361</article-id>
    <article-id pub-id-type="publisher-id">btz361</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Ismb/Eccb 2019 Conference Proceedings</subject>
        <subj-group subj-group-type="category-toc-heading">
          <subject>Studies of Phenotypes and Clinical Applications</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Model-based optimization of subgroup weights for survival analysis</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Richter</surname>
          <given-names>Jakob</given-names>
        </name>
        <xref ref-type="corresp" rid="btz361-cor1"/>
        <!--<email>jakob.richter@tu-dortmund.de</email>-->
        <xref ref-type="aff" rid="btz361-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Madjar</surname>
          <given-names>Katrin</given-names>
        </name>
        <xref ref-type="aff" rid="btz361-aff1"/>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Rahnenführer</surname>
          <given-names>Jörg</given-names>
        </name>
        <xref ref-type="aff" rid="btz361-aff1"/>
      </contrib>
    </contrib-group>
    <aff id="btz361-aff1">Department of Statistics, TU Dortmund University, Dortmund, Germany</aff>
    <author-notes>
      <corresp id="btz361-cor1">To whom correspondence should be addressed. <email>jakob.richter@tu-dortmund.de</email></corresp>
    </author-notes>
    <pub-date pub-type="ppub">
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="epub" iso-8601-date="2019-07-05">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>05</day>
      <month>7</month>
      <year>2019</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. -->
    <volume>35</volume>
    <issue>14</issue>
    <fpage>i484</fpage>
    <lpage>i491</lpage>
    <permissions>
      <copyright-statement>© The Author(s) 2019. Published by Oxford University Press.</copyright-statement>
      <copyright-year>2019</copyright-year>
      <license license-type="cc-by-nc" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">
        <license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link>), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="btz361.pdf"/>
    <abstract>
      <title>Abstract</title>
      <sec id="s1">
        <title>Motivation</title>
        <p>To obtain a reliable prediction model for a specific cancer subgroup or cohort is often difficult due to limited sample size and, in survival analysis, due to potentially high censoring rates. Sometimes similar data from other patient subgroups are available, e.g. from other clinical centers. Simple pooling of all subgroups can decrease the variance of the predicted parameters of the prediction models, but also increase the bias due to heterogeneity between the cohorts. A promising compromise is to identify those subgroups with a similar relationship between covariates and target variable and then include only these for model building.</p>
      </sec>
      <sec id="s2">
        <title>Results</title>
        <p>We propose a subgroup-based weighted likelihood approach for survival prediction with high-dimensional genetic covariates. When predicting survival for a specific subgroup, for every other subgroup an individual weight determines the strength with which its observations enter into model building. MBO (model-based optimization) can be used to quickly find a good prediction model in the presence of a large number of hyperparameters. We use MBO to identify the best model for survival prediction of a specific subgroup by optimizing the weights for additional subgroups for a Cox model. The approach is evaluated on a set of lung cancer cohorts with gene expression measurements. The resulting models have competitive prediction quality, and they reflect the similarity of the corresponding cancer subgroups, with both weights close to 0 and close to 1 and medium weights.</p>
      </sec>
      <sec id="s3">
        <title>Availability and implementation</title>
        <p><monospace>mlrMBO</monospace> is implemented as an R-package and is freely available at <ext-link ext-link-type="uri" xlink:href="http://github.com/mlr-org/mlrMBO">http://github.com/mlr-org/mlrMBO</ext-link>.</p>
      </sec>
    </abstract>
    <funding-group>
      <award-group award-type="grant">
        <funding-source>
          <named-content content-type="funder-name">Deutsche Forschungsgemeinschaft</named-content>
          <named-content content-type="funder-identifier">10.13039/501100001659</named-content>
        </funding-source>
        <award-id>SFB 876, A3</award-id>
      </award-group>
    </funding-group>
    <counts>
      <page-count count="8"/>
    </counts>
  </article-meta>
</front>
<body>
  <sec>
    <title>1 Introduction</title>
    <p>Survival analysis is a central aspect in cancer research with the aim of predicting a patient’s risk based on genomic and/or clinical covariates. In clinical practice, this is often challenging because patient cohorts are typically small and can be heterogeneous with regard to their relationship between covariates and survival outcome. One standard approach in multicenter studies is to simply pool different patient cohorts (here cohorts from different clinical centers) to increase sample size. However, this can lead to biased results especially when the cohorts are heterogeneous. In standard subgroup analysis, only the patients of the subgroup of interest <inline-formula id="IE1"><mml:math id="IM1"><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> are included in the subgroup-specific model. This can lead to unstable results, especially for smaller subgroups.</p>
    <p>We aim at improving the prediction performance for a specific subgroup by adaptively adding data from the other subgroups, in order to benefit from the larger sample size, but at the same time taking into account heterogeneity. Our proposed model potentially uses all subgroups but assigns them subgroup-dependent weights. If the inclusion of another subgroup increases the predictive performance, this subgroup enters with a higher weight into the model building process.</p>
    <p>This idea extends the work of <xref rid="btz361-B28" ref-type="bibr">Weyer and Binder (2015)</xref> who aim at improving stability and prediction quality of a model for a specific subgroup by including one additional weighted subgroup. The authors study the effects of a set of different fixed weights for the additional subgroup in a stratified Cox model, with respect to both, model performance and parameter stability.</p>
    <p>In our approach, we use multiple additional subgroups and efficiently optimize respective subgroup-specific weight parameters to improve the prediction quality of a Cox model. The optimal subgroup weights are determined by optimizing the cross-validated Concordance index (C-index) through Bayesian optimization (<xref rid="btz361-B16" ref-type="bibr">Jones <italic>et al.</italic>, 1998</xref>). In an adapted version of classical cross-validation, only the patients of the subgroup <inline-formula id="IE2"><mml:math id="IM2"><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> of interest are included in the test set, while all patients from all subgroups can potentially be used for training. The idea is to assign large weights exactly to those subgroups that improve the prediction performance of the model for subgroup <inline-formula id="IE3"><mml:math id="IM3"><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. Those subgroups that deteriorate the predictive performance (mainly due to a different relationship between covariates and survival outcome) are assigned lower weights.</p>
    <p>We show that with our subgroup weights optimization approach, the predictive quality can be improved compared to the two naïve approaches to either fully include or fully exclude all other subgroups. As an application example, we use 10 non-small-cell lung cancer (NSCLC) studies as subgroups and optimize the prediction quality for each subgroup, respectively, using all other subgroups with optimized weights.</p>
    <sec>
      <title>1.1 Related work</title>
      <p>The approach of <xref rid="btz361-B28" ref-type="bibr">Weyer and Binder (2015)</xref> uses the same fixed weight for all other subgroups. Alternatively, individual weights for each patient can be estimated from the training data as proposed by <xref rid="btz361-B3" ref-type="bibr">Bickel <italic>et al.</italic> (2008)</xref>. The idea is that weights match the joint distribution of the complete data to the distribution in each subgroup, such that a patient who is likely to belong to the subgroup of interest receives a higher weight in the subgroup-specific model. Weights correspond to the conditional probability of belonging to the target subgroup <inline-formula id="IE4"><mml:math id="IM4"><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> given the observed covariates and outcome divided by the prior probability for <inline-formula id="IE5"><mml:math id="IM5"><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. The former is estimated from the training data by multiclass classification and the latter by the relative frequency of <inline-formula id="IE6"><mml:math id="IM6"><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
      <p>Bayesian approaches for estimating subgroup weights were proposed by <xref rid="btz361-B7" ref-type="bibr">Bogojeska and Lengauer (2012)</xref> and <xref rid="btz361-B24" ref-type="bibr">Simon (2002)</xref>. <xref rid="btz361-B7" ref-type="bibr">Bogojeska and Lengauer (2012)</xref> use a hierarchical weighted logistic regression model with prior distributions for the subgroup weights to predict the binary treatment response of an HIV combination therapy. <xref rid="btz361-B24" ref-type="bibr">Simon (2002)</xref> considers a Cox model including a binary treatment effect, a binary subgroup indicator and the corresponding treatment-by-subgroup interaction with prior distribution for the regression coefficients. The author shows that the components of the posterior mean are linear combinations of the estimated treatment effects in different subgroups and extracting the respective scalars yields the subgroup-specific weights.</p>
      <p>Integrative analysis combines data from different data sources such as multiple studies. In the context of high-dimensional genomic predictors, Liu <italic>et al.</italic> (<xref rid="btz361-B19" ref-type="bibr">2014a</xref>, <xref rid="btz361-B20" ref-type="bibr">b</xref>) suggest regularized regression with composite penalties for parameter estimation and gene selection. These penalties allow to select either the same set of genes or different sets of genes in all studies. Instead of aggregating multiple studies with the same type of (omics) data, <xref rid="btz361-B8" ref-type="bibr">Boulesteix <italic>et al.</italic> (2017)</xref> perform integrative analysis of multiple omics data types available for the same patient cohort. They use a lasso penalty with different penalty parameters for the different data types. <xref rid="btz361-B1" ref-type="bibr">Bergersen <italic>et al.</italic> (2011)</xref> integrate external information provided by another genomic data type by using a weighted lasso that penalizes each covariate individually with weights inversely proportional to the external information.</p>
      <p>Instead of sharing information between subgroups by integrating external information into variable selection, <xref rid="btz361-B15" ref-type="bibr">Huang <italic>et al.</italic> (2011)</xref> propose a weighted approach for combining positive predictive value (PPV) and negative predictive value (NPV) across populations when the assumption of common classification accuracy is justified. ROC curve estimation is used to evaluate the ability of a risk prediction marker in discriminating diseased from non-diseased. The estimates of PPV and NPV are based on a weighted average of the ROC curves from a target and an auxiliary population.</p>
      <p>Local regression uses weighted regression models but without predefined groups. A separate model is fitted to each observation based on its neighboring observations. Weights in the likelihood of the local regression model represent the distance from the observation of interest and determine to which extent the neighboring observations influence the estimation. All single local regression models together form the local weighted regression based on all observations (<xref rid="btz361-B12" ref-type="bibr">Hastie <italic>et al.</italic>, 2009</xref>, chapters 2.8.2 and 6).</p>
      <p>Instead of using distance in covariate space, our proposed weights are optimized with respect to prediction performance. A drawback of localized regression is that it does not provide global regression parameters, making interpretation difficult. Furthermore, only a small number of observations is used for each local fit in contrast to our approach, where the weighted likelihood is based on all training data. This makes estimation in high-dimensional settings even more complicated. To deal with this problem, <xref rid="btz361-B27" ref-type="bibr">Tutz and Binder (2005)</xref> developed a penalized localized classification approach and <xref rid="btz361-B4" ref-type="bibr">Binder <italic>et al.</italic> (2012)</xref> propose a cluster-localized logistic regression with weighted component-wise likelihood-based boosting for automatic variable selection and a special clustering for SNP data.</p>
      <p>Above-mentioned approaches have in common that the goal is to achieve a high predictive accuracy on a specific subgroup by combining data from different subgroups. If multiple subgroups are available, another aim can be the identification of models that not only work well on the data they have been trained on but also on the other subgroups. <xref rid="btz361-B2" ref-type="bibr">Bernau <italic>et al.</italic> (2014)</xref> point out that classical cross-validation tends to be too optimistic, with respect to accuracy on data of unseen subgroups. They propose to include all available subgroups for the validation of a single model. <xref rid="btz361-B29" ref-type="bibr">Zhao <italic>et al.</italic> (2014)</xref> compare different regression methods for gene expression data and survival outcome with respect to accuracy. They use the largest subgroup for training and investigate which regression approach performs well on the remaining subgroups.</p>
    </sec>
  </sec>
  <sec>
    <title>2 Gene expression data</title>
    <p>Ten lung cancer cohorts with overall survival and censoring information, Affymetrix microarray gene expression data of the tumor material, and several clinicopathologic information, were downloaded from the Gene Expression Omnibus (GEO) data repository (<xref rid="btz361-B11" ref-type="bibr">Edgar <italic>et al.</italic>, 2002</xref>) and manually curated as follows. Raw gene expression data (CEL files), measured on the Affymetrix HG-U133 Plus 2.0 and HGU-133A array, were normalized using frozen robust multiarray analysis (fRMA) (<xref rid="btz361-B21" ref-type="bibr">McCall <italic>et al.</italic>, 2010</xref>), except for <monospace>GSE3141</monospace> and <monospace>GSE4573</monospace>, where only MAS5-normalized data were available. All cohorts were checked for duplicates by looking at correlations of the expression value vectors. Duplicates, small cell cancer samples and normal (nontumorous) samples, as well as samples with missing survival endpoint were removed. More details on the data curation process can be found in <xref rid="btz361-B13" ref-type="bibr">Hellwig <italic>et al.</italic> (2016)</xref>.</p>
    <p>The resulting 10 NSCLC cohorts comprise <italic>n </italic> = 1779 patients with available overall survival endpoint and gene expression data as covariates which are used for analysis. The total number of measured genetic covariates (probe sets that represent genes) in each cohort is 22 283 or 54 675 depending on the Affymetrix array. We restricted the analysis to the 22 277 probe sets in the overlap of both Affymetrix arrays. The majority of these probe sets are noise and do not contain relevant information regarding survival outcome. This makes the identification of the prognostic genes more difficult and slows down computation time. Therefore, we use a reduced gene set for analysis that is based on the 1000 features (probe sets) with the highest variance in gene expression values across all 10 cohorts within the optimization dataset and a small number of literature-based prognostic genes. The selection of the top-1000-variance features is based on the assumption that important prognostic genes imply systematic changes in their expression values and thus, a larger variance in contrast to irrelevant noise genes. The following 30 prognostic features (probe sets) belong to 13 of the 14 prognostic lung cancer genes from <xref rid="btz361-B18" ref-type="bibr">Kratz <italic>et al.</italic> (2012)</xref> with matches on the Affymetrix HG-U133 Plus 2.0 and HGU-133A array. Gene symbols (provided in brackets) were translated into corresponding probe set IDs using the R/Bioconductor annotation package hgu133plus2.db (version 3.2.3):</p>
    <p><monospace>202387_at</monospace> (BAG1), <monospace>211475_s_at</monospace> (BAG1), <monospace>229720_at</monospace> (BAG1), <monospace>204531_s_at</monospace> (BRCA1), <monospace>211851_x_at</monospace> (BRCA1), <monospace>203967_at</monospace> (CDC6), <monospace>203968_s_at</monospace> (CDC6), <monospace>201938_at</monospace> (CDK2AP1), <monospace>1563252_at</monospace> (ERBB3), <monospace>1563253_s_at</monospace> (ERBB3), <monospace>202454_s_at</monospace> (ERBB3), <monospace>215638_at</monospace> (ERBB3), <monospace>226213_at</monospace> (ERBB3), <monospace>214088_s_at</monospace> (FUT3), 216010_x_at (FUT3), <monospace>206924_at</monospace> (IL11), <monospace>206926_s_at</monospace> (IL11), <monospace>204890_s_at</monospace> (LCK), <monospace>204891_s_at</monospace> (LCK), <monospace>212724_at</monospace> (RND3), <monospace>204979_s_at</monospace> (SH3BGR), <monospace>209009_at</monospace> (ESD), <monospace>215095_at</monospace> (ESD), <monospace>215096_s_at</monospace> (ESD), <monospace>228162_at</monospace> (ESD), <monospace>240808_at</monospace> (ESD), <monospace>203135_at</monospace> (TBP), <monospace>213342_at</monospace> (YAP1), <monospace>224894_at</monospace> (YAP1), <monospace>224895_at</monospace> (YAP1).</p>
    <p>For each cohort, the Kaplan–Meier estimator of the survival function is plotted in <xref ref-type="fig" rid="btz361-F1">Figure 1</xref>. The Kaplan–Meier plot shows that patients in cohort <monospace>GSE31210</monospace> have the best prognosis with a 10-year overall survival probability of about 75%, while <monospace>GSE37745</monospace> exhibits a poor prognosis with a 10-year overall survival of 25%. <monospace>GSE29013</monospace> has the shortest maximum follow-up time with about 7 years, and <monospace>GSE30219</monospace> the longest maximum follow-up time with about 20 years. A summary of the clinicopathologic variables is provided in <xref rid="btz361-T1" ref-type="table">Table 1</xref>.</p>
    <table-wrap id="btz361-T1" orientation="portrait" position="float">
      <label>Table 1.</label>
      <caption>
        <p>Overview of clinical variables for each lung cancer cohort in the complete <monospace>NSCLC</monospace> dataset</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="char" char="." span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="1" colspan="1">Variable</th>
            <th align="left" rowspan="1" colspan="1">Values</th>
            <th rowspan="1" colspan="1">
              <monospace>GSE14814</monospace>
            </th>
            <th rowspan="1" colspan="1">
              <monospace>GSE19188</monospace>
            </th>
            <th rowspan="1" colspan="1">
              <monospace>GSE29013</monospace>
            </th>
            <th rowspan="1" colspan="1">
              <monospace>GSE30219</monospace>
            </th>
            <th rowspan="1" colspan="1">
              <monospace>GSE31210</monospace>
            </th>
            <th rowspan="1" colspan="1">
              <monospace>GSE3141</monospace>
            </th>
            <th rowspan="1" colspan="1">
              <monospace>GSE37745</monospace>
            </th>
            <th rowspan="1" colspan="1">
              <monospace>GSE4573</monospace>
            </th>
            <th rowspan="1" colspan="1">
              <monospace>GSE50081</monospace>
            </th>
            <th rowspan="1" colspan="1">
              <monospace>Shedden</monospace>
            </th>
          </tr>
          <tr>
            <th colspan="12" rowspan="1">
              <hr/>
            </th>
          </tr>
          <tr>
            <th rowspan="1" colspan="1">Sample size</th>
            <th rowspan="1" colspan="1"/>
            <th align="center" rowspan="1" colspan="1">90</th>
            <th align="center" rowspan="1" colspan="1">82</th>
            <th align="center" rowspan="1" colspan="1">55</th>
            <th align="center" rowspan="1" colspan="1">269</th>
            <th align="center" rowspan="1" colspan="1">226</th>
            <th align="center" rowspan="1" colspan="1">110</th>
            <th align="center" rowspan="1" colspan="1">194</th>
            <th align="center" rowspan="1" colspan="1">130</th>
            <th align="center" rowspan="1" colspan="1">181</th>
            <th align="center" rowspan="1" colspan="1">442</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">Min.</td>
            <td rowspan="1" colspan="1">38</td>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">32</td>
            <td rowspan="1" colspan="1">15</td>
            <td rowspan="1" colspan="1">30</td>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">39</td>
            <td rowspan="1" colspan="1">42</td>
            <td rowspan="1" colspan="1">40</td>
            <td rowspan="1" colspan="1">33</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Age (years)</td>
            <td rowspan="1" colspan="1">Mean</td>
            <td rowspan="1" colspan="1">62</td>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">64</td>
            <td rowspan="1" colspan="1">61</td>
            <td rowspan="1" colspan="1">60</td>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">64</td>
            <td rowspan="1" colspan="1">67</td>
            <td rowspan="1" colspan="1">68</td>
            <td rowspan="1" colspan="1">64</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">Max.</td>
            <td rowspan="1" colspan="1">81</td>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">76</td>
            <td rowspan="1" colspan="1">84</td>
            <td rowspan="1" colspan="1">76</td>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">84</td>
            <td rowspan="1" colspan="1">91</td>
            <td rowspan="1" colspan="1">87</td>
            <td rowspan="1" colspan="1">87</td>
          </tr>
          <tr>
            <td colspan="12" rowspan="1">
              <hr/>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">Male</td>
            <td rowspan="1" colspan="1">67</td>
            <td rowspan="1" colspan="1">59</td>
            <td rowspan="1" colspan="1">38</td>
            <td rowspan="1" colspan="1">228</td>
            <td rowspan="1" colspan="1">105</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">105</td>
            <td rowspan="1" colspan="1">82</td>
            <td rowspan="1" colspan="1">98</td>
            <td rowspan="1" colspan="1">223</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Sex</td>
            <td rowspan="1" colspan="1">Female</td>
            <td rowspan="1" colspan="1">23</td>
            <td rowspan="1" colspan="1">23</td>
            <td rowspan="1" colspan="1">17</td>
            <td rowspan="1" colspan="1">40</td>
            <td rowspan="1" colspan="1">121</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">89</td>
            <td rowspan="1" colspan="1">47</td>
            <td rowspan="1" colspan="1">83</td>
            <td rowspan="1" colspan="1">219</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">NA</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">1</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">110</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">1</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
          </tr>
          <tr>
            <td colspan="12" rowspan="1">
              <hr/>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">I</td>
            <td rowspan="1" colspan="1">45</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">24</td>
            <td rowspan="1" colspan="1">183</td>
            <td rowspan="1" colspan="1">168</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">128</td>
            <td rowspan="1" colspan="1">73</td>
            <td rowspan="1" colspan="1">127</td>
            <td rowspan="1" colspan="1">0</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">II</td>
            <td rowspan="1" colspan="1">45</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">14</td>
            <td rowspan="1" colspan="1">35</td>
            <td rowspan="1" colspan="1">58</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">35</td>
            <td rowspan="1" colspan="1">34</td>
            <td rowspan="1" colspan="1">54</td>
            <td rowspan="1" colspan="1">0</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">pTNM stage</td>
            <td rowspan="1" colspan="1">III</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">17</td>
            <td rowspan="1" colspan="1">42</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">27</td>
            <td rowspan="1" colspan="1">23</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">IV</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">4</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">4</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">NA</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">82</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">5</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">110</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">442</td>
          </tr>
          <tr>
            <td colspan="12" rowspan="1">
              <hr/>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">SQC</td>
            <td rowspan="1" colspan="1">52</td>
            <td rowspan="1" colspan="1">24</td>
            <td rowspan="1" colspan="1">25</td>
            <td rowspan="1" colspan="1">61</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">52</td>
            <td rowspan="1" colspan="1">64</td>
            <td rowspan="1" colspan="1">130</td>
            <td rowspan="1" colspan="1">43</td>
            <td rowspan="1" colspan="1">0</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">ADC</td>
            <td rowspan="1" colspan="1">28</td>
            <td rowspan="1" colspan="1">40</td>
            <td rowspan="1" colspan="1">30</td>
            <td rowspan="1" colspan="1">85</td>
            <td rowspan="1" colspan="1">226</td>
            <td rowspan="1" colspan="1">58</td>
            <td rowspan="1" colspan="1">106</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">127</td>
            <td rowspan="1" colspan="1">442</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Histology</td>
            <td rowspan="1" colspan="1">LCC</td>
            <td rowspan="1" colspan="1">10</td>
            <td rowspan="1" colspan="1">18</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">55</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">24</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">7</td>
            <td rowspan="1" colspan="1">0</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">other NSCLC</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">68</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">4</td>
            <td rowspan="1" colspan="1">0</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">NA</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
          </tr>
          <tr>
            <td colspan="12" rowspan="1">
              <hr/>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">Never smoker</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">2</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">115</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">15</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">24</td>
            <td rowspan="1" colspan="1">49</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Smoking status</td>
            <td rowspan="1" colspan="1">Current /ex-smoker</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">53</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">111</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">179</td>
            <td rowspan="1" colspan="1">123</td>
            <td rowspan="1" colspan="1">136</td>
            <td rowspan="1" colspan="1">300</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">NA</td>
            <td rowspan="1" colspan="1">90</td>
            <td rowspan="1" colspan="1">82</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">269</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">110</td>
            <td rowspan="1" colspan="1">0</td>
            <td rowspan="1" colspan="1">7</td>
            <td rowspan="1" colspan="1">21</td>
            <td rowspan="1" colspan="1">93</td>
          </tr>
          <tr>
            <td colspan="12" rowspan="1">
              <hr/>
            </td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Survival status</td>
            <td rowspan="1" colspan="1">Censoring</td>
            <td rowspan="1" colspan="1">52</td>
            <td rowspan="1" colspan="1">32</td>
            <td rowspan="1" colspan="1">37</td>
            <td rowspan="1" colspan="1">99</td>
            <td rowspan="1" colspan="1">191</td>
            <td rowspan="1" colspan="1">52</td>
            <td rowspan="1" colspan="1">51</td>
            <td rowspan="1" colspan="1">63</td>
            <td rowspan="1" colspan="1">106</td>
            <td rowspan="1" colspan="1">206</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1"/>
            <td rowspan="1" colspan="1">Event</td>
            <td rowspan="1" colspan="1">38</td>
            <td rowspan="1" colspan="1">50</td>
            <td rowspan="1" colspan="1">18</td>
            <td rowspan="1" colspan="1">170</td>
            <td rowspan="1" colspan="1">35</td>
            <td rowspan="1" colspan="1">58</td>
            <td rowspan="1" colspan="1">143</td>
            <td rowspan="1" colspan="1">67</td>
            <td rowspan="1" colspan="1">75</td>
            <td rowspan="1" colspan="1">236</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <fig id="btz361-F1" orientation="portrait" position="float">
      <label>Fig. 1.</label>
      <caption>
        <p>Kaplan–Meier plots of the estimated survival functions for all 10 lung cancer cohorts</p>
      </caption>
      <graphic xlink:href="btz361f1"/>
    </fig>
  </sec>
  <sec>
    <title>3 Weighted Cox model</title>
    <p>Assume the observed data of patient <italic>i</italic> consists of the tuples <inline-formula id="IE7"><mml:math id="IM7"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>δ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, the covariate vectors <inline-formula id="IE8"><mml:math id="IM8"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ip</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>′</mml:mo><mml:mo>∈</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mi>p</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, and the subgroup membership <inline-formula id="IE9"><mml:math id="IM9"><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> with <italic>S</italic> the number of subgroups in the complete dataset, and <inline-formula id="IE10"><mml:math id="IM10"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>. <inline-formula id="IE11"><mml:math id="IM11"><mml:mrow><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>min</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denotes the observed time of patient <italic>i</italic>, with <italic>T<sub>i</sub></italic> the event time and <italic>C<sub>i</sub></italic> the censoring time. <inline-formula id="IE12"><mml:math id="IM12"><mml:mrow><mml:msub><mml:mrow><mml:mo>δ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> indicates whether a patient experienced an event (<inline-formula id="IE13"><mml:math id="IM13"><mml:mrow><mml:msub><mml:mrow><mml:mo>δ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) or was (right-)censored (<inline-formula id="IE14"><mml:math id="IM14"><mml:mrow><mml:msub><mml:mrow><mml:mo>δ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>). The most popular regression model in survival analysis is the Cox proportional hazards model (<xref rid="btz361-B9" ref-type="bibr">Cox, 1972</xref>). It models the hazard rate <inline-formula id="IE15"><mml:math id="IM15"><mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> of an individual at time <italic>t</italic> as
<disp-formula id="E1"><mml:math id="M1"><mml:mrow><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>·</mml:mo><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>′</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>·</mml:mo><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE16"><mml:math id="IM16"><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the baseline hazard rate, and <inline-formula id="IE17"><mml:math id="IM17"><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:math></inline-formula> is the unknown parameter vector. The parameters are estimated by maximizing the partial log-likelihood (<xref rid="btz361-B17" ref-type="bibr">Klein and Moeschberger, 2003</xref>, chapter 8.3).In order to take subgroups into account, a weighted version of the partial log-likelihood as in <xref rid="btz361-B28" ref-type="bibr">Weyer and Binder (2015)</xref> is used:
<disp-formula id="E2"><label>(1)</label><mml:math id="M2"><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mo>δ</mml:mo></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="true">(</mml:mo><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>′</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>ln</mml:mi><mml:mo stretchy="true">[</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mo> </mml:mo><mml:mn mathvariant="double-struck">1</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mtext>exp</mml:mtext><mml:mo> </mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo>′</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy="true">]</mml:mo><mml:mo stretchy="true">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
    <p>In the subgroup-specific model for subgroup <inline-formula id="IE18"><mml:math id="IM18"><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>, the individual weights are given by
<disp-formula id="E3"><label>(2)</label><mml:math id="M3"><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mtable><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo> </mml:mo><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo> </mml:mo><mml:mtext>if</mml:mtext><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>g</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>}</mml:mo><mml:mo>∖</mml:mo><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE19"><mml:math id="IM19"><mml:mrow><mml:msup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> is the specific weight for subgroup <italic>g</italic>. Standard subgroup analysis is based only on the patients in the subgroup of interest (target subgroup <inline-formula id="IE20"><mml:math id="IM20"><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>), which corresponds to <italic>w </italic>=<italic> </italic>0 for all patients not belonging to <inline-formula id="IE21"><mml:math id="IM21"><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. A combined model that pools patients from all subgroups corresponds to <italic>w </italic>=<italic> </italic>1 for all patients.</p>
    <p>In high-dimensional settings where the number of covariates <italic>p</italic> is typically much larger than the sample size <italic>n</italic>, standard maximum likelihood cannot be used for parameter estimation. Therefore, we add a lasso penalty (<xref rid="btz361-B25" ref-type="bibr">Tibshirani, 1996</xref>, <xref rid="btz361-B26" ref-type="bibr">1997</xref>) to the partial log-likelihood. Lasso regression performs variable selection and yields a sparse model solution. The resulting maximization problem of the penalized partial log-likelihood is given by
<disp-formula id="E4"><mml:math id="M4"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mtext>argmax</mml:mtext></mml:mrow><mml:mi mathvariant="bold-italic">β</mml:mi></mml:munder><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">β</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo>λ</mml:mo><mml:mo>·</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mo>β</mml:mo></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo stretchy="true">}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p>
    <p>The parameter <italic>λ</italic> controls the strength of penalization and is optimized by 10-fold cross-validation.</p>
  </sec>
  <sec>
    <title>4 Model-based optimization</title>
    <p>Sequential model-based optimization (MBO) (<xref rid="btz361-B16" ref-type="bibr">Jones <italic>et al.</italic>, 1998</xref>) (also known as Bayesian optimization) is a state-of-the-art (<xref rid="btz361-B23" ref-type="bibr">Shahriari <italic>et al.</italic>, 2016</xref>) technique for expensive black-box optimization problems. In comparison to other black-box optimization methods, like genetic algorithms or simulated annealing, MBO is especially suitable when evaluating a configuration (e.g. fitting and evaluating a model with specific hyperparameters, here denoted by <italic>θ</italic>) is very time consuming, as it becomes infeasible to evaluate the black box for thousands of configurations. MBO solves the optimization problem within a bounded search space <italic>θ</italic>:
<disp-formula id="E5"><mml:math id="M5"><mml:mrow><mml:msup><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mo>∗</mml:mo></mml:msup><mml:mo>:</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi>argmin</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mo>θ</mml:mo><mml:mo>∈</mml:mo><mml:mo>Θ</mml:mo></mml:mrow></mml:msub><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>θ</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula id="IE22"><mml:math id="IM22"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>θ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> denotes the evaluation of the black box with the input configuration <italic>θ</italic>. To reduce the number of evaluations on <italic>f</italic> the key idea of MBO is to only evaluate values of <italic>θ</italic> that are expected to lead to a small value of <inline-formula id="IE23"><mml:math id="IM23"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>θ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. The estimate <inline-formula id="IE24"><mml:math id="IM24"><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mo>θ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is generated by a so-called <italic>surrogate model</italic>. Typically, this is a regression model that predicts the outcome of <italic>f</italic> based on previous evaluations of <italic>f</italic>. First, an initial design of already evaluated configurations is needed. Then, iteratively, the MBO algorithm fits the surrogate on the previous evaluations, proposes a new configuration <italic>θ</italic> and evaluates it on <italic>f</italic>.</p>
    <p>A so-called infill criterion guides the proposal of new configurations <italic>θ</italic> based on <inline-formula id="IE25"><mml:math id="IM25"><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. It balances between exploration of not yet evaluated regions in Θ and exploitation, i.e. the search in regions that promise best outcomes. As infill criterion, we use the augmented expected improvement (<xref rid="btz361-B14" ref-type="bibr">Huang <italic>et al.</italic>, 2006</xref>) that is well suited for noisy functions. The steps are repeated until a budget is exhausted. For non-noisy optimization, we would choose the configuration <inline-formula id="IE26"><mml:math id="IM26"><mml:mrow><mml:msup><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> that has led to the best outcome of <italic>f</italic> to be returned as the tuning result. If the function outcome is noisy, the best observed outcome is likely to be distorted by noise and not located at the true posterior mean. Therefore, we employ the surrogate to estimate the posterior mean for each evaluated configuration to cancel out the noise. The configuration for which the surrogate estimates the best outcome is then returned as the optimization result <inline-formula id="IE27"><mml:math id="IM27"><mml:mrow><mml:msup><mml:mrow><mml:mo>θ</mml:mo></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>.</p>
    <p>We apply Kriging (also called Gaussian process regression) to fit the surrogate model that predicts the outcome of <italic>f</italic> for unknown values of <italic>θ</italic>. We use the implementation in the R-package <italic>DiceKriging</italic> (<xref rid="btz361-B22" ref-type="bibr">Roustant <italic>et al.</italic>, 2012</xref>) and configure it to apply the Mattern <inline-formula id="IE28"><mml:math id="IM28"><mml:mrow><mml:mn>3</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> kernel with an estimated <italic>nugget effect</italic> to account for the noisy response of <italic>f</italic>.</p>
    <p>In our study, we apply MBO to optimize the subgroup-specific weights <inline-formula id="IE29"><mml:math id="IM29"><mml:mrow><mml:msup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> in the weighted Cox model. For each weight configuration <inline-formula id="IE30"><mml:math id="IM30"><mml:mrow><mml:mo>θ</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> (assuming <inline-formula id="IE31"><mml:math id="IM31"><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:math></inline-formula>), we evaluate the weighted Cox model with a 10-fold cross-validation. As a result, we obtain 10 noisy outcomes for each <italic>θ</italic>. These are fed to the MBO. However, due to numerical instabilities in some situations, the maximum likelihood estimation of the covariance matrix of the Kriging surrogate model can fail which results in a constant mean prediction. This leads to randomly proposed points for the next MBO step. To avoid this case, we implemented a fallback model: If the prediction of the surrogate model is constant, all noisy response values <inline-formula id="IE32"><mml:math id="IM32"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>θ</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> belonging to the same <italic>θ</italic> are aggregated by their means. These simplified data usually lead to models without constant predictions.</p>
  </sec>
  <sec>
    <title>5 Evaluation and results</title>
    <p>We apply the methods described above to obtain a separate predictive model for each of the 10 NSCLC cohorts. We use a weighted Cox model to predict the survival function of each patient in the respective target subgroup <inline-formula id="IE33"><mml:math id="IM33"><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. The unknown parameter vector <inline-formula id="IE34"><mml:math id="IM34"><mml:mi mathvariant="bold-italic">β</mml:mi></mml:math></inline-formula> is estimated by maximizing the penalized weighted partial log-likelihood in (1). Subgroup-specific weights (2) are optimized using MBO, with a budget of 300 evaluations. Parameters to be optimized are the Cox model parameters and the weight vector. The initial design for MBO consists of <inline-formula id="IE35"><mml:math id="IM35"><mml:mrow><mml:mn>2</mml:mn><mml:mo>·</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>S</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> randomly sampled subgroup weights and the following additional specific extreme cases: exactly one other subgroup has weight 1 and all others have weight 0; all other subgroups have weight 0 or all other subgroups have weight 1. The target subgroup <inline-formula id="IE36"><mml:math id="IM36"><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> always has weight 1. The objective is to maximize the predictive performance by adapting the weights for all other subgroups.</p>
    <p>The predictive performance of the weighted Cox model is evaluated using the C-index. To assess the performance of a weight configuration, the C-index is evaluated on each fold of 10-fold cross-validation. We use a modified version of the cross-validation to take into account that we are only interested in the predictions on the target subgroup: The target subgroup is divided into 10 chunks, and to obtain the prediction for one chunk all remaining 9 chunks plus all observations from the additional subgroups are combined to the training dataset. The C-index is calculated only on the chunk of the target subgroup that was not used for model building.</p>
    <p>To avoid overfitting and to judge the stability, we conduct the optimization in a nested cross-validation setting. We use a 5-fold cross-validation for the outer validation and we use the same modification as described above for the inner cross-validation. The target subgroup is divided into five chunks and four of those chunks plus all observations from the additional subgroups are combined to the data that is used as <italic>optimization dataset</italic>, i.e. for the inner cross-validation. Accordingly, the optimization is carried out five times on slightly different data with different random samples of the initial design. For each outer cross-validation fold, the optimization returns an optimal weight vector. The Cox model is then trained on the complete optimization dataset and the final C-index is calculated on the remaining chunk of the target subgroup. Therefore, we obtain five different weight vectors and five different C-index values. This enables us to judge the stability of the optimization results.</p>
    <p>Our subgroups are derived from the gene expression data introduced in Section 2. We only use gene expression data as covariates, and each cohort acts as a subgroup. The number of genes included in the analysis is initially reduced to the 1000 features with highest variance across all 10 subgroups within the optimization dataset and in addition the 30 mandatory prognostic features given in Section 2.</p>
    <p>The underlying algorithms in this study are implemented in R, for the MBO the R-package mlrMBO (<xref rid="btz361-B6" ref-type="bibr">Bischl <italic>et al.</italic>, 2017</xref>) is used and survival analysis is performed using the R-package mlr (<xref rid="btz361-B5" ref-type="bibr">Bischl <italic>et al.</italic>, 2016</xref>).</p>
    <p>We evaluate the effectiveness of the optimization by comparing the C-index resulting from three different strategies.</p>
    <p><bold>Subgroup</bold> uses only the observations of the target subgroup to train the Cox model (all weights 0, expect for target subgroup).</p>
    <p><bold>Pooled</bold> uses all subgroups to train the Cox model (all weights 1).</p>
    <p><bold>MBO</bold> uses the weight configuration that is proposed by the MBO for noisy black-box functions.</p>
    <p><xref ref-type="fig" rid="btz361-F2">Figure 2</xref> shows the averaged optimization curves from the five MBO optimization processes per target subgroup. It shows the averaged predictive performance of the so far best model at each optimization iteration for each target subgroup. For some cohorts, the predictive performance increases strongly over time, while for others no major improvement is observed. A strong increase can be seen especially for <monospace>GSE29013</monospace>, which is the smallest subgroup, with only 55 patients. Minor improvements can be seen for <monospace>GSE4573</monospace>, <monospace>GSE3141</monospace>, <monospace>GSE14814</monospace> and <monospace>GSE19188</monospace>, although the last two suffer from a bad predictive performance even after optimization. For <monospace>GSE30219</monospace>, <monospace>GSE31210</monospace> and <monospace>Shedden</monospace>, no major increase in performance can be observed. These are also the largest subgroups with 269, 226 and 442 patients. The performance reached at the end of the optimization is the <italic>training error</italic> and has the tendency to be too optimistic regarding the predictive performance on unseen data. Therefore, we use the C-index measured on the outer cross-validation in the following part.
</p>
    <fig id="btz361-F2" orientation="portrait" position="float">
      <label>Fig. 2.</label>
      <caption>
        <p>Averaged progress of the MBO optimization runs for each target subgroup over all 300 optimization iterations</p>
      </caption>
      <graphic xlink:href="btz361f2"/>
    </fig>
    <p><xref ref-type="fig" rid="btz361-F3">Figure 3</xref> compares the predictive performance of the weights obtained by <italic>MBO</italic> against the <italic>Pooled</italic> and <italic>Subgroup</italic> approach. <xref rid="btz361-T2" ref-type="table">Table 2</xref> shows the median C-index values obtained by the outer 5-fold cross-validation and their ranks for each target subgroup. For five target subgroups <italic>MBO</italic> obtained the best median C-index, for four subgroups <italic>Pooled</italic> gave the best results and in one case <italic>Subgroup</italic> yielded the best results. Using only the target subgroup to train the Cox model yields the worst C-index for 6 out of 10 subgroups. Although the box plots in <xref ref-type="fig" rid="btz361-F3">Figure 3</xref> do not directly indicate a superiority of <italic>MBO</italic> for each single target subgroup, the combined ranks in <xref rid="btz361-T2" ref-type="table">Table 2</xref> show that on average using <italic>MBO</italic> is a promising strategy.</p>
    <table-wrap id="btz361-T2" orientation="portrait" position="float">
      <label>Table 2</label>
      <caption>
        <p>Median C-index for each target subgroup obtained on the outer 5-fold cross-validation by the different strategies</p>
      </caption>
      <table frame="hsides" rules="groups">
        <colgroup span="1">
          <col valign="top" align="left" span="1"/>
          <col valign="top" align="center" span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="center" span="1"/>
          <col valign="top" align="char" char="." span="1"/>
          <col valign="top" align="center" span="1"/>
          <col valign="top" align="char" char="." span="1"/>
        </colgroup>
        <thead>
          <tr>
            <th rowspan="1" colspan="1"/>
            <th colspan="2" rowspan="1">Subgroup<hr/></th>
            <th colspan="2" rowspan="1">Pooled<hr/></th>
            <th colspan="2" rowspan="1">MBO<hr/></th>
          </tr>
          <tr>
            <th rowspan="1" colspan="1">Target subgroup</th>
            <th rowspan="1" colspan="1">Med</th>
            <th rowspan="1" colspan="1">Rank</th>
            <th rowspan="1" colspan="1">Med</th>
            <th rowspan="1" colspan="1">Rank</th>
            <th rowspan="1" colspan="1">Med</th>
            <th rowspan="1" colspan="1">Rank</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>GSE14814</monospace>
            </td>
            <td rowspan="1" colspan="1">0.48</td>
            <td rowspan="1" colspan="1">(3)</td>
            <td rowspan="1" colspan="1">
              <bold>0.53</bold>
            </td>
            <td rowspan="1" colspan="1">(1)</td>
            <td rowspan="1" colspan="1">0.52</td>
            <td rowspan="1" colspan="1">(2)</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>GSE19188</monospace>
            </td>
            <td rowspan="1" colspan="1">0.48</td>
            <td rowspan="1" colspan="1">(2)</td>
            <td rowspan="1" colspan="1">0.47</td>
            <td rowspan="1" colspan="1">(3)</td>
            <td rowspan="1" colspan="1">
              <bold>0.50</bold>
            </td>
            <td rowspan="1" colspan="1">(1)</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>GSE29013</monospace>
            </td>
            <td rowspan="1" colspan="1">0.62</td>
            <td rowspan="1" colspan="1">(3)</td>
            <td rowspan="1" colspan="1">0.81</td>
            <td rowspan="1" colspan="1">(2)</td>
            <td rowspan="1" colspan="1">
              <bold>0.85</bold>
            </td>
            <td rowspan="1" colspan="1">(1)</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>GSE30219</monospace>
            </td>
            <td rowspan="1" colspan="1">0.67</td>
            <td rowspan="1" colspan="1">(2)</td>
            <td rowspan="1" colspan="1">
              <bold>0.68</bold>
            </td>
            <td rowspan="1" colspan="1">(1)</td>
            <td rowspan="1" colspan="1">0.65</td>
            <td rowspan="1" colspan="1">(3)</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>GSE31210</monospace>
            </td>
            <td rowspan="1" colspan="1">0.75</td>
            <td rowspan="1" colspan="1">(2)</td>
            <td rowspan="1" colspan="1">0.73</td>
            <td rowspan="1" colspan="1">(3)</td>
            <td rowspan="1" colspan="1">
              <bold>0.75</bold>
            </td>
            <td rowspan="1" colspan="1">(1)</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>GSE3141</monospace>
            </td>
            <td rowspan="1" colspan="1">0.54</td>
            <td rowspan="1" colspan="1">(3)</td>
            <td rowspan="1" colspan="1">
              <bold>0.59</bold>
            </td>
            <td rowspan="1" colspan="1">(1)</td>
            <td rowspan="1" colspan="1">0.56</td>
            <td rowspan="1" colspan="1">(2)</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>GSE37745</monospace>
            </td>
            <td rowspan="1" colspan="1">
              <bold>0.63</bold>
            </td>
            <td rowspan="1" colspan="1">(1)</td>
            <td rowspan="1" colspan="1">0.60</td>
            <td rowspan="1" colspan="1">(3)</td>
            <td rowspan="1" colspan="1">0.61</td>
            <td rowspan="1" colspan="1">(2)</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>GSE4573</monospace>
            </td>
            <td rowspan="1" colspan="1">0.59</td>
            <td rowspan="1" colspan="1">(3)</td>
            <td rowspan="1" colspan="1">
              <bold>0.68</bold>
            </td>
            <td rowspan="1" colspan="1">(1)</td>
            <td rowspan="1" colspan="1">0.61</td>
            <td rowspan="1" colspan="1">(2)</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>GSE50081</monospace>
            </td>
            <td rowspan="1" colspan="1">0.58</td>
            <td rowspan="1" colspan="1">(3)</td>
            <td rowspan="1" colspan="1">0.63</td>
            <td rowspan="1" colspan="1">(2)</td>
            <td rowspan="1" colspan="1">
              <bold>0.66</bold>
            </td>
            <td rowspan="1" colspan="1">(1)</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">
              <monospace>Shedden</monospace>
            </td>
            <td rowspan="1" colspan="1">0.64</td>
            <td rowspan="1" colspan="1">(3)</td>
            <td rowspan="1" colspan="1">0.66</td>
            <td rowspan="1" colspan="1">(2)</td>
            <td rowspan="1" colspan="1">
              <bold>0.66</bold>
            </td>
            <td rowspan="1" colspan="1">(1)</td>
          </tr>
          <tr>
            <td rowspan="1" colspan="1">Average rank</td>
            <td rowspan="1" colspan="1"/>
            <td align="center" rowspan="1" colspan="1">2.50</td>
            <td rowspan="1" colspan="1"/>
            <td align="center" rowspan="1" colspan="1">1.90</td>
            <td rowspan="1" colspan="1"/>
            <td align="center" rowspan="1" colspan="1">1.60</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="tblfn1">
          <p><italic>Note</italic>: Ranks are given in brackets and averaged ranks across all target subgroups are given at the bottom.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
    <fig id="btz361-F3" orientation="portrait" position="float">
      <label>Fig. 3.</label>
      <caption>
        <p>The predictive performance of the best weight configuration according to different strategies. Each box plot includes the C-indices measured on the outer 5-fold cross-validation</p>
      </caption>
      <graphic xlink:href="btz361f3"/>
    </fig>
    <p>To verify whether there are statistically significant differences between the strategies, we perform a nonparametric test in accordance with <xref rid="btz361-B10" ref-type="bibr">Demšar (2006)</xref>. The Friedman test is employed to test whether there are statistical differences between the given strategies at an <italic>α</italic>-level of 0.05. With a <italic>P</italic>-value of 0.12, the null hypothesis cannot be rejected.</p>
    <p>Altogether, the results indicate that optimizing the subgroup weights is in most cases superior to the <italic>Subgroup</italic> strategy and competitive to the <italic>Pooled</italic> strategy. Moreover, we showed that <italic>MBO</italic> is capable of optimizing these weights.</p>
    <sec>
      <title>5.1 Subgroup weights</title>
      <p><xref ref-type="fig" rid="btz361-F4">Figure 4</xref> shows the optimal weight vectors for each subgroup identified by <italic>MBO</italic>. Rows correspond to target subgroups and columns per plot indicate the subgroups to be used for model building. The line denotes the mean optimal weights averaged over the results of the five outer cross-validation folds. Overall, we see different patterns with weights close to 0 and close to 1, but sometimes also medium weights. For instance, for the target subgroup GSE31210, we see that there are consistent optimization results for the weights of the additional subgroups <monospace>GSE14814</monospace>, <monospace>GSE29013</monospace>, <monospace>GSE3141</monospace>, <monospace>GSE37745</monospace> and <monospace>GSE4573</monospace>. Interestingly, for the target subgroups <monospace>GSE19188</monospace>, <monospace>GSE29013</monospace> and <monospace>GSE4573</monospace>, no clear preferences for weights close to 0 or 1 are observable for any of the additional subgroups. However, this does not imply that <italic>MBO</italic> failed for those target subgroups. Looking at the results in <xref rid="btz361-T2" ref-type="table">Table 2</xref>, we see that <italic>MBO</italic> performs better or comparable then the <italic>Pooled</italic> approach for those cases.
</p>
      <fig id="btz361-F4" orientation="portrait" position="float">
        <label>Fig. 4.</label>
        <caption>
          <p>Subgroup weights corresponding to the best predictive performance found by the model-based optimization. The row indicates the target cohort, the columns indicate the cohorts to be used for model building. Each dot represents the optimal weight for the respective subgroup obtained in one repetition of the optimization run. The red line denotes the mean over the five repetitions. If the dots per subgroup scatter heavily this indicates an unstable result</p>
        </caption>
        <graphic xlink:href="btz361f4"/>
      </fig>
      <p>An immediate question is whether weight values are bidirectional, meaning that an additional subgroup with a high weight for predicting the target subgroup also includes the latter with a high weight if it is the target subgroup itself. In <xref ref-type="fig" rid="btz361-F4">Figure 4</xref> we can especially notice that for some additional subgroups, a weight near 0 or 1 is clearly chosen by <italic>MBO</italic>. For example, <monospace>GSE14814</monospace> clearly benefits from <monospace>GSE30219</monospace> and vice versa. The same can be observed for the pairs <monospace>GSE37745</monospace>, <monospace>Shedden</monospace> as well as <monospace>GSE31210</monospace>, <monospace>GSE4573</monospace> and <monospace>GSE31210</monospace>, <monospace>GSE3141</monospace>. One can suspect that these datasets are similar in terms of which models achieve high performance values, and thus having a larger training dataset helps to increase the predictive performance.</p>
      <p>A different scenario can be observed for the subgroup <monospace>GSE29013</monospace> (55 patients). As target subgroup, there is no clear preference for any additional subgroup. However, it is included with a high weight into the prediction of <monospace>Shedden</monospace> (442 patients). Also <monospace>GSE4573</monospace> (130 patients) does not show any clear preference toward additional subgroups but is included into the prediction of <monospace>GSE30219</monospace> (269 patients), <monospace>GSE31210</monospace> (226 patients) and <monospace>GSE37745</monospace> (194 patients) with a high weight. It appears that for smaller target subgroups, it can be advantageous to only include bigger additional subgroups with a slightly lower weight than 1 to obtain a high predictive accuracy. The other way around, for the bigger subgroups, the relatively few observations from the additional subgroups can be included with a high weight.</p>
    </sec>
    <sec>
      <title>5.2 Deteriorated subgroups</title>
      <p>To analyze how sensitive the different strategies react to subgroups that do not contain any information, we permuted the survival data of specific subgroups. For this analysis we used <monospace>GSE3141</monospace> and <monospace>GSE37745</monospace> as target subgroups. This has the effect that for these subgroups no useful information should be obtainable from the survival learner. Including them is expected to deteriorate the predictive performance for the target subgroup.</p>
      <p><bold>none</bold> uses the original data without permutations.</p>
      <p><bold>perm1</bold> permutes the survival data of those subgroups to that <monospace>MBO</monospace> assigned weights below 0.5 in at least two runs. For the target subgroup <monospace>GSE3141</monospace>, we permute the survival data of <monospace>GSE19188</monospace>, <monospace>GSE30219</monospace>, <monospace>GSE37745</monospace>, <monospace>GSE4573</monospace> and <monospace>Shedden</monospace>. For the target subgroup <monospace>GSE37745</monospace>, we permute the survival data of <monospace>GSE14814</monospace>, <monospace>GSE19188</monospace>, <monospace>GSE29013</monospace>, <monospace>GSE30219</monospace>, <monospace>GSE31210</monospace>, <monospace>GSE3141</monospace> and <monospace>GSE50081</monospace>.</p>
      <p><bold>perm2</bold> permutes the survival data of those subgroups to that <monospace>MBO</monospace> assigned the highest and the lowest weights on average. For the target subgroup <monospace>GSE3141</monospace>, we permute the survival data of the highly weighted <monospace>GSE31210</monospace> and the down-weighted <monospace>GSE37745</monospace> subgroup. For the target subgroup <monospace>GSE37745</monospace>, we permute the survival data of the highly weighted <monospace>Shedden</monospace> and the down-weighted <monospace>GSE50081</monospace>.</p>
      <p>In <xref ref-type="fig" rid="btz361-F5">Figure 5</xref> we show how this permutation affects the predictive performance. As expected, the <italic>Subgroup</italic> strategy is not affected by distorting other subgroups. The results only vary slightly due to the randomness of the cross-validation. Interestingly, the <italic>Pooled</italic> strategy is not heavily affected by distorting many of the additional subgroups in <monospace>perm1</monospace>. The performance just slightly decreases. In contrast, the performance of <italic>MBO</italic> is capable of improving its performance. However, this cannot be easily explained by the corresponding weights. For <monospace>perm2</monospace> the performance of the <italic>Pooled</italic> strategy and <italic>MBO</italic> drops noticeably. This indicates that the subgroups that were included with a high weight in the original setting were important to obtain the good prediction performance for both, <italic>MBO</italic> and the <italic>Pooled</italic> strategy.
</p>
      <fig id="btz361-F5" orientation="portrait" position="float">
        <label>Fig. 5.</label>
        <caption>
          <p>Similar to <xref ref-type="fig" rid="btz361-F3">Figure 3</xref>, the predictive performance is shown. For <monospace>perm1</monospace> the subgroups with previously low predicted weights are additionally deteriorated and for <monospace>perm2</monospace> the additional subgroup with the highest and the lowest previous weights are deteriorated</p>
        </caption>
        <graphic xlink:href="btz361f5"/>
      </fig>
      <p>Looking at the newly obtained weights in <xref ref-type="fig" rid="btz361-F6">Figure 6</xref>, we can observe that for <monospace>perm1</monospace> the assigned weights of the distorted subgroups are not closer to zero for <monospace>GSE3141</monospace>. However, for <monospace>GSE37745</monospace> a slight tendency toward lower weights for deteriorated subgroups can be observed, expect for <monospace>GSE3141</monospace> and <monospace>GSE50081</monospace>. The results are more conclusive for <monospace>perm2</monospace>: subgroups with a high weight in the original setting, now obtain low weights after permuting. Here <italic>MBO</italic> reliably detects the deterioration. We observe that deteriorating data from subgroups with small weights does not change their weights toward zero, different from what would be expected. It can be speculated that some of the additional subgroups have a small influence on the prediction on the target subgroup in the <italic>Pooled</italic> strategy and therefore, decreasing their weight does not strongly affect the predictive performance. If including a certain subgroup in the original data has a negative effect on the predictive performance, it has obtained a low weight by <italic>MBO</italic>. After permuting the survival data of this subgroup, this negative effect vanishes and thus, it is not as crucial anymore to assign low weights for the subgroup.
</p>
      <fig id="btz361-F6" orientation="portrait" position="float">
        <label>Fig. 6.</label>
        <caption>
          <p>Similar to <xref ref-type="fig" rid="btz361-F4">Figure 4</xref> the subgroup weights corresponding to the best predictive performance found by the model-based optimization are shown for two exemplary target subgroups. For <monospace>perm1</monospace> and <monospace>perm2</monospace> the survival data of the subgroups that are marked with an empty circle are permuted. The weights with no permutation in the upper panel are the same as in <xref ref-type="fig" rid="btz361-F4">Figure 4</xref> and drawn for comparison</p>
        </caption>
        <graphic xlink:href="btz361f6"/>
      </fig>
    </sec>
  </sec>
  <sec>
    <title>6 Summary</title>
    <p>When multiple patient cohorts with a similar disease and treatment are available, it is tempting to pool the cohorts to one overall cohort to increase sample size and therefore, the stability of conclusions drawn from the data. However, heterogeneity between the cohorts can heavily distort these conclusions. We considered the situation in which one is interested in a good prediction model for one specific cohort out of a set of potentially similar cohorts. We analyzed a weighted likelihood strategy that is intended to only add those cohorts to the prediction model building process that represent a similar feature–outcome relationship. For optimizing the weights of the other cohorts, we used MBO. In a lung cancer survival study, it turned out that this strategy often leads to an improved C-index as performance criterion, in a cross-validation setting.</p>
    <p>Some important aspects for future research remain. It will be interesting to analyze in which way the size of the weight for a subgroup can be related to other properties of the corresponding patient subgroup, especially regarding sample size and the distributions of clinical covariates. Furthermore, our results indicate that the inconsistencies in the obtained weights are likely due to the small sample sizes. It remains to be examined to what extent more features, i.e. no filtering, and more observations lead to more stable and better predictions. For proposing the final weight MBO returns, the weight configuration that is estimated to perform best. This estimation can be nearly the same for various weight configurations. Therefore it might be interesting to introduce some slight regularization to give preference to specific values, e.g. <inline-formula id="IE37"><mml:math id="IM37"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. Setting weights strictly to zero would lead to clearer decisions which subgroups to include for the model building process.</p>
  </sec>
  <sec>
    <title>Funding</title>
    <p>This work was partly supported by Deutsche Forschungsgemeinschaft (DFG) within the Collaborative Research Center SFB 876, A3.</p>
    <p><italic>Conflict of Interest</italic>: none declared.</p>
  </sec>
</body>
<back>
  <ref-list id="ref1">
    <title>References</title>
    <ref id="btz361-B1">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bergersen</surname><given-names>L.C.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Weighted lasso with data integration</article-title>. <source>Statist. Appl. Genet. Mol. Biol</source>., <volume>10</volume>, <fpage>666.</fpage></mixed-citation>
    </ref>
    <ref id="btz361-B2">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bernau</surname><given-names>C.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Cross-study validation for the assessment of prediction algorithms</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>i105</fpage>–<lpage>i112</lpage>.<pub-id pub-id-type="pmid">24931973</pub-id></mixed-citation>
    </ref>
    <ref id="btz361-B3">
      <mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Bickel</surname><given-names>S.</given-names></name></person-group><etal>et al</etal> (<year>2008</year>) Multi-task learning for HIV therapy screening. In: <italic>Proceedings of the 25th International Conference on Machine Learning, ICML ’08, Helsinki, Finland, 2008</italic>, pp. <fpage>56</fpage>–<lpage>63</lpage>. ACM, New York.</mixed-citation>
    </ref>
    <ref id="btz361-B4">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Binder</surname><given-names>H.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>Cluster-localized sparse logistic regression for SNP data</article-title>. <source>Statist. Appl. Genet. Mol. Biol</source>., <volume>11</volume>, <fpage>1</fpage>–<lpage>28</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B5">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bischl</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Mlr: machine learning in R</article-title>. <source>J. Mach. Learn. Res</source>., <volume>17</volume>, <fpage>1</fpage>–<lpage>5</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B6">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bischl</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>mlrMBO: a modular framework for model-based optimization of expensive black-box functions</article-title>. <source>arXiv</source>: 1703.03373 [stat], pp. <fpage>1</fpage>–<lpage>26</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B7">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bogojeska</surname><given-names>J.</given-names></name>, <name name-style="western"><surname>Lengauer</surname><given-names>T.</given-names></name></person-group> (<year>2012</year>) 
<article-title>Hierarchical Bayes model for predicting effectiveness of HIV combination therapies</article-title>. <source>Statist. Appl. Genet. Mol. Biol</source>., <volume>11</volume>, <fpage>1</fpage>–<lpage>19</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B8">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Boulesteix</surname><given-names>A.-L.</given-names></name></person-group><etal>et al</etal> (<year>2017</year>) 
<article-title>IPF-LASSO: integrative L 1-penalized regression with penalty factors for prediction based on multi-omics data</article-title>. <source>Comput. Math. Methods Med</source>., <volume>2017</volume>, <fpage>1.</fpage></mixed-citation>
    </ref>
    <ref id="btz361-B9">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Cox</surname><given-names>D.R.</given-names></name></person-group> (<year>1972</year>) 
<article-title>Regression models and life-tables</article-title>. <source>J. Royal Statist. Soc</source>., <volume>34</volume>, <fpage>187</fpage>–<lpage>220</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B10">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Demšar</surname><given-names>J.</given-names></name></person-group> (<year>2006</year>) 
<article-title>Statistical comparisons of classifiers over multiple data sets</article-title>. <source>J. Mach. Learn. Res</source>., <volume>7</volume>, <fpage>1</fpage>–<lpage>30</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B11">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Edgar</surname><given-names>R.</given-names></name></person-group><etal>et al</etal> (<year>2002</year>) 
<article-title>Gene expression omnibus: nCBI gene expression and hybridization array data repository</article-title>. <source>Nucleic Acids Res</source>., <volume>30</volume>, <fpage>207</fpage>–<lpage>210</lpage>.<pub-id pub-id-type="pmid">11752295</pub-id></mixed-citation>
    </ref>
    <ref id="btz361-B12">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Hastie</surname><given-names>T.</given-names></name></person-group><etal>et al</etal> (<year>2009</year>) <source>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</source>, <edition>2</edition>nd edn. 
<publisher-name>Springer Science &amp; Business Media</publisher-name>, New York.</mixed-citation>
    </ref>
    <ref id="btz361-B13">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hellwig</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Epsin family member 3 and ribosome-related genes are associated with late metastasis in estrogen receptor-positive breast cancer and long-term survival in non-small cell lung cancer using a genome-wide identification and validation strategy</article-title>. <source>PLoS One</source>, <volume>11</volume>, <fpage>e0167585.</fpage><pub-id pub-id-type="pmid">27926932</pub-id></mixed-citation>
    </ref>
    <ref id="btz361-B14">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huang</surname><given-names>D.</given-names></name></person-group><etal>et al</etal> (<year>2006</year>) 
<article-title>Global optimization of stochastic black-box systems via sequential kriging meta-models</article-title>. <source>J. Global Optim</source>., <volume>34</volume>, <fpage>441</fpage>–<lpage>466</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B15">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Huang</surname><given-names>Y.</given-names></name></person-group><etal>et al</etal> (<year>2011</year>) 
<article-title>Borrowing information across populations in estimating positive and negative predictive values</article-title>. <source>J. Royal Statist. Soc</source>., <volume>60</volume>, <fpage>633</fpage>–<lpage>653</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B16">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jones</surname><given-names>D.R.</given-names></name></person-group><etal>et al</etal> (<year>1998</year>) 
<article-title>Efficient global optimization of expensive black-box functions</article-title>. <source>J. Global Optim</source>., <volume>13</volume>, <fpage>455</fpage>–<lpage>492</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B17">
      <mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Klein</surname><given-names>J.P.</given-names></name>, <name name-style="western"><surname>Moeschberger</surname><given-names>M.L.</given-names></name></person-group> (<year>2003</year>) <source>Survival Analysis: Techniques for Censored and Truncated Data</source>. Statistics for Biology and Health, <edition>2</edition>nd edn. 
<publisher-name>Springer</publisher-name>, 
<publisher-loc>New York</publisher-loc>.</mixed-citation>
    </ref>
    <ref id="btz361-B18">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kratz</surname><given-names>J.R.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>A practical molecular assay to predict survival in resected non-squamous, non-small-cell lung cancer: development and international validation studies</article-title>. <source>Lancet</source>, <volume>379</volume>, <fpage>823</fpage>–<lpage>832</lpage>.<pub-id pub-id-type="pmid">22285053</pub-id></mixed-citation>
    </ref>
    <ref id="btz361-B19">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2014a</year>) 
<article-title>Integrative analysis of cancer diagnosis studies with composite penalization</article-title>. <source>Scand. J. Statist. Theory Appl</source>., <volume>41</volume>, <fpage>87</fpage>–<lpage>103</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B20">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>J.</given-names></name></person-group><etal>et al</etal> (<year>2014b</year>) 
<article-title>Integrative analysis of prognosis data on multiple cancer subtypes</article-title>. <source>Biometrics</source>, <volume>70</volume>, <fpage>480</fpage>–<lpage>488</lpage>.<pub-id pub-id-type="pmid">24766212</pub-id></mixed-citation>
    </ref>
    <ref id="btz361-B21">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>McCall</surname><given-names>M.N.</given-names></name></person-group><etal>et al</etal> (<year>2010</year>) 
<article-title>Frozen robust multiarray analysis (fRMA)</article-title>. <source>Biostatistics</source>, <volume>11</volume>, <fpage>242</fpage>–<lpage>253</lpage>.<pub-id pub-id-type="pmid">20097884</pub-id></mixed-citation>
    </ref>
    <ref id="btz361-B22">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Roustant</surname><given-names>O.</given-names></name></person-group><etal>et al</etal> (<year>2012</year>) 
<article-title>DiceKriging, DiceOptim: two R packages for the analysis of computer experiments by kriging-based metamodeling and optimization</article-title>. <source>J. Statist. Softw. Art</source>., <volume>51</volume>, <fpage>1</fpage>–<lpage>55</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B23">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shahriari</surname><given-names>B.</given-names></name></person-group><etal>et al</etal> (<year>2016</year>) 
<article-title>Taking the Human out of the loop: a review of Bayesian optimization</article-title>. <source>Proc. IEEE</source>, <volume>104</volume>, <fpage>148</fpage>–<lpage>175</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B24">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Simon</surname><given-names>R.</given-names></name></person-group> (<year>2002</year>) 
<article-title>Bayesian subset analysis: application to studying treatment-by-gender interactions</article-title>. <source>Statist. Med</source>., <volume>21</volume>, <fpage>2909</fpage>–<lpage>2916</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B25">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tibshirani</surname><given-names>R.</given-names></name></person-group> (<year>1996</year>) 
<article-title>Regression shrinkage and selection via the lasso</article-title>. <source>J. Royal Statist. Soc</source>., <volume>58</volume>, <fpage>267</fpage>–<lpage>288</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B26">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tibshirani</surname><given-names>R.</given-names></name></person-group> (<year>1997</year>) 
<article-title>The lasso method for variable selection in the Cox model</article-title>. <source>Statist. Med</source>., <volume>16</volume>, <fpage>385</fpage>–<lpage>395</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B27">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tutz</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Binder</surname><given-names>H.</given-names></name></person-group> (<year>2005</year>) 
<article-title>Localized classification</article-title>. <source>Statist. Comput</source>., <volume>15</volume>, <fpage>155</fpage>–<lpage>166</lpage>.</mixed-citation>
    </ref>
    <ref id="btz361-B28">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Weyer</surname><given-names>V.</given-names></name>, <name name-style="western"><surname>Binder</surname><given-names>H.</given-names></name></person-group> (<year>2015</year>) 
<article-title>A weighting approach for judging the effect of patient strata on high-dimensional risk prediction signatures</article-title>. <source>BMC Bioinformatics</source>, <volume>16</volume>, <fpage>294</fpage>.<pub-id pub-id-type="pmid">26374641</pub-id></mixed-citation>
    </ref>
    <ref id="btz361-B29">
      <mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhao</surname><given-names>S.D.</given-names></name></person-group><etal>et al</etal> (<year>2014</year>) 
<article-title>Más-o-menos: a simple sign averaging method for discrimination in genomic data analysis</article-title>. <source>Bioinformatics</source>, <volume>30</volume>, <fpage>3062</fpage>–<lpage>3069</lpage>.<pub-id pub-id-type="pmid">25061068</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
