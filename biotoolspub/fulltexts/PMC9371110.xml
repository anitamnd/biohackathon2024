<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1-3.dtd?>
<?SourceDTD.Version 1.3?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id>
    <journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id>
    <journal-id journal-id-type="publisher-id">sensors</journal-id>
    <journal-title-group>
      <journal-title>Sensors (Basel, Switzerland)</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1424-8220</issn>
    <publisher>
      <publisher-name>MDPI</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9371110</article-id>
    <article-id pub-id-type="doi">10.3390/s22155849</article-id>
    <article-id pub-id-type="publisher-id">sensors-22-05849</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MaD GUI: An Open-Source Python Package for Annotation and Analysis of Time-Series Data</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-8135-6740</contrib-id>
        <name>
          <surname>Ollenschläger</surname>
          <given-names>Malte</given-names>
        </name>
        <xref rid="af1-sensors-22-05849" ref-type="aff">1</xref>
        <xref rid="af2-sensors-22-05849" ref-type="aff">2</xref>
        <xref rid="c1-sensors-22-05849" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-5686-281X</contrib-id>
        <name>
          <surname>Küderle</surname>
          <given-names>Arne</given-names>
        </name>
        <xref rid="af1-sensors-22-05849" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Mehringer</surname>
          <given-names>Wolfgang</given-names>
        </name>
        <xref rid="af1-sensors-22-05849" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Seifer</surname>
          <given-names>Ann-Kristin</given-names>
        </name>
        <xref rid="af1-sensors-22-05849" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-0630-9204</contrib-id>
        <name>
          <surname>Winkler</surname>
          <given-names>Jürgen</given-names>
        </name>
        <xref rid="af2-sensors-22-05849" ref-type="aff">2</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-2037-9460</contrib-id>
        <name>
          <surname>Gaßner</surname>
          <given-names>Heiko</given-names>
        </name>
        <xref rid="af2-sensors-22-05849" ref-type="aff">2</xref>
        <xref rid="af3-sensors-22-05849" ref-type="aff">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-4921-6104</contrib-id>
        <name>
          <surname>Kluge</surname>
          <given-names>Felix</given-names>
        </name>
        <xref rid="af1-sensors-22-05849" ref-type="aff">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-0417-0336</contrib-id>
        <name>
          <surname>Eskofier</surname>
          <given-names>Bjoern M.</given-names>
        </name>
        <xref rid="af1-sensors-22-05849" ref-type="aff">1</xref>
      </contrib>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Boissy</surname>
          <given-names>Patrick</given-names>
        </name>
        <role>Academic Editor</role>
      </contrib>
    </contrib-group>
    <aff id="af1-sensors-22-05849"><label>1</label>Machine Learning and Data Analytics Lab, Department of Artificial Intelligence in Biomedical Engineering (AIBE), Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), 91052 Erlangen, Germany</aff>
    <aff id="af2-sensors-22-05849"><label>2</label>Department of Molecular Neurology, University Hospital Erlangen, Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU), 91054 Erlangen, Germany</aff>
    <aff id="af3-sensors-22-05849"><label>3</label>Fraunhofer IIS, Fraunhofer Institute for Integrated Circuits IIS, 91058 Erlangen, Germany</aff>
    <author-notes>
      <corresp id="c1-sensors-22-05849"><label>*</label>Correspondence: <email>malte.ollenschlaeger@fau.de</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>05</day>
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <month>8</month>
      <year>2022</year>
    </pub-date>
    <volume>22</volume>
    <issue>15</issue>
    <elocation-id>5849</elocation-id>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>6</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>03</day>
        <month>8</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2022 by the authors.</copyright-statement>
      <copyright-year>2022</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p>
      </license>
    </permissions>
    <abstract>
      <p>Developing machine learning algorithms for time-series data often requires manual annotation of the data. To do so, graphical user interfaces (GUIs) are an important component. Existing Python packages for annotation and analysis of time-series data have been developed without addressing adaptability, usability, and user experience. Therefore, we developed a generic open-source Python package focusing on adaptability, usability, and user experience. The developed package, Machine Learning and Data Analytics (MaD) GUI, enables developers to rapidly create a GUI for their specific use case. Furthermore, MaD GUI enables domain experts without programming knowledge to annotate time-series data and apply algorithms to it. We conducted a small-scale study with participants from three international universities to test the adaptability of MaD GUI by developers and to test the user interface by clinicians as representatives of domain experts. MaD GUI saves up to 75% of time in contrast to using a state-of-the-art package. In line with this, subjective ratings regarding usability and user experience show that MaD GUI is preferred over a state-of-the-art package by developers and clinicians. MaD GUI reduces the effort of developers in creating GUIs for time-series analysis and offers similar usability and user experience for clinicians as a state-of-the-art package.</p>
    </abstract>
    <kwd-group>
      <kwd>python</kwd>
      <kwd>time series analysis</kwd>
      <kwd>annotation</kwd>
      <kwd>graphical user interface</kwd>
      <kwd>gait analysis</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>Federal Ministry of Education and Research, Germany</funding-source>
        <award-id>01GM1905</award-id>
      </award-group>
      <award-group>
        <funding-source>Fraunhofer Internal Programs</funding-source>
        <award-id>044-602140</award-id>
        <award-id>044-602150</award-id>
      </award-group>
      <award-group>
        <funding-source>Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)—“Mobility_APP”</funding-source>
        <award-id>438496663</award-id>
      </award-group>
      <award-group>
        <funding-source>Mobilise-D project</funding-source>
        <funding-source>Innovative Medicines Initiative 2 Joint Undertaking (JU)</funding-source>
        <award-id>820820</award-id>
      </award-group>
      <award-group>
        <funding-source>European Union’s Horizon 2020 research and innovation program</funding-source>
        <funding-source>European Federation of Pharmaceutical Industries and Associations (EFPIA)</funding-source>
      </award-group>
      <funding-statement>This work was supported by the Federal Ministry of Education and Research, Germany (treatHSP, Grant Number 01GM1905) and the Fraunhofer Internal Programs under Grant No. Attract 044-602140 and 044-602150. Further, this work was funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)—“Mobility_APP”, Grant Number 438496663. H.G., A.K., J.W., and B.M.E. are supported by the Mobilise-D project that has received funding from the Innovative Medicines Initiative 2 Joint Undertaking (JU) under grant agreement No. 820820. This JU receives support from the European Union’s Horizon 2020 research and innovation program and the European Federation of Pharmaceutical Industries and Associations (EFPIA). Content in this publication reflects the authors’ view and neither IMI nor the European Union, EFPIA, or any Associated Partners are responsible for any use that may be made of the information contained herein.</funding-statement>
    </funding-group>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="sec1-sensors-22-05849">
    <title>1. Introduction</title>
    <p>Machine learning algorithms are a promising approach for different areas in medical research and clinical practice [<xref rid="B1-sensors-22-05849" ref-type="bibr">1</xref>,<xref rid="B2-sensors-22-05849" ref-type="bibr">2</xref>,<xref rid="B3-sensors-22-05849" ref-type="bibr">3</xref>]. They can support clinical workflows or decision-making in diagnosis, treatment, rehabilitation, or prognosis [<xref rid="B2-sensors-22-05849" ref-type="bibr">2</xref>,<xref rid="B4-sensors-22-05849" ref-type="bibr">4</xref>,<xref rid="B5-sensors-22-05849" ref-type="bibr">5</xref>,<xref rid="B6-sensors-22-05849" ref-type="bibr">6</xref>]. One part of the development of such algorithms is training or learning. In the case of supervised or semi-supervised machine learning, this necessitates annotated data, which is a time-consuming process [<xref rid="B2-sensors-22-05849" ref-type="bibr">2</xref>,<xref rid="B7-sensors-22-05849" ref-type="bibr">7</xref>]. For annotating data, the developers of the algorithm or domain experts assign a ground truth value to individual data points. In the domain of gait analysis, this could refer to annotating walking bouts as being part of a standardized gait test [<xref rid="B8-sensors-22-05849" ref-type="bibr">8</xref>] or whether a gait pattern is physiological or pathological [<xref rid="B9-sensors-22-05849" ref-type="bibr">9</xref>]. The annotated data can then be used to train the algorithm. Furthermore, the annotations can be used to evaluate the algorithm’s performance regarding unseen data.</p>
    <p>The segmentation and annotation of time-series can be performed using graphical user interfaces (GUIs) [<xref rid="B10-sensors-22-05849" ref-type="bibr">10</xref>,<xref rid="B11-sensors-22-05849" ref-type="bibr">11</xref>,<xref rid="B12-sensors-22-05849" ref-type="bibr">12</xref>,<xref rid="B13-sensors-22-05849" ref-type="bibr">13</xref>,<xref rid="B14-sensors-22-05849" ref-type="bibr">14</xref>,<xref rid="B15-sensors-22-05849" ref-type="bibr">15</xref>,<xref rid="B16-sensors-22-05849" ref-type="bibr">16</xref>,<xref rid="B17-sensors-22-05849" ref-type="bibr">17</xref>,<xref rid="B18-sensors-22-05849" ref-type="bibr">18</xref>,<xref rid="B19-sensors-22-05849" ref-type="bibr">19</xref>]. Although some existing GUIs process similar data with similar goals, for example the annotation of human activities from videos and wearable sensors, they have been developed independently of each other [<xref rid="B15-sensors-22-05849" ref-type="bibr">15</xref>,<xref rid="B16-sensors-22-05849" ref-type="bibr">16</xref>,<xref rid="B17-sensors-22-05849" ref-type="bibr">17</xref>,<xref rid="B18-sensors-22-05849" ref-type="bibr">18</xref>,<xref rid="B19-sensors-22-05849" ref-type="bibr">19</xref>]. This means the existing code is not re-used within the community, and thus, similar functionalities are implemented in numerous ways, leading to duplicated work. Furthermore, this increases the likelihood of incompatibilities resulting in a barrier to the adoption of technologies [<xref rid="B1-sensors-22-05849" ref-type="bibr">1</xref>,<xref rid="B20-sensors-22-05849" ref-type="bibr">20</xref>].</p>
    <p>One of the reasons for code not being re-used includes code not being publicly available [<xref rid="B15-sensors-22-05849" ref-type="bibr">15</xref>,<xref rid="B16-sensors-22-05849" ref-type="bibr">16</xref>,<xref rid="B17-sensors-22-05849" ref-type="bibr">17</xref>,<xref rid="B18-sensors-22-05849" ref-type="bibr">18</xref>]. According to a study conducted by Stodden et al. [<xref rid="B21-sensors-22-05849" ref-type="bibr">21</xref>], the major reason for not publishing code is that researchers declare their code as not being cleaned up and undocumented. Another reason for not re-using the mentioned GUIs is that many of them are not written in Python, although Python is the dominant language in scientific computing, especially for machine learning [<xref rid="B22-sensors-22-05849" ref-type="bibr">22</xref>,<xref rid="B23-sensors-22-05849" ref-type="bibr">23</xref>]. Thus, it can be expected that developers of GUIs for time-series analysis would prefer Python as a programming language and therefore discard available GUIs that have not been written in Python. Furthermore, most of the GUIs seem not to be adaptable to other data formats and/or algorithms and, thus, can only be used with the data and algorithms from the original publication [<xref rid="B12-sensors-22-05849" ref-type="bibr">12</xref>,<xref rid="B13-sensors-22-05849" ref-type="bibr">13</xref>,<xref rid="B14-sensors-22-05849" ref-type="bibr">14</xref>,<xref rid="B15-sensors-22-05849" ref-type="bibr">15</xref>,<xref rid="B16-sensors-22-05849" ref-type="bibr">16</xref>,<xref rid="B17-sensors-22-05849" ref-type="bibr">17</xref>,<xref rid="B18-sensors-22-05849" ref-type="bibr">18</xref>,<xref rid="B19-sensors-22-05849" ref-type="bibr">19</xref>].</p>
    <p>Although some authors mention usability or efficiency to be important [<xref rid="B10-sensors-22-05849" ref-type="bibr">10</xref>,<xref rid="B11-sensors-22-05849" ref-type="bibr">11</xref>,<xref rid="B17-sensors-22-05849" ref-type="bibr">17</xref>], to the best of the authors’ knowledge, for only one of the GUIs from [<xref rid="B10-sensors-22-05849" ref-type="bibr">10</xref>,<xref rid="B11-sensors-22-05849" ref-type="bibr">11</xref>,<xref rid="B12-sensors-22-05849" ref-type="bibr">12</xref>,<xref rid="B13-sensors-22-05849" ref-type="bibr">13</xref>,<xref rid="B14-sensors-22-05849" ref-type="bibr">14</xref>,<xref rid="B15-sensors-22-05849" ref-type="bibr">15</xref>,<xref rid="B16-sensors-22-05849" ref-type="bibr">16</xref>,<xref rid="B17-sensors-22-05849" ref-type="bibr">17</xref>,<xref rid="B18-sensors-22-05849" ref-type="bibr">18</xref>,<xref rid="B19-sensors-22-05849" ref-type="bibr">19</xref>], a usability study was conducted. The <italic toggle="yes">Wearables Development Toolkit</italic> (WDK) by Haladjian [<xref rid="B11-sensors-22-05849" ref-type="bibr">11</xref>] was tested by three students without prior knowledge of the programming language. Qualitative feedback was collected using semi-structured interviews. The feedback was then used to improve the WDK. Afterwards, a user study with two participants was conducted. For evaluation purposes, an unstructured interview was conducted and seven questions were answered using a five-point Likert scale. However, the sample size of two participants is very small. For a different GUI developed by Fedjajevs et al. [<xref rid="B10-sensors-22-05849" ref-type="bibr">10</xref>] named <italic toggle="yes">Platform for Analysis and Labeling of Medical time-series</italic> (PALMS), no explicit results regarding usability were reported. However, the GUI includes algorithms to lower the necessary effort for labeling. These automatically detect characteristic points in an electrocardiogram (ECG) or a photoplethysmogram (PPG) and, thus, decrease the necessary effort for labeling. Likely, this increases usability; however, usability was not evaluated in the study. Furthermore, the authors state that the GUI is adaptable to load data of different formats and use different algorithms. However, evaluations regarding such adaptations are not described in the publication.</p>
    <p>Missing evaluations can lead to technical roadblocks, since systems that are difficult to use for domain experts, such as healthcare workers, discourage them from using them [<xref rid="B24-sensors-22-05849" ref-type="bibr">24</xref>]. Ultimately, this hinders the translation of developed systems to domain experts or end-users, for example in the domains of sports and health [<xref rid="B11-sensors-22-05849" ref-type="bibr">11</xref>,<xref rid="B25-sensors-22-05849" ref-type="bibr">25</xref>,<xref rid="B26-sensors-22-05849" ref-type="bibr">26</xref>]. More detailed information about technical roadblocks for clinical practitioners was collected in a study by Routhier et al. [<xref rid="B26-sensors-22-05849" ref-type="bibr">26</xref>]. They conducted a study on clinicians’ perspectives on factors hindering the data analysis and visualization of time-series data recorded with a wearable sensor. The clinicians most frequently stated that high ease-of-use, as well as the quick generation of results were important to them, underlining the need for testing usability and user experience.</p>
    <p>However, usability and user experience have not been tested in existing packages for time-series analysis. More importantly, only one of the GUIs (<italic toggle="yes">PALMS</italic> [<xref rid="B10-sensors-22-05849" ref-type="bibr">10</xref>]) listed above is a Python package, which is adaptable in terms of loading different data formats and customization of labels and algorithms. Nonetheless, we observed shortcomings in terms of the adaptability of PALMS and using it in a domain other than ECG/PPG, such as human activity or gait. Additionally, existing GUIs cannot be used for macro annotations, e.g., walking bouts, and micro annotations, e.g., strides, at the same time, which is a major requirement for adoption in the analysis of human activity or gait.</p>
    <p>Therefore, we developed a new Python package, the Machine Learning and Data Analytics (MaD) GUI (see <xref rid="app1-sensors-22-05849" ref-type="app">Supplementary Materials</xref> for code, documentation, and videos). The main contribution of MaD GUI are: (1) It is open-source and, thus, can in the future be used and adapted by other developers for different domains or clinical use cases. (2) MaD GUI’s plugin architecture allows loading arbitrary data formats and the integration of algorithms. (3) The extensive documentation supports the development of plugins and using the GUI.</p>
    <p>As a supplement to publishing MaD GUI, we conducted a small-scale study to assess MaD GUI from the perspective of developers, as well as domain experts represented by clinical researchers. Although related publications did not provide such insights [<xref rid="B10-sensors-22-05849" ref-type="bibr">10</xref>,<xref rid="B12-sensors-22-05849" ref-type="bibr">12</xref>,<xref rid="B13-sensors-22-05849" ref-type="bibr">13</xref>,<xref rid="B14-sensors-22-05849" ref-type="bibr">14</xref>,<xref rid="B15-sensors-22-05849" ref-type="bibr">15</xref>,<xref rid="B16-sensors-22-05849" ref-type="bibr">16</xref>,<xref rid="B17-sensors-22-05849" ref-type="bibr">17</xref>,<xref rid="B18-sensors-22-05849" ref-type="bibr">18</xref>], we think that this is an important step in providing software that can be re-used in the community.</p>
  </sec>
  <sec id="sec2-sensors-22-05849">
    <title>2. Materials and Methods</title>
    <sec id="sec2dot1-sensors-22-05849">
      <title>2.1. Requirements</title>
      <p>Fulfilling certain requirements is crucial to enable developers and domain experts to use the package [<xref rid="B27-sensors-22-05849" ref-type="bibr">27</xref>]. For both, the package must be compatible with major operating systems, such as Windows, macOS, or Unix-based systems. We achieved this by including developers using different operating systems in the development of the package. Additionally, we automatically build standalone versions for Windows, macOS, and Ubuntu upon new releases of the package.</p>
      <sec id="sec2dot1dot1-sensors-22-05849">
        <title>2.1.1. Source Code</title>
        <p><bold>Programming language and packages:</bold> As described in the Introduction, Python has become the dominant language in scientific computing, especially in the area of machine learning [<xref rid="B22-sensors-22-05849" ref-type="bibr">22</xref>,<xref rid="B23-sensors-22-05849" ref-type="bibr">23</xref>]. Therefore, we chose Python as the programming language, such that most researchers in the domain can make use of the package. Furthermore, the plots in the GUI are based on PyQtGraph since it contains classes for labeling regions or samples, which can serve as base classes for our implementation [<xref rid="B28-sensors-22-05849" ref-type="bibr">28</xref>]. Accordingly, we used PySide (<uri xlink:href="https://pypi.org/project/PySide2/">https://pypi.org/project/PySide2/</uri> (accessed on 27 December 2021)), the Python bindings for the Qt GUI framework, to create the user interface.</p>
        <p><bold>Readability:</bold> Using consistent formatting is important to the readability of code [<xref rid="B29-sensors-22-05849" ref-type="bibr">29</xref>]. Therefore, we decided to use the <italic toggle="yes">black</italic> code formatter [<xref rid="B30-sensors-22-05849" ref-type="bibr">30</xref>], which enforces following the <italic toggle="yes">PEP8</italic> guidelines [<xref rid="B31-sensors-22-05849" ref-type="bibr">31</xref>]. Furthermore, we used <italic toggle="yes">pylint</italic> [<xref rid="B32-sensors-22-05849" ref-type="bibr">32</xref>] for additional guidelines not enforced by <italic toggle="yes">PEP8</italic>, as for example, the number of arguments of a method or function. We note that <italic toggle="yes">black</italic> and <italic toggle="yes">pylint</italic> are opinionated and thus could be replaced by other methods.</p>
        <p><bold>Documentation:</bold> Especially for scientific work, documentation is important to ensure reproducibility [<xref rid="B33-sensors-22-05849" ref-type="bibr">33</xref>]. As stated in the Introduction, poor documentation is one likely reason for other GUIs not being publicly available. The documentation is even more important for MaD GUI since members of the community must be able to understand the code, which is a prerequisite for adapting the code or for adding new features [<xref rid="B34-sensors-22-05849" ref-type="bibr">34</xref>]. The most important parts of the documentation are how to set up the project, how it works, and guides to performing common tasks [<xref rid="B27-sensors-22-05849" ref-type="bibr">27</xref>]. All of these items are part of our documentation [<xref rid="B35-sensors-22-05849" ref-type="bibr">35</xref>].</p>
        <p><bold>Barriers to entry:</bold> The developer’s effort to use open-source software is an important aspect [<xref rid="B27-sensors-22-05849" ref-type="bibr">27</xref>]. Therefore, future users of the MaD GUI package should only be required to interact with packages and data types they are likely familiar with. We achieved this by constructing the plugins to use mostly Python builtins, such as dictionaries, or well-known Python libraries, such as pandas [<xref rid="B22-sensors-22-05849" ref-type="bibr">22</xref>,<xref rid="B36-sensors-22-05849" ref-type="bibr">36</xref>]. Additionally, we kept the code complexity of the package low by using a linter. Furthermore, we provide a quick start guide for developers in the documentation, provide exemplary data, and made the package installable via pip.</p>
        <p><bold>Composability:</bold> MaD GUI should provide composability, which increases the possibilities for the adaption and maintainability of the package [<xref rid="B37-sensors-22-05849" ref-type="bibr">37</xref>]. We achieved this, on the one hand, by using a minimal set of four dependencies. This way, dependency conflicts are only expected in rare cases when implementing other algorithms. On the other hand, we attained composability on a higher level by developing MaD GUI as a plugin system. This makes it possible to combine plugins, for example a plugin for loading a specific dataset with a plugin algorithm.</p>
        <p><bold>Testing:</bold> To keep all parts of the package working even when it grows, for example by attracting other developers, we maintain an extensive test suite for all the core components of the GUI. It is automatically run on each change and assesses whether new developments break important parts of the code, allowing for quick fixes [<xref rid="B38-sensors-22-05849" ref-type="bibr">38</xref>]. As a common metric, the percentage of tested code is evaluated. However, this does not reflect the quality of conducted tests and, thus, needs to be treated with caution.</p>
      </sec>
      <sec id="sec2dot1dot2-sensors-22-05849">
        <title>2.1.2. User Interface</title>
        <p><bold>Design:</bold> A well-designed user interface can shorten the required time to learn the system, decrease the time to complete tasks, and overall, lead to increased user satisfaction [<xref rid="B38-sensors-22-05849" ref-type="bibr">38</xref>]. We followed evidence-based guidelines for designing the user interface and hope to encourage other researchers to follow these or other applicable guidelines, especially when sharing software with the community. Some principles to mention are the <italic toggle="yes">Eight Golden Rules</italic> by Shneiderman [<xref rid="B38-sensors-22-05849" ref-type="bibr">38</xref>], the <italic toggle="yes">Gestalt Laws of Perception</italic> [<xref rid="B39-sensors-22-05849" ref-type="bibr">39</xref>,<xref rid="B40-sensors-22-05849" ref-type="bibr">40</xref>], as well as <italic toggle="yes">Fitts’ Law of Human Hand Movement</italic> [<xref rid="B41-sensors-22-05849" ref-type="bibr">41</xref>,<xref rid="B42-sensors-22-05849" ref-type="bibr">42</xref>]. This is not extensive and gives only an exemplary overview of elements we found not, or not completely, fulfilled by other available GUIs for time-series analysis.</p>
        <p><bold>Functionalities:</bold> Next to the design, the user interface must provide certain functionalities. Here, we focus on the functionalities that are relevant for domain experts from gait analysis. According to Routhier et al. [<xref rid="B26-sensors-22-05849" ref-type="bibr">26</xref>], the most important aspect for clinicians in terms of functionality is the speed with which results can be generated. This refers both to the processing time of the computer, as well as the amount of “clicks” needed. In terms of analyzing data from inertial measurement units (IMUs), clinicians need to be able to visualize 24 h datasets. Furthermore, clinicians want to be able to select the desired raw data and apply algorithms to them. When asked for improvements regarding existing technology, they most often named ease-of-use.</p>
        <p>Although some of these requirements are met by existing GUIs, we had additional requirements that were missing: In our scenario of gait analysis, it is necessary to label macro activities, e.g., walking or jumping, and micro activities, such as single strides. Therefore, several levels of annotations were necessary. Furthermore, it should be possible to load and save custom data formats. Implementing state-of-the-art algorithms in the GUI should be possible in a short amount of time. In terms of use for domain experts, it should be possible to create a standalone executable. Additionally, when labeling activity data, it may be useful to synchronize recorded sensor data with video.</p>
      </sec>
    </sec>
    <sec id="sec2dot2-sensors-22-05849">
      <title>2.2. Implementation of the User Interface</title>
      <p>The user interface consists of three areas, as shown in <xref rid="sensors-22-05849-f001" ref-type="fig">Figure 1</xref>: the side-bar on the left, the plot, and the mode buttons at the top of the GUI. They serve different functionalities, which are described on a functional level in the next paragraphs.</p>
      <p>The side-bar servers as an interface to plugins, which can be used to load data of a specific format, apply an algorithm to the displayed data, or export the displayed data and annotations. When pressing any of the three upper buttons in the side-bar, the user can select a plugin to use. In the case of the <italic toggle="yes">Load data</italic> button, the user can also select a data file and, optionally, a video to be displayed or already existing annotations to be loaded, as shown in <xref rid="sensors-22-05849-f002" ref-type="fig">Figure 2</xref>.</p>
      <p>After loading data, the user can click the <italic toggle="yes">Use algorithm</italic> button to run an algorithm. The MaD GUI package contains two exemplary algorithms: one for detecting stationary moments and one for calculating the energy in the detected stationary moments. For exporting the data, displayed annotations, or calculated features, the user can select a plugin by clicking on the <italic toggle="yes">Export data</italic> button. Additionally, the GUI offers the possibility to <italic toggle="yes">Save displayed data</italic> in a pickle format [<xref rid="B43-sensors-22-05849" ref-type="bibr">43</xref>]. This allows loading the displayed data and annotations again later using the <italic toggle="yes">Reload displayed data</italic> button or to load them in other applications.</p>
      <p>The plot area is created dynamically depending on the plugin that has been used to load the data. This refers to the number of plots being created and the x-axis labels. For example, in gait analysis, it might be necessary to plot data of several sensors from different body parts, e.g., foot, shank, thigh, and lower back [<xref rid="B44-sensors-22-05849" ref-type="bibr">44</xref>]. Each of the sensors would be represented in separate plots. The x-axis label can be set to a datetime representation instead of seconds if the start time of the recording is known.</p>
      <p>Buttons at the top of the GUI can be used to change the GUI’s mode. To indicate the active mode, the button changes its color, as can be seen in <xref rid="sensors-22-05849-f001" ref-type="fig">Figure 1</xref>. The green line moves with the mouse arrow and is set by pressing the left mouse button or space. Afterwards, a description of the generated annotation can be set in a dialog window. In the <italic toggle="yes">Edit annotation</italic> mode, the user can change an annotation’s description and boundaries. To remove an annotation, the user has to switch to the <italic toggle="yes">Remove annotation</italic> mode. By clicking the button of the activated mode or by pressing <italic toggle="yes">Esc</italic> on the keyboard, the GUI is in <italic toggle="yes">Investigation mode</italic>, and the user cannot add, change, nor delete annotations mistakenly. In this mode, it is possible to move/zoom in and out the data, execute plugins, and inspect the annotations’ description. When hovering over an annotation, a tooltip with the annotation’s description will be shown. If a video is loaded and displayed in additional to the sensor data, synchronization of video and sensor data can be performed in synchronization mode.</p>
    </sec>
    <sec id="sec2dot3-sensors-22-05849">
      <title>2.3. Software Structure</title>
      <p>An important goal of this package is composability. In terms of software structure, we achieved this using a plugin architecture, which is explained in the following section. Afterwards, we describe the interface between plugins, data, and plots of the GUI represented as a model–view–controller logic.</p>
      <sec id="sec2dot3dot1-sensors-22-05849">
        <title>2.3.1. Plugins</title>
        <p>Developers who use the MaD GUI package can create and inject plugins to extend MaD GUI’s functionality. These plugins can be used to:<list list-type="bullet"><list-item><p>Import data from a recording device <italic toggle="yes">(Importer)</italic>;</p></list-item><list-item><p>Define a label to be used within the GUI <italic toggle="yes">(Label)</italic>;</p></list-item><list-item><p>Execute an algorithm, which creates or processes annotations <italic toggle="yes">(Algorithm)</italic>;</p></list-item><list-item><p>Export plotted data and/or annotations <italic toggle="yes">(Exporter)</italic>.</p></list-item></list></p>
        <p>Plugins can be combined in development or at runtime, such that it is, for example, possible to use an algorithm with data from different recording devices. Here, we give an insight into how a plugin for an <italic toggle="yes">Importer</italic> can be created. An extensive description of plugins and working examples is a part of MaD GUI’s documentation [<xref rid="B35-sensors-22-05849" ref-type="bibr">35</xref>].</p>
        <p>For all plugins, developers need to create a class inheriting from one of several base classes provided by MaD GUI. In the case of an Importer, this class is called <italic toggle="yes">BaseImporter</italic>. It has a method to expose its name to the GUI, which is used to represent the Importer in the dropdown menu of the load data dialog; see also <xref rid="sensors-22-05849-f002" ref-type="fig">Figure 2</xref>. Additionally, it has a method <italic toggle="yes">load_sensor_data</italic>, which returns a dictionary containing sensor data as a pandas DataFrame and a sampling rate. The exemplary importer that comes with the GUI is able to read <italic toggle="yes">csv</italic> files:</p>
        <p>
          <inline-graphic xlink:href="sensors-22-05849-i001.jpg"/>
        </p>
        <p>Similarly, as shown in this example, developers can also pass algorithms, configurations for the labels, settings, or a color theme to the GUI. More details on creating these are available in MaD GUI’s documentation [<xref rid="B35-sensors-22-05849" ref-type="bibr">35</xref>].</p>
      </sec>
      <sec id="sec2dot3dot2-sensors-22-05849">
        <title>2.3.2. Model–View–Controller</title>
        <p>Plugins like an importer or an algorithm use Python dictionaries and pandas DataFrames represent data such that developers of plugins can use familiar data types. However, the underlying libraries for plotting the data need a different representation of the data. Therefore, MaD GUI uses a model–view–controller approach to separate the representation of data from the plotting of the data and from the user interaction [<xref rid="B45-sensors-22-05849" ref-type="bibr">45</xref>,<xref rid="B46-sensors-22-05849" ref-type="bibr">46</xref>].</p>
        <p><bold>Model:</bold> The model is a representation of all data available in the GUI. Therefore, it serves as an interface between the MaD GUI package and developers of plugins. The model is a <italic toggle="yes">GlobalData</italic> object, which, among other things, keeps the name of the currently loaded file. Additionally, the <italic toggle="yes">GlobalData</italic> object contains one <italic toggle="yes">PlotData</italic> object per plot in the GUI. The <italic toggle="yes">PlotData</italic> object contains the plotted data represented as a pandas DataFrame. Furthermore, plotted annotations are stored in <italic toggle="yes">PlotData’s</italic> attribute <italic toggle="yes">annotations</italic>, represented as a pandas DataFrame. Furthermore, a <italic toggle="yes">PlotData</italic> object can be used to store additional data that are not plotted, but might be necessary for the algorithms to process the data. More information about <italic toggle="yes">GlobalData</italic>, <italic toggle="yes">PlotData</italic>, and <italic toggle="yes">AnnotationData</italic> is available in the package documentation.</p>
        <p><bold>View:</bold> The data and annotations in the <italic toggle="yes">PlotData</italic> objects are plotted by the <italic toggle="yes">view</italic>. Plotting is necessary if data are loaded, an algorithm is executed, or when the user interacts with the view, for example to add or remove an annotation. For plotting, we use <italic toggle="yes">pyqtgrpah</italic>, although matplotlib is the de facto standard for 2D plotting in scientific computing with Python. We chose <italic toggle="yes">pyqtgraph</italic> because it has inbuilt classes for labeling samples or regions, which serve as base classes for the labels that can be plotted. Furthermore, plotting is faster compared to matplotlib [<xref rid="B28-sensors-22-05849" ref-type="bibr">28</xref>].</p>
        <p><bold>Controller:</bold> The controller serves as an interface between the user input and the <italic toggle="yes">model</italic>, as well as the <italic toggle="yes">view</italic>. In our approach, there is a global controller, which is the class <italic toggle="yes">MainWindow</italic>. Among others, it handles button clicks and instantiates the views. Furthermore, each plot has one local controller, which changes according to the GUI’s modes. For example, this handles the consequence of a mouse click on an annotation. If the GUI is in the mode <italic toggle="yes">remove</italic>, it gets removed from the view. However, if the GUI is in the mode <italic toggle="yes">investigate</italic>, this would not result in any change.</p>
      </sec>
    </sec>
    <sec id="sec2dot4-sensors-22-05849">
      <title>2.4. Code Complexity</title>
      <p>The more complex the code is, the harder it is to maintain. Further, a complex software structure makes it harder for new developers to use it. One of the first approaches to assessing the maintainability of software modules was suggested by McCabe in 1976 [<xref rid="B47-sensors-22-05849" ref-type="bibr">47</xref>]. He suggested cyclomatic complexity, which is a graph-theoretic complexity measure. It determines the number of independent paths that can be taken through a code and is widely used [<xref rid="B48-sensors-22-05849" ref-type="bibr">48</xref>]. The original concept, developed in Fortran, is outdated. This is exemplified by the fact that it does not include structures such as try/catch or lambdas. Furthermore, cyclomatic complexity does not necessarily reflect the effort necessary to comprehend the code [<xref rid="B49-sensors-22-05849" ref-type="bibr">49</xref>,<xref rid="B50-sensors-22-05849" ref-type="bibr">50</xref>]. Therefore, several models have been developed to assess cognitive complexity, specifically designed to assess code understandability [<xref rid="B49-sensors-22-05849" ref-type="bibr">49</xref>,<xref rid="B51-sensors-22-05849" ref-type="bibr">51</xref>,<xref rid="B52-sensors-22-05849" ref-type="bibr">52</xref>,<xref rid="B53-sensors-22-05849" ref-type="bibr">53</xref>]. A well-accepted model was suggested by <italic toggle="yes">SonarSource SA</italic> [<xref rid="B54-sensors-22-05849" ref-type="bibr">54</xref>]. Although this model is based on cyclomatic complexity, <italic toggle="yes">SonarSource SA’s</italic> model of cognitive complexity is closer to representing code understandability, which is described in detail elsewhere [<xref rid="B55-sensors-22-05849" ref-type="bibr">55</xref>] It is accessible via sonarcloud, but can also be used locally using an extension for <italic toggle="yes">flake8</italic> [<xref rid="B56-sensors-22-05849" ref-type="bibr">56</xref>]. For these reasons, we evaluated the packages using this implementation of cognitive complexity.</p>
    </sec>
    <sec id="sec2dot5-sensors-22-05849">
      <title>2.5. Study</title>
      <p>Similar tools fulfilling parts of the requirements mentioned above for time-series analysis have been published [<xref rid="B10-sensors-22-05849" ref-type="bibr">10</xref>,<xref rid="B11-sensors-22-05849" ref-type="bibr">11</xref>,<xref rid="B15-sensors-22-05849" ref-type="bibr">15</xref>,<xref rid="B16-sensors-22-05849" ref-type="bibr">16</xref>,<xref rid="B17-sensors-22-05849" ref-type="bibr">17</xref>,<xref rid="B18-sensors-22-05849" ref-type="bibr">18</xref>]. However, they were not evaluated regarding adaptability or the user interface for other researchers, except for the <italic toggle="yes">WDK</italic>, which was tested in a pre-study with three participants and a study with two participants. Although studying adaptability and usability is not typical for publishing software packages, we decided to conduct a small-scale study to minimize the potential of severe issues regarding these aspects. The study was conducted among developers to assess the adaptability of MaD GUI from the developers’ perspective and a separate study among clinicians to assess the user interface.</p>
      <p>In both parts of the study, we compared MaD GUI to PALMS as representative of the state-of-the-art [<xref rid="B10-sensors-22-05849" ref-type="bibr">10</xref>]. We chose PALMS for several reasons: The first reason is that it fulfills our requirement of being programmed in Python. Furthermore, it claims to be adaptable to other data formats or algorithms that are not known to the open-source implementation, which meets another of our requirements. Lastly, the process of annotating data is similar in that both regions and single events can be annotated in MaD GUI and PALMS. In contrast to MaD GUI, PALMS was developed with a focus on ECG and PPG signals and not with a focus on generalization. However, it was the only GUI coming close to our requirements, and thus, we chose to compare MaD GUI with PALMS.</p>
      <p>After communication with the local Ethics Committee, this study was exempt from the need to obtain ethical approval. Reasons for this include that we did not expect the study participants to be under higher emotional or psychological stress than in their everyday work. To ensure this, they participated in the study separately and the coordinator of the study did not observe them during the execution of the tasks. Although this study was exempt from ethical approval, participants gave informed consent before they were included in the study.</p>
      <sec id="sec2dot5dot1-sensors-22-05849">
        <title>2.5.1. Adaptability</title>
        <p><bold>Background information:</bold> We included ten participants to assess both MaD GUI and PALMS. The participants had different career stages: four participants were students; four were research assistants or Ph.D. students; two were postdocs. However, since the study was time-demanding, we used a between-group study design. Participants were assigned to either MaD GUI or PALMS. Care was taken to ensure that each group had an equal number of participants from each career stage. Furthermore, we assessed their programming experience and balanced the groups. An approach recommended by Siegmund et al. [<xref rid="B57-sensors-22-05849" ref-type="bibr">57</xref>] is to assess self-estimated programming experience compared to peers, as well as programming experience in general. Regarding the latter, all participants had more than two years of programming experience. Specifically for Python, the students had one to two years of experience. The research assistants/Ph.D. students had more than two years of Python experience. One postdoc had 1–2 years of experience in Python and the other one less than one year. The remaining participants had more than two years of experience in Python. Two questions were answered using a five-point Likert scale from 1 (very inexperienced) to 5 (very experienced), of which the results are shown in <xref rid="sensors-22-05849-t001" ref-type="table">Table 1</xref>:<list list-type="bullet"><list-item><p>How do you estimate your programming experience compared to your colleagues/fellow students?</p></list-item><list-item><p>How experienced are you with object-oriented programming?</p></list-item></list></p>
        <p>The study was conducted remotely at each user’s workplace, on his/her computer. The operating systems were Windows, macOS, and Linux (manjaro). When having certain issues, participants were offered to share their screens and get help from the study coordinator (M.O.). Before conducting the study, several topics were selected for which help was granted: understanding the task, solving dependency conflicts, problems with the development environment, importing classes or functions, or transforming between different data types such as pandas DataFrames and NumPy arrays.</p>
        <p><bold>Tasks:</bold> Before executing the tasks described below, the study coordinator assisted in setting up a virtual environment and the IDE the programmer used. We decided to exclude this from the study since it is the same process for both packages. Afterwards, study participants had to solve four tasks.</p>
        <p>First, they were given a link to the GitHub page of the <uri xlink:href="https://github.com/mad-lab-fau/mad-gui#readme">https://github.com/mad-lab-fau/mad-gui#readme</uri> (accessed 26 October 2021), <uri xlink:href="https://github.com/PALMS-gui/PALMS#readme">https://github.com/PALMS-gui/PALMS#readme</uri> (accessed 26 October 2021). The objective was to get an overview of the documentation, such that they get an impression of the package and learn about its documentation structure. Participants could take as much time for this task as they felt necessary, but were informed that they can go back to the documentation any time they felt it was necessary while conducting the remaining tasks.</p>
        <p>A low entry barrier is important, as stated in the Introduction. Developers may wish to test the package using example data to get a feeling of whether it suffices for their needs. Thus, installing and starting the GUI is an important aspect. Therefore, this was the second task for developers.</p>
        <p>Thirdly, the developers were asked to use the package to load a data format that is not natively supported by the package. The data used in this study were recorded using wearable sensors, which are increasingly adopted in patient monitoring [<xref rid="B4-sensors-22-05849" ref-type="bibr">4</xref>]. We used data published by Weiss et al. [<xref rid="B58-sensors-22-05849" ref-type="bibr">58</xref>] available via PhysioNet [<xref rid="B59-sensors-22-05849" ref-type="bibr">59</xref>]. After the study participants implemented the necessary code, they were asked to show the resulting plot in the GUI to the study supervisor to validate the result.</p>
        <p>For the fourth task, developers were asked to implement an open-source algorithm for gait analysis in the GUI. For this task, they were instructed to additionally install PDkit [<xref rid="B60-sensors-22-05849" ref-type="bibr">60</xref>]. The developer’s goal was to apply PDkit’s Bellman segmentation to gait data to divide them into two segments. Since we wanted to exclude the time for comprehending PDkit’s interface from this study, we provided them with a function that applies this method to data. Therefore, the users were required to pass data as a pandas DataFrame and the sampling frequency as a float to the mentioned function. It then transforms the data into the PDkit data format, constructs the object for segmentation, and returns results as a human-readable pandas DataFrame. After implementing the necessary code, they were asked to show the resulting plot in the GUI to the study supervisor to validate the result.</p>
      </sec>
      <sec id="sec2dot5dot2-sensors-22-05849">
        <title>2.5.2. User Interface</title>
        <p><bold>Background Information:</bold> For this part of the study, the domain of gait analysis was chosen. However, the only important aspect is to include participants without programming knowledge. The reason is that the user interface should also enable persons without programming knowledge to use open-source, state-of-the-art algorithms. We argue that it is not necessary to have the user interface also evaluated by developers because they likely have a higher technical affinity and will get along easier than users from other domains.</p>
        <p>We included six participants in the evaluation of the user interface. Here, we used a within-group study design, since the tasks were less time-demanding compared to the adaptability study. However, half of the group started with MaD GUI, while the other half started with PALMS. Both groups contained a student, a physiotherapist or study nurse, and a medical doctor. All participants had prior experience with recording sensor data. Therefore, they were familiar with IMUs. However, they were given short information on what signals of motion and rest look like. In an attempt to reduce bias, participants were told that both GUIs had been developed by the study coordinator. Upon finishing the study, the participants were informed that PALMS existed before the study and was developed by another group.</p>
        <p>Both MaD GUI and PALMS were slightly modified for the user interface study. It was necessary to enable them to load the data of an IMU and to execute the segmentation algorithm from the adaptability study. Furthermore, both packages were adapted such that time spent in the GUI and time spent elsewhere was recorded, for example in the task description or package documentation.</p>
        <p>The study was conducted at the university hospital Erlangen, Germany. During the execution of the tasks, the study coordinator did not watch the participants’ actions, unless asked for help. Support was given if participants did not find certain information after searching for more than five minutes and asked for help. Furthermore, questions regarding the necessary accuracy of annotating data were answered.</p>
        <p><bold>Tasks:</bold> Before executing any task, the participants were shown how to start the GUI via the IDE. Furthermore, they received information about how to switch between the browser, the task description, and the GUI. Furthermore, they could ask questions regarding clarification of the tasks.</p>
        <p>Before the study, two datasets were recorded by the study coordinator (M.O.). An IMU was worn in the subject’s pocket, who first walked at normal speed, then slow, and then fast. In between, the subject took a short break. In the second recording, the subject walked back and forth a fixed distance four times, referred to as the 4 × 10 m gait test.</p>
        <p>The first task was the same as in the adaptability study—to get an overview of the package’s documentation. Participants could spend as much time as they wanted. No questions were answered during this task.</p>
        <p>For the second task, the participants had to load data and create manual annotations. In the case of MaD GUI, the task description named the importer they should use, and in the case of PALMS, it provided the database name. They loaded the data of the subject walking at three speeds and were instructed to annotate them accordingly. They could freely switch between the GUI and the task description or GUI documentation if it was necessary. This task was used to assess how easy it was to create annotations in the GUIs.</p>
        <p>Lastly, they had to use an algorithm to create automated annotations for the 4 × 10 m gait test. Upon execution of the PDkit algorithm, four segments for walking and four segments for standing were created. The participants had to delete annotations where the subject was not walking. Additionally, they had to adapt the boundaries for the annotations of walking, since most of the automatically created annotations missed one or two gait cycles in the end. This task assesses the usability of editing and removing annotations, but also whether it is easy for users to understand how to edit and remove annotations.</p>
      </sec>
      <sec id="sec2dot5dot3-sensors-22-05849">
        <title>2.5.3. Evaluation</title>
        <p>Regarding objective code analysis, we determined cognitive complexity, number of comments, and lines of code. On the one hand, this limits the comparability to projects written in other languages. For example in Java, Weighted Methods per Class, Coupling Between Objects, or Lack of Cohesion in Methods are the most frequently used object-oriented programming metrics [<xref rid="B61-sensors-22-05849" ref-type="bibr">61</xref>]. On the other hand, we chose the metrics mentioned above since these are accessible via Python packages, such as radon or prospector. This makes it more likely for our results to be comparable to other Python projects.</p>
        <p>All tasks were evaluated using the task completion time. The time needed to fulfill each task was stopped by the supervisor of the study. However, in the case of the adaptability study, we excluded the time needed for installing dependencies. We decided on this since it only led to dependency conflicts with PALMS when additionally installing PDkit. These conflicts can be fixed quickly, by using less strict dependency management in PALMS or PDkit and, therefore, were excluded from the evaluation of the package itself.</p>
        <p>We suggest that the task completion time indirectly assesses factors such as good readability, usefulness, structured documentation, and low barrier to entry. However, since it does not yield information about the issues participants encountered during the study, we decided to additionally offer the participants to give unstructured free-text feedback.</p>
        <p>After completing all tasks, the study participants filled out two questionnaires. The System Usability Scale (SUS) was used to assess the overall impression of the package [<xref rid="B62-sensors-22-05849" ref-type="bibr">62</xref>]. Furthermore, user experience was assessed with the user experience questionnaire [<xref rid="B63-sensors-22-05849" ref-type="bibr">63</xref>].</p>
        <p>Certain requirements for the MaD GUI package were not assessed directly in the study. Some requirements are fulfilled inherently, for example readability, which is ensured by using a linter and a formatter. Furthermore, a low barrier to entry is partly fulfilled because only Python builtins or well-known Python packages need to be used by the developers. Therefore, these factors were not assessed directly. Instead, we assessed them indirectly using the task completion time. The reason is that code comprehension does not only depend on factors such as objective readability, but is individual, as it depends on factors such as cognitive speed [<xref rid="B64-sensors-22-05849" ref-type="bibr">64</xref>]. However, task completion time does not indicate which aspects are causing potential issues, so we additionally obtained unstructured, free-text feedback from the study participants.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="results" id="sec3-sensors-22-05849">
    <title>3. Results</title>
    <p>The following section reports results regarding the code of MaD GUI and PALMS. Afterwards, we describe the results of the adaptability and user studies. We are aware that the comparability of MaD GUI and PALMS GUI is limited, as the latter was not specifically built for certain tasks used in this study. In no way should our results be considered a direct criticism of the PALMS GUI, and we encourage authors to consider PALMS as an alternative to our package, especially when using PPG or ECG data.</p>
    <sec id="sec3dot1-sensors-22-05849">
      <title>3.1. Code Complexity</title>
      <p>We used sonarcloud for code analysis (<uri xlink:href="https://sonarcloud.io/component_measures?id=MalteOlle_mad-gui">https://sonarcloud.io/component_measures?id=MalteOlle_mad-gui</uri> (accessed 6 February 2022), <uri xlink:href="https://sonarcloud.io/component_measures?id=MalteOlle_PALMS">https://sonarcloud.io/component_measures?id=MalteOlle_PALMS</uri> (accessed 6 February 2022)). Selected results are shown in <xref rid="sensors-22-05849-t002" ref-type="table">Table 2</xref>. MaD GUI roughly has half the cognitive complexity of PALMS. On the one hand, this is attributed to the fact that MaD GUI has 30% fewer lines of code than PALMS. On the other hand, this is influenced by the coding style. Furthermore, the analysis showed that MaD GUI has more comments, both absolutely and relative to the number of lines.</p>
    </sec>
    <sec id="sec3dot2-sensors-22-05849">
      <title>3.2. Adaptability Study</title>
      <p>This section first describes the time needed to execute the tasks in the study. Afterwards, the results of the assessed questionnaires and free text are presented.</p>
      <p><bold>Time:</bold> Developers using MaD GUI could solve the first task faster than using PALMS, as shown in <xref rid="sensors-22-05849-f003" ref-type="fig">Figure 3</xref>. Regarding the installation and start of MaD GUI, there were no delays on any of the tested operating systems.</p>
      <p>Regarding the extension of the packages to load gait data from PhysioNet, MaD GUI outperformed PALMS by twenty minutes, or a factor of two. For PALMS, developers had difficulties understanding the structure of the exemplary database. Furthermore, they had difficulties regarding the data types to be used. Especially, they had to create objects of a specific PALMS in-built class (<italic toggle="yes">Wave</italic>). Before creating this object, they had to understand its structure and working principle. In contrast, for MaD GUI, the developers were required to create a dictionary containing a pandas DataFrame and a float, which are well-known data formats.</p>
      <p>The largest difference was found when implementing an open-source algorithm into the GUI. For MaD GUI, the developers needed ten minutes, while for PALMS, they needed 45 min. This large difference resulted mainly from two issues. First, the developers had to find out how to plot annotations (partitions) in PALMS, which was not documented. Second, they had to find out where to execute the algorithm, such that they would have access to the already plotted data. In contrast, for MaD GUI, the developers only needed to fill a method in a documented example and pass the created class to MaD GUI’s function <italic toggle="yes">start_gui</italic>. Similar to loading data, they had to deal with well-known libraries, such as pandas. As an additional contrast to PALMS, plotting was then handled by the MaD GUI package, such that the developers did not need to implement plotting themselves.</p>
      <p>For tasks of loading data and implementing an algorithm, we did not include the time needed to install dependencies. The reason is that installing both PALMS and PDkit resulted in dependency conflicts that had to be solved. When installing MaD GUI and PDkit, no dependency conflicts occurred.</p>
      <p><bold>Questionnaires.</bold> The median score for the SUS was 90 and 35 for MaD GUI and PALMS, respectively. The value for MaD GUI is in the third quartile, and the value for PALMS is in the first quartile, referring to quartiles as suggested by Bangor et al. [<xref rid="B65-sensors-22-05849" ref-type="bibr">65</xref>]. This suggests better usability of MaD GUI than PALMS from the perspective of a developer extending the package.</p>
      <p>Regarding the user experience questionnaire, results are shown in <xref rid="sensors-22-05849-t003" ref-type="table">Table 3</xref>. MaD GUI received better scores throughout all scales of the UEQ. The lowest rating for MaD GUI was <italic toggle="yes">novelty</italic>, indicating that the design of the overall package could be improved. For PALMS, the lowest rating was obtained for <italic toggle="yes">perspicuity</italic>, indicating that it is hard for developers to get familiar with the system. This is also the score with the largest difference between both packages.</p>
      <p><bold>Feedback:</bold> In free text, the participants stated that both Python packages are useful in general. For PALMS, the developers liked that the readme file is short. Although MaD GUI has a much larger readme file, the developers did not comment on this. Some participants felt MaD GUI’s documentation is well structured and has useful cross-references and helpful working examples, others found the documentation partly confusing. It was noted that there were spelling errors in MaD GUI’s documentation. For PALMS, developers also noted that the documentation was partly confusing. Furthermore, they stated that it could be improved in terms of method docstrings and information about partitions or annotations in general. Several users had issues installing an open-source algorithm and PALMS in the same Python environment due to the strict dependency management of both packages. Additionally, developers disliked that they received error messages, which were not meaningful to them.</p>
    </sec>
    <sec id="sec3dot3-sensors-22-05849">
      <title>3.3. User Interface Study</title>
      <p>This section follows the same outline as the previous section. First, the time needed to fulfill the tasks is described. Then, we show the results of the questionnaires. The last part describes the written feedback from the participants.</p>
      <p><bold>Time:</bold> The median time to load data and annotate them was below two minutes for MaD GUI and below five minutes for PALMS, as shown in <xref rid="sensors-22-05849-f004" ref-type="fig">Figure 4</xref>. Most participants needed longer for PALMS since they had difficulties finding the documentation for generating annotations in the provided videos. For the second task, using an algorithm for annotations, one participant stated that she did not find the necessary information for PALMS after seven minutes. The participant was then given the hint to watch the video. However, once participants knew how to interact with the annotations, they were nearly as fast as using MaD GUI.</p>
      <p><bold>Questionnaires:</bold> The median score for the SUS was 85.0 for MaD GUI and 62.5 for PALMS. With these results, MaD GUI is in the second and PALMS in the first quartile according to an empirical study by Bangor et al. [<xref rid="B65-sensors-22-05849" ref-type="bibr">65</xref>]. This suggests higher usability of MaD GUI’s interface than PALMS interface. The difference between both packages’ scores is much smaller than in the adaptability study. However, PALMS is below the average score for GUIs of 75 [<xref rid="B65-sensors-22-05849" ref-type="bibr">65</xref>].</p>
      <p>Results from the user experience questionnaire are shown in <xref rid="sensors-22-05849-t004" ref-type="table">Table 4</xref>. For both packages, the lowest value was <italic toggle="yes">novelty</italic>, indicating that the design of the user interface does not catch users’ interest to a high degree. A large difference of more than two points is evident regarding <italic toggle="yes">perspicuity</italic>. Consistent with the task completion time, this suggests that it is easier to get familiar with MaD GUI than with the PALMS user interface.</p>
      <p><bold>Feedback:</bold> In free-text answers, the users stated that both GUIs offer a good overview of the data. For MaD GUI, it was also noted that it was easy to learn. As a drawback of MaD GUI, the participants mentioned that algorithms are not executed automatically upon loading data, but have to be selected manually by the user. Furthermore, one participant did not like that possible shortcuts were not shown within the GUI. For PALMS, the same user noted positively that shortcuts are shown in the GUI. However, others would rather have liked an overview of shortcuts in the form of a table as it is part of MaD GUI’s documentation. Another participant stated that the shortcuts of PALMS are not intuitive, while the mode buttons of MaD GUI are intuitively usable. For both packages, the participants stated that the documentation was confusing. Opinions about color scheme and contrast differed: some users preferred PALMS and others MaD GUI. In summary, controversial feedback was given with personal preferences for one version or another.</p>
    </sec>
  </sec>
  <sec sec-type="discussion" id="sec4-sensors-22-05849">
    <title>4. Discussion and Limitations</title>
    <p>In this small-scale study, we compared MaD GUI to PALMS as representative of the state-of-the-art. We used both objective and subjective measures and found the novel MaD GUI to perform superior in the given context. In no way should our discussion be considered a direct criticism of the PALMS GUI, and we encourage authors to consider PALMS as an alternative to our package, especially when using PPG or ECG data.</p>
    <p>This study comprises a small sample size. However, according to Virzi [<xref rid="B66-sensors-22-05849" ref-type="bibr">66</xref>], as few as five participants are sufficient to find 80% of issues. Therefore, we suggest that our study is useful to rule out the fundamental shortcomings of the MaD GUI package.</p>
    <p>Our study showed that the MaD GUI package is easier to use than the state-of-the-art regarding adaptability by developers. MaD GUI has a lower code complexity, indicating that it is easier to maintain and extend. Additionally, the number of comments is higher for MaD GUI than for PALMS. This is backed up by the fact that developers suggested improving PALMS’ method docstrings, whereas no developer suggested this for MaD GUI.</p>
    <p>The task completion time was lower for MaD GUI for all tasks in the adaptability study. However, the increased time needed to start PALMS results from the fact that it depends on <italic toggle="yes">pywin32</italic> and, as such, only users of Unix-based operating systems experienced this issue. If this would be fixed, the difference in task completion time would decrease and new developers might need the same time to start MaD GUI and PALMS. However, the more relevant task completion times are those of loading data and implementing an algorithm, since those tasks take the longest to complete. Here, MaD GUI outperforms PALMS. For the task of implementing an algorithm, this is mostly attributed to the quality of documentation, as became apparent from the developers’ feedback. The objective results are further supported by subjective feedback in terms of questionnaires and open feedback. Concluding, the results indicate the superior performance of MaD GUI in this study setting.</p>
    <p>Regarding the user interface study, the task completion time for both tasks was smaller for MaD GUI than for PALMS. However, the differences were small, which is, among others, attributed to the short absolute amount of time needed to fulfill the tasks. The results indicate that users need a shorter time to understand the working principle of MaD compared to PALMS. However, for the second task, there was a difference of less than a minute compared to MaD GUI, suggesting that after initially understanding the GUI, domain experts can apply algorithms in an equal amount of time using MaD GUI or PALMS. The subjective feedback in terms of SUS and UEQ also indicates the superior performance of MaD GUI. However, these subjective differences are small considering the free-text answers.</p>
    <p>Since our implementation was based on guidelines from the literature and the limitations of existing packages, it is expectable that MaD GUI outperforms the state-of-the-art. However, in contrast to other publications, we are the first to conduct an evaluation of the package in a study, which can serve as a guideline for developers of other tools.</p>
    <p>A limitation of this study is that MaD GUI’s documentation was created by the authors of this study. As a result, the authors may have had a special focus on the parts of the documentation that were necessary to conduct the study. This will only become evident if the MaD GUI package is going to be used by more developers.</p>
    <p>Furthermore, we did not consider the time developers needed to set up their programming environment, e.g., installing dependencies. We argue that this highly depends on the way project dependencies are handled and on the experience of the developers. Furthermore, changing the way of handling project dependencies can be resolved fairly quickly and, therefore, should not be a major point of concern.</p>
    <p>For the user interface study, a reason for the difference in task completion time between MaD GUI and PALMS was that users were not able to find the necessary information in PALMS’ documentation quickly. However, this could be solved in a real-life scenario by the developer explaining the respective GUI or documentation to the potential user. Nonetheless, we decided not to give study participants an oral introduction in order not to bias them in any direction.</p>
    <p>Participants of the adaptability study were mostly from the same lab as the authors of MaD GUI. Therefore, they may share similar coding styles, which may have influenced the results in favor of MaD GUI. However, only two of the study participants had been working with the authors of MaD GUI before, and considering, this they were assigned to the PALMS GUI. Additionally, we included two external participants from Universidade do Vale do Rio dos Sinos (Brazil) and Newcastle University (United Kingdom) in the adaptability study to mitigate this issue.</p>
    <p>One clinician noted that she had difficulties finding certain information in MaD GUI’s documentation. However, this could be avoided by separating the documentation for the user interface and for developing plugins from each other. One option is to separate the documentation for the user interface from the GitHub main project page, for example to GitHub pages.</p>
    <p>Future developments may improve usability and user experience even further, for example by adding information about shortcuts to the user interface. Similarly, displaying tooltips more prominently might reduce the need for users to search for relevant information in MaD GUI’s documentation. In the current implementation, tooltips are shown only when the mouse is not moving for several seconds. The explorative behavior of users continuously moving the mouse might prevent the tooltips from being shown in the current implementation. Although not tested in this study, at the time of writing, issues are known regarding the synchronization of video and sensor data, which does not work for certain types of videos. However, a fix is known and being implemented, as can be seen in the GitHub issue tracking of MaD GUI.</p>
  </sec>
  <sec sec-type="conclusions" id="sec5-sensors-22-05849">
    <title>5. Conclusions</title>
    <p>We created and analyzed a Python package, MaD GUI, for the development of GUIs for time-series analysis. MaD GUI is open-source and, thus, can, in the future, be used and extended by other developers for different domains or clinical use cases. In a study, we showed that MaD GUI’s plugin architecture allows easy adaptation to other data formats and algorithms. Furthermore, MaD GUI is usable for domain experts outside of computer science, e.g., clinical researchers, for annotating time-series data or applying algorithms.</p>
    <p>The plugin-based architecture of the package allows it to be used in various contexts and enables easy implementation of (open-source) Python algorithms. In comparison to a recently published package for a similar purpose, MaD GUI enabled both developers, as well as domain experts to fulfill their tasks more rapidly, saving up to 75% of the time. Furthermore, they were more content with the documentation and effort needed to execute the tasks. Our approach shows that considering generic guidelines for the development of user interfaces, as well as the opinions of domain experts drastically increases the package’s quality. On the one hand, we hope that this encourages researchers creating algorithms or GUIs to follow some of these and related principles to increase the reusability and quality of their research. On the other hand, MaD GUI should serve as a package for the community to ease the creation of GUIs for time-series analysis and, therefore, to be able to focus on their actual research topics. The conducted study suggests that MaD GUI performs well concerning adaptability and usability in terms of the tested aspects.</p>
  </sec>
</body>
<back>
  <ack>
    <title>Acknowledgments</title>
    <p>We acknowledge financial support by Deutsche Forschungsgemeinschaft and Friedrich-Alexander-Universität Erlangen-Nürnberg within the funding program “Open Access Publication Funding”. Bjoern Eskofier gratefully acknowledges the support of the German Research Foundation (DFG) within the framework of the Heisenberg professorship program (Grant Number ES 434/8-1).</p>
  </ack>
  <fn-group>
    <fn>
      <p><bold>Publisher’s Note:</bold> MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <app-group>
    <app id="app1-sensors-22-05849">
      <title>Supplementary Materials</title>
      <p>Source code: <uri xlink:href="https://github.com/mad-lab-fau/mad-gui">https://github.com/mad-lab-fau/mad-gui</uri>; package documentation: <uri xlink:href="https://mad-gui.readthedocs.io/en/latest/README.html">https://mad-gui.readthedocs.io/en/latest/README.html</uri>; videos: <uri xlink:href="https://www.youtube.com/watch?v=cSFFSTUM4e0&amp;list=PLf4GpKhBjGcswKIkNeahNt5nDxt8oXPue">https://www.youtube.com/watch?v=cSFFSTUM4e0&amp;list=PLf4GpKhBjGcswKIkNeahNt5nDxt8oXPue</uri>.</p>
    </app>
  </app-group>
  <notes>
    <title>Author Contributions</title>
    <p>Conceptualization, M.O. and A.K.; methodology, M.O., W.M., A.K., H.G. and F.K.; software, M.O., A.-K.S. and A.K.; data curation, M.O.; formal analysis, M.O., A.K., W.M., A.-K.S., J.W., H.G., F.K. and B.M.E.; writing—original draft preparation, M.O.; writing—review and editing, M.O., A.K., W.M., A.-K.S., J.W., H.G., F.K. and B.M.E.; funding acquisition, H.G., J.W., F.K. and B.M.E.; supervision, B.M.E. All authors have read and agreed to the published version of the manuscript.</p>
  </notes>
  <notes>
    <title>Institutional Review Board Statement</title>
    <p>This study was exempt from an ethics review by the Ethics Committee of the University Hospital Erlangen, Germany.</p>
  </notes>
  <notes>
    <title>Informed Consent Statement</title>
    <p>This study was exempt from the need to obtain ethical approval by the local Ethics Committee. Nonetheless, all participants gave informed consent before they were included in the study.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Data Availability Statement</title>
    <p>Study data will be made accessible upon reasonable request to the corresponding author.</p>
  </notes>
  <notes notes-type="COI-statement">
    <title>Conflicts of Interest</title>
    <p>The authors declare no conflict of interest with respect to this manuscript.</p>
  </notes>
  <glossary>
    <title>Abbreviations</title>
    <p>The following abbreviations are used in this manuscript:
<array><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">ECG</td><td align="left" valign="middle" rowspan="1" colspan="1">Electrocardiogram</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">GUI</td><td align="left" valign="middle" rowspan="1" colspan="1">Graphical user interface</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">IMU</td><td align="left" valign="middle" rowspan="1" colspan="1">Inertial measurement unit</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">MaD</td><td align="left" valign="middle" rowspan="1" colspan="1">Machine Learning and Data Analytics</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">PALMS</td><td align="left" valign="middle" rowspan="1" colspan="1">Platform for Analysis and Labeling of Medical time-series</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">PPG</td><td align="left" valign="middle" rowspan="1" colspan="1">Photoplethysmogram</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">SUS</td><td align="left" valign="middle" rowspan="1" colspan="1">System Usability Scale</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">UEQ</td><td align="left" valign="middle" rowspan="1" colspan="1">User Experience Questionnaire</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">WDK</td><td align="left" valign="middle" rowspan="1" colspan="1">Wearables Development Toolkit</td></tr></tbody></array></p>
  </glossary>
  <ref-list>
    <title>References</title>
    <ref id="B1-sensors-22-05849">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Varghese</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Artificial Intelligence in Medicine: Chances and Challenges for Wide Clinical Adoption</article-title>
        <source>Visc. Med.</source>
        <year>2020</year>
        <volume>36</volume>
        <fpage>443</fpage>
        <lpage>449</lpage>
        <pub-id pub-id-type="doi">10.1159/000511930</pub-id>
        <?supplied-pmid 33442551?>
        <pub-id pub-id-type="pmid">33442551</pub-id>
      </element-citation>
    </ref>
    <ref id="B2-sensors-22-05849">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Qayyum</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Qadir</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Bilal</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Al-Fuqaha</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Secure and Robust Machine Learning for Healthcare: A Survey</article-title>
        <source>IEEE Rev. Biomed. Eng.</source>
        <year>2021</year>
        <volume>14</volume>
        <fpage>156</fpage>
        <lpage>180</lpage>
        <pub-id pub-id-type="doi">10.1109/RBME.2020.3013489</pub-id>
        <?supplied-pmid 32746371?>
        <pub-id pub-id-type="pmid">32746371</pub-id>
      </element-citation>
    </ref>
    <ref id="B3-sensors-22-05849">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mueller</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Kinoshita</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Peebles</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Graber</surname>
            <given-names>M.A.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Artificial intelligence and machine learning in emergency medicine: A narrative review</article-title>
        <source>Acute Med. Surg.</source>
        <year>2022</year>
        <volume>9</volume>
        <fpage>e740</fpage>
        <pub-id pub-id-type="doi">10.1002/ams2.740</pub-id>
        <?supplied-pmid 35251669?>
        <pub-id pub-id-type="pmid">35251669</pub-id>
      </element-citation>
    </ref>
    <ref id="B4-sensors-22-05849">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baig</surname>
            <given-names>M.M.</given-names>
          </name>
          <name>
            <surname>GholamHosseini</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Moqeem</surname>
            <given-names>A.A.</given-names>
          </name>
          <name>
            <surname>Mirza</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Lindén</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>A Systematic Review of Wearable Patient Monitoring Systems—Current Challenges and Opportunities for Clinical Adoption</article-title>
        <source>J. Med. Syst.</source>
        <year>2017</year>
        <volume>41</volume>
        <fpage>115</fpage>
        <pub-id pub-id-type="doi">10.1007/s10916-017-0760-1</pub-id>
        <?supplied-pmid 28631139?>
        <pub-id pub-id-type="pmid">28631139</pub-id>
      </element-citation>
    </ref>
    <ref id="B5-sensors-22-05849">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Khera</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>N.</given-names>
          </name>
        </person-group>
        <article-title>Role of machine learning in gait analysis: A review</article-title>
        <source>J. Med. Eng. Technol.</source>
        <year>2020</year>
        <volume>44</volume>
        <fpage>441</fpage>
        <lpage>467</lpage>
        <pub-id pub-id-type="doi">10.1080/03091902.2020.1822940</pub-id>
        <pub-id pub-id-type="pmid">33078988</pub-id>
      </element-citation>
    </ref>
    <ref id="B6-sensors-22-05849">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jakobsen</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Garcia-Ceja</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Riegler</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Stabell</surname>
            <given-names>L.A.</given-names>
          </name>
          <name>
            <surname>Nordgreen</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Torresen</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Fasmer</surname>
            <given-names>O.B.</given-names>
          </name>
          <name>
            <surname>Oedegaard</surname>
            <given-names>K.J.</given-names>
          </name>
        </person-group>
        <article-title>Applying machine learning in motor activity time series of depressed bipolar and unipolar patients compared to healthy controls</article-title>
        <source>PLoS ONE</source>
        <year>2020</year>
        <volume>15</volume>
        <elocation-id>e0231995</elocation-id>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0231995</pub-id>
        <pub-id pub-id-type="pmid">32833958</pub-id>
      </element-citation>
    </ref>
    <ref id="B7-sensors-22-05849">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Soriano-Valdez</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Pelaez-Ballestas</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Manrique de Lara</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Gastelum-Strozzi</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>The basics of data, big data, and machine learning in clinical practice</article-title>
        <source>Clin. Rheumatol.</source>
        <year>2021</year>
        <volume>40</volume>
        <fpage>11</fpage>
        <lpage>23</lpage>
        <pub-id pub-id-type="doi">10.1007/s10067-020-05196-z</pub-id>
        <pub-id pub-id-type="pmid">32504192</pub-id>
      </element-citation>
    </ref>
    <ref id="B8-sensors-22-05849">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ullrich</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Mucke</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Kuderle</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Roth</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Gladow</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Gabner</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Marxreiter</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Klucken</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Eskofier</surname>
            <given-names>B.M.</given-names>
          </name>
          <name>
            <surname>Kluge</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>Detection of Unsupervised Standardized Gait Tests From Real-World Inertial Sensor Data in Parkinson’s Disease</article-title>
        <source>IEEE Trans. Neural Syst. Rehabil. Eng.</source>
        <year>2021</year>
        <volume>29</volume>
        <fpage>2103</fpage>
        <lpage>2111</lpage>
        <pub-id pub-id-type="doi">10.1109/TNSRE.2021.3119390</pub-id>
        <pub-id pub-id-type="pmid">34633932</pub-id>
      </element-citation>
    </ref>
    <ref id="B9-sensors-22-05849">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Ahmed</surname>
            <given-names>J.B.</given-names>
          </name>
          <name>
            <surname>Tan</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Gu</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Prediction of Freezing of Gait in Patients With Parkinson’s Disease by Identifying Impaired Gait Patterns</article-title>
        <source>IEEE Trans. Neural Syst. Rehabil. Eng.</source>
        <year>2020</year>
        <volume>28</volume>
        <fpage>591</fpage>
        <lpage>600</lpage>
        <pub-id pub-id-type="doi">10.1109/TNSRE.2020.2969649</pub-id>
        <pub-id pub-id-type="pmid">31995497</pub-id>
      </element-citation>
    </ref>
    <ref id="B10-sensors-22-05849">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fedjajevs</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Groenendaal</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Agell</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Hermeling</surname>
            <given-names>E.</given-names>
          </name>
        </person-group>
        <article-title>Platform for Analysis and Labeling of Medical Time Series</article-title>
        <source>Sensors</source>
        <year>2020</year>
        <volume>20</volume>
        <elocation-id>7302</elocation-id>
        <pub-id pub-id-type="doi">10.3390/s20247302</pub-id>
      </element-citation>
    </ref>
    <ref id="B11-sensors-22-05849">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Haladjian</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>The Wearables Development Toolkit: An Integrated Development Environment for Activity Recognition Applications</article-title>
        <source>Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.</source>
        <year>2019</year>
        <volume>3</volume>
        <fpage>1</fpage>
        <lpage>26</lpage>
        <pub-id pub-id-type="doi">10.1145/3369813</pub-id>
        <pub-id pub-id-type="pmid">34164595</pub-id>
      </element-citation>
    </ref>
    <ref id="B12-sensors-22-05849">
      <label>12.</label>
      <element-citation publication-type="webpage">
        <article-title>CrowdCurio Time Series Annotator Library</article-title>
        <year>2022</year>
        <comment>Available online: <ext-link xlink:href="https://github.com/CrowdCurio/time-series-annotator" ext-link-type="uri">https://github.com/CrowdCurio/time-series-annotator</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2021-12-27">(accessed on 27 December 2021)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B13-sensors-22-05849">
      <label>13.</label>
      <element-citation publication-type="webpage">
        <article-title>Curve</article-title>
        <year>2022</year>
        <comment>Available online: <ext-link xlink:href="https://github.com/baidu/Curve" ext-link-type="uri">https://github.com/baidu/Curve</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2021-12-27">(accessed on 27 December 2021)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B14-sensors-22-05849">
      <label>14.</label>
      <element-citation publication-type="webpage">
        <article-title>TagAnomaly</article-title>
        <year>2022</year>
        <comment>Available online: <ext-link xlink:href="https://github.com/Microsoft/TagAnomaly" ext-link-type="uri">https://github.com/Microsoft/TagAnomaly</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2021-12-27">(accessed on 27 December 2021)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B15-sensors-22-05849">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Espinosa</surname>
            <given-names>H.G.</given-names>
          </name>
          <name>
            <surname>James</surname>
            <given-names>D.A.</given-names>
          </name>
          <name>
            <surname>Kelly</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Wixted</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <article-title>Sports Monitoring Data and Video Interface Using a GUI Auto Generation Matlab Tool</article-title>
        <source>Procedia Eng.</source>
        <year>2013</year>
        <volume>60</volume>
        <fpage>243</fpage>
        <lpage>248</lpage>
        <pub-id pub-id-type="doi">10.1016/j.proeng.2013.07.047</pub-id>
      </element-citation>
    </ref>
    <ref id="B16-sensors-22-05849">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rowlands</surname>
            <given-names>D.D.</given-names>
          </name>
          <name>
            <surname>McCarthy</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>James</surname>
            <given-names>D.A.</given-names>
          </name>
        </person-group>
        <article-title>Using inertial sensors to index into video</article-title>
        <source>Procedia Eng.</source>
        <year>2012</year>
        <volume>34</volume>
        <fpage>598</fpage>
        <lpage>603</lpage>
        <pub-id pub-id-type="doi">10.1016/j.proeng.2012.04.102</pub-id>
      </element-citation>
    </ref>
    <ref id="B17-sensors-22-05849">
      <label>17.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Barz</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Moniri</surname>
            <given-names>M.M.</given-names>
          </name>
          <name>
            <surname>Weber</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Sonntag</surname>
            <given-names>D.</given-names>
          </name>
        </person-group>
        <article-title>Multimodal multisensor activity annotation tool</article-title>
        <source>Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct</source>
        <conf-loc>Heidelberg, Germany</conf-loc>
        <conf-date>12–16 September 2016</conf-date>
        <publisher-name>ACM</publisher-name>
        <publisher-loc>Heidelberg, Germany</publisher-loc>
        <year>2016</year>
        <fpage>17</fpage>
        <lpage>20</lpage>
        <pub-id pub-id-type="doi">10.1145/2968219.2971459</pub-id>
      </element-citation>
    </ref>
    <ref id="B18-sensors-22-05849">
      <label>18.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Martindale</surname>
            <given-names>C.F.</given-names>
          </name>
          <name>
            <surname>Roth</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Hannink</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Sprager</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Eskofier</surname>
            <given-names>B.M.</given-names>
          </name>
        </person-group>
        <article-title>Smart Annotation Tool for Multi-sensor Gait-based Daily Activity Data</article-title>
        <source>Proceedings of the 2018 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)</source>
        <conf-loc>Athens, Greece</conf-loc>
        <conf-date>19–23 March 2018</conf-date>
        <publisher-name>IEEE</publisher-name>
        <publisher-loc>Athens, Greece</publisher-loc>
        <year>2018</year>
        <fpage>549</fpage>
        <lpage>554</lpage>
        <pub-id pub-id-type="doi">10.1109/PERCOMW.2018.8480193</pub-id>
      </element-citation>
    </ref>
    <ref id="B19-sensors-22-05849">
      <label>19.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Ponnada</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Cooper</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Thapa-Chhetry</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>J.A.</given-names>
          </name>
          <name>
            <surname>John</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Intille</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Signaligner Pro: A Tool to Explore and Annotate Multi-day Raw Accelerometer Data</article-title>
        <source>Proceedings of the 2021 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)</source>
        <conf-loc>Kassel, Germany</conf-loc>
        <conf-date>22–26 March 2021</conf-date>
        <publisher-name>IEEE</publisher-name>
        <publisher-loc>Kassel, Germany</publisher-loc>
        <year>2021</year>
        <fpage>475</fpage>
        <lpage>480</lpage>
        <pub-id pub-id-type="doi">10.1109/PerComWorkshops51409.2021.9431110</pub-id>
      </element-citation>
    </ref>
    <ref id="B20-sensors-22-05849">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Espay</surname>
            <given-names>A.J.</given-names>
          </name>
          <name>
            <surname>Bonato</surname>
            <given-names>P.</given-names>
          </name>
          <name>
            <surname>Nahab</surname>
            <given-names>F.B.</given-names>
          </name>
          <name>
            <surname>Maetzler</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Dean</surname>
            <given-names>J.M.</given-names>
          </name>
          <name>
            <surname>Klucken</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Eskofier</surname>
            <given-names>B.M.</given-names>
          </name>
          <name>
            <surname>Merola</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Horak</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Lang</surname>
            <given-names>A.E.</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Technology in Parkinson’s disease: Challenges and opportunities: Technology in PD</article-title>
        <source>Mov. Disord.</source>
        <year>2016</year>
        <volume>31</volume>
        <fpage>1272</fpage>
        <lpage>1282</lpage>
        <pub-id pub-id-type="doi">10.1002/mds.26642</pub-id>
        <pub-id pub-id-type="pmid">27125836</pub-id>
      </element-citation>
    </ref>
    <ref id="B21-sensors-22-05849">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stodden</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>The Scientific Method in Practice: Reproducibility in the Computational Sciences</article-title>
        <source>SSRN Electron. J.</source>
        <year>2010</year>
        <volume>15</volume>
        <fpage>35</fpage>
        <lpage>52</lpage>
        <pub-id pub-id-type="doi">10.2139/ssrn.1550193</pub-id>
      </element-citation>
    </ref>
    <ref id="B22-sensors-22-05849">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Raschka</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Patterson</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Nolet</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Machine Learning in Python: Main Developments and Technology Trends in Data Science, Machine Learning, and Artificial Intelligence</article-title>
        <source>Information</source>
        <year>2020</year>
        <volume>11</volume>
        <elocation-id>193</elocation-id>
        <pub-id pub-id-type="doi">10.3390/info11040193</pub-id>
      </element-citation>
    </ref>
    <ref id="B23-sensors-22-05849">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Gao</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Mei</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Piccialli</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Cuomo</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Tu</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Huo</surname>
            <given-names>Z.</given-names>
          </name>
        </person-group>
        <article-title>Julia language in machine learning: Algorithms, applications, and open issues</article-title>
        <source>Comput. Sci. Rev.</source>
        <year>2020</year>
        <volume>37</volume>
        <fpage>100254</fpage>
        <pub-id pub-id-type="doi">10.1016/j.cosrev.2020.100254</pub-id>
      </element-citation>
    </ref>
    <ref id="B24-sensors-22-05849">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vyas</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Bhargava</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Bhola</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Ujjan</surname>
            <given-names>J.A.</given-names>
          </name>
          <name>
            <surname>Eswaran</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Rahmani</surname>
            <given-names>A.W.</given-names>
          </name>
        </person-group>
        <article-title>Critical Retrospection of Performance of Emerging Mobile Technologies in Health Data Management</article-title>
        <source>J. Healthc. Eng.</source>
        <year>2022</year>
        <volume>2022</volume>
        <fpage>8903604</fpage>
        <pub-id pub-id-type="doi">10.1155/2022/8903604</pub-id>
        <pub-id pub-id-type="pmid">35345655</pub-id>
      </element-citation>
    </ref>
    <ref id="B25-sensors-22-05849">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hofer</surname>
            <given-names>I.S.</given-names>
          </name>
          <name>
            <surname>Burns</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Kendale</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Wanderer</surname>
            <given-names>J.P.</given-names>
          </name>
        </person-group>
        <article-title>Realistically Integrating Machine Learning Into Clinical Practice: A Road Map of Opportunities, Challenges, and a Potential Future</article-title>
        <source>Anesth. Analg.</source>
        <year>2020</year>
        <volume>130</volume>
        <fpage>1115</fpage>
        <lpage>1118</lpage>
        <pub-id pub-id-type="doi">10.1213/ANE.0000000000004575</pub-id>
        <pub-id pub-id-type="pmid">32287118</pub-id>
      </element-citation>
    </ref>
    <ref id="B26-sensors-22-05849">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Routhier</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Duclos</surname>
            <given-names>N.C.</given-names>
          </name>
          <name>
            <surname>Lacroix</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Lettre</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Turcotte</surname>
            <given-names>E.</given-names>
          </name>
          <name>
            <surname>Hamel</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Michaud</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Duclos</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Archambault</surname>
            <given-names>P.S.</given-names>
          </name>
          <name>
            <surname>Bouyer</surname>
            <given-names>L.J.</given-names>
          </name>
        </person-group>
        <article-title>Clinicians’ perspectives on inertial measurement units in clinical practice</article-title>
        <source>PLoS ONE</source>
        <year>2020</year>
        <volume>15</volume>
        <elocation-id>e0241922</elocation-id>
        <pub-id pub-id-type="doi">10.1371/journal.pone.0241922</pub-id>
        <pub-id pub-id-type="pmid">33186363</pub-id>
      </element-citation>
    </ref>
    <ref id="B27-sensors-22-05849">
      <label>27.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Fogel</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <source>Producing Open Source Software: How to Run a Successful Free Software Project</source>
        <publisher-name>O’Reilly Media, Inc.</publisher-name>
        <publisher-loc>Sebastopol, CA, USA</publisher-loc>
        <year>2009</year>
      </element-citation>
    </ref>
    <ref id="B28-sensors-22-05849">
      <label>28.</label>
      <element-citation publication-type="webpage">
        <article-title>PyQtGraph</article-title>
        <year>2022</year>
        <comment>Available online: <ext-link xlink:href="https://www.pyqtgraph.org" ext-link-type="uri">https://www.pyqtgraph.org</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2022-02-02">(accessed on 2 February 2022)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B29-sensors-22-05849">
      <label>29.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Anaya</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <source>Clean Code in Python Develop Maintainable and Efficient Code</source>
        <edition>2nd ed.</edition>
        <publisher-name>Packt Publishing, Limited</publisher-name>
        <publisher-loc>Birmingham, UK</publisher-loc>
        <year>2021</year>
      </element-citation>
    </ref>
    <ref id="B30-sensors-22-05849">
      <label>30.</label>
      <element-citation publication-type="webpage">
        <article-title>black</article-title>
        <year>2022</year>
        <comment>Available online: <ext-link xlink:href="https://github.com/psf/black" ext-link-type="uri">https://github.com/psf/black</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2022-01-01">(accessed on 1 January 2022)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B31-sensors-22-05849">
      <label>31.</label>
      <element-citation publication-type="webpage">
        <article-title>PEP 8</article-title>
        <year>2022</year>
        <comment>Available online: <ext-link xlink:href="https://www.python.org/dev/peps/pep-0008/" ext-link-type="uri">https://www.python.org/dev/peps/pep-0008/</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2022-01-02">(accessed on 2 January 2022)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B32-sensors-22-05849">
      <label>32.</label>
      <element-citation publication-type="webpage">
        <article-title>pylint</article-title>
        <year>2022</year>
        <comment>Available online: <ext-link xlink:href="https://pylint.org" ext-link-type="uri">https://pylint.org</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2022-01-02">(accessed on 2 January 2022)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B33-sensors-22-05849">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>LeVeque</surname>
            <given-names>R.J.</given-names>
          </name>
          <name>
            <surname>Mitchell</surname>
            <given-names>I.M.</given-names>
          </name>
          <name>
            <surname>Stodden</surname>
            <given-names>V.</given-names>
          </name>
        </person-group>
        <article-title>Reproducible research for scientific computing: Tools and strategies for changing the culture</article-title>
        <source>Comput. Sci. Eng.</source>
        <year>2012</year>
        <volume>14</volume>
        <fpage>13</fpage>
        <lpage>17</lpage>
        <pub-id pub-id-type="doi">10.1109/MCSE.2012.38</pub-id>
      </element-citation>
    </ref>
    <ref id="B34-sensors-22-05849">
      <label>34.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Sweigart</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <source>Beyond the Basic Stuff with Python: Best Practices for Writing Clean Code</source>
        <publisher-name>No Starch Press</publisher-name>
        <publisher-loc>San Francisco, CA, USA</publisher-loc>
        <year>2021</year>
      </element-citation>
    </ref>
    <ref id="B35-sensors-22-05849">
      <label>35.</label>
      <element-citation publication-type="webpage">
        <person-group person-group-type="author">
          <name>
            <surname>Ollenschläger</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Küderle</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Seifer</surname>
            <given-names>A.K.</given-names>
          </name>
        </person-group>
        <article-title>MaD GUI Docs</article-title>
        <year>2022</year>
        <comment>Available online: <ext-link xlink:href="https://mad-gui.readthedocs.io/en/latest/index.html" ext-link-type="uri">https://mad-gui.readthedocs.io/en/latest/index.html</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2022-02-02">(accessed on 2 February 2022)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B36-sensors-22-05849">
      <label>36.</label>
      <element-citation publication-type="webpage">
        <article-title>pandas</article-title>
        <year>2022</year>
        <comment>Available online: <ext-link xlink:href="https://pandas.pydata.org" ext-link-type="uri">https://pandas.pydata.org</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2022-01-03">(accessed on 3 January 2022)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B37-sensors-22-05849">
      <label>37.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Viafore</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <source>Robust Python</source>
        <publisher-name>O’Reilly Media, Incorporated</publisher-name>
        <publisher-loc>Sebastopol, CA, USA</publisher-loc>
        <year>2021</year>
      </element-citation>
    </ref>
    <ref id="B38-sensors-22-05849">
      <label>38.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Shneiderman</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Plaisant</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Cohen</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Jacobs</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Elmqvist</surname>
            <given-names>N.</given-names>
          </name>
        </person-group>
        <source>Designing the User Interface: Strategies for Effective Human-Computer Interaction</source>
        <edition>6th ed.</edition>
        <publisher-name>Pearson</publisher-name>
        <publisher-loc>Boston, MA, USA</publisher-loc>
        <year>2017</year>
      </element-citation>
    </ref>
    <ref id="B39-sensors-22-05849">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wertheimer</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Untersuchungen zur Lehre von der Gestalt</article-title>
        <source>Z. Psychol. Ihre Grenzwissenschaften</source>
        <year>1923</year>
        <volume>1</volume>
        <fpage>47</fpage>
        <lpage>58</lpage>
        <pub-id pub-id-type="doi">10.1007/BF00410640</pub-id>
      </element-citation>
    </ref>
    <ref id="B40-sensors-22-05849">
      <label>40.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Johnson</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <source>Designing with the Mind in Mind: Simple Guide to Understanding User Interface Design Rules</source>
        <publisher-name>Morgan Kaufmann Publishers</publisher-name>
        <publisher-loc>Boston, MA, USA</publisher-loc>
        <publisher-name>Elsevier</publisher-name>
        <publisher-loc>Amsterdam, The Netherlands</publisher-loc>
        <year>2010</year>
      </element-citation>
    </ref>
    <ref id="B41-sensors-22-05849">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fitts</surname>
            <given-names>P.M.</given-names>
          </name>
        </person-group>
        <article-title>The information capacity of the human motor system in controlling the amplitude of movement</article-title>
        <source>J. Exp. Psychol.</source>
        <year>1954</year>
        <volume>47</volume>
        <fpage>381</fpage>
        <lpage>391</lpage>
        <pub-id pub-id-type="doi">10.1037/h0055392</pub-id>
        <?supplied-pmid 13174710?>
        <pub-id pub-id-type="pmid">13174710</pub-id>
      </element-citation>
    </ref>
    <ref id="B42-sensors-22-05849">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>MacKenzie</surname>
            <given-names>I.S.</given-names>
          </name>
        </person-group>
        <article-title>Fitts’ Law as a Research and Design Tool in Human-Computer Interaction</article-title>
        <source>Hum. Comput. Interact.</source>
        <year>1992</year>
        <volume>7</volume>
        <fpage>91</fpage>
        <lpage>139</lpage>
        <pub-id pub-id-type="doi">10.1207/s15327051hci0701_3</pub-id>
      </element-citation>
    </ref>
    <ref id="B43-sensors-22-05849">
      <label>43.</label>
      <element-citation publication-type="webpage">
        <person-group person-group-type="author">
          <name>
            <surname>Foundation</surname>
            <given-names>P.S.</given-names>
          </name>
        </person-group>
        <article-title>Python Pickle</article-title>
        <year>2022</year>
        <comment>Available online: <ext-link xlink:href="https://docs.python.org/3/library/pickle.html" ext-link-type="uri">https://docs.python.org/3/library/pickle.html</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2022-02-02">(accessed on 2 February 2022)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B44-sensors-22-05849">
      <label>44.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Lach</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Lo</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>G.Z.</given-names>
          </name>
        </person-group>
        <article-title>Toward Pervasive Gait Analysis with Wearable Sensors: A Systematic Review</article-title>
        <source>IEEE J. Biomed. Health Inform.</source>
        <year>2016</year>
        <volume>20</volume>
        <fpage>1521</fpage>
        <lpage>1537</lpage>
        <pub-id pub-id-type="doi">10.1109/JBHI.2016.2608720</pub-id>
        <pub-id pub-id-type="pmid">28113185</pub-id>
      </element-citation>
    </ref>
    <ref id="B45-sensors-22-05849">
      <label>45.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Krasner</surname>
            <given-names>G.E.</given-names>
          </name>
          <name>
            <surname>Pope</surname>
            <given-names>S.T.</given-names>
          </name>
        </person-group>
        <article-title>A Description of the Model-View-Controller User Interface Paradigm in the Smalltalk-80 System</article-title>
        <source>J. Object Oriented Program.</source>
        <year>1988</year>
        <volume>1</volume>
        <fpage>26</fpage>
        <lpage>49</lpage>
      </element-citation>
    </ref>
    <ref id="B46-sensors-22-05849">
      <label>46.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Moore</surname>
            <given-names>A.D.</given-names>
          </name>
        </person-group>
        <source>Mastering GUI Programming with Python: Develop Impressive Cross-Platform GUI Applications with PyQt</source>
        <publisher-name>Packt Publishing Ltd.</publisher-name>
        <publisher-loc>Birmingham, UK</publisher-loc>
        <year>2019</year>
      </element-citation>
    </ref>
    <ref id="B47-sensors-22-05849">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>McCabe</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>A Complexity Measure</article-title>
        <source>IEEE Trans. Softw. Eng.</source>
        <year>1976</year>
        <volume>SE-2</volume>
        <fpage>308</fpage>
        <lpage>320</lpage>
        <pub-id pub-id-type="doi">10.1109/TSE.1976.233837</pub-id>
      </element-citation>
    </ref>
    <ref id="B48-sensors-22-05849">
      <label>48.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Stahl</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Martini</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Martensson</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <article-title>Big Bangs and Small Pops: On Critical Cyclomatic Complexity and Developer Integration Behavior</article-title>
        <source>Proceedings of the 2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)</source>
        <conf-loc>Montreal, QC, Canada</conf-loc>
        <conf-date>25–31 May 2019</conf-date>
        <publisher-name>IEEE</publisher-name>
        <publisher-loc>Montreal, QC, Canada</publisher-loc>
        <year>2019</year>
        <fpage>81</fpage>
        <lpage>90</lpage>
        <pub-id pub-id-type="doi">10.1109/ICSE-SEIP.2019.00017</pub-id>
      </element-citation>
    </ref>
    <ref id="B49-sensors-22-05849">
      <label>49.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stetter</surname>
            <given-names>F.</given-names>
          </name>
        </person-group>
        <article-title>A measure of program complexity</article-title>
        <source>Comput. Lang.</source>
        <year>1984</year>
        <volume>9</volume>
        <fpage>203</fpage>
        <lpage>208</lpage>
        <pub-id pub-id-type="doi">10.1016/0096-0551(84)90006-7</pub-id>
      </element-citation>
    </ref>
    <ref id="B50-sensors-22-05849">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wijendra</surname>
            <given-names>D.R.</given-names>
          </name>
          <name>
            <surname>Hewagamage</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Analysis of Cognitive Complexity with Cyclomatic Complexity Metric of Software</article-title>
        <source>Int. J. Comput. Appl.</source>
        <year>2021</year>
        <volume>174</volume>
        <fpage>14</fpage>
        <lpage>19</lpage>
        <pub-id pub-id-type="doi">10.5120/ijca2021921066</pub-id>
      </element-citation>
    </ref>
    <ref id="B51-sensors-22-05849">
      <label>51.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kushwaha</surname>
            <given-names>D.S.</given-names>
          </name>
          <name>
            <surname>Misra</surname>
            <given-names>A.K.</given-names>
          </name>
        </person-group>
        <article-title>A modified cognitive information complexity measure of software</article-title>
        <source>ACM SIGSOFT Softw. Eng. Notes</source>
        <year>2006</year>
        <volume>31</volume>
        <fpage>1</fpage>
        <lpage>4</lpage>
        <pub-id pub-id-type="doi">10.1145/1108768.1108776</pub-id>
      </element-citation>
    </ref>
    <ref id="B52-sensors-22-05849">
      <label>52.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Chhabra</surname>
            <given-names>J.K.</given-names>
          </name>
        </person-group>
        <article-title>Code Cognitive Complexity: A New Measure</article-title>
        <source>Proceedings of the World Congress on Engineering</source>
        <conf-loc>London, UK</conf-loc>
        <conf-date>6–8 July 2011</conf-date>
        <publisher-name>International Association of Engineers</publisher-name>
        <publisher-loc>Hong Kong, China</publisher-loc>
        <year>2011</year>
      </element-citation>
    </ref>
    <ref id="B53-sensors-22-05849">
      <label>53.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Klemola</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Rilling</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>A cognitive complexity metric based on category learning</article-title>
        <source>Proceedings of the Second IEEE International Conference on Cognitive Informatics</source>
        <conf-loc>London, UK</conf-loc>
        <conf-date>20 August 2003</conf-date>
        <publisher-name>IEEE Computer Society</publisher-name>
        <publisher-loc>London, UK</publisher-loc>
        <year>2003</year>
        <fpage>106</fpage>
        <lpage>112</lpage>
        <pub-id pub-id-type="doi">10.1109/COGINF.2003.1225966</pub-id>
      </element-citation>
    </ref>
    <ref id="B54-sensors-22-05849">
      <label>54.</label>
      <element-citation publication-type="confproc">
        <person-group person-group-type="author">
          <name>
            <surname>Campbell</surname>
            <given-names>G.A.</given-names>
          </name>
        </person-group>
        <article-title>Cognitive complexity: An overview and evaluation</article-title>
        <source>Proceedings of the Proceedings of the 2018 International Conference on Technical Debt</source>
        <conf-loc>Gothenburg, Sweden</conf-loc>
        <conf-date>27–28 May 2018</conf-date>
        <publisher-name>ACM</publisher-name>
        <publisher-loc>Gothenburg, Sweden</publisher-loc>
        <year>2018</year>
        <fpage>57</fpage>
        <lpage>58</lpage>
        <pub-id pub-id-type="doi">10.1145/3194164.3194186</pub-id>
      </element-citation>
    </ref>
    <ref id="B55-sensors-22-05849">
      <label>55.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Campbell</surname>
            <given-names>G.A.</given-names>
          </name>
        </person-group>
        <source>Cognitive Complexity</source>
        <publisher-name>SonarSource</publisher-name>
        <publisher-loc>Geneva, Switzerland</publisher-loc>
        <year>2020</year>
      </element-citation>
    </ref>
    <ref id="B56-sensors-22-05849">
      <label>56.</label>
      <element-citation publication-type="webpage">
        <person-group person-group-type="author">
          <name>
            <surname>Lebedev</surname>
            <given-names>I.</given-names>
          </name>
          <name>
            <surname>Wienke</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>King</surname>
            <given-names>K.</given-names>
          </name>
        </person-group>
        <article-title>Flake8: Cognitive Complexity</article-title>
        <year>2022</year>
        <comment>Available online: <ext-link xlink:href="https://github.com/Melevir/flake8-cognitive-complexity" ext-link-type="uri">https://github.com/Melevir/flake8-cognitive-complexity</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2022-02-02">(accessed on 2 February 2022)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B57-sensors-22-05849">
      <label>57.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Siegmund</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Kästner</surname>
            <given-names>C.</given-names>
          </name>
          <name>
            <surname>Liebig</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Apel</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Hanenberg</surname>
            <given-names>S.</given-names>
          </name>
        </person-group>
        <article-title>Measuring and modeling programming experience</article-title>
        <source>Empir. Softw. Eng.</source>
        <year>2014</year>
        <volume>19</volume>
        <fpage>1299</fpage>
        <lpage>1334</lpage>
        <pub-id pub-id-type="doi">10.1007/s10664-013-9286-4</pub-id>
      </element-citation>
    </ref>
    <ref id="B58-sensors-22-05849">
      <label>58.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Weiss</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Brozgol</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Dorfman</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Herman</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Shema</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Giladi</surname>
            <given-names>N.</given-names>
          </name>
          <name>
            <surname>Hausdorff</surname>
            <given-names>J.M.</given-names>
          </name>
        </person-group>
        <article-title>Does the Evaluation of Gait Quality During Daily Life Provide Insight Into Fall Risk? A Novel Approach Using 3-Day Accelerometer Recordings</article-title>
        <source>Neurorehabilit. Neural Repair</source>
        <year>2013</year>
        <volume>27</volume>
        <fpage>742</fpage>
        <lpage>752</lpage>
        <pub-id pub-id-type="doi">10.1177/1545968313491004</pub-id>
        <?supplied-pmid 23774124?>
        <pub-id pub-id-type="pmid">23774124</pub-id>
      </element-citation>
    </ref>
    <ref id="B59-sensors-22-05849">
      <label>59.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Goldberger</surname>
            <given-names>A.L.</given-names>
          </name>
          <name>
            <surname>Amaral</surname>
            <given-names>L.A.N.</given-names>
          </name>
          <name>
            <surname>Glass</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Hausdorff</surname>
            <given-names>J.M.</given-names>
          </name>
          <name>
            <surname>Ivanov</surname>
            <given-names>P.C.</given-names>
          </name>
          <name>
            <surname>Mark</surname>
            <given-names>R.G.</given-names>
          </name>
          <name>
            <surname>Mietus</surname>
            <given-names>J.E.</given-names>
          </name>
          <name>
            <surname>Moody</surname>
            <given-names>G.B.</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>C.K.</given-names>
          </name>
          <name>
            <surname>Stanley</surname>
            <given-names>H.E.</given-names>
          </name>
        </person-group>
        <article-title>PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals</article-title>
        <source>Circulation</source>
        <year>2000</year>
        <volume>101</volume>
        <fpage>e215</fpage>
        <lpage>e220</lpage>
        <pub-id pub-id-type="doi">10.1161/01.CIR.101.23.e215</pub-id>
        <?supplied-pmid 10851218?>
        <pub-id pub-id-type="pmid">10851218</pub-id>
      </element-citation>
    </ref>
    <ref id="B60-sensors-22-05849">
      <label>60.</label>
      <element-citation publication-type="webpage">
        <article-title>Joans; PDkit Project; Stamate; Gkroussos. <italic toggle="yes">pdkit</italic></article-title>
        <year>2020</year>
        <comment>Available online: <ext-link xlink:href="https://zenodo.org/record/3632529/export/geojson#.Yusl9RxBxPY" ext-link-type="uri">https://zenodo.org/record/3632529/export/geojson#.Yusl9RxBxPY</ext-link></comment>
        <date-in-citation content-type="access-date" iso-8601-date="2022-02-02">(accessed on 2 February 2022)</date-in-citation>
      </element-citation>
    </ref>
    <ref id="B61-sensors-22-05849">
      <label>61.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Nuñez-Varela</surname>
            <given-names>A.S.</given-names>
          </name>
          <name>
            <surname>Pérez-Gonzalez</surname>
            <given-names>H.G.</given-names>
          </name>
          <name>
            <surname>Martínez-Perez</surname>
            <given-names>F.E.</given-names>
          </name>
          <name>
            <surname>Soubervielle-Montalvo</surname>
            <given-names>C.</given-names>
          </name>
        </person-group>
        <article-title>Source code metrics: A systematic mapping study</article-title>
        <source>J. Syst. Softw.</source>
        <year>2017</year>
        <volume>128</volume>
        <fpage>164</fpage>
        <lpage>197</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jss.2017.03.044</pub-id>
      </element-citation>
    </ref>
    <ref id="B62-sensors-22-05849">
      <label>62.</label>
      <element-citation publication-type="book">
        <article-title>SUS: A ‘Quck and Dirty’ Usability Scale</article-title>
        <source>Usability Evaluation in Industry</source>
        <edition>1st ed.</edition>
        <person-group person-group-type="editor">
          <name>
            <surname>Jordan</surname>
            <given-names>P.W.</given-names>
          </name>
          <name>
            <surname>Thomas</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>McClelland</surname>
            <given-names>I.L.</given-names>
          </name>
          <name>
            <surname>Weerdmeester</surname>
            <given-names>B.</given-names>
          </name>
        </person-group>
        <publisher-name>CRC Press</publisher-name>
        <publisher-loc>Boca Raton, FL, USA</publisher-loc>
        <year>1996</year>
        <pub-id pub-id-type="doi">10.1201/9781498710411</pub-id>
      </element-citation>
    </ref>
    <ref id="B63-sensors-22-05849">
      <label>63.</label>
      <element-citation publication-type="book">
        <article-title>Konstruktion eines Fragebogens zur Messung der User Experience von Softwareprodukten</article-title>
        <source>Mensch und Computer 2006: Mensch und Computer im StrukturWandel</source>
        <person-group person-group-type="editor">
          <name>
            <surname>Heinecke</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Paul</surname>
            <given-names>H.</given-names>
          </name>
        </person-group>
        <publisher-name>Oldenbourg Wissenschaftsverlag</publisher-name>
        <publisher-loc>Munich, Germany</publisher-loc>
        <year>2006</year>
        <pub-id pub-id-type="doi">10.1524/9783486841749</pub-id>
      </element-citation>
    </ref>
    <ref id="B64-sensors-22-05849">
      <label>64.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wagner</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Wyrich</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Code Comprehension Confounders: A Study of Intelligence and Personality</article-title>
        <source>IEEE Trans. Softw. Eng.</source>
        <year>2021</year>
        <fpage>1</fpage>
        <pub-id pub-id-type="doi">10.1109/TSE.2021.3127131</pub-id>
      </element-citation>
    </ref>
    <ref id="B65-sensors-22-05849">
      <label>65.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bangor</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Kortum</surname>
            <given-names>P.T.</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>J.T.</given-names>
          </name>
        </person-group>
        <article-title>An Empirical Evaluation of the System Usability Scale</article-title>
        <source>Int. J. Hum.-Comput. Interact.</source>
        <year>2008</year>
        <volume>24</volume>
        <fpage>574</fpage>
        <lpage>594</lpage>
        <pub-id pub-id-type="doi">10.1080/10447310802205776</pub-id>
      </element-citation>
    </ref>
    <ref id="B66-sensors-22-05849">
      <label>66.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Virzi</surname>
            <given-names>R.A.</given-names>
          </name>
        </person-group>
        <article-title>Refining the Test Phase of Usability Evaluation: How Many Subjects Is Enough?</article-title>
        <source>Hum. Factors J. Hum. Factors Ergon. Soc.</source>
        <year>1992</year>
        <volume>34</volume>
        <fpage>457</fpage>
        <lpage>468</lpage>
        <pub-id pub-id-type="doi">10.1177/001872089203400407</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig position="float" id="sensors-22-05849-f001">
    <label>Figure 1</label>
    <caption>
      <p>Main window of MaD GUI. The side-bar (left) gives access to plugins, which can be injected into the GUI. The buttons on the top change the GUI’s mode, and the <italic toggle="yes">Add annotation</italic> mode is selected. In the upper part of the plot (first level), activities were annotated. The second level was used to annotate strides.</p>
    </caption>
    <graphic xlink:href="sensors-22-05849-g001" position="float"/>
  </fig>
  <fig position="float" id="sensors-22-05849-f002">
    <label>Figure 2</label>
    <caption>
      <p>The load data dialog, where the user selects data to be loaded.</p>
    </caption>
    <graphic xlink:href="sensors-22-05849-g002" position="float"/>
  </fig>
  <fig position="float" id="sensors-22-05849-f003">
    <label>Figure 3</label>
    <caption>
      <p>Median task completion time for developers. For the tasks <italic toggle="yes">Load data</italic> and <italic toggle="yes">Implement algorithm</italic>, the time needed for installing the required Python packages is not included.</p>
    </caption>
    <graphic xlink:href="sensors-22-05849-g003" position="float"/>
  </fig>
  <fig position="float" id="sensors-22-05849-f004">
    <label>Figure 4</label>
    <caption>
      <p>Task completion time for clinicians. Divided into the GUI being in the background (lower opacity) or foreground (higher opacity). Time in the background and foreground are medians over five study participants. For one subject, data recording failed for the task <italic toggle="yes">Load and annotate</italic>; however, according to the manually stopped overall time, this person’s data would not change the median.</p>
    </caption>
    <graphic xlink:href="sensors-22-05849-g004" position="float"/>
  </fig>
  <table-wrap position="float" id="sensors-22-05849-t001">
    <object-id pub-id-type="pii">sensors-22-05849-t001_Table 1</object-id>
    <label>Table 1</label>
    <caption>
      <p>Developer programming experience according to a 5-point Likert scale (1: very inexperienced, 5: very experienced) reported as the mean (median).</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Item</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">PALMS</th>
          <th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">MaD</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="center" valign="middle" rowspan="1" colspan="1">Experience with respect to colleagues</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">3.8 (4.0)</td>
          <td align="center" valign="middle" rowspan="1" colspan="1">3.4 (3.0)</td>
        </tr>
        <tr>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Object-oriented programming</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3.4 (3.0)</td>
          <td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3.4 (3.0)</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="sensors-22-05849-t002">
    <object-id pub-id-type="pii">sensors-22-05849-t002_Table 2</object-id>
    <label>Table 2</label>
    <caption>
      <p>Static code analysis. Percentage values are relative to lines of code.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Measure</th>
          <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">PALMS</th>
          <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">MaD GUI</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Lines of code</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">5134</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">3574</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Comments (%)</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">897 (14.9)</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">1009 (22.0)</td>
        </tr>
        <tr>
          <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Cognitive complexity (%)</td>
          <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1035 (0.20)</td>
          <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">548 (0.15)</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="sensors-22-05849-t003">
    <object-id pub-id-type="pii">sensors-22-05849-t003_Table 3</object-id>
    <label>Table 3</label>
    <caption>
      <p>User experience questionnaire median scores for the adaptability study. For each item, a score between −3 (worst) and 3 (best) is possible.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Scale</th>
          <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">MaD GUI</th>
          <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">PALMS</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Attractiveness</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">2.17</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">−0.67</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Perspicuity</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">2.25</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">−2.00</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Efficiency</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">2.50</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">−0.50</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Dependability</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">2.25</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">−0.50</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Stimulation</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">2.00</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.25</td>
        </tr>
        <tr>
          <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Novelty</td>
          <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.75</td>
          <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">−1.00</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
  <table-wrap position="float" id="sensors-22-05849-t004">
    <object-id pub-id-type="pii">sensors-22-05849-t004_Table 4</object-id>
    <label>Table 4</label>
    <caption>
      <p>User experience questionnaire median scores for the user interface study. For each item, a score between −3 (worst) and 3 (best) is possible.</p>
    </caption>
    <table frame="hsides" rules="groups">
      <thead>
        <tr>
          <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Scale</th>
          <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">MaD GUI</th>
          <th align="left" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">PALMS</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Attractiveness</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">1.67</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.33</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Perspicuity</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">2.88</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.75</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Efficiency</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">2.13</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">1.38</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Dependability</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">1.50</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.63</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Stimulation</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">1.25</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.46</td>
        </tr>
        <tr>
          <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Novelty</td>
          <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.75</td>
          <td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">−0.42</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</floats-group>
