<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9535948</article-id>
    <article-id pub-id-type="publisher-id">4971</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-022-04971-w</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>EnsembleSplice: ensemble deep learning model for splice site prediction</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Akpokiro</surname>
          <given-names>Victor</given-names>
        </name>
        <address>
          <email>vakpokir@uccs.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" equal-contrib="yes">
        <name>
          <surname>Martin</surname>
          <given-names>Trevor</given-names>
        </name>
        <address>
          <email>trevormartin4321@gmail.com</email>
        </address>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Oluwadare</surname>
          <given-names>Oluwatosin</given-names>
        </name>
        <address>
          <email>ooluwada@uccs.edu</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.266186.d</institution-id><institution-id institution-id-type="ISNI">0000 0001 0684 1394</institution-id><institution>Department of Computer Science, </institution><institution>University of Colorado, </institution></institution-wrap>Colorado Springs, CO 80918 USA </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.261284.b</institution-id><institution-id institution-id-type="ISNI">0000 0001 2193 5532</institution-id><institution>Department of Mathematics, </institution><institution>Oberlin College, </institution></institution-wrap>Oberlin, OH 44074 USA </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>6</day>
      <month>10</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>6</day>
      <month>10</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>23</volume>
    <elocation-id>413</elocation-id>
    <history>
      <date date-type="received">
        <day>31</day>
        <month>7</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>29</day>
        <month>9</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Identifying splice site regions is an important step in the genomic DNA sequencing pipelines of biomedical and pharmaceutical research. Within this research purview, efficient and accurate splice site detection is highly desirable, and a variety of computational models have been developed toward this end. Neural network architectures have recently been shown to outperform classical machine learning approaches for the task of splice site prediction. Despite these advances, there is still considerable potential for improvement, especially regarding model prediction accuracy, and error rate.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">Given these deficits, we propose EnsembleSplice, an ensemble learning architecture made up of four (4) distinct convolutional neural networks (CNN) model architecture combination that outperform existing splice site detection methods in the experimental evaluation metrics considered including the accuracies and error rates. We trained and tested a variety of ensembles made up of CNNs and DNNs using the five-fold cross-validation method to identify the model that performed the best across the evaluation and diversity metrics. As a result, we developed our diverse and highly effective splice site (SS) detection model, which we evaluated using two (2) genomic <italic>Homo sapiens</italic> datasets and the <italic>Arabidopsis thaliana</italic> dataset. The results showed that for of the <italic>Homo sapiens</italic> EnsembleSplice achieved accuracies of 94.16% for one of the acceptor splice sites and 95.97% for donor splice sites, with an error rate for the same <italic>Homo sapiens</italic> dataset, 4.03% for the donor splice sites and 5.84% for the <italic>a</italic>cceptor splice sites datasets.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">Our five-fold cross validation ensured the prediction accuracy of our models are consistent. For reproducibility, all the datasets used, models generated, and results in our work are publicly available in our GitHub repository here: <ext-link ext-link-type="uri" xlink:href="https://github.com/OluwadareLab/EnsembleSplice">https://github.com/OluwadareLab/EnsembleSplice</ext-link></p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Splice sites (SS)</kwd>
      <kwd>Ensemble learning</kwd>
      <kwd>Deep learning (DL)</kwd>
      <kwd>Convolutional neural network (CNN)</kwd>
      <kwd>Dense neural network (DNN)</kwd>
      <kwd>Feature extraction</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id>
            <institution>National Science Foundation</institution>
          </institution-wrap>
        </funding-source>
        <award-id>2050919</award-id>
        <principal-award-recipient>
          <name>
            <surname>Oluwadare</surname>
            <given-names>Oluwatosin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010175</institution-id>
            <institution>University of Colorado Colorado Springs</institution>
          </institution-wrap>
        </funding-source>
        <award-id>Start-up Fund</award-id>
        <principal-award-recipient>
          <name>
            <surname>Oluwadare</surname>
            <given-names>Oluwatosin</given-names>
          </name>
        </principal-award-recipient>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par14">The development of high-throughput computational sequencing methods and technologies has created a significant opportunity for gene structure analysis research and experiments. We focus on splice sites detection in this paper, which is critical for gene structure and expression analysis. The gene sequences essential for protein synthesis are composed of alternating nucleotide regions called introns, which are the non-protein-coding regions, and exons, which are the protein-coding regions. During DNA transcription in eukaryotic cells, an enzyme called spliceosomes cuts out introns and concatenates exons; this process is known as RNA splicing and is required for the creation of mature mRNA from pre-mRNA, which is required for gene expression and protein synthesis [<xref ref-type="bibr" rid="CR1">1</xref>]. The dinucleotides AG and GT are biological markers involved in RNA splicing and are often found in the 3′ intron boundary, or donor splice site (DoSS) region, and the 5′ intron boundary, or acceptor splice site (AcSS) region, respectively [<xref ref-type="bibr" rid="CR2">2</xref>] as shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>.<fig id="Fig1"><label>Fig. 1</label><caption><p>Illustration of 2 step biochemistry process for Splice Sites. This figure shows canonical sequence distribution in a splice site location, the Introns are spliced, hence the name splice sites resulting in proteins as a final product</p></caption><graphic xlink:href="12859_2022_4971_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par15">Organismal genomes are studied primarily through genome annotation, which involves classifying genomic elements based on their function and location [<xref ref-type="bibr" rid="CR3">3</xref>]. This annotation is typically performed at the nucleotide level to determine the locations of key genetic elements in DNA sequences, as well as at the protein level to assess proteomic function and investigate the mechanisms underlying gene interaction and splice site localization [<xref ref-type="bibr" rid="CR4">4</xref>]. More specifically, different computational methods have been proposed to accurately detect splice sites location, which can be used to identify genes in eukaryotic genomes. This biological and biochemical process has proven to be time-consuming and ineffective in the real world, necessitating the development of computational tools for accurate splice site prediction.</p>
    <p id="Par16">The earliest research on genomic DNA splice site prediction primarily leveraged methods in machine learning and probabilistic modeling. GeneSplicer was the first to achieve record accuracies with its Markov model-enhanced maximal dependence decomposition decision trees, which contributed to the popularity of Markov models for splice site prediction [<xref ref-type="bibr" rid="CR2">2</xref>]. Other earlier works used Markov Model as a preprocessing technique for other algorithms such as shallow neural networks, or to enhance performance [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR6">6</xref>]. Burge et al. [<xref ref-type="bibr" rid="CR7">7</xref>] developed the MDD method [<xref ref-type="bibr" rid="CR8">8</xref>] as a decision tree approach to reduce the computational burden of increasing the Markov model order. Goel et al. [<xref ref-type="bibr" rid="CR9">9</xref>] proposed a method also based on Markov model. Some other methods adopted the use of support vector machines (SVMs) for their simplicity and speed [<xref ref-type="bibr" rid="CR10">10</xref>, <xref ref-type="bibr" rid="CR11">11</xref>]. While the intricacy of these machine learning models grew, their accuracy plateaued. This was due to both compute power and the bottleneck of having to select the model's features manually.</p>
    <p id="Par17">Deep learning, along with better computing methods and resources, has largely solved these issues. In recent years, splice site prediction has been performed using the deep learning (DL) approach with neural networks (NNs). Convolutional Neural Networks (CNN) are the most frequent neural network (NN) architecture adopted for this deep learning approaches, and widely deviates in their depth (number of layers) and parameters across studies. SpliceRover [<xref ref-type="bibr" rid="CR12">12</xref>], SpliceFinder [<xref ref-type="bibr" rid="CR13">13</xref>], DeepSplicer [<xref ref-type="bibr" rid="CR14">14</xref>], DeepSS [<xref ref-type="bibr" rid="CR15">15</xref>], Spliceator [<xref ref-type="bibr" rid="CR16">16</xref>], and iSS-CNN [<xref ref-type="bibr" rid="CR17">17</xref>], among others, employ CNNs. Donor and acceptor sites are typically one-hot-encoded and batch-fed into these architectures, which perform feature extraction and exceed the earlier ML techniques in classification accuracy. On genomic DNA, other deep learning methods have been used, including the Long-Short Term Memory (LSTM) neural network and the Recurrent Neural Network (RNN), which are sequence learning networks commonly used in time-series analyses. SpliceViNCI, for example, is a bidirectional LSTM with integrated gradients [<xref ref-type="bibr" rid="CR18">18</xref>].</p>
    <p id="Par18">In this work, we propose a stacking ensemble method for splice site prediction to combine various classifiers to produce an alpha-classifier that is more effective at classification and generalization than the individual classifiers. Through training, a stack (ensemble) of various neural networks models (base-models) develops its own representation of the genomic data. Following this, each network predicts the unidentified splice sequences on its own. These predictions are combined into a new dataset's pool entries. For example, if the ensemble included three different CNNs and two different DNNs, and the predictions for a splice site were [1], [1], [1], [0], [1] for each network, then the row of entries would read [1, 1, 1, 0, 1]. Following the creation of this new dataset, a final prediction using the new dataset is then made using simple logistic regression (meta-model). The main importance of ensemble learning is that the diversity of predictions balances out the weaknesses of individual base model performances, increasing overall accuracy and resulting in improved performance and robustness. This performance and robustness importance can be seen in other deep learning works of literature, including models for positioning footballers [<xref ref-type="bibr" rid="CR19">19</xref>] in sport science research, models for predicting generic Escherichia coli population in agricultural ponds based on weather station measurements [<xref ref-type="bibr" rid="CR20">20</xref>], and improving model performances for the detection of Alzheimer's disease [<xref ref-type="bibr" rid="CR21">21</xref>] in health science research.</p>
    <p id="Par19">Our method combines deep neural network architectures to create EnsembleSplice, a novel ensemble architecture. Hence, we propose a deep learning architecture that learns from an ensemble of CNNs to achieve a state-of-the-art performance in true and false splice sites prediction accuracy and efficiency. We used grid search methods to determine the best hyperparameters, and the best ensemble selection was achieved using five-fold cross-validation, as shown in the manuscript's tables and results. Furthermore, we compare EnsembleSplice’s splice site identification performance to that of existing splice site tools using three genomic DNA datasets as benchmarks. The datasets, datasets preprocessing using one-hot encoding, EnsembleSplice pipeline, performance benchmarks methods, subsections are discussed in the methodology section, while explanatory evaluation metrics, cross-validation, result discussion and model interpretability subsections are discussed in the experiments and results section, as well as the conclusion sections.</p>
    <p id="Par20">In summary, the aim and objective of this work is as follow:<list list-type="bullet"><list-item><p id="Par21">Develop a deep ensemble model architecture consisting of DNNs and/or CNNs that achieves excellent performance on the task of splice site classification.</p></list-item><list-item><p id="Par22">Ensure via cross validation, that the deep ensemble consists of effective component neural networks (CNNs and/or DNNs) with high diversity across them.</p></list-item><list-item><p id="Par23">Ensure that our deep ensemble architecture is robust, with a minimum dispersion and consistent in performance in splice site prediction across different datasets, than current state-of-the-art algorithms.</p></list-item></list></p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <sec id="Sec3">
      <title>Datasets</title>
      <p id="Par24">Each dataset used in this research consists of both confirmed true (positive) AcSS/DoSS and confirmed false (negative) AcSS/DoSS. Evaluation of classification performance is partitioned by splice site type. This means that EnsembleSplice is trained to distinguish between true and false DoSS regions and is trained again and separately to distinguish between true and false AcSS regions.</p>
      <sec id="Sec4">
        <title>HS3D</title>
        <p id="Par25">The <italic>Homo Sapiens</italic> Splice Sites Dataset (<italic>HS3D</italic>) is a collection of human genomic DNA introns and exons extracted from GenBank Rel.123 [<xref ref-type="bibr" rid="CR22">22</xref>] <italic>HS3D'</italic>s Primate Division. There are 2796 confirmed true DoSS regions, 2880 true positive AcSS regions, 271,937 confirmed false DoSS regions, and 329,374 confirmed false AcSS regions. This paper randomly selects 2750 false DoSS regions and 2750 false AcSS regions from the 271,937 and 329,374 available in the dataset, respectively; the Python code snippet <italic>random.seed(123,454)</italic> is used to shuffle the entire <italic>HS3D</italic> dataset before the false DoSS and false AcSS subsets are selected. The full set of 2750 confirmed true DoSS regions and 2750 confirmed true positive AcSS regions are used. The nucleotide consensus AG for AcSS regions occurs at positions 69 and 70, and the nucleotide consensus GT for DoSS regions occurs at positions 71 and 72. In total, each <italic>HS3D</italic> donor and acceptor site splice sequence is 140 nucleotides long, with this sequence length used for the cross-validation, performance, and comparison experiment. The <italic>HS3D</italic> dataset can be accessed at <ext-link ext-link-type="uri" xlink:href="http://www.sci.unisannio.it/docenti/rampone/">http://www.sci.unisannio.it/docenti/rampone/</ext-link><underline>.</underline></p>
      </sec>
      <sec id="Sec5">
        <title>Homo sapiens and Arabidopsis thaliana</title>
        <p id="Par26">The <italic>Homo sapiens</italic> and <italic>Arabidopsis thaliana</italic> datasets consist of splice site regions selected from annotated genomic DNA sequences for Homo sapiens and <italic>A. thaliana</italic> in Ensembl 2018 [<xref ref-type="bibr" rid="CR23">23</xref>]. Using Bedtools [<xref ref-type="bibr" rid="CR24">24</xref>, <xref ref-type="bibr" rid="CR25">25</xref>], the peripheral nucleotide sequences padding each AcSS, or DoSS were determined. Each splice site region in these datasets is 602 nucleotides long; each DoSS region has consensus GT at positions 301 and 302, and each AcSS has consensus AG also at positions 301 and 302. There are 250,400 confirmed true and false DoSS regions and 248,150 confirmed true and false AcSS regions in the <italic>Homo sapiens</italic> dataset. There are 110,314 confirmed true and false DoSS regions and 112,336 confirmed true and false AcSS regions in the <italic>A. thaliana</italic> dataset. The confirmed true AcSS and DoSS regions were selected from chromosomes 21, 2, 2L, 1, and I. This paper randomly selects 8000 true and false DoSS regions (totaling 16,000 entries) and 8000 true and false AcSS regions (totaling 16,000 entries) from both datasets. As with the <italic>HS3D</italic> dataset, the Python code snippet <italic>random.seed</italic>(123,454) is used for shuffling the Homo sapiens and <italic>A. thaliana</italic> datasets before the DoSS and AcSS subsets are selected. The <italic>Homo sapiens</italic> and <italic>A. thaliana</italic> datasets can be accessed at <ext-link ext-link-type="uri" xlink:href="https://github.com/SomayahAlbaradei/Splice_Deep">https://github.com/SomayahAlbaradei/Splice_Deep</ext-link>.</p>
        <p id="Par27">We used the source sequence length—140 nucleotides for HS3D and 602 for <italic>Homo sapiens</italic> and <italic>A. thaliana</italic> datasets —as discussed in the subsections for all cross-validation, performance, and comparison experiments executed and results reported.</p>
      </sec>
    </sec>
    <sec id="Sec6">
      <title>One-hot encoding and hyper-parameter search space and tuning</title>
      <p id="Par28">Genomic DNA splice site regions are composed of four nucleotides: A (Adenine), G (Guanine), C (Cytosine), and T (Thymine). Given constraints on the input of DL architectures, these nucleotides are encoded numerically, with each nucleotide corresponding to a row in a 4 × 4 identity matrix. The encoding scheme utilized in this paper is that A corresponds to [1, 0, 0, 0], G corresponds to [0, 0, 1, 0], C corresponds to [0, 1, 0, 0], and T corresponds to [0, 0, 0, 1]. Now consider a family.<disp-formula id="Equa"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$D = \left\{ {S_{0} , S_{1} , \ldots , S_{n} } \right\}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2022_4971_Article_Equa.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par29">of nucleotide splice site regions. We have the ordered set.<disp-formula id="Equb"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_{i} = \left\{ {x_{1} , x_{2} , \ldots , x_{{\left| {S_{i} } \right|}} } \right\}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mfenced close="|" open="|"><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2022_4971_Article_Equb.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par30">which <inline-formula id="IEq1"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S_{i}$$\end{document}</tex-math><mml:math id="M6"><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq1.gif"/></alternatives></inline-formula> is the <italic>i</italic>-th nucleotide splice site region, and<disp-formula id="Equc"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{j} \in X = \left\{ {A, C, G, T} \right\}, 0 \le j \le \left| {S_{i} } \right|$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mfenced close="}" open="{"><mml:mrow><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mfenced close="|" open="|"><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><graphic xlink:href="12859_2022_4971_Article_Equc.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par31">For all <inline-formula id="IEq2"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$0 \le j \le \left| {S_{i} } \right|$$\end{document}</tex-math><mml:math id="M10"><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mfenced close="|" open="|"><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq2.gif"/></alternatives></inline-formula> is encoded as a <inline-formula id="IEq3"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\left| {S_{i} } \right|*\left| X \right|$$\end{document}</tex-math><mml:math id="M12"><mml:mrow><mml:mfenced close="|" open="|"><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mrow/><mml:mo>∗</mml:mo><mml:mfenced close="|" open="|"><mml:mi>X</mml:mi></mml:mfenced></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq3.gif"/></alternatives></inline-formula> binary matrix through one-hot encoding.</p>
      <p id="Par32">Alternatively stated, if each splice site region consists of some <inline-formula id="IEq4"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N$$\end{document}</tex-math><mml:math id="M14"><mml:mi>N</mml:mi></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq4.gif"/></alternatives></inline-formula> nucleotides, the final numerical representation for each splice site region is a <inline-formula id="IEq5"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$N \times 4$$\end{document}</tex-math><mml:math id="M16"><mml:mrow><mml:mi>N</mml:mi><mml:mo>×</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq5.gif"/></alternatives></inline-formula> matrix, where each row is a one-hot encoded nucleotide that occurs at the same index as it did in the splice site region's original representation.</p>
      <p id="Par33">We used an easily optimizable hyperparameter tool called KerasTurner (<ext-link ext-link-type="uri" xlink:href="https://keras.io/api/keras_tuner/tuners/hyperband/">https://keras.io/api/keras_tuner/tuners/hyperband/</ext-link>) for our hyperparameter search. We configure this tool based on the search space parameters as shown in Table <xref rid="Tab1" ref-type="table">1</xref>. This table shows the hyper-parameters, search range, steps, and selected parameters for each CNN and DNN subgroup. To reduce the learning rate as the training proceeds, we used the TensorFlow inverse time decay schedule. For the CNNs, the parameters are initial learning rate 0.001, decay steps 140, and decay rate 0.1, while for the DNNs, the parameters are initial learning rate 0.002, decay steps 80, and decay rate 1.4. We have used a 32-batch size for each neural network model compilation and a 30-epoch for each.<table-wrap id="Tab1"><label>Table 1</label><caption><p>EnsembleSplice neural network hyper-parameter search space</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Neural Network</th><th align="left">Hyper-parameter</th><th align="left">Range</th><th align="left">Steps</th><th align="left">Selected</th></tr></thead><tbody><tr><td align="left" rowspan="4">CNN</td><td align="left">Filters</td><td align="left">8–400</td><td align="left">8</td><td align="left">72, 120, 136, 144, 168, 208, 250, 272,</td></tr><tr><td align="left">Kernel size</td><td align="left">1–9</td><td align="left">2</td><td align="left">3, 4, 5, 7, 9</td></tr><tr><td align="left">Dropout</td><td align="left">0.05–0.30</td><td align="left">0.05</td><td align="left">0.20, 0.35</td></tr><tr><td align="left">Max-Pool size</td><td align="left">1–9</td><td align="left">2</td><td align="left">3</td></tr><tr><td align="left" rowspan="3">DNN</td><td align="left">Units</td><td align="left">32–704</td><td align="left">32</td><td align="left">32, 128, 224, 250, 256, 352, 512, 704,</td></tr><tr><td align="left">Kernel regularizers</td><td align="left">0.0025, 0.025, 0.036</td><td align="left">-</td><td align="left">0.0025, 0.025, 0.036</td></tr><tr><td align="left">Dropout</td><td align="left">0.05–0.50</td><td align="left">0.50</td><td align="left">0.1, 0.15, 0.25</td></tr></tbody></table><table-wrap-foot><p>This table shows the convolutional neural network (CNN) and Dense Neural Network (DNN) search space. This includes the search range, steps and the selected hyperparameter</p></table-wrap-foot></table-wrap></p>
    </sec>
    <sec id="Sec7">
      <title>Deep learning</title>
      <p id="Par34">Deep learning is a branch of machine learning that uses layered learning and a hierarchical learning model to enable computers to learn complex concepts [<xref ref-type="bibr" rid="CR26">26</xref>]. Deep Learning is based on an artificial neural network that mimics the concept of brain neurons. Artificial neural networks contain neuronal connections and the ability to send inputs within layers of neurons [<xref ref-type="bibr" rid="CR26">26</xref>]. Moreso, an artificial neural network with convolutional blocks as its fundamental layers is known as a convolutional neural network. [<xref ref-type="bibr" rid="CR27">27</xref>–<xref ref-type="bibr" rid="CR29">29</xref>]. The EnsembleSplice model combines convolutional layers and dense layers networks to receive input, transform it, and output the transformed results between layers to a simple logistics regression. In other words, they combine features and pattern extraction on the genomic acceptor and donor datasets with organized (element-wise multiplication) operations between the layer inputs and their corresponding weights. To detect these patterns, the number and size of filters are given. These filters are matrices with randomly defined values in the rows and columns, allowing for effective differentiation of true/false acceptors and donor splice sites. We tested and analyzed mean cross-validation results for the different ensemble architectures across the acceptor and donor organism datasets to find the best performing model for predicting splice locations. The architecture and model parameters are covered in detail in the EnsembleSplice pipeline section below.</p>
    </sec>
    <sec id="Sec8">
      <title>EnsembleSplice pipeline</title>
      <p id="Par35">EnsembleSplice is an ensemble learning architecture made up of eight sub-models: four deep neural networks and four convolutional neural networks. The architecture of each CNN and DNN sub-models is shown in Table <xref rid="Tab2" ref-type="table">2</xref> with colored pattern representation in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. Each sub-model's architectural design choices differ significantly. These EnsembleSplice sub-models predict whether inputted genomic DNA sequences are true or false splice regions and handle DoSS and AcSS separately, implying that there are two sets of weights, one for DoSS and the other for AcSS classification. Both DoSS and AcSS use the same sub-model architecture (the architecture of the <italic>i-th</italic> CNN is identical in both). The sub-models produce binary predictions, which are then aggregated (stacked) into a new dataset, with row <italic>i</italic> containing all sub-model predictions for data entry <italic>i</italic>, and this dataset is then fed into an output predictor (logistic regression), which produces a final set of predictions for the inputted nucleotide sequences. Each CNN sub-model in EnsembleSplice is composed of some combination of convolutional layers, a dropout layer, and max-pooling layers. The convolutional layers automatically extract local and global features from the AcSS or DoSS input sequences. These layers create complex representations of the AcSS or DoSS, allowing CNN to distinguish between true and false AcSS/DoSS with accuracy. Each convolutional layer employs the ReLU activation function as its final component; this removes noisy or otherwise irrelevant features, thus improving feature selection [<xref ref-type="bibr" rid="CR30">30</xref>, <xref ref-type="bibr" rid="CR31">31</xref>]. The dropout layer prunes a percentage of each network's total convolutional nodes, which reduces model overfitting by limiting the co-dependencies each node in the network has on other nodes in the network [<xref ref-type="bibr" rid="CR32">32</xref>]. Each CNN optimizer uses the ADAM optimizer [<xref ref-type="bibr" rid="CR33">33</xref>] with an inverse time decay learning rate schedule during model compilation.<table-wrap id="Tab2"><label>Table 2</label><caption><p>EnsembleSplices’ CNNs and DNNs model architecture</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Neural networks</th><th align="left">Layer type</th></tr></thead><tbody><tr><td align="left" rowspan="6">CNN 1</td><td align="left">Conv1D(72, 5)</td></tr><tr><td align="left">Conv1D(144, 7)</td></tr><tr><td align="left">Conv1D(168, 7)</td></tr><tr><td align="left">Flatten()</td></tr><tr><td align="left">Dropout(0.20)</td></tr><tr><td align="left">Dense(2, "sigmoid")</td></tr><tr><td align="left" rowspan="8">CNN 2</td><td align="left">Conv1D(136, 3)</td></tr><tr><td align="left">Conv1D(72, 4)</td></tr><tr><td align="left">MaxPooling1D(7)</td></tr><tr><td align="left">Conv1D(272, 7)</td></tr><tr><td align="left">MaxPooling1D(3)</td></tr><tr><td align="left">Flatten()</td></tr><tr><td align="left">Dropout(rate = 0.35)</td></tr><tr><td align="left">Dense(2, "sigmoid")</td></tr><tr><td align="left" rowspan="7">CNN 3</td><td align="left">Conv1D(208, 9)</td></tr><tr><td align="left">MaxPooling1D(6)</td></tr><tr><td align="left">Conv1D(120, 5)</td></tr><tr><td align="left">MaxPooling1D(3)</td></tr><tr><td align="left">Flatten()</td></tr><tr><td align="left">Dropout(0.20)</td></tr><tr><td align="left">Dense(2, "sigmoid")</td></tr><tr><td align="left" rowspan="7">CNN 4</td><td align="left">Conv1D(250, 5)</td></tr><tr><td align="left">Conv1D(250, 5)</td></tr><tr><td align="left">Conv1D(250, 5)</td></tr><tr><td align="left">MaxPooling1D(3)</td></tr><tr><td align="left">Flatten()</td></tr><tr><td align="left">Dropout(0.20)</td></tr><tr><td align="left">Dense(2, "sigmoid")</td></tr><tr><td align="left" rowspan="7">DNN 1</td><td align="left">Flatten()</td></tr><tr><td align="left">Dense(704)</td></tr><tr><td align="left">Dense(224)</td></tr><tr><td align="left">Dropout(0.1)</td></tr><tr><td align="left">Dense(512)</td></tr><tr><td align="left">Dropout(0.15)</td></tr><tr><td align="left">Dense(2, "sigmoid")</td></tr><tr><td align="left" rowspan="6">DNN 2</td><td align="left">Flatten()</td></tr><tr><td align="left">Dense(704)</td></tr><tr><td align="left">Dense(224)</td></tr><tr><td align="left">Dense(128)</td></tr><tr><td align="left">Dropout(0.15)</td></tr><tr><td align="left">Dense(2, "sigmoid")</td></tr><tr><td align="left" rowspan="7">DNN 3</td><td align="left">Flatten()</td></tr><tr><td align="left">Dense(256)</td></tr><tr><td align="left">Dense(352)</td></tr><tr><td align="left">Dense(32)</td></tr><tr><td align="left">Dense(352)</td></tr><tr><td align="left">Dropout(0.15)</td></tr><tr><td align="left">Dense(2, "sigmoid")</td></tr><tr><td align="left" rowspan="6">DNN 4</td><td align="left">Flatten()</td></tr><tr><td align="left">Dense(250)</td></tr><tr><td align="left">Dense(250)</td></tr><tr><td align="left">Dense(250)</td></tr><tr><td align="left">Dropout(0.25)</td></tr><tr><td align="left">Dense(2, "sigmoid")</td></tr></tbody></table><table-wrap-foot><p>The number of filters and kernel size are the first and second parameters for convolutional layers (CNN), respectively, with the same activation function (ReLu) and padding. The pool size is the parameter in the max-pooling layer, and the number of dense nodes and ReLu activation function is the parameter in the layer for dense neural networks (DNNs). DNN 4 uses the random normal as its kernel initializer</p></table-wrap-foot></table-wrap><fig id="Fig2"><label>Fig. 2</label><caption><p>EnsembleSplices’ CNNs and DNNs model architecture. This figure depicts each CNNs and DNNs base model’s architecture used in this cross-validation experiment. This Figure contains <bold>a</bold> CNN 1; <bold>b</bold> CNN 2; <bold>c</bold> CNN 3; <bold>d</bold> CNN 4; <bold>e</bold> DNN 1; <bold>f</bold> DNN 2; <bold>g</bold> DNN 3; <bold>h</bold> DNN 4, with architecture containing its respective layers and their distinct labels</p></caption><graphic xlink:href="12859_2022_4971_Fig2_HTML" id="MO2"/></fig></p>
      <p id="Par36">Each DNN sub-model in EnsembleSplice consists of several fully connected dense layers, up to 2 dropout layers, and, in some cases, an L2 kernel regularization penalty. Similar to the CNN sub-models, the ReLU activation function and the ADAM optimizer with an inverse time decay learning rate schedule are used.</p>
      <p id="Par37">EnsembleSplice is implemented via the TensorFlow/Keras framework [<xref ref-type="bibr" rid="CR34">34</xref>, <xref ref-type="bibr" rid="CR35">35</xref>]. For all experiments conducted, we use a training maximum epoch of 30. The training and validation were performed in Google Coolaboratory using Graphical Processing Unit (GPU) hardware, and the early model stopping callback, which stops training if the model's validation loss does not decrease for a predetermined number of epochs. The CNN and DNN ensemble sub-model architecture evaluation and selection is discussed in details in the cross-validation section of the Results and Discission section.</p>
    </sec>
    <sec id="Sec9">
      <title>Evaluation metrics</title>
      <p id="Par38">The counts of correctly identified True AcSS or DoSS (true positive, "TP"), correctly identified False AcSS or DoSS (true negative, "TN"), incorrectly annotated True AcSS or DoSS (false positive, "FP"), and incorrectly annotated False AcSS or DoSS (false negative, "FN") are used to evaluate EnsembleSplice's classification performance and to compare EnsembleSplice with other splice site detection models used.</p>
      <p id="Par39">For this experiment, we used evaluation metrics standard to splice site detection research. This includes.<list list-type="bullet"><list-item><p id="Par40">Accuracy (Acc): the value of AcSS and DoSS correctly identified, given by <inline-formula id="IEq6"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Accuracy = \frac{TP + TN}{{TP + TN + FP + FN}}$$\end{document}</tex-math><mml:math id="M18"><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq6.gif"/></alternatives></inline-formula>.</p></list-item><list-item><p id="Par41">Precision (Pre): the fraction of positive classifications for AcSS or DoSS that were positive, given by <inline-formula id="IEq7"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Precision = \frac{TP}{{{\text{TP}} + FP}}$$\end{document}</tex-math><mml:math id="M20"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq7.gif"/></alternatives></inline-formula>.</p></list-item><list-item><p id="Par42">Sensitivity (Sn): the fraction of positive AcSS or DoSS with a positive classification (true positive rate), given by <inline-formula id="IEq8"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Sensitivity = \frac{TP}{{{\text{TP}} + {\text{FN}}}}$$\end{document}</tex-math><mml:math id="M22"><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TP</mml:mi></mml:mrow><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FN</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq8.gif"/></alternatives></inline-formula>.</p></list-item><list-item><p id="Par43">Specificity (Sp): the fraction of negative AcSS or DoSS with a negative classification (true negative rate), given by <inline-formula id="IEq9"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Specificity = \frac{TN}{{{\text{TN}} + {\text{FP}}}}$$\end{document}</tex-math><mml:math id="M24"><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="italic">TN</mml:mi></mml:mrow><mml:mrow><mml:mtext>TN</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FP</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq9.gif"/></alternatives></inline-formula>.</p></list-item><list-item><p id="Par44">Matthew’s Correlation Coefficient (MCC): the correlation between true and false AcSS and DoSS and the classifications for them generated by the mode, given by <inline-formula id="IEq10"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$MCC = \frac{{{\text{TP}} \times {\text{TN}} - {\text{FP}} \times {\text{FN}}}}{{\sqrt {\left( {{\text{TP}} + {\text{FP}}} \right)\left( {{\text{TP}} + {\text{FN}}} \right)\left( {{\text{TN}} + {\text{FP}}} \right)\left( {{\text{TN}} + {\text{FN}}} \right)} }}$$\end{document}</tex-math><mml:math id="M26"><mml:mrow><mml:mi>M</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>×</mml:mo><mml:mtext>TN</mml:mtext><mml:mo>-</mml:mo><mml:mtext>FP</mml:mtext><mml:mo>×</mml:mo><mml:mtext>FN</mml:mtext></mml:mrow><mml:msqrt><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FP</mml:mtext></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FN</mml:mtext></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:mtext>TN</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FP</mml:mtext></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:mtext>TN</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FN</mml:mtext></mml:mrow></mml:mfenced></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq10.gif"/></alternatives></inline-formula>.</p></list-item><list-item><p id="Par45">F1 Score (F1): the harmonic mean of the fraction of positive classifications for AcSS or DoSS that were positive and the fraction of positive AcSS or DoSS that were correctly identified, given by <inline-formula id="IEq11"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F1 Score = \frac{{2 \times {\text{TP}}}}{{2 \times {\text{TP}} + {\text{FP}} + {\text{FN}}}}$$\end{document}</tex-math><mml:math id="M28"><mml:mrow><mml:mi>F</mml:mi><mml:mn>1</mml:mn><mml:mi>S</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mtext>TP</mml:mtext></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mtext>TP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FP</mml:mtext><mml:mo>+</mml:mo><mml:mtext>FN</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq11.gif"/></alternatives></inline-formula>.</p></list-item><list-item><p id="Par46">Error Rate: the fraction of AcSS or DoSS incorrectly identified, given by 1 − Accuracy.</p></list-item></list></p>
      <p id="Par47">We utilized four diversity metrics described below to evaluate how well the different ensembles might generalize in our ensemble cross-validation experiments. They are as follows: correlation, double fault, disagreement, and Q-statistic. For a mathematical illustration of these diversity metrics, we use two classifiers and define <inline-formula id="IEq12"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K^{ij}$$\end{document}</tex-math><mml:math id="M30"><mml:msup><mml:mi>K</mml:mi><mml:mrow><mml:mi mathvariant="italic">ij</mml:mi></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq12.gif"/></alternatives></inline-formula> as the number of measures for which binary vector <inline-formula id="IEq13"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s_{y, x} = i$$\end{document}</tex-math><mml:math id="M32"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq13.gif"/></alternatives></inline-formula> and <inline-formula id="IEq14"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$s_{y, z} = j$$\end{document}</tex-math><mml:math id="M34"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq14.gif"/></alternatives></inline-formula>. Thus, <inline-formula id="IEq15"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K^{11}$$\end{document}</tex-math><mml:math id="M36"><mml:msup><mml:mi>K</mml:mi><mml:mn>11</mml:mn></mml:msup></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq15.gif"/></alternatives></inline-formula> is the number of examples that is correctly classified by the ensemble classifier [<xref ref-type="bibr" rid="CR36">36</xref>].</p>
      <p id="Par48">Given the output of two classifiers, <inline-formula id="IEq16"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q_{x}$$\end{document}</tex-math><mml:math id="M38"><mml:msub><mml:mi>Q</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq16.gif"/></alternatives></inline-formula> and <inline-formula id="IEq17"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Q_{Z}$$\end{document}</tex-math><mml:math id="M40"><mml:msub><mml:mi>Q</mml:mi><mml:mi>Z</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq17.gif"/></alternatives></inline-formula>:<list list-type="bullet"><list-item><p id="Par49">Correlation: the correlation is given by <inline-formula id="IEq18"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{K^{11} K^{00} - K^{01} K^{10} }}{{\sqrt {\left( {K^{11} + K^{10} } \right)\left( {K^{01} + K^{00} } \right)\left( {K^{11} + K^{01} } \right)\left( {K^{10} + K^{00} } \right)} }}$$\end{document}</tex-math><mml:math id="M42"><mml:mfrac><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mn>11</mml:mn></mml:msup><mml:msup><mml:mi>K</mml:mi><mml:mn>00</mml:mn></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>01</mml:mn></mml:msup><mml:msup><mml:mi>K</mml:mi><mml:mn>10</mml:mn></mml:msup></mml:mrow><mml:msqrt><mml:mrow><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mn>11</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>10</mml:mn></mml:msup></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mn>01</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>00</mml:mn></mml:msup></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mn>11</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>01</mml:mn></mml:msup></mml:mrow></mml:mfenced><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mn>10</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>00</mml:mn></mml:msup></mml:mrow></mml:mfenced></mml:mrow></mml:msqrt></mml:mfrac></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq18.gif"/></alternatives></inline-formula>. The correlation measure is diverse when the value is low</p></list-item><list-item><p id="Par50">Double Fault: this measure the fraction of the misclassified examples by both classifier ensemble and is given by <inline-formula id="IEq19"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{K^{00} }}{{K^{11} + K^{10} + K^{01} + K^{00} }}$$\end{document}</tex-math><mml:math id="M44"><mml:mfrac><mml:msup><mml:mi>K</mml:mi><mml:mn>00</mml:mn></mml:msup><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mn>11</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>10</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>01</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>00</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq19.gif"/></alternatives></inline-formula>. This metric is diverse when the value is low.</p></list-item><list-item><p id="Par51">Disagreement: the fraction between the true classifier and false classifier to the total number of examples and is given by <inline-formula id="IEq20"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{K^{01} + K^{10} }}{{K^{11} + K^{10} + K^{01} + K^{00} }}$$\end{document}</tex-math><mml:math id="M46"><mml:mfrac><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mn>01</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>10</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mn>11</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>10</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>01</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>00</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq20.gif"/></alternatives></inline-formula>. Disagreement measure is diverse when the value is high.</p></list-item><list-item><p id="Par52">Q-statistics: this measure is given by <inline-formula id="IEq21"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{{K^{11} K^{00} - K^{01} K^{10} }}{{K^{11} K^{00} - K^{01} K^{10} }}$$\end{document}</tex-math><mml:math id="M48"><mml:mfrac><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mn>11</mml:mn></mml:msup><mml:msup><mml:mi>K</mml:mi><mml:mn>00</mml:mn></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>01</mml:mn></mml:msup><mml:msup><mml:mi>K</mml:mi><mml:mn>10</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mn>11</mml:mn></mml:msup><mml:msup><mml:mi>K</mml:mi><mml:mn>00</mml:mn></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mn>01</mml:mn></mml:msup><mml:msup><mml:mi>K</mml:mi><mml:mn>10</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12859_2022_4971_Article_IEq21.gif"/></alternatives></inline-formula>. A low value shows high diversity for the Q - statistics metrics.</p></list-item></list></p>
    </sec>
    <sec id="Sec10">
      <title>Performance benchmark methods</title>
      <p id="Par53">In this study, we chose existing cutting-edge splice site models iSS-CNN [<xref ref-type="bibr" rid="CR17">17</xref>], SpliceRover [<xref ref-type="bibr" rid="CR12">12</xref>], SpliceFinder [<xref ref-type="bibr" rid="CR13">13</xref>] and DeepSplicer [<xref ref-type="bibr" rid="CR14">14</xref>] for benchmark comparison with EnsembleSplice based on their training architecture, experiment datasets and recent deep-learning based splice site state-of-the-arts.</p>
    </sec>
    <sec id="Sec11">
      <title><bold><italic>Tayara </italic></bold>et al<bold><italic>. </italic></bold>[<xref ref-type="bibr" rid="CR17">17</xref>]</title>
      <p id="Par54">iSS-CNN [<xref ref-type="bibr" rid="CR17">17</xref>], which was trained on a subset of <italic>HS3D</italic> data, has three layers: a dropout layer that prunes 30% of the nodes, a fully connected dense layer using the Sigmoid activation function, one convolutional layer of 16 filters and kernel size 7, stride size 3, and a classification threshold of 0.5 for predicting AcSS or DoSS. The testing was done on the public web server of iSS-CNN and is accessible at <ext-link ext-link-type="uri" xlink:href="http://nsclbio.jbnu.ac.kr/tools/iSS-CNN/">http://nsclbio.jbnu.ac.kr/tools/iSS-CNN/</ext-link>. For evaluation, EnsembleSplice uses the same <italic>HS3D</italic> testing subset as the benchmarked iSS-CNN.</p>
    </sec>
    <sec id="Sec12">
      <title><bold><italic>Zuallaert </italic></bold>et al<bold><italic>. </italic></bold>[<xref ref-type="bibr" rid="CR12">12</xref>]</title>
      <p id="Par55">SpliceRover [<xref ref-type="bibr" rid="CR12">12</xref>] which is also a deep learning approach to splice site prediction was trained on human genomic DNA data and <italic>A. thaliana</italic> genomic DNA data. Its architecture consists of a convolutional layer with filters equal in number to the AcSS or DoSS length, a max-pooling layer, and a series of convolutional and max-pooling layers. A fully connected dense layer follows the convolutional layers, and the output is input to the Softmax activation function. When comparing SpliceRover to EnsembleSplice, their publicly accessible web server is used. This time, a cut of 0.5 was used. The web server can be found at the following link: <ext-link ext-link-type="uri" xlink:href="http://bioit2.irc.ugent.be/rover/splicerover">http://bioit2.irc.ugent.be/rover/splicerover</ext-link>.</p>
    </sec>
    <sec id="Sec13">
      <title><bold><italic>Wang </italic></bold>et al<bold><italic>. </italic></bold>[<xref ref-type="bibr" rid="CR13">13</xref>]</title>
      <p id="Par56">SpliceFinder [<xref ref-type="bibr" rid="CR13">13</xref>] was tested on other species of datasets after being trained on the human dataset. Its classification accuracy was 90.25% and it used one-hot encoding, one convolutional layer, a fully connected layer, and Softmax. We use this method as a benchmark for evaluation comparison since it is a more recent splice site prediction method that has been published.</p>
    </sec>
    <sec id="Sec14">
      <title><bold><italic>Akpokiro </italic></bold>et al<bold><italic>. </italic></bold>[<xref ref-type="bibr" rid="CR14">14</xref>]</title>
      <p id="Par57">DeepSplicer [<xref ref-type="bibr" rid="CR14">14</xref>] uses a five-fold cross-validation approach for its model selection. This convolutional neural network state-of-the-art method uses three convolution neural network layers with flatten, dense, dropout, and Softmax layers in its architecture. Similar to EnsembleSplice, this method is trained and tested on <italic>Homo sapiens</italic> and <italic>A. thaliana</italic>. The models, software architecture, and datasets for SpliceFinder [<xref ref-type="bibr" rid="CR13">13</xref>] and DeepSplicer [<xref ref-type="bibr" rid="CR14">14</xref>] are all available in the corresponding GitHub repositories.</p>
    </sec>
  </sec>
  <sec id="Sec15">
    <title>Results and discussion</title>
    <sec id="Sec16">
      <title>Cross-validation</title>
      <p id="Par58">To establish a more efficient and consistent model, we performed a five-fold cross-validation experiment. Through this experiment, we estimated the splice site prediction accuracy by dividing the balanced training datasets into K equal dataset splits. This split has an equal number of true and false genomic sequences, with true and false splice sites being genomic sequence patterns with consensus AcSS AG and DoSS GT dinucleotide molecules annotated as splice sites and not annotated as splice sites, respectively. We essentially used the K-1 fold for training and the one-fold for testing for each subset of the data partitions. Finally, the reported accuracy represents the mean accuracy computed from all K data splits across each balanced genomic organism dataset. EnsembleSplice employs the StratifiedKFold [<xref ref-type="bibr" rid="CR17">17</xref>] ML module for its k-fold (k = 5) cross-validation for each acceptor and donor organism dataset. Consequently, there were five groups from the training datasets.</p>
      <p id="Par59">We tested potential ensemble architectures using the cross-validation method on the following set:<list list-type="bullet"><list-item><p id="Par60">Ensemble ENS1 contains all DNN’s (DNN1, DNN2, DNN3, DNN4).</p></list-item><list-item><p id="Par61">Ensemble ENS2 contains all the CNNs (CNN1, CNN2, CNN3, CNN4).</p></list-item><list-item><p id="Par62">Ensemble ENS3 contains all the neural network models (DNN1, DNN2, DNN3, DNN4, CNN1, CNN2, CNN3, CNN4).</p></list-item><list-item><p id="Par63">Ensemble ENS4 consists of CNN1, CNN2, CNN3, DNN1, DNN3, this does not include the two worst DNNs and one worst CNN.</p></list-item><list-item><p id="Par64">Ensemble ENS5 contains all the neural network sub models except the single worst CNN and DNN (DNN1, DNN3, DNN4, CNN1, CNN2, CNN3).</p></list-item><list-item><p id="Par65">Ensemble ENS6 includes all DNNs with the worst DNN removed and all CNNs with the worst two CNNs removed (DNN1, DNN3, DNN4, CNN1, CNN2).</p></list-item></list></p>
      <p id="Par66">The architecture of each of this ensemble sub-models—that is CNNs and DNNs— are provided in Table <xref rid="Tab2" ref-type="table">2</xref>, with the architecture representation in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. All the architectures use the one-hot encoding of genome data as their input. Additionally, the output of this architecture serves as the input for a dense and dropout layer. Consequently, we compute the mean results for the evaluation and diversity metrics of the cross-validation results across the organism for each acceptor and donor dataset with results shown in the Table <xref rid="Tab3" ref-type="table">3</xref>. From the table, we observe that the performance of the ENS2 architecture is highly competitive across all the diversity metrics. Importantly, this architecture outperformed the competition in accuracy metrics and error rates for the acceptor and donor splice site datasets for the benchmark organisms. Thus, we selected the ENS2 as the representative EnsembleSplice model. The evaluation metrics section explains the metrics used in this experiment and the Fig. <xref rid="Fig4" ref-type="fig">4</xref> outlines the entire architecture of the ENS2 model, from input, one-hot encoding of the genome data, to output specifying the false and true AcSS/DoSS splice site prediction score.<fig id="Fig3"><label>Fig. 3</label><caption><p>Cross-Validation Ensemble model architecture. These are the architectural representation of each Ensemble model architecture and their individual base model architecture combination used in the cross-validation experiment. This contain <bold>a</bold> Ensemble ENS1 contains all DNN’s (DNN1, DNN2, DNN3, DNN4); <bold>b</bold> Ensemble ENS2 contains all the CNNs (CNN1, CNN2, CNN3, CNN4); <bold>c</bold> Ensemble ENS3 contains all the neural network models (DNN1, DNN2, DNN3, DNN4, CNN1, CNN2, CNN3, CNN4); <bold>d</bold> Ensemble ENS4 consists of CNN1, CNN2, CNN3, DNN1, DNN3; <bold>e</bold> Ensemble ENS5 consists of DNN1, DNN3, DNN4, CNN1, CNN2, CNN3; <bold>f</bold> Ensemble ENS6 consist of DNN1, DNN3, DNN4, CNN1, CNN2. We selected the Ensemble ENS2 from our cross-validation experiment</p></caption><graphic xlink:href="12859_2022_4971_Fig3a_HTML" id="MO34"/><graphic xlink:href="12859_2022_4971_Fig3b_HTML" id="MO37"/><graphic xlink:href="12859_2022_4971_Fig3c_HTML" id="MO39"/></fig><table-wrap id="Tab3"><label>Table 3</label><caption><p>The cross-validation results for the dataset for the genomic organisms</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Datasets</th><th align="left">SpliceSites</th><th align="left">Metrics</th><th align="left">ENS1</th><th align="left">ENS2</th><th align="left">ENS3</th><th align="left">ENS4</th><th align="left">ENS5</th><th align="left">ENS6</th></tr></thead><tbody><tr><td align="left" rowspan="10"><italic>HS3D</italic></td><td align="left" rowspan="5">Acceptor</td><td align="left">Double fault</td><td char="." align="char">0.033</td><td char="." align="char">0.00</td><td char="." align="char">0.01</td><td char="." align="char">0.01</td><td char="." align="char">0.007</td><td char="." align="char">0.011</td></tr><tr><td align="left">Correlation</td><td char="." align="char">0.612</td><td char="." align="char">0.06</td><td char="." align="char">0.22</td><td char="." align="char">0.20</td><td char="." align="char">0.21</td><td char="." align="char">0.33</td></tr><tr><td align="left">Q-statistics</td><td char="." align="char">0.89</td><td char="." align="char">0.131</td><td char="." align="char">0.50</td><td char="." align="char">0.65</td><td char="." align="char">0.553</td><td char="." align="char">0.83</td></tr><tr><td align="left">Disagreement</td><td char="." align="char">0.03</td><td char="." align="char">0.00</td><td char="." align="char">0.03</td><td char="." align="char">0.03</td><td char="." align="char">0.02</td><td char="." align="char">0.03</td></tr><tr><td align="left">Accuracy</td><td char="." align="char">0.89</td><td char="." align="char">0.936</td><td char="." align="char">0.94</td><td char="." align="char">0.93</td><td char="." align="char">0.94</td><td char="." align="char">0.93</td></tr><tr><td align="left" rowspan="5">Donor</td><td align="left">Double fault</td><td char="." align="char">0.013</td><td char="." align="char">0.00</td><td char="." align="char">0.00</td><td char="." align="char">0.00</td><td char="." align="char">0.003</td><td char="." align="char">0.003</td></tr><tr><td align="left">Correlation</td><td char="." align="char">0.496</td><td char="." align="char">0.02</td><td char="." align="char">0.18</td><td char="." align="char">0.11</td><td char="." align="char">0.19</td><td char="." align="char">0.20</td></tr><tr><td align="left">Q-Statistics</td><td char="." align="char">0.796</td><td char="." align="char">− 0.001</td><td char="." align="char">0.44</td><td char="." align="char">0.37</td><td char="." align="char">0.451</td><td char="." align="char">0.478</td></tr><tr><td align="left">Disagreement</td><td char="." align="char">0.015</td><td char="." align="char">0.00</td><td char="." align="char">0.01</td><td char="." align="char">0.01</td><td char="." align="char">0.01</td><td char="." align="char">0.01</td></tr><tr><td align="left">Accuracy</td><td char="." align="char">0.93</td><td char="." align="char">0.958</td><td char="." align="char">0.95</td><td char="." align="char">0.95</td><td char="." align="char">0.94</td><td char="." align="char">0.94</td></tr><tr><td align="left" rowspan="10"><italic>A. thaliana</italic></td><td align="left" rowspan="5">Acceptor</td><td align="left">Double fault</td><td char="." align="char">0.023</td><td char="." align="char">0.003</td><td char="." align="char">0.012</td><td char="." align="char">0.01</td><td char="." align="char">0.011</td><td char="." align="char">0.01</td></tr><tr><td align="left">Correlation</td><td char="." align="char">0.667</td><td char="." align="char">0.215</td><td char="." align="char">0.358</td><td char="." align="char">0.401</td><td char="." align="char">0.413</td><td char="." align="char">0.415</td></tr><tr><td align="left">Q-Statistics</td><td char="." align="char">0.988</td><td char="." align="char">0.713</td><td char="." align="char">0.843</td><td char="." align="char">0.98</td><td char="." align="char">0.982</td><td char="." align="char">0.985</td></tr><tr><td align="left">Disagreement</td><td char="." align="char">0.023</td><td char="." align="char">0.016</td><td char="." align="char">0.097</td><td char="." align="char">0.027</td><td char="." align="char">0.03</td><td char="." align="char">0.025</td></tr><tr><td align="left">Accuracy</td><td char="." align="char">0.913</td><td char="." align="char">0.947</td><td char="." align="char">0.946</td><td char="." align="char">0.945</td><td char="." align="char">0.948</td><td char="." align="char">0.942</td></tr><tr><td align="left" rowspan="5">Donor</td><td align="left">Double fault</td><td char="." align="char">0.013</td><td char="." align="char">0.019</td><td char="." align="char">0.008</td><td char="." align="char">0.006</td><td char="." align="char">0.007</td><td char="." align="char">0.007</td></tr><tr><td align="left">Correlation</td><td char="." align="char">0.638</td><td char="." align="char">0.132</td><td char="." align="char">0.317</td><td char="." align="char">0.3</td><td char="." align="char">0.315</td><td char="." align="char">0.326</td></tr><tr><td align="left">Q-Statistics</td><td char="." align="char">0.992</td><td char="." align="char">0.308</td><td char="." align="char">0.689</td><td char="." align="char">0.83</td><td char="." align="char">0.882</td><td char="." align="char">0.747</td></tr><tr><td align="left">Disagreement</td><td char="." align="char">0.016</td><td char="." align="char">0.079</td><td char="." align="char">0.089</td><td char="." align="char">0.056</td><td char="." align="char">0.085</td><td char="." align="char">0.016</td></tr><tr><td align="left">Accuracy</td><td char="." align="char">0.93</td><td char="." align="char">0.954</td><td char="." align="char">0.954</td><td char="." align="char">0.95</td><td char="." align="char">0.953</td><td char="." align="char">0.952</td></tr><tr><td align="left" rowspan="10"><italic>Homo Sapiens</italic></td><td align="left" rowspan="5">Acceptor</td><td align="left">Double fault</td><td char="." align="char">0.034</td><td char="." align="char">0.003</td><td char="." align="char">0.015</td><td char="." align="char">0.01</td><td char="." align="char">0.013</td><td char="." align="char">0.015</td></tr><tr><td align="left">Correlation</td><td char="." align="char">0.702</td><td char="." align="char">0.19</td><td char="." align="char">0.325</td><td char="." align="char">0.338</td><td char="." align="char">0.353</td><td char="." align="char">0.399</td></tr><tr><td align="left">Q-Statistics</td><td char="." align="char">0.989</td><td char="." align="char">0.555</td><td char="." align="char">0.667</td><td char="." align="char">0.978</td><td char="." align="char">0.844</td><td char="." align="char">0.978</td></tr><tr><td align="left">Disagreement</td><td char="." align="char">0.028</td><td char="." align="char">0.022</td><td char="." align="char">0.083</td><td char="." align="char">0.037</td><td char="." align="char">0.069</td><td char="." align="char">0.037</td></tr><tr><td align="left">Accuracy</td><td char="." align="char">0.894</td><td char="." align="char">0.938</td><td char="." align="char">0.938</td><td char="." align="char">0.939</td><td char="." align="char">0.937</td><td char="." align="char">0.933</td></tr><tr><td align="left" rowspan="5">Donor</td><td align="left">Double fault</td><td char="." align="char">0.022</td><td char="." align="char">0.001</td><td char="." align="char">0.008</td><td char="." align="char">0.007</td><td char="." align="char">0.01</td><td char="." align="char">0.008</td></tr><tr><td align="left">Correlation</td><td char="." align="char">0.665</td><td char="." align="char">0.103</td><td char="." align="char">0.289</td><td char="." align="char">0.298</td><td char="." align="char">0.338</td><td char="." align="char">0.315</td></tr><tr><td align="left">Q-Statistics</td><td char="." align="char">0.989</td><td char="." align="char">0.274</td><td char="." align="char">0.773</td><td char="." align="char">0.894</td><td char="." align="char">0.978</td><td char="." align="char">0.907</td></tr><tr><td align="left">Disagreement</td><td char="." align="char">0.022</td><td char="." align="char">0.057</td><td char="." align="char">0.024</td><td char="." align="char">0.025</td><td char="." align="char">0.033</td><td char="." align="char">0.025</td></tr><tr><td align="left">Accuracy</td><td char="." align="char">0.907</td><td char="." align="char">0.952</td><td char="." align="char">0.952</td><td char="." align="char">0.951</td><td char="." align="char">0.949</td><td char="." align="char">0.946</td></tr><tr><td align="left" rowspan="10">Average</td><td align="left" rowspan="5">Acceptor</td><td align="left">Double fault</td><td char="." align="char">0.03</td><td char="." align="char"><bold>0.002</bold></td><td char="." align="char">0.01</td><td char="." align="char">0.02</td><td char="." align="char">0.01</td><td char="." align="char">0.012</td></tr><tr><td align="left">Correlation</td><td char="." align="char">0.66</td><td char="." align="char"><bold>0.16</bold></td><td char="." align="char">0.30</td><td char="." align="char">0.31</td><td char="." align="char">0.32</td><td char="." align="char">0.38</td></tr><tr><td align="left">Q-Statistics</td><td char="." align="char">0.955</td><td char="." align="char"><bold>0.466</bold></td><td char="." align="char">0.58</td><td char="." align="char">0.87</td><td char="." align="char">0.793</td><td char="." align="char">0.931</td></tr><tr><td align="left">Disagreement</td><td char="." align="char">0.027</td><td char="." align="char">0.012</td><td char="." align="char"><bold>0.070</bold></td><td char="." align="char">0.033</td><td char="." align="char">0.040</td><td char="." align="char">0.030</td></tr><tr><td align="left">Accuracy</td><td char="." align="char">0.830</td><td char="." align="char"><bold>0.941</bold></td><td char="." align="char">0.940</td><td char="." align="char">0.940</td><td char="." align="char">0.940</td><td char="." align="char">0.930</td></tr><tr><td align="left" rowspan="5">Donor</td><td align="left">Double fault</td><td char="." align="char">0.015</td><td char="." align="char">0.012</td><td char="." align="char">0.010</td><td char="." align="char"><bold>0.004</bold></td><td char="." align="char">0.006</td><td char="." align="char">0.008</td></tr><tr><td align="left">Correlation</td><td char="." align="char">0.599</td><td char="." align="char"><bold>0.09</bold></td><td char="." align="char">0.260</td><td char="." align="char">0.240</td><td char="." align="char">0.28</td><td char="." align="char">0.28</td></tr><tr><td align="left">Q-Statistics</td><td char="." align="char">0.9256</td><td char="." align="char"><bold>0.193</bold></td><td char="." align="char">0.630</td><td char="." align="char">0.700</td><td char="." align="char">0.770</td><td char="." align="char">0.710</td></tr><tr><td align="left">Disagreement</td><td char="." align="char">0.017</td><td char="." align="char"><bold>0.045</bold></td><td char="." align="char">0.040</td><td char="." align="char">0.030</td><td char="." align="char">0.040</td><td char="." align="char">0.020</td></tr><tr><td align="left">Accuracy</td><td char="." align="char">0.920</td><td char="." align="char"><bold>0.954</bold></td><td char="." align="char">0.950</td><td char="." align="char">0.950</td><td char="." align="char">0.950</td><td char="." align="char">0.950</td></tr></tbody></table><table-wrap-foot><p>This table depicts the five-fold Cross-validation Results, average result across the organism distribution, evaluation metrics and the ensemble combinations considered. Results highlighted in black shows the best average evaluation metrics. <italic>ENS1</italic> consist of DNN1, DNN2, DNN3, DNN4; <italic>ENS2</italic> consists OF CNN1, CNN2, CNN3, CNN4; <italic>ENS3</italic> consists of DNN1, DNN2, DNN3, DNN4, CNN1, CNN2, CNN3, CNN4; <italic>ENS4</italic> consists of CNN1, CNN2, CNN3, DNN1, DNN3; <italic>ENS5</italic> consist of DNN1, DNN3, DNN4, CNN1, CNN2, CNN3; <italic>ENS6</italic> includes the DNN1, DNN3, DNN4, CNN1, CNN2</p></table-wrap-foot></table-wrap><fig id="Fig4"><label>Fig. 4</label><caption><p>EnsembleSplice architectural pipeline. This figure depicts the Ensemble architecture used for this experiment. This contains the one-hot encoded datasets, the ensemble neural network combination, prediction and label, and the logistics regression and evaluation</p></caption><graphic xlink:href="12859_2022_4971_Fig4_HTML" id="MO4"/></fig></p>
    </sec>
    <sec id="Sec17">
      <title>Performance evaluation</title>
      <p id="Par67">We evaluated and compared EnsembleSplice performance to the benchmarked methods based on the metrics described above in the evaluation metrics section and the datasets as discussed in the datasets section with the state-of-the-art methods considered because of their deep learning application. EnsembleSplice outperforms all other methods for the <italic>HS3D</italic> acceptor datasets, with the exception of the precision metrics, where DeepSplicer outperformed EnsembleSplice by a factor of 1.05%. Furthermore, our approach outperforms other cutting-edge methodologies and records an accuracy of 93.79% and a reduced error rate of 6.36%. With an improved accuracy of 96.25% and a reduced error rate of 3.81% in the <italic>HS3D</italic> donor datasets, EnsembleSplice outperforms competing methods. We continued to test EnsembleSplice to predict splice sites in the <italic>A. thaliana</italic> genomic dataset and discovered that it performed better than other methods in every metric for both the acceptor and donor genomic dataset organisms. We tested and compared other splice site models on the Homo-sapiens datasets in order to demonstrate EnsembleSplice's consistency in predicting the splice site. In the acceptor and donor datasets, EnsembleSplice records data with higher accuracy and lower error rates than other methods. In the Table <xref rid="Tab4" ref-type="table">4</xref> result, N/A denoted results for methods of no known datasets model.<table-wrap id="Tab4"><label>Table 4</label><caption><p>The Evaluation performance comparison results</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Datasets</th><th align="left">SpliceSites</th><th align="left">Model</th><th align="left">Sp</th><th align="left">Sn</th><th align="left">Pre</th><th align="left">Err</th><th align="left">Acc</th><th align="left">MCC</th><th align="left">F1</th></tr></thead><tbody><tr><td align="left" rowspan="10"><italic>HS3D</italic></td><td align="left" rowspan="5">Acceptor</td><td align="left">ISSCNN</td><td align="left">87.27</td><td align="left">91.81</td><td align="left">87.82</td><td align="left">10.45</td><td align="left">89.55</td><td align="left">79.17</td><td align="left">81.45</td></tr><tr><td align="left">SpliceRover</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td></tr><tr><td align="left">DeepSplicer</td><td align="left">92.55</td><td align="left">92.91</td><td align="left"><bold>92.57</bold></td><td align="left">7.27</td><td align="left">92.73</td><td align="left">85.46</td><td align="left">92.74</td></tr><tr><td align="left">SpliceFinder</td><td align="left">89.09</td><td align="left">93.09</td><td align="left">89.51</td><td align="left">8.90</td><td align="left">91.09</td><td align="left">82.24</td><td align="left">91.26</td></tr><tr><td align="left">EnsembleSplice</td><td align="left"><bold>91.09</bold></td><td align="left"><bold>96.18</bold></td><td align="left">91.52</td><td align="left"><bold>6.36</bold></td><td align="left"><bold>93.64</bold></td><td align="left"><bold>87.39</bold></td><td align="left"><bold>93.79</bold></td></tr><tr><td align="left" rowspan="5">Donor</td><td align="left">ISSCNN</td><td align="left">94.36</td><td align="left">94.90</td><td align="left">94.39</td><td align="left">5.35</td><td align="left">94.64</td><td align="left">89.27</td><td align="left">89.84</td></tr><tr><td align="left">SpliceRover</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td></tr><tr><td align="left">DeepSplicer</td><td align="left">95.45</td><td align="left">94.36</td><td align="left">95.40</td><td align="left">5.09</td><td align="left">94.91</td><td align="left">89.82</td><td align="left">94.88</td></tr><tr><td align="left">SpliceFinder</td><td align="left">94.00</td><td align="left">95.09</td><td align="left">94.06</td><td align="left">5.45</td><td align="left">94.54</td><td align="left">89.09</td><td align="left">94.57</td></tr><tr><td align="left">EnsembleSplice</td><td align="left"><bold>94.37</bold></td><td align="left"><bold>98.00</bold></td><td align="left"><bold>94.56</bold></td><td align="left"><bold>3.81</bold></td><td align="left"><bold>96.18</bold></td><td align="left"><bold>92.43</bold></td><td align="left"><bold>96.25</bold></td></tr><tr><td align="left" rowspan="10"><italic>A. thaliana</italic></td><td align="left" rowspan="5">Acceptor</td><td align="left">SpliceRover</td><td align="left">88.31</td><td align="left">89.25</td><td align="left">88.42</td><td align="left">11.22</td><td align="left">88.78</td><td align="left">77.57</td><td align="left">88.83</td></tr><tr><td align="left">ISSCNN</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td></tr><tr><td align="left">DeepSplicer</td><td align="left">90.00</td><td align="left">94.50</td><td align="left">90.43</td><td align="left">7.75</td><td align="left">92.25</td><td align="left">84.59</td><td align="left">92.40</td></tr><tr><td align="left">SpliceFinder</td><td align="left">90.88</td><td align="left">92.69</td><td align="left">91.04</td><td align="left">8.22</td><td align="left">91.78</td><td align="left">83.58</td><td align="left">91.86</td></tr><tr><td align="left">EnsembleSplice</td><td align="left"><bold>93.13</bold></td><td align="left"><bold>95.94</bold></td><td align="left"><bold>93.31</bold></td><td align="left"><bold>5.47</bold></td><td align="left"><bold>94.53</bold></td><td align="left"><bold>89.10</bold></td><td align="left"><bold>94.61</bold></td></tr><tr><td align="left" rowspan="5">Donor</td><td align="left">SpliceRover</td><td align="left">86.88</td><td align="left">87.13</td><td align="left">86.91</td><td align="left">13.00</td><td align="left">87.00</td><td align="left">74.00</td><td align="left">87.02</td></tr><tr><td align="left">ISSCNN</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td></tr><tr><td align="left">DeepSplicer</td><td align="left">90.44</td><td align="left"><bold>95.06</bold></td><td align="left">90.86</td><td align="left">7.25</td><td align="left">92.75</td><td align="left">85.59</td><td align="left">92.91</td></tr><tr><td align="left">SpliceFinder</td><td align="left">93.50</td><td align="left">91.13</td><td align="left">93.34</td><td align="left">7.69</td><td align="left">92.31</td><td align="left">84.65</td><td align="left">92.22</td></tr><tr><td align="left">EnsembleSplice</td><td align="left"><bold>94.94</bold></td><td align="left">94.38</td><td align="left"><bold>94.91</bold></td><td align="left"><bold>5.34</bold></td><td align="left"><bold>94.66</bold></td><td align="left"><bold>89.31</bold></td><td align="left"><bold>94.64</bold></td></tr><tr><td align="left" rowspan="10"><italic>Homo Sapiens</italic></td><td align="left" rowspan="5">Acceptor</td><td align="left">SpliceRover</td><td align="left">88.25</td><td align="left">93.44</td><td align="left">88.83</td><td align="left">9.16</td><td align="left">90.84</td><td align="left">81.80</td><td align="left">91.08</td></tr><tr><td align="left">ISSCNN</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td></tr><tr><td align="left">DeepSplicer</td><td align="left">90.88</td><td align="left">91.19</td><td align="left">90.90</td><td align="left">8.97</td><td align="left">91.03</td><td align="left">82.06</td><td align="left">91.04</td></tr><tr><td align="left">SpliceFinder</td><td align="left">90.75</td><td align="left">89.94</td><td align="left">90.67</td><td align="left">9.66</td><td align="left">90.34</td><td align="left">80.69</td><td align="left">90.3</td></tr><tr><td align="left">EnsembleSplice</td><td align="left"><bold>93.31</bold></td><td align="left"><bold>95.00</bold></td><td align="left"><bold>93.42</bold></td><td align="left"><bold>5.84</bold></td><td align="left"><bold>94.16</bold></td><td align="left"><bold>88.33</bold></td><td align="left"><bold>94.20</bold></td></tr><tr><td align="left" rowspan="5">Donor</td><td align="left">SpliceRover</td><td align="left">85.44</td><td align="left">91.13</td><td align="left">86.22</td><td align="left">11.72</td><td align="left">88.28</td><td align="left">76.69</td><td align="left">88.61</td></tr><tr><td align="left">ISSCNN</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td><td align="left">N/A</td></tr><tr><td align="left">DeepSplicer</td><td align="left"><bold>96.62</bold></td><td align="left">88.00</td><td align="left"><bold>96.31</bold></td><td align="left">7.69</td><td align="left">92.31</td><td align="left">84.94</td><td align="left">91.97</td></tr><tr><td align="left">SpliceFinder</td><td align="left">93.00</td><td align="left">91.25</td><td align="left">92.88</td><td align="left">7.87</td><td align="left">92.13</td><td align="left">84.26</td><td align="left">92.06</td></tr><tr><td align="left">EnsembleSplice</td><td align="left">96.06</td><td align="left"><bold>95.88</bold></td><td align="left">96.06</td><td align="left"><bold>4.03</bold></td><td align="left"><bold>95.97</bold></td><td align="left"><bold>91.94</bold></td><td align="left"><bold>95.96</bold></td></tr></tbody></table><table-wrap-foot><p>This table shows the EnsembleSplice splice site prediction performance results and its comparison to other methods which includes iSS-CNN [<xref ref-type="bibr" rid="CR17">17</xref>], SpliceRover [<xref ref-type="bibr" rid="CR12">12</xref>], SpliceFinder [<xref ref-type="bibr" rid="CR13">13</xref>], and DeepSplicer [<xref ref-type="bibr" rid="CR14">14</xref>]. We show the prediction accuracy measures and the error rate amongst other evaluation metrics performance results. Results figures highlighted in black denotes best performance, N/A are results for methods of no known datasets model. For this table, <italic>Sp</italic> denotes specificity, <italic>Sn</italic> denotes sensitivity, <italic>Pre</italic> denotes precision, <italic>Err</italic> error rate, <italic>Acc</italic> accuracy, <italic>MCC</italic> denotes Mathew’s correlation coefficient, and <italic>F1</italic> denotes the F1 score</p></table-wrap-foot></table-wrap></p>
      <p id="Par68">Based on the results we have observed and reported above, we can conclude that each of our research objectives have been fulfilled. We have successfully developed a deep ensemble model architecture algorithm for splice site prediction (<italic>objective point 1</italic>). EnsembleSplice is the first deep ensemble model architecture algorithm proposed for splice site prediction. Our method records an outstanding performance in comparison to the state-of-the-art methods and across the evaluation metrics, especially in accuracy and error rate, as shown in Table <xref rid="Tab4" ref-type="table">4</xref><bold>.</bold> This superior performance can be attributed to both the use of individually effective DNN and CNN architectures for splice site prediction and the use five-fold cross-validation to select the best ensemble architecture capable of generalizing for maximum performance and the diversity of our ensemble-based model to provide model performance robustness <italic>(objective point 2).</italic> Comparing our stable and successful model to other state-of-the-art models, Table <xref rid="Tab4" ref-type="table">4</xref> demonstrates how the use of ensemble learning for splice site prediction out-performs other cutting-edge models (<italic>objective point 3</italic>).</p>
    </sec>
    <sec id="Sec18">
      <title>Impact and benefit of this study</title>
      <p id="Par69">The primary appeal of deep learning for splice site prediction is that it is more accurate than earlier machine learning methods, especially ones that involved manual feature selection. Although deep learning is somewhat more computationally intensive, it is effective for solving complex problems, which has been its second major appeal. EnsembleSplice further benefits biological research involving splice site classification in that its deep ensemble architecture outperforms individual deep learning networks and exceeds state-of-the-art performance in splice site prediction, not just in terms of accuracy, but also in terms of other classification metrics, such as precision and sensitivity, because of the diverse combination of its base models. Additionally, in this study, we adopt the stacked ensemble learning algorithm which has the major advantage of using a variety of effective models to accomplish classification or regression tasks and produce predictions that perform better than any one model in the ensemble. In our benchmarking results, the performance of EnsembleSplice’s all-CNN stacked ensemble model demonstrates the advantages of using an ensemble architecture over a single CNN model for the prediction of splice sites, and this knowledge may be applied and transferred to other domains to address still unsolved complex regression or classification problems.</p>
    </sec>
    <sec id="Sec19">
      <title>EnsembleSplice model interpretability</title>
      <p id="Par70">To increase the model's interpretability, we isolated and showed the motifs that drive our EnsembleSplice model's deep learning processes. Understanding the underlying pattern of the genomic sequence by generating the contribution scores of the sequence window is required for implementation. We used the WebLogo [<xref ref-type="bibr" rid="CR37">37</xref>] (<ext-link ext-link-type="uri" xlink:href="http://weblogo.threeplusone.com/create.cgi">http://weblogo.threeplusone.com/create.cgi</ext-link>) web server was also used to illustrate the sequence logo for our model interpretability test outputs. WebLogo is a web-based tool for efficiently generating sequence logos from genomic datasets sequence alignment. This genomic sequence logo displays the weighted average nucleotide base position contribution score for the genomic sequence organism. To show the contributions of genomic motifs in each positive and negative acceptor and donor organism dataset, we use the entire <italic>HS3D</italic> sequence length of 140. Figure <xref rid="Fig5" ref-type="fig">5</xref>a indicates that the nucleotide sequence AG contributes significantly to the <italic>HS3D</italic> acceptor positive splice sites, as Fig. <xref rid="Fig5" ref-type="fig">5</xref>b shows that the nucleotide sequence AG contributes significantly to <italic>HS3D</italic> acceptor negative splice sites. While Fig. <xref rid="Fig5" ref-type="fig">5</xref>c shows the nucleotide sequence GT contributes significantly to the <italic>HS3D</italic> donor positive splice sites as Fig. <xref rid="Fig5" ref-type="fig">5</xref>d indicates the nucleotide sequence GT contributes significantly to the <italic>HS3D</italic> donor negative splice sites. According to this figure, the nucleotide consensus AG for AcSS regions occurs at positions 69 and 70 and the nucleotide consensus GT for DoSS regions occurs at positions 71 and 72 for the <italic>HS3D</italic> datasets. This figure also validates that the splice site distribution is most significant in sequence region position 70.<fig id="Fig5"><label>Fig. 5</label><caption><p>EnsembleSplice model interpretability. This figure is a sequence logo to visualize the importance score for each nucleotide per position for the <italic>HS3D</italic> datasets. <bold>a</bold> indicates the acceptor positive splice sites, as <bold>b</bold> shows that acceptor negative splice sites. While <bold>c</bold> shows the donor positive splice sites as <bold>d</bold> indicates the donor negative splice sites</p></caption><graphic xlink:href="12859_2022_4971_Fig5a_HTML" id="MO55"/><graphic xlink:href="12859_2022_4971_Fig5b_HTML" id="MO58"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec20">
    <title>Conclusion</title>
    <p id="Par71">Inspired by the stacking ensemble machine learning method, we introduce a method that combines heterogeneous base neural network models, learns them in parallel, and combines them by training a meta-model to output a prediction based on the different base model predictions. EnsembleSplice has the advantage of balancing out the base model's flaws and produces a diverse and stable model that can be applied to both competitive, industrial, and academic research applications. EnsembleSplice has consistently shown competitive performance on all metrics used when compared to other methods considered in this experiment. As it contributes computationally to the foundation of protein synthesis and gene expression, this tool finds use in both industrial and academic research applications. In our future work, we will test the generalization strength of the EnsembleSplice model for the prediction of splice sites in DNA sequences across a variety of species.</p>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>SS</term>
        <def>
          <p id="Par4">Splice site</p>
        </def>
      </def-item>
      <def-item>
        <term>CNN</term>
        <def>
          <p id="Par5">Convolutional neural networks</p>
        </def>
      </def-item>
      <def-item>
        <term>DL</term>
        <def>
          <p id="Par6">Deep learning</p>
        </def>
      </def-item>
      <def-item>
        <term>ReLU</term>
        <def>
          <p id="Par7">Rectified linear unit</p>
        </def>
      </def-item>
      <def-item>
        <term>ML</term>
        <def>
          <p id="Par8">Machine learning</p>
        </def>
      </def-item>
      <def-item>
        <term>SVM</term>
        <def>
          <p id="Par9">Support vector machines</p>
        </def>
      </def-item>
      <def-item>
        <term>MM</term>
        <def>
          <p id="Par10">Markov model</p>
        </def>
      </def-item>
      <def-item>
        <term>MDD</term>
        <def>
          <p id="Par11">Maximum dependency decomposition</p>
        </def>
      </def-item>
      <def-item>
        <term>AG</term>
        <def>
          <p id="Par12">Adenine–Guanine</p>
        </def>
      </def-item>
      <def-item>
        <term>GT</term>
        <def>
          <p id="Par13">Guanine–Thymine</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
    <fn>
      <p>Victor Akpokiro and Trevor Martin contributed equally to this work.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>OO conceived the project. TM and OO designed the algorithm. TM implemented the algorithm and drafted the initial manuscript. VA wrote and revised the manuscript and performed the statistical and simulation analyses. VA, TM, and OO evaluated the results. All authors reviewed the manuscript. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work was supported by the National Science Foundation [2050919]. The APC was funded by the start-up funding from the University of Colorado, Colorado Springs [to O.O.]. Any opinions, findings and conclusions or recommendations expressed in this work are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The datasets, models and codebase for this study are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/OluwadareLab/EnsembleSplice">https://github.com/OluwadareLab/EnsembleSplice</ext-link><underline>.</underline> The Python source codes for EnsembleSplice are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/OluwadareLab/EnsembleSplice">https://github.com/OluwadareLab/EnsembleSplice</ext-link><underline>.</underline></p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1">
      <title>Ethics approval and consent to participate</title>
      <p id="Par72">Not applicable.</p>
    </notes>
    <notes id="FPar2">
      <title>Consent for publication</title>
      <p id="Par73">Not applicable.</p>
    </notes>
    <notes id="FPar3" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par74">The authors declare they have no conflict of interest.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pohl</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bortfeldt</surname>
            <given-names>RH</given-names>
          </name>
          <name>
            <surname>Grützmann</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Schuster</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Alternative splicing of mutually exclusive exons—a review</article-title>
        <source>Biosystems</source>
        <year>2013</year>
        <volume>114</volume>
        <issue>1</issue>
        <fpage>31</fpage>
        <lpage>38</lpage>
        <pub-id pub-id-type="doi">10.1016/j.biosystems.2013.07.003</pub-id>
        <pub-id pub-id-type="pmid">23850531</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pertea</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Salzberg</surname>
            <given-names>SL</given-names>
          </name>
        </person-group>
        <article-title>GeneSplicer: a new computational method for splice site prediction</article-title>
        <source>Nucleic Acids Res</source>
        <year>2001</year>
        <volume>29</volume>
        <issue>5</issue>
        <fpage>1185</fpage>
        <lpage>1190</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/29.5.1185</pub-id>
        <pub-id pub-id-type="pmid">11222768</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Abril</surname>
            <given-names>JF</given-names>
          </name>
          <name>
            <surname>Castellano Hereza</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <source>Genome annotation</source>
        <year>2019</year>
        <publisher-name>Elsevier</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>de Sá</surname>
            <given-names>PH</given-names>
          </name>
          <name>
            <surname>Guimarães</surname>
            <given-names>LC</given-names>
          </name>
          <name>
            <surname>Das Graças</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>de Oliveira Veras</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Barh</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Azevedo</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Ramos</surname>
            <given-names>RT</given-names>
          </name>
        </person-group>
        <article-title>Next-generation sequencing and data analysis: strategies, tools, pipelines and protocols</article-title>
        <source>Omics technologies and bio-engineering</source>
        <year>2018</year>
        <publisher-name>Academic Press</publisher-name>
        <fpage>191</fpage>
        <lpage>207</lpage>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ho</surname>
            <given-names>LS</given-names>
          </name>
          <name>
            <surname>Rajapakse</surname>
            <given-names>JC</given-names>
          </name>
        </person-group>
        <article-title>Splice site detection with a higher-order Markov model implemented on a neural network</article-title>
        <source>Genome Inf</source>
        <year>2003</year>
        <volume>14</volume>
        <fpage>64</fpage>
        <lpage>72</lpage>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Huang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Umbach</surname>
            <given-names>DM</given-names>
          </name>
          <name>
            <surname>Ohler</surname>
            <given-names>U</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Optimized mixed Markov models for motif identification</article-title>
        <source>BMC Bioinform</source>
        <year>2006</year>
        <volume>7</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>17</lpage>
        <pub-id pub-id-type="doi">10.1186/1471-2105-7-279</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Burge</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Karlin</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Prediction of complete gene structures in human genomic DNA</article-title>
        <source>J Mol Biol</source>
        <year>1997</year>
        <volume>268</volume>
        <issue>1</issue>
        <fpage>78</fpage>
        <lpage>94</lpage>
        <pub-id pub-id-type="doi">10.1006/jmbi.1997.0951</pub-id>
        <pub-id pub-id-type="pmid">9149143</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Baten</surname>
            <given-names>AK</given-names>
          </name>
          <name>
            <surname>Halgamuge</surname>
            <given-names>SK</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>BC</given-names>
          </name>
        </person-group>
        <article-title>Fast splice site detection using information content and feature reduction</article-title>
        <source>BMC Bioinform</source>
        <year>2008</year>
        <volume>9</volume>
        <issue>12</issue>
        <fpage>1</fpage>
        <lpage>12</lpage>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <mixed-citation publication-type="other">Goel N, Singh S, Aseri TC. A review of soft computing techniques for gene prediction. International Scholarly Research Notices, (2013).</mixed-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sonnenburg</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Schweikert</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Philips</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Behr</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Rätsch</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Accurate splice site prediction using support vector machines</article-title>
        <source>BMC Bioinform</source>
        <year>2007</year>
        <volume>8</volume>
        <issue>10</issue>
        <fpage>1</fpage>
        <lpage>16</lpage>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Splice sites prediction of human genome using length-variable Markov model and feature selection</article-title>
        <source>Expert Syst Appl</source>
        <year>2010</year>
        <volume>37</volume>
        <issue>4</issue>
        <fpage>2771</fpage>
        <lpage>2782</lpage>
        <pub-id pub-id-type="doi">10.1016/j.eswa.2009.09.014</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zuallaert</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Godin</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Soete</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Saeys</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>De Neve</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>SpliceRover: interpretable convolutional neural networks for improved splice site prediction</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>24</issue>
        <fpage>4180</fpage>
        <lpage>4188</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty497</pub-id>
        <pub-id pub-id-type="pmid">29931149</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>SpliceFinder: ab initio prediction of splice sites using convolutional neural network</article-title>
        <source>BMC Bioinform</source>
        <year>2019</year>
        <volume>20</volume>
        <issue>23</issue>
        <fpage>1</fpage>
        <lpage>13</lpage>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Akpokiro V, Oluwadare O, Kalita J. DeepSplicer: an improved method of splice sites prediction using deep learning. In: 2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA). 2021. pp. 606–609</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Du</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Yao</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Diao</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Deepss: exploring splice site motif through convolutional neural network directly from DNA sequence</article-title>
        <source>IEEE Access</source>
        <year>2018</year>
        <volume>6</volume>
        <fpage>32958</fpage>
        <lpage>32978</lpage>
        <pub-id pub-id-type="doi">10.1109/ACCESS.2018.2848847</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thompson</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Scalzitti</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Kress</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Orhand</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Weber</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Moulinier</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Poch</surname>
            <given-names>O</given-names>
          </name>
        </person-group>
        <article-title>Spliceator: multi-species splice site prediction using convolutional neural networks</article-title>
        <source>BMC Bioinform</source>
        <year>2021</year>
        <volume>22</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>26</lpage>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tayara</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Tahir</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Chong</surname>
            <given-names>KT</given-names>
          </name>
        </person-group>
        <article-title>iSS-CNN: identifying splicing sites using convolution neural network</article-title>
        <source>Chemom Intell Lab Syst</source>
        <year>2019</year>
        <volume>188</volume>
        <fpage>63</fpage>
        <lpage>69</lpage>
        <pub-id pub-id-type="doi">10.1016/j.chemolab.2019.03.002</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dutta</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Singh</surname>
            <given-names>KK</given-names>
          </name>
          <name>
            <surname>Anand</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>SpliceViNCI: visualizing the splicing of non-canonical introns through recurrent neural networks</article-title>
        <source>J Bioinform Comput Biol</source>
        <year>2021</year>
        <volume>19</volume>
        <issue>04</issue>
        <fpage>2150014</fpage>
        <pub-id pub-id-type="doi">10.1142/S0219720021500141</pub-id>
        <pub-id pub-id-type="pmid">34088258</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Buyrukoğlu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Savaş</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Stacked-based ensemble machine learning model for positioning footballer</article-title>
        <source>Arab J Sci Eng</source>
        <year>2022</year>
        <pub-id pub-id-type="doi">10.1007/s13369-022-06857-8</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Buyrukoğlu</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Buyrukoğlu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Topalcengiz</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>Comparing regression models with count data to artificial neural network and ensemble models for prediction of generic <italic>Escherichia coli</italic> population in agricultural ponds based on weather station measurements</article-title>
        <source>Microb Risk Anal</source>
        <year>2021</year>
        <volume>19</volume>
        <fpage>100171</fpage>
        <pub-id pub-id-type="doi">10.1016/j.mran.2021.100171</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <mixed-citation publication-type="other">Buyrukoğlu S. Improvement of machine learning models’ performances based on ensemble learning for the detection of Alzheimer disease. In 2021 6th International Conference on Computer Science and Engineering (UBMK). 2021. pp. 102–106.</mixed-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pollastro</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Rampone</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>HS3D, a dataset of Homo Sapiens splice regions, and its extraction procedure from a major public database</article-title>
        <source>Int J Mod Phys C</source>
        <year>2002</year>
        <volume>13</volume>
        <issue>08</issue>
        <fpage>1105</fpage>
        <lpage>1117</lpage>
        <pub-id pub-id-type="doi">10.1142/S0129183102003796</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zerbino</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>Achuthan</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Akanni</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Amode</surname>
            <given-names>MR</given-names>
          </name>
          <name>
            <surname>Barrell</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Bhai</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Flicek</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Ensembl 2018</article-title>
        <source>Nucleic Acids Res</source>
        <year>2018</year>
        <volume>46</volume>
        <issue>D1</issue>
        <fpage>D754</fpage>
        <lpage>D761</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gkx1098</pub-id>
        <pub-id pub-id-type="pmid">29155950</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Albaradei</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Magana-Mora</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Thafar</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Uludag</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Bajic</surname>
            <given-names>VB</given-names>
          </name>
          <name>
            <surname>Gojobori</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Jankovic</surname>
            <given-names>BR</given-names>
          </name>
        </person-group>
        <article-title>Splice2Deep: an ensemble of deep convolutional neural networks for improved splice site prediction in genomic DNA</article-title>
        <source>Gene</source>
        <year>2020</year>
        <volume>763</volume>
        <fpage>100035</fpage>
        <pub-id pub-id-type="doi">10.1016/j.gene.2020.100035</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Quinlan</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Hall</surname>
            <given-names>IM</given-names>
          </name>
        </person-group>
        <article-title>BEDTools: a flexible suite of utilities for comparing genomic features</article-title>
        <source>Bioinformatics</source>
        <year>2010</year>
        <volume>26</volume>
        <issue>6</issue>
        <fpage>841</fpage>
        <lpage>842</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btq033</pub-id>
        <pub-id pub-id-type="pmid">20110278</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <mixed-citation publication-type="other">Goodfellow I, Bengio Y, Courville A. Deep learning. MIT press. 2016.</mixed-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ren</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yuan</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Sc-dcnn: highly-scalable deep convolutional neural network using stochastic computing</article-title>
        <source>ACM SIGPLAN Notices</source>
        <year>2017</year>
        <volume>52</volume>
        <issue>4</issue>
        <fpage>405</fpage>
        <lpage>418</lpage>
        <pub-id pub-id-type="doi">10.1145/3093336.3037746</pub-id>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <mixed-citation publication-type="other">Bačanin Džakula N. Convolutional neural network layers and architectures. In Sinteza 2019-International Scientific Conference on Information Technology and Data Related Research. Singidunum University; 2019. pp. 445–451.</mixed-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tammina</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Transfer learning using VGG-16 with deep convolutional neural network for classifying images</article-title>
        <source>Int J Sci Res Publ (IJSRP)</source>
        <year>2019</year>
        <volume>9</volume>
        <issue>10</issue>
        <fpage>143</fpage>
        <lpage>150</lpage>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hahnloser</surname>
            <given-names>RH</given-names>
          </name>
          <name>
            <surname>Sarpeshkar</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Mahowald</surname>
            <given-names>MA</given-names>
          </name>
          <name>
            <surname>Douglas</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Seung</surname>
            <given-names>HS</given-names>
          </name>
        </person-group>
        <article-title>Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit</article-title>
        <source>Nature</source>
        <year>2000</year>
        <volume>405</volume>
        <issue>6789</issue>
        <fpage>947</fpage>
        <lpage>951</lpage>
        <pub-id pub-id-type="doi">10.1038/35016072</pub-id>
        <pub-id pub-id-type="pmid">10879535</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Krizhevsky A, Hinton G. Convolutional deep belief networks on cifar-10. Unpublished manuscript, 2010;40(7): 1–9.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
        <source>J Mach Learn Res</source>
        <year>2014</year>
        <volume>15</volume>
        <issue>1</issue>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <mixed-citation publication-type="other">Kingma DP, Ba J. Adam: A method for stochastic optimization. 2014. arXiv preprint <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1412.6980">arXiv:1412.6980</ext-link>. </mixed-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <mixed-citation publication-type="other">Abadi M, Barham P, Chen J, Chen Z, Davis A, Dean J, Zheng X. {TensorFlow}: a system for {Large-Scale} machine learning. In 12th USENIX symposium on operating systems design and implementation (OSDI 16). 2016. pp. 265–283.</mixed-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <mixed-citation publication-type="other">Chollet F. Keras: The python deep learning library. Astrophysics source code library, ascl-1806. (2018)</mixed-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <mixed-citation publication-type="other">Johansson U, Lofstrom T, Niklasson L. The importance of diversity in neural network ensembles-an empirical investigation. In: 2007 International Joint Conference on Neural Networks. 2007. pp. 661–666.</mixed-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Crooks</surname>
            <given-names>GE</given-names>
          </name>
          <name>
            <surname>Hon</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Chandonia</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Brenner</surname>
            <given-names>SE</given-names>
          </name>
        </person-group>
        <article-title>WebLogo: a sequence logo generator</article-title>
        <source>Genome Res</source>
        <year>2004</year>
        <volume>14</volume>
        <issue>6</issue>
        <fpage>1188</fpage>
        <lpage>1190</lpage>
        <pub-id pub-id-type="doi">10.1101/gr.849004</pub-id>
        <pub-id pub-id-type="pmid">15173120</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
