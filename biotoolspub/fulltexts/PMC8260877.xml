<?DTDIdentifier.IdentifierValue -//ES//DTD journal article DTD version 5.6.0//EN//XML?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName art560.dtd?>
<?SourceDTD.Version 5.6.0?>
<?ConverterInfo.XSLTName elsevier2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<?origin publisher?>
<?FILEmeta_XPRO100639 xml ?>
<?FILEmain xml ?>
<?FILEmain pdf ?>
<?FILEgr1 jpg ?>
<?FILEgr2 jpg ?>
<?FILEgr3 jpg ?>
<?FILEgr4 jpg ?>
<?FILEgr5 jpg ?>
<?FILEgr6 jpg ?>
<?FILEgr7 jpg ?>
<?FILEgr8 jpg ?>
<?FILEgr9 jpg ?>
<?FILEgr10 jpg ?>
<?FILEgr11 jpg ?>
<?FILEfx1 jpg ?>
<?FILEfx2 jpg ?>
<?FILEfx3 jpg ?>
<?FILEsi1 gif ?>
<?FILEsi2 gif ?>
<?FILEsi3 gif ?>
<?FILEsi4 gif ?>
<?FILEsi5 gif ?>
<?FILEsi6 gif ?>
<?FILEsi7 gif ?>
<?FILEsi8 gif ?>
<?FILEsi9 gif ?>
<?FILEsi10 gif ?>
<?FILEsi11 gif ?>
<?FILEsi12 gif ?>
<?FILEsi13 gif ?>
<?FILEsi14 gif ?>
<?FILEsi15 gif ?>
<?FILEsi16 gif ?>
<?FILEsi17 gif ?>
<?FILEsi18 gif ?>
<?FILEsi19 gif ?>
<?FILEsi20 gif ?>
<?FILEsi21 gif ?>
<?FILEsi22 gif ?>
<?FILEsi23 gif ?>
<?FILEsi24 gif ?>
<?FILEsi25 gif ?>
<?FILEsi26 gif ?>
<?FILEsi27 gif ?>
<?FILEsi28 gif ?>
<?FILEsi29 gif ?>
<?FILEsi30 gif ?>
<?FILEsi31 gif ?>
<?FILEsi32 gif ?>
<?FILEsi33 gif ?>
<?FILEsi34 gif ?>
<?FILEsi35 gif ?>
<?FILEsi36 gif ?>
<?properties open_access?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">STAR Protoc</journal-id>
    <journal-id journal-id-type="iso-abbrev">STAR Protoc</journal-id>
    <journal-title-group>
      <journal-title>STAR Protocols</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2666-1667</issn>
    <publisher>
      <publisher-name>Elsevier</publisher-name>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">8260877</article-id>
    <article-id pub-id-type="pii">S2666-1667(21)00346-4</article-id>
    <article-id pub-id-type="doi">10.1016/j.xpro.2021.100639</article-id>
    <article-id pub-id-type="publisher-id">100639</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Protocol</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Timesias: A machine learning pipeline for predicting outcomes from time-series clinical records</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" id="au1">
        <name>
          <surname>Zhang</surname>
          <given-names>Hanrui</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="fn1" ref-type="fn">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au2">
        <name>
          <surname>Yi</surname>
          <given-names>Daiyao</given-names>
        </name>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="fn1" ref-type="fn">3</xref>
      </contrib>
      <contrib contrib-type="author" id="au3">
        <name>
          <surname>Guan</surname>
          <given-names>Yuanfang</given-names>
        </name>
        <email>gyuanfan@umich.edu</email>
        <xref rid="aff1" ref-type="aff">1</xref>
        <xref rid="aff2" ref-type="aff">2</xref>
        <xref rid="fn2" ref-type="fn">4</xref>
        <xref rid="fn3" ref-type="fn">5</xref>
        <xref rid="cor1" ref-type="corresp">∗</xref>
      </contrib>
      <aff id="aff1"><label>1</label>Department of Computational Medicine and Bioinformatics, Michigan Medicine, University of Michigan, Ann Arbor, MI, USA</aff>
      <aff id="aff2"><label>2</label>Department of Internal Medicine, Michigan Medicine, University of Michigan, Ann Arbor, MI, USA</aff>
    </contrib-group>
    <author-notes>
      <corresp id="cor1"><label>∗</label>Corresponding author <email>gyuanfan@umich.edu</email></corresp>
      <fn id="fn1">
        <label>3</label>
        <p id="ntpara0010">These authors contributed equally</p>
      </fn>
      <fn id="fn2">
        <label>4</label>
        <p id="ntpara0015">Technical contact</p>
      </fn>
      <fn id="fn3">
        <label>5</label>
        <p id="ntpara0020">Lead contact</p>
      </fn>
    </author-notes>
    <pub-date pub-type="pmc-release">
      <day>02</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="epub">.-->
    <pub-date pub-type="collection">
      <day>17</day>
      <month>9</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>02</day>
      <month>7</month>
      <year>2021</year>
    </pub-date>
    <volume>2</volume>
    <issue>3</issue>
    <elocation-id>100639</elocation-id>
    <permissions>
      <copyright-statement>© 2021 The Author(s)</copyright-statement>
      <copyright-year>2021</copyright-year>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref>
        <license-p>This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).</license-p>
      </license>
    </permissions>
    <abstract id="abs0010">
      <title>Summary</title>
      <p>The prediction of outcomes is a critical part of the clinical surveillance for hospitalized patients. Here, we present Timesias, a machine learning pipeline which predicts outcomes from real-time sequential clinical data. The strategy implemented in Timesias is the first-place solution in the crowd-sourcing DII (discover, innovate, impact) National Data Science Challenge involving more than 100,000 patients, achieving 0.85 as evaluated by AUROC (area under receiver operator characteristic curve) in predicting the early onset of sepsis status. Timesias is freely available via PyPI and GitHub.</p>
      <p>For complete details on the use and execution of this protocol, please refer to <xref rid="bib8" ref-type="bibr">Guan et al. (2021)</xref>.</p>
    </abstract>
    <abstract abstract-type="graphical" id="abs0015">
      <title>Graphical abstract</title>
      <fig id="undfig1" position="anchor">
        <graphic xlink:href="fx1"/>
      </fig>
    </abstract>
    <abstract abstract-type="author-highlights" id="abs0020">
      <title>Highlights</title>
      <p>
        <list list-type="simple" id="ulist0010">
          <list-item id="u0010">
            <label>•</label>
            <p id="p0010">Timesisas can predict outcomes from time-series data with excellent performance</p>
          </list-item>
          <list-item id="u0015">
            <label>•</label>
            <p id="p0015">The last few time points can contain adequate information for outcome predictions.</p>
          </list-item>
          <list-item id="u0020">
            <label>•</label>
            <p id="p0020">Missing value patterns contain useful information for outcome predictions</p>
          </list-item>
          <list-item id="u0025">
            <label>•</label>
            <p id="p0025">Timesias provides instant visualization of top features by AI interpretation methods</p>
          </list-item>
        </list>
      </p>
    </abstract>
    <abstract abstract-type="teaser" id="abs0025">
      <p>The prediction of outcomes is a critical part of the clinical surveillance for hospitalized patients. Here, we present Timesias, a machine learning pipeline which predicts outcomes from real-time sequential clinical data. The strategy implemented in Timesias is the first-place solution in the crowd-sourcing DII National Data Science Challenge involving more than 100,000 patients, achieving 0.85 as evaluated by AUC in predicting the early onset of sepsis status. Timesias is freely available via PyPI and GitHub.</p>
    </abstract>
    <kwd-group id="kwrds0010">
      <title>Subject areas</title>
      <kwd>Bioinformatics</kwd>
      <kwd>Health Sciences</kwd>
      <kwd>Clinical Protocol</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec id="sec1">
    <title>Before you begin</title>
    <p id="p0030">The application of digital systems in the clinical system stimulates an exponential growth of Electronic Health Records (EHR) in the last decade, enabling the potential secondary usage of such records to further improve the clinical practice. Outcome prediction from EHR is one of the most interesting topics in the field of clinical informatics and so far has attracted growing efforts in developing algorithms addressing this task (<xref rid="bib4" ref-type="bibr">Che et al., 2016</xref>; <xref rid="bib17" ref-type="bibr">Shickel et al., 2018</xref>; <xref rid="bib5" ref-type="bibr">Dash et al., 2019</xref>; <xref rid="bib12" ref-type="bibr">Liu et al., 2019</xref>; <xref rid="bib14" ref-type="bibr">Morawski et al., 2020</xref>; <xref rid="bib15" ref-type="bibr">Shamout et al., 2021</xref>). More specifically, predicting clinical outcomes from real-time sequential data from clinical surveillance is crucial for preventing sudden outburst of an emergency.</p>
    <p id="p0035">A variety of machine learning models has been drawn in EHR clinical outcome prediction, including mathematical models, such as Linear and Logistic regression (<xref rid="bib7" ref-type="bibr">Generalized Linear Models (GLMs), 2005</xref>; <xref rid="bib3" ref-type="bibr">Chatterjee and Hadi, 2015</xref>). Machine learning models such as SVM and Random Forest have also been used (<xref rid="bib2" ref-type="bibr">Breiman, 2001</xref>). Deep learning models, including Gated Recurrent Units (GRU), LSTM (Long Short-term Memory) Neural Network, CNN (Convolution Neural Network) and Attention Network have also been used to capture the longitudinal information in the time-series records (<xref rid="bib9" ref-type="bibr">Hochreiter and Schmidhuber, 1997</xref>; <xref rid="bib11" ref-type="bibr">LeCun et al., 2015</xref>; <xref rid="bib17" ref-type="bibr">Shickel et al., 2018</xref>). Recently, the light-weight gradient boosting machine, such as LightGBM, has become the top performer in dozens of Data Science challenges. The advantage of LightGBM against the other model is its significant speed in training on large datasets (<xref rid="bib10" ref-type="bibr">Ke et al., 2017</xref>).</p>
    <p id="p0040">One of the biggest challenges for employing EHR data is the unavoidable missing information in the sequential timely records. However, previous observations provided substantial support that the missing values can also convey informative data suggesting patients' health status (<xref rid="bib16" ref-type="bibr">Sharafoddini et al., 2019</xref>). Therefore, besides the temporal changes in health status, the pattern of missing information may further assist the clinical outcome prediction and was taken advantage of by our feature design.</p>
    <p id="p0045">Here we introduce Timesias, a LightGBM machine learning pipeline utilizing time-series EHR data to predict clinical outcomes. Our algorithm, which placed first in the 2019 DII National Data Science Challenge (<xref rid="bib6" ref-type="bibr">DII Challenge, 2019</xref>) and then in the ongoing COVID-19 EHR DREAM Challenge (<xref rid="bib1" ref-type="bibr">Sage Bionetworks, 2020</xref>), is highly versatile and can be easily accommodated to different time-series data inputs. Here we implemented Timesias as a user-friendly command line interface, allowing non-programmers to train predictive machine learning models for their own purpose. Meanwhile, Timesias also allows users to visualize the top ranked features selected by the machine learning models using SHAP analysis (<xref rid="bib13" ref-type="bibr">Lundberg and Lee, 2017</xref>), improving interpretability of the black box models.</p>
    <sec id="sec1.1">
      <title>Software prerequisites and data requirements</title>
      <p id="p0050">Our model is installed and run under the Linux or Mac system. Before launching our program, pre-installed Python (&gt;= v.3.6) and LightGBM (&gt;=v.3.1.1) modules are required. You should also prepare your own timely EHR records with the clinical outcomes of interest. The example of prerequisites and input data format can be found from our GitHub repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/GuanLab/timesias.git" id="intref0010">https://github.com/GuanLab/timesias.git</ext-link>.</p>
      <p id="p0055">While this protocol can be applied to any time-series records, here we describe how to perform our pipeline on the randomly generated time series EHR data in predicting sepsis onset, a binary classification task. Timesias can also be used for multiclass classification or regression tasks.</p>
    </sec>
  </sec>
  <sec id="sec9">
    <title>Key resources table</title>
    <p id="p0410">
      <table-wrap position="float" id="undtbl1">
        <table frame="hsides" rules="groups">
          <thead>
            <tr>
              <th>REAGENT or RESOURCE</th>
              <th>SOURCE</th>
              <th>IDENTIFIER</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td colspan="3">
                <bold>Deposited data</bold>
              </td>
            </tr>
            <tr>
              <td colspan="3">
                <hr/>
              </td>
            </tr>
            <tr>
              <td>example.gs.file</td>
              <td>This paper (mock sepsis diagnosis for 100 patients)</td>
              <td>N/A</td>
            </tr>
            <tr>
              <td>./data/∗.psv</td>
              <td>This paper (mock time series EHR for 100 patients)</td>
              <td>N/A</td>
            </tr>
            <tr>
              <td colspan="3">
                <hr/>
              </td>
            </tr>
            <tr>
              <td colspan="3">
                <bold>Software and algorithms</bold>
              </td>
            </tr>
            <tr>
              <td colspan="3">
                <hr/>
              </td>
            </tr>
            <tr>
              <td>Python (&gt;=3.6)</td>
              <td>Python Software Foundation, 2021: high-level programming language</td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://www.python.org/downloads/release/python-365/" id="intref0040">https://www.python.org/downloads/release/python-365/</ext-link>
              </td>
            </tr>
            <tr>
              <td>numpy (&gt;=1.14.1)</td>
              <td>Community project, 2021: array processing for numbers, strings, records, and objects</td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/numpy/" id="intref0045">https://pypi.org/project/numpy/</ext-link>
              </td>
            </tr>
            <tr>
              <td>scikit-learn (&gt;=0.24.1)</td>
              <td>Original by David Cournapeau as a Google Summer of Code Project 2021: a Python module for machine learning</td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/scikit-learn/" id="intref0050">https://pypi.org/project/scikit-learn/</ext-link>
              </td>
            </tr>
            <tr>
              <td>lightgbm (&gt;=3.1.1)</td>
              <td>Microsoft Corporation, 2020: a gradient boosting framework</td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/lightgbm/" id="intref0055">https://pypi.org/project/lightgbm/</ext-link>
              </td>
            </tr>
            <tr>
              <td>shap (0.35.0)</td>
              <td>Scott Lundberg, 2021: a unified approach to explain the output of any machine learning model.</td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/shap/0.35.0/" id="intref0060">https://pypi.org/project/shap/0.35.0/</ext-link>
              </td>
            </tr>
            <tr>
              <td>bokeh (&gt;=2.3.0)</td>
              <td>Numfocus, 2021: an interactive visualization library for modern web browsers</td>
              <td>
                <ext-link ext-link-type="uri" xlink:href="https://docs.bokeh.org/en/latest/docs/first_steps/installation.html" id="intref0065">https://docs.bokeh.org/en/latest/docs/first_steps/installation.html</ext-link>
              </td>
            </tr>
            <tr>
              <td>Timesias</td>
              <td>This paper</td>
              <td><ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/timesias/" id="intref0070">https://pypi.org/project/timesias/</ext-link> or <ext-link ext-link-type="uri" xlink:href="https://github.com/GuanLab/timesias" id="intref0075">https://github.com/GuanLab/timesias</ext-link></td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </p>
  </sec>
  <sec id="sec2">
    <title>Materials and equipment</title>
    <p id="p0060">The program in this protocol was written in the Ubuntu Linux system using Python language (&gt;=v.3.6). All experiments were carried out and evaluated under the Ubuntu system with the computational resources listed in <xref rid="tbl1" ref-type="table">Table 1</xref>.<disp-quote><p><inline-graphic xlink:href="fx2.gif"/><bold>CRITICAL:</bold> The implementation of the model is light weight. However, the required memory usage in practice depends on the size of your own data.</p></disp-quote><disp-quote><p><bold><italic>Alternatives:</italic></bold> 1. Our model can work with fewer CPU cores and less RAM memory, although it may take longer time for a large dataset. 2. This model can also be run and tested on MacOS system (Version 10.15.7)</p></disp-quote><table-wrap position="float" id="tbl1"><label>Table 1</label><caption><p>Computation resources used in this study</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Operating system</th><th>Version</th></tr></thead><tbody><tr><td>Ubuntu</td><td>18.04.2 (Bionic Beaver)</td></tr></tbody></table><table frame="hsides" rules="groups"><thead><tr><th>CPU information</th><th>Parameter</th></tr></thead><tbody><tr><td>RAM Memory</td><td>503GB</td></tr><tr><td>Total number of cores</td><td>40</td></tr><tr><td>Processor speed</td><td>2.40 GHz</td></tr></tbody></table></table-wrap></p>
  </sec>
  <sec id="sec3">
    <title>Step-by-step method details</title>
    <sec id="sec3.1">
      <title>Download our package and install the prerequisites</title>
      <p id="p0065">
        <disp-quote>
          <p>
            <inline-graphic xlink:href="fx3.gif"/>
            <bold>Timing: &lt;</bold>
            <bold>5</bold>
            <bold>min</bold>
          </p>
        </disp-quote>
        <list list-type="simple" id="olist0010">
          <list-item id="o0010">
            <label>1.</label>
            <p id="p0070">install the latest version of Timesias via pip:<list list-type="simple" id="ulist0015"><list-item id="u0030"><p id="p0075">pip install timesias</p><p id="p0080">or clone the whole package from our GitHub repository using the following command to your local directory using the following command (<xref rid="fig1" ref-type="fig">Figure 1</xref>):<fig id="fig1"><label>Figure 1</label><caption><p>Model installation from GitHub and the required dependencies</p></caption><graphic xlink:href="gr1"/></fig></p></list-item><list-item id="u0035"><p id="p0085">git clone <ext-link ext-link-type="uri" xlink:href="https://github.com/GuanLab/timesias.git" id="intref0015">https://github.com/GuanLab/timesias.git</ext-link></p></list-item></list></p>
          </list-item>
        </list>
        <disp-quote>
          <p><inline-graphic xlink:href="fx2.gif"/><bold>CRITICAL:</bold> check if all required dependencies listed in <xref rid="sec9" ref-type="sec">key resources table</xref> are correctly downloaded and installed. Originally, installing Timesias via pip will automatically check for and install the required dependencies. However, errors during installation could occur when installing on computational environments (<xref rid="sec7.1" ref-type="sec">Troubleshooting 1</xref>).</p>
        </disp-quote>
      </p>
    </sec>
    <sec id="sec3.2">
      <title>Prepare data</title>
      <p id="p0090">
        <disp-quote>
          <p>
            <inline-graphic xlink:href="fx3.gif"/>
            <bold>Timing: &lt;</bold>
            <bold>10</bold>
            <bold>min</bold>
          </p>
        </disp-quote>
      </p>
      <p id="p0095">Two types of data should be prepared for model training and prediction: 1) gold standard file, which contains the names of the record file from patients and the corresponding gold standard (clinical outcome of that patient). 2) time-series records files, which are “|” delimited time series records. The two types of data mentioned above should follow the following formats:<list list-type="simple" id="olist0015"><list-item id="o0015"><label>2.</label><p id="p0100">Gold standard file (for example: example.gs.file): a ‘,’ delimited table with two columns. Each row in the gold standard file represents a sample. The details of gold standard file are described below (<xref rid="tbl2" ref-type="table">Table 2</xref>):<list list-type="simple" id="olist0020"><list-item id="o0020"><label>a.</label><p id="p0105">first column: path of the time-series record files. the details of the time-series record files which will be detailed later.</p></list-item><list-item id="o0025"><label>b.</label><p id="p0110">The second column: gold standard, or label for the time-series record files. In the example data, we use binary label 1/0 to indicate failure/survival, which is the status of sepsis onset of the patients.</p></list-item></list><table-wrap position="float" id="tbl2"><label>Table 2</label><caption><p>Example data format for gold standard file</p></caption><table frame="hsides" rules="groups"><thead><tr><th>./Data/0.psv</th><th>0</th></tr></thead><tbody><tr><td>./data/1.psv</td><td>1</td></tr><tr><td>...</td><td>…</td></tr><tr><td>./data/n.psv</td><td>0</td></tr></tbody></table></table-wrap></p></list-item><list-item id="o0030"><label>3.</label><p id="p0115">Record files (for example: ∗.psv): “|” delimited time series records. The record files should be corresponding to the first column in the gold standard file, which are the time-series records for each individual sample/patient. Each individual sample should have one record file. The record file should be in the following format (<xref rid="tbl3" ref-type="table">Table 3</xref>):<list list-type="simple" id="olist0025"><list-item id="o0035"><label>a.</label><p id="p0120">The first row, or the header: the clinical measurements (Features). The first header should be the time point, and from the second column to the end, the header should be the clinical measurements recorded at each time point.</p></list-item><list-item id="o0040"><label>b.</label><p id="p0125">The first column, or the row names: the exact time points in ascending order.</p></list-item><list-item id="o0045"><label>c.</label><p id="p0130">From the second column to the last, the values should be the observed values for each clinical measurement at the nth time point.</p></list-item></list><table-wrap position="float" id="tbl3"><label>Table 3</label><caption><p>Example data format for time-series record file</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Time point</th><th>Feature 1</th><th>Feature 2</th><th>… …</th><th>Feature 4</th><th>Feature 5</th><th>… …</th></tr></thead><tbody><tr><td>1</td><td/><td/><td/><td/><td/><td/></tr><tr><td>2</td><td/><td/><td/><td/><td/><td/></tr><tr><td colspan="7">………</td></tr><tr><td>N</td><td/><td/><td/><td/><td/><td/></tr></tbody></table></table-wrap></p></list-item></list></p>
      <p id="p0135">It is worth noting that, for some time points, some features might be missing. Therefore, it is recommended that researchers fill the missing values as ‘NaN’ instead of leaving them blank. The demonstrated datasets can be found in our Timesias GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/GuanLab/timesias/tree/master/data" id="intref0020">https://github.com/GuanLab/timesias/tree/master/data</ext-link>).<disp-quote><p><inline-graphic xlink:href="fx2.gif"/><bold>CRITICAL:</bold> 1. Both types of datasets should follow the format described above. 2. Make sure that the first column in the gold standard file matches the file name of the records. Namely, the total number of rows in the gold standard file is always equal to the total number of records.</p></disp-quote></p>
    </sec>
    <sec id="sec3.3">
      <title>Train models, evaluate results, and visualize top features</title>
      <p id="p0140">
        <disp-quote>
          <p>
            <inline-graphic xlink:href="fx3.gif"/>
            <bold>Timing: ∼0.5 h (depending on your data)</bold>
          </p>
        </disp-quote>
      </p>
      <p id="p0145">Our package provides a one-line command to perform feature construction, model training and five-fold cross-validation at the same time, followed by the SHAP analysis with a visualization report of top contributing features (<xref rid="fig2" ref-type="fig">Figure 2</xref>).<list list-type="simple" id="olist0030"><list-item id="o0050"><label>4.</label><p id="p0150">To start training the LightGBM regression model, five-fold cross-validation and top feature analysis on your data, simply run the following command: timesias -g [GS_FILE_PATH] -t [LAST_N_RECORDS] -f [EXTRA_FEATURES] -e [EVA_METRICS] --shap</p><p id="p0155">The arguments are defined as follows:<list list-type="simple" id="olist0035"><list-item id="o0055"><label>a.</label><p id="p0160">-g [GS_FILE_PATH]: the path to the gold standard file (example.gs.file) you prepared in step 2.</p></list-item><list-item id="o0060"><label>b.</label><p id="p0165">-t [LAST_N_RECORDS]: the last n records you want to use for prediction, default is 16.<disp-quote><p><bold><italic>Note:</italic></bold> The missing values contain critical information for outcome predictions. Here we introduce a specific feature construction method implemented in Timesias to preserve the missing value information (<xref rid="fig3" ref-type="fig">Figure3</xref>). First, for each feature in a certain time point, we add an additional value to annotate the binary status if it is missing or not (1/0). This will double the total number of features in the matrix. For example, if we use the last <inline-formula><mml:math id="M1" altimg="si1.gif"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> time points of the record of <inline-formula><mml:math id="M2" altimg="si2.gif"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> features, the original feature matrix would be an <inline-formula><mml:math id="M3" altimg="si3.gif"><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> matrix. After the missing value annotation step, the processed feature matrix will be <inline-formula><mml:math id="M4" altimg="si4.gif"><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mn>2</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>. At the same time, the missing values in the original feature matrix will be replaced by an arbitrary constant, here we set it to ‘−3000’ as default. As we have designated a fixed length <inline-formula><mml:math id="M5" altimg="si5.gif"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> for all timely records by using the argument -t [LAST_N_RECORDS], if the provided record (with <inline-formula><mml:math id="M6" altimg="si1.gif"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula> timepoints) is shorter than <inline-formula><mml:math id="M7" altimg="si5.gif"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>, we will fill the missing earliest timepoints of the original record with another arbitrary constant. Here we use ‘−5000’ as default. Otherwise, the record will be cropped to the last <inline-formula><mml:math id="M8" altimg="si5.gif"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>timepoints. The replacement values of the above missing information can also be changed according to your own data (<xref rid="sec7.3" ref-type="sec">Troubleshooting 2</xref>). The above are the feature preprocessing step, which generates a <inline-formula><mml:math id="M9" altimg="si6.gif"><mml:mrow><mml:mi>n</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mn>2</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> matrix, from which extra features can be generated as described next.</p></disp-quote></p></list-item><list-item id="o0065"><label>c.</label><p id="p0170">-f [EXTRA_FEATURES]: additional features you want to include for prediction. We provide four additional features to construct based on your original data: <bold>norm</bold>, <bold>std</bold>, <bold>missing portion</bold> and <bold>baseline.</bold></p><p id="p0175"><disp-quote><p><bold><italic>Note:</italic></bold> These additional features will capture the temporal changes as well as the patterns of missing values in the timely records. The details of the extra features are described here:</p></disp-quote><fig id="fig3"><label>Figure 3</label><caption><p>Overview of the feature construction process</p><p>First, the missing information will be replaced by different replacement values (for missing feature values (gray), replace with −3000; for missing timepoints (green), replace with −5000). Then we compute four types of characteristics for each feature: ‘std’, ‘norm’, ‘missing portion’ and ‘baseline’. Then the final feature matrix will be generated by concatenating all generated features together.</p></caption><graphic xlink:href="gr3"/></fig></p><p id="p0180">1) ‘norm’: normalized feature values. For each column <inline-formula><mml:math id="M10" altimg="si7.gif"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:math></inline-formula> in the <inline-formula><mml:math id="M11" altimg="si6.gif"><mml:mrow><mml:mi>n</mml:mi><mml:mo linebreak="goodbreak" linebreakstyle="after">×</mml:mo><mml:mn>2</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> matrix, we calculate the mean and standard deviation across all rows. The normed new feature value <inline-formula><mml:math id="M12" altimg="si8.gif"><mml:mrow><mml:mi>f</mml:mi><mml:msub><mml:mo>′</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> will be<disp-formula id="ufd1"><mml:math id="M13" altimg="si9.gif"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mfrac><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mo linebreak="goodbreak">∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo linebreak="goodbreak">∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mn>2</mml:mn><mml:mi>j</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="M14" altimg="si10.gif"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>is value of the <inline-formula><mml:math id="M15" altimg="si11.gif"><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:math></inline-formula>th timepoint in the <inline-formula><mml:math id="M16" altimg="si7.gif"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:math></inline-formula> th column, <inline-formula><mml:math id="M17" altimg="si12.gif"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>is the mean for the <inline-formula><mml:math id="M18" altimg="si7.gif"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:math></inline-formula> th column through the timeline; <inline-formula><mml:math id="M19" altimg="si13.gif"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the standard deviation for the <inline-formula><mml:math id="M20" altimg="si7.gif"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:math></inline-formula> th column through the timeline; <inline-formula><mml:math id="M21" altimg="si5.gif"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>: total number of time points; and <inline-formula><mml:math id="M22" altimg="si2.gif"><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula> is the total number of features.</p><p id="p0185">2) ‘std’: as mentioned above, is the standard deviation (<inline-formula><mml:math id="M23" altimg="si14.gif"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:math></inline-formula>) of each feature throughout the whole time-course:<disp-formula id="ufd2"><mml:math id="M24" altimg="si15.gif"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>n</mml:mi></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo linebreak="badbreak">−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mi>n</mml:mi></mml:mfrac></mml:msqrt><mml:mi>p</mml:mi><mml:mo linebreak="goodbreak">∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo linebreak="goodbreak">∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>..2</mml:mn><mml:mi>j</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="M25" altimg="si10.gif"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the value of the <inline-formula><mml:math id="M26" altimg="si11.gif"><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:math></inline-formula>th feature in the <inline-formula><mml:math id="M27" altimg="si7.gif"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:math></inline-formula> th column; is mean for the <inline-formula><mml:math id="M28" altimg="si7.gif"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:math></inline-formula> th feature through the timeline; and <inline-formula><mml:math id="M29" altimg="si5.gif"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula> is the total number of time points.</p><p id="p0190">3) ‘missing portion’: the percentage of missing points for each feature, which is calculated as:<disp-formula id="ufd3"><mml:math id="M30" altimg="si16.gif"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi mathvariant="italic">sin</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="M31" altimg="si17.gif"><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the number of missing values of the <inline-formula><mml:math id="M32" altimg="si7.gif"><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:math></inline-formula> th feature.</p><p id="p0195">4) ‘baseline’: for each feature, we record the earliest time point for each feature to be collected and the corresponding feature value.</p></list-item><list-item id="o0070"><label>d.</label><p id="p0200">-e [EVA_METRICS]: evaluation metrics you choose. Our program primarily provides five options: AUROC, AUPRC, C-index, Spearman’s r and Pearson’s r, which are used for different prediction tasks (binary/multiclass classification and regression). The details for the above metrics are described in <xref rid="sec5" ref-type="sec">Quantification and Statistical Analysis</xref>.</p></list-item><list-item id="o0075"><label>e.</label><p id="p0205">--shap: an optional argument. If used, SHAP analysis (<xref rid="bib13" ref-type="bibr">Lundberg and Lee, 2017</xref>) will be carried out, using the trained model from five-fold cross-validation on the test set to visualize the top measurements and time points.</p></list-item></list></p></list-item></list><disp-quote><p><bold><italic>Note:</italic></bold> Our program also provides an option to analyze the top features by SHAP analysis by using the --shap argument. If additional features were constructed from the original features, we group the corresponding values of the original feature to analyze its overall importance. According to the additivity of SHAP values, the grouped SHAP values of features and time points can be computed following the formula below:</p></disp-quote><disp-formula id="ufd4"><mml:math id="M33" altimg="si18.gif"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>X</mml:mi></mml:msub><mml:mo linebreak="badbreak">=</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo linebreak="badbreak">∈</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>S</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <italic>X</italic> is all features of interests. For example, if we want to know the aggregated SHAP importance of the last 6th time point, <inline-formula><mml:math id="M34" altimg="si19.gif"><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:math></inline-formula>can be all features from the last 6th timepoint. The top features (clinical measurements and timepoints) are visualized in bar graphs.<fig id="fig2"><label>Figure 2</label><caption><p>The workflow of the main program using a one-line command</p><p>This includes model training, validation and SHAP analysis.</p></caption><graphic xlink:href="gr2"/></fig></p>
      <p id="p0210">Then the program will start training the prediction model using the arguments you specified. When model training is finished, the models will be automatically saved to ‘./model’, and the evaluation on the test set will be automatically performed. Also, if --shap is used, the program will start SHAP analysis after prediction performance evaluation.<disp-quote><p><inline-graphic xlink:href="fx2.gif"/><bold>CRITICAL:</bold> 1. To successfully run through the model training and cross-validation process, make sure the gold standard file path (-g) is correct (<xref rid="sec7.5" ref-type="sec">Troubleshooting 3</xref>). Also, check if the time-series records are correctly formatted. Problems with time-series records could lead to aborted programs (See <xref rid="sec7.7" ref-type="sec">Troubleshooting 4</xref> and <xref rid="sec7.9" ref-type="sec">Troubleshooting 5</xref>). Additionally, we require all feature values in the time-series data to be numeric, and categorical features need to be encoded in advance (See <xref rid="sec7.11" ref-type="sec">Troubleshooting 6</xref>). 2. The default length of the last n records (-t) is 16. However, the choice of -t can affect the model performance, CPU occupancy and training time. We recommend different trials of -t for a proper choice (See <xref rid="sec7.13" ref-type="sec">Troubleshooting 7</xref>). 3. While the default settings of the hyperparameters of the LightGBM models are the same as the winning algorithm in the DII Data Science Challenge, we also encourage the users to adjust the model hyperparameters in respect to their own dataset (See <xref rid="sec7.15" ref-type="sec">Troubleshooting 8</xref>). 4. While the example only presents the prediction of binary outcomes, our model also can take continuous values as gold standards. However, suitable evaluation metrics should be selected per prediction task. For example, in the demonstrated binary classification task, AUROC and AUPRC were selected. For regression tasks, C-index, Pearson’s correlation or Spearman’s correlation can be used. The users can also use their own customized evaluation metrics on the prediction results by modifying the code in statistics.py (<ext-link ext-link-type="uri" xlink:href="https://github.com/GuanLab/timesias/blob/master/src/statistics.py" id="intref0025">https://github.com/GuanLab/timesias/blob/master/src/statistics.py</ext-link>).</p></disp-quote></p>
    </sec>
  </sec>
  <sec id="sec4">
    <title>Expected outcomes</title>
    <p id="p0215">The above command will generate the following results from your training data: Saved models: five models resulting from five-fold cross-validation will be saved in ./models/finalized_model.sav.∗ and can reload by the standard <italic>pickle</italic> module in Python. Evaluation results (e.g., AUROC and AUPRC) from five-fold cross validation, which will be saved in ‘./results/eva.tsv’.</p>
    <p id="p0220">if --shap is specified, results from SHAP analysis will be stored in the following files: ‘./results/shap_group_by_measurment.csv’: Feature importance of all measurements resulted from SHAP analysis using the five models in five-fold cross-validation; ‘./results/shap_group_by_timeslot.csv’: Feature importance of all time points resulted from SHAP analysis using the five models in five-fold cross-validation;‘./results/top_feature_report.html’: the top features (measurements and timepoints) visualized in bar graphs (<xref rid="fig4" ref-type="fig">Figure 4</xref>).<fig id="fig4"><label>Figure 4</label><caption><p>Results from SHAP analysis shows the top 50 measurements (upper panel) and time points (lower panel) for outcome prediction</p><p>The top measurements and timepoints were ordered by the average of absolute shap values for all five models generated by five fold cross validations.</p></caption><graphic xlink:href="gr4"/></fig></p>
  </sec>
  <sec id="sec5">
    <title>Quantification and statistical analysis</title>
    <p id="p0225">Timesias provide the following matrices to evaluate the model performance, which can be specified using -e argument:<list list-type="simple" id="olist0040"><list-item id="o0080"><label>1.</label><p id="p0230">AUROC (Area under the Receiver Operating Characteristics curve): The ROC plots the false positive rate (FPR) versus the true positive rate (TPR), where:</p></list-item></list><disp-formula id="ufd5"><mml:math id="M35" altimg="si20.gif"><mml:mrow><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="goodbreak">−</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="ufd6"><mml:math id="M36" altimg="si21.gif"><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
    <p id="p0235">TP: True Positive; TN: True Negative; FP: False Positive; FN: False Negative.</p>
    <p id="p0240">Generally, an AUROC of 0.5 indicates random prediction (no signal) and 1 indicates perfect prediction.<list list-type="simple" id="olist0045"><list-item id="o0085"><label>2.</label><p id="p0245">AUPRC (Area under the precision-recall curve): The PR curve plots <italic>precisions</italic> versus <italic>recall</italic>, where:</p></list-item></list><disp-formula id="ufd7"><mml:math id="M37" altimg="si22.gif"><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula><disp-formula id="ufd8"><mml:math id="M38" altimg="si23.gif"><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mi>R</mml:mi><mml:mo linebreak="goodbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo linebreak="badbreak">+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
    <p id="p0250">The expected value of AUPRC is the proportion of true positive cases in the dataset.<list list-type="simple" id="olist0050"><list-item id="o0090"><label>3.</label><p id="p0255">C-index (Harrell’s C-index, or Concordance index): It is the generalization of AUROC into censored data. C-index can be calculated using the following formula:</p></list-item></list><disp-formula id="ufd9"><mml:math id="M39" altimg="si24.gif"><mml:mrow><mml:mi>c</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">&lt;</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">&gt;</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo linebreak="badbreak">≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo linebreak="badbreak">&gt;</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
    <p id="p0260"><inline-formula><mml:math id="M40" altimg="si25.gif"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: prediction value, or predicted risk of disease of sample</p>
    <p id="p0430"><inline-formula><mml:math id="M41" altimg="si26.gif"><mml:mrow><mml:mspace width="0.25em"/><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="M42" altimg="si27.gif"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: gold standard, or survival time, of sample</p>
    <p id="p0435"><inline-formula><mml:math id="M43" altimg="si26.gif"><mml:mrow><mml:mspace width="0.25em"/><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="M44" altimg="si28.gif"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: an auxiliary variable indicating whether sample<inline-formula><mml:math id="M45" altimg="si29.gif"><mml:mrow><mml:mspace width="0.25em"/><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>is censored. if uncensored, <inline-formula><mml:math id="M46" altimg="si28.gif"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>is 1; else 0.</p>
    <p id="p0265">C-index = 0.5 represents random and 1 represents perfect prediction.<list list-type="simple" id="olist0055"><list-item id="o0095"><label>4.</label><p id="p0270">Pearson’s r (Pearson’s correlation coefficient): which evaluates the linear correlation between the prediction value and gold standards:</p></list-item></list><disp-formula id="ufd10"><mml:math id="M47" altimg="si30.gif"><mml:mrow><mml:mi>r</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">−</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">−</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:msqrt><mml:mrow><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">−</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo linebreak="badbreak">−</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
    <p id="p0275"><inline-formula><mml:math id="M48" altimg="si31.gif"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: prediction value of sample</p>
    <p id="p0440"><inline-formula><mml:math id="M49" altimg="si1.gif"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="M50" altimg="si32.gif"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>: average of all prediction values</p>
    <p id="p0280"><inline-formula><mml:math id="M51" altimg="si33.gif"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: gold standard of sample</p>
    <p id="p0445"><inline-formula><mml:math id="M52" altimg="si1.gif"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="M53" altimg="si34.gif"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>: average of all gold standard valueswhere Pearson’s r = 0 represents random and 1 represents perfect predictions.<list list-type="simple" id="olist0060"><list-item id="o0100"><label>5.</label><p id="p0285">Spearman’s r (Pearson’s correlation coefficient): which evaluates the ranked correlation between the prediction value and gold standards:</p></list-item></list><disp-formula id="ufd11"><mml:math id="M54" altimg="si35.gif"><mml:mrow><mml:mi>r</mml:mi><mml:mo linebreak="badbreak">=</mml:mo><mml:mn>1</mml:mn><mml:mo linebreak="goodbreak">−</mml:mo><mml:mfrac><mml:mrow><mml:mn>6</mml:mn><mml:mo>∑</mml:mo><mml:msubsup><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo linebreak="badbreak">−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p>
    <p id="p0290"><inline-formula><mml:math id="M55" altimg="si36.gif"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>: difference between the ranks of prediction and gold standard in sample</p>
    <p id="p0450"><inline-formula><mml:math id="M56" altimg="si1.gif"><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="M57" altimg="si5.gif"><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>: number of observationswhere Spearman’s r = 0 represents random and 1 represents perfect predictions.</p>
    <p id="p0295">Among the above, AUROC and AUPRC can be used for binary classification problems, and C-index, Pearson’s r and Spearman’s r can be used for regression problems. The users can also implement other customized evaluation metrics.</p>
  </sec>
  <sec id="sec6">
    <title>Limitations</title>
    <p id="p0300">One possible limitation of Timesias is the memory usage. After filling all missing values, the feature matrices will increase to more than twice of the original input, depending on how many time points you decided to use (<xref rid="fig3" ref-type="fig">Figure 3</xref>). Additionally, when using the full set of features (norm, std, missing portion, baseline), the feature number will also increase. Therefore, when there are many samples (for example, in the DII National Data Science Challenge, the training data could be up to ∼100, 000 samples), the CPU memory could be a potential limitation of our method.</p>
  </sec>
  <sec id="sec7">
    <title>Troubleshooting</title>
    <sec id="sec7.1">
      <title>Problem 1</title>
      <p id="p0305">Installation of Timesias fails due to uninstalled prerequisites (step 1).</p>
    </sec>
    <sec id="sec7.2">
      <title>Potential solution</title>
      <p id="p0310">Please install the required dependencies manually through the links we provided in <xref rid="sec9" ref-type="sec">key resources table</xref>, and then try installing Timesias again.</p>
    </sec>
    <sec id="sec7.3">
      <title>Problem 2</title>
      <p id="p0315">Different missing value replacement could affect the prediction performance. In our default setting, the missing feature values are replaced with −3000 and the missing timepoints are replaced with −5000. Difference replacement values may have a significant influence on the prediction accuracy (<xref rid="tbl4" ref-type="table">Table 4</xref>). (step 4)<table-wrap position="float" id="tbl4"><label>Table 4</label><caption><p>Prediction performance (AUROC) with different replacements for missing feature value and timepoints on the toy data</p></caption><table frame="hsides" rules="groups"><thead><tr><th>MIssing feature replacement</th><th>Time point replacement</th><th>AUROC</th><th>AUPRC</th></tr></thead><tbody><tr><td>−3000</td><td>−5000</td><td>0.6484</td><td>0.7699</td></tr><tr><td>−5000</td><td>−5000</td><td>0.6484</td><td>0.7699</td></tr><tr><td>−5000</td><td>−3000</td><td>0.6484</td><td>0.7699</td></tr><tr><td>−1000</td><td>−1000</td><td>0.6484</td><td>0.7699</td></tr><tr><td>−100</td><td>−100</td><td>0.6153</td><td>0.7267</td></tr><tr><td>100</td><td>100</td><td>0.5826</td><td>0.7490</td></tr><tr><td>3000</td><td>5000</td><td>0.6044</td><td>0.7626</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="sec7.4">
      <title>Potential solution</title>
      <p id="p0320">Use other replacement values for missing feature value replacement and missing time point replacement. To change missing value/timepoint replacement, in utils.py, assign val_rep/t_rep with other values you would like instead of −3000 and −5000 (<xref rid="fig5" ref-type="fig">Figure 5</xref>).<fig id="fig5"><label>Figure 5</label><caption><p>Default missing value settings for missing record values (val_rep) and missing timepoints (t_rep)</p></caption><graphic xlink:href="gr5"/></fig></p>
      <p id="p0325">Usually, the replacement values should be lower than the lowest feature value. Also, we recommend that val_rep and t_rep not be equal to retain more information in the dataset.</p>
    </sec>
    <sec id="sec7.5">
      <title>Problem 3</title>
      <p id="p0330">The program will check if the gold standard file exists. If not, the program will halt and print the following information in the terminal (<xref rid="fig6" ref-type="fig">Figure 6</xref>). (step 4)<fig id="fig6"><label>Figure 6</label><caption><p>Screenshot of the terminal if the gold standard file path is wrong</p></caption><graphic xlink:href="gr6"/></fig></p>
    </sec>
    <sec id="sec7.6">
      <title>Potential solution</title>
      <p id="p0335">Check if the gold standard file path (-g) is correct.</p>
    </sec>
    <sec id="sec7.7">
      <title>Problem 4</title>
      <p id="p0340">If the program fails to read the time-series records, the terminal prints out the following assertion error (<xref rid="fig7" ref-type="fig">Figure 7</xref>). (step 4)<fig id="fig7"><label>Figure 7</label><caption><p>Screenshot of the terminal if the time-series file doesn’t exist</p></caption><graphic xlink:href="gr7"/></fig></p>
      <p id="p0345">It means the file path of the time series records are wrong (∗.psv file).</p>
    </sec>
    <sec id="sec7.8">
      <title>Potential solution</title>
      <p id="p0350">Check if the training record paths (first column) listed in the gold standard file are correct.</p>
    </sec>
    <sec id="sec7.9">
      <title>Problem 5</title>
      <p id="p0355">If the time-series record file is empty, the following errors could be raised (<xref rid="fig8" ref-type="fig">Figure 8</xref>). (step 4)<fig id="fig8"><label>Figure 8</label><caption><p>Screenshot of the terminal if the time-series file is empty</p></caption><graphic xlink:href="gr8"/></fig></p>
    </sec>
    <sec id="sec7.10">
      <title>Potential solution</title>
      <p id="p0360">Check the file in the training data, and exclude it from the training data if it is not available.</p>
    </sec>
    <sec id="sec7.11">
      <title>Problem 6</title>
      <p id="p0365">Feature value error. We assume all feature values used for prediction should be numeric. However, if the feature value is a string, the following error could occur (<xref rid="fig9" ref-type="fig">Figure 9</xref>). (step 4)<fig id="fig9"><label>Figure 9</label><caption><p>Screenshot of the terminal when there are categorical features in the time-series data</p></caption><graphic xlink:href="gr9"/></fig></p>
    </sec>
    <sec id="sec7.12">
      <title>Potential solution</title>
      <p id="p0370">If categorical features are used, you can encode them as numeric values before training with our program.</p>
    </sec>
    <sec id="sec7.13">
      <title>Problem 7</title>
      <p id="p0375">While the default value of -t is 16, usually a larger -t could retain more information, while increasing CPU usage and training time correspondingly. We plot the memory (CPU) and time versus last n point using the deposited data (100 samples) (<xref rid="fig10" ref-type="fig">Figure 10</xref>). (step 4)<fig id="fig10"><label>Figure 10</label><caption><p>The relationship between the number of time point selected and time/CPU occupancy required</p></caption><graphic xlink:href="gr10"/></fig></p>
    </sec>
    <sec id="sec7.14">
      <title>Potential solution</title>
      <p id="p0380">Choose a proper number for -t. We also encourage the users to try different -t and compare the performance/resource requirements for a most preferred choice.</p>
    </sec>
    <sec id="sec7.15">
      <title>Problem 8</title>
      <p id="p0385">We also encourage the users to tune the hyperparameters of the LightGBM model for better performance. The default parameters for the LightGBM regression model are set as <xref rid="fig11" ref-type="fig">Figure 11</xref> and default boosting round is set to 1000. However, the default setting may not be optimal for variable datasets. (step 4)<fig id="fig11"><label>Figure 11</label><caption><p>Default parameter settings in the LightGBM model</p></caption><graphic xlink:href="gr11"/></fig></p>
    </sec>
    <sec id="sec7.16">
      <title>Potential solution</title>
      <p id="p0390">The model parameters in model.py can be modified. If the model overfits, choose smaller ‘num_leaves’ and ‘n_estimator’ and smaller boosting rounds. If the model underfits, choose larger ‘num_leaves’ and ‘n_estimator’ and larger boosting rounds. Larger ‘learning_rate’ could speed up the training process while a smaller ‘learning_rate’ with larger boosting rounds may help achieve better prediction accuracy.</p>
    </sec>
  </sec>
  <sec id="sec8">
    <title>Resource availability</title>
    <sec id="sec8.1">
      <title>Lead contact</title>
      <p id="p0395">Further information and requests for resources and reagents should be directed to and will be fulfilled by the lead contact, Yuanfang Guan (<ext-link ext-link-type="uri" xlink:href="mailto:gyuanfan@umich.edu" id="intref0030">gyuanfan@umich.edu</ext-link>).</p>
    </sec>
    <sec id="sec8.2">
      <title>Materials availability</title>
      <p id="p0400">This study did not generate new unique reagents.</p>
    </sec>
    <sec sec-type="data-availability" id="sec8.3">
      <title>Data and code availability</title>
      <p id="p0405">The code generated in this study is available at [<ext-link ext-link-type="uri" xlink:href="https://github.com/GuanLab/timesias" id="intref0035">https://github.com/GuanLab/timesias</ext-link>]. The mock dataset used for display in this paper is deposited to and available at [<ext-link ext-link-type="uri" xlink:href="https://github.com/GuanLab/timesias/tree/master/data" id="interref0010">https://github.com/GuanLab/timesias/tree/master/data</ext-link>].</p>
    </sec>
  </sec>
</body>
<back>
  <ref-list id="cebib0010">
    <title>References</title>
    <ref id="bib2">
      <element-citation publication-type="journal" id="sref2">
        <person-group person-group-type="author">
          <name>
            <surname>Breiman</surname>
            <given-names>L.</given-names>
          </name>
        </person-group>
        <article-title>Random forests</article-title>
        <source>Mach. Learn.</source>
        <volume>45</volume>
        <year>2001</year>
        <fpage>5</fpage>
        <lpage>32</lpage>
      </element-citation>
    </ref>
    <ref id="bib3">
      <element-citation publication-type="book" id="sref3">
        <person-group person-group-type="author">
          <name>
            <surname>Chatterjee</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Hadi</surname>
            <given-names>A.S.</given-names>
          </name>
        </person-group>
        <chapter-title>Regression Analysis by Example</chapter-title>
        <year>2015</year>
        <publisher-name>John Wiley &amp; Sons</publisher-name>
      </element-citation>
    </ref>
    <ref id="bib4">
      <element-citation publication-type="journal" id="sref4">
        <person-group person-group-type="author">
          <name>
            <surname>Che</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Purushotham</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Khemani</surname>
            <given-names>R.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y.</given-names>
          </name>
        </person-group>
        <article-title>Interpretable deep models for ICU outcome prediction</article-title>
        <source>AMIA Annu. Symp. Proc.</source>
        <volume>2016</volume>
        <year>2016</year>
        <fpage>371</fpage>
        <lpage>380</lpage>
        <pub-id pub-id-type="pmid">28269832</pub-id>
      </element-citation>
    </ref>
    <ref id="bib5">
      <element-citation publication-type="book" id="sref5">
        <person-group person-group-type="author">
          <name>
            <surname>Dash</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Acharya</surname>
            <given-names>B.R.</given-names>
          </name>
          <name>
            <surname>Mittal</surname>
            <given-names>M.</given-names>
          </name>
          <name>
            <surname>Abraham</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Kelemen</surname>
            <given-names>A.</given-names>
          </name>
        </person-group>
        <chapter-title>Deep Learning Techniques for Biomedical and Health Informatics</chapter-title>
        <year>2019</year>
        <publisher-name>Springer Nature</publisher-name>
      </element-citation>
    </ref>
    <ref id="bib6">
      <element-citation publication-type="other" id="sref6">
        <person-group person-group-type="author">
          <collab>DII Challenge</collab>
        </person-group>
        <ext-link ext-link-type="uri" xlink:href="https://sbmi.uth.edu/dii-challenge/index-new.htm" id="interref0015">https://sbmi.uth.edu/dii-challenge/index-new.htm</ext-link>
        <year>2019</year>
      </element-citation>
    </ref>
    <ref id="bib7">
      <mixed-citation publication-type="other" id="sref7">Generalized Linear Models (GLMs) (2005) Generalized, linear, and mixed models, pp. 135–155. <pub-id pub-id-type="doi">10.1002/0471722073.ch5</pub-id>.</mixed-citation>
    </ref>
    <ref id="bib8">
      <element-citation publication-type="journal" id="sref8">
        <person-group person-group-type="author">
          <name>
            <surname>Guan</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>X.</given-names>
          </name>
          <name>
            <surname>Yi</surname>
            <given-names>D.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>X.</given-names>
          </name>
        </person-group>
        <article-title>Assessment of the timeliness and robustness for predicting adult sepsis</article-title>
        <source>iScience</source>
        <volume>24</volume>
        <year>2021</year>
        <fpage>102106</fpage>
        <pub-id pub-id-type="pmid">33659874</pub-id>
      </element-citation>
    </ref>
    <ref id="bib9">
      <element-citation publication-type="journal" id="sref9">
        <person-group person-group-type="author">
          <name>
            <surname>Hochreiter</surname>
            <given-names>S.</given-names>
          </name>
          <name>
            <surname>Schmidhuber</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>Long short-term memory</article-title>
        <source>Neural Comput.</source>
        <volume>9</volume>
        <year>1997</year>
        <fpage>1735</fpage>
        <lpage>1780</lpage>
        <pub-id pub-id-type="pmid">9377276</pub-id>
      </element-citation>
    </ref>
    <ref id="bib10">
      <element-citation publication-type="book" id="sref10">
        <person-group person-group-type="author">
          <name>
            <surname>Ke</surname>
            <given-names>G.</given-names>
          </name>
          <name>
            <surname>Menge</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Finley</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>W.</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>Q.</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>T.</given-names>
          </name>
        </person-group>
        <chapter-title>LightGBM: A Highly Efficient Gradient Boosting Decision Tree</chapter-title>
        <person-group person-group-type="editor">
          <name>
            <surname>Guyon</surname>
            <given-names>I.</given-names>
          </name>
        </person-group>
        <source>Advances in Neural Information Processing Systems 30</source>
        <year>2017</year>
        <publisher-name>Curran Associates, Inc.</publisher-name>
        <fpage>3146</fpage>
        <lpage>3154</lpage>
      </element-citation>
    </ref>
    <ref id="bib11">
      <element-citation publication-type="journal" id="sref11">
        <person-group person-group-type="author">
          <name>
            <surname>LeCun</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G.</given-names>
          </name>
        </person-group>
        <article-title>Deep learning</article-title>
        <source>Nature</source>
        <year>2015</year>
        <fpage>436</fpage>
        <lpage>444</lpage>
        <pub-id pub-id-type="doi">10.1038/nature14539</pub-id>
      </element-citation>
    </ref>
    <ref id="bib12">
      <element-citation publication-type="journal" id="sref12">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>L.</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>H.</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Z.</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>J.</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>M.</given-names>
          </name>
        </person-group>
        <article-title>Learning hierarchical representations of electronic health records for clinical outcome prediction</article-title>
        <source>AMIA Annu. Symp. Proc.</source>
        <volume>2019</volume>
        <year>2019</year>
        <fpage>597</fpage>
        <lpage>606</lpage>
        <pub-id pub-id-type="pmid">32308854</pub-id>
      </element-citation>
    </ref>
    <ref id="bib13">
      <element-citation publication-type="book" id="sref13">
        <person-group person-group-type="author">
          <name>
            <surname>Lundberg</surname>
            <given-names>S.M.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>S.-I.</given-names>
          </name>
        </person-group>
        <chapter-title>A unified approach to interpreting model predictions</chapter-title>
        <person-group person-group-type="editor">
          <name>
            <surname>Guyon</surname>
            <given-names>I.</given-names>
          </name>
        </person-group>
        <source>Advances in Neural Information Processing Systems 30</source>
        <year>2017</year>
        <publisher-name>Curran Associates, Inc.</publisher-name>
        <fpage>4765</fpage>
        <lpage>4774</lpage>
      </element-citation>
    </ref>
    <ref id="bib14">
      <element-citation publication-type="journal" id="sref14">
        <person-group person-group-type="author">
          <name>
            <surname>Morawski</surname>
            <given-names>K.</given-names>
          </name>
          <name>
            <surname>Dvorkis</surname>
            <given-names>Y.</given-names>
          </name>
          <name>
            <surname>Monsen</surname>
            <given-names>C.B.</given-names>
          </name>
        </person-group>
        <article-title>Predicting hospitalizations from electronic health record data</article-title>
        <source>Am. J. Manag. Care</source>
        <volume>26</volume>
        <year>2020</year>
        <fpage>e7</fpage>
        <lpage>e13</lpage>
        <pub-id pub-id-type="pmid">31951361</pub-id>
      </element-citation>
    </ref>
    <ref id="bib1">
      <element-citation publication-type="other" id="sref1">
        <person-group person-group-type="author">
          <collab>Sage Bionetworks</collab>
        </person-group>
        <ext-link ext-link-type="uri" xlink:href="https://www.synapse.org/#!Synapse:syn21849255/wiki/" id="interref0020">https://www.synapse.org/#!Synapse:syn21849255/wiki/</ext-link>
        <year>2020</year>
      </element-citation>
    </ref>
    <ref id="bib15">
      <element-citation publication-type="journal" id="sref15">
        <person-group person-group-type="author">
          <name>
            <surname>Shamout</surname>
            <given-names>F.</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>T.</given-names>
          </name>
          <name>
            <surname>Clifton</surname>
            <given-names>D.A.</given-names>
          </name>
        </person-group>
        <article-title>Machine learning for clinical outcome prediction</article-title>
        <source>IEEE Rev. Biomed. Eng.</source>
        <volume>14</volume>
        <year>2021</year>
        <fpage>116</fpage>
        <lpage>126</lpage>
        <pub-id pub-id-type="pmid">32746368</pub-id>
      </element-citation>
    </ref>
    <ref id="bib16">
      <element-citation publication-type="journal" id="sref16">
        <person-group person-group-type="author">
          <name>
            <surname>Sharafoddini</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Dubin</surname>
            <given-names>J.A.</given-names>
          </name>
          <name>
            <surname>Maslove</surname>
            <given-names>D.M.</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>J.</given-names>
          </name>
        </person-group>
        <article-title>A new insight into missing data in intensive care unit patient profiles: observational study</article-title>
        <source>JMIR Med. Inform.</source>
        <volume>7</volume>
        <year>2019</year>
        <fpage>e11605</fpage>
        <pub-id pub-id-type="pmid">30622091</pub-id>
      </element-citation>
    </ref>
    <ref id="bib17">
      <element-citation publication-type="journal" id="sref17">
        <person-group person-group-type="author">
          <name>
            <surname>Shickel</surname>
            <given-names>B.</given-names>
          </name>
          <name>
            <surname>Tighe</surname>
            <given-names>P.J.</given-names>
          </name>
          <name>
            <surname>Bihorac</surname>
            <given-names>A.</given-names>
          </name>
          <name>
            <surname>Rashidi</surname>
            <given-names>P.</given-names>
          </name>
        </person-group>
        <article-title>Deep EHR: a survey of recent advances in deep learning techniques for electronic health record (EHR) analysis</article-title>
        <source>IEEE J. Biomed. Health Inform.</source>
        <volume>22</volume>
        <year>2018</year>
        <fpage>1589</fpage>
        <lpage>1604</lpage>
        <pub-id pub-id-type="pmid">29989977</pub-id>
      </element-citation>
    </ref>
  </ref-list>
  <ack id="ack0010">
    <title>Acknowledgments</title>
    <p id="p0415">This work is supported by <funding-source id="gs1"><institution-wrap><institution-id institution-id-type="doi">10.13039/100000002</institution-id><institution>National Institute of Health</institution></institution-wrap></funding-source> (NIH), R35-GM133346 and <funding-source id="gs2"><institution-wrap><institution-id institution-id-type="doi">10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source> (NSF), #1452656.</p>
    <sec id="sec10">
      <title>Author contributions</title>
      <p id="p0420">H.Z packaged the code and wrote the manuscript. D.Y. prepared the figures. Y.G. developed the method and original code. All authors edited and agreed with this manuscript.</p>
    </sec>
    <sec sec-type="COI-statement" id="sec11">
      <title>Declaration of interests</title>
      <p id="p0425">The authors declare no competing interests.</p>
    </sec>
  </ack>
</back>
