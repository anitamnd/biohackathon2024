<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-id journal-id-type="pmc">plosone</journal-id>
    <journal-title-group>
      <journal-title>PLoS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6033424</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0199589</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-17-44408</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Cell Biology</subject>
          <subj-group>
            <subject>Cellular Types</subject>
            <subj-group>
              <subject>Animal Cells</subject>
              <subj-group>
                <subject>Neurons</subject>
                <subj-group>
                  <subject>Neuronal Dendrites</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Cellular Neuroscience</subject>
            <subj-group>
              <subject>Neurons</subject>
              <subj-group>
                <subject>Neuronal Dendrites</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Neural Networks</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Neural Networks</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
              <subj-group>
                <subject>Machine Learning Algorithms</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Cell Biology</subject>
          <subj-group>
            <subject>Cellular Types</subject>
            <subj-group>
              <subject>Animal Cells</subject>
              <subj-group>
                <subject>Neurons</subject>
                <subj-group>
                  <subject>Neuronal Dendrites</subject>
                  <subj-group>
                    <subject>Dendritic Structure</subject>
                  </subj-group>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Neuroscience</subject>
          <subj-group>
            <subject>Cellular Neuroscience</subject>
            <subj-group>
              <subject>Neurons</subject>
              <subj-group>
                <subject>Neuronal Dendrites</subject>
                <subj-group>
                  <subject>Dendritic Structure</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Imaging Techniques</subject>
          <subj-group>
            <subject>Fluorescence Imaging</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Geometry</subject>
            <subj-group>
              <subject>Geodesics</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>An open-source tool for analysis and automatic identification of dendritic spines using machine learning</article-title>
      <alt-title alt-title-type="running-head">Automated identification of dendritic spines</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-2248-8863</contrib-id>
        <name>
          <surname>Smirnov</surname>
          <given-names>Michael S.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Formal analysis</role>
        <role content-type="http://credit.casrai.org/">Investigation</role>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Project administration</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Visualization</role>
        <role content-type="http://credit.casrai.org/">Writing – original draft</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Garrett</surname>
          <given-names>Tavita R.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Data curation</role>
        <role content-type="http://credit.casrai.org/">Formal analysis</role>
        <role content-type="http://credit.casrai.org/">Investigation</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Yasuda</surname>
          <given-names>Ryohei</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Formal analysis</role>
        <role content-type="http://credit.casrai.org/">Funding acquisition</role>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Project administration</role>
        <role content-type="http://credit.casrai.org/">Resources</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Neuronal Signal Transduction, Max Planck Florida Institute for Neuroscience, Jupiter, Florida, United States of America</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Neuroscience, Oregon Health and Science University School of Medicine, Portland, Oregon, United States of America</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Bernardino de la Serna</surname>
          <given-names>Jorge</given-names>
        </name>
        <role>Editor</role>
        <xref ref-type="aff" rid="edit1"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Science and Technology Facilities Council, UNITED KINGDOM</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>Michael.Smirnov@mpfi.org</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>5</day>
      <month>7</month>
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2018</year>
    </pub-date>
    <volume>13</volume>
    <issue>7</issue>
    <elocation-id>e0199589</elocation-id>
    <history>
      <date date-type="received">
        <day>20</day>
        <month>12</month>
        <year>2017</year>
      </date>
      <date date-type="accepted">
        <day>11</day>
        <month>6</month>
        <year>2018</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2018 Smirnov et al</copyright-statement>
      <copyright-year>2018</copyright-year>
      <copyright-holder>Smirnov et al</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pone.0199589.pdf"/>
    <abstract>
      <p>Synaptic plasticity, the cellular basis for learning and memory, is mediated by a complex biochemical network of signaling proteins. These proteins are compartmentalized in dendritic spines, the tiny, bulbous, post-synaptic structures found on neuronal dendrites. The ability to screen a high number of molecular targets for their effect on dendritic spine structural plasticity will require a high-throughput imaging system capable of stimulating and monitoring hundreds of dendritic spines in various conditions. For this purpose, we present a program capable of automatically identifying dendritic spines in live, fluorescent tissue. Our software relies on a machine learning approach to minimize any need for parameter tuning from the user. Custom thresholding and binarization functions serve to “clean” fluorescent images, and a neural network is trained using features based on the relative shape of the spine perimeter and its corresponding dendritic backbone. Our algorithm is rapid, flexible, has over 90% accuracy in spine detection, and bundled with our user-friendly, open-source, MATLAB-based software package for spine analysis.</p>
    </abstract>
    <funding-group>
      <funding-statement>All relevant work by Smirnov, Garrett, and Yasuda was supported by National Institutes of Health- National Institute of Neurological Disorders and Stroke - 5DP1NS096787.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="9"/>
      <table-count count="0"/>
      <page-count count="16"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All source code data is available via a public GitHub repository found at <ext-link ext-link-type="uri" xlink:href="https://github.com/mikeusru/Braintown">https://github.com/mikeusru/Braintown</ext-link>. All training data can be found at <ext-link ext-link-type="uri" xlink:href="https://figshare.com/articles/Labeled_Dendritic_Spines_-_Training_Data/6149207">https://figshare.com/articles/Labeled_Dendritic_Spines_-_Training_Data/6149207</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All source code data is available via a public GitHub repository found at <ext-link ext-link-type="uri" xlink:href="https://github.com/mikeusru/Braintown">https://github.com/mikeusru/Braintown</ext-link>. All training data can be found at <ext-link ext-link-type="uri" xlink:href="https://figshare.com/articles/Labeled_Dendritic_Spines_-_Training_Data/6149207">https://figshare.com/articles/Labeled_Dendritic_Spines_-_Training_Data/6149207</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Structural changes in dendritic spines, tiny postsynaptic protrusions on the dendritic surface of neurons, are considered to be the basis of synaptic plasticity [<xref rid="pone.0199589.ref001" ref-type="bibr">1</xref>] and are known to be important for learning and memory [<xref rid="pone.0199589.ref002" ref-type="bibr">2</xref>]. Dysfunctions in synaptic plasticity are a feature of affective disorders, neurodegenerative diseases, and aging-associated cognitive decline [<xref rid="pone.0199589.ref001" ref-type="bibr">1</xref>].</p>
    <p>Recent advances in photostimulation and imaging techniques have made it possible to visualize the morphological and molecular changes in individual spines with high time resolution. Two-photon laser-scanning microscopy in live brain tissue is often used due to its relatively low scattering and precise localization in deep samples [<xref rid="pone.0199589.ref003" ref-type="bibr">3</xref>]. Furthermore, two-photon microscopy can be combined with glutamate uncaging, resulting in targeted photoactivation and plasticity in individual dendritic spines [<xref rid="pone.0199589.ref004" ref-type="bibr">4</xref>]. However, the process of finding, imaging, and analyzing changes in individual dendritic spines is cumbersome and time-consuming. Therefore, the identification of dendritic spines needs to be automated.</p>
    <p>Recently, several approaches to semi-automated identification and analysis of dendritic spines have been described [<xref rid="pone.0199589.ref005" ref-type="bibr">5</xref>–<xref rid="pone.0199589.ref010" ref-type="bibr">10</xref>]. These methods have the potential to greatly reduce the amount of effort required for large-scale spine counting and analysis, but are often optimized to a specific cell type, imaging technique, or magnification. Since the majority of spine segmentation algorithms are designed to be used for post-hoc analysis rather than to assist with live imaging, they may require large amounts of computing time and always rely on human input for error correction. Furthermore, variations in image intensity, background signal, and spine length must be accounted for by manual optimization of program settings. Therefore, the application of these algorithms to assist with live spine imaging under varying physiological conditions proves prohibitively difficult.</p>
    <p>To reduce errors due to sample variability, some spine identification techniques incorporate machine learning techniques [<xref rid="pone.0199589.ref005" ref-type="bibr">5</xref>, <xref rid="pone.0199589.ref011" ref-type="bibr">11</xref>]. Since differences in microscopes, fluorescent markers, and spine morphologies lead to variability in how spines are visualized, complex machine learning algorithms such as neural networks and deep learning often require enormous amounts of labeled training images (&gt;10,000), while simpler classifier techniques lack the ability to properly capture the amount of features required to identify spines.</p>
    <p>Here we provide a user-friendly tool to analyze, label, segment, and automatically identify dendritic spines. We use a machine learning approach to dendritic spine identification which is highly adaptable to any fluorescent imaging setup. By using adaptive thresholding, we identify neuronal dendrites regardless of background noise and signal intensity. Next, we train a neural network to identify spines based on the position of perimeter pixels relative to the dendrite and spine backbone, as well as the fluorescence intensity along the spine backbone. Our approach is fast and works with a training data set of as few as two thousand images which can be labeled within a few hours using our semi-automated labeling software. Furthermore, our software can be easily adapted to unique imaging setups, and is freely available in open-source MATLAB code.</p>
  </sec>
  <sec id="sec002">
    <title>Image acquisition</title>
    <sec id="sec003">
      <title>Tissue preparation</title>
      <p>To create an algorithm able to detect dendritic spines within a variety of morphologies, the images used for analysis were collected from a variety of genotypes. Organotypic hippocampal slice cultures were prepared as described previously [<xref rid="pone.0199589.ref012" ref-type="bibr">12</xref>] from p4-p6 mice were cultured for 10–12 days before transfection. A biolostic particle delivery system (Helios® Gene Gun System, Bio-Rad) was used to introduce fluorescent GFP labels to obtain sparse transfection of neurons. Two to six days after transfection, neurons in sparsely GFP-labeled CA1 hippocampal regions were chosen for imaging. Individual spines in the striatum radiatum on secondary apical dendrites were chosen for observation.</p>
    </sec>
    <sec id="sec004">
      <title>Animals</title>
      <p>Wild-type C57BL/6J were purchased from Charles river laboratories, and conditional knockout (cKO) lines were generated for IGF1 Receptor and Insulin Receptors as using standard knockout techniques. Animals were housed on a 12 hour light cycle with a room temperature of 74°F, 50% humidity, with Harlan 7092 ¼” corn cob bedding. P4-p6 pups were taken from mothers housed individually in Tecniplast® ventilated cages. Pups were sacrificed using decapitation. This study, including all animal procedures, was approved by the Max Planck Florida Institute for Neuroscience Animal Care and Use Committee, in accordance with guidelines by the US National Institutes of Health. Max Planck Florida Institute has been AAALAC Accredited since June, 2014.</p>
    </sec>
    <sec id="sec005">
      <title>Microscopy</title>
      <p>Imaging was done on a custom built, two-photon microscope controlled by Scanimage and modified to allow for automated, multiposition image collection [<xref rid="pone.0199589.ref013" ref-type="bibr">13</xref>, <xref rid="pone.0199589.ref014" ref-type="bibr">14</xref>]. Dendritic spines were imaged over ~1 hour using a 60X objective and 30X or 15X galvanometer-scan zoom (image field ~8x8 μm or 16x16 μm). One 5 μm Z-stack was collected over five Z-planes at each imaging position per minute. Each image was acquired at 128x128 pixels, resulting in a resolution of ~ 15 pixels per μm in both X and Y.</p>
    </sec>
    <sec id="sec006">
      <title>Image analysis</title>
      <p>The image processing workflow for feature extraction is illustrated in <xref ref-type="fig" rid="pone.0199589.g001">Fig 1</xref>. First, spine locations are labeled in each image, and images are automatically segmented. After segmentation, individual feature vectors consisting of 221 values were used to train a neural network using a scaled conjugate gradient propagation algorithm [<xref rid="pone.0199589.ref015" ref-type="bibr">15</xref>]. Once trained, the neural network was used to evaluate whether feature vectors from newly segmented images represent spine or non-spine locations. All code was written in MATLAB and is freely available at <ext-link ext-link-type="uri" xlink:href="https://github.com/mikeusru/Braintown">https://github.com/mikeusru/Braintown</ext-link>. All functions have been tested in MATLAB 2016b and require the Image Processing, Neural Network, and Statistics and Machine Learning toolboxes. All training data has also been made available [<xref rid="pone.0199589.ref016" ref-type="bibr">16</xref>].</p>
      <fig id="pone.0199589.g001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0199589.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>Image processing workflow for automated identification of dendritic spines.</title>
          <p>Orange: Spine locations are labeled in each image prior to automated segmentation. Extracted feature vectors are used to train a neural network using a scaled conjugate gradient propagation algorithm. Blue: Novel images are preprocessed, segmented, and feature vectors are extracted. Feature vectors are used to evaluate identify potential dendritic spines using the previously trained neural network.</p>
        </caption>
        <graphic xlink:href="pone.0199589.g001"/>
      </fig>
    </sec>
    <sec id="sec007">
      <title>Preprocessing and binarization</title>
      <p>Once an image is loaded (<xref ref-type="fig" rid="pone.0199589.g002">Fig 2A</xref>), pixels are converted to grayscale floating-point numbers ranging between 0 to 1. Noise is removed using a standard 2D median filter. Highest-probability background is identified using Otsu’s method of globally thresholding [<xref rid="pone.0199589.ref017" ref-type="bibr">17</xref>]. To ensure no relevant pixels are lost, the global threshold value is reduced by 70%. The average pixel below the background threshold is then subtracted from the image. Next, an adaptive image threshold is computed using local first-order statistics with a neighborhood size of 10x10 μm. Any resulting holes smaller than 0.5 μm<sup>2</sup> are filled. Ideally, the resulting binary image (<xref ref-type="fig" rid="pone.0199589.g002">Fig 2B</xref>) includes only regions of neuronal tissue.</p>
      <fig id="pone.0199589.g002" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0199589.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Steps in image segmentation.</title>
          <p>A. Original Image. B. Thresholding using Otsu’s global method, followed by adaptive thresholding and binarization. C. Backbone Extraction D. Identification of removed spines. E. Geodesic distance transform using dendrite backbone as seed location F. Identification of potential spine locations by local maxima along perimeter. G, H. Local geodesic distance transforms for each individual potential spine point, using spine backbone (shortest path between local maxima and dendrite backbone) as seed point. Scale bar = 5 <bold>μ</bold>m.</p>
        </caption>
        <graphic xlink:href="pone.0199589.g002"/>
      </fig>
    </sec>
    <sec id="sec008">
      <title>Backbone extraction</title>
      <p>The backbone of the dendrite (<xref ref-type="fig" rid="pone.0199589.g002">Fig 2C</xref>) was identified by thinning the binary image until all structures had a thickness of no more than one pixel, and then removing any branches which didn’t belong to the dendrite. After skeletonization [<xref rid="pone.0199589.ref018" ref-type="bibr">18</xref>], the presence of dendritic spines and noise within the image causes a significant number of spurious branches and loops which are not representative of the dendrite itself. Loop artifacts were removed by filling in all areas smaller than 0.5 μm<sup>2</sup> and undergoing a second round of skeletonization. Any isolated segments where p&lt;M were removed, where p was the amount of pixels in the segment, and M was the minimum branch length (2 μm) multiplied by the number of pixels per μm. The remainder of the spurious segments were removed by a recursive trimming algorithm adapted from Cheng et al. [<xref rid="pone.0199589.ref007" ref-type="bibr">7</xref>]. Basically, endpoint pixels were iteratively removed from the skeleton and added to a set of deleting templates through the use of a nested loop. If the iteration did not add to the deleting template, then the deleting template was permanently removed from the skeleton. The code structure is presented below:</p>
      <list list-type="order">
        <list-item>
          <p>
            <monospace>Initialize m = 1</monospace>
          </p>
        </list-item>
        <list-item>
          <p>
            <monospace>Repeat until m = M</monospace>
            <list list-type="alpha-lower">
              <list-item>
                <p>
                  <monospace>Initialize removed segments = blank</monospace>
                </p>
              </list-item>
              <list-item>
                <p>
                  <monospace>Repeat m times:</monospace>
                  <list list-type="roman-lower">
                    <list-item>
                      <p>
                        <monospace>Find skeleton endpoints, ignoring those near border</monospace>
                      </p>
                    </list-item>
                    <list-item>
                      <p>
                        <monospace>Add skeleton endpoints to removed segments</monospace>
                      </p>
                    </list-item>
                  </list>
                </p>
              </list-item>
              <list-item>
                <p>
                  <monospace>Remove skeleton endpoints from skeleton</monospace>
                </p>
              </list-item>
              <list-item>
                <p>
                  <monospace>Restore any removed segments that have m pixels</monospace>
                </p>
              </list-item>
              <list-item>
                <p>
                  <monospace>m = m + 1</monospace>
                </p>
              </list-item>
            </list>
          </p>
        </list-item>
      </list>
      <p>After trimming, the backbone often retained some small kinks leftover from the initial skeletonization process. As these kinks could introduce artifacts in the later perimeter distance calculation, they were removed by a custom smoothing algorithm also adapted from Cheng at al. [<xref rid="pone.0199589.ref007" ref-type="bibr">7</xref>]: First, all branch points belonging to the initial, untrimmed skeleton were located along the dendrite backbone. Next, the branchpoints were dilated by M/4 to include all local backbone pieces which might belong to a kink. Finally, these kinks were removed, and the resulting line endpoints connected, resulting in a smooth backbone segment.</p>
    </sec>
    <sec id="sec009">
      <title>Surface smoothing</title>
      <p>To isolate individual segments of the cell perimeter to be used as features for spine detection, the surface of the binary object needed to be smooth, lacking any spurious pixels or diagonally connected regions. Smoothing was achieved using an array of morphological operations on the binary image. First, a majority operation [<xref rid="pone.0199589.ref019" ref-type="bibr">19</xref>] set a pixel to 1 if five or more pixels in its 3x3 neighborhood are 1s, otherwise the pixel is set to 0. Next, the image is morphologically opened, closed, and opened again using a 3x3 structuring element of ones. Pixels connected to fewer than three other pixels were removed, and a diagonal fill was used to eliminate any 8-connectivity of the background, essentially transforming diagonal connections into right angles. The binary objects were then thickened by adding a one-pixel width border, as long as that border did not form a new connection with a neighboring border. An example of the result attained through surface smoothing can be seen in <xref ref-type="fig" rid="pone.0199589.g003">Fig 3</xref>.</p>
      <fig id="pone.0199589.g003" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0199589.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>Surface smoothing of binary image.</title>
          <p>(A) Initial binary image contains a significant noise around its perimeter. (B) Surface-smoothed image lacks kinks, as well as spurious or diagonally–connected pixels.</p>
        </caption>
        <graphic xlink:href="pone.0199589.g003"/>
      </fig>
    </sec>
    <sec id="sec010">
      <title>Identification of disconnected spines</title>
      <p>As the purpose of our algorithm was to find spines which were obviously attached to the dendrite, small objects which became disconnected from the dendrite (<xref ref-type="fig" rid="pone.0199589.g002">Fig 2D</xref>) during the surface smoothing step were categorized using k-means clustering, but were ignored from the neural network training data. In any individual image, the signal to noise ratio was calculated in objects that were within distance M from the dendrite backbone. Each respective signal was collected from the pixels in the original image (<xref ref-type="fig" rid="pone.0199589.g002">Fig 2A</xref>) which overlapped with the object, while noise was calculated using pixels in the bounding box of the object minus the pixels within the object. If more than two objects were detected, spines were identified using k-means clustering of the signal to noise ratios into two clusters. The group with a larger average signal to noise ratio were identifies as spines, while others were non-spine objects. All objects detached from the main dendrite structure were ignored for the remaining calculations.</p>
    </sec>
    <sec id="sec011">
      <title>Perimeter feature extraction</title>
      <p>Three feature vectors were used for neural network training and spine identification: perimeter distance from dendrite backbone (PD), perimeter distance from spine backbone (PS), and fluorescence intensity along the spine backbone (IS). The location of each feature vector, as well as the individual values of PD features, were quantified based on a geodesic distance transform [<xref rid="pone.0199589.ref020" ref-type="bibr">20</xref>] of the binary image of the dendrite, using the dendrite backbone as a seed location. Thus, the value assigned to each connected pixel represents its relative distance from the dendrite backbone (<xref ref-type="fig" rid="pone.0199589.g002">Fig 2E</xref>). The central position of each feature vector was assigned by finding local maxima along the perimeter of the geodesic transform (<xref ref-type="fig" rid="pone.0199589.g002">Fig 2F</xref>), and a geodesic distance transform of the perimeter itself (<xref ref-type="fig" rid="pone.0199589.g004">Fig 4A</xref>) served to organize all perimeter pixels into relative locations. Vectors were all standardized to contain a minimum value of 0 to reflect the shape of the spine while ignoring dendrite thickness. Each PD feature vector represents a 5 μm segment of pixel values along the edge of the geodesic transform (<xref ref-type="fig" rid="pone.0199589.g004">Fig 4C</xref>).</p>
      <fig id="pone.0199589.g004" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0199589.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>PD and PS feature vectors.</title>
          <p>(A) Relative position values, in <bold>μ</bold>m, assigned to each pixel starting from a random seed and following a single direction. (B) 5 <bold>μ</bold>m perimeter segments are extracted at each potential spine point to create PS feature vectors. Brighter pixels indicate higher distance from spine backbone. Left box (blue) is a true spine, right box (orange) is a non-spine. (C) Perimeter feature vectors represent respective pixel values (y axis) and pixel position (x axis).</p>
        </caption>
        <graphic xlink:href="pone.0199589.g004"/>
      </fig>
      <p>Unlike PD features, which represent distance from the dendrite backbone, PS features represent distance from the spine backbone. The spine backbone was identified as the shortest path between the feature origin point on the perimeter (<xref ref-type="fig" rid="pone.0199589.g002">Fig 2F, 2G and 2H</xref>) and its nearest point on the dendrite backbone with the help of a fast marching algorithm [<xref rid="pone.0199589.ref021" ref-type="bibr">21</xref>]. A geodesic distance transforms was calculated using the spine backbone as a seed (<xref ref-type="fig" rid="pone.0199589.g002">Fig 2G and 2H</xref>), and PS features are represented as a 5 μm segment of pixel values along the resulting perimeter (<xref ref-type="fig" rid="pone.0199589.g004">Fig 4B and 4C</xref>).</p>
      <p>PD and PS features were arranged based on their respective position along the perimeter. To minimize the amount of necessary training data, position information was defined by a single value as the directional distance along the perimeter from the center of the feature origin. To assign position values, a closed-loop perimeter was first cut at a random point. A geodesic distance transform, with one endpoint as a seed, was then used to assign a single value to each pixel (<xref ref-type="fig" rid="pone.0199589.g004">Fig 4A</xref>). As a result of the transform, each consecutive pixel was assigned a value based on its travel distance from the seed pixel. Prior surface smoothing (<xref ref-type="fig" rid="pone.0199589.g003">Fig 3</xref>) was exceptionally important for this distance transform to work properly, since any kinks or loops in the perimeter would result in duplicate position values. By assigning these position values to each perimeter feature, we translated 2D perimeter images (<xref ref-type="fig" rid="pone.0199589.g004">Fig 4B</xref>) into 1D arrays of feature-specific values (<xref ref-type="fig" rid="pone.0199589.g004">Fig 4C</xref>). Finally, since the amount of pixels in a 5 μm segment varied based on the resolution of the initial image, PS and PD feature vectors were standardized by interpolating to 100 values each.</p>
      <p>Features in the IS group were assigned using pixel positions from the spine backbone, and pixel values from the original image. The resulting feature vector represents a line of intensity values starting at the dendrite backbone and finishing at the tip of the spine. Due to the spine backbone varying in length, each group of values was interpolated to 20 features (<xref ref-type="fig" rid="pone.0199589.g005">Fig 5A</xref>), while the 21<sup>th</sup> feature represented the original spine backbone length in μm (<xref ref-type="fig" rid="pone.0199589.g005">Fig 5B</xref>).</p>
      <fig id="pone.0199589.g005" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0199589.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <title>Length and Intensity of the spine backbone.</title>
          <p><bold>(</bold>A) Average pixel intensity in pixels taken along line connecting tip of potential spine to closest point in dendrite backbone. (B) Average length of spine backbone in pre-labeled Spine and Non-Spine objects.</p>
        </caption>
        <graphic xlink:href="pone.0199589.g005"/>
      </fig>
    </sec>
  </sec>
  <sec id="sec012">
    <title>Network training</title>
    <p>PD, PS, and IS feature sets consisting of a combined 221 values were used to train a neural network using a scaled conjugate gradient propagation algorithm [<xref rid="pone.0199589.ref015" ref-type="bibr">15</xref>] from the MATLAB (2016b) Neural Network Toolbox using default parameters. Weights and biases were initialized randomly between -1 and 1. To elicit the highest accuracy in spine categorization while keeping training and classification times manageable, the network was configured to have a single hidden layer with 20 nodes. Features sets were classified as either spine or non-spine. To label training data, we designed an application which allows users to rapidly identify dendritic spines by clicking on their location in an image. A 1x1 μm box was then drawn around each identified spine. Boxes that were within 1.5 μm from the image border were ignored to avoid edge artifacts. Boxes which overlapped with a disconnected blob (Figs <xref ref-type="fig" rid="pone.0199589.g002">2</xref> and <xref ref-type="fig" rid="pone.0199589.g001">1D</xref>) were ignored as well. Feature sets were classified as spines if their point of origin was inside the box.</p>
  </sec>
  <sec id="sec013">
    <title>Software design</title>
    <p>To make our tools accessible to users who may lack any significant coding expertise, we built a straightforward front-end user interface for viewing, analyzing, labeling, and segmenting images of dendritic spines in MATLAB (<xref ref-type="fig" rid="pone.0199589.g006">Fig 6</xref>). The main window (<xref ref-type="fig" rid="pone.0199589.g006">Fig 6A</xref>) allows users to load either individual images or image sets, browse through the loaded data (<xref ref-type="fig" rid="pone.0199589.g006">Fig 6B</xref>), and restrict certain files from being loaded (<xref ref-type="fig" rid="pone.0199589.g006">Fig 6C</xref>). Drop-down menus also let users perform common calculations such as 3D projection on Z stacks and drift correction on timelapse image sets. Users can draw circular or polygonal ROIs on the image (<xref ref-type="fig" rid="pone.0199589.g006">Fig 6E</xref>) to calculate changes in spine volume over time (<xref ref-type="fig" rid="pone.0199589.g006">Fig 6D</xref>). While remaining compatible with variable data sources, this program is particularly tuned to analyze data collected using our automated multiposition imaging system [<xref rid="pone.0199589.ref014" ref-type="bibr">14</xref>]. A semi-automated spine selection tool for labeling training data is also provided (<xref ref-type="fig" rid="pone.0199589.g006">Fig 6F</xref>). Users can enter spine selection mode (<xref ref-type="fig" rid="pone.0199589.g006">Fig 6G</xref>), where clicking on the image frame will label and store the local coordinates of each spine (<xref ref-type="fig" rid="pone.0199589.g006">Fig 6E</xref>). Users have the option to track spines through brightness, where given a timelapse image set, spine coordinates will automatically update to their new closest position. Finally, the spine selection tool allows users to train, preview, and test a neural network for its capability to find dendritic spines (<xref ref-type="fig" rid="pone.0199589.g006">Fig 6H</xref>).</p>
    <fig id="pone.0199589.g006" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0199589.g006</object-id>
      <label>Fig 6</label>
      <caption>
        <title>Graphical user interface to label and measure image regions.</title>
        <p>(A) Base dendrite analysis window responsible of loading/saving data, (B) switching between images, (C) avoid particular files, and (D) running calculations on ROI area over time. (D) Image preview window for drawing polygonal/circle ROIs, and identifying individual spines (red/black rhombi). (F) Spine selection and machine learning tool allows toggling of (G) spine selection mode, semi-automated spine tracking, (H) gathering and previewing of training data, and spine finding using a trained neural network.</p>
      </caption>
      <graphic xlink:href="pone.0199589.g006"/>
    </fig>
    <p>To create a powerful yet user-friendly system for image segmentation, we created a modular interface where users can manually select, customize, evaluate, and share plugins and configurations without any coding experience (<xref ref-type="fig" rid="pone.0199589.g007">Fig 7</xref>). A function selection window (<xref ref-type="fig" rid="pone.0199589.g007">Fig 7A</xref>) loads all of the plugins from a local plugins folder and displays them in an alphabetized list (<xref ref-type="fig" rid="pone.0199589.g007">Fig 7B</xref>). Each plugin serves as a step in the image segmentation, analysis, or feature extraction process, and may have unique inputs and outputs. Using drop-down lists, users may select which output variables will serve as inputs for plugins down the line. For example, the function selected in <xref ref-type="fig" rid="pone.0199589.g007">Fig 7C</xref> takes the input variable “BW (1)”, and outputs “thin (2)” and “spineSearchZone (2)”, both of which are used as inputs in other steps down the line. A number referencing the analysis step is attached to each variable name to avoid errors where multiple plugins have outputs with the same name. To clarify the types of input and output variables associated with each plugin, as well as the general function of the plugin itself, an informational window previews all relevant information as each function is selected (<xref ref-type="fig" rid="pone.0199589.g007">Fig 7D</xref>). Once the custom segmentation process is run, all individual output variables are previewed as images in a separate window (<xref ref-type="fig" rid="pone.0199589.g007">Fig 7E</xref>). Once users are satisfied with their plugin configuration, the configuration can be saved, shared, commented on, and even rated for success at a certain task by multiple users (<xref ref-type="fig" rid="pone.0199589.g007">Fig 7F</xref>).</p>
    <fig id="pone.0199589.g007" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0199589.g007</object-id>
      <label>Fig 7</label>
      <caption>
        <title>Graphical user interface for image segmentation.</title>
        <p>(A) The function selection window handles the available functions and their configuration. (B) All available functions are displayed in the plugin repository. (C) Selected functions and their inputs are selected in the current configuration space. (D) A short tutorial for each individual plugin is displayed upon selection. (E) Outputs of each plugin are previewed in a separate, scrollable window. (F) Plugin configurations can be saved, shared, and rated between multiple users.</p>
      </caption>
      <graphic xlink:href="pone.0199589.g007"/>
    </fig>
  </sec>
  <sec id="sec014">
    <title>Results and discussion</title>
    <p>We used 1837 images to train, validate, and test the neural network. 3627 and 11922 feature sets were categorized as spine and non-spine, respectively. Spine PD feature arrays were often marked with a pseudo-linear increase, and then a decrease, indicating the protruding shape of the spine, while non-spine PD arrays tended to be flat, with a lower amplitude at the center (Figs <xref ref-type="fig" rid="pone.0199589.g004">4C</xref> and <xref ref-type="fig" rid="pone.0199589.g008">8A</xref>). PS feature arrays, on the other hand, tended to have lower amplitudes when associated with a spine, and had a more pronounced V-shape at non-spine positions (Figs <xref ref-type="fig" rid="pone.0199589.g004">4C</xref> and <xref ref-type="fig" rid="pone.0199589.g008">8B</xref>).</p>
    <fig id="pone.0199589.g008" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0199589.g008</object-id>
      <label>Fig 8</label>
      <caption>
        <title>Cumulative PD and PS features.</title>
        <p>Each chart represents total points binned from all feature vectors in. (A) Left–Spine, Right–Non-Spine binned feature vectors. (B) Left–Spine, Right–Non-Spine binned feature vectors. Blue lines represent the average of all feature vectors in each group.</p>
      </caption>
      <graphic xlink:href="pone.0199589.g008"/>
    </fig>
    <p>As expected, the length of the spine backbone tended to be longer in spines versus non-spines (<xref ref-type="fig" rid="pone.0199589.g005">Fig 5B</xref>). Spine IS feature arrays often had a pronounced increase followed by decrease in amplitude, indicating the bright center of the dendritic spine, while non-spine groups were characterized by a more linear drop-off in signal (<xref ref-type="fig" rid="pone.0199589.g005">Fig 5A</xref>).</p>
    <p>Labeled data was split into three groups–Training (60%), Validation (20%), and Testing (20%). Classifier results for training and testing data are shown in <xref ref-type="fig" rid="pone.0199589.g009">Fig 9</xref>. Overall, classification accuracy was highly similar between training, test, and validation datasets, indicating that there was no overfitting of the model. In the testing dataset, 94.5% of actual spines were classified as spines (true positive rate), and 5.5% were classified as non-spines (false negative). 98.5% of non-spines were classified as non-spines (true negative) and 1.5% classified as spines (false positive). The positive predictive value of the algorithm (precision) was 94.7%. These results indicate that our model is highly successful in spine identification. Reshuffling of the training, validation, and testing sets did not make any significant difference to the algorithm’s success. Previous algorithms tend to report results that are either lower or as good. For example, Blumer at al. [<xref rid="pone.0199589.ref005" ref-type="bibr">5</xref>] achieved a true positive rate and precision of 55% and 65%, respectively, on 2P images, while Cheng et al. [<xref rid="pone.0199589.ref007" ref-type="bibr">7</xref>] saw results comparable to ours. Notably, many of these previous algorithms report test results on extremely small datasets, suggesting a high probability of overfitting. Algorithm functionality is also difficult to compare since some code is built specifically for images collected by other imaging tools, such as SEM, or using specific biomarkers. None of the data from our validation group was used to train the model indicates the high predictive value of our algorithms. Furthermore, spine identification in dendrites collected at magnification values different from those of the training data (<xref ref-type="fig" rid="pone.0199589.g009">Fig 9B</xref>) predicts the scalability of our algorithm to broader datasets. In keeping with best community practices, we have made our code and data open to the public in an easily accessible online format.</p>
    <fig id="pone.0199589.g009" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0199589.g009</object-id>
      <label>Fig 9</label>
      <caption>
        <title>Neural Network’s ability to identify spines.</title>
        <p>(A) Training and Test confusion matrices. (B) Yellow circles indicate spines identified by neural network in naïve images.</p>
      </caption>
      <graphic xlink:href="pone.0199589.g009"/>
    </fig>
    <p>A major benefit of our spine classification algorithm is a lack of parameters which users are required to tune. The only input required by the algorithm is the relative scale of the image in pixels/μm, which can often be extracted automatically from images saved with modern imaging software. Furthermore, we expect our algorithm to become more powerful and accurate for dendritic spine identification as more training data becomes available. Therefore, we see our algorithm as a particularly user-friendly option for those looking to automate fluorescent imaging and/or targeting of dendritic spines. In particular, we expect that the combination of this technique with our previously developed spine imaging automation software [<xref rid="pone.0199589.ref014" ref-type="bibr">14</xref>] will lead to significant increases in the throughput of spine imaging and stimulation.</p>
    <p>It is important to note that while our algorithm lacks tunable parameters, it differs significantly from the current state-of-the-art, end-to-end convolutional networks. Our model includes automated denoising and thresholding steps which are explicitly programmed as opposed to being learned. A common pitfall of including explicit processing steps in the pipeline is poor parameter tuning, which leads to imprecise feature selection, but we felt that our algorithm performs adequately enough that these problems were generally avoided. The benefit of including these initial steps over an end-to-end approach is an overall reduction in feature amount, which leads to smaller processing power for network training. Therefore, while deep, convolutional networks are an invaluable tool in computer vision, we feel that a shallow network with explicit feature selection is simple, effective, and practical, making it a useful tool for the identification of fluorescent subcellular features such as dendritic spines.</p>
    <p>While many techniques have been developed to identify dendritic spines [<xref rid="pone.0199589.ref005" ref-type="bibr">5</xref>–<xref rid="pone.0199589.ref011" ref-type="bibr">11</xref>, <xref rid="pone.0199589.ref022" ref-type="bibr">22</xref>], many of these techniques were specifically designed for post-hoc analysis, relying on additional human input to correct mistakes. While our algorithm does not claim to have 100% accuracy, its goal is to identify a large majority of clearly demarcated spines, specific to a single focus plane, within a sample for automated imaging and photostimulation. For such an automated system to work, spine labeling must require no human input, and have a minimal number of false positives, which lead to throwaway data. Our algorithm accomplishes precisely this feat, relying only on machine learning and previously labeled training data. Furthermore, to minimize the amount of human training time necessary to train the neural network algorithm, we’ve taken steps to simplify our data as much as possible, reducing images to a set of feature vectors which convey important information about spine shape. Since our training data and code is open-sourced and shared online, we expect other labs to build upon and improve our algorithm by adding their own training data, therefore increasing the potential accuracy of spine identification. Furthermore, our software can add additional training features, allowing for even further improvements of detection accuracy.</p>
  </sec>
  <sec sec-type="conclusions" id="sec015">
    <title>Conclusion</title>
    <p>Overall, we believe that our neural network model for automated spine identification in fluorescent neurons is highly accurate, scalable, and is built to easily be upgraded with the addition of training data and programmatic improvements. Due to its open-source availability, simplicity, and lack of tunable features, we expect this software to be used both in post-hoc spine analysis, as well as for automated spine tracking during imaging experiments.</p>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pone.0199589.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Kasai</surname><given-names>H</given-names></name>, <name><surname>Fukuda</surname><given-names>M</given-names></name>, <name><surname>Watanabe</surname><given-names>S</given-names></name>, <name><surname>Hayashi-Takagi</surname><given-names>A</given-names></name>, <name><surname>Noguchi</surname><given-names>J</given-names></name>. <article-title>Structural dynamics of dendritic spines in memory and cognition</article-title>. <source>Trends in Neurosciences</source>. <year>2010</year>;<volume>33</volume>(<issue>3</issue>):<fpage>121</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2010.01.001">10.1016/j.tins.2010.01.001</ext-link></comment><?supplied-pmid 20138375?><pub-id pub-id-type="pmid">20138375</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Kim</surname><given-names>IH</given-names></name>, <name><surname>Wang</surname><given-names>H</given-names></name>, <name><surname>Soderling</surname><given-names>SH</given-names></name>, <name><surname>Yasuda</surname><given-names>R</given-names></name>. <article-title>Loss of Cdc42 leads to defects in synaptic plasticity and remote memory recall</article-title>. <source>Elife</source>. <year>2014</year>;<volume>3</volume>:<fpage>e02839</fpage>–e. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.02839">10.7554/eLife.02839</ext-link></comment> ; PubMed Central PMCID: PMCPMC4115656.<?supplied-pmid 25006034?><pub-id pub-id-type="pmid">25006034</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Hoover</surname><given-names>EE</given-names></name>, <name><surname>Squier</surname><given-names>JA</given-names></name>. <article-title>Advances in multiphoton microscopy technology</article-title>. <source>Nature photonics</source>. <year>2013</year>;<volume>7</volume>(<issue>2</issue>):<fpage>93</fpage>–<lpage>101</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nphoton.2012.361">10.1038/nphoton.2012.361</ext-link></comment><?supplied-pmid 24307915?><pub-id pub-id-type="pmid">24307915</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Svoboda</surname><given-names>K</given-names></name>, <name><surname>Yasuda</surname><given-names>R</given-names></name>. <article-title>Principles of Two-Photon Excitation Microscopy and Its Applications to Neuroscience</article-title>. <source>Neuron</source>. <year>2006</year>;<volume>50</volume>(<issue>6</issue>):<fpage>823</fpage>–<lpage>39</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2006.05.019">10.1016/j.neuron.2006.05.019</ext-link></comment><?supplied-pmid 16772166?><pub-id pub-id-type="pmid">16772166</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Blumer</surname><given-names>C</given-names></name>, <name><surname>Vivien</surname><given-names>C</given-names></name>, <name><surname>Genoud</surname><given-names>C</given-names></name>, <name><surname>Perez-Alvarez</surname><given-names>A</given-names></name>, <name><surname>Wiegert</surname><given-names>JS</given-names></name>, <name><surname>Vetter</surname><given-names>T</given-names></name>, <etal>et al</etal><article-title>Automated analysis of spine dynamics on live CA1 pyramidal cells</article-title>. <source>Medical image analysis</source>. <year>2014</year>;<volume>19</volume>(<issue>1</issue>):<fpage>87</fpage>–<lpage>97</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.media.2014.09.004">10.1016/j.media.2014.09.004</ext-link></comment><?supplied-pmid 25299432?><pub-id pub-id-type="pmid">25299432</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref006">
      <label>6</label>
      <mixed-citation publication-type="other">Cheng J. Automated detection and time lapse analysis of dendritic spines in laser scanning microscopy images. 2009;Northeaste(April):n/a-n/a.</mixed-citation>
    </ref>
    <ref id="pone.0199589.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Cheng</surname><given-names>J</given-names></name>, <name><surname>Zhou</surname><given-names>X</given-names></name>, <name><surname>Miller</surname><given-names>E</given-names></name>, <name><surname>Witt</surname><given-names>RM</given-names></name>, <name><surname>Zhu</surname><given-names>J</given-names></name>, <name><surname>Sabatini</surname><given-names>BL</given-names></name>, <etal>et al</etal><article-title>A novel computational approach for automatic dendrite spines detection in two-photon laser scan microscopy</article-title>. <source>J Neurosci Methods</source>. <year>2007</year>;<volume>165</volume>(<issue>1</issue>):<fpage>122</fpage>–<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jneumeth.2007.05.020">10.1016/j.jneumeth.2007.05.020</ext-link></comment> ; PubMed Central PMCID: PMCPMC1989684.<?supplied-pmid 17629570?><pub-id pub-id-type="pmid">17629570</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Sa</surname><given-names>Swanger</given-names></name>, <name><surname>Yao</surname><given-names>X</given-names></name>, <name><surname>Gross</surname><given-names>C</given-names></name>, <name><surname>Bassell</surname><given-names>GJ</given-names></name>. <article-title>Automated 4D analysis of dendritic spine morphology: applications to stimulus-induced spine remodeling and pharmacological rescue in a disease model</article-title>. <source>Molecular Brain</source>. <year>2011</year>;<volume>4</volume>(<issue>1</issue>):<fpage>38</fpage>–. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/1756-6606-4-38">10.1186/1756-6606-4-38</ext-link></comment><?supplied-pmid 21982080?><pub-id pub-id-type="pmid">21982080</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>S</given-names></name>, <name><surname>Chen</surname><given-names>M</given-names></name>, <name><surname>Li</surname><given-names>Y</given-names></name>, <name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Han</surname><given-names>L</given-names></name>, <name><surname>Wu</surname><given-names>J</given-names></name>, <etal>et al</etal><article-title>Detection of Dendritic Spines Using Wavelet-Based Conditional Symmetric Analysis and Regularized Morphological Shared-Weight Neural Networks</article-title>. <source>Comput Math Methods Med</source>. <year>2015</year>;<volume>2015</volume>:<fpage>454076</fpage><comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1155/2015/454076">10.1155/2015/454076</ext-link></comment> ; PubMed Central PMCID: PMCPMC4672122.<?supplied-pmid 26692046?><pub-id pub-id-type="pmid">26692046</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref010">
      <label>10</label>
      <mixed-citation publication-type="journal"><name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Chen</surname><given-names>K</given-names></name>, <name><surname>Baron</surname><given-names>M</given-names></name>, <name><surname>Teylan</surname><given-names>Ma</given-names></name>, <name><surname>Kim</surname><given-names>Y</given-names></name>, <name><surname>Song</surname><given-names>Z</given-names></name>, <etal>et al</etal><article-title>A neurocomputational method for fully automated 3D dendritic spine detection and segmentation of medium-sized spiny neurons</article-title>. <source>NeuroImage</source>. <year>2010</year>;<volume>50</volume>(<issue>4</issue>):<fpage>1472</fpage>–<lpage>84</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2010.01.048">10.1016/j.neuroimage.2010.01.048</ext-link></comment><?supplied-pmid 20100579?><pub-id pub-id-type="pmid">20100579</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Gala</surname><given-names>R</given-names></name>, <name><surname>Chapeton</surname><given-names>J</given-names></name>, <name><surname>Jitesh</surname><given-names>J</given-names></name>, <name><surname>Bhavsar</surname><given-names>C</given-names></name>, <name><surname>Stepanyants</surname><given-names>A</given-names></name>. <article-title>Active learning of neuron morphology for accurate automated tracing of neurites</article-title>. <source>Frontiers in neuroanatomy</source>. <year>2014</year>;<volume>8</volume>(May):<fpage>37</fpage>–. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnana.2014.00037">10.3389/fnana.2014.00037</ext-link></comment><?supplied-pmid 24904306?><pub-id pub-id-type="pmid">24904306</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Stoppini</surname><given-names>L</given-names></name>, <name><surname>Buchs</surname><given-names>PA</given-names></name>, <name><surname>Muller</surname><given-names>D</given-names></name>. <article-title>A simple method for organotypic cultures of nervous tissue</article-title>. <source>J Neurosci Methods</source>. <year>1991</year>;<volume>37</volume>(<issue>2</issue>):<fpage>173</fpage>–<lpage>82</lpage>. .<?supplied-pmid 1715499?><pub-id pub-id-type="pmid">1715499</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Pologruto</surname><given-names>TA</given-names></name>, <name><surname>Sabatini</surname><given-names>BL</given-names></name>, <name><surname>Svoboda</surname><given-names>K</given-names></name>. <article-title>ScanImage: flexible software for operating laser scanning microscopes</article-title>. <source>Biomed Eng Online</source>. <year>2003</year>;<volume>2</volume>(<issue>1</issue>):<fpage>13</fpage><comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/1475-925X-2-13">10.1186/1475-925X-2-13</ext-link></comment> ; PubMed Central PMCID: PMCPMC161784.<?supplied-pmid 12801419?><pub-id pub-id-type="pmid">12801419</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Smirnov</surname><given-names>MS</given-names></name>, <name><surname>Evans</surname><given-names>PR</given-names></name>, <name><surname>Garrett</surname><given-names>TR</given-names></name>, <name><surname>Yan</surname><given-names>L</given-names></name>, <name><surname>Yasuda</surname><given-names>R</given-names></name>. <article-title>Automated Remote Focusing, Drift Correction, and Photostimulation to Evaluate Structural Plasticity in Dendritic Spines</article-title>. <source>PLoS One</source>. <year>2017</year>;<volume>12</volume>(<issue>1</issue>):<fpage>e0170586</fpage><comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0170586">10.1371/journal.pone.0170586</ext-link></comment> ; PubMed Central PMCID: PMCPMC5256890.<?supplied-pmid 28114380?><pub-id pub-id-type="pmid">28114380</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Møller</surname><given-names>MF</given-names></name>. <article-title>A scaled conjugate gradient algorithm for fast supervised learning</article-title>. <source>Neural networks</source>. <year>1993</year>;<volume>6</volume>(<issue>4</issue>):<fpage>525</fpage>–<lpage>33</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0199589.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Michael</surname><given-names>S</given-names></name>, <name><surname>Tavita</surname><given-names>G</given-names></name>. <article-title>Labeled Dendritic Spines—Training Data</article-title>. <year>2018</year><comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.6149207.v1">10.6084/m9.figshare.6149207.v1</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0199589.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Otsu</surname><given-names>N</given-names></name>. <article-title>A threshold selection method from gray-level histograms</article-title>. <source>IEEE Transactions on systems, man, and cybernetics</source>. <year>1979</year>;<volume>9</volume>(<issue>1</issue>):<fpage>62</fpage>–<lpage>6</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0199589.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Lam</surname><given-names>L</given-names></name>, <name><surname>Lee</surname><given-names>S-W</given-names></name>, <name><surname>Suen</surname><given-names>CY</given-names></name>. <article-title>Thinning methodologies-a comprehensive survey</article-title>. <source>IEEE Transactions on pattern analysis and machine intelligence</source>. <year>1992</year>;<volume>14</volume>(<issue>9</issue>):<fpage>869</fpage>–<lpage>85</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0199589.ref019">
      <label>19</label>
      <mixed-citation publication-type="book"><name><surname>Kong</surname><given-names>TY</given-names></name>, <name><surname>Rosenfeld</surname><given-names>A</given-names></name>. <chapter-title>Topological algorithms for digital image processing</chapter-title>: <publisher-name>Elsevier</publisher-name>; <year>1996</year>.</mixed-citation>
    </ref>
    <ref id="pone.0199589.ref020">
      <label>20</label>
      <mixed-citation publication-type="book"><name><surname>Soille</surname><given-names>P</given-names></name>. <chapter-title>Morphological image analysis: principles and applications</chapter-title>: <publisher-name>Springer Science &amp; Business Media</publisher-name>; <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="pone.0199589.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Sethian</surname><given-names>JA</given-names></name>. <article-title>A fast marching level set method for monotonically advancing fronts</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>1996</year>;<volume>93</volume>(<issue>4</issue>):<fpage>1591</fpage>–<lpage>5</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0199589.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Jungblut</surname><given-names>D</given-names></name>, <name><surname>Vlachos</surname><given-names>A</given-names></name>, <name><surname>Schuldt</surname><given-names>G</given-names></name>, <name><surname>Zahn</surname><given-names>N</given-names></name>, <name><surname>Deller</surname><given-names>T</given-names></name>, <name><surname>Wittum</surname><given-names>G</given-names></name>. <article-title>SpineLab: tool for three-dimensional reconstruction of neuronal cell morphology</article-title>. <source>J Biomed Opt</source>. <year>2012</year>;<volume>17</volume>(<issue>7</issue>):<fpage>076007</fpage><comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1117/1.JBO.17.7.076007">10.1117/1.JBO.17.7.076007</ext-link></comment> .<?supplied-pmid 22894490?><pub-id pub-id-type="pmid">22894490</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
