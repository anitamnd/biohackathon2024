<?all-math-mml yes?>
<?use-mml?>
<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.2?>
<?ConverterInfo.XSLTName nihms2pmcx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<?origin ukpmcpa?>
<?ManuscriptPrefix new?>
<?iso-abbr J R Stat Soc Ser C Appl Stat?>
<?submitter-userid 0?>
<?domain wtpa?>
<?pmc-id-preallocated 7612194?>
<?properties manuscript?>
<?origin ukpmcpa?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-journal-id">101086541</journal-id>
    <journal-id journal-id-type="nlm-ta">J R Stat Soc Ser C Appl Stat</journal-id>
    <journal-id journal-id-type="iso-abbrev">J R Stat Soc Ser C Appl Stat</journal-id>
    <journal-title-group>
      <journal-title>Journal of the Royal Statistical Society. Series C, Applied statistics</journal-title>
    </journal-title-group>
    <issn pub-type="ppub">0035-9254</issn>
    <issn pub-type="epub">1467-9876</issn>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7612194</article-id>
    <article-id pub-id-type="manuscript">ems140622</article-id>
    <article-id pub-id-type="doi">10.1111/rssc.12490</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A computationally efficient Bayesian seemingly unrelated regressions model for high-dimensional quantitative trait loci discovery</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Bottolo</surname>
          <given-names>Leonardo</given-names>
        </name>
        <xref ref-type="aff" rid="A1">1</xref>
        <xref ref-type="aff" rid="A2">2</xref>
        <xref ref-type="aff" rid="A3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Banterle</surname>
          <given-names>Marco</given-names>
        </name>
        <xref ref-type="aff" rid="A4">4</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Richardson</surname>
          <given-names>Sylvia</given-names>
        </name>
        <xref ref-type="aff" rid="A2">2</xref>
        <xref ref-type="aff" rid="A3">3</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Ala-Korpela</surname>
          <given-names>Mika</given-names>
        </name>
        <xref ref-type="aff" rid="A5">5</xref>
        <xref ref-type="aff" rid="A6">6</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Järvelin</surname>
          <given-names>Marjo-Riitta</given-names>
        </name>
        <xref ref-type="aff" rid="A7">7</xref>
        <xref ref-type="aff" rid="A8">8</xref>
        <xref ref-type="aff" rid="A9">9</xref>
        <xref ref-type="aff" rid="A10">10</xref>
        <xref ref-type="aff" rid="A11">11</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-0081-7582</contrib-id>
        <name>
          <surname>Lewin</surname>
          <given-names>Alex</given-names>
        </name>
        <xref ref-type="aff" rid="A4">4</xref>
      </contrib>
    </contrib-group>
    <aff id="A1"><label>1</label>Department of Medical Genetics, University of Cambridge, Cambridge, UK</aff>
    <aff id="A2"><label>2</label>The Alan Turing Institute, London, UK</aff>
    <aff id="A3"><label>3</label>MRC Biostatistics Unit, Cambridge, UK</aff>
    <aff id="A4"><label>4</label>Department of Medical Statistics, London School of Hygiene and Tropical Medicine, London, UK</aff>
    <aff id="A5"><label>5</label>Computational Medicine, Faculty of Medicine, University of Oulu and Biocenter Oulu, Oulu, Finland</aff>
    <aff id="A6"><label>6</label>NMR Metabolomics Laboratory, School of Pharmacy, University of Eastern Finland, Kuopio, Finland</aff>
    <aff id="A7"><label>7</label>Center for Life Course Health Research, University of Oulu, Oulu, Finland</aff>
    <aff id="A8"><label>8</label>Biocenter Oulu, University of Oulu, Oulu, Finland</aff>
    <aff id="A9"><label>9</label>Department of Epidemiology and Biostatistics, Imperial College London, London, UK</aff>
    <aff id="A10"><label>10</label>MRC-PHE Centre for Environment and Health, Imperial College London, London, UK</aff>
    <aff id="A11"><label>11</label>Department of Life Sciences, Brunel University London, Uxbridge, UK
</aff>
    <author-notes>
      <corresp id="CR1"><bold>Correspondence</bold> Alex Lewin, Department of Medical Statistics, London School of Hygiene and Tropical Medicine, London, UK. <email>alex.lewin@lshtm.ac.uk</email></corresp>
    </author-notes>
    <pub-date pub-type="nihms-submitted">
      <day>20</day>
      <month>12</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="ppub">
      <month>8</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>8</day>
      <month>5</month>
      <year>2021</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>07</day>
      <month>1</month>
      <year>2022</year>
    </pub-date>
    <volume>70</volume>
    <issue>4</issue>
    <fpage>886</fpage>
    <lpage>908</lpage>
    <permissions>
      <ali:free_to_read xmlns:ali="http://www.niso.org/schemas/ali/1.0/"/>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution</ext-link> License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="https://rss.onlinelibrary.wiley.com/doi/10.1111/rssc.12490"/>
    <abstract>
      <p id="P1">Our work is motivated by the search for metabolite quantitative trait loci (QTL) in a cohort of more than 5000 people. There are 158 metabolites measured by NMR spectroscopy in the 31-year follow-up of the Northern Finland Birth Cohort 1966 (NFBC66). These metabolites, as with many multivariate phenotypes produced by high-throughput biomarker technology, exhibit strong correlation structures. Existing approaches for combining such data with genetic variants for multivariate QTL analysis generally ignore phenotypic correlations or make restrictive assumptions about the associations between phenotypes and genetic loci. We present a computationally efficient Bayesian seemingly unrelated regressions model for high-dimensional data, with cell-sparse variable selection and sparse graphical structure for covariance selection. Cell sparsity allows different phenotype responses to be associated with different genetic predictors and the graphical structure is used to represent the conditional dependencies between phenotype variables. To achieve feasible computation of the large model space, we exploit a factorisation of the covariance matrix. Applying the model to the NFBC66 data with 9000 directly genotyped single nucleotide polymorphisms, we are able to simultaneously estimate genotype–phenotype associations and the residual dependence structure among the metabolites. The R package <monospace>BayesSUR</monospace> with full documentation is available at <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/BayesSUR/">https://cran.r-project.org/web/packages/BayesSUR/</ext-link>
</p>
    </abstract>
    <kwd-group>
      <kwd>Bayesian computation</kwd>
      <kwd>covariance reparametrisation</kwd>
      <kwd>graphical models</kwd>
      <kwd>Markov chain Monte Carlo</kwd>
      <kwd>metabolomics</kwd>
      <kwd>quantitative trait loci</kwd>
    </kwd-group>
  </article-meta>
</front>
<body>
  <sec sec-type="intro" id="S1">
    <label>1</label>
    <title>Introduction</title>
    <p id="P2">Integrating high-dimensional molecular biomarker data sets is a fundamental problem in genetic epidemiology and bioinformatics, in the search for molecular mechanisms mediating the effects of genetic variants on clinical phenotypes. An important step in this search is to find associations between a set of genetic variants and downstream molecular phenotypes such as gene expression, proteomics, metabolomics or epigenetic data (quantitative trait loci or QTL analysis). In the simplest analysis, univariate regressions are performed for each phenotype–genotype pair, needing post hoc adjustment for multiple comparisons and ignoring any correlations between genotypes and between phenotypes. This is unlikely to be the best strategy for data where latent structures induce high levels of correlation between phenotypes, for example serum metabolomic profiles (<xref rid="R25" ref-type="bibr">Kettunen et al., 2012</xref>; <xref rid="R49" ref-type="bibr">Soininen et al., 2009</xref>), imaging and gene expressions. Comparison studies show that using multivariate quantitative phenotypes increases the statistical power in association tests compared to univariate analysis (<xref rid="R15" ref-type="bibr">Fusi et al., 2012</xref>; <xref rid="R22" ref-type="bibr">Inouye et al., 2012</xref>).</p>
    <p id="P3">In this paper, we develop a model designed for integrated multivariate QTL analysis, particular aimed at highly correlated molecular phenotypes. Our case study is in metabolomics quantitative trait locus (mQTL), a powerful approach used to identify genes associated with metabolic markers of diseases, where the multivariate response is generally on the order of hundreds of metabolites. The model is also suitable for other multivariate molecular phenotypes. We have a data set from the Northern Finland Birth Cohort 1966 (NFBC66) 31-year follow-up, consisting of 158 nuclear magnetic resonance (NMR) spectroscopy measured metabolites and over 9000 directly genotyped single nucleotide polymorphisms (SNPs) on chromosome 16, with a sample size of more than 5000 people. The metabolites set comprises lipoprotein particle concentrations, low molecular weight metabolites such as amino acids, 3-hydroxybutyrate and creatinine and different serum lipids, including free and esterified cholesterol, sphingomyelin and fatty acid saturation. These data exhibit strong residual correlation (<xref rid="R25" ref-type="bibr">Kettunen et al., 2012</xref>; <xref rid="R30" ref-type="bibr">Marttinen et al., 2014</xref>), even after accounting for the variance explained by all reported SNPs.</p>
    <p id="P4"><xref rid="R5" ref-type="bibr">Brown et al. (1998</xref>, <xref rid="R6" ref-type="bibr">2002)</xref> developed a general framework for Bayesian variable selection (BVS) models for multivariate outcomes (<italic>s</italic> responses) and multiple predictors (<italic>p</italic> covariates). In applications of this model, two alternative simplifying assumptions have been made in order to improve computational efficiency. The first simplifying assumption is to assume row sparsity, in which a single set of predictors is selected across all response variables. <xref rid="R35" ref-type="bibr">Petretto et al. (2010)</xref> use this assumption for expression quantitative trait loci (eQTL) analysis, with a dense residual covariance matrix across responses. <xref rid="R2" ref-type="bibr">Bhadra and Mallick (2013)</xref> also assume row sparsity, but include sparse residual covariance selection between regressions, using graphical modelling based on decomposable graphs. In these models, row sparsity induces conjugacy for regression coefficients and residual covariances, so these parameters are integrated out, resulting in a model search over the space of variable selection indicator variables. This approach has been used for small numbers of response variables (e.g. <italic>s</italic> around 10), with the number of predictors <italic>p</italic> in the thousands.</p>
    <p id="P5">The second simplifying assumption is to assume conditional independence between regressions. <xref rid="R23" ref-type="bibr">Jia and Xu (2007)</xref>, <xref rid="R4" ref-type="bibr">Bottolo et al. (2011)</xref>, <xref rid="R47" ref-type="bibr">Scott-Boyer et al. (2012)</xref>, <xref rid="R43" ref-type="bibr">Ruffieux et al. (2017</xref>, <xref rid="R44" ref-type="bibr">2020a</xref>, <xref rid="R45" ref-type="bibr">b</xref>) take this approach for eQTL analysis, using hierarchical sparsity priors on the probabilities of associations, to share information across the gene expression outcomes. The assumption of residual independence between regressions ensures conjugacy of the regression coefficients and residual variances, enabling exploration of the full posterior space of selection models. In this scenario different predictors can be associated with different response variables without losing conjugacy. We refer to this as cell sparsity. These hierarchical models can be used for larger numbers response variables, for example, <italic>s</italic> in the hundreds or thousands.</p>
    <p id="P6">Biologically complex phenotypes such as metabolomics and proteomics show strong correlation structures in comparison with transcriptomics data used in eQTL analyses, for which most BVS models have been developed. Therefore, accounting for correlation not only to better reveal associations with genetic profiles, but also to infer their dependence structure, is becoming increasingly important to improve our understanding of integrated functioning of living organisms (<xref rid="R9" ref-type="bibr">Cichonska et al., 2016</xref>; <xref rid="R39" ref-type="bibr">Rodriguez-Martinez et al., 2017</xref>). Suitable statistical tools which can tackle these problems while retaining computational feasibility are thus necessary.</p>
    <p id="P7">We present a Bayesian model for multivariate QTL analysis with correlated phenotypes, allowing for (i) cell sparsity in the genotype–phenotype associations and (ii) residual dependence among phenotypes. We present two versions of the model, one with dense residual dependence structure and one with sparse covariance selection. Each instance of the multivariate regression model has the form of a seemingly unrelated regressions (SUR) model. We exploit a factorisation of the covariance matrix parameter to enable faster computation using Markov chain Monte Carlo (MCMC) methods. We are able to infer associations with thousands of candidate predictors (<italic>p</italic> over 9000) multivariately on all responses. In the case of sparse covariance, thanks to the computationally efficient junction tree representation of a decomposable graph as its state variable (<xref rid="R19" ref-type="bibr">Green &amp; Thomas, 2013</xref>), we also infer an underlying graph detailing the conditional independence relationships between hundreds of responses (<italic>s</italic> = 158).</p>
    <p id="P8">The Bayesian framework has the advantage that it allows flexible sparsity priors on the regression and covariance coefficients, while being transparent about the overall level of sparsity. It also provides a rich output, full posterior distributions of coefficients and probabilities of variable inclusion.</p>
    <p id="P9">The factorisation we use is related to the Cholesky decomposition of the precision matrix and was first proposed in the graphical modelling literature by <xref rid="R54" ref-type="bibr">Wermuth (1980)</xref> for multivariate Gaussian data with zero means and has been used in these so called ‘covariance selection’ models for computational convenience and for interpretability of the now unconstrained transformed off-diagonal elements of the covariance matrix, see for example <xref rid="R36" ref-type="bibr">Pourahmadi (1999)</xref>, <xref rid="R50" ref-type="bibr">Stingo and Marchetti (2014)</xref>. Modelling Cholesky factors is also popular in econometrics in both conditional and simultaneous autoregressive models (<xref rid="R11" ref-type="bibr">Datta et al., 2019</xref>). <xref rid="R53" ref-type="bibr">Wang et al. (2012)</xref> use a similar idea in the context of sampling the parameters for the Bayesian lasso, and <xref rid="R56" ref-type="bibr">Zellner and Ando (2010)</xref> used this reparametrisation for a SUR model with fixed covariates that is not resulting from variable selection.</p>
    <p id="P10">To our knowledge, this is the first model proposed for fully Bayesian analysis for multivariate QTLs allowing for both cell-sparsity and residual dependence. A similar model was proposed by <xref rid="R52" ref-type="bibr">Wang (2010)</xref> for autoregressive models in econometrics, with two computational algorithms, an MCMC algorithm using Gibbs updates (<xref rid="R16" ref-type="bibr">George &amp; McCulloch, 1993</xref>) for variable selection called ‘indirect’ and a ‘direct’ algorithm involving numerical approximation of the marginal likelihood (<xref rid="R8" ref-type="bibr">Chib, 1995</xref>) combined with a Metropolis–Hastings algorithm for posterior models exploration. Both approaches work well for small data sets but are computationally prohibitive in high-dimensional space comprising hundreds of responses and predictors such as in molecular QTL work. Our novel contribution to the computational method is that we derive the priors (dense and sparse versions) in the space of the transformed covariance matrix and therefore run the whole computation in this space, enabling parallelisation over the response variables. We are thus able to estimate models for mQTLs with hundreds of response variables and thousands of predictors.</p>
    <p id="P11"><xref ref-type="sec" rid="S2">Section 2</xref> introduces the model including the derived priors in the transformed space. <xref ref-type="sec" rid="S7">Section 3</xref> provides the posterior computations for the parameters and details the MCMC algorithm used to estimate them. In <xref ref-type="sec" rid="S8">Section 4</xref>, the method is validated in an extensive simulation study, where we show that we can estimate larger models with more accuracy in considerably less computational time than the <xref rid="R52" ref-type="bibr">Wang (2010)</xref> software. We also obtain similar sensitivity but fewer false positives than the penalized likelihood method with simultaneous estimation of regression coefficients and covariance structure proposed by <xref rid="R40" ref-type="bibr">Rothman et al. (2010)</xref>. <xref ref-type="sec" rid="S11">Section 5</xref> presents the results on the NFBC66 mQTL data set, including visualisation both of the genotype–phenotype associations and of the residual dependence structure between metabolites.</p>
    <p id="P12">Further details of model derivations and posterior updates are available in the Supplementary Material. An R package <monospace>BayesSUR</monospace> with full documentation is available at <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/web/packages/BayesSUR/">https://cran.r-project.org/web/packages/BayesSUR/</ext-link>.</p>
  </sec>
  <sec id="S2">
    <label>2</label>
    <title>Model</title>
    <p id="P13">The model can be seen as a set of regressions for multivariate phenotype responses <italic><bold>Y</bold></italic> = (<bold><italic>y</italic></bold>
<sub>1</sub>, …, <bold><italic>y</italic></bold>
<sub><italic>s</italic></sub>), <italic><bold>y</bold><sub>k</sub></italic> = (<italic>y</italic>
<sub>1<italic>k</italic></sub>, …, <italic>y<sub>nk</sub></italic>)<sup><italic>T</italic></sup>, for <italic>k</italic> = 1, …, <italic>s</italic> and corresponding covariate genotype matrices <italic><bold>X</bold><sub>k</sub></italic> with dimensions <italic>n</italic> × <italic>p</italic>. We assume independence between samples, but allow for dependence across responses. Moreover, we assume that the same set of predictors is available for all responses. The same set of genotypes may be used for all regressions, but this is not necessary. The predictors may be continuous or categorical, hence the model accommodates the usual additive genetic association models using observed and imputed allele counts or can be extended to more complex genetic models including interactions.</p>
    <p id="P14">Variable selection is performed on the predictors using binary indicators vector <italic><bold>γ</bold><sub>k</sub></italic> = (<italic>γ<sub>k</sub></italic>
<sub>1</sub>, …, <italic>γ<sub>kp</sub></italic>)<sup><italic>T</italic></sup>, where <italic>γ<sub>kj</sub></italic> is 1 if covariate <italic>j</italic> is included in the regression for response <italic>k</italic> and 0 if not. We use the shorthand notation <italic><bold>X</bold><sub><bold>γ</bold>k</sub></italic> for the columns of <italic><bold>X</bold><sub>k</sub></italic> selected by the vector <italic><bold>γ</bold><sub>k</sub></italic> and similar for <italic><bold>β</bold><sub><bold>γ</bold>k</sub></italic>. Thus, we can write the set of linked regressions as <disp-formula id="FD1"><label>(1)</label><mml:math id="M1"><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo></mml:math></disp-formula>
but most importantly the residuals will be correlated, that is, <bold><italic>u</italic></bold>
<sub>i</sub> = (<italic>u</italic>
<sub><italic>i</italic>1</sub>, …, <italic>u<sub>is</sub></italic>) ∼ N(<bold>0</bold>, <italic>C</italic>). We can also write the likelihood for this model as <disp-formula id="FD2"><mml:math id="M2"><mml:mi mathvariant="script">Y</mml:mi><mml:mo>∣</mml:mo><mml:mi mathvariant="script">X</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>∼</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="script">X</mml:mi><mml:mi>γ</mml:mi></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mi>γ</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>⊗</mml:mo><mml:msub><mml:mo>⫾</mml:mo><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula> where 𝑦 = vec(<italic>Y</italic>), vec(<italic>·</italic>) being the vectorisation operator, <bold><italic>γ</italic></bold> = vec(<bold><italic>γ</italic></bold>
<sub>1</sub>, …, <bold><italic>γ</italic></bold>
<sub>s</sub>), <bold><italic>β</italic></bold>
<sub><bold><italic>γ</italic></bold>1</sub> = vec(<italic><bold>β</bold><sub><bold>γ</bold><sub>1</sub></sub></italic>, …, <bold><italic>β</italic></bold>
<sub><italic>γ</italic><sub>s</sub></sub>) and <italic>χ</italic>
<sub><bold><italic>γ</italic></bold></sub> is a block-diagonal matrix with <italic><bold>X</bold></italic>
<sub><italic><bold>γ</bold>k</italic></sub> as the <italic>k</italic>-th diagonal element.</p>
    <p id="P15">Following <xref rid="R16" ref-type="bibr">George and McCulloch (1993)</xref>, we set <italic>β<sub>kj</sub></italic> = 0 conditional on <italic>γ<sub>kj</sub></italic> = 0, while nonzero coefficients follow a diffuse normal distribution, that is, <inline-formula><mml:math id="M3"><mml:mi>β</mml:mi><mml:mo>∣</mml:mo><mml:mi>γ</mml:mi><mml:mo>∼</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mi>γ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>
<bold><italic>γ</italic></bold>. The precision matrix <italic>W</italic> is generally decomposed into a shrinking coefficient, say <italic>w</italic>, and a matrix that governs the covariance structure. Here, we use <inline-formula><mml:math id="M4"><mml:msub><mml:mi>W</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>□</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>γ</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula>, with an inverse-gamma prior on <italic>w</italic> and |<bold><italic>γ</italic></bold>| the number of selected predictors across all outcomes. A number of sparsity inducing priors for <bold><italic>γ</italic></bold> have been used in the literature, the most common being <italic>γ<sub>kj</sub></italic> ∼ Ber(<italic>π</italic>) with a fixed or random <italic>π</italic>. Another choice in QTL analysis is the ‘hotspot detection’ prior used in <xref rid="R4" ref-type="bibr">Bottolo et al. (2011)</xref>, which decomposes the inclusion probability into an overall sparsity level for each outcome (<italic>o<sub>k</sub></italic>) and a propensity parameter (<italic>π<sub>j</sub></italic>) for each predictor, that is, <italic>γ<sub>kj</sub></italic> ∼ Ber(<italic>o<sub>k</sub></italic> × <italic>π<sub>j</sub></italic>). In this work, we use the hotspot detection model with a beta prior on <italic>o<sub>k</sub></italic> and a gamma prior on the propensity <italic>π<sub>j</sub></italic> and its simplified version with <italic>π<sub>j</sub></italic> = 1, <italic>j</italic> = 1, …, <italic>p</italic>, which corresponds to a beta-binomial sparsity prior for each response.</p>
    <sec id="S3">
      <label>2.1</label>
      <title>Factorisation of the likelihood</title>
      <p id="P16">If one assumes either a diagonal <italic>C</italic> or row sparsity for <italic><bold>γ</bold></italic>
<sub><italic>k</italic></sub>, with conjugate priors on <italic>C</italic> and <bold><italic>β<sub>γ</sub></italic></bold>, both <bold><italic>β<sub>γ</sub></italic></bold> and <italic>C</italic> can be integrated out analytically (<xref rid="R2" ref-type="bibr">Bhadra &amp; Mallick, 2013</xref>). In our model, the usual priors on these parameters lose conjugacy and cannot be integrated out. Nonetheless, the full conditionals retain their simple forms, so it is straightforward to write a Gibbs sampler for the posterior distributions (<xref rid="R21" ref-type="bibr">Holmes et al., 2002</xref>). The computational time needed is, however, prohibitive for most high-dimensional settings.</p>
      <p id="P17">To overcome this issue, we decompose the covariance matrix <italic>C</italic> iteratively as <disp-formula id="FD3"><mml:math id="M5"><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>c</mml:mi><mml:mi>k</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula> for all <italic>k</italic> = 2, …, <italic>s</italic>, with <italic>C</italic>
<sub>(<italic>s</italic>)</sub> = <italic>C</italic> and <italic>C</italic>
<sub>(1)</sub> = <italic>c</italic>
<sub>1</sub> = <italic>C</italic>
<sub>11</sub> (the scalar variance of response 1) and <bold><italic>c</italic></bold>
<sub>1</sub> is null. Thus, each <italic>C</italic>
<sub>(<italic>k</italic>)</sub> is the marginal covariance matrix for responses 1, …, <italic>k</italic>, <italic>c<sub>k</sub></italic> is the variance of response <italic>k</italic> and <bold><italic>c</italic></bold>
<sub><bold>k</bold></sub> is the vector of covariances between response <italic>k</italic> and responses {1, …, <italic>k</italic> − 1}.</p>
      <p id="P18">With this decomposition, the likelihood can be factorised (e.g. <xref rid="R17" ref-type="bibr">Giri, 2014</xref>) as <disp-formula id="FD4"><label>(2)</label><mml:math id="M6"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">Y</mml:mi><mml:mo>∣</mml:mo><mml:mi mathvariant="script">X</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∏</mml:mo></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>s</mml:mi></mml:munderover><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mo>⫾</mml:mo><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula> where <italic>U</italic>
<sub>(<italic>k</italic>−1)</sub> = <italic>Y</italic>
<sub>(<italic>k</italic>−1)</sub> − (<italic>X<sub><bold>γ</bold></sub></italic>
<sub>1</sub>
<bold><italic>β</italic></bold>
<sub><bold><italic>β</italic></bold><sub>1</sub></sub>
<italic>X<sub><bold>γ</bold></sub></italic>
<sub>2</sub>
<bold><italic>β</italic><sub><italic>γ</italic><sub>2</sub></sub></bold> … <italic>X<sub><bold>γ</bold></sub><sub><italic>k</italic><sub>−1</sub></sub></italic>
<italic>α<sub><bold>γ</bold></sub><sub><italic>k</italic><sub>−1</sub></sub></italic>) is a matrix consisting of the first <italic>k</italic> − 1 residuals from the original linked regressions where <italic>U</italic>
<sub>(0)</sub> is null. For <italic>k</italic> = 1, the likelihood simplifies to <inline-formula><mml:math id="M7"><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>∣</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mrow/><mml:mi>n</mml:mi></mml:msub><mml:mtext>​</mml:mtext><mml:msub><mml:mo>⫾</mml:mo><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>. The parameters <inline-formula><mml:math id="M8"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> and <bold><italic>ρ</italic></bold>
<sub><italic>k</italic></sub> are also defined through the reparametrisation of the residual covariance matrix, that is, <inline-formula><mml:math id="M9"><mml:msubsup><mml:mi>σ</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <disp-formula id="FD5"><label>(3)</label><mml:math id="M10"><mml:mrow><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mi>k</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>.</mml:mo></mml:math></disp-formula>
</p>
      <p id="P19">Note that the joint distribution <italic>p</italic>(𝑦 | <bold><italic>χ</italic></bold>, <bold><italic>β</italic></bold>, <bold><italic>γ</italic></bold>, <italic>C</italic>) is the same regardless of the order used for the decomposition since we are simply factorising it by chain conditioning. From Equation (<xref ref-type="disp-formula" rid="FD4">2</xref>), it is straightforward to see that <inline-formula><mml:math id="M11"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> is the residual variance of response <italic>k</italic> conditioned on <italic>U</italic>
<sub>(<italic>k</italic>−1)</sub> and <bold><italic>ρ</italic></bold>
<sub>k</sub> is the (<italic>k</italic> − 1)-vector of regression coefficients on the same <italic>U</italic>
<sub>(<italic>k</italic>−1)</sub> residuals. The likelihood is thus decomposed into a product of independent (conditionally on the new parameters) factors over the outcomes. The novelty of our approach is two-fold. First, we estimate our model completely in the reparametrised space, deriving priors and posterior full conditionals for the parameters <inline-formula><mml:math id="M12"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> and <bold><italic>ρ</italic></bold>
<sub><italic>k</italic></sub>. Second, this allows us to update these parameters in parallel, which greatly increases the computational efficiency of this model.</p>
    </sec>
    <sec id="S4">
      <label>2.2</label>
      <title>Prior for dense residual dependence</title>
      <p id="P20">In order to take advantage of the factorisation of the model across responses, we must also transform the model priors. For modelling dense dependence structure between responses, we use an inverse-Wishart prior on the original covariance matrix <italic>C</italic> ∼ IW(<italic>ν</italic>, <italic>M</italic>). We use standard matrix properties of the inverse-Wishart distribution (<xref rid="R12" ref-type="bibr">Dawid, 1981</xref>; <xref rid="R13" ref-type="bibr">Dempster, 1969</xref>; <xref rid="R41" ref-type="bibr">Roverato, 2000</xref>) to calculate the transformed prior. The <italic>C</italic>
<sub>(<italic>k</italic>)</sub> is a submatrix of <italic>C</italic>, thus it also has an inverse-Wishart distribution. The new parameters are related to the block structure of the inverse of this matrix, <inline-formula><mml:math id="M13"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> being the Schur complement of <italic>C</italic>
<sub>(<italic>k</italic>−1</sub>) in <italic>C</italic>
<sub>(<italic>k</italic>)</sub> and <inline-formula><mml:math id="M14"><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula>. Decomposing <italic>M</italic> conformally with <italic>C</italic> into <inline-formula><mml:math id="M15"><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>m</mml:mi><mml:mi>k</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula> for <italic>k</italic> = 2, …, <italic>s</italic>, the priors on the changed variables become <disp-formula id="FD6"><mml:math id="M16"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>∼</mml:mo><mml:mtext>IGa</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>m</mml:mi><mml:mi>k</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mi>M</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>m</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>∼</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>M</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>m</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mi>M</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> for <italic>k</italic> = 2, …, <italic>s</italic>, and <inline-formula><mml:math id="M17"><mml:msubsup><mml:mi>σ</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>∼</mml:mo><mml:mi>I</mml:mi><mml:mi>G</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>. From the prior on <inline-formula><mml:math id="M18"><mml:msubsup><mml:mi>σ</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>, we can see that we the degrees of freedom in the inverse-Wishart distribution must be chosen to be <italic>ν</italic> &gt; <italic>s</italic> − 1. Moreover, from these equations, we can see that we obtain independent priors for <inline-formula><mml:math id="M19"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> and <bold><italic>ρ</italic></bold>
<sub><italic>k</italic></sub> for different <italic>k</italic>. Thus, since both likelihood and prior factorise across responses, the posterior full conditionals also factorise and hence the MCMC update of the residual covariance parameters can be parallelised.</p>
    </sec>
    <sec id="S5">
      <label>2.3</label>
      <title>Prior for sparse residual dependence</title>
      <p id="P21">To model sparsity in the residual dependency structure, we introduce a decomposable graph <italic>G</italic> such that variables are conditionally independent if there is no direct edge between them in the graph (<xref rid="R27" ref-type="bibr">Lauritzen, 1996</xref>). Conditional on the graph, we use the hyper inverse-Wishart prior on the original covariance matrix <italic>C</italic> ∼ HIW<sub><italic>G</italic></sub>(<italic>ν</italic>, <italic>M</italic>) (<xref rid="R7" ref-type="bibr">Carvalho et al., 2007</xref>). This is defined as the distribution such that the covariance matrix for each prime component in the decomposable graph is marginally inverse Wishart, that is, <italic>C<sub>Pq</sub></italic> ∼ IW(<italic>ν</italic> − (<italic>s</italic> − |<italic>P<sub>q</sub></italic>|), <italic>M<sub>Pq</sub></italic>), where <italic>P<sub>q</sub></italic> is the <italic>q</italic>-th prime component, <italic>M<sub>Pq</sub></italic> is the sub-matrix of <italic>M</italic> corresponding to <italic>P<sub>q</sub></italic> and |<italic>Pq</italic>| is its cardinality.</p>
      <p id="P22">In the following, we derive the corresponding prior for the transformed variables <inline-formula><mml:math id="M20"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> and <bold><italic>ρ</italic></bold>
<sub><italic>k</italic></sub> under the assumption of a sparse covariance matrix. A more in depth derivation of the following results can be found in the Supplementary Material <xref ref-type="supplementary-material" rid="SD1">Section S.1.1</xref>. Briefly, the decomposability of the graph <italic>G</italic> allows us to define a sequence of complete, overlapping, subgraphs (i.e. cliques) called ‘prime components’ <italic>P<sub>q</sub></italic>, <italic>q</italic> ∈ (1, …, <italic>Q</italic>) that can be ordered in such a way that for every <italic>q</italic> &gt; 1 there exists <italic>m</italic> &lt; <italic>q</italic> such that <italic>P<sub>q</sub></italic> ⋂ <italic>H<sub>q</sub> ⊂ P<sub>m</sub></italic>, where <inline-formula><mml:math id="M21"><mml:msub><mml:mi>H</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>∪</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> for <italic>q</italic> = 2, …, <italic>Q</italic>. We also define the separators <italic>S<sub>q</sub></italic> = <italic>P<sub>q</sub></italic> ⋂ <italic>H<sub>q</sub></italic> and residuals <italic>R<sub>q</sub></italic> = <italic>P<sub>q</sub> \ S<sub>q</sub></italic> for <italic>q</italic> = 2, …, <italic>Q</italic>. The nodes of <italic>G</italic> can also be arranged according to a so-called ‘perfect elimination ordering’, denoted by <italic>ξ</italic>, which implies that if Λ<sub><italic>ξ</italic>(<italic>k</italic>)<italic>ξ</italic>(<italic>l</italic>)</sub> = 0 then <italic>ρ<sub>ξ</sub></italic>
<sub>(<italic>k</italic>)<italic>ξ</italic>(<italic>l</italic>)</sub> = 0, where Λ is the precision matrix <italic>C</italic>
<sup>−1</sup> (<xref rid="R34" ref-type="bibr">Paulsen et al., 1989</xref>).</p>
      <p id="P23">Due to this correspondence between Λ<sub><italic>ξ</italic>(<italic>k</italic>)<italic>ξ</italic>(<italic>l</italic>)</sub> = 0 and <italic>ρ<sub>ξ</sub></italic>
<sub>(<italic>k</italic>)<italic>ξ</italic>(<italic>l</italic>)</sub> = 0, the transformation in Equation (<xref ref-type="disp-formula" rid="FD5">3</xref>) decomposes across the prime components, so that, for nodes ordered according to a perfect elimination ordering, the new variables <inline-formula><mml:math id="M22"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> and <bold><italic>ρ</italic></bold>
<sub><italic>k</italic></sub> are defined within the prime components, that is, <disp-formula id="FD7"><mml:math id="M23"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>c</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>c</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <inline-formula><mml:math id="M24"><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> is the submatrix of <italic>C<sub>P<sub>q</sub></sub></italic> with variable <italic>k</italic> removed and <bold><italic>c</italic></bold>
<sub><italic>k</italic></sub>
<sub>,<italic>Pq</italic></sub> is the final column of <italic>C<sub>Pq</sub></italic> without the last element. All other elements of <bold><italic>ρ</italic></bold>
<sub><italic>k</italic></sub> are zero.</p>
      <p id="P24">We parameterise <italic>G</italic> using the junction tree representation of a decomposable graph as its state variable proposed by <xref rid="R19" ref-type="bibr">Green and Thomas (2013)</xref>. A decomposable graph may have many junction tree representations. However, for a given junction tree <italic>J</italic>, the implied graph <italic>G</italic> is uniquely determined.</p>
      <p id="P25">To write the densities explicitly, we need to order the nodes using the perfect elimination order <italic>ξ</italic>, which respects the perfect ordering of the prime components. With this ordering, we find that the hyper inverse-Wishart prior on <italic>C</italic> is transformed to <disp-formula id="FD8"><mml:math id="M25"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>J</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∏</mml:mo></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:munder><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∏</mml:mo></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mi>Q</mml:mi></mml:munderover><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∏</mml:mo></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:munder><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula> where the ordering of nodes within each residual does not matter. The corresponding prior densities are <disp-formula id="FD9"><label>(4)</label><mml:math id="M26"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>∼</mml:mo><mml:mtext>IGa</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>m</mml:mi><mml:mi>k</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mi>M</mml:mi><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>m</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula>
<disp-formula id="FD10"><label>(5)</label><mml:math id="M27"><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>∼</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>M</mml:mi><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mi>m</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mi>M</mml:mi><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula> where <italic>q</italic> is the index of the prime residual that node <italic>k</italic> belongs to in the particular node ordering of the graph, for all <italic>k</italic>, except for the first node, that is, <inline-formula><mml:math id="M28"><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:msup><mml:mi>ξ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>∼</mml:mo><mml:mtext>IGa</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>j</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></inline-formula>. The sets <italic>P<sub>q</sub></italic> and <italic>S<sub>q</sub></italic> are defined above. The index <italic>t</italic> in <xref ref-type="disp-formula" rid="FD9">Equations (4)</xref> and <xref ref-type="disp-formula" rid="FD10">(5)</xref> is the index of the node within the graph residual component and is given by <inline-formula><mml:math id="M29"><mml:msub><mml:mi>ξ</mml:mi><mml:mi>J</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:math></inline-formula>. Here, we have applied similar arguments as for the dense covariance case presented in <xref ref-type="sec" rid="S4">Section 2.2</xref>, using the properties of block matrices and the inverse-Wishart distribution. Again, we see that the priors factorise over responses, so the posterior full conditionals in Equations (<xref ref-type="disp-formula" rid="FD9">4</xref>) and (<xref ref-type="disp-formula" rid="FD10">5</xref>) also factorise enabling faster computation of the model through parallelization of the MCMC updates. An important feature of working with this transformation is that we do not need to do any completion operation to fill in the covariances between the separated parts of prime components (<xref rid="R7" ref-type="bibr">Carvalho et al., 2007</xref>) since these correspond to the zeros in the <bold><italic>ρ</italic></bold>
<sub><italic>k</italic></sub>, <italic>k</italic> = 1, …, <italic>s</italic>, parameters.</p>
      <p id="P26">We use a prior on the junction tree <italic>J</italic> which is proportional to a Binomial distribution on the number of edges |<italic>J</italic>| in the graph, that is, <inline-formula><mml:math id="M30"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo>∣</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mo>∣</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mo>∣</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msup></mml:math></inline-formula>. Since sparser graphs in general have more junction tree representations (<xref rid="R51" ref-type="bibr">Thomas &amp; Green, 2009</xref>), this prior favours sparse structures. Finally, we use a conjugate Beta prior on the hyperparameter <italic>η</italic>.</p>
    </sec>
    <sec id="S6">
      <label>2.4</label>
      <title>Summary of full model</title>
      <p id="P27">In this section, we summarise the full model with all its conditional dependencies. We provide the version using the sparse covariance structure. The dense covariance case is as below, except that there are no <italic>J</italic> or <italic>η</italic> parameters and the distributions for <inline-formula><mml:math id="M31"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula> and <bold><italic>ρ</italic></bold>
<sub>k</sub> are the simpler expressions presented in <xref ref-type="sec" rid="S4">Section 2.2</xref>. In <xref ref-type="sec" rid="S4">Sections 2.2</xref> and <xref ref-type="sec" rid="S5">2.3</xref>, we have illustrated the results in terms of a general matrix <italic>M</italic> in the (hyper) inverse-Wishart distribution. In our implementation, we use <inline-formula><mml:math id="M32"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mo>⫾</mml:mo><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula>.</p>
      <p id="P28">The joint distribution is <disp-formula id="FD11"><mml:math id="M33"><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>s</mml:mi></mml:munderover><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>
</mml:mi><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>J</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mi>η</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo>×</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:msubsup><mml:mi>ξ</mml:mi><mml:mi>J</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>J</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:munder><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>|</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>J</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mi>Q</mml:mi></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∏</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>J</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:munder><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>|</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>J</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula> where <disp-formula id="FD12"><mml:math id="M34"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>~</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>X</mml:mtext><mml:mrow><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mi>⫾</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>TESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTING</mml:mtext><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>~</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>TESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTING</mml:mtext><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>o</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>~</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>Ber</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>o</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>TESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTING</mml:mtext><mml:msub><mml:mi>o</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>~</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>Beta</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mtext>a</mml:mtext><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>TESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTING</mml:mtext><mml:msub><mml:mi>π</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>~</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>GaTESTING</mml:mtext><mml:msub><mml:mrow><mml:mtext>(a</mml:mtext></mml:mrow><mml:mi>π</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mtext>, b</mml:mtext></mml:mrow><mml:mi>π</mml:mi></mml:msub><mml:mtext>),</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>TESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTING</mml:mtext><mml:mi>w</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>~</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>IGaTESTING</mml:mtext><mml:msub><mml:mrow><mml:mtext>(a</mml:mtext></mml:mrow><mml:mi>w</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mtext>, b</mml:mtext></mml:mrow><mml:mi>w</mml:mi></mml:msub><mml:mtext>),</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>TESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTING</mml:mtext><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>|</mml:mo><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>~</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>IGa</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ν</mml:mi><mml:mo>−</mml:mo><mml:mtext>sTESTING+TESTING</mml:mtext><mml:msub><mml:mi>ξ</mml:mi><mml:mi>J</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msubsup><mml:mi>H</mml:mi><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>J</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>TESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTING</mml:mtext><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>~</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext>TESTING</mml:mtext><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>/</mml:mo><mml:mi>τ</mml:mi><mml:msub><mml:mi>⫾</mml:mi><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>TESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTING</mml:mtext><mml:mi>τ</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>~</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>Ga(</mml:mtext><mml:msub><mml:mi>a</mml:mi><mml:mi>τ</mml:mi></mml:msub><mml:mtext>, </mml:mtext><mml:msub><mml:mi>b</mml:mi><mml:mi>τ</mml:mi></mml:msub><mml:mtext>),</mml:mtext></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>TESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTING</mml:mtext><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>J</mml:mi><mml:mo>|</mml:mo><mml:mi>η</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>∝</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>-</mml:mo><mml:mtext>1</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>|</mml:mo><mml:mi>J</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mi>J</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>-</mml:mo><mml:mtext>1</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mo>|</mml:mo><mml:mi>J</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mtext>TESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTINGTESTING</mml:mtext><mml:mi>η</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mo>~</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mtext>Beta</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>η</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>η</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula> with <italic>U</italic>
<sub>(<italic>k</italic>−1)</sub> is defined as in Equation (<xref ref-type="disp-formula" rid="FD4">2</xref>) and <italic>δ</italic>
<sub>0</sub> is the Dirac delta function centred at 0. The parameter <italic>J</italic> stands for the junction tree representing the graph and |<italic>J</italic>| is the number of edges in the graph represented by the junction tree. <italic>ξ<sub>J</sub></italic> is a perfect elimination ordering of the nodes in the graph. Both <inline-formula><mml:math id="M35"><mml:msubsup><mml:mi>S</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M36"><mml:msubsup><mml:mi>H</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> depend on the graph and are defined in <xref ref-type="sec" rid="S5">Section 2.3</xref>. The index <italic>q</italic>(<italic>k</italic>) is the index of the prime residual <inline-formula><mml:math id="M37"><mml:msubsup><mml:mi>R</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> that node <italic>k</italic> belongs to in the current node ordering for graph <italic>J</italic>.</p>
      <p id="P29">Finally, the parameters <italic>a<sub>o</sub></italic>, <italic>b<sub>o</sub></italic>, <italic>a<sub>π</sub></italic>, <italic>b<sub>π</sub></italic>, <italic>a<sub>w</sub></italic>, <italic>b<sub>w</sub></italic>, <italic>a<sub>τ</sub></italic>, <italic>b<sub>τ</sub></italic> and <italic>a<sub>η</sub></italic>, <italic>b<sub>η</sub></italic> are fixed. The degrees of freedom <italic>ν</italic> &gt; <italic>s</italic> − 1 in the inverse-Wishart distribution is also fixed.</p>
    </sec>
  </sec>
  <sec id="S7">
    <label>3</label>
    <title>Posterior Computations</title>
    <p id="P30">In the original model space, posterior full conditionals for <bold><italic>β<sub>γ</sub></italic></bold> and <italic>C</italic> are available analytically (<xref rid="R21" ref-type="bibr">Holmes et al., 2002</xref>). However, these updates require inverting at every MCMC update both the |<bold><italic>γ</italic></bold>| × |<bold><italic>γ</italic></bold>| quadratic form in the selected columns of the design matrix <italic>χ</italic>
<sub><bold><italic>γ</italic></bold></sub> and the <italic>s</italic> × <italic>s</italic> matrix for the covariance matrix <italic>C</italic>. Additionally, the update of <bold><italic>γ</italic></bold> and all other unknowns where the likelihood is involved, require the heavy computation of the non-factorised likelihood. Our approach, based on the reparametrisation of <italic>C</italic> which leads to the factorisation of the model and the introduction of a sparse precision matrix <italic>via</italic> the junction tree representation of the decomposable graph <italic>G</italic> as its state variable, allows us to introduce a much more computational efficient MCMC scheme that scales well in high-dimensional settings.</p>
    <p id="P31"><xref rid="R56" ref-type="bibr">Zellner and Ando (2010)</xref> used the same reparametrisation in a simpler SUR model without variable selection, using Jeffrey’s priors. They devised a direct Monte Carlo procedure for <bold><italic>β</italic></bold>, <bold><italic>σ</italic></bold>
<sup>2</sup> and <bold><italic>ρ</italic></bold>. Their method uses an approximation to the full conditionals, with an additional resampling step for the <bold><italic>β</italic></bold>. However, it is possible to recover the correct posterior full conditional for <bold><italic>β</italic></bold>, avoiding unnecessary and computationally prohibitive resampling steps as we show below.</p>
    <p id="P32">To sample from the posterior distribution of the binary indicators vector <bold><italic>γ</italic></bold>, we use the evolutionary stochastic search (ESS) algorithm (<xref rid="R3" ref-type="bibr">Bottolo &amp; Richardson, 2010</xref>; <xref rid="R4" ref-type="bibr">Bottolo et al., 2011</xref>; <xref rid="R28" ref-type="bibr">Lewin et al., 2016</xref>), which uses a particular form of evolutionary Monte Carlo as defined in <xref rid="R29" ref-type="bibr">Liang and Wong (2000)</xref>. Within this framework, posterior samples of <bold><italic>β</italic><sub><italic>γ</italic></sub></bold>, <bold><italic>σ</italic></bold>
<sup>2</sup> and <bold><italic>ρ</italic></bold> are obtained by employing a Gibbs sampler, but used instead in the joint updates of {<bold><italic>γ</italic></bold>, <bold><italic>β</italic></bold>
<italic><sub><bold>γ</bold></sub></italic>} and {<italic>J</italic>, <bold><italic>σ</italic></bold>
<sup>2</sup>, <bold><italic>ρ</italic></bold>}. Specifically, the posterior full conditionals for <bold><italic>β<sub>γ</sub></italic></bold> and <bold><italic>σ</italic></bold>
<sup>2</sup>, <bold><italic>ρ</italic></bold> are used as proposal distributions in the joint updates with <bold><italic>γ</italic></bold> and <italic>J</italic>, respectively, since it reduces the posterior correlation between <bold><italic>γ</italic></bold>−<bold><italic>β<sub>γ</sub></italic></bold> and <italic>J</italic>–{<bold><italic>σ</italic></bold>
<sup>2</sup>, <bold><italic>ρ</italic></bold>}. In this set-up, the proposal and target densities cancel out in the Metropolis–Hastings acceptance ratios. This is known as ‘implicit marginalisation’ (<xref rid="R1" ref-type="bibr">Alexopoulos &amp; Bottolo, 2020</xref>; <xref rid="R20" ref-type="bibr">Holmes &amp; Held, 2006</xref>) since the resulting acceptance ratio does not contain the current and proposed values of <bold><italic>β<sub>γ</sub></italic></bold> or {<bold><italic>σ</italic></bold>
<sup>2</sup>, <bold><italic>ρ</italic></bold>} and it has been shown to greatly improve mixing of the structural parameters <bold><italic>γ</italic></bold> and <italic>J</italic> which are in our case the main focus of inference.</p>
    <p id="P33">We have derived the full conditionals for the regression parameters and state the results here. Further details regarding the derivations can be found in the <xref ref-type="supplementary-material" rid="SD1">Section S1.5</xref>. The posterior conditional for the non-zero regression coefficients is <disp-formula id="FD13"><label>(6)</label><mml:math id="M38"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>∣</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mo>∖</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>∼</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math></disp-formula> where the subscript ‘∖<italic>k</italic>’ implies that the vector of the regression coefficients consists of all the elements except those that are related to the <italic>k</italic>th response, <disp-formula id="FD14"><mml:math id="M39"><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>ℳ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mo>⫾</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math></disp-formula>, and <disp-formula id="FD15"><mml:math id="M40"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>ℒ</mml:mi><mml:mi>J</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>u</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>ℳ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>m</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>ℋ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>u</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula> with <italic><bold>u</bold><sub>k</sub></italic> defined as the residuals given in Equation (<xref ref-type="disp-formula" rid="FD1">1</xref>).</p>
    <p id="P34">In the sparse covariance case, the index sets are defined with respect to the perfect elimination order ξ, that is, <disp-formula id="FD16"><label>(7)</label><mml:math id="M41"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>ℒ</mml:mi><mml:mi>J</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>J</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>l</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>J</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>∼</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>ℳ</mml:mi><mml:mi>J</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>J</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>J</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>∼</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>ℋ</mml:mi><mml:mi>J</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>∣</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>J</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>J</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>∼</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula> where <italic>l</italic>∼<italic>k</italic> means that nodes <italic>l</italic> and <italic>k</italic> are in the same prime component. In the dense case, these reduce to <disp-formula id="FD17"><mml:math id="M42"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>ℒ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>l</mml:mi><mml:mo>∣</mml:mo><mml:mi>l</mml:mi><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>ℳ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>m</mml:mi><mml:mo>∣</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>〉</mml:mo></mml:mrow><mml:mi>k</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>ℋ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>h</mml:mi><mml:mo>∣</mml:mo><mml:mi>h</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi><mml:mo>}</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p>
    <p id="P35">The posterior updates of the reparametrised covariance parameters depend on the ordering of the nodes and prime residuals of the graph <disp-formula id="FD18"><label>(8)</label><mml:math id="M43"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>∣</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>∼</mml:mo><mml:mtext>IGa</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula>
<disp-formula id="FD19"><label>(9)</label><mml:math id="M44"><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mi>J</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>∼</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math></disp-formula> with <inline-formula><mml:math id="M45"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mi>J</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo>∣</mml:mo><mml:msubsup><mml:mi>H</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> as before, <inline-formula><mml:math id="M46"><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msub><mml:mi>τ⫾</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mi>U</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub></mml:math></inline-formula> and <bold><italic>m̃<sub>qt</sub></italic></bold> are submatrices of <italic>M̃</italic> defined con-formally with previous transformations. In the dense covariance case, the posterior updates reduce to the following equations (with any ordering on the outcomes) <disp-formula id="FD20"><mml:math id="M47"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>∣</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>∼</mml:mo><mml:mtext>IGa</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∣</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mi>τ</mml:mi><mml:mo>∼</mml:mo><mml:mtext>N</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:msubsup><mml:mover accent="true"><mml:mi>M</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula>
</p>
    <p id="P36">To efficiently explore the graphical structure <italic>G</italic>, we use the sampler introduced by <xref rid="R19" ref-type="bibr">Green and Thomas (2013)</xref>, making use of the junction tree representation of a decomposable graph as its state variable to allow for bolder, multi-edge proposals in the graph space. The edge probability <italic>η</italic> is updated via a Gibbs perturbation. All other unknowns are updated via Metropolis-within-Gibbs updates with adaptive proposal distributions (<xref rid="R38" ref-type="bibr">Roberts &amp; Rosenthal, 2009</xref>). <xref ref-type="boxed-text" rid="BX1">Algorithm 1</xref> provides an overview of the designed MCMC algorithm to sample from the joint posterior distribution <italic>p</italic>(<bold><italic>β</italic></bold>, <bold><italic>γ</italic></bold>, <bold><italic>σ</italic></bold>
<sup>2</sup>, <bold><italic>ρ</italic></bold>, <italic>J</italic>, <bold><italic>π</italic></bold>, <bold><italic>o</italic></bold>, <italic>w</italic>, <italic>τ</italic>, <italic>η</italic> | Y</p>
    <p id="P37">Note that, even though each sample is from a decomposable model, the sampler allows us to discover non-decomposable graph structures via Bayesian model averaging of the marginal edge inclusion probabilities. As the graph is updated, the perfect elimination ordering ξ changes, hence we do not retain the sampled values of <bold><italic>σ</italic></bold>
<sup>2</sup> and <bold><italic>ρ</italic></bold>. Moreover, as we are interested mainly in structure learning, both for variable and covariance selection, we consider the reparametrised covariance as nuisance parameters.</p>
    <boxed-text id="BX1" position="margin" content-type="above" orientation="portrait">
      <label>Algorithm 1</label>
      <caption>
        <title>MCMC algorithm</title>
      </caption>
      <p id="P38">1: Set the number of iterations <italic>L</italic>
</p>
      <p id="P39">2: <bold>for</bold>
<italic>ℓ</italic> = 1,…, <italic>L</italic>
<bold>do</bold>
</p>
      <p id="P40">3:    Propose new junction tree <italic>J</italic>* using Green and Thomas sampler</p>
      <p id="P41">4:    <bold>for</bold>
<italic>q</italic> = 1,…, <italic>Q</italic>
<bold>do</bold>
</p>
      <p id="P42">5:        Obtain perfect ordering of graph prime components <inline-formula><mml:math id="M48"><mml:msubsup><mml:mi>P</mml:mi><mml:mi>q</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>J</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math></inline-formula>
</p>
      <p id="P43">6:    <bold>end for</bold>
</p>
      <p id="P44">7:    Obtain perfect elimination ordering of graph nodes (<italic>ξ<sup>J</sup></italic>*)</p>
      <p id="P45">8:    <bold>for</bold>
<italic>k</italic> = 1,…, <italic>s</italic>
<bold>do</bold>
</p>
      <p id="P46">9:        Propose new <inline-formula><mml:math id="M49"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="M50"><mml:msubsup><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi><mml:mo>∗</mml:mo></mml:msubsup></mml:math></inline-formula> using full conditionals (8) and (9)</p>
      <p id="P47">10:    <bold>end for</bold>
</p>
      <p id="P48">11:    Accept/reject {<italic>J</italic>*, <bold><italic>σ</italic></bold>
<sup>2</sup>*, <bold><italic>ρ</italic></bold>*} <italic>via</italic> Metropolis-Hastings step</p>
      <p id="P49">12:    <bold>for</bold>
<italic>k</italic> = 1,…, <italic>s</italic>
<bold>do</bold>
</p>
      <p id="P50">13:        Obtain sets <italic>𝓛<sub>J</sub></italic>(<italic>k</italic>), <italic>𝓜<sub>J</sub></italic>(<italic>k</italic>) and <italic>𝓗<sub>J</sub></italic>(<italic>k</italic>, <italic>m</italic>) based on the current graph <italic>J</italic>
</p>
      <p id="P51">14:        Propose new binary indicators vector <inline-formula><mml:math id="M51"><mml:msubsup><mml:mi>γ</mml:mi><mml:mi>k</mml:mi><mml:mo>∗</mml:mo></mml:msubsup></mml:math></inline-formula> using ESS sampler</p>
      <p id="P52">15:        Propose new <inline-formula><mml:math id="M52"><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:msubsup><mml:mi>γ</mml:mi><mml:mover accent="true"><mml:mi>k</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>∗</mml:mo></mml:msubsup></mml:mrow><mml:mo>∗</mml:mo></mml:msubsup></mml:math></inline-formula> using full conditional (6)</p>
      <p id="P53">16:        Accept/reject <inline-formula><mml:math id="M53"><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mi>γ</mml:mi><mml:mi>k</mml:mi><mml:mo>∗</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:msubsup><mml:mi>γ</mml:mi><mml:mi>k</mml:mi><mml:mo>∗</mml:mo></mml:msubsup></mml:mrow><mml:mo>∗</mml:mo></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>
<italic>via</italic> Metropolis-Hastings step</p>
      <p id="P54">17:        Update parameters <italic>O<sub>k</sub> via</italic> Metropolis-Hastings step</p>
      <p id="P55">18:    <bold>end for</bold>
</p>
      <p id="P56">19:    <bold>for</bold>
<italic>j</italic> = 1,…, <italic>p</italic>
<bold>do</bold>
</p>
      <p id="P57">20:        Update parameters <italic>π<sub>J</sub> via</italic> Metropolis-Hastings step</p>
      <p id="P58">21:    <bold>end for</bold>
</p>
      <p id="P59">22:    Update parameters <italic>ω</italic>, <italic>τ</italic> and <italic>η via</italic> Gibbs and Metropolis-Hastings steps</p>
      <p id="P60">23: <bold>end for</bold>
</p>
    </boxed-text>
  </sec>
  <sec id="S8">
    <label>4</label>
    <title>Simulation Study</title>
    <p id="P61">We evaluate the performance of the reparametrised multivariate sparse SUR model and our efficient sampler in simulated mQTL data. We first investigate the effect of allowing for residual dependence in the phenotypes, by comparing dependent and independent covariances within our own model. We then compare our model with sparse dependence structure against other methods that also allow for dependence. For all the work in the simulation study, we employ the same priors as we use for the mQTL analysis of the NFBC cohort data, see <xref ref-type="sec" rid="S11">Section 5</xref> for details, except in the comparison with other models that allow covariance selection where we use the simplified version of the hotspot detection prior with <italic>π<sub>j</sub></italic> = 1, <italic>j</italic> = 1, …, <italic>p</italic>.</p>
    <sec id="S9">
      <label>4.1</label>
      <title>Comparison with models without covariance selection</title>
      <p id="P62">We validate our method against the Hierarchical Evolutionary Stochastic Search (HESS) algorithm of <xref rid="R4" ref-type="bibr">Bottolo et al. (2011)</xref> in a synthetic setting. Following <xref rid="R37" ref-type="bibr">Richardson et al. (2010)</xref> and <xref rid="R2" ref-type="bibr">Bhadra and Mallick (2013)</xref>, we set up our simulation study by randomly subsampling <italic>p</italic> = 300 SNPs from our real <italic>-omics</italic> data set (see <xref ref-type="sec" rid="S11">Section 5</xref>). This forms our covariate set <italic>X</italic> and allows us to mimic real correlation effects and linkage disequilibrium between genetic markers that would be difficult to simulate artificially. The observed correlations between predictors range from small to over 0.8 in absolute value. We set <italic>n</italic> = 200 and <italic>s</italic> = 30 and proceed by selecting the correlation structure for the outcomes in form of a graph. We explore three graphical structures, that is, a block diagonal, a decomposable and a non-decomposable model.</p>
      <p id="P63">To present a range of possible association patterns between outcomes and predictors, we fix (conditionally on the selected graph structure) the binary indicators vector <bold><italic>γ</italic></bold> so that different sets of predictors display associations with, that is, <italic>all</italic> outcomes (representing true hotspots), all outcomes within each prime component, all outcomes within each residual component (so predictors are linked only with correlated outcomes and not to conditionally independent ones) and finally with a set of selected outcomes that spans multiple components, so that selected predictors are linked to both correlated and (conditionally) independent outcomes. See <xref ref-type="supplementary-material" rid="SD1">Figure S2</xref> for an example of the generated structures.</p>
      <p id="P64">With the structure fixed, we sample the non-zero regression coefficients from a N(5, 1), so that most of them are distinct from zero, and the residuals from a matrix variate normal distribution, that is, MN (0, ⫾<sub><italic>n</italic></sub>, <italic>C</italic>). <italic>C</italic>
<sup>−1</sup> is sampled from a G-Wishart distribution, W<sub><italic>G</italic></sub> (<italic>s</italic> + 2, <italic>M</italic>), using the R package <monospace>BDgraph</monospace> (<xref rid="R33" ref-type="bibr">Mohammadi &amp; Wit, 2019</xref>) with <italic>M</italic> = <italic>αR</italic>, <italic>R</italic> a correlation matrix with <italic>r</italic> on the off-diagonal elements and <italic>γ</italic> ∈ <bold>ℝ</bold>
<sup>+</sup> to obtain data sets with the desired noise.</p>
      <p id="P65">We consider two summaries of signal to noise, designed to be sensitive to the information contained in the predictors and in the covariance matrix, respectively: <disp-formula id="FD21"><mml:math id="M54"><mml:msub><mml:mtext>SNR</mml:mtext><mml:mi>β</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>s</mml:mi></mml:mfrac><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi>ξ</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>∑</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math></disp-formula>
<disp-formula id="FD22"><mml:math id="M55"><mml:msub><mml:mtext>SNR</mml:mtext><mml:mi>C</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>s</mml:mi></mml:mfrac><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi>ξ</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mi>∑</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>∈</mml:mo><mml:mi>ℒ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mstyle></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mrow><mml:msup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mi>∑</mml:mi></mml:mstyle><mml:mtext>​</mml:mtext></mml:msup></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mo>∈</mml:mo><mml:mi>ℒ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math></disp-formula> where <bold><italic>σ</italic></bold>
<sup>2</sup> and <bold><italic>ρ</italic></bold> are the reparametrised values of the covariance matrix <italic>C</italic> and 𝓛 is as defined in <xref ref-type="disp-formula" rid="FD16">Equation(7)</xref>. We observe that SNR<sub><italic>C</italic></sub> is highly correlated with the off-diagonal (residual) correlation <italic>r</italic>. Thus, we parameterise the simulation study in terms of <italic>G</italic> (block-diagonal, decomposable and non-decomposable), <italic>r</italic> ∈ {0.3, 0.6, 0.9} and SNR<sub><italic>γ</italic></sub>. For each value of <italic>G</italic> and <italic>r</italic>, we generate multiple data sets with different <italic>α</italic> values and use the data with resulting SNR<sub><italic>γ</italic></sub> within 10% of each of the desired values of 5, 15 and 25. Based on this criteria, we simulate 20 replicates for each combination of the parameters and run both sparse BayesSUR model and HESS for 250,000 iterations of which 50,000 as burn-in.</p>
      <p id="P66">To report on performance, we focus on posterior marginal inclusion probabilities, that is, the average over the MCMC iterations of <italic>γ<sub>kj</sub></italic>, <italic>k</italic> = 1, …, <italic>s</italic>, <italic>j</italic> = 1, …, <italic>p</italic>. <xref ref-type="fig" rid="F1">Figure 1</xref> shows the average ROC curves over 20 replicates for each simulation set-up corresponding to SNR<sub><italic>γ</italic></sub> = 5, the lowest signal-to-noise ratio, for both BayesSUR with covariance selection and HESS. The results correspond to our expectations, that is, HESS is known to perform relatively well even in cases where residuals are correlated (<xref rid="R4" ref-type="bibr">Bottolo et al., 2011</xref>; <xref rid="R28" ref-type="bibr">Lewin et al., 2016</xref>) as long as <italic>r</italic> is not too high. In most cases though, especially at higher <italic>r</italic>, HESS estimates are more noisy and more false positives are picked up due to the confounding effect of the correlations. BayesSUR has a more marked separations between true and false positive signals and overall returns less noisy estimates (see <xref ref-type="supplementary-material" rid="SD1">Figure S5</xref>, top panels). The ROC curves relative to the other SNR<sub><italic>γ</italic></sub> levels are reported in <xref ref-type="supplementary-material" rid="SD1">Figures S3</xref> and <xref ref-type="supplementary-material" rid="SD1">S4</xref>.</p>
      <p id="P67">BayesSUR is also able to recover simultaneously the conditional (in)dependence structure of the residuals. <xref rid="T1" ref-type="table">Table 1</xref> shows the average over 20 simulated replicates of true positive rates (TPR) and false positive rates (FPR) for graph edges found by thresholding Pr(<italic>G<sub>kk</sub>’</italic> = 1 data) at 0.5 probability level.</p>
      <p id="P68">The graphs are in general well estimated. For non-decomposable graphs, there is a tendency towards over-inclusion, as we would expect based on <xref rid="R14" ref-type="bibr">Fitch et al. (2014)</xref>, who find that graphs constrained to be decomposable converge to a close (in the graph space), more dense, chordal graph alternative (see for example <xref ref-type="supplementary-material" rid="SD1">Figure S.5</xref> in the Supplementary Material). The estimated TPR and FPR for different values of SNR<sub><italic>β</italic></sub> do not differ significantly from the one presented here. See, for details, <xref ref-type="supplementary-material" rid="SD1">Table S1</xref>.</p>
    </sec>
    <sec id="S10">
      <label>4.2</label>
      <title>Comparison with alternative covariance models</title>
      <p id="P69">We compare the performance of BayesSUR to two different software implementations of a sparse seemingly unrelated regressions (SSUR) model by <xref rid="R52" ref-type="bibr">Wang (2010)</xref>. SSUR indirect performs posterior computation of the SSUR model using MCMC, where the regression coefficients are sampled using the Gibbs sampler described in <xref rid="R16" ref-type="bibr">George and McCulloch (1993)</xref>. SSUR direct uses the marginal likelihood approach of <xref rid="R8" ref-type="bibr">Chib (1995)</xref> for ‘direct’ variable selection of important predictors and non-zero entries of the sparse inverse covariance matrix <italic>via</italic> Metropolis–Hastings steps. The Matlab version of the SSUR code is available from the author web site. For the ‘indirect’ version, we run the algorithm for 5 × 10<sup>5</sup> iterations with 10<sup>5</sup> as burn-in, storing the MCMC output every 500 iterations. For the ‘direct’ version, we run the algorithm for 2 × 10<sup>3</sup> iterations with 10<sup>3</sup> as burn-in. In each iteration, the calculation of the marginal likelihood requires 500 extra samples from the Gibbs sampler, including 100 as burn-in. Overall, the algorithm is run for10<sup>6</sup> iterations. All hyperparameters and proposal densities are left unchanged as originally set-up in the Matlab code. The prior probability of inclusion is set equal to 0.1 in both versions of the Matlab code. We run BayesSUR with covariance selection for 5 × 10<sup>5</sup> iterations with 10<sup>5</sup> as burn-in, two parallel chains in the EES sampler and matching the hyperparameters of the Beta-Binomial prior on the inclusion probability with the prior used in the SSUR algorithms.</p>
      <p id="P70">We simulate three scenarios, with differing levels of sparsity in the inverse covariance matrix. For each scenario, we simulate 20 replicates with <italic>n</italic> = 150, <italic>p</italic> = 30 and <italic>s</italic> = 20. Out of 30 × 20 regression coefficients, 120 (20%) are simulated from an uniform distribution in (−2, 2). We selected at random the same proportion of cells in the 30 × 20 matrix of regression coefficients and assigned to them the simulated values, while the other cells are set to zero. In our experiment, for each response, on average between 2 and 10 non-zero regression coefficients are assigned. To generate the correlated predictors, we follow <xref rid="R40" ref-type="bibr">Rothman et al. (2010)</xref> and simulate, for each <italic>i</italic> = 1, …, <italic>n</italic> and <italic>k</italic> = 1, …, <italic>s</italic>, <bold><italic>x</italic></bold>
<sub><italic>ik</italic></sub> ∼ N(0, <italic>V</italic>), where <italic>V<sub>jj</sub></italic> = 0. 7|<sup><italic>j−j′</italic></sup> is the (<italic>j</italic>, <italic>j′</italic>)th element of <italic>V</italic>, <italic>j</italic>, <italic>j</italic> = 1, …, <italic>p</italic>, implying the same unit marginal variance. The inverse error covariance <italic>T</italic>
<sup>−1</sup> is a Toeplitz matrix with value 0.5 in the first principal diagonal, 0.5 and 0.4 in the first two principal diagonals and 0.5, 0.4 and 0.3 in the first three principal diagonals in Scenario 1, 2 and 3, respectively. In all scenario considered, the sparse diagonal inverse error covariance is positive definite with 19 (10%), 37 (19%) and 54 (28%) non-zeros entries in Scenario 1, 2 and 3, respectively, while the corresponding covariance matrices are dense. Finally, the responses are generated from a Normal matrix variate distribution using the simulated matrix of regression coefficients, the predictors matrix and the dense covariance matrices, that is, <italic>Y</italic> ∼ MN(<italic>XB</italic>, <bold>⫾</bold>
<sub><italic>n</italic></sub>, <italic>T</italic>), where <italic>B</italic> is the <italic>p</italic> × <italic>q</italic> matrix of the simulated regression coefficients and <italic>T</italic> is the inverse of the <italic>q</italic> × <italic>q</italic> Toeplitz matrix.</p>
      <p id="P71"><xref ref-type="fig" rid="F2">Figure 2</xref> shows the ROC curves obtained from the simulation study distinguishing between the estimation of the non-zeros regression coefficients (top panels) and the estimation of non-zero entries of the inverse error covariance (bottom panels). From the plots, it is apparent that BayesSUR (with or without covariance selection) has better or similar performance to SSUR. It is more efficient than SSUR direct in all scenarios considered due to the expensive computation of the approximate marginal likelihood that prevents running the algorithm for many iterations. BayesSUR performs better than SSUR indirect whose performance deteriorates as the estimation of the sparse inverse error covariance becomes less sparse (Scenarios 2 and 3). A closer inspection of the MCMC output shows that in Scenarios 2 and 3 both versions of the SSUR algorithm incorrectly estimate that the responses are almost independent conditionally on the estimated regression coefficients (results not shown).</p>
      <p id="P72">We also compare the performance of BayesSUR with MRCE, the penalized likelihood method with simultaneous estimation of the regression coefficients and the covariance structure proposed by <xref rid="R40" ref-type="bibr">Rothman et al. (2010)</xref>. While the power to detect non-zero regression coefficients and non-zero elements of the precision matrix is similar to BayesSUR, in all simulated scenarios, MRCE seems to include a larger number of false positives, in particular in the covariance selection.</p>
      <p id="P73">In addition, we examine the computational time of the algorithms presented in this section. For the Bayesian algorithms, we match the values of the sparse priors hyperparameters and, as far as possible, the total number of iterations. For MRCE, we select the option cv, i.e., the penalty parameters for the regression coefficients and for the covariance structure are chosen by using a 5-fold cross-validation procedure. We also specify different dimensions of the candidate penalty vectors to check the impact of this choice on the computation time. All algorithms are run on an Intel(R) CPU 2.60 GHz with 64 Gb memory.</p>
      <p id="P74"><xref rid="T2" ref-type="table">Table 2</xref> shows that BayesSUR is 20 times faster than SSUR direct in all scenarios considered. Interestingly, it is also almost 10 times faster than SSUR indirect with the SSVS Gibbs sampler. This is due to the effect of the direct manipulation of the junction tree representation of a decomposable graph (<xref rid="R19" ref-type="bibr">Green &amp; Thomas, 2013</xref>) used in this work, in contrast to the computational expensive evaluation of the decomposability after edge perturbation employed in <xref rid="R52" ref-type="bibr">Wang (2010)</xref> and originally proposed by <xref rid="R18" ref-type="bibr">Giudici and Green (1999)</xref>. The different computational efficiency depends also on the programming language used by the two algorithms, C++ and Matlab, respectively. Note that we employ a single core to run BayesSUR in order to make the comparison with other methods fair. However, large computational gains can be achieved by using a multi-core parallel computing architecture such as Message Passing Interface to exploit the parallelization of step 9 in <xref ref-type="boxed-text" rid="BX1">Algorithm 1</xref>. The computational time of MRCE greatly depends on the number of candidate values where the fivefold cross-validation procedure is performed. At the default value, 4 equally spaced grid points, the algorithm is very fast, but it becomes slower than BayesSUR when 200 candidate values are specified. Moreover, in contrast to BayesSUR, the sparser the graph, the slower MRCE becomes. Similarly to the number of iterations in MCMC algorithms, for penalised likelihood methods the choice of the number of candidate penalty values depends on the trade-off between accuracy and computational time.</p>
      <p id="P75">Finally, we repeat the same analysis presented in this section with <italic>s</italic> = 150 responses to mimic the number of responses in the motivating application presented in the next section. Results are similar to those presented here, although the analysis becomes computationally prohibitive for both SSUR direct and SUUR indirect. Details of the selection performance of the different methods as well as their computational time are shown in <xref ref-type="supplementary-material" rid="SD1">Figure S6</xref> and <xref ref-type="supplementary-material" rid="SD1">Table S2</xref>, respectively.</p>
    </sec>
  </sec>
  <sec id="S11">
    <label>5</label>
    <title>Metabolite Quantitative Trait Loci (mQTL) Analysis in The Northern Finnish Birth Cohort</title>
    <p id="P76">In this section, we present our results of the mQTL analysis of the NFBC66 data. The serum metabolic data are from the 31-year follow-up study of the NFBC66 and based on a widespread metabolomics platform in epidemiology and genetics (<xref rid="R55" ref-type="bibr">Würtz et al., 2017</xref>). After quality control and data cleaning, the data consist of <italic>p</italic> = 9310 directly genotyped SNPs on chromosome 16 and <italic>s</italic> = 158 metabolite concentrations, measured on <italic>n</italic> = 5154 individuals. The metabolites are normalised and standardised <italic>via</italic> the inverse rank-Normal transformation, following <xref rid="R26" ref-type="bibr">Kettunen et al. (2016)</xref>.</p>
    <p id="P77">Thanks to growing evidence in favour of pleiotropy (the association of multiple phenotypes with the same locus) in mQTL analysis (<xref rid="R46" ref-type="bibr">Sabatti et al., 2009</xref>), we expect these associations to be driven by a handful of SNPs that associate with numerous metabolites. To drive the variable selection procedure we will therefore use the <italic>hotspot</italic> prior introduced by <xref rid="R4" ref-type="bibr">Bottolo et al. (2011)</xref> which expresses the prior probabilities for variable inclusion into overall sparsity level <italic>o<sub>k</sub></italic> for outcome <italic>k</italic> and a propensity parameter <italic>π<sub>j</sub></italic> for each predictor <italic>j</italic> with <italic>γ<sub>kj</sub></italic> ∼ Ber (<italic>o<sub>k</sub></italic> × <italic>π<sub>j</sub></italic>), <italic>π<sub>j</sub></italic> ∼ Ga(1/2, 1/2) (E(<italic>π<sub>j</sub></italic>) = 1, Var(<italic>π<sub>j</sub></italic>) = 4) and <italic>o<sub>k</sub></italic> ∼ Beta(<italic>a<sub>o</sub></italic>, <italic>b<sub>o</sub></italic>) under the constraint <italic>o<sub>k</sub></italic> × <italic>π<sub>j</sub></italic> ≤ 1 ∀<italic>j</italic>, <italic>k</italic>. The hyperparameters <italic>a<sub>o</sub></italic>, <italic>b<sub>o</sub></italic> are chosen so that the average model size and its variance for each outcome is small, as we want to enforce a strong sparsity in the model, that is, E(<italic>o<sub>k</sub></italic>) = 2 and Var(<italic>o<sub>k</sub></italic>) = 2. These values imply <italic>a priori</italic> a range of associations for each response between 0 and 6. We use independent N(0, <italic>w</italic>) priors on non-zero regression coefficients which correspond to <italic>W<sub><bold>~</bold></sub></italic> = <italic>w</italic>
<sup>−1</sup>
<bold>⫾<sub><italic>γ</italic></sub></bold> and let the prior matrix in the Inverse-Wishart for the covariance be diagonal, that is, <italic>M</italic> = <italic>γ</italic>⫾<sub><italic>s</italic></sub>. Since we standardise and centre all responses and predictors, the hyperparameters for <italic>τ</italic> and <italic>w</italic> are set such that these variances are centred on small values but, at the same time, allowing the respective prior to be diffuse (<italic>a<sub>w</sub></italic> = <italic>b<sub>w</sub></italic> = 0.1 and <italic>a<sub>τ</sub></italic> = <italic>b<sub>τ</sub></italic> = 0.1). Finally, we set <italic>a<sub>η</sub></italic> = 1, <italic>b<sub>η</sub></italic> = 1 (E(<italic>η</italic>) = 1/2, Var(<italic>η</italic>) ⋍ 1/12) which <italic>a priori</italic> does not push for a sparse graph <italic>G</italic>.</p>
    <p id="P78">Our model provides us with a rich output that can be summarised in many ways. Regarding the regression structure, one example is that we can use the posterior of the covariate propensity parameter <italic>π<sub>j</sub></italic>, <italic>j</italic> = 1, …, <italic>p</italic>, to search for hotspots (i.e. genetic variants that are associated with multiple metabolites). <xref ref-type="fig" rid="F3">Figure 3</xref> shows the posterior expectations of <italic>π<sub>j</sub></italic> for each SNP on chromosome 16. In particular, we report rs4985124, rs931406 and most importantly rs12102766 and rs3764261. Analysing the whole binary indicators vector <bold><italic>γ</italic></bold> gives us a lot more information though, as shown in <xref ref-type="fig" rid="F4">Figure 4</xref>, where we plot the marginal posterior inclusion probabilities (mPIP) for each SNP in chromosome 16, all metabolites superimposed. From the plot, we can see how some SNPs are associated with only one or a few outcomes and would thus be missed by only looking at hotspots detection. By thresholding mPIPs at 0.5, we discover a total of 38 associations and the average Bayes FDR (bFDR, see, e.g. <xref rid="R28" ref-type="bibr">Lewin et al., 2016</xref>) is ≈0.058. The associations found using the mPIP are presented in Supplementary Tables S.3 and S.4. By increasing the mPIP threshold to 0.9, we would keep 32 SNP-metabolite associations with bFDR &lt; 0.01.</p>
    <p id="P79">The results obtained by BayesSUR confirm the known association between SNP rs3764261 in the <italic>CEPT</italic> gene and HDLs (<xref rid="R25" ref-type="bibr">Kettunen et al., 2012</xref>; <xref rid="R46" ref-type="bibr">Sabatti et al., 2009</xref>), but additionally highlights the relevance of the <italic>CEPT</italic> locus on different lipoproteins. rs4985124, that we report associated with fatty acids, is situated in the <italic>PDXDC1</italic> locus, roughly 23 Kb from SNPs rs11075253 and rs11644601 which were previously linked with fatty acids metabolism (<xref rid="R25" ref-type="bibr">Kettunen et al., 2012</xref>, 2016). Finally, rs1210276, that we report associated with multiple metabolites connected to VLDL, is situated in the proximity of rs74249229, previously reported by <xref rid="R26" ref-type="bibr">Kettunen et al. (2016)</xref>.</p>
    <p id="P80">A comparison with MatrixeQTL (<xref rid="R48" ref-type="bibr">Shabalin, 2012</xref>), a widely used ‘one-SNP-one-trait-at-a-time’ method in GWAS analysis is presented in the Supplementary Material. Not accounting for correlations between metabolites, highly reduces the number of findings in the GWAS analysis. While mostly consistent with BayesSUR in terms of detected loci, multiple close-by SNPs are selected by MatrixeQTL as significantly predictive, whereas BayesSUR method picks only one (see <xref ref-type="supplementary-material" rid="SD1">Figures S7</xref> and <xref ref-type="supplementary-material" rid="SD1">S8</xref>). Our method, that accounts for residual correlation, was also able to uncover other potential important associations that warrant further investigations, in particular rs7191766 associated with multiple cholesterol-related phenotypes.</p>
    <p id="P81">Finally, <xref ref-type="fig" rid="F5">Figure 5</xref> presents a summary of the estimated graph <italic>G</italic>. By thresholding the marginal posterior edge inclusion probabilities (mEPIP) at 0.5, we obtain an adjacency matrix that we represent as a network plot, using the R package <monospace>igraph</monospace> (<xref rid="R10" ref-type="bibr">Csardi &amp; Nepusz, 2006</xref>). In the same plot, we also represent the selected SNPs and their associations with the metabolites.</p>
    <p id="P82">An interesting feature of the estimate of <italic>G</italic> is that we recover the three macrogroups mentioned in the Introduction, that is, lipoprotein concentrations (represented by circles), serum lipids (squares) and low molecular weight metabolites (triangles), with the lipoproteins being further separated into two components. HDLs and LDLs in particular seem to be highly associated with serum lipids, while the VLDL and IDL concentrations form a group almost by themselves. There are associations between the serum lipids and low molecular weight metabolites, driven mostly by a couple of low molecular weight hubs. It is important to note that edges here represent non-zero conditional correlations and we thus expect a much sparser graph than would be seen using marginal correlations. The highly sparse estimate of <italic>G</italic> also implies that considerable computational gains were achieved using the sparse model.</p>
  </sec>
  <sec sec-type="discussion" id="S12">
    <label>6</label>
    <title>Discussion</title>
    <p id="P83">In this work, we present a novel computational method to perform Bayesian variable selection in a multivariate regression setting for QTLoci analysis that takes into account residual correlations between phenotypes while maintaining a flexible association pattern between phenotypes and genotypes. Although conjugacy is lost for this model, by virtue of a crucial reparametrisation of the covariance matrix, our novel results show that: (i) it is possible to obtain simple expressions for the priors distribution of the reparametrised parameters <bold><italic>σ</italic></bold>
<sup>2</sup>
<sub><italic>k</italic></sub> and <bold><italic>ρ</italic></bold>
<sub><italic>k</italic></sub>, <italic>k</italic> = 1, …, <italic>s</italic>, in both dense and sparse cases, (ii) posterior full conditionals are available in closed-form expression, including for the regression coefficients <bold><italic>σ</italic></bold>
<sub><italic>k</italic></sub>, and (iii) since the likelihood is now computed as a product of independent factors, the posterior updates of <bold><italic>γ</italic></bold>
<sup>2</sup>
<sub><italic>k</italic></sub> and <bold><italic>ρ</italic></bold>
<sub><italic>k</italic></sub> can be trivially parallelised which greatly increases the computational efficiency of our model. Thus, our method is able to analyse a large number of outcomes and their associations with a large set of predictors, thanks as well to the efficient C++ implementation, as illustrate in the simulation study and in the motivating application. It is moreover possible to introduce further computational gains by assuming that the conditional independence structure between the residuals is sparse, and inference on the resulting graph is straightforward to obtain. We demonstrate this feature in a simulated example with 150 responses, where BayesSUR with covariance selection is 30% faster than the version of the algorithm with dense covariance estimation.</p>
    <p id="P84">We have also shown in the simulation study that, when there is non-negligible residual correlations between the responses, our method exhibits better performance in selecting relevant predictors than existing methods (<xref rid="R4" ref-type="bibr">Bottolo et al., 2011</xref>; <xref rid="R28" ref-type="bibr">Lewin et al., 2016</xref>) and is able at the same time to effectively perform covariance selection. Computationally, BayeSUR is faster than existing Bayesian sparse SUR methods with covariance selection, although in the simulated examples we have not shown the reduction in computational time when multiple cores are used in order to exploit the factorisation of the proposed model. When a large number of responses are considered and the graph is very sparse, BayeSUR computational time is almost comparable to penalized likelihood methods, although the output of the former is much richer (full posterior distributions <italic>versus</italic> point estimates).</p>
    <p id="P85">Our method is able to scale well in the regime of hundreds of outcomes and thousands of predictors, as demonstrated in the analysis of the NFBC66 mQTL data set; we are able to recover already published and known associations, as well as uncovering some previously unknown associations that might offer new insights into the relationships between chromosome 16 and lipid metabolism.</p>
    <p id="P86">One might expect the restriction to decomposable graphs to be too stringent for real applications and various attempt have been made to relax such an assumption, using the <italic>G</italic>-Wishart distribution first introduced by <xref rid="R42" ref-type="bibr">Roverato (2002)</xref> (see also <xref rid="R31" ref-type="bibr">Mitsakakis et al., 2011</xref>; <xref rid="R32" ref-type="bibr">Mohammadi &amp; Wit, 2015</xref>; <xref rid="R53" ref-type="bibr">Wang et al., 2012</xref> and references therein for some recent examples). However, the computational disadvantages connected with a general graph are in general exceedingly high (<xref rid="R24" ref-type="bibr">Jones et al., 2005</xref>).</p>
    <p id="P87">The work of <xref rid="R14" ref-type="bibr">Fitch et al. (2014)</xref> concludes that, under model assumptions similar to ours, inference on <italic>G</italic> will asymptotically converge towards minimal triangulations of the true graph, that is, the decomposable graph with the smallest number of extra edges, and that inference on the covariance matrix is competitive in terms of prediction errors against penalised likelihood methods that estimate unrestricted graphs like the graphical lasso. In practice, assuming decomposability seems to be sensible and inference on the covariance matrix under such an assumption sound. Additionally, Bayesian modelling averaging enables the estimation via marginal edge inclusion probabilities of a general non-decomposable graph.</p>
    <p id="P88">Thanks to the very general formulation of the SUR models we expect the present work to find applications beyond the mQTL application presented here, for example in finance, econometrics and other biological settings where linked regression models are already widespread.</p>
  </sec>
  <sec sec-type="supplementary-material" id="SM">
    <title>Supplementary Material</title>
    <supplementary-material content-type="local-data" id="SD1">
      <label>Supplementary File</label>
      <media xlink:href="EMS140622-supplement-Supplementary_File.pdf" mimetype="application" mime-subtype="pdf" orientation="portrait" id="d40e5842" position="anchor"/>
    </supplementary-material>
  </sec>
</body>
<back>
  <ack id="S13">
    <title>Acknowledgements</title>
    <p>The authors are grateful to the associate editor and two anonymous referees for their valuable and detailed comments that greatly improved the presentation of the paper.</p>
    <sec id="S14">
      <title>Funding</title>
      <p>This work was supported by the UK Medical Research Council grant MR/M013138/1 ‘Methods and tools for structural models integrating multiple high-throughput omics data sets in genetic epidemiology’ (AL, LB, MB, MRJ and SR), the European Union Horizon 2020 grant ‘DynaHealth: Understanding the dynamic determinants of glucose homeostasis and social capability to promote healthy and active aging’ grant agreement No 633595 (AL and MRJ), the Medical Research Council grant MC_UP_0801/1 (SR) and The Alan Turing Institute under the Engineering and Physical Sciences Research Council grant EP/N510129/1 (LB and SR). MAK works in a unit that is supported by the University of Bristol and UK Medical Research Council (MC_UU_12013/1). The Baker Institute is supported in part by the Victorian Government’s Operational Infrastructure Support Program.</p>
    </sec>
  </ack>
  <ref-list>
    <ref id="R1">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Alexopoulos</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Bottolo</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Bayesian variable selection for Gaussian copula regression models</article-title>
        <source>Journal of Computational and Graphical Statistics</source>
        <year>2020</year>
        <pub-id pub-id-type="doi">10.1080/10618600.2020.1840997</pub-id>
        <comment>in press</comment>
      </element-citation>
    </ref>
    <ref id="R2">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bhadra</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Mallick</surname>
            <given-names>BK</given-names>
          </name>
        </person-group>
        <article-title>Joint high-dimensional Bayesian variable and covariance selection with an application to eQTL analysis</article-title>
        <source>Biometrics</source>
        <year>2013</year>
        <volume>69</volume>
        <fpage>447</fpage>
        <lpage>457</lpage>
        <pub-id pub-id-type="pmid">23607608</pub-id>
      </element-citation>
    </ref>
    <ref id="R3">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bottolo</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Richardson</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Evolutionary stochastic search for Bayesian model exploration</article-title>
        <source>Bayesian Analysis</source>
        <year>2010</year>
        <volume>5</volume>
        <fpage>583</fpage>
        <lpage>618</lpage>
      </element-citation>
    </ref>
    <ref id="R4">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bottolo</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Petretto</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Blankenberg</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Cambien</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Cook</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Tiret</surname>
            <given-names>L</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Bayesian detection of expression quantitative trait loci hotspots</article-title>
        <source>Genetics</source>
        <year>2011</year>
        <volume>189</volume>
        <fpage>1449</fpage>
        <lpage>1459</lpage>
        <pub-id pub-id-type="pmid">21926303</pub-id>
      </element-citation>
    </ref>
    <ref id="R5">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brown</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Vannucci</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Fearn</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Multivariate Bayesian variable selection and prediction</article-title>
        <source>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</source>
        <year>1998</year>
        <volume>60</volume>
        <fpage>627</fpage>
        <lpage>641</lpage>
      </element-citation>
    </ref>
    <ref id="R6">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Brown</surname>
            <given-names>PJ</given-names>
          </name>
          <name>
            <surname>Vannucci</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Fearn</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Bayes model averaging with selection of regressors</article-title>
        <source>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</source>
        <year>2002</year>
        <volume>64</volume>
        <fpage>519</fpage>
        <lpage>536</lpage>
      </element-citation>
    </ref>
    <ref id="R7">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Carvalho</surname>
            <given-names>CM</given-names>
          </name>
          <name>
            <surname>Massam</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>West</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Simulation of hyper-inverse Wishart distributions in graphical models</article-title>
        <source>Biometrika</source>
        <year>2007</year>
        <volume>94</volume>
        <fpage>647</fpage>
        <lpage>659</lpage>
      </element-citation>
    </ref>
    <ref id="R8">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chib</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Marginal likelihood from the Gibbs output</article-title>
        <source>Journal of the American Statistical Association</source>
        <year>1995</year>
        <volume>90</volume>
        <fpage>1313</fpage>
        <lpage>1321</lpage>
      </element-citation>
    </ref>
    <ref id="R9">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cichonska</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Rousu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Marttinen</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Kangas</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Soininen</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Lehtimäki</surname>
            <given-names>T</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>metaCCA: Summary statistics-based multivariate meta-analysis of genome-wide association studies using canonical correlation analysis</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <fpage>1981</fpage>
        <lpage>1989</lpage>
        <pub-id pub-id-type="pmid">27153689</pub-id>
      </element-citation>
    </ref>
    <ref id="R10">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Csardi</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Nepusz</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>The igraph software package for complex network research</article-title>
        <source>InterJournal-Complex Systems</source>
        <year>2006</year>
        <volume>1695</volume>
        <fpage>1</fpage>
        <lpage>9</lpage>
      </element-citation>
    </ref>
    <ref id="R11">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Datta</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Banerjee</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Hodges</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Spatial disease mapping using directed acyclic graph auto-regressive (DAGAR) models</article-title>
        <source>Bayesian Analysis</source>
        <year>2019</year>
        <volume>14</volume>
        <fpage>1221</fpage>
        <lpage>1244</lpage>
        <pub-id pub-id-type="pmid">33859772</pub-id>
      </element-citation>
    </ref>
    <ref id="R12">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dawid</surname>
            <given-names>AP</given-names>
          </name>
        </person-group>
        <article-title>Some matrix-variate distribution theory: Notational considerations and a Bayesian application</article-title>
        <source>Biometrika</source>
        <year>1981</year>
        <volume>68</volume>
        <fpage>265</fpage>
        <lpage>274</lpage>
      </element-citation>
    </ref>
    <ref id="R13">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Dempster</surname>
            <given-names>AP</given-names>
          </name>
        </person-group>
        <source>Elements of continuous multivariate analysis</source>
        <publisher-name>Addison Wesley Longman</publisher-name>
        <publisher-loc>Boston</publisher-loc>
        <year>1969</year>
      </element-citation>
    </ref>
    <ref id="R14">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fitch</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>MB</given-names>
          </name>
          <name>
            <surname>Massam</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>The performance of covariance selection methods that consider decomposable models only</article-title>
        <source>Bayesian Analysis</source>
        <year>2014</year>
        <volume>9</volume>
        <fpage>659</fpage>
        <lpage>684</lpage>
      </element-citation>
    </ref>
    <ref id="R15">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fusi</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Stegle</surname>
            <given-names>O</given-names>
          </name>
          <name>
            <surname>Lawrence</surname>
            <given-names>ND</given-names>
          </name>
        </person-group>
        <article-title>Joint modelling of confounding factors and prominent genetic regulators provides increased accuracy in genetical genomics studies</article-title>
        <source>PLoS Computational Biology</source>
        <year>2012</year>
        <volume>8</volume>
        <elocation-id>e1002330</elocation-id>
        <pub-id pub-id-type="pmid">22241974</pub-id>
      </element-citation>
    </ref>
    <ref id="R16">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>George</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>McCulloch</surname>
            <given-names>RE</given-names>
          </name>
        </person-group>
        <article-title>Variable selection via Gibbs sampling</article-title>
        <source>Journal of the American Statistical Association</source>
        <year>1993</year>
        <volume>88</volume>
        <fpage>881</fpage>
        <lpage>889</lpage>
      </element-citation>
    </ref>
    <ref id="R17">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Giri</surname>
            <given-names>NC</given-names>
          </name>
        </person-group>
        <source>Multivariate statistical inference</source>
        <publisher-name>Academic Press</publisher-name>
        <publisher-loc>London</publisher-loc>
        <year>2014</year>
      </element-citation>
    </ref>
    <ref id="R18">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Giudici</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Green</surname>
            <given-names>PJ</given-names>
          </name>
        </person-group>
        <article-title>Decomposable graphical Gaussian model determination</article-title>
        <source>Biometrika</source>
        <year>1999</year>
        <volume>86</volume>
        <fpage>785</fpage>
        <lpage>801</lpage>
      </element-citation>
    </ref>
    <ref id="R19">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Green</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Thomas</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Sampling decomposable graphs using a Markov chain on junction trees</article-title>
        <source>Biometrika</source>
        <year>2013</year>
        <volume>100</volume>
        <fpage>91</fpage>
        <lpage>110</lpage>
      </element-citation>
    </ref>
    <ref id="R20">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Holmes</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Held</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Bayesian auxiliary variable models for binary and multinomial regression</article-title>
        <source>Bayesian Analysis</source>
        <year>2006</year>
        <volume>1</volume>
        <fpage>145</fpage>
        <lpage>168</lpage>
      </element-citation>
    </ref>
    <ref id="R21">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Holmes</surname>
            <given-names>CC</given-names>
          </name>
          <name>
            <surname>Denison</surname>
            <given-names>DGT</given-names>
          </name>
          <name>
            <surname>Mallick</surname>
            <given-names>BK</given-names>
          </name>
        </person-group>
        <article-title>Accounting for model uncertainty in seemingly unrelated regressions</article-title>
        <source>Journal of Computational and Graphical Statistics</source>
        <year>2002</year>
        <volume>11</volume>
        <fpage>533</fpage>
        <lpage>551</lpage>
      </element-citation>
    </ref>
    <ref id="R22">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Inouye</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Ripatti</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kettunen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Lyytikäinen</surname>
            <given-names>L-P</given-names>
          </name>
          <name>
            <surname>Oksala</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Laurila</surname>
            <given-names>P-P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Novel loci for metabolic networks and multi-tissue expression studies reveal genes for atherosclerosis</article-title>
        <source>PLoS Genetics</source>
        <year>2012</year>
        <volume>8</volume>
        <elocation-id>e1002907</elocation-id>
        <pub-id pub-id-type="pmid">22916037</pub-id>
      </element-citation>
    </ref>
    <ref id="R23">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jia</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Mapping quantitative trait loci for expression abundance</article-title>
        <source>Genetics</source>
        <year>2007</year>
        <volume>176</volume>
        <fpage>611</fpage>
        <lpage>623</lpage>
        <pub-id pub-id-type="pmid">17339210</pub-id>
      </element-citation>
    </ref>
    <ref id="R24">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Carvalho</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Dobra</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Hans</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Carter</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>West</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Experiments in stochastic computation for high-dimensional graphical models</article-title>
        <source>Statistical Science</source>
        <year>2005</year>
        <volume>20</volume>
        <fpage>388</fpage>
        <lpage>400</lpage>
      </element-citation>
    </ref>
    <ref id="R25">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kettunen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Tukiainen</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Sarin</surname>
            <given-names>A-P</given-names>
          </name>
          <name>
            <surname>Ortega-Alonso</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tikkanen</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Lyytikäinen</surname>
            <given-names>L-P</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Genome-wide association study identifies multiple loci influencing human serum metabolite levels</article-title>
        <source>Nature Genetics</source>
        <year>2012</year>
        <volume>44</volume>
        <fpage>269</fpage>
        <pub-id pub-id-type="pmid">22286219</pub-id>
      </element-citation>
    </ref>
    <ref id="R26">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kettunen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Demirkan</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Würtz</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Draisma</surname>
            <given-names>HH</given-names>
          </name>
          <name>
            <surname>Haller</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Rawal</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Genomewide study for circulating metabolites identifies 62 loci and reveals novel systemic effects of LPA</article-title>
        <source>Nature Communications</source>
        <year>2016</year>
        <volume>7</volume>
        <elocation-id>11122</elocation-id>
      </element-citation>
    </ref>
    <ref id="R27">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Lauritzen</surname>
            <given-names>SL</given-names>
          </name>
        </person-group>
        <source>Graphical models</source>
        <publisher-name>Oxford University Press</publisher-name>
        <publisher-loc>New York</publisher-loc>
        <year>1996</year>
      </element-citation>
    </ref>
    <ref id="R28">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lewin</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Saadi</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Peters</surname>
            <given-names>JE</given-names>
          </name>
          <name>
            <surname>Moreno-Moral</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>KGC</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MT-HESS: An efficient Bayesian approach for simultaneous association detection in OMICS datasets, with application to eQTL mapping in multiple tissues</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <fpage>523</fpage>
        <lpage>532</lpage>
        <pub-id pub-id-type="pmid">26504141</pub-id>
      </element-citation>
    </ref>
    <ref id="R29">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Wong</surname>
            <given-names>WH</given-names>
          </name>
        </person-group>
        <article-title>Evolutionary Monte Carlo: Applications to Cp model sampling and change point problem</article-title>
        <source>Statistica Sinica</source>
        <year>2000</year>
        <volume>10</volume>
        <fpage>317</fpage>
        <lpage>342</lpage>
      </element-citation>
    </ref>
    <ref id="R30">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Marttinen</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Pirinen</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sarin</surname>
            <given-names>A-P</given-names>
          </name>
          <name>
            <surname>Gillberg</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Kettunen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Surakka</surname>
            <given-names>I</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Assessing multivariate gene-metabolome associations with rare variants using Bayesian reduced rank regression</article-title>
        <source>Bioinformatics</source>
        <year>2014</year>
        <volume>30</volume>
        <fpage>2026</fpage>
        <lpage>2034</lpage>
        <pub-id pub-id-type="pmid">24665129</pub-id>
      </element-citation>
    </ref>
    <ref id="R31">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mitsakakis</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Massam</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Escobar</surname>
            <given-names>MD</given-names>
          </name>
        </person-group>
        <article-title>A Metropolis-Hastings based method for sampling from the G-Wishart distribution in Gaussian graphical models</article-title>
        <source>Electronic Journal of Statistics</source>
        <year>2011</year>
        <volume>5</volume>
        <fpage>18</fpage>
        <lpage>30</lpage>
      </element-citation>
    </ref>
    <ref id="R32">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mohammadi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wit</surname>
            <given-names>EC</given-names>
          </name>
        </person-group>
        <article-title>Bayesian structure learning in sparse Gaussian graphical models</article-title>
        <source>Bayesian Analysis</source>
        <year>2015</year>
        <volume>10</volume>
        <fpage>109</fpage>
        <lpage>138</lpage>
      </element-citation>
    </ref>
    <ref id="R33">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Mohammadi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wit</surname>
            <given-names>EC</given-names>
          </name>
        </person-group>
        <article-title>BDgraph: An R package for Bayesian structure learning in graphical models</article-title>
        <source>Journal of Statistical Software</source>
        <year>2019</year>
        <volume>89</volume>
        <fpage>1</fpage>
        <lpage>30</lpage>
      </element-citation>
    </ref>
    <ref id="R34">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Paulsen</surname>
            <given-names>VI</given-names>
          </name>
          <name>
            <surname>Power</surname>
            <given-names>SC</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>RR</given-names>
          </name>
        </person-group>
        <article-title>Schur products and matrix completions</article-title>
        <source>Journal of Functional Analysis</source>
        <year>1989</year>
        <volume>85</volume>
        <fpage>151</fpage>
        <lpage>178</lpage>
      </element-citation>
    </ref>
    <ref id="R35">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Petretto</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Bottolo</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Langley</surname>
            <given-names>SR</given-names>
          </name>
          <name>
            <surname>Heinig</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>McDermott-Roe</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sarwar</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>New insights into the genetic control of gene expression using a Bayesian multi-tissue approach</article-title>
        <source>PLoS Computational Biology</source>
        <year>2010</year>
        <volume>6</volume>
        <elocation-id>e1000737</elocation-id>
        <pub-id pub-id-type="pmid">20386736</pub-id>
      </element-citation>
    </ref>
    <ref id="R36">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pourahmadi</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Joint mean-covariance models with applications to longitudinal data: Unconstrained parameterisation</article-title>
        <source>Biometrika</source>
        <year>1999</year>
        <volume>86</volume>
        <fpage>677</fpage>
        <lpage>690</lpage>
      </element-citation>
    </ref>
    <ref id="R37">
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Richardson</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Bottolo</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Rosenthal</surname>
            <given-names>JS</given-names>
          </name>
        </person-group>
        <part-title>Bayesian models for sparse regression analysis of high dimensional data</part-title>
        <person-group person-group-type="editor">
          <name>
            <surname>Bernardo</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Bayarri</surname>
            <given-names>MJ</given-names>
          </name>
          <name>
            <surname>Berger</surname>
            <given-names>JO</given-names>
          </name>
          <name>
            <surname>Dawid</surname>
            <given-names>AP</given-names>
          </name>
          <name>
            <surname>Heckerman</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Smith</surname>
            <given-names>AFM</given-names>
          </name>
          <name>
            <surname>West</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <source>Bayesian statistics</source>
        <publisher-name>Oxford University Press</publisher-name>
        <publisher-loc>New York</publisher-loc>
        <year>2010</year>
        <volume>9</volume>
        <fpage>539</fpage>
        <lpage>569</lpage>
      </element-citation>
    </ref>
    <ref id="R38">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Roberts</surname>
            <given-names>GO</given-names>
          </name>
          <name>
            <surname>Rosenthal</surname>
            <given-names>JS</given-names>
          </name>
        </person-group>
        <article-title>Examples of adaptive MCMC</article-title>
        <source>Journal of Computational and Graphical Statistics</source>
        <year>2009</year>
        <volume>18</volume>
        <fpage>349</fpage>
        <lpage>367</lpage>
      </element-citation>
    </ref>
    <ref id="R39">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rodriguez-Martinez</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Posma</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Ayala</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Neves</surname>
            <given-names>AL</given-names>
          </name>
          <name>
            <surname>Anwar</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Petretto</surname>
            <given-names>E</given-names>
          </name>
        </person-group>
        <article-title>MWASTools: An R/bio-conductor package for metabolome-wide association studies</article-title>
        <source>Bioinformatics</source>
        <year>2017</year>
        <volume>34</volume>
        <fpage>890</fpage>
        <lpage>892</lpage>
      </element-citation>
    </ref>
    <ref id="R40">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rothman</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Levina</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Sparse multivariate regression with covariance estimation</article-title>
        <source>Journal of Computational and Graphical Statistics</source>
        <year>2010</year>
        <volume>19</volume>
        <fpage>947</fpage>
        <lpage>962</lpage>
        <pub-id pub-id-type="pmid">24963268</pub-id>
      </element-citation>
    </ref>
    <ref id="R41">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Roverato</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Cholesky decomposition of a hyper inverse Wishart matrix</article-title>
        <source>Biometrika</source>
        <year>2000</year>
        <volume>87</volume>
        <fpage>99</fpage>
        <lpage>112</lpage>
      </element-citation>
    </ref>
    <ref id="R42">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Roverato</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Hyper inverse Wishart distribution for non-decomposable graphs and its application to Bayesian inference for Gaussian graphical models</article-title>
        <source>Scandinavian Journal of Statistics</source>
        <year>2002</year>
        <volume>29</volume>
        <fpage>391</fpage>
        <lpage>411</lpage>
      </element-citation>
    </ref>
    <ref id="R43">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ruffieux</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Davison</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Hager</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Irincheeva</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Efficient inference for genetic association studies with multiple outcomes</article-title>
        <source>Biostatistics</source>
        <year>2017</year>
        <volume>18</volume>
        <fpage>618</fpage>
        <lpage>636</lpage>
        <pub-id pub-id-type="pmid">28334312</pub-id>
      </element-citation>
    </ref>
    <ref id="R44">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ruffieux</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Davison</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Hager</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Inshaw</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Fairfax</surname>
            <given-names>BP</given-names>
          </name>
          <name>
            <surname>Richardson</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A global-local approach for detecting hotspots in multipleresponse regression</article-title>
        <source>Annals of Applied Statistics</source>
        <year>2020a</year>
        <volume>14</volume>
        <fpage>905</fpage>
        <lpage>928</lpage>
      </element-citation>
    </ref>
    <ref id="R45">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ruffieux</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Fairfax</surname>
            <given-names>BP</given-names>
          </name>
          <name>
            <surname>Nassiri</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Vigorito</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Wallace</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Richardson</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>EPISPOT: An epigenome-driven approach for detecting and interpreting hotspots in molecular QTL studies</article-title>
        <source>bioRxiv</source>
        <year>2020b</year>
        <pub-id pub-id-type="doi">10.1101/2020.09.21.305789</pub-id>
      </element-citation>
    </ref>
    <ref id="R46">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sabatti</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Service</surname>
            <given-names>SK</given-names>
          </name>
          <name>
            <surname>Hartikainen</surname>
            <given-names>A-L</given-names>
          </name>
          <name>
            <surname>Pouta</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ripatti</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Brodsky</surname>
            <given-names>J</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Genome-wide association analysis of metabolic traits in a birth cohort from a founder population</article-title>
        <source>Nature Genetics</source>
        <year>2009</year>
        <volume>41</volume>
        <fpage>35</fpage>
        <pub-id pub-id-type="pmid">19060910</pub-id>
      </element-citation>
    </ref>
    <ref id="R47">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Scott-Boyer</surname>
            <given-names>MP</given-names>
          </name>
          <name>
            <surname>Imholte</surname>
            <given-names>GC</given-names>
          </name>
          <name>
            <surname>Tayeb</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Labbe</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Deschepper</surname>
            <given-names>CF</given-names>
          </name>
          <name>
            <surname>Gottardo</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>An integrated hierarchical Bayesian model for multivariate eQTL mapping</article-title>
        <source>Statistical Applications in Genetics and Molecular Biology</source>
        <year>2012</year>
        <volume>11</volume>
      </element-citation>
    </ref>
    <ref id="R48">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shabalin</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Matrix eQTL: Ultra fast eQTL analysis via large matrix operations</article-title>
        <source>Bioinformatics</source>
        <year>2012</year>
        <volume>28</volume>
        <fpage>1353</fpage>
        <lpage>1358</lpage>
        <pub-id pub-id-type="pmid">22492648</pub-id>
      </element-citation>
    </ref>
    <ref id="R49">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Soininen</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Kangas</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Würtz</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Tukiainen</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Tynkkynen</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Laatikainen</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Highthroughput serum NMR metabonomics for cost-effective holistic studies on systemic metabolism</article-title>
        <source>Analyst</source>
        <year>2009</year>
        <volume>134</volume>
        <fpage>1781</fpage>
        <lpage>1785</lpage>
        <pub-id pub-id-type="pmid">19684899</pub-id>
      </element-citation>
    </ref>
    <ref id="R50">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Stingo</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Marchetti</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Efficient local updates for undirected graphical models</article-title>
        <source>Statistics and Computing</source>
        <year>2014</year>
        <volume>25</volume>
        <fpage>159</fpage>
        <lpage>171</lpage>
      </element-citation>
    </ref>
    <ref id="R51">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Thomas</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Green</surname>
            <given-names>PJ</given-names>
          </name>
        </person-group>
        <article-title>Enumerating the junction trees of a decomposable graph</article-title>
        <source>Journal of Computational and Graphical Statistics</source>
        <year>2009</year>
        <volume>18</volume>
        <fpage>930</fpage>
        <lpage>940</lpage>
        <pub-id pub-id-type="pmid">20981245</pub-id>
      </element-citation>
    </ref>
    <ref id="R52">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Sparse seemingly unrelated regression modelling: Applications in finance and econometrics</article-title>
        <source>Computational Statistics &amp; Data Analysis</source>
        <year>2010</year>
        <volume>54</volume>
        <fpage>2866</fpage>
        <lpage>2877</lpage>
      </element-citation>
    </ref>
    <ref id="R53">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Bayesian graphical lasso models and efficient posterior computation</article-title>
        <source>Bayesian Analysis</source>
        <year>2012</year>
        <volume>7</volume>
        <fpage>867</fpage>
        <lpage>886</lpage>
      </element-citation>
    </ref>
    <ref id="R54">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wermuth</surname>
            <given-names>N</given-names>
          </name>
        </person-group>
        <article-title>Linear recursive equations, covariance selection, and path analysis</article-title>
        <source>Journal of the American Statistical Association</source>
        <year>1980</year>
        <volume>75</volume>
        <fpage>963</fpage>
        <lpage>972</lpage>
      </element-citation>
    </ref>
    <ref id="R55">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Würtz</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Kangas</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Soininen</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Lawlor</surname>
            <given-names>DA</given-names>
          </name>
          <name>
            <surname>Davey Smith</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Ala-Korpela</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Quantitative serum nuclear magnetic resonance metabolomics in large-scale epidemiology: A primer on -Omic technologies</article-title>
        <source>American Journal of Epidemiology</source>
        <year>2017</year>
        <volume>186</volume>
        <fpage>1084</fpage>
        <lpage>1096</lpage>
        <pub-id pub-id-type="doi">10.1093/aje/kwx016</pub-id>
        <pub-id pub-id-type="pmid">29106475</pub-id>
      </element-citation>
    </ref>
    <ref id="R56">
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zellner</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Ando</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>A direct Monte Carlo approach for Bayesian analysis of the seemingly unrelated regression model</article-title>
        <source>Journal of Econometrics</source>
        <year>2010</year>
        <volume>159</volume>
        <fpage>33</fpage>
        <lpage>45</lpage>
      </element-citation>
    </ref>
  </ref-list>
</back>
<floats-group>
  <fig id="F1" orientation="portrait" position="float">
    <label>Figure 1</label>
    <caption>
      <p>Averaged (over 20 simulated replicates) ROC curves for BayesSUR with covariance selection (red line) and HESS (black line) to compare the variable selection performance of the two methods for different combinations of the simulated graphical model <italic>G</italic> and the (residual) correlation between responses <italic>r</italic> and with signal-to-noise ratio for the predictors SNR<sub><italic>γ</italic></sub> = 5 [Colour figure can be viewed at <ext-link ext-link-type="uri" xlink:href="https://onlinelibrary.wiley.com/">wileyonlinelibrary.com</ext-link>]</p>
    </caption>
    <graphic xlink:href="EMS140622-f001"/>
  </fig>
  <fig id="F2" orientation="portrait" position="float">
    <label>Figure 2</label>
    <caption>
      <p>Averaged (over 20 simulated replicates) ROC curves to compare the selection performance of the non-zero regression coefficients (top panels) and non-zero elements of the precision matrix (bottom panels) for the methods considered: BayesSUR with covariance selection (solid red line), BayesSUR with dense covariance estimation (dashed red line), SSUR Indirect (black line), SSUR Direct (blue line) and MRCE (green dot). For MRCE, each dot represents the averaged specificity and sensitivity of the corresponding penalised likelihood solution. BayesSUR with dense covariance estimation appears only in the top panels since it does not perform covariance selection. Its performance with respect to selecting regression coefficients is equal to that of BayesSUR with sparse covariance selection, hence the red dashed lines are indistinuishable from the red solid lines. Different scenarios are obtained by specifying distinct Toeplitz matrices for the inverse error covariance [Colour figure can be viewed at <ext-link ext-link-type="uri" xlink:href="https://onlinelibrary.wiley.com/">wileyonlinelibrary.com</ext-link>]</p>
    </caption>
    <graphic xlink:href="EMS140622-f002"/>
  </fig>
  <fig id="F3" orientation="portrait" position="float">
    <label>Figure 3</label>
    <caption>
      <p>Manhattan plot of the posterior expectation of <italic>π<sub>j</sub></italic>, <italic>j</italic> = 1, …, 9310, ordered along chromosome 16, for hotspots detection. Red triangles indicate putative hotspots identified by BayesSUR with the corresponding genetic variant name [Colour figure can be viewed at <ext-link ext-link-type="uri" xlink:href="https://onlinelibrary.wiley.com/">wileyonlinelibrary.com</ext-link>]</p>
    </caption>
    <graphic xlink:href="EMS140622-f003"/>
  </fig>
  <fig id="F4" orientation="portrait" position="float">
    <label>Figure 4</label>
    <caption>
      <p>Manhattan plot of marginal posterior inclusion probabilities of association for SNPs in chromosome 16, all metabolites superimposed. Red triangles indicate putative hotspots identified by BayesSUR with the corresponding genetic variant name. Only a few SNPs seem to be relevant and for a restricted number of metabolites. Some SNPs appear to be associated with more than one metabolite. Vertical green dotted lines show previously identified loci associated with lipids metabolites (Kettunen et al., 2016) [Colour figure can be viewed at <ext-link ext-link-type="uri" xlink:href="https://onlinelibrary.wiley.com/">wileyonlinelibrary.com</ext-link>]</p>
    </caption>
    <graphic xlink:href="EMS140622-f004"/>
  </fig>
  <fig id="F5" orientation="portrait" position="float">
    <label>Figure 5</label>
    <caption>
      <p>Network representation of the associations between SNPs (right) and metabolite (left) after thresholding the marginal posterior inclusion probabilities at 0.5 and dependence structure between metabolites estimate from the graph <italic>G</italic> after thresholding the marginal posterior edge inclusion probabilities at 0.5 [Colour figure can be viewed at <ext-link ext-link-type="uri" xlink:href="https://onlinelibrary.wiley.com/">wileyonlinelibrary.com</ext-link>]</p>
    </caption>
    <graphic xlink:href="EMS140622-f005"/>
  </fig>
  <table-wrap id="T1" position="float" orientation="portrait">
    <label>TABLE 1</label>
    <caption>
      <title>Averaged (over 20 simulated replicates) true positive and false positive rates for the graph estimation after thresholding at 0.5 the posterior marginal edge inclusion probabilities</title>
    </caption>
    <table frame="void" rules="none">
      <thead>
        <tr style="background-color:#d1d2d4">
          <th align="left" valign="middle" rowspan="1" colspan="1">
            <italic>G</italic>
          </th>
          <th align="left" valign="middle" rowspan="1" colspan="1">
            <italic>r</italic>
          </th>
          <th align="left" valign="middle" rowspan="1" colspan="1">True positive rate</th>
          <th align="left" valign="middle" rowspan="1" colspan="1">False positive rate</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Block diagonal</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.3</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.937</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.008</td>
        </tr>
        <tr style="background-color:#e7e7e9">
          <td align="left" valign="middle" rowspan="1" colspan="1">Block diagonal</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.6</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.960</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.036</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Block diagonal</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.9</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.953</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.016</td>
        </tr>
        <tr style="background-color:#e7e7e9">
          <td align="left" valign="middle" rowspan="1" colspan="1">Decomposable</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.3</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.935</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.085</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Decomposable</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.6</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.958</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.108</td>
        </tr>
        <tr style="background-color:#e7e7e9">
          <td align="left" valign="middle" rowspan="1" colspan="1">Decomposable</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.9</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.922</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.127</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Non-decomposable</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.3</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.962</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.027</td>
        </tr>
        <tr style="background-color:#e7e7e9">
          <td align="left" valign="middle" rowspan="1" colspan="1">Non-decomposable</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.6</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.986</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.117</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Non-decomposable</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.9</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.979</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">0.146</td>
        </tr>
      </tbody>
    </table>
    <table-wrap-foot>
      <fn id="TFN1">
        <p id="P89">Results are reported for SNR<sub><italic>β</italic></sub> = 5 and for different combinations of the graphical model <italic>G</italic> and the (residual) correlation between responses <italic>r</italic>.</p>
      </fn>
    </table-wrap-foot>
  </table-wrap>
  <table-wrap id="T2" position="float" orientation="portrait">
    <label>TABLE 2</label>
    <caption>
      <p>Averaged (over 20 simulated replicates) computational time in minutes for the algorithms considered: BayesSUR with covariance selection (Sparse), BayesSUR with dense covariance estimation (Dense), SSUR indirect, SSUR direct and MRCE with different numbers of candidate values for the penalty parameters where the crossvalidation procedure is performed</p>
    </caption>
    <table frame="void" rules="none">
      <thead>
        <tr style="background-color:#d1d2d4">
          <th align="left" valign="middle" rowspan="1" colspan="1">Algorithm</th>
          <th align="left" valign="middle" rowspan="1" colspan="1"/>
          <th align="center" valign="middle" rowspan="1" colspan="1">Scenario 1</th>
          <th align="center" valign="middle" rowspan="1" colspan="1">Scenario 2</th>
          <th align="center" valign="middle" rowspan="1" colspan="1">Scenario 3</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td align="left" valign="top" rowspan="2" colspan="1">BayesSUR</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">Sparse</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">57</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">89</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">87</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">Dense</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">54</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">64</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">60</td>
        </tr>
        <tr style="background-color:#e7e7e9">
          <td align="left" valign="top" rowspan="2" colspan="1">SSUR</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">Indirect</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">655</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">823</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">790</td>
        </tr>
        <tr style="background-color:#e7e7e9">
          <td align="left" valign="middle" rowspan="1" colspan="1">Direct</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">1549</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">1810</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">1661</td>
        </tr>
        <tr>
          <td align="left" valign="top" rowspan="3" colspan="1">MRCE</td>
          <td align="left" valign="middle" rowspan="1" colspan="1">200 candidate values for penalty parameters</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">281</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">156</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">109</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">40 candidate values for penalty parameters</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">32</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">9</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">7</td>
        </tr>
        <tr>
          <td align="left" valign="middle" rowspan="1" colspan="1">4 candidate values for penalty parameters</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">2</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">1</td>
          <td align="right" valign="middle" rowspan="1" colspan="1">1</td>
        </tr>
      </tbody>
    </table>
  </table-wrap>
</floats-group>
