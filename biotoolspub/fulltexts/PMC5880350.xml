<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-id journal-id-type="pmc">plosone</journal-id>
    <journal-title-group>
      <journal-title>PLoS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">5880350</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-17-44346</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0194361</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Gene Expression</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Information Technology</subject>
          <subj-group>
            <subject>Data Mining</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Computer Software</subject>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Social Sciences</subject>
        <subj-group>
          <subject>Sociology</subject>
          <subj-group>
            <subject>Communications</subject>
            <subj-group>
              <subject>Marketing</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Information Technology</subject>
          <subj-group>
            <subject>Text Mining</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Organisms</subject>
          <subj-group>
            <subject>Eukaryota</subject>
            <subj-group>
              <subject>Animals</subject>
              <subj-group>
                <subject>Vertebrates</subject>
                <subj-group>
                  <subject>Amniotes</subject>
                  <subj-group>
                    <subject>Mammals</subject>
                    <subj-group>
                      <subject>Wildebeest</subject>
                    </subj-group>
                  </subj-group>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>ParBiBit: Parallel tool for binary biclustering on modern distributed-memory systems</article-title>
      <alt-title alt-title-type="running-head">ParBiBit: Parallel tool for binary biclustering on modern distributed-memory systems</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2602-4874</contrib-id>
        <name>
          <surname>González-Domínguez</surname>
          <given-names>Jorge</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Investigation</role>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Resources</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Writing – original draft</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001"/>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Expósito</surname>
          <given-names>Roberto R.</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Resources</role>
        <role content-type="http://credit.casrai.org/">Writing – original draft</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff001"/>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <addr-line>Grupo de Arquitectura de Computadores, Universidade da Coruña, A Coruña, Spain</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Wang</surname>
          <given-names>Junwen</given-names>
        </name>
        <role>Editor</role>
        <xref ref-type="aff" rid="edit1"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Mayo Clinic Arizona, UNITED STATES</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>jgonzalezd@udc.es</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <year>2018</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>2</day>
      <month>4</month>
      <year>2018</year>
    </pub-date>
    <volume>13</volume>
    <issue>4</issue>
    <elocation-id>e0194361</elocation-id>
    <history>
      <date date-type="received">
        <day>20</day>
        <month>12</month>
        <year>2017</year>
      </date>
      <date date-type="accepted">
        <day>1</day>
        <month>3</month>
        <year>2018</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2018 González-Domínguez, Expósito</copyright-statement>
      <copyright-year>2018</copyright-year>
      <copyright-holder>González-Domínguez, Expósito</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pone.0194361.pdf"/>
    <abstract>
      <p>Biclustering techniques are gaining attention in the analysis of large-scale datasets as they identify two-dimensional submatrices where both rows and columns are correlated. In this work we present <italic>ParBiBit</italic>, a parallel tool to accelerate the search of interesting biclusters on binary datasets, which are very popular on different fields such as genetics, marketing or text mining. It is based on the state-of-the-art sequential Java tool <italic>BiBit</italic>, which has been proved accurate by several studies, especially on scenarios that result on many large biclusters. <italic>ParBiBit</italic> uses the same methodology as <italic>BiBit</italic> (grouping the binary information into patterns) and provides the same results. Nevertheless, our tool significantly improves performance thanks to an efficient implementation based on C++11 that includes support for threads and MPI processes in order to exploit the compute capabilities of modern distributed-memory systems, which provide several multicore CPU nodes interconnected through a network. Our performance evaluation with 18 representative input datasets on two different eight-node systems shows that our tool is significantly faster than the original <italic>BiBit</italic>. Source code in C++ and MPI running on Linux systems as well as a reference manual are available at <ext-link ext-link-type="uri" xlink:href="https://sourceforge.net/projects/parbibit/">https://sourceforge.net/projects/parbibit/</ext-link>.</p>
    </abstract>
    <funding-group>
      <funding-statement>This work was supported by the Ministry of Economy, Industry and Competitiveness of Spain and FEDER funds of the European Union (grant TIN2016-75845-P [AEI/FEDER/UE]), as well as by Xunta de Galicia (Centro Singular de Investigacion de Galicia accreditation 2016–2019, ref. EDG431G/01).</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="8"/>
      <table-count count="3"/>
      <page-count count="19"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>The experimental evaluation was performed with synthetic data. The program to generate these data can be publicly obtained from: <ext-link ext-link-type="uri" xlink:href="https://osf.io/9pvh8/">https://osf.io/9pvh8/</ext-link>.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>The experimental evaluation was performed with synthetic data. The program to generate these data can be publicly obtained from: <ext-link ext-link-type="uri" xlink:href="https://osf.io/9pvh8/">https://osf.io/9pvh8/</ext-link>.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>The amount of data that can be collected and stored in several research and industry fields has significantly increased during the last years. This information is often described in a two-dimensional way, where rows and columns represent the measured attributes and samples, respectively. The analysis of these data is a complex and computationally expensive procedure that often requires data mining techniques to extract valuable information and transform it into an understandable structure for further use. A widely spread data mining approach is the clustering, that allows to identify some patterns and structures between the attribute and sample relationships. However, traditional clustering techniques are not able to provide information to understand local relationships between both samples and attributes. In this case, biclustering approaches should be used in order to identify a subset of rows (attributes) that exhibit similar patterns on a subset of columns (samples) in a two-dimensional data matrix.</p>
    <p>There exist several biclustering techniques, with different advantages and drawbacks depending on the characteristics of the input datasets and the research field where the approach will be used [<xref rid="pone.0194361.ref001" ref-type="bibr">1</xref>]. Gene expression analyses are probably nowadays the most common application of biclustering techniques. In this case datasets contain information about the expression level of many genes on several individuals under different experimental conditions. Rows and columns represent genes and samples, respectively. Biclustering is able to diagnose genes responsible of certain diseases only on a group of individuals. Many research works have focused on analyzing the best biclustering approaches for gene expression data [<xref rid="pone.0194361.ref002" ref-type="bibr">2</xref>–<xref rid="pone.0194361.ref004" ref-type="bibr">4</xref>]. Other fields where biclustering has been satisfactorily applied are drug activity [<xref rid="pone.0194361.ref005" ref-type="bibr">5</xref>], text mining [<xref rid="pone.0194361.ref006" ref-type="bibr">6</xref>], information theory [<xref rid="pone.0194361.ref007" ref-type="bibr">7</xref>] or marketing [<xref rid="pone.0194361.ref008" ref-type="bibr">8</xref>].</p>
    <p>Among the different alternatives for biclustering, some algorithms are especially designed for binary data so that they are able to obtain results with better accuracy in lower runtime over these very common datasets. For instance, in genetics the data can be simplified so that each value one or zero represents whether a gene is differentially expressed in an individual or not. A recent survey has proved that binary biclustering can provide high precision results for gene expression data analyses [<xref rid="pone.0194361.ref009" ref-type="bibr">9</xref>]. Binary data matrices are also useful in text mining (values are one only when certain word appears in a document) or marketing (each value represents whether a costumer buys a product or not).</p>
    <p>Despite binary biclustering techniques are usually faster than those for quantitative data, the computational cost of the available methods that provide accurate results is still prohibitive for large datasets. This paper presents <italic>ParBiBit</italic>, a parallel application that exploits computational capability of modern distributed-memory systems to accelerate the search of biclusters on binary datasets. It is implemented with a hybrid approach that uses MPI [<xref rid="pone.0194361.ref010" ref-type="bibr">10</xref>] to work on different nodes connected through a network, with the multithreaded support of C++11 [<xref rid="pone.0194361.ref011" ref-type="bibr">11</xref>] to exploit several cores within the same node.</p>
  </sec>
  <sec id="sec002">
    <title>Related work</title>
    <p>Several biclustering approaches have been suggested to deal with binary two-dimensional matrices. Among all of them, we have selected the Java-based application <italic>BiBit</italic> [<xref rid="pone.0194361.ref012" ref-type="bibr">12</xref>] as basis for our tool due to several reasons:</p>
    <list list-type="bullet">
      <list-item>
        <p>A recent review of 17 available biclustering methods [<xref rid="pone.0194361.ref009" ref-type="bibr">9</xref>] has proved that <italic>BiBit</italic> obtains accurate results for gene expression data, especially on cases with many large biclusters. This work also shows that the <italic>BiBit</italic> approach can be useful for quantitative data if applying a binarization.</p>
      </list-item>
      <list-item>
        <p><italic>BiBit</italic> exploits the binary nature of the data by efficiently using Boolean algebra operations. This makes it faster than <italic>Bimax</italic> [<xref rid="pone.0194361.ref013" ref-type="bibr">13</xref>], probably the most commonly employed binary biclustering tool.</p>
      </list-item>
      <list-item>
        <p>Although in the last years several algorithms not tested in the aforementioned review have been presented for binary biclustering [<xref rid="pone.0194361.ref014" ref-type="bibr">14</xref>–<xref rid="pone.0194361.ref016" ref-type="bibr">16</xref>], their related publications do not include tests that prove that any of these novel approaches are more accurate than <italic>BiBit</italic>. Furthermore, these implementations are not publicly available for further testing.</p>
      </list-item>
    </list>
    <p><italic>ParBiBit</italic> is significantly faster than <italic>BiBit</italic> thanks to an efficient C++ implementation and its ability to exploit the computational capabilities of large systems with several multicore nodes connected through a network (also known as CPU clusters). Previous works that address the biclustering on this type of facilities are available for quantitative datasets following either the message-passing paradigm [<xref rid="pone.0194361.ref017" ref-type="bibr">17</xref>, <xref rid="pone.0194361.ref018" ref-type="bibr">18</xref>] or the MapReduce approach [<xref rid="pone.0194361.ref019" ref-type="bibr">19</xref>, <xref rid="pone.0194361.ref020" ref-type="bibr">20</xref>]. The only work focused on binary data [<xref rid="pone.0194361.ref021" ref-type="bibr">21</xref>] is implemented with this last MapReduce paradigm. However, all these previous works seem preliminary implementations as their parallel software have not been released. Consequently, up to our knowledge, <italic>ParBiBit</italic> is the first publicly available tool to accelerate binary biclustering on multicore CPU clusters. Finally, implementations designed for other type of high performance computing architectures such as GPUs [<xref rid="pone.0194361.ref022" ref-type="bibr">22</xref>–<xref rid="pone.0194361.ref024" ref-type="bibr">24</xref>] or FPGAs [<xref rid="pone.0194361.ref025" ref-type="bibr">25</xref>, <xref rid="pone.0194361.ref026" ref-type="bibr">26</xref>] have also been presented, but none of them dedicated to binary data.</p>
  </sec>
  <sec id="sec003">
    <title>Background</title>
    <p>This section describes the main concepts and technologies on which <italic>ParBiBit</italic> relies on, and thus are necessary to understand the behavior and implementation of our tool.</p>
    <sec id="sec004">
      <title>Binary biclustering: The BiBit approach</title>
      <p>A bicluster in a binary matrix <italic>M</italic> with dimensions <italic>m</italic> × <italic>n</italic> consists of a set of rows and columns (<italic>R</italic>, <italic>C</italic>) so that all the values within that subset are one. A formal definition can be: ∀<italic>i</italic> ∈ <italic>R</italic>, ∀<italic>j</italic> ∈ <italic>C</italic>, <italic>M</italic>[<italic>i</italic>, <italic>j</italic>] = 1. Additionally, most tools search for only maximal biclusters, i.e., those that are not entirely contained by any other bicluster.</p>
      <p>Similarly to <italic>BiBit</italic>, our tool uses the concept of <italic>bit-pattern</italic> in order to find the biclusters of a binary matrix with a minimum number of rows (<italic>mnr</italic>) and columns (<italic>mnc</italic>) specified by the user. The joint pattern of a subset of rows consists of <italic>n</italic> bits (one per column) where the bit <italic>k</italic> is set to one if the binary value of column <italic>k</italic> in all the rows of the subset is equal to one. Otherwise, the bit is set to zero. It means that the joint pattern <italic>p</italic> of a subset of rows (<italic>r</italic><sub>1</sub>, <italic>r</italic><sub>2</sub>, …, <italic>r</italic><sub><italic>z</italic></sub>) can be defined as: <italic>p</italic> = <italic>r</italic><sub>1</sub> ∧ <italic>r</italic><sub>2</sub> ∧ … ∧ <italic>r</italic><sub><italic>z</italic></sub>, where ∧ is the binary AND operator. The pattern of a bicluster is the joint pattern of all the rows contained in it. <italic>BiBit</italic> works as follows (we refer to the <italic>BiBit</italic> main publication [<xref rid="pone.0194361.ref012" ref-type="bibr">12</xref>] for more details):</p>
      <list list-type="order">
        <list-item>
          <p>Initializes an empty list of bicluster structures.</p>
        </list-item>
        <list-item>
          <p>For each pair of rows (<italic>r</italic><sub><italic>i</italic>1</sub>, <italic>r</italic><sub><italic>i</italic>2</sub>) from the input matrix <italic>M</italic>:</p>
          <list list-type="alpha-lower">
            <list-item>
              <p>Creates a new bicluster with pattern <italic>p</italic> = <italic>r</italic><sub><italic>i</italic>1</sub> ∧ <italic>r</italic><sub><italic>i</italic>2</sub> and rows <italic>r</italic><sub><italic>i</italic>1</sub>, <italic>r</italic><sub><italic>i</italic>2</sub>.</p>
            </list-item>
            <list-item>
              <p>Checks that the number of ones in the pattern is equal or higher than <italic>mnc</italic> and the pattern has not been used for any bicluster already inserted in the list. Otherwise, the bicluster is discarded and the algorithm returns to step 2.a for new pair.</p>
            </list-item>
            <list-item>
              <p>All rows <italic>r</italic><sub><italic>i</italic>3</sub> different than <italic>r</italic><sub><italic>i</italic>1</sub> and <italic>r</italic><sub><italic>i</italic>2</sub> are compared to <italic>p</italic>, and those that satisfy that <italic>p</italic> ∧ <italic>r</italic><sub><italic>i</italic>3</sub> = <italic>p</italic> are included in the bicluster.</p>
            </list-item>
            <list-item>
              <p>The bicluster is inserted in the list if the number of rows is equal or higher than <italic>mnr</italic>.</p>
            </list-item>
          </list>
        </list-item>
        <list-item>
          <p>The information of the list is printed in the output file. The rows that belong to each bicluster were directly saved in the structure, while the columns can be obtained as those elements in the pattern equal to one.</p>
        </list-item>
      </list>
      <p>However, the dependencies among the iterations of the loop in step 2 (each iteration checks whether the pattern has already been used) make the <italic>BiBit</italic> algorithm not adequate for parallel computing. Thus, it had to be modified in <italic>ParBiBit</italic> as will be explained in following sections.</p>
    </sec>
    <sec id="sec005">
      <title>Multithreading with C++11</title>
      <p>Historically, there have been several C and C++-based libraries that support multithreading over several CPU cores that share memory. Some examples are POSIX Threads [<xref rid="pone.0194361.ref027" ref-type="bibr">27</xref>] or Intel’s Threading Building Blocks [<xref rid="pone.0194361.ref028" ref-type="bibr">28</xref>]. This heterogeneous software landscape made it difficult to write platform-portable C/C++ codes. With the release of C++11 [<xref rid="pone.0194361.ref011" ref-type="bibr">11</xref>] and its novel multithreading API it is finally possible to write platform-independent code in C++ that is supported by compilers from both the Linux/UNIX world and the Windows ecosystem without the need for third party libraries.</p>
      <p>When a C++ program is executed, only one main thread exists. An arbitrary number of software threads can be spawned by the main thread of a system process, and are represented in C++11 with an object of class <italic>thread</italic>. It is even possible to recursively spawn threads from within already spawned ones. The actual number of concurrently running threads should be adjusted to roughly match the amount of physical cores of the system since the OS might serialize their execution using expensive context switches if their number exceeds the amount of available cores. All threads share the resources of the parent system process, i.e., they can access the same memory space. This is advantageous since threads can be spawned with low latency and benefit from lightweight inter-thread communication using shared registers and arrays. The instruction flow of the main thread continues independently of the work accomplished in the spawned threads until the end of the main function is reached. In order to ensure that all spawned threads have finished their work, the main thread should wait for them. This is accomplished with a call to the method <italic>join</italic> of the class <italic>thread</italic>.</p>
      <p>As all threads share the same memory space, one of the most common causes of errors are the race conditions, i.e., situations where two or more threads want to access the same data and they try to change it simultaneously. As the thread scheduling algorithm can swap between threads at any time, we do not know the order in which the threads will attempt to access the shared data. Therefore, the result of the change in data would be dependent on the thread scheduling algorithm, i.e., both threads are racing to access/change the data. The solution in C++11 consists in using an object of the class <italic>mutex</italic> to restrict the execution of critical sections to a certain thread in a mutually exclusive manner. A mutex can be locked by a specific thread, i.e., the subsequent code fragment can only be executed by the issuing thread until the mutex is released. While being locked a mutex cannot be locked or unlocked by other threads which have to wait for its release causing an implicit synchronization of threads. Nevertheless, it is not advisable to abuse of the use of mutexes as its synchronization leads to some performance overhead (some threads stop their execution and remain idle). In <italic>ParBiBit</italic>, mutexes are used to serialize the modification of the list of biclusters to ensure that all threads have the most updated information when they check whether the pattern has already been used (see point 2.d in the background subsection that describes the <italic>BiBit</italic> approach).</p>
    </sec>
    <sec id="sec006">
      <title>Message passing interface (MPI)</title>
      <p>The target parallel architecture of this work are distributed-memory systems that consist of several nodes interconnected through a network, each of them with a memory module and several CPU cores (see <xref ref-type="fig" rid="pone.0194361.g001">Fig 1</xref>). Parallel computing on this kind of systems usually follows the Single Program Multiple Data (SPMD) style, i.e., it splits the workload into different tasks that are executed on multiple CPUs so that all nodes and cores collaborate to accelerate computation. The computational capability of the cluster depends on factors such as the number of nodes, the number of cores per node, the network characteristics, the memory bandwidth, etc.</p>
      <fig id="pone.0194361.g001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0194361.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>Abstraction of a distributed-memory system with several cores and one memory module per node.</title>
        </caption>
        <graphic xlink:href="pone.0194361.g001"/>
      </fig>
      <p>The most common programming model for high-performance cluster systems is message-passing. MPI [<xref rid="pone.0194361.ref010" ref-type="bibr">10</xref>] is established as a <italic>de-facto</italic> standard for message-passing as it is based on the consensus of more than 40 participating organizations, including vendors, researchers, software library developers, and users. MPI provides a portable, efficient, and flexible standard for message-passing. Note that it is only a definition of an interface, that has been implemented by several developers for different architectures. Nowadays there exist several implementations whose routines or functions can be directly called from C, C++, Fortran or Java code.</p>
      <p>A parallel MPI program consists of several processes with associated local memory. In a pure MPI program each process is linked to one core. In hybrid MPI and multithreaded programs as <italic>ParBiBit</italic> each process is usually mapped to one node and it has several associated threads launched with the C++11 multithreading support (often the same number of threads as cores within the node). We should remark that each process has its own memory address space that cannot be directly accessed by other processes. If one process needs information stored in a remote memory module data communication must be performed, which is usually the main performance overhead. The traditional MPI communication style is two-sided, where the source and destination processes must be synchronized through either send and receive functions or collective routines for communications that involve more than two processes. Nevertheless, <italic>ParBiBit</italic> improves the efficiency of the internal data exchanges by making use of the Remote Memory Access (RMA) one-sided communications included in MPI since its 3.0 version. These kind of routines have been proved more efficient than two-sided communication on several scenarios, thanks to avoiding synchronizations between source and destination processes [<xref rid="pone.0194361.ref029" ref-type="bibr">29</xref>, <xref rid="pone.0194361.ref030" ref-type="bibr">30</xref>].</p>
    </sec>
  </sec>
  <sec sec-type="materials|methods" id="sec007">
    <title>Methods</title>
    <p><italic>ParBiBit</italic> is a command line tool that receives as arguments some configuration parameters such as the path to the input and output files, the minimum number of rows (<italic>mnr</italic>) and columns (<italic>mnc</italic>) per bicluster, etc. An explanation of all the arguments, as well as installation and execution instructions, are included in the reference manual of the tool. Although <italic>BiBit</italic> introduces the bit-pattern approach used in our tool, its algorithm is not adequate for parallel computation. Therefore, instead of having one only loop with dependencies among all its iterations, <italic>ParBiBit</italic> divides the computation into the following phases:</p>
    <list list-type="order">
      <list-item>
        <p>Input reading. Read the two-dimensional data matrix with the input values for <italic>m</italic> attributes and <italic>n</italic> samples from a file with ARFF extension.</p>
      </list-item>
      <list-item>
        <p>Binarization (optional). Although our tool is designed for binary biclustering, it also accepts real values in the input data file. In this case it applies a binarization procedure where all values higher than a certain threshold are set to one, and otherwise to zero. This threshold is also indicated as a parameter by command line. This approach has been used in previous analyses with satisfactory results [<xref rid="pone.0194361.ref009" ref-type="bibr">9</xref>].</p>
      </list-item>
      <list-item>
        <p>Encoding. Instead of saving in memory a <italic>m</italic> × <italic>n</italic> matrix with the binary values, <italic>ParBiBit</italic> encodes the values associated to each attribute into an array of 32-bit integers with length <inline-formula id="pone.0194361.e001"><alternatives><graphic xlink:href="pone.0194361.e001.jpg" id="pone.0194361.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mfrac><mml:mi>n</mml:mi><mml:mn>32</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula> (each integer contains the information of 32 samples). Working with encoded values accelerates the procedure of checking whether a row must be included in a bicluster (see point 2.c in the background subsection that explains the <italic>BiBit</italic> approach): for each 32 samples we only need one 32-bit AND operation, which is much faster than 32 1-bit AND operations. This encoding technique had already been applied in <italic>BiBit</italic> but with a 16-bit basis that is less effective than our 32-bit approach. The use of 64-bit (or even larger) encoded values was discarded as one 64-bit AND logic operation is not faster than two 32-bit AND operations on most computing platforms.</p>
      </list-item>
      <list-item>
        <p>Bicluster initialization. Create one bicluster structure for each pair of rows with the following information: the joint pattern and the id of the two rows of the pair. Insert in a set all the structures that correspond to biclusters with different patterns.</p>
      </list-item>
      <list-item>
        <p>Bicluster completion. For each bicluster with rows (<italic>r</italic><sub><italic>i</italic>1</sub>, <italic>r</italic><sub><italic>i</italic>2</sub>) available in the set from the previous phase, complete its information by checking whether all rows <italic>r</italic><sub><italic>i</italic>3</sub> (with <italic>i</italic>3 ≠ <italic>i</italic>1, <italic>i</italic>2) belong to the bicluster. Include the id <italic>i</italic>3 in the structure when the condition is satisfied.</p>
      </list-item>
      <list-item>
        <p>Output writing. The information of the biclusters found in the previous steps is written into an output file that follows the same format as for <italic>BiBit</italic>, i.e., one line per bicluster with the following values separated by semicolons:</p>
        <list list-type="alpha-lower">
          <list-item>
            <p>An integer with the number of rows in the bicluster (<italic>nr</italic>).</p>
          </list-item>
          <list-item>
            <p>An integer with the number of columns in the bicluster (<italic>nc</italic>).</p>
          </list-item>
          <list-item>
            <p>A list of <italic>nr</italic> strings with the names or ids of the attributes included in the bicluster. They are explicitly stored in the structure.</p>
          </list-item>
          <list-item>
            <p>A list of <italic>nc</italic> strings with the names or ids of the samples included in the bicluster. They can be obtained from the pattern, as those elements with bit one in the pattern represent columns included in the bicluster.</p>
          </list-item>
        </list>
      </list-item>
    </list>
    <p>The impact of binarization and encoding on the total runtime is negligible, while the reading/writing of the input/output are I/O intensive phases without chances for parallelization. Therefore, we have focused on accelerating the phases that initialize and complete the biclusters (steps 4 and 5), which are the most computationally demanding ones (more than 98% of the total runtime when executing on one core). Finally, remark that the sequential C++ code of <italic>ParBiBit</italic> is more efficient than the <italic>BiBit</italic> one with Java, especially thanks to better memory management.</p>
    <sec id="sec008">
      <title>Parallel bicluster initialization</title>
      <p>Algorithm 1 shows the pseudocode of this phase, that receives as input the encoded data and the minimum number of columns, and whose goal is to provide a set of all the bicluster structures with only two row ids that have different patterns. The information of all these initialized biclusters will be extended in the next step. Each bicluster is represented as a structure with a list of attribute ids (integers) and a pattern (i.e., an array with <inline-formula id="pone.0194361.e002"><alternatives><graphic xlink:href="pone.0194361.e002.jpg" id="pone.0194361.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:mfrac><mml:mi>n</mml:mi><mml:mn>32</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula> 32-bit integers where a bit equal to one in position <italic>j</italic> represents that the value of the <italic>j</italic>-th sample is one in all the rows that belong to the bicluster). The C++ <monospace>set</monospace> container is used to save all bicluster structures as it works faster than a <monospace>list</monospace> for insertions, deletions and searches when each element can be identified by a unique key (logarithmic complexity instead of linear). In this case the key is equal to the pattern, as no biclusters with the same pattern are allowed. The C++ <monospace>set</monospace> is initially empty and is stored in shared memory so all threads can insert the structure and check whether the pattern is repeated.</p>
      <p><bold>Algorithm 1:</bold> Pseudocode of the multithreaded approach to initialize the biclusters.</p>
      <p specific-use="line">1 INPUT: <inline-formula id="pone.0194361.e003"><alternatives><graphic xlink:href="pone.0194361.e003.jpg" id="pone.0194361.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:mn>32</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> 32-bit integer matrix <italic>D</italic> with the encoded data</p>
      <p specific-use="line">2 INPUT: Integer <italic>mnc</italic> with the minimum number of columns per bicluster</p>
      <p specific-use="line">3 Initialize empty bicluster set <italic>S</italic></p>
      <p specific-use="line">4 Initialize mutex <italic>x</italic></p>
      <p specific-use="line">5 # Multiple threads responsible of different <italic>i</italic> indexes</p>
      <p specific-use="line">6 <bold>for</bold>
<italic>Each row i from</italic> 0 <italic>to m</italic> − 2 <bold>do</bold></p>
      <p specific-use="line">7  <bold>for</bold>
<italic>Each row k from i</italic> + 1 <italic>to m</italic> − 1 <bold>do</bold></p>
      <p specific-use="line">8   Initialize pattern <italic>p</italic> as empty array of 32-bit integers</p>
      <p specific-use="line">9   Initialize <italic>num</italic>1 ≔ 0</p>
      <p specific-use="line">10  <bold>for</bold>
<italic>Each encoded column j from</italic> 0 <italic>to</italic>
<inline-formula id="pone.0194361.e004"><alternatives><graphic xlink:href="pone.0194361.e004.jpg" id="pone.0194361.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:mfrac><mml:mi>n</mml:mi><mml:mn>32</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula>
<bold>do</bold></p>
      <p specific-use="line">11   <italic>p</italic>[<italic>j</italic>] ≔ <italic>D</italic>[<italic>i</italic>][<italic>j</italic>] ∧ <italic>D</italic>[<italic>k</italic>][<italic>j</italic>]</p>
      <p specific-use="line">12   <italic>num</italic>1 ≔ <italic>num</italic>1 + <italic>popcount</italic>(<italic>p</italic>[<italic>j</italic>])</p>
      <p specific-use="line">    <bold>end</bold></p>
      <p specific-use="line">13  <bold>if</bold>
<italic>num</italic>1 ≥ <italic>mnc</italic>
<bold>then</bold></p>
      <p specific-use="line">14   Create bicluster structure <italic>b</italic> with <italic>p</italic>, <italic>i</italic> and <italic>k</italic></p>
      <p specific-use="line">15   Lock <italic>x</italic></p>
      <p specific-use="line">16   <bold>if</bold>
<italic>No bicluster structure with pattern p in S</italic>
<bold>then</bold></p>
      <p specific-use="line">17    Insert <italic>b</italic> in <italic>S</italic></p>
      <p specific-use="line">    <bold>end</bold></p>
      <p specific-use="line">18   Unlock <italic>x</italic>;</p>
      <p specific-use="line">     <bold>end</bold></p>
      <p specific-use="line">   <bold>end</bold></p>
      <p specific-use="line">  <bold>end</bold></p>
      <p>Two loops that iterate among the rows of the encoded matrix <italic>D</italic> are necessary to work over all the pairs of attributes (Lines 6 and 7). The pattern of each pair is calculated by applying one 32-bit logical AND (∧) operation for each encoded value (Line 11). The number of ones in the pattern represents the number of samples that are included in the bicluster. Therefore, only those patterns with higher number of one values than <italic>mnc</italic> are useful (Line 13). The function <monospace>popcount</monospace> of Line 12 represents a custom-made routine that efficiently counts the number of positive bits of a 32-bit integer on a x86-based computing system.</p>
      <p>The second condition that must be fulfilled in order to insert a new bicluster in the <monospace>set</monospace> is that no previous structure has the same pattern. Remark that several threads searching and/or inserting biclusters with the same pattern at the same time could lead to race conditions. A mutex is employed to serialize these accesses and thus avoid that two threads could simultaneously insert biclusters with the same pattern (Lines 15-18). In order to minimize the amount of serial work, the creation of the bicluster of Line 14 was removed from the critical section.</p>
      <p>No MPI parallelization has been included in this step as its performance would not be satisfactory on distributed-memory nodes. Every time that one structure is initialized the process should check in the <monospace>set</monospace> whether the pattern is repeated. It could be performed either with a centralized container or with a copy of the <monospace>set</monospace> on each process. Nevertheless, both solutions would be extremely inefficient due to the large amount of MPI communications needed to synchronize each insertion in the <monospace>set</monospace>. Therefore, at the end of this phase only one process has the information available in its local memory.</p>
    </sec>
    <sec id="sec009">
      <title>Bicluster completion</title>
      <p>Bicluster completion consists in finding which rows belong to each of the already initialized biclusters. In this stage <italic>ParBiBit</italic> launches several MPI processes that work over different biclusters at the same time, applying a static distribution where the same amount of biclusters are assigned to each process. This distribution provides a well-balanced workload among processes as the computational cost of each bicluster completion is similar. Algorithm 2 illustrates the work performed by each process. It starts by copying the initial encoded data to the memory of all processes (Line 4), as this data is initially only available on the main process (the only one that worked during the previous phase) but will be needed by all of them. We use the <monospace>MPI_Bcast</monospace> collective that is usually faster than point-to-point communications [<xref rid="pone.0194361.ref031" ref-type="bibr">31</xref>, <xref rid="pone.0194361.ref032" ref-type="bibr">32</xref>]. Although this data replication leads to memory overhead, it allows <italic>ParBiBit</italic> to reduce communication. In order to limit the memory overhead and make it affordable for current systems, <italic>ParBiBit</italic> does not create one MPI process per core (each one with its own copy of the encoded data). Instead, each process is related to a group of cores and launches several C++11 threads that are able to access shared memory, use the same copy of the data and collaborate to complete the biclusters assigned to their parent process. This hybrid model has already been satisfactorily applied to other fields such as bioinformatics [<xref rid="pone.0194361.ref033" ref-type="bibr">33</xref>], molecular dynamics [<xref rid="pone.0194361.ref034" ref-type="bibr">34</xref>] or linear algebra [<xref rid="pone.0194361.ref035" ref-type="bibr">35</xref>]. Our implementation is flexible enough to allow the users to specify the desired number of MPI processes and threads (see the reference manual).</p>
      <p><bold>Algorithm 2:</bold> Pseudocode of the hybrid MPI/multithreaded approach on each process (with id <italic>myId</italic>) to complete the biclusters.</p>
      <p specific-use="line">1 INPUT only in Process 0: <inline-formula id="pone.0194361.e005"><alternatives><graphic xlink:href="pone.0194361.e005.jpg" id="pone.0194361.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mrow><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:mn>32</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> 32-bit integer matrix <italic>D</italic> with the encoded data</p>
      <p specific-use="line">2 INPUT only in Process 0: Set <italic>S</italic> with <italic>nb</italic> initialized biclusters</p>
      <p specific-use="line">3 INPUT: Integer <italic>mnr</italic> with the minimum number of rows per bicluster</p>
      <p specific-use="line">4 <italic>MPI</italic>_<italic>Bcast</italic> with <italic>D</italic> from Process 0 to the others</p>
      <p specific-use="line">5 Calculate <italic>myIniB</italic> and <italic>myLastB</italic></p>
      <p specific-use="line">6 <bold>if</bold>
<italic>myId</italic> == 0 <bold>then</bold></p>
      <p specific-use="line">7  Create <italic>MPI</italic>_<italic>Window</italic>
<italic>W</italic> with <inline-formula id="pone.0194361.e006"><alternatives><graphic xlink:href="pone.0194361.e006.jpg" id="pone.0194361.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:mrow><mml:mi>n</mml:mi><mml:mi>b</mml:mi><mml:mover accent="true"><mml:mo>(</mml:mo><mml:mo>˙</mml:mo></mml:mover><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:mn>32</mml:mn></mml:mfrac><mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> 32-bit integers accessible to all processes</p>
      <p specific-use="line">8  <bold>for</bold>
<italic>Each bicluster b in position j of S</italic>
<bold>do</bold></p>
      <p specific-use="line">9   Copy the id of the first attribute of <italic>b</italic> in <inline-formula id="pone.0194361.e007"><alternatives><graphic xlink:href="pone.0194361.e007.jpg" id="pone.0194361.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:mrow><mml:mi>W</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:mn>32</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>·</mml:mo><mml:mi>j</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula></p>
      <p specific-use="line">10  Copy the id of the second attribute of <italic>b</italic> in <inline-formula id="pone.0194361.e008"><alternatives><graphic xlink:href="pone.0194361.e008.jpg" id="pone.0194361.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:mrow><mml:mi>W</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:mn>32</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>·</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula></p>
      <p specific-use="line">11  Copy the <inline-formula id="pone.0194361.e009"><alternatives><graphic xlink:href="pone.0194361.e009.jpg" id="pone.0194361.e009g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M9"><mml:mfrac><mml:mi>n</mml:mi><mml:mn>32</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula> integers of the pattern of <italic>b</italic> in <inline-formula id="pone.0194361.e010"><alternatives><graphic xlink:href="pone.0194361.e010.jpg" id="pone.0194361.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:mrow><mml:mi>W</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:mn>32</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>·</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula></p>
      <p specific-use="line">   <bold>end</bold></p>
      <p specific-use="line">12 <italic>MPI</italic>_<italic>Win</italic>_<italic>fence</italic> to guarantee that copies to <italic>W</italic> are completed</p>
      <p specific-use="line">  <bold>end</bold></p>
      <p specific-use="line">  <bold>else</bold></p>
      <p specific-use="line">13 <italic>MPI</italic>_<italic>Win</italic>_<italic>fence</italic> to guarantee that the necessary initial bicluster information is in <italic>W</italic></p>
      <p specific-use="line">14 Get the information of <italic>W</italic> from <inline-formula id="pone.0194361.e011"><alternatives><graphic xlink:href="pone.0194361.e011.jpg" id="pone.0194361.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:mrow><mml:mi>m</mml:mi><mml:mi>y</mml:mi><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>B</mml:mi><mml:mover accent="true"><mml:mo>(</mml:mo><mml:mo>˙</mml:mo></mml:mover><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:mn>32</mml:mn></mml:mfrac><mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> to <inline-formula id="pone.0194361.e012"><alternatives><graphic xlink:href="pone.0194361.e012.jpg" id="pone.0194361.e012g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M12"><mml:mrow><mml:mi>m</mml:mi><mml:mi>y</mml:mi><mml:mi>I</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>B</mml:mi><mml:mover accent="true"><mml:mo>(</mml:mo><mml:mo>˙</mml:mo></mml:mover><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mfrac><mml:mi>n</mml:mi><mml:mn>32</mml:mn></mml:mfrac><mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula></p>
      <p specific-use="line">15 Create a list with the information copied from <italic>W</italic> in the previous line</p>
      <p specific-use="line">  <bold>end</bold></p>
      <p specific-use="line">16 # Multiple threads responsible of different biclusters</p>
      <p specific-use="line">17 <bold>for</bold>
<italic>Each bicluster b from myIniB to myLastB</italic>
<bold>do</bold></p>
      <p specific-use="line">18 <italic>nr</italic> ≔ 2</p>
      <p specific-use="line">19 <bold>for</bold>
<italic>Each row i from</italic> 0 <italic>to m</italic>
<bold>do</bold></p>
      <p specific-use="line">20  <bold>if</bold>
<italic>i is not one of the initial row ids of b</italic>
<bold>then</bold></p>
      <p specific-use="line">21   <italic>p</italic> equal to the pattern of <italic>b</italic></p>
      <p specific-use="line">22   <italic>j</italic> ≔ 0</p>
      <p specific-use="line">23   <bold>while</bold> (<italic>j</italic> &lt; <italic>n</italic>) ∧ (<italic>p</italic>[<italic>j</italic>] == <italic>p</italic>[<italic>j</italic>] ∧ <italic>D</italic>[<italic>i</italic>][<italic>j</italic>]) <bold>do</bold></p>
      <p specific-use="line">24    <italic>j</italic> ≔ <italic>j</italic> + 1</p>
      <p specific-use="line">    <bold>end</bold></p>
      <p specific-use="line">25   <bold>if</bold>
<italic>j</italic> == <italic>n</italic>
<bold>then</bold></p>
      <p specific-use="line">26    Insert row <italic>i</italic> as part of <italic>b</italic></p>
      <p specific-use="line">27    <italic>nr</italic> ≔ <italic>nr</italic> + 1</p>
      <p specific-use="line">     <bold>end</bold></p>
      <p specific-use="line">     <bold>end</bold></p>
      <p specific-use="line">   <bold>end</bold></p>
      <p specific-use="line">28 <bold>if</bold>
<italic>nr</italic> &lt; <italic>mnr</italic>
<bold>then</bold></p>
      <p specific-use="line">29  Remove <italic>b</italic> from the list of biclusters</p>
      <p specific-use="line">   <bold>end</bold></p>
      <p specific-use="line">  <bold>end</bold></p>
      <p>Similarly to the encoded data, at the beginning of the phase the information of the initialized bicluster structures is only available on the main process memory. In this case it must be distributed (not replicated) among all processes so that each one only saves the information of those biclusters that it will work with. It is performed with one-sided RMA routines which in general are more efficient than two-sided counterparts, as mentioned in the MPI background subsection. RMA communications work with windows, i.e., arrays of data that belong to one process but are directly accessible to the other, without requiring any synchronization between senders and receivers. This window is created in the memory of the main process (Line 7) with enough space to store all the initial information of the bicluster structures: the id of the two rows that are already included as well as the <inline-formula id="pone.0194361.e013"><alternatives><graphic xlink:href="pone.0194361.e013.jpg" id="pone.0194361.e013g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M13"><mml:mrow><mml:mfrac><mml:mi>n</mml:mi><mml:mn>32</mml:mn></mml:mfrac><mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> integer pattern. The information of each bicluster is consecutively stored in the window (Lines 8-11). Then, each process accesses to their associated data just with one <monospace>get</monospace> routine (Line 14) after a synchronization that guarantees that the data has been effectively copied to the window (Lines 12-13). <xref ref-type="fig" rid="pone.0194361.g002">Fig 2</xref> illustrates with an example the procedure of the bicluster distribution.</p>
      <fig id="pone.0194361.g002" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0194361.g002</object-id>
        <label>Fig 2</label>
        <caption>
          <title>Example of a bicluster distribution for a program with three MPI processes using RMA windows.</title>
          <p>The main process (Proc. 0) copies the whole data to the window and, after a synchronization that guarantees that the copies have been completed, the other processes directly get only the information of their associated biclusters.</p>
        </caption>
        <graphic xlink:href="pone.0194361.g002"/>
      </fig>
      <p>Once all processes have the necessary information, each one can start the completion of its associated biclusters by launching several threads (each thread responsible of different biclusters). No synchronization is needed among processes or threads as the procedure is completely independent among biclusters. Assume that the initial pair of rows of a certain bicluster is (<italic>r</italic><sub>1</sub>, <italic>r</italic><sub>2</sub>). Then we must analyze all the rows <italic>r</italic><sub><italic>x</italic></sub> different than <italic>r</italic><sub>1</sub> and <italic>r</italic><sub>2</sub> (loop between Lines 19 and 27). As explained for <italic>BiBit</italic> a row must be included in the bicluster when the result of the logical AND operations between the bicluster pattern and the row data are the same (Lines 23-26). Every time that <italic>ParBiBit</italic> adds a new row it updates the variable <italic>nr</italic> with the number of rows per bicluster (Line 27). Once all rows different than <italic>r</italic><sub>1</sub> and <italic>r</italic><sub>2</sub> have been tested, we remove the bicluster from the list if the number of rows <italic>nr</italic> is lower than <italic>mnr</italic> (Lines 28-29). Finally, each process prints the information of their associated biclusters into the output file.</p>
    </sec>
  </sec>
  <sec id="sec010">
    <title>Experimental results</title>
    <p>Two Intel platforms with different characteristics are used to evaluate the efficiency and scalability of <italic>ParBiBit</italic>, as well as to compare its performance to the original <italic>BiBit</italic>. <xref ref-type="table" rid="pone.0194361.t001">Table 1</xref> summarizes their characteristics. Both GNU compilers support the C++11 standard, and all the experiments are compiled with the -O3 flag. The evaluation shown in this section is focused on performance in terms of execution time, as the biclustering approach of <italic>ParBiBit</italic> is the same as in <italic>BiBit</italic> and its accuracy was already satisfactorily tested in previous studies [<xref rid="pone.0194361.ref009" ref-type="bibr">9</xref>]. The input datasets were created by randomly generating one and zero values. We vary the number of samples (100 and 200), the number of attributes (12,800, 25,600 and 51,200), and the percentage of one values (10% and 15%). The percentage of one values has significant influence on the speed as different amount of biclusters are found for the same dataset dimensions. The more biclusters are found with not repeated pattern, the more analyses must be made in the computationally intensive bicluster completion phase of the algorithm. The results shown in this section were obtained by searching for biclusters with at least 2 samples and 1% of the attribtes (i.e., 128, 256 and 512 for the datasets with 12,800, 25,600 and 51,200 attributes, respectively).</p>
    <table-wrap id="pone.0194361.t001" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0194361.t001</object-id>
      <label>Table 1</label>
      <caption>
        <title>Characteristics of the test platforms used in the experimental evaluation.</title>
      </caption>
      <alternatives>
        <graphic id="pone.0194361.t001g" xlink:href="pone.0194361.t001"/>
        <table frame="box" rules="all" border="0">
          <colgroup span="1">
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="center" rowspan="1" colspan="1"/>
              <th align="center" rowspan="1" colspan="1">Platform1</th>
              <th align="center" rowspan="1" colspan="1">Platform2</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" rowspan="1" colspan="1">Nodes</td>
              <td align="center" rowspan="1" colspan="1">8</td>
              <td align="center" rowspan="1" colspan="1">8</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">CPU type</td>
              <td align="center" rowspan="1" colspan="1">Intel Sandy Bridge</td>
              <td align="center" rowspan="1" colspan="1">Intel Haswell</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">CPUs per node</td>
              <td align="center" rowspan="1" colspan="1">2</td>
              <td align="center" rowspan="1" colspan="1">2</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Cores per CPU</td>
              <td align="center" rowspan="1" colspan="1">8</td>
              <td align="center" rowspan="1" colspan="1">12</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Clock frequency</td>
              <td align="center" rowspan="1" colspan="1">2.20GHz</td>
              <td align="center" rowspan="1" colspan="1">2.50GHz</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Memory per node</td>
              <td align="center" rowspan="1" colspan="1">64GB</td>
              <td align="center" rowspan="1" colspan="1">128GB</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">Network</td>
              <td align="center" colspan="2" rowspan="1">InfiniBand FDR</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">MPI Compiler</td>
              <td align="center" colspan="2" rowspan="1">Open MPI 1.7.2</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">C++ Compiler</td>
              <td align="center" rowspan="1" colspan="1">GNU 4.9.2</td>
              <td align="center" rowspan="1" colspan="1">GNU 5.3.0</td>
            </tr>
          </tbody>
        </table>
      </alternatives>
    </table-wrap>
    <p>The experimental evaluation started by finding the best configuration of the number of threads and MPI processes for <italic>ParBiBit</italic> on each system. <xref ref-type="fig" rid="pone.0194361.g003">Fig 3</xref> shows the runtime on a single node of each platform (16 and 24 cores on the Sandy Bridge and Haswell systems, respectively) for different configurations. The datasets with 12,800 attributes and 200 samples with both 10% and 15% of one values are used in this case as illustrative examples. An intermediate configuration is the best option on both platforms: two processes and eight threads on the Sandy Bridge system, while four processes and six threads on the second machine. The performance differences are mainly generated during the phase of biclustering initialization as we must find a balance between using more threads to increase parallelization in this step (remind that only one process is used to do so) and reducing the number of threads to limit the overhead due to mutex synchronization. During the biclustering completion, increasing the number of MPI processes leads to more communication operations for the encoded data replication and the initial bicluster distribution. Nevertheless, the increase of communication overhead is not significant compared to the total runtime of this phase. Figs <xref ref-type="fig" rid="pone.0194361.g004">4</xref> and <xref ref-type="fig" rid="pone.0194361.g005">5</xref> show the partial runtime of the initialization and completion steps for the different configurations on each platform to illustrate the previous assertions. As a rule of thumb, using as many processes as CPUs per node and as many threads as cores per CPU is a good starting point for achieving optimal or quasi-optimal performance on most systems. From now on all the experimental results shown in this manuscript were obtained with the best configuration for each platform.</p>
    <fig id="pone.0194361.g003" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0194361.g003</object-id>
      <label>Fig 3</label>
      <caption>
        <title>Runtime of <italic>ParBiBit</italic> on one node of each system with different configurations of processes and threads when searching biclusters on the datasets with 12,800 attributes and 200 samples.</title>
      </caption>
      <graphic xlink:href="pone.0194361.g003"/>
    </fig>
    <fig id="pone.0194361.g004" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0194361.g004</object-id>
      <label>Fig 4</label>
      <caption>
        <title>Partial time of the bicluster initialization and completion steps on one node of the Sandy Bridge system for different configurations of processes and threads.</title>
        <p><italic>ParBiBit</italic> searches for biclusters on the datasets with 12,800 attributes and 200 samples.</p>
      </caption>
      <graphic xlink:href="pone.0194361.g004"/>
    </fig>
    <fig id="pone.0194361.g005" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0194361.g005</object-id>
      <label>Fig 5</label>
      <caption>
        <title>Partial time of the bicluster initialization and completion steps on one node of the Haswell system for different configurations of processes and threads.</title>
        <p><italic>ParBiBit</italic> searches for biclusters on the datasets with 12,800 attributes and 200 samples.</p>
      </caption>
      <graphic xlink:href="pone.0194361.g005"/>
    </fig>
    <p><xref ref-type="table" rid="pone.0194361.t002">Table 2</xref> shows a comparison of the runtime (in minutes) of the original <italic>BiBit</italic> tool and <italic>ParBiBit</italic> using different amount of cores and nodes. The first conclusion that can be obtained is that <italic>ParBiBit</italic> is significantly faster than <italic>BiBit</italic> even when using the same amount of resources (one core). In fact, <italic>ParBiBit</italic> is on average 2.70 and 3.35 times faster on the Sandy Bridge and Haswell platforms, respectively. Furthermore, <italic>ParBiBit</italic> is able to complete the biclustering of the largest dataset (51,200 rows, 200 columns and 15% of one values) while <italic>BiBit</italic> was not able to finish in the maximum computation time allowed to the users on the clusters (four days). Two are the reasons for this performance improvement on one core: 1) a more efficient memory and I/O management of our C++ implementation compared to the Java one of <italic>BiBit</italic>; and 2) the use of 32-bit logical AND operations for the encoding data instead of being based on 16-bit integers.</p>
    <table-wrap id="pone.0194361.t002" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0194361.t002</object-id>
      <label>Table 2</label>
      <caption>
        <title>Runtimes (in minutes) of <italic>ParBiBit</italic> using up to eight nodes with the best configuration of threads and MPI processes per platform.</title>
        <p>The runtime of the sequential <italic>BiBit</italic> tool are also included for comparison purposes. Both tools look for biclusters with at least 2 samples and 1% of the attributes present in the input dataset. − means that <italic>BiBit</italic> was not able to finish the biclustering in the maximum time allowed for computation (four days).</p>
      </caption>
      <alternatives>
        <graphic id="pone.0194361.t002g" xlink:href="pone.0194361.t002"/>
        <table frame="box" rules="all" border="0">
          <colgroup span="1">
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="center" rowspan="2" colspan="1">Platform</th>
              <th align="center" rowspan="2" colspan="1">Att.</th>
              <th align="center" rowspan="2" colspan="1">Sam.</th>
              <th align="center" rowspan="2" colspan="1">% of ones</th>
              <th align="center" rowspan="2" colspan="1">Bicl.</th>
              <th align="center" rowspan="2" colspan="1">
                <italic>BiBit</italic>
              </th>
              <th align="center" colspan="3" rowspan="1">
                <italic>ParBiBit</italic>
              </th>
            </tr>
            <tr>
              <th align="center" rowspan="1" colspan="1">1 core</th>
              <th align="center" rowspan="1" colspan="1">1 node</th>
              <th align="center" rowspan="1" colspan="1">8 nodes</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" rowspan="12" colspan="1">Sandy Br.</td>
              <td align="center" rowspan="4" colspan="1">12800</td>
              <td align="center" rowspan="2" colspan="1">100</td>
              <td align="center" rowspan="1" colspan="1">10</td>
              <td align="center" rowspan="1" colspan="1">2359</td>
              <td align="char" char="." rowspan="1" colspan="1">7.41</td>
              <td align="char" char="." rowspan="1" colspan="1">5.51</td>
              <td align="char" char="." rowspan="1" colspan="1">0.48</td>
              <td align="char" char="." rowspan="1" colspan="1">0.39</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">4950</td>
              <td align="char" char="." rowspan="1" colspan="1">29.48</td>
              <td align="char" char="." rowspan="1" colspan="1">11.50</td>
              <td align="char" char="." rowspan="1" colspan="1">1.37</td>
              <td align="char" char="." rowspan="1" colspan="1">0.79</td>
            </tr>
            <tr>
              <td align="center" rowspan="2" colspan="1">200</td>
              <td align="center" rowspan="1" colspan="1">10</td>
              <td align="center" rowspan="1" colspan="1">9510</td>
              <td align="char" char="." rowspan="1" colspan="1">49.88</td>
              <td align="char" char="." rowspan="1" colspan="1">18.50</td>
              <td align="char" char="." rowspan="1" colspan="1">1.82</td>
              <td align="char" char="." rowspan="1" colspan="1">0.96</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">19900</td>
              <td align="char" char="." rowspan="1" colspan="1">214.27</td>
              <td align="char" char="." rowspan="1" colspan="1">73.64</td>
              <td align="char" char="." rowspan="1" colspan="1">7.49</td>
              <td align="char" char="." rowspan="1" colspan="1">3.31</td>
            </tr>
            <tr>
              <td align="center" rowspan="4" colspan="1">25600</td>
              <td align="center" rowspan="2" colspan="1">100</td>
              <td align="center" rowspan="1" colspan="1">10</td>
              <td align="center" rowspan="1" colspan="1">2313</td>
              <td align="char" char="." rowspan="1" colspan="1">40.52</td>
              <td align="char" char="." rowspan="1" colspan="1">24.25</td>
              <td align="char" char="." rowspan="1" colspan="1">2.02</td>
              <td align="char" char="." rowspan="1" colspan="1">1.44</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">4950</td>
              <td align="char" char="." rowspan="1" colspan="1">159.18</td>
              <td align="char" char="." rowspan="1" colspan="1">59.70</td>
              <td align="char" char="." rowspan="1" colspan="1">5.87</td>
              <td align="char" char="." rowspan="1" colspan="1">2.75</td>
            </tr>
            <tr>
              <td align="center" rowspan="2" colspan="1">200</td>
              <td align="center" rowspan="1" colspan="1">10</td>
              <td align="center" rowspan="1" colspan="1">9357</td>
              <td align="char" char="." rowspan="1" colspan="1">243.65</td>
              <td align="char" char="." rowspan="1" colspan="1">117.99</td>
              <td align="char" char="." rowspan="1" colspan="1">9.23</td>
              <td align="char" char="." rowspan="1" colspan="1">3.96</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">19900</td>
              <td align="char" char="." rowspan="1" colspan="1">1541.89</td>
              <td align="char" char="." rowspan="1" colspan="1">505.57</td>
              <td align="char" char="." rowspan="1" colspan="1">43.88</td>
              <td align="char" char="." rowspan="1" colspan="1">14.19</td>
            </tr>
            <tr>
              <td align="center" rowspan="4" colspan="1">51200</td>
              <td align="center" rowspan="2" colspan="1">100</td>
              <td align="center" rowspan="1" colspan="1">10</td>
              <td align="center" rowspan="1" colspan="1">2283</td>
              <td align="char" char="." rowspan="1" colspan="1">249.19</td>
              <td align="char" char="." rowspan="1" colspan="1">101.23</td>
              <td align="char" char="." rowspan="1" colspan="1">7.62</td>
              <td align="char" char="." rowspan="1" colspan="1">5.67</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">4950</td>
              <td align="char" char="." rowspan="1" colspan="1">1069.27</td>
              <td align="char" char="." rowspan="1" colspan="1">318.97</td>
              <td align="char" char="." rowspan="1" colspan="1">31.79</td>
              <td align="char" char="." rowspan="1" colspan="1">11.36</td>
            </tr>
            <tr>
              <td align="center" rowspan="2" colspan="1">200</td>
              <td align="center" rowspan="1" colspan="1">10</td>
              <td align="center" rowspan="1" colspan="1">9855</td>
              <td align="char" char="." rowspan="1" colspan="1">2354.67</td>
              <td align="char" char="." rowspan="1" colspan="1">474.06</td>
              <td align="char" char="." rowspan="1" colspan="1">41.21</td>
              <td align="char" char="." rowspan="1" colspan="1">14.63</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">20137</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="char" char="." rowspan="1" colspan="1">1540.39</td>
              <td align="char" char="." rowspan="1" colspan="1">118.40</td>
              <td align="char" char="." rowspan="1" colspan="1">31.16</td>
            </tr>
            <tr>
              <td align="center" rowspan="12" colspan="1">Haswell</td>
              <td align="center" rowspan="4" colspan="1">12800</td>
              <td align="center" rowspan="2" colspan="1">100</td>
              <td align="center" rowspan="1" colspan="1">10</td>
              <td align="center" rowspan="1" colspan="1">2359</td>
              <td align="char" char="." rowspan="1" colspan="1">5.58</td>
              <td align="char" char="." rowspan="1" colspan="1">1.62</td>
              <td align="char" char="." rowspan="1" colspan="1">0.45</td>
              <td align="char" char="." rowspan="1" colspan="1">0.34</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">4950</td>
              <td align="char" char="." rowspan="1" colspan="1">28.07</td>
              <td align="char" char="." rowspan="1" colspan="1">10.54</td>
              <td align="char" char="." rowspan="1" colspan="1">0.85</td>
              <td align="char" char="." rowspan="1" colspan="1">0.47</td>
            </tr>
            <tr>
              <td align="center" rowspan="2" colspan="1">200</td>
              <td align="center" rowspan="1" colspan="1">10</td>
              <td align="center" rowspan="1" colspan="1">9510</td>
              <td align="char" char="." rowspan="1" colspan="1">51.59</td>
              <td align="char" char="." rowspan="1" colspan="1">12.50</td>
              <td align="char" char="." rowspan="1" colspan="1">1.00</td>
              <td align="char" char="." rowspan="1" colspan="1">0.54</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">19900</td>
              <td align="char" char="." rowspan="1" colspan="1">200.97</td>
              <td align="char" char="." rowspan="1" colspan="1">58.06</td>
              <td align="char" char="." rowspan="1" colspan="1">4.12</td>
              <td align="char" char="." rowspan="1" colspan="1">1.91</td>
            </tr>
            <tr>
              <td align="center" rowspan="4" colspan="1">25600</td>
              <td align="center" rowspan="2" colspan="1">100</td>
              <td align="center" rowspan="1" colspan="1">10</td>
              <td align="center" rowspan="1" colspan="1">2313</td>
              <td align="char" char="." rowspan="1" colspan="1">28.31</td>
              <td align="char" char="." rowspan="1" colspan="1">7.97</td>
              <td align="char" char="." rowspan="1" colspan="1">1.58</td>
              <td align="char" char="." rowspan="1" colspan="1">1.29</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">4950</td>
              <td align="char" char="." rowspan="1" colspan="1">150.80</td>
              <td align="char" char="." rowspan="1" colspan="1">56.25</td>
              <td align="char" char="." rowspan="1" colspan="1">3.90</td>
              <td align="char" char="." rowspan="1" colspan="1">1.88</td>
            </tr>
            <tr>
              <td align="center" rowspan="2" colspan="1">200</td>
              <td align="center" rowspan="1" colspan="1">10</td>
              <td align="center" rowspan="1" colspan="1">9357</td>
              <td align="char" char="." rowspan="1" colspan="1">313.16</td>
              <td align="char" char="." rowspan="1" colspan="1">100.11</td>
              <td align="char" char="." rowspan="1" colspan="1">5.19</td>
              <td align="char" char="." rowspan="1" colspan="1">2.16</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">19900</td>
              <td align="char" char="." rowspan="1" colspan="1">1564.62</td>
              <td align="char" char="." rowspan="1" colspan="1">531.15</td>
              <td align="char" char="." rowspan="1" colspan="1">25.04</td>
              <td align="char" char="." rowspan="1" colspan="1">8.73</td>
            </tr>
            <tr>
              <td align="center" rowspan="4" colspan="1">51200</td>
              <td align="center" rowspan="2" colspan="1">100</td>
              <td align="center" rowspan="1" colspan="1">10</td>
              <td align="center" rowspan="1" colspan="1">2283</td>
              <td align="char" char="." rowspan="1" colspan="1">103.18</td>
              <td align="char" char="." rowspan="1" colspan="1">36.16</td>
              <td align="char" char="." rowspan="1" colspan="1">6.22</td>
              <td align="char" char="." rowspan="1" colspan="1">5.02</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">4950</td>
              <td align="char" char="." rowspan="1" colspan="1">1123.99</td>
              <td align="char" char="." rowspan="1" colspan="1">311.25</td>
              <td align="char" char="." rowspan="1" colspan="1">17.38</td>
              <td align="char" char="." rowspan="1" colspan="1">7.74</td>
            </tr>
            <tr>
              <td align="center" rowspan="2" colspan="1">200</td>
              <td align="center" rowspan="1" colspan="1">10</td>
              <td align="center" rowspan="1" colspan="1">9855</td>
              <td align="char" char="." rowspan="1" colspan="1">1869.82</td>
              <td align="char" char="." rowspan="1" colspan="1">424.97</td>
              <td align="char" char="." rowspan="1" colspan="1">27.67</td>
              <td align="char" char="." rowspan="1" colspan="1">9.21</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">15</td>
              <td align="center" rowspan="1" colspan="1">20137</td>
              <td align="center" rowspan="1" colspan="1">-</td>
              <td align="char" char="." rowspan="1" colspan="1">1660.45</td>
              <td align="char" char="." rowspan="1" colspan="1">94.53</td>
              <td align="char" char="." rowspan="1" colspan="1">29.71</td>
            </tr>
          </tbody>
        </table>
      </alternatives>
    </table-wrap>
    <p>Furthermore, the use of our two-level parallelization on a multicore cluster significantly reduces runtimes. For instance, <italic>BiBit</italic> needs more than four days to process the dataset with 51,200 attributes, 200 samples and 15% of one values, while <italic>ParBiBit</italic> reduces the runtime to only around 94 and 30 minutes on one and eight nodes of the Haswell system, respectively. Figs <xref ref-type="fig" rid="pone.0194361.g006">6</xref> and <xref ref-type="fig" rid="pone.0194361.g007">7</xref> provide an insight of the benefit in terms of performance that can be obtained by our tool compared to the state of the art. As expected, the acceleration is higher on the Haswell platform as it provides more resources (24 instead of 16 cores per node). In an attempt to show the adequacy of <italic>ParBiBit</italic> to different scenarios, experiments with 40% of one values and selecting 20 samples per bicluster have also been executed. For simplicity, acceleration is represented in <xref ref-type="fig" rid="pone.0194361.g008">Fig 8</xref>. It is worth noting that this paper does not include a comparison to other parallel tools because, as mentioned in the related work section, up to our knowledge there is no publicly available tool to accelerate the biclustering procedure of binary data on parallel architectures.</p>
    <fig id="pone.0194361.g006" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0194361.g006</object-id>
      <label>Fig 6</label>
      <caption>
        <title>Speedups of <italic>ParBiBit</italic> over <italic>BiBit</italic> for varying number of nodes on the Sandy Bridge platform.</title>
        <p>Each line represents a different number of attributes (the number of samples is fixed to 200) and each graph is associated to a different percentage of one values.</p>
      </caption>
      <graphic xlink:href="pone.0194361.g006"/>
    </fig>
    <fig id="pone.0194361.g007" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0194361.g007</object-id>
      <label>Fig 7</label>
      <caption>
        <title>Speedups of <italic>ParBiBit</italic> over <italic>BiBit</italic> for varying number of nodes on the Haswell platform.</title>
        <p>Each line represents a different number of attributes (the number of samples is fixed to 200) and each graph is associated to a different percentage of one values.</p>
      </caption>
      <graphic xlink:href="pone.0194361.g007"/>
    </fig>
    <fig id="pone.0194361.g008" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0194361.g008</object-id>
      <label>Fig 8</label>
      <caption>
        <title>Speedups of <italic>ParBiBit</italic> over <italic>BiBit</italic> for varying number of nodes.</title>
        <p>Each line represents a different number of attributes (the number of samples is fixed to 100, while the percentage of one values is 40%).</p>
      </caption>
      <graphic xlink:href="pone.0194361.g008"/>
    </fig>
    <p>It was not possible to include in these figures the speedups over <italic>BiBit</italic> for the most computationally expensive dataset. As mentioned before, the original Java tool did not finish in four days (the maximum allowed runtime of the systems). Instead, <xref ref-type="table" rid="pone.0194361.t003">Table 3</xref> shows the scalability of our tool for this dataset using as baseline the runtime of <italic>ParBiBit</italic> on only one core. These results (and the ones in Figs <xref ref-type="fig" rid="pone.0194361.g006">6</xref> and <xref ref-type="fig" rid="pone.0194361.g007">7</xref>) prove that our tool scales in all scenarios at least up to eight nodes. In our opinion, the parallel approach included in <italic>ParBiBit</italic> provides good scalability. Its main strength is that we focused on obtaining very high performance during the most computationally demanding phase with the hybrid MPI/multithreaded parallelization: more than 90% of parallel efficiency during bicluster completion even using the eight nodes. As drawbacks we should mention that some parts cannot be parallelized (I/O routines, data encoding), the bicluster initialization is only parallelized with threads, and some communications (with their associated overhead) are compulsory.</p>
    <table-wrap id="pone.0194361.t003" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.1371/journal.pone.0194361.t003</object-id>
      <label>Table 3</label>
      <caption>
        <title>Speedups of <italic>ParBiBit</italic> for varying number of nodes using as baseline the runtime on a single core.</title>
        <p>The input dataset contains 51,200 attributes, 200 samples and 15% of one values.</p>
      </caption>
      <alternatives>
        <graphic id="pone.0194361.t003g" xlink:href="pone.0194361.t003"/>
        <table frame="box" rules="all" border="0">
          <colgroup span="1">
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
            <col align="left" valign="middle" span="1"/>
          </colgroup>
          <thead>
            <tr>
              <th align="center" rowspan="1" colspan="1">Num. Nodes</th>
              <th align="center" rowspan="1" colspan="1">Sandy Bridge</th>
              <th align="center" rowspan="1" colspan="1">Haswell</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" rowspan="1" colspan="1">1</td>
              <td align="char" char="." rowspan="1" colspan="1">13.01</td>
              <td align="char" char="." rowspan="1" colspan="1">17.57</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">2</td>
              <td align="char" char="." rowspan="1" colspan="1">21.66</td>
              <td align="char" char="." rowspan="1" colspan="1">26.40</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">4</td>
              <td align="char" char="." rowspan="1" colspan="1">35.35</td>
              <td align="char" char="." rowspan="1" colspan="1">46.12</td>
            </tr>
            <tr>
              <td align="center" rowspan="1" colspan="1">8</td>
              <td align="char" char="." rowspan="1" colspan="1">49.44</td>
              <td align="char" char="." rowspan="1" colspan="1">55.88</td>
            </tr>
          </tbody>
        </table>
      </alternatives>
    </table-wrap>
    <p>Finally, the acceleration was also tested in a scenario with non-binary real data. Authors in [<xref rid="pone.0194361.ref012" ref-type="bibr">12</xref>] explain a method to work with data that is not binary: 1) standardize the data, generating a real value matrix with a mean of zero and a variance of one; 2) data discretization to establish 12 different levels of gene expression values; and 3) execution of <italic>BiBit</italic> or <italic>ParBiBit</italic> over this dataset by applying the optional binarization step (point 2 in “<xref ref-type="sec" rid="sec007">Methods</xref>”). In order to provide a fair comparison with <italic>BiBit</italic> the same real dataset used in its manuscript [<xref rid="pone.0194361.ref012" ref-type="bibr">12</xref>] for this last performance evaluation (i.e., a central nervous system embryonic tumor gene expression dataset obtained from DNA microarray technology [<xref rid="pone.0194361.ref036" ref-type="bibr">36</xref>] with 40 tumor samples and 7,129 genes). The runtime of <italic>BiBit</italic> to complete the biclustering of the 11 binary matrices that are generated by this real dataset on both platforms is higher than seven hours. Each of the 11 matrices has a different percentage of one values. ParBiBit is also beneficial for this real dataset as it reduces the runtimes to less than two minutes.</p>
  </sec>
  <sec sec-type="conclusions" id="sec011">
    <title>Conclusions</title>
    <p>Current biclustering data mining algorithms allow to extract useful biclusters from large binary datasets. Even though these algorithms can provide highly accurate results, the procedure of extracting those biclusters is a very time-consuming task, which can represent a significant performance bottleneck in some fields such as gene expression data analyses. To overcome this issue, we propose to take advantage of parallel architectures as the modern distributed-memory systems to alleviate this runtime bottleneck, thus being able to process very large binary datasets within reasonable times.</p>
    <p>In this paper we introduce <italic>ParBiBit</italic>, a parallel biclustering tool that significantly speeds up the procedure of discovering interesting biclusters from binary data. Our tool benefits from a two-level parallelism strategy by combining message-passing with multithreading in order to fully exploit the computing resources of multicore CPU clusters. This hybrid approach has been evaluated on two representative systems, showing experimental evidence of significant performance improvements when compared with the original <italic>BiBit</italic> tool. In fact, <italic>ParBiBit</italic> reduces the execution time of <italic>BiBit</italic> by up to 203x when processing a dataset with 51,200 attributes on a 8-node Intel Haswell-based cluster. The experimental results also indicate that our tool provides good scalability. The source code of the parallel tool described in this paper is distributed as free software, being publicly available under an open-source license at <ext-link ext-link-type="uri" xlink:href="https://sourceforge.net/projects/parbibit/">https://sourceforge.net/projects/parbibit/</ext-link>.</p>
    <p>As future work, we aim to adapting <italic>ParBiBit</italic> to exploit other parallel architectures such as GPUs and/or Intel Xeon Phi coprocessors, as well as developing a counterpart to run non-binary biclustering on multicore clusters.</p>
  </sec>
</body>
<back>
  <ack>
    <p>This work was supported by the Ministry of Economy, Industry and Competitiveness of Spain and FEDER funds of the European Union [grant TIN2016-75845-P (AEI/FEDER/UE)], as well as by Xunta de Galicia (Centro Singular de Investigacion de Galicia accreditation 2016-2019, ref. EDG431G/01).</p>
  </ack>
  <ref-list>
    <title>References</title>
    <ref id="pone.0194361.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Busygin</surname><given-names>S</given-names></name>, <name><surname>Prokopyev</surname><given-names>O</given-names></name>, <name><surname>Pardalosa</surname><given-names>PM</given-names></name>. <article-title>Biclustering in Data Mining</article-title>. <source>Computers and Operations Research</source>. <year>2008</year>;<volume>35</volume>(<issue>9</issue>):<fpage>2964</fpage>–<lpage>2987</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cor.2007.01.005">10.1016/j.cor.2007.01.005</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref002">
      <label>2</label>
      <mixed-citation publication-type="other">Bozdag D, Kumar AS, Catalyurek UV. Comparative Analysis of Biclustering Algorithms. In: 1st ACM International Conference on Bioinformatics and Computational Biology (BCB 2010). Niagara Falls, NY, USA; 2010. p. 265–274.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Eren</surname><given-names>K</given-names></name>, <name><surname>Deveci</surname><given-names>M</given-names></name>, <name><surname>Küçüktunç</surname><given-names>O</given-names></name>, <name><surname>Çatalyürek</surname><given-names>ÜV</given-names></name>. <article-title>A Comparative Analysis of Biclustering Algorithms for Gene Expression Data</article-title>. <source>Briefings in Bioinformatics</source>. <year>2013</year>;<volume>14</volume>(<issue>3</issue>):<fpage>279</fpage>–<lpage>292</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bib/bbs032">10.1093/bib/bbs032</ext-link></comment><?supplied-pmid 22772837?><pub-id pub-id-type="pmid">22772837</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Pontes</surname><given-names>B</given-names></name>, <name><surname>Giráldez</surname><given-names>R</given-names></name>, <name><surname>Aguilar-Ruiz</surname><given-names>JS</given-names></name>. <article-title>Biclustering on Expression Data: a Review</article-title>. <source>Journal of Biomedical Informatics</source>. <year>2015</year>;<volume>57</volume>:<fpage>163</fpage>–<lpage>180</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jbi.2015.06.028">10.1016/j.jbi.2015.06.028</ext-link></comment><?supplied-pmid 26160444?><pub-id pub-id-type="pmid">26160444</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref005">
      <label>5</label>
      <mixed-citation publication-type="other">Liu J, Wang W. OP-Cluster: Clustering by Tendency in High Dimensional Space. In: 3rd International Conference on Data Mining (ICDM 2003). Melbourne, FL, USA; 2003. p. 187–194.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref006">
      <label>6</label>
      <mixed-citation publication-type="other">Mimaroglu S, Uehara K. Bit Sequences and Biclustering of Text Documents. In: 7th International Conference on Data Mining (ICDM 2007). Omaha, NE, USA; 2007. p. 51–56.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref007">
      <label>7</label>
      <mixed-citation publication-type="other">Dhillon IS, Mallela S, Modha DS. Information-Theoretic Co-Clustering. In: 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2003). Washington DC, USA; 2003. p. 89–98.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref008">
      <label>8</label>
      <mixed-citation publication-type="other">Wang H, Wang W, Yang J, Yu PS. Clustering by Pattern Similarity in Large Data Sets. In: 2002 ACM SIGMOD International Conference on Management of Data (SIGMOD 2002). Madison, WI, USA; 2002. p. 304–405.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Padilha</surname><given-names>VA</given-names></name>, <name><surname>Campello</surname><given-names>R</given-names></name>. <article-title>A Systematic Comparative Evaluation of Biclustering Techniques</article-title>. <source>BMC Bioinformatics</source>. <year>2017</year>;<volume>18</volume>(<issue>55</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s12859-017-1487-1">10.1186/s12859-017-1487-1</ext-link></comment><?supplied-pmid 28114903?><pub-id pub-id-type="pmid">28114903</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref010">
      <label>10</label>
      <mixed-citation publication-type="other">The MPI Forum. MPI: A Message Passing Interface; 1993.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref011">
      <label>11</label>
      <mixed-citation publication-type="book"><name><surname>Yablonsky</surname><given-names>B</given-names></name>. <source>C++11 Standard Library: Usage and Implementation</source>. <publisher-name>CreateSpace Independent Publishing Platform</publisher-name>; <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Rodríguez-Baena</surname><given-names>DS</given-names></name>, <name><surname>Pérez-Pulido</surname><given-names>AJ</given-names></name>, <name><surname>Aguilar-Ruiz</surname><given-names>JS</given-names></name>. <article-title>A Biclustering Algorithm for Extracting Bit-Patterns from Binary Datasets</article-title>. <source>Bioinformatics</source>. <year>2011</year>;<volume>27</volume>(<issue>19</issue>):<fpage>2738</fpage>–<lpage>2745</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btr464">10.1093/bioinformatics/btr464</ext-link></comment><?supplied-pmid 21824973?><pub-id pub-id-type="pmid">21824973</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Prelic</surname><given-names>A</given-names></name>, <name><surname>Bleuler</surname><given-names>S</given-names></name>, <name><surname>Zimmermann</surname><given-names>P</given-names></name>, <name><surname>Wille</surname><given-names>A</given-names></name>, <name><surname>Bühlmann</surname><given-names>P</given-names></name>, <name><surname>Gruissem</surname><given-names>W</given-names></name>, <etal>et al</etal><article-title>A Systematic Comparison and Evaluation of Biclustering Methods for Gene Expression Data</article-title>. <source>Bioinformatics</source>. <year>2006</year>;<volume>22</volume>(<issue>9</issue>):<fpage>1122</fpage>–<lpage>1129</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btl060">10.1093/bioinformatics/btl060</ext-link></comment><?supplied-pmid 16500941?><pub-id pub-id-type="pmid">16500941</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>HC</given-names></name>, <name><surname>Zou</surname><given-names>W</given-names></name>, <name><surname>Tien</surname><given-names>YJ</given-names></name>, <name><surname>Chen</surname><given-names>JJ</given-names></name>. <article-title>Identification of Bicluster Regions in a Binary Matrix and Its Applications</article-title>. <source>PLOS One</source>. <year>2013</year>;<volume>8</volume>(<issue>8</issue>).</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Lee</surname><given-names>S</given-names></name>, <name><surname>Huang</surname><given-names>JZ</given-names></name>. <article-title>A Biclustering Algorithm for Binary Matrices Based on Penalized Bernoulli Likelihood</article-title>. <source>Statistics and Computing</source>. <year>2014</year>;<volume>24</volume>(<issue>3</issue>):<fpage>429</fpage>–<lpage>441</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s11222-013-9379-3">10.1007/s11222-013-9379-3</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Saber</surname><given-names>HB</given-names></name>, <name><surname>Elloumi</surname><given-names>M</given-names></name>. <article-title>Efficiently Mining Gene Expression Data via Novel Binary Biclustering Algorithms</article-title>. <source>Journal of Proteomics and Bioinformatics</source>. <year>2015</year>;<volume>8</volume>(<issue>4</issue>).</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Wei</surname><given-names>L</given-names></name>, <name><surname>Ling</surname><given-names>C</given-names></name>. <article-title>A Parallel Algorithm for Gene Expressing Data Biclustering</article-title>. <source>Journal of Computers</source>. <year>2008</year>;<volume>3</volume>(<issue>10</issue>):<fpage>71</fpage>–<lpage>77</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref018">
      <label>18</label>
      <mixed-citation publication-type="other">Bhatnagar R, Kumar L. High Performance Parallel/Distributed Biclustering Using Barycenter Heuristic. In: 2009 SIAM International Conference on Data Mining (SDM 2009). Sparks, NV, USA; 2009. p. 1050–1061.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref019">
      <label>19</label>
      <mixed-citation publication-type="other">Sarazin T, Lebbah M, Azzag H. Biclustering Using Spark-MapReduce. In: 2nd IEEE International Conference on Big Data (Big Data 2014). Washington DC, USA; 2014. p. 58–60.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref020">
      <label>20</label>
      <mixed-citation publication-type="other">Lin Q, Xue Y, Chen WS, Ye SQ, Li WL, Liu JJ. Parallel Large Average Submatrices Biclustering Based on MapReduce. In: 11th International Conference on Computational Intelligence and Security (CIS 2015). Shenzhen, China; 2015.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref021">
      <label>21</label>
      <mixed-citation publication-type="other">Nisar A, Ahmad W, Liao WK, Choudhary A. An Efficient Map-Reduce Algorithm for Computing Formal Concepts from Binary Data. In: 3rd IEEE International Conference on Big Data (Big Data 2015). Santa Clara, CA, USA; 2015. p. 1519–1528.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>B</given-names></name>, <name><surname>Xin</surname><given-names>Y</given-names></name>, <name><surname>Cheung</surname><given-names>RC</given-names></name>, <name><surname>Hong</surname><given-names>Yan</given-names></name>. <article-title>GPU-Based Biclustering for Microarray Data Analysis in Neurocomputing</article-title>. <source>Neurocomputing</source>. <year>2014</year>;<volume>134</volume>:<fpage>239</fpage>–<lpage>246</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neucom.2013.06.049">10.1016/j.neucom.2013.06.049</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Orzechowski</surname><given-names>P</given-names></name>, <name><surname>Boryczko</surname><given-names>K</given-names></name>. <article-title>Rough Assessment of GPU Capabilities for Parallel PCC-Based Biclustering Method Applied to Microarray Data Sets</article-title>. <source>Bio-Algorithms and Med-Systems</source>. <year>2015</year>;<volume>11</volume>(<issue>4</issue>):<fpage>243</fpage>–<lpage>248</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1515/bams-2015-0033">10.1515/bams-2015-0033</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>Bhattacharya</surname><given-names>A</given-names></name>, <name><surname>Cui</surname><given-names>Y</given-names></name>. <article-title>A GPU-Accelerated Algorithm for Biclustering Analysis and Detection of Condition-Dependent Coexpression Network Modules</article-title>. <source>Scientific Reports</source>. <year>2017</year>;<volume>7</volume><comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41598-017-04070-4">10.1038/s41598-017-04070-4</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>B</given-names></name>, <name><surname>Yu</surname><given-names>C</given-names></name>, <name><surname>Wang</surname><given-names>DZ</given-names></name>, <name><surname>Cheung</surname><given-names>RC</given-names></name>, <name><surname>Yan</surname><given-names>H</given-names></name>. <article-title>Design Exploration of Geometric Biclustering for Microarray Data Analysis in Data Mining</article-title>. <source>IEEE Transactions on Parallel and Distributed Computing</source>. <year>2013</year>;<volume>25</volume>(<issue>10</issue>):<fpage>2540</fpage>–<lpage>2550</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TPDS.2013.204">10.1109/TPDS.2013.204</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref026">
      <label>26</label>
      <mixed-citation publication-type="journal"><name><surname>Gómez-Pulido</surname><given-names>JA</given-names></name>, <name><surname>Cerrada-Barrios</surname><given-names>JL</given-names></name>, <name><surname>Trinidad-Amado</surname><given-names>S</given-names></name>, <name><surname>Lanza-Gutiérrez</surname><given-names>JM</given-names></name>, <name><surname>Fernández-Díaz</surname><given-names>RA</given-names></name>, <name><surname>Crawford</surname><given-names>B</given-names></name>, <etal>et al</etal><article-title>Fine-Grained Parallelization of Fitness Functions in Bioinformatics Optimization Problems: Gene Selection for Cancer Classification and Biclustering of Gene Expression Data</article-title>. <source>BMC Bioinformatics</source>. <year>2013</year>;<volume>17</volume>(<issue>1</issue>):<fpage>2540</fpage>–<lpage>2550</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref027">
      <label>27</label>
      <mixed-citation publication-type="book"><name><surname>Nichols</surname><given-names>B</given-names></name>, <name><surname>Buttlar</surname><given-names>D</given-names></name>, <name><surname>Farrell</surname><given-names>JP</given-names></name>. <source>Pthreads Programming</source>. <publisher-loc>Sebastopol, CA, USA</publisher-loc>: <publisher-name>O’Reilly &amp; Associates, Inc</publisher-name>; <year>1996</year>.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref028">
      <label>28</label>
      <mixed-citation publication-type="book"><name><surname>Reinders</surname><given-names>J</given-names></name>. <source>Intel Threading Building Blocks</source>. <publisher-loc>Sebastopol, CA, USA</publisher-loc>: <publisher-name>O’Reilly &amp; Associates, Inc.</publisher-name>; <year>2007</year>.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref029">
      <label>29</label>
      <mixed-citation publication-type="other">Kumar S, Blocksome M. Scalable MPI-3.0 RMA on the Blue Gene/Q Supercomputer. In: 21st European MPI Users’ Group Meeting (EuroMPI’14). Kyoto, Japan; 2014.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref030">
      <label>30</label>
      <mixed-citation publication-type="journal"><name><surname>Hoefler</surname><given-names>T</given-names></name>, <name><surname>Dinan</surname><given-names>J</given-names></name>, <name><surname>Thakur</surname><given-names>R</given-names></name>, <name><surname>Barrett</surname><given-names>B</given-names></name>, <name><surname>Balaji</surname><given-names>P</given-names></name>, <name><surname>Gropp</surname><given-names>W</given-names></name>, <etal>et al</etal><article-title>Remote Memory Access Programming in MPI-3</article-title>. <source>ACM Transactions on Parallel Computing</source>. <year>2015</year>;<volume>2</volume>(<issue>2</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1145/2780584">10.1145/2780584</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref031">
      <label>31</label>
      <mixed-citation publication-type="other">Mamidala AR, Kumar R, De D, Panda DK. MPI Collectives on Modern Multicore Clusters: Performance Optimizations and Communication Characteristics. In: 8th International Symposium on Cluster, Cloud and Grid Computing (CCGRID’08). Lyon, France; 2008. p. 130–137.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Tu</surname><given-names>B</given-names></name>, <name><surname>Fan</surname><given-names>J</given-names></name>, <name><surname>Zhan</surname><given-names>J</given-names></name>, <name><surname>Zhao</surname><given-names>X</given-names></name>. <article-title>Performance Analysis and Optimization of MPI Collective Operations on Multi-Core Clusters</article-title>. <source>The Journal of Supercomputing</source>. <year>2012</year>;<volume>60</volume>(<issue>1</issue>):<fpage>141</fpage>–<lpage>162</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s11227-009-0296-3">10.1007/s11227-009-0296-3</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>González-Domínguez</surname><given-names>J</given-names></name>, <name><surname>Liu</surname><given-names>Y</given-names></name>, <name><surname>Touriño</surname><given-names>J</given-names></name>, <name><surname>Schmidt</surname><given-names>B</given-names></name>. <article-title>MSAProbs-MPI: Parallel Multiple Sequence Aligner for Distributed-Memory Systems</article-title>. <source>Bioinformatics</source>. <year>2016</year>;<volume>32</volume>(<issue>24</issue>):<fpage>3826</fpage>–<lpage>3828</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btw558">10.1093/bioinformatics/btw558</ext-link></comment><?supplied-pmid 27638400?><pub-id pub-id-type="pmid">27638400</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Chorley</surname><given-names>MJ</given-names></name>, <name><surname>Walker</surname><given-names>DW</given-names></name>. <article-title>Performance Analysis of a Hybrid MPI/OpenMP Application on Multi-Core Clusters</article-title>. <source>Journal of Computational Science</source>. <year>2010</year>;<volume>1</volume>(<issue>3</issue>):<fpage>168</fpage>–<lpage>174</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jocs.2010.05.001">10.1016/j.jocs.2010.05.001</ext-link></comment></mixed-citation>
    </ref>
    <ref id="pone.0194361.ref035">
      <label>35</label>
      <mixed-citation publication-type="other">Coulaud O, Fortin P, Roman J. Hybrid MPI-Thread Parallelization of the Fast Multipole Method. In: 6th International Symposium on Parallel and Distributed Computing (ISPDC’07). Hagenberg, Austria; 2007.</mixed-citation>
    </ref>
    <ref id="pone.0194361.ref036">
      <label>36</label>
      <mixed-citation publication-type="journal"><name><surname>Pomeroy</surname><given-names>SL</given-names></name>, <name><surname>Tamayo</surname><given-names>P</given-names></name>, <name><surname>Gaasenbeek</surname><given-names>M</given-names></name>, <name><surname>Sturla</surname><given-names>LM</given-names></name>, <name><surname>Angelo</surname><given-names>M</given-names></name>, <name><surname>McLaughlin</surname><given-names>ME</given-names></name>, <etal>et al</etal><article-title>Prediction of Central Nervous System Embryonal Tumour Outcome Based on Gene Expression</article-title>. <source>Nature</source>. <year>2002</year>;<volume>415</volume>(<issue>6870</issue>):<fpage>436</fpage>–<lpage>442</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/415436a">10.1038/415436a</ext-link></comment><?supplied-pmid 11807556?><pub-id pub-id-type="pmid">11807556</pub-id></mixed-citation>
    </ref>
  </ref-list>
</back>
