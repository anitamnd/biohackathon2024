<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 1.1?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PeerJ Comput Sci</journal-id>
    <journal-id journal-id-type="iso-abbrev">PeerJ Comput Sci</journal-id>
    <journal-id journal-id-type="publisher-id">peerj-cs</journal-id>
    <journal-id journal-id-type="pmc">peerj-cs</journal-id>
    <journal-title-group>
      <journal-title>PeerJ Computer Science</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2376-5992</issn>
    <publisher>
      <publisher-name>PeerJ Inc.</publisher-name>
      <publisher-loc>San Diego, USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7924420</article-id>
    <article-id pub-id-type="publisher-id">cs-177</article-id>
    <article-id pub-id-type="doi">10.7717/peerj-cs.177</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Bioinformatics</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Computational Biology</subject>
      </subj-group>
      <subj-group subj-group-type="heading">
        <subject>Data Mining and Machine Learning</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>SNARE-CNN: a 2D convolutional neural network architecture to identify SNARE proteins from high-throughput sequencing data</article-title>
    </title-group>
    <contrib-group>
      <contrib id="author-1" contrib-type="author" corresp="yes">
        <name>
          <surname>Le</surname>
          <given-names>Nguyen Quoc Khanh</given-names>
        </name>
        <email>khanhle@ntu.edu.sg</email>
        <email>khanhlee87@gmail.com</email>
        <xref ref-type="aff" rid="aff-1">1</xref>
      </contrib>
      <contrib id="author-2" contrib-type="author">
        <name>
          <surname>Nguyen</surname>
          <given-names>Van-Nui</given-names>
        </name>
        <xref ref-type="aff" rid="aff-2">2</xref>
      </contrib>
      <aff id="aff-1"><label>1</label><institution>School of Humanities, Nanyang Technological University</institution>, <country>Singapore</country></aff>
      <aff id="aff-2"><label>2</label><institution>University of Information and Communication Technology, Thai Nguyen University</institution>, <city>Thai Nguyen</city>, <country>Vietnam</country></aff>
    </contrib-group>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Gomez</surname>
          <given-names>Shawn</given-names>
        </name>
      </contrib>
    </contrib-group>
    <pub-date pub-type="epub" date-type="pub" iso-8601-date="2019-02-25">
      <day>25</day>
      <month>2</month>
      <year iso-8601-date="2019">2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>5</volume>
    <elocation-id>e177</elocation-id>
    <history>
      <date date-type="received" iso-8601-date="2018-11-20">
        <day>20</day>
        <month>11</month>
        <year iso-8601-date="2018">2018</year>
      </date>
      <date date-type="accepted" iso-8601-date="2019-02-06">
        <day>6</day>
        <month>2</month>
        <year iso-8601-date="2019">2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>©2019 Le and Nguyen</copyright-statement>
      <copyright-year>2019</copyright-year>
      <copyright-holder>Le and Nguyen</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, reproduction and adaptation in any medium and for any purpose provided that it is properly attributed. For attribution, the original author(s), title, publication source (PeerJ Computer Science) and either DOI or URL of the article must be cited.</license-p>
      </license>
    </permissions>
    <self-uri xlink:href="https://peerj.com/articles/cs-177"/>
    <abstract>
      <p>Deep learning has been increasingly and widely used to solve numerous problems in various fields with state-of-the-art performance. It can also be applied in bioinformatics to reduce the requirement for feature extraction and reach high performance. This study attempts to use deep learning to predict SNARE proteins, which is one of the most vital molecular functions in life science. A functional loss of SNARE proteins has been implicated in a variety of human diseases (e.g., neurodegenerative, mental illness, cancer, and so on). Therefore, creating a precise model to identify their functions is a crucial problem for understanding these diseases, and designing the drug targets. Our SNARE-CNN model which uses two-dimensional convolutional neural networks and position-specific scoring matrix profiles could identify SNARE proteins with achieved sensitivity of 76.6%, specificity of 93.5%, accuracy of 89.7%, and MCC of 0.7 in cross-validation dataset. We also evaluate the performance of our model via an independent dataset and the result shows that we are able to solve the overfitting problem. Compared with other state-of-the-art methods, this approach achieved significant improvement in all of the metrics. Throughout the proposed study, we provide an effective model for identifying SNARE proteins and a basis for further research that can apply deep learning in bioinformatics, especially in protein function prediction. SNARE-CNN are freely available at <ext-link ext-link-type="uri" xlink:href="https://github.com/khanhlee/snare-cnn">https://github.com/khanhlee/snare-cnn</ext-link>.</p>
    </abstract>
    <kwd-group kwd-group-type="author">
      <kwd>Position specific scoring matrix</kwd>
      <kwd>SNARE protein function</kwd>
      <kwd>Deep learning</kwd>
      <kwd>Membrane fusion</kwd>
      <kwd>Vesicular transport protein</kwd>
      <kwd>Cancer</kwd>
      <kwd>Human disease</kwd>
      <kwd>Biological domain</kwd>
      <kwd>Overfitting</kwd>
      <kwd>Protein family classification</kwd>
    </kwd-group>
    <funding-group>
      <funding-statement>The authors received no funding for this work.</funding-statement>
    </funding-group>
  </article-meta>
</front>
<body>
  <sec sec-type="intro">
    <title>Introduction</title>
    <p>Deep learning is an advanced machine learning and artificial intelligent technique to learn the representative data with multiple layers of neural networks (<xref rid="ref-39" ref-type="bibr">LeCun, Bengio &amp; Hinton, 2015</xref>). Numerous difficult problems have been solved with deep learning, e.g., speech recognition, visual object recognition, object detection. The advantages of deep learning are: (1) significantly outperforms other solutions in multiple domains, (2) reduces the requirement for feature extraction and time consumption with the use of graphic processing units (GPUs), and (3) easily adapts to a new problem. Deep neural network models often achieve better performance compared to shallow networks, especially in most of problems with big data. Therefore, deep learning becomes popular and attracts numerous huge companies establishing their directions in this field in recent years. Nowadays, much progress towards deep learning has been made using different deep neural network architectures. A number of studies showed that using deep learning can enhance results in various fields, e.g., prediction of cervical cancer diagnosis (<xref rid="ref-22" ref-type="bibr">Fernandes et al., 2018</xref>), piRNA (<xref rid="ref-54" ref-type="bibr">Wang, Hoeksema &amp; Liang, 2018</xref>), and isolated guitar transcription (<xref rid="ref-3" ref-type="bibr">Burlet &amp; Hindle, 2017</xref>). Hence, deep learning is also a fascinating trend in bioinformatics and computational biology research. This study attempts to present a framework to apply deep learning in bioinformatics by using two-dimensional convolutional neural network (2D CNN), which is one popular type of deep neural networks. We anticipate our method will lead to a significant improvement when compared to traditional machine learning techniques in the bioinformatics field.</p>
    <p>In earlier years, researchers used shallow neural networks for solving a number of problems in bioinformatics and computational biology. For example, Ou constructed QuickRBF package (<xref rid="ref-43" ref-type="bibr">Oyang et al., 2005</xref>) for training radial basis function (RBF) networks and applied them on several bioinformatics problems including classifying electron transport proteins (<xref rid="ref-35" ref-type="bibr">Le, Nguyen &amp; Ou, 2017</xref>), transporters (<xref rid="ref-38" ref-type="bibr">Le, Sandag &amp; Ou, 2018</xref>), and binding sites (<xref rid="ref-36" ref-type="bibr">Le &amp; Ou, 2016a</xref>; <xref rid="ref-37" ref-type="bibr">Le &amp; Ou, 2016b</xref>). <xref rid="ref-4" ref-type="bibr">Chang &amp; Lin (2011)</xref> introduced LibSVM to help biologists implement bioinformatics models by using support vector machines. Recently, as deep learning has been successfully applied in various fields, researchers started to use it in bioinformatics problems, e.g., prediction of piRNA (<xref rid="ref-54" ref-type="bibr">Wang, Hoeksema &amp; Liang, 2018</xref>) and ab initio protein secondary structure (<xref rid="ref-48" ref-type="bibr">Spencer, Eickholt &amp; Cheng, 2015</xref>). Although those studies achieved very good performances, we believe that we can obtain superior results by using 2D CNN in some bioinformatics applications. In this study, we applied our architecture in the prediction of SNARE proteins, which is one of the most vital molecules in the life sciences.</p>
    <p>SNARE is an evolutionary superfamily of small proteins that have a conservation pattern of 60–70 amino acids (SNAP motifs) in their cytoplasmic domain. SNARE proteins catalyze cell membrane integration in eukaryotes and are essential for a wide range of cellular processes, including cell growth, cytokinesis, and synaptic transmission (<xref rid="ref-25" ref-type="bibr">Jahn &amp; Scheller, 2006</xref>; <xref rid="ref-56" ref-type="bibr">Wickner &amp; Schekman, 2008</xref>). Most SNAREs contain only one SNARE motif adjacent to a single C-terminal membrane (e.g., synaptobrevin 2 and syntaxin 1). Some SNAREs contain two SNARE motifs that are connected by a long linkage and non-transmembrane sequence (e.g., SNAP-25) but are attached to the membrane through a post-translational modification such as palmitoylation. Various types of SNARE proteins now identified and several studies demonstrated that a functional loss of SNARE proteins has been implicated in numerous diseases (e.g., neurodegenerative (<xref rid="ref-24" ref-type="bibr">Hou et al., 2017</xref>), mental illness (<xref rid="ref-23" ref-type="bibr">Honer et al., 2002</xref>), cancer (<xref rid="ref-41" ref-type="bibr">Meng &amp; Wang, 2015</xref>; <xref rid="ref-50" ref-type="bibr">Sun et al., 2016</xref>), and so on). Therefore, SNARE proteins play an important function in the cell and there is a need to develop some bioinformatics techniques to identify them.</p>
    <p>Because of the essential role in human diseases, SNARE proteins attracted various researchers who conducted their research on them. For instance, Kloepper team attempted to build a database to store and classify SNARE proteins (<xref rid="ref-29" ref-type="bibr">Kienle, Kloepper &amp; Fasshauer, 2009</xref>; <xref rid="ref-30" ref-type="bibr">Kloepper, Kienle &amp; Fasshauer, 2007</xref>; <xref rid="ref-31" ref-type="bibr">Kloepper, Kienle &amp; Fasshauer, 2008</xref>). Next, <xref rid="ref-53" ref-type="bibr">Van Dijk et al. (2008)</xref> built a framework to predict functions of SNAREs in sub-Golgi localization. Moreover, <xref rid="ref-55" ref-type="bibr">Weimbs et al. (1997)</xref> used bioinformatics techniques to analyze conserved domains in SNARE. <xref rid="ref-60" ref-type="bibr">Yoshizawa et al. (2006)</xref> extracted sequence motifs and the phylogenetic features of SNARE-dependent membrane trafficking. <xref rid="ref-46" ref-type="bibr">Shi et al. (2016)</xref> directed targeting of membrane fusion by SNARE mimicry by convergent evolution of Legionella effectors. <xref rid="ref-40" ref-type="bibr">Lu (2015)</xref> analyzed the destructive effect of botulinum neurotoxins on the SNARE protein and proposed that the truncated SNAP-25 mutants will disrupt the assembly of the SNARE core complex, and then inhibit the synaptic membrane fusion accordingly.</p>
    <p>Most published works on SNARE proteins achieved high performance, but to our knowledge, no researcher conducted the prediction of SNARE proteins using machine learning techniques. It is challenging and motivates us to create a precise model for this. Besides that, we also applied deep learning in this problem, which is a modern technique for classification and obtain high accuracies in various fields. Based on the advantages of deep learning, this study consequently proposes the use of a 2D convolutional neural network (CNN) constructed from position-specific scoring matrix (PSSM) profiles to identify SNARE proteins. The basic principle has already been successfully applied to identify electron transporting proteins (<xref rid="ref-32" ref-type="bibr">Le, Ho &amp; Ou, 2017</xref>) and Rab GTPases (<xref rid="ref-33" ref-type="bibr">Le, Ho &amp; Ou, 2018</xref>). Thus, in this paper, we extend this approach to identify the molecular functions of SNARE proteins. The main achievements, including contributions to the field, are presented as follows: (i) development of a deep learning framework to identify SNARE functions from protein sequences, in which our model exhibited a significant improvement beyond traditional machine learning algorithms; (ii) first computational study to identify SNARE proteins and provide useful information to biologists to discover the SNARE molecular functions; (iii) valid benchmark dataset to train and test SNARE proteins with high accuracy, which forms a basis for future research on SNARE proteins.</p>
    <p>As shown in a series of recent publications (<xref rid="ref-6" ref-type="bibr">Chen et al., 2018</xref>; <xref rid="ref-10" ref-type="bibr">Cheng, Xiao &amp; Chou, 2018a</xref>; <xref rid="ref-11" ref-type="bibr">Cheng, Xiao &amp; Chou, 2018b</xref>; <xref rid="ref-19" ref-type="bibr">Chou, Cheng &amp; Xiao, 2018</xref>; <xref rid="ref-20" ref-type="bibr">Feng et al., 2018</xref>; <xref rid="ref-26" ref-type="bibr">Jia et al., 2019</xref>; <xref rid="ref-28" ref-type="bibr">Khan et al., 2018</xref>; <xref rid="ref-58" ref-type="bibr">Xiao et al., 2018b</xref>), to develop a really useful statistical predictor for a biological system, one should observe the guidelines of Chou’s 5-step rule (<xref rid="ref-15" ref-type="bibr">Chou, 2011</xref>) to make the following five steps very clear: (i) how to construct or select a valid benchmark dataset to train and test the predictor; (ii) how to formulate the statistical samples with an effective mathematical expression that can truly reflect their intrinsic correlation with the target to be predicted; (iii) how to introduce or develop a powerful algorithm (or engine) to operate the prediction; (iv) how to properly perform cross-validation tests to objectively evaluate the anticipated accuracy of the predictor; (v) how to provide source code and dataset that are accessible to the public. Below, we are to describe how to deal with these steps one-by-one.</p>
  </sec>
  <sec sec-type="materials|methods">
    <title>Materials &amp; Methods</title>
    <p>We implemented an efficient framework for identifying SNARE proteins by using a 2D CNN and PSSM profiles. The framework consists of four procedures: data collection, feature extraction, CNN generation, and model evaluation. <xref ref-type="fig" rid="fig-1">Figure 1</xref> presents the flowchart of our framework, and its details are described as follows.</p>
    <fig id="fig-1" orientation="portrait" position="float">
      <object-id pub-id-type="doi">10.7717/peerjcs.177/fig-1</object-id>
      <label>Figure 1</label>
      <caption>
        <title>Flowchart for identifying SNARE proteins using two-dimensional convolutional neural networks.</title>
      </caption>
      <graphic xlink:href="peerj-cs-05-177-g001"/>
    </fig>
    <sec>
      <title>Dataset</title>
      <p>The dataset was retrieved from the UniProt database (by 22-10-2018) (<xref rid="ref-52" ref-type="bibr">UniProt Consortium, 2014</xref>), which is one of the comprehensive resources for the protein sequence. First of all, we collected all SNAREs proteins from the UniProt annotation (by using keyword “SNARE”). Note that only reviewed proteins (records with information extracted from literature and curator-evaluated computational analysis) were collected. Subsequently, BLAST (<xref rid="ref-1" ref-type="bibr">Altschul et al., 1997</xref>) was applied to remove the redundant sequences with similarity more than 30%. However, after this process, the rest of proteins only reached 245 SNAREs, and the number of data points was insufficient for a precise deep learning model. Hence, we used a cut-off level of 100% in the cross-validation dataset for more data to create a significant model. We still used similarity of 30% in the independent dataset to evaluate the performance of the model. This step is a very important step to check if the model was overfitting or not.</p>
      <p>The proposed problem was the binary classification between SNARE proteins and general proteins, thus we collected a set of general proteins as negative data. In order to create a precise model, there is a need to collect negative dataset which has a similar function and structure with the positive dataset. From that, it is challenging to build a precise model but it increases our contribution to the predictor. It will also help us decrease the number of negative data collected. After considering the structure and function, we chose vesicular transport protein, which is a general protein including SNARE protein. We counted it as negative data to perform the classification problem. We removed the redundant data between two datasets as well as the sequences with similarity more than 30%. Finally, there were 682 SNARE proteins and 2583 non-SNARE proteins used. We then divided data into cross-validation and independent dataset. The detail of the dataset using in this study is listed in <xref rid="table-1" ref-type="table">Table 1</xref>.</p>
      <table-wrap id="table-1" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerjcs.177/table-1</object-id>
        <label>Table 1</label>
        <caption>
          <title>Statistics of all retrieved SNARE and non-SNARE proteins.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="peerj-cs-05-177-g004"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1">Cross-validation</th>
                <th rowspan="1" colspan="1">Independent</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">SNARE</td>
                <td rowspan="1" colspan="1">644</td>
                <td rowspan="1" colspan="1">38</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Non-SNARE</td>
                <td rowspan="1" colspan="1">2,234</td>
                <td rowspan="1" colspan="1">349</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec>
      <title>Encoding feature sets from the protein sequence information</title>
      <p>In order to convert the protein sequence information into feature sets, we applied the PSSM matrices for FASTA sequences. A PSSM profile is a matrix represented by all motifs in biological sequences in general and in protein sequences in particular. It is created by rendering two sequences having similar structures with different amino acid compositions. Therefore, PSSM profiles have been adopted and used in a number of bioinformatics problems, e.g., prediction of protein secondary structure (<xref rid="ref-27" ref-type="bibr">Jones, 1999</xref>), protein disorder (<xref rid="ref-47" ref-type="bibr">Shimizu, Hirose &amp; Noguchi, 2007</xref>), and transport protein (<xref rid="ref-42" ref-type="bibr">Ou, Chen &amp; Gromiha, 2010</xref>) with significant improvements.</p>
      <p>Since the retrieved dataset is in FASTA format, it needs to be converted into PSSM profiles. To perform this task, we used PSI-BLAST (<xref rid="ref-1" ref-type="bibr">Altschul et al., 1997</xref>) to search all the sequence alignments of proteins in the non-redundant (NR) database with two iterations. The query to produce the PSSM profile is as follows:</p>
      <p>psiblast.exe -num_iterations 2 -db &lt;nr&gt;-in_msa &lt;fasta_file&gt;-out_ascii_&lt;pssm_file&gt;</p>
      <p>The feature extraction part of <xref ref-type="fig" rid="fig-1">Fig. 1</xref> indicates the information of generating the 400 PSSM capabilities from original PSSM profiles. Each amino acid in the sequence is represented by a vector of 20 values (each row). First, we summed up all rows with the same amino acid to transform the original PSSM profiles to PSSM profiles with 400 dimensions. The purpose of this step is to force this data type into something easier for the neural network to deal with. Each element of the 400D input vector was then divided by the sequence length and then be scaled before inserting into neural networks.</p>
    </sec>
    <sec>
      <title>Input layers for 2D convolutional neural networks</title>
      <p>The architecture of our CNN is described in the below part of <xref ref-type="fig" rid="fig-1">Fig. 1</xref>. The CNN contains three layers: an input layer, hidden layers (including convolutional, pooling and fully connected layers), and an output layer. CNN had been applied in numerous applications in various fields and convinced wonderful results (<xref rid="ref-2" ref-type="bibr">Amidi et al., 2018</xref>; <xref rid="ref-44" ref-type="bibr">Palatnik de Sousa, 2018</xref>). In our study, an input of the CNN is a PSSM corresponding to the protein sequences. We then propose a method to predict SNARE proteins by using their PSSM profiles as the input data. With this type of dataset, we assumed the PSSM profile with 20 × 20 matrix as a grayscale image with 20 × 20 pixels, we can then train the model with two-dimensional CNN. The input PSSM profile was then connected to our 2D CNN in which we set a variety of parameters to improve the performance of the model. By using a 2D CNN rather than other neural network structures, we aimed to capture as many hidden spatial features as possible in the PSSM matrices. This approach guarantees the correctness of the generated features and prevents the disorder problem inside the amino acid sequences. The more hidden layers generated, the more hidden features generated in CNN to identify SNARE proteins easily. In this work, we used four filter layers (with 32, 64, 128, and 256 filters) and three different kernel sizes in each filter.</p>
    </sec>
    <sec>
      <title>Multiple hidden layers for deep neural networks</title>
      <p>Following the input layer, hidden layers aim to generate matrices to learn the features. We established the hidden layers that contained various sub-layers with different parameters and shapes. Those 2D sub-layers are zero padding, convolutional, max pooling and fully-connected layers with different numbers of filters. All of the layers are combined together to become the nodes in the deep neural networks. The quality of our model was determined by the number of layers and parameters. The first layer of our 2D CNN architecture is the zero padding 2D layer, which added zero values at the beginning and the end of 20 × 20 matrices. The shape matrix changed to 22 × 22 dimensions when we added the zero padding layer into our network. After we applied the filters into the input shape, the output dimension was not different under the effect of the zero padding. <disp-formula id="eqn-1"><label>(1)</label><alternatives><graphic xlink:href="peerj-cs-05-177-e001.jpg" mimetype="image" mime-subtype="png" position="float" orientation="portrait"/><tex-math id="M1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{eqnarray*}zp= \frac{k-1}{2} \end{eqnarray*}\end{document}</tex-math><mml:math id="mml-eqn-1"><mml:mstyle displaystyle="true"><mml:mi>z</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mstyle></mml:math></alternatives></disp-formula>
</p>
      <p>where <italic>k</italic> is the filter size. Next, the 2D convolution layer was used with a kernel size of 3 × 3, meaning that the features will be learned with the 3 × 3 matrices and sliced to the end. After each step, the next layer will take the weights and biases from its previous layer and train again. Normally, a 2D max-pooling layer follows the 2D convolution layer. There are several parameters for a max-pooling layer, i.e., loop size and stride. In our study, we performed max pooling by a stride of 2 through the selection of the maximum value over a window of 22. By using this process, we can reduce the processing time in the next layers. The output size of a convolutional layer is computed as follow. <disp-formula id="eqn-2"><label>(2)</label><alternatives><graphic xlink:href="peerj-cs-05-177-e002.jpg" mimetype="image" mime-subtype="png" position="float" orientation="portrait"/><tex-math id="M2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{eqnarray*}os= \frac{w-k+2p}{s} +1\end{eqnarray*}\end{document}</tex-math><mml:math id="mml-eqn-2"><mml:mstyle displaystyle="true"><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>w</mml:mi><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></alternatives></disp-formula>
</p>
      <p>where <italic>w</italic> is the input size, <italic>k</italic> is the filter size, <italic>p</italic> is the padding and <italic>s</italic> is the stride size.</p>
    </sec>
    <sec>
      <title>Output layers</title>
      <p>The first layer in the output layer is a flatten layer. A flatten layer is always included before fully connected layers to convert the input matrix into a vector. We applied two fully connected layers in which each node is fully-connected to all the nodes of the previous layer. Fully connected layers are typically used in the last stages of CNNs. All the nodes of the first layer are connected to the flatten layer to allow the model to gain more knowledge and perform better. The second layer connects the first fully-connected layer to the output layer. Moreover, we inserted the next layer, dropout, to enhance the performance results of the model and it also helps our model prevent overfitting (<xref rid="ref-49" ref-type="bibr">Srivastava et al., 2014</xref>). In the dropout layer, the model will randomly deactivate a number of neurons with a certain probability p. By tuning the dropout value (from 0 to 1), we will save a lot of computing time for the next layers, and the training time will be faster. Furthermore, an additional non-linear operation called ReLU (Rectified Linear Unit) was performed after each convolution operation. To define the ReLU output, we used this formula: <disp-formula id="eqn-3"><label>(3)</label><alternatives><graphic xlink:href="peerj-cs-05-177-e003.jpg" mimetype="image" mime-subtype="png" position="float" orientation="portrait"/><tex-math id="M3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{eqnarray*}f \left( x \right) =\max \nolimits \left( 0,x \right) \end{eqnarray*}\end{document}</tex-math><mml:math id="mml-eqn-3"><mml:mstyle displaystyle="true"><mml:mi>f</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo class="qopname"> max</mml:mo><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:mfenced></mml:mstyle></mml:math></alternatives></disp-formula>
</p>
      <p>where <italic>x</italic> is the number of inputs into a neural network. The output of the model was computed through a softmax function by which the probability for each possible output was determined. The softmax function is a logistic function which is defined by the following formula: <disp-formula id="eqn-4"><label>(4)</label><alternatives><graphic xlink:href="peerj-cs-05-177-e004.jpg" mimetype="image" mime-subtype="png" position="float" orientation="portrait"/><tex-math id="M4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{eqnarray*}\sigma { \left( z \right) }_{i}= \frac{{e}^{{z}_{i}}}{\sum _{k=1}^{K}{e}^{{z}_{k}}} \end{eqnarray*}\end{document}</tex-math><mml:math id="mml-eqn-4"><mml:mstyle displaystyle="true"><mml:mi>σ</mml:mi><mml:msub><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mi>z</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:munderover><mml:mrow><mml:mo mathsize="big" movablelimits="false"> ∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:math></alternatives></disp-formula>
</p>
      <p>where <italic>z</italic> is the input vector with K-dimensional vector, K-dimensional vector <italic>σ</italic>(<italic>z</italic>) is real values in the range (0, 1) and j<sup>th</sup> class is the predicted probability from sample vector <italic>x</italic>. In summary, we set a total of 233,314 trainable parameters in the model (<xref rid="table-2" ref-type="table">Table 2</xref>).</p>
      <table-wrap id="table-2" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerjcs.177/table-2</object-id>
        <label>Table 2</label>
        <caption>
          <title>All layers and trainable parameters of the two-dimensional convolutional neural networks in this study.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="peerj-cs-05-177-g005"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Layer (type)</th>
                <th rowspan="1" colspan="1">Output shape</th>
                <th rowspan="1" colspan="1">Parameters #</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">Zeropadding2d_1</td>
                <td rowspan="1" colspan="1">(None, 3, 22, 20)</td>
                <td rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Conv2d_1</td>
                <td rowspan="1" colspan="1">(None, 1, 20, 32)</td>
                <td rowspan="1" colspan="1">5,792</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Max_pooling2d_1</td>
                <td rowspan="1" colspan="1">(None, 1, 10, 16)</td>
                <td rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Zeropadding2d_2</td>
                <td rowspan="1" colspan="1">(None, 3, 12, 16)</td>
                <td rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Conv2d_2</td>
                <td rowspan="1" colspan="1">(None, 1, 10, 64)</td>
                <td rowspan="1" colspan="1">9,280</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Max_pooling2d_2</td>
                <td rowspan="1" colspan="1">(None, 1, 5, 32)</td>
                <td rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Zeropadding2d_3</td>
                <td rowspan="1" colspan="1">(None, 3, 7, 32)</td>
                <td rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Conv2d_3</td>
                <td rowspan="1" colspan="1">(None, 1, 5, 128)</td>
                <td rowspan="1" colspan="1">36,992</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Max_pooling2d_3</td>
                <td rowspan="1" colspan="1">(None, 1, 2, 64)</td>
                <td rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Zeropadding2d_4</td>
                <td rowspan="1" colspan="1">(None, 3, 4, 64)</td>
                <td rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Conv2d_4</td>
                <td rowspan="1" colspan="1">(None, 1, 2, 256)</td>
                <td rowspan="1" colspan="1">147,712</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Max_pooling2d_4</td>
                <td rowspan="1" colspan="1">(None, 1, 1, 128)</td>
                <td rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Flatten_1</td>
                <td rowspan="1" colspan="1">(None, 128)</td>
                <td rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Dense_1</td>
                <td rowspan="1" colspan="1">(None, 256)</td>
                <td rowspan="1" colspan="1">33,024</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Dropout_1</td>
                <td rowspan="1" colspan="1">(None, 256)</td>
                <td rowspan="1" colspan="1">0</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Dense_2</td>
                <td rowspan="1" colspan="1">(None, 2)</td>
                <td rowspan="1" colspan="1">514</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Activation_1</td>
                <td rowspan="1" colspan="1">(None, 2)</td>
                <td rowspan="1" colspan="1">0</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec>
      <title>Performance evaluation</title>
      <p>The most important purpose of the present study was to predict whether or not a sequence is SNARE protein; therefore, we used “Positive” to define the SNARE protein, and “Negative” to define the non-SNARE protein. For each dataset, we first trained the model by applying 5-fold cross-validation technique on the training dataset. Based on the 5-fold cross-validation results, hyper-parameter optimization process was employed to find the best model for each dataset. Finally, the independent dataset was used to assess the predictive ability of the current model.</p>
      <p>Based on the Chou’s symbols introduced for studying protein signal peptides (<xref rid="ref-14" ref-type="bibr">Chou, 2001</xref>), a set of four intuitive metrics were derived, as given in Eq. 14 of <xref rid="ref-7" ref-type="bibr">Chen et al. (2013)</xref> or in Eq. 19 of <xref rid="ref-59" ref-type="bibr">Xu et al. (2013)</xref>. For evaluating the performance of the methods, we also adopted Chou’s criterion used in many bioinformatics studies (<xref rid="ref-5" ref-type="bibr">Chen et al., 2007</xref>; <xref rid="ref-21" ref-type="bibr">Feng et al., 2013</xref>; <xref rid="ref-51" ref-type="bibr">Taju et al., 2018</xref>). Either the set of traditional metrics copied from math books or the intuitive metrics derived from the Chou’s symbols (<xref ref-type="disp-formula" rid="eqn-5">Eqs. (5)</xref>–<xref ref-type="disp-formula" rid="eqn-8">(8)</xref>) are valid only for the single-label systems (where each sample only belongs to one class). For the multi-label systems (where a sample may simultaneously belong to several classes), whose existence has become more frequent in system biology (<xref rid="ref-8" ref-type="bibr">Cheng, Xiao &amp; Chou, 2017a</xref>; <xref rid="ref-9" ref-type="bibr">Cheng, Xiao &amp; Chou, 2017b</xref>; <xref rid="ref-12" ref-type="bibr">Cheng et al., 2017a</xref>; <xref rid="ref-57" ref-type="bibr">Xiao et al., 2018a</xref>), system medicine (<xref rid="ref-13" ref-type="bibr">Cheng et al., 2017b</xref>) and biomedicine (<xref rid="ref-45" ref-type="bibr">Qiu et al., 2016</xref>), a completely different set of metrics as defined in (<xref rid="ref-16" ref-type="bibr">Chou, 2013</xref>) is absolutely needed. Some standard metrics were used, such as sensitivity, specificity, accuracy, and Matthews correlation coefficient (MCC) using below given formulae (TP, FP, TN, FN are true positive, false positive, true negative, and false negative values, respectively):</p>
      <p>
        <disp-formula id="eqn-5">
          <label>(5)</label>
          <alternatives>
            <graphic xlink:href="peerj-cs-05-177-e005.jpg" mimetype="image" mime-subtype="png" position="float" orientation="portrait"/>
            <tex-math id="M5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{eqnarray*}Sensitivity=1- \frac{{N}_{-}^{+}}{{N}^{+}} ,0\leq Sen\leq 1\end{eqnarray*}\end{document}</tex-math>
            <mml:math id="mml-eqn-5">
              <mml:mstyle displaystyle="true">
                <mml:mi>S</mml:mi>
                <mml:mi>e</mml:mi>
                <mml:mi>n</mml:mi>
                <mml:mi>s</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>t</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>v</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>t</mml:mi>
                <mml:mi>y</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mn>1</mml:mn>
                <mml:mo>−</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>−</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>+</mml:mo>
                      </mml:mrow>
                    </mml:msubsup>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>+</mml:mo>
                      </mml:mrow>
                    </mml:msup>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>,</mml:mo>
                <mml:mn>0</mml:mn>
                <mml:mo>≤</mml:mo>
                <mml:mi>S</mml:mi>
                <mml:mi>e</mml:mi>
                <mml:mi>n</mml:mi>
                <mml:mo>≤</mml:mo>
                <mml:mn>1</mml:mn>
              </mml:mstyle>
            </mml:math>
          </alternatives>
        </disp-formula>
        <disp-formula id="eqn-6">
          <label>(6)</label>
          <alternatives>
            <graphic xlink:href="peerj-cs-05-177-e006.jpg" mimetype="image" mime-subtype="png" position="float" orientation="portrait"/>
            <tex-math id="M6">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{eqnarray*}Specificity=1- \frac{{N}_{+}^{-}}{{N}^{-}} ,0\leq Spec\leq 1\end{eqnarray*}\end{document}</tex-math>
            <mml:math id="mml-eqn-6">
              <mml:mstyle displaystyle="true">
                <mml:mi>S</mml:mi>
                <mml:mi>p</mml:mi>
                <mml:mi>e</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>f</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>i</mml:mi>
                <mml:mi>t</mml:mi>
                <mml:mi>y</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mn>1</mml:mn>
                <mml:mo>−</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>+</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>−</mml:mo>
                      </mml:mrow>
                    </mml:msubsup>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>−</mml:mo>
                      </mml:mrow>
                    </mml:msup>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>,</mml:mo>
                <mml:mn>0</mml:mn>
                <mml:mo>≤</mml:mo>
                <mml:mi>S</mml:mi>
                <mml:mi>p</mml:mi>
                <mml:mi>e</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mo>≤</mml:mo>
                <mml:mn>1</mml:mn>
              </mml:mstyle>
            </mml:math>
          </alternatives>
        </disp-formula>
        <disp-formula id="eqn-7">
          <label>(7)</label>
          <alternatives>
            <graphic xlink:href="peerj-cs-05-177-e007.jpg" mimetype="image" mime-subtype="png" position="float" orientation="portrait"/>
            <tex-math id="M7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{eqnarray*}Accuracy=1- \frac{{N}_{-}^{+}+{N}_{+}^{-}}{{N}^{+}+{N}^{-}} ,0\leq Acc\leq 1\end{eqnarray*}\end{document}</tex-math>
            <mml:math id="mml-eqn-7">
              <mml:mstyle displaystyle="true">
                <mml:mi>A</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>u</mml:mi>
                <mml:mi>r</mml:mi>
                <mml:mi>a</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>y</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mn>1</mml:mn>
                <mml:mo>−</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>−</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>+</mml:mo>
                      </mml:mrow>
                    </mml:msubsup>
                    <mml:mo>+</mml:mo>
                    <mml:msubsup>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>+</mml:mo>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>−</mml:mo>
                      </mml:mrow>
                    </mml:msubsup>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>+</mml:mo>
                      </mml:mrow>
                    </mml:msup>
                    <mml:mo>+</mml:mo>
                    <mml:msup>
                      <mml:mrow>
                        <mml:mi>N</mml:mi>
                      </mml:mrow>
                      <mml:mrow>
                        <mml:mo>−</mml:mo>
                      </mml:mrow>
                    </mml:msup>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>,</mml:mo>
                <mml:mn>0</mml:mn>
                <mml:mo>≤</mml:mo>
                <mml:mi>A</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mi>c</mml:mi>
                <mml:mo>≤</mml:mo>
                <mml:mn>1</mml:mn>
              </mml:mstyle>
            </mml:math>
          </alternatives>
        </disp-formula>
        <disp-formula id="eqn-8">
          <label>(8)</label>
          <alternatives>
            <graphic xlink:href="peerj-cs-05-177-e008.jpg" mimetype="image" mime-subtype="png" position="float" orientation="portrait"/>
            <tex-math id="M8">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{eqnarray*}MCC= \frac{1- \left( \frac{{N}_{-}^{+}}{{N}^{+}} + \frac{{N}_{+}^{-}}{{N}^{-}} \right) }{\sqrt{ \left( 1+ \frac{{N}_{+}^{-}-{N}_{-}^{+}}{{N}^{+}} \right) \left( 1+ \frac{{N}_{-}^{+}-{N}_{+}^{-}}{{N}^{-}} \right) }} ,-1\leq MCC\leq 1\end{eqnarray*}\end{document}</tex-math>
            <mml:math id="mml-eqn-8">
              <mml:mstyle displaystyle="true">
                <mml:mi>M</mml:mi>
                <mml:mi>C</mml:mi>
                <mml:mi>C</mml:mi>
                <mml:mo>=</mml:mo>
                <mml:mfrac>
                  <mml:mrow>
                    <mml:mn>1</mml:mn>
                    <mml:mo>−</mml:mo>
                    <mml:mfenced separators="" open="(" close=")">
                      <mml:mrow>
                        <mml:mfrac>
                          <mml:mrow>
                            <mml:msubsup>
                              <mml:mrow>
                                <mml:mi>N</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mo>−</mml:mo>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mo>+</mml:mo>
                              </mml:mrow>
                            </mml:msubsup>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:msup>
                              <mml:mrow>
                                <mml:mi>N</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mo>+</mml:mo>
                              </mml:mrow>
                            </mml:msup>
                          </mml:mrow>
                        </mml:mfrac>
                        <mml:mo>+</mml:mo>
                        <mml:mfrac>
                          <mml:mrow>
                            <mml:msubsup>
                              <mml:mrow>
                                <mml:mi>N</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mo>+</mml:mo>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mo>−</mml:mo>
                              </mml:mrow>
                            </mml:msubsup>
                          </mml:mrow>
                          <mml:mrow>
                            <mml:msup>
                              <mml:mrow>
                                <mml:mi>N</mml:mi>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:mo>−</mml:mo>
                              </mml:mrow>
                            </mml:msup>
                          </mml:mrow>
                        </mml:mfrac>
                      </mml:mrow>
                    </mml:mfenced>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:msqrt>
                      <mml:mrow>
                        <mml:mfenced separators="" open="(" close=")">
                          <mml:mrow>
                            <mml:mn>1</mml:mn>
                            <mml:mo>+</mml:mo>
                            <mml:mfrac>
                              <mml:mrow>
                                <mml:msubsup>
                                  <mml:mrow>
                                    <mml:mi>N</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mo>+</mml:mo>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mo>−</mml:mo>
                                  </mml:mrow>
                                </mml:msubsup>
                                <mml:mo>−</mml:mo>
                                <mml:msubsup>
                                  <mml:mrow>
                                    <mml:mi>N</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mo>−</mml:mo>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mo>+</mml:mo>
                                  </mml:mrow>
                                </mml:msubsup>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:msup>
                                  <mml:mrow>
                                    <mml:mi>N</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mo>+</mml:mo>
                                  </mml:mrow>
                                </mml:msup>
                              </mml:mrow>
                            </mml:mfrac>
                          </mml:mrow>
                        </mml:mfenced>
                        <mml:mfenced separators="" open="(" close=")">
                          <mml:mrow>
                            <mml:mn>1</mml:mn>
                            <mml:mo>+</mml:mo>
                            <mml:mfrac>
                              <mml:mrow>
                                <mml:msubsup>
                                  <mml:mrow>
                                    <mml:mi>N</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mo>−</mml:mo>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mo>+</mml:mo>
                                  </mml:mrow>
                                </mml:msubsup>
                                <mml:mo>−</mml:mo>
                                <mml:msubsup>
                                  <mml:mrow>
                                    <mml:mi>N</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mo>+</mml:mo>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mo>−</mml:mo>
                                  </mml:mrow>
                                </mml:msubsup>
                              </mml:mrow>
                              <mml:mrow>
                                <mml:msup>
                                  <mml:mrow>
                                    <mml:mi>N</mml:mi>
                                  </mml:mrow>
                                  <mml:mrow>
                                    <mml:mo>−</mml:mo>
                                  </mml:mrow>
                                </mml:msup>
                              </mml:mrow>
                            </mml:mfrac>
                          </mml:mrow>
                        </mml:mfenced>
                      </mml:mrow>
                    </mml:msqrt>
                  </mml:mrow>
                </mml:mfrac>
                <mml:mo>,</mml:mo>
                <mml:mo>−</mml:mo>
                <mml:mn>1</mml:mn>
                <mml:mo>≤</mml:mo>
                <mml:mi>M</mml:mi>
                <mml:mi>C</mml:mi>
                <mml:mi>C</mml:mi>
                <mml:mo>≤</mml:mo>
                <mml:mn>1</mml:mn>
              </mml:mstyle>
            </mml:math>
          </alternatives>
        </disp-formula>
      </p>
      <p>The relations between these symbols and the symbols in <xref ref-type="disp-formula" rid="eqn-5">Eqs. (5)</xref>–<xref ref-type="disp-formula" rid="eqn-8">(8)</xref> are given by: <disp-formula id="eqn-9"><label>(9)</label><alternatives><graphic xlink:href="peerj-cs-05-177-e009.jpg" mimetype="image" mime-subtype="png" position="float" orientation="portrait"/><tex-math id="M9">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{eqnarray*} \left\{ \begin{array}{@{}l@{}} \displaystyle {N}_{+}^{-}=FP \\ \displaystyle {N}_{-}^{+}=FN \\ \displaystyle \begin{array}{@{}c@{}} \displaystyle {N}^{+}=TP+{N}_{-}^{+}\\ \displaystyle {N}^{-}=TN+{N}_{+}^{-} \end{array} \end{array} \right. \end{eqnarray*}\end{document}</tex-math><mml:math id="mml-eqn-9"><mml:mstyle displaystyle="true"><mml:mfenced separators="" open="{" close=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mspace width="10.00002pt"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi><mml:mspace width="10.00002pt"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mtable><mml:mtr><mml:mtd columnalign="center"><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="center"><mml:msup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mspace width="10.00002pt"/></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:mstyle></mml:math></alternatives></disp-formula>
</p>
    </sec>
  </sec>
  <sec>
    <title>Results and Discussions</title>
    <p>The quality and reliability of the modeling techniques of research is an important factor in the study. Initially, we designed an experiment by analyzing data, perform calculations and take various comparisons in the results and discussions section.</p>
    <sec>
      <title>Composition of amino acid in SNARE and non-SNARE proteins</title>
      <p>We analyzed the composition of amino acid and the variance of amino acid composition in SNARE sequences and non-SNARE sequences by computing the frequency between them. <xref ref-type="fig" rid="fig-2">Figure 2</xref> illustrates the amino acids which contributed the significantly highest frequency in two different datasets. We realized that the amino acid E, and K, and L occur at the highest frequencies surrounding the SNARE proteins. On the other hand, amino acids G and P occur at the highest frequencies surrounding the non-SNARE proteins. Therefore, these amino acids certainly had an essential role in identifying SNARE proteins. Thus, our model might predict SNARE proteins accurately via the special features from those amino acids contributions.</p>
      <fig id="fig-2" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerjcs.177/fig-2</object-id>
        <label>Figure 2</label>
        <caption>
          <title>Amino acid composition in SNARE and non-SNARE proteins.</title>
        </caption>
        <graphic xlink:href="peerj-cs-05-177-g002"/>
      </fig>
    </sec>
    <sec>
      <title>Performance for identifying SNARE proteins with 2D CNN</title>
      <p>We implemented our 2D CNN architecture by using Keras package with Tensorflow backend. First, we tried to find the optimal setup for the hidden layers by doing experiments using four different filter sizes: 32, 64, 128, and 256. <xref rid="table-3" ref-type="table">Table 3</xref> demonstrates the performance results from various filter layers in the cross-validation dataset. We easily observe that during the 5-fold cross-validation to identify SNAREs, the model with 256 filters was prominent identifying these sequences with an average 5-fold cross-validation accuracy of 88.2%. The performance results are higher than the performances from the other results with other filters. The sensitivity, specificity, and MCC for cross-validation data achieved 70.5%, 93.3%, and 0.65, respectively. Therefore, we used 256 filters for the hidden layer to develop our model. We then optimized the neural networks using a variety of optimizers: rmsprop, adam, nadam, sgd, and adadelta. The model was reinitialized, i.e., a new network is built, after each round of optimization so as to provide a fair comparison between the different optimizers. Overall, the performance results are shown in <xref ref-type="fig" rid="fig-3">Fig. 3</xref> and we decided to choose nadam, an optimizer with consistent performance to create our final model.</p>
      <table-wrap id="table-3" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerjcs.177/table-3</object-id>
        <label>Table 3</label>
        <caption>
          <title>Performance results of identifying SNAREs with different filter layers.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="peerj-cs-05-177-g006"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Filters</th>
                <th rowspan="1" colspan="1">Sens</th>
                <th rowspan="1" colspan="1">Spec</th>
                <th rowspan="1" colspan="1">Acc</th>
                <th rowspan="1" colspan="1">MCC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">32</td>
                <td rowspan="1" colspan="1">68.3</td>
                <td rowspan="1" colspan="1">91.9</td>
                <td rowspan="1" colspan="1">86.6</td>
                <td rowspan="1" colspan="1">0.61</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">32–64</td>
                <td rowspan="1" colspan="1">69.9</td>
                <td rowspan="1" colspan="1">93.2</td>
                <td rowspan="1" colspan="1">88</td>
                <td rowspan="1" colspan="1">0.65</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">32–64–128</td>
                <td rowspan="1" colspan="1">73.3</td>
                <td rowspan="1" colspan="1">91.5</td>
                <td rowspan="1" colspan="1">87.5</td>
                <td rowspan="1" colspan="1">0.64</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">32–64–128–256</td>
                <td rowspan="1" colspan="1">70.5</td>
                <td rowspan="1" colspan="1">93.3</td>
                <td rowspan="1" colspan="1">88.2</td>
                <td rowspan="1" colspan="1">0.65</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <fig id="fig-3" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerjcs.177/fig-3</object-id>
        <label>Figure 3</label>
        <caption>
          <title>The validation accuracy on identifying SNARE proteins using different optimizers.</title>
        </caption>
        <graphic xlink:href="peerj-cs-05-177-g003"/>
      </fig>
    </sec>
    <sec>
      <title>Improving the performance results and preventing overfitting problem with dropout</title>
      <p>It can be seen that there was a fair difference in performance between using the cross-validation dataset and the independent dataset. It is due to the non-removing similarity in cross-validation, and now we address this issue. To solve this issue, we applied an important technique called dropout (<xref rid="ref-49" ref-type="bibr">Srivastava et al., 2014</xref>). <xref rid="table-4" ref-type="table">Table 4</xref> presents the performances of the model when we varied the dropout value from 0 to 1. It can be seen that the performance from the dropout value of 0.1 was higher than others, with the sensitivity, specificity, accuracy, and MCC of 72.4%, 94.4%, 89.5%, and 0.69, respectively. In the independent dataset, the sensitivity, specificity, accuracy, and MCC were 44.7%, 95.4%, 90.4%, and 0.43, respectively. We can see that the performance of the independent dataset has been already improved and moved closer to that of the cross-validation dataset. Therefore, the overfitting problem was gradually resolved, and we used this dropout value for our final model.</p>
      <table-wrap id="table-4" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerjcs.177/table-4</object-id>
        <label>Table 4</label>
        <caption>
          <title>Performance results of identifying SNAREs with different dropout levels.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="peerj-cs-05-177-g007"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th align="center" colspan="4" rowspan="1">Cross-validation</th>
                <th align="center" colspan="4" rowspan="1">Independent</th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1">Dropout</th>
                <th rowspan="1" colspan="1">Sens</th>
                <th rowspan="1" colspan="1">Spec</th>
                <th rowspan="1" colspan="1">Acc</th>
                <th rowspan="1" colspan="1">MCC</th>
                <th rowspan="1" colspan="1">Sens</th>
                <th rowspan="1" colspan="1">Spec</th>
                <th rowspan="1" colspan="1">Acc</th>
                <th rowspan="1" colspan="1">MCC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">0</td>
                <td rowspan="1" colspan="1">70.5</td>
                <td rowspan="1" colspan="1">93.3</td>
                <td rowspan="1" colspan="1">88.2</td>
                <td rowspan="1" colspan="1">0.65</td>
                <td rowspan="1" colspan="1">57.9</td>
                <td rowspan="1" colspan="1">85.7</td>
                <td rowspan="1" colspan="1">82.9</td>
                <td rowspan="1" colspan="1">0.33</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.1</td>
                <td rowspan="1" colspan="1">72.4</td>
                <td rowspan="1" colspan="1">94.4</td>
                <td rowspan="1" colspan="1">89.5</td>
                <td rowspan="1" colspan="1">0.69</td>
                <td rowspan="1" colspan="1">44.7</td>
                <td rowspan="1" colspan="1">95.4</td>
                <td rowspan="1" colspan="1">90.4</td>
                <td rowspan="1" colspan="1">0.43</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.2</td>
                <td rowspan="1" colspan="1">69.3</td>
                <td rowspan="1" colspan="1">93.9</td>
                <td rowspan="1" colspan="1">88.4</td>
                <td rowspan="1" colspan="1">0.65</td>
                <td rowspan="1" colspan="1">50</td>
                <td rowspan="1" colspan="1">87.4</td>
                <td rowspan="1" colspan="1">83.7</td>
                <td rowspan="1" colspan="1">0.3</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.3</td>
                <td rowspan="1" colspan="1">69.6</td>
                <td rowspan="1" colspan="1">94.2</td>
                <td rowspan="1" colspan="1">88.7</td>
                <td rowspan="1" colspan="1">0.66</td>
                <td rowspan="1" colspan="1">42.1</td>
                <td rowspan="1" colspan="1">86</td>
                <td rowspan="1" colspan="1">81.7</td>
                <td rowspan="1" colspan="1">0.22</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.4</td>
                <td rowspan="1" colspan="1">72</td>
                <td rowspan="1" colspan="1">92.6</td>
                <td rowspan="1" colspan="1">88</td>
                <td rowspan="1" colspan="1">0.65</td>
                <td rowspan="1" colspan="1">39.5</td>
                <td rowspan="1" colspan="1">91.4</td>
                <td rowspan="1" colspan="1">86.3</td>
                <td rowspan="1" colspan="1">0.29</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">0.5</td>
                <td rowspan="1" colspan="1">69.7</td>
                <td rowspan="1" colspan="1">94.8</td>
                <td rowspan="1" colspan="1">89.1</td>
                <td rowspan="1" colspan="1">0.68</td>
                <td rowspan="1" colspan="1">36.8</td>
                <td rowspan="1" colspan="1">92.8</td>
                <td rowspan="1" colspan="1">87.3</td>
                <td rowspan="1" colspan="1">0.29</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>Moreover, the number of epochs used in the experiment extremely affects the performance results. To discover the optimal epoch, we ran our experiments by ranging the epoch value from the first epoch to the 500th epoch. During this process, we saved the checkpoint with the highest performance and used its parameters to create our model. Until this final step, the independent sensitivity, specificity, accuracy, and MCC reached 65.8%, 90.3%, 87.9% and 0.46, respectively. This result is close to that of the cross-validation dataset at the same level of 2D CNN architecture. Finally, our model applied 256 filter layers, nadam optimizer, and dropout value of 0.1 to identify SNARE proteins with the highest performance.</p>
    </sec>
    <sec>
      <title>Comparative performance for identifying SNAREs between 2D CNN and shallow neural networks</title>
      <p>We examined the performances of using different machine learning classifiers for identifying SNARE proteins. We used four different classifiers (i.e., nearest neighbor (kNN), Gaussian, Random Forest, and support vector machine (SVM)) to evaluate the model and compared 2D CNN results with their results. For a fair comparison, we definitely used the optimal parameters for all the classifiers in all the experiments. <xref rid="table-5" ref-type="table">Table 5</xref> shows the performance results between our method and other machine learning algorithms. It can be seen that our 2D CNN exhibited higher performance than those of the other traditional machine learning techniques using the same experimental setup. Especially, our 2D CNN outperformed other algorithms when using the independent dataset.</p>
      <table-wrap id="table-5" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerjcs.177/table-5</object-id>
        <label>Table 5</label>
        <caption>
          <title>Comparative performance between 2D CNN and other shallow neural networks.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="peerj-cs-05-177-g008"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Classifier</th>
                <th align="center" colspan="4" rowspan="1">Cross-validation</th>
                <th align="center" colspan="4" rowspan="1">Independent</th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1">Sens</th>
                <th rowspan="1" colspan="1">Spec</th>
                <th rowspan="1" colspan="1">Acc</th>
                <th rowspan="1" colspan="1">MCC</th>
                <th rowspan="1" colspan="1">Sens</th>
                <th rowspan="1" colspan="1">Spec</th>
                <th rowspan="1" colspan="1">Acc</th>
                <th rowspan="1" colspan="1">MCC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">kNN</td>
                <td rowspan="1" colspan="1">60.1</td>
                <td rowspan="1" colspan="1">95.4</td>
                <td rowspan="1" colspan="1">87.5</td>
                <td rowspan="1" colspan="1">0.62</td>
                <td rowspan="1" colspan="1">28.9</td>
                <td rowspan="1" colspan="1">95.1</td>
                <td rowspan="1" colspan="1">88.6</td>
                <td rowspan="1" colspan="1">0.28</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">RandomForest</td>
                <td rowspan="1" colspan="1">59.6</td>
                <td rowspan="1" colspan="1">98.2</td>
                <td rowspan="1" colspan="1">89.5</td>
                <td rowspan="1" colspan="1">0.68</td>
                <td rowspan="1" colspan="1">15.8</td>
                <td rowspan="1" colspan="1">98</td>
                <td rowspan="1" colspan="1">89.9</td>
                <td rowspan="1" colspan="1">0.23</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">Gaussian</td>
                <td rowspan="1" colspan="1">93.5</td>
                <td rowspan="1" colspan="1">30.5</td>
                <td rowspan="1" colspan="1">44.6</td>
                <td rowspan="1" colspan="1">0.23</td>
                <td rowspan="1" colspan="1">81.6</td>
                <td rowspan="1" colspan="1">23.2</td>
                <td rowspan="1" colspan="1">28.9</td>
                <td rowspan="1" colspan="1">0.03</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">SVM</td>
                <td rowspan="1" colspan="1">35.2</td>
                <td rowspan="1" colspan="1">98.1</td>
                <td rowspan="1" colspan="1">84</td>
                <td rowspan="1" colspan="1">0.48</td>
                <td rowspan="1" colspan="1">28.9</td>
                <td rowspan="1" colspan="1">97.1</td>
                <td rowspan="1" colspan="1">90.4</td>
                <td rowspan="1" colspan="1">0.34</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">2D CNN</td>
                <td rowspan="1" colspan="1">76.6</td>
                <td rowspan="1" colspan="1">93.5</td>
                <td rowspan="1" colspan="1">89.7</td>
                <td rowspan="1" colspan="1">0.7</td>
                <td rowspan="1" colspan="1">65.8</td>
                <td rowspan="1" colspan="1">90.3</td>
                <td rowspan="1" colspan="1">87.9</td>
                <td rowspan="1" colspan="1">0.46</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec>
      <title>Comparative performance for identifying SNAREs between 2D CNN and BLAST search pipeline</title>
      <p>To make our prediction have convincing, we aimed to simply BLASTing the SNARE and non-SNARE sequences. The objective of this step is to check whether the first non-identical match was a SNARE/non-SNARE protein. We then compared with our PSSM via PSI-BLAST and the performance results were shown in <xref rid="table-6" ref-type="table">Table 6</xref>. It is easy to say that we are able to reach a better performance when using the PSSM profiles to build a classifier. It also means that BLAST can search a sequence within motifs, but it cannot capture hidden information in sequences. Therefore, it is necessary and useful to create an advanced classifier with stronger features e.g., PSSM profiles in this study.</p>
      <table-wrap id="table-6" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.7717/peerjcs.177/table-6</object-id>
        <label>Table 6</label>
        <caption>
          <title>Comparative performance between our classification method and BLAST search pipeline.</title>
        </caption>
        <alternatives>
          <graphic xlink:href="peerj-cs-05-177-g009"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
              <col span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th rowspan="1" colspan="1">Method</th>
                <th align="center" colspan="4" rowspan="1">Cross-validation</th>
                <th align="center" colspan="4" rowspan="1">Independent</th>
              </tr>
              <tr>
                <th rowspan="1" colspan="1"/>
                <th rowspan="1" colspan="1">Sens</th>
                <th rowspan="1" colspan="1">Spec</th>
                <th rowspan="1" colspan="1">Acc</th>
                <th rowspan="1" colspan="1">MCC</th>
                <th rowspan="1" colspan="1">Sens</th>
                <th rowspan="1" colspan="1">Spec</th>
                <th rowspan="1" colspan="1">Acc</th>
                <th rowspan="1" colspan="1">MCC</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">BLAST</td>
                <td rowspan="1" colspan="1">37.0</td>
                <td rowspan="1" colspan="1">99.3</td>
                <td rowspan="1" colspan="1">85.3</td>
                <td rowspan="1" colspan="1">0.53</td>
                <td rowspan="1" colspan="1">26.3</td>
                <td rowspan="1" colspan="1">99.4</td>
                <td rowspan="1" colspan="1">92.2</td>
                <td rowspan="1" colspan="1">0.44</td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">2D CNN</td>
                <td rowspan="1" colspan="1">76.6</td>
                <td rowspan="1" colspan="1">93.5</td>
                <td rowspan="1" colspan="1">89.7</td>
                <td rowspan="1" colspan="1">0.7</td>
                <td rowspan="1" colspan="1">65.8</td>
                <td rowspan="1" colspan="1">90.3</td>
                <td rowspan="1" colspan="1">87.9</td>
                <td rowspan="1" colspan="1">0.46</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>Furthermore, source codes and publicly accessible web-servers represent the current trend for developing various computational methods (<xref rid="ref-6" ref-type="bibr">Chen et al., 2018</xref>; <xref rid="ref-10" ref-type="bibr">Cheng, Xiao &amp; Chou, 2018a</xref>; <xref rid="ref-11" ref-type="bibr">Cheng, Xiao &amp; Chou, 2018b</xref>; <xref rid="ref-19" ref-type="bibr">Chou, Cheng &amp; Xiao, 2018</xref>; <xref rid="ref-20" ref-type="bibr">Feng et al., 2018</xref>; <xref rid="ref-26" ref-type="bibr">Jia et al., 2019</xref>; <xref rid="ref-28" ref-type="bibr">Khan et al., 2018</xref>; <xref rid="ref-34" ref-type="bibr">Le, Ho &amp; Ou, 2019</xref>; <xref rid="ref-58" ref-type="bibr">Xiao et al., 2018b</xref>). Actually, they have significantly enhanced the impacts of computational biology on medical science (<xref rid="ref-17" ref-type="bibr">Chou, 2015</xref>), driving medicinal chemistry into an unprecedented revolution (<xref rid="ref-18" ref-type="bibr">Chou, 2017</xref>), here we also publish our source codes and dataset at <ext-link ext-link-type="uri" xlink:href="https://github.com/khanhlee/snare-cnn">https://github.com/khanhlee/snare-cnn</ext-link> for presenting the new method reported in this paper.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions">
    <title>Conclusions</title>
    <p>Deep learning, a leading technique in various fields, has been increasingly applied in bioinformatics and computational biology. This study approaches a novel for identifying SNARE proteins by using deep learning. The idea is to transform PSSM profiles into matrices and use them as the input to 2D CNN architectures. We evaluated the performance of our model, which was developed by using a 2D CNN and PSSM profiles, using 5-fold cross-validation and an independent testing dataset. Our method produced superior performance, and compared to other state-of-the-art neural networks, it achieved a significant improvement in all the typical measurement metrics. Using our model, new SNARE proteins can be accurately identified and used for drug development. Moreover, the contribution of this study could help further research to promote the use of 2D CNN in bioinformatics, especially in protein function prediction.</p>
  </sec>
</body>
<back>
  <sec sec-type="additional-information">
    <title>Additional Information and Declarations</title>
    <fn-group content-type="competing-interests">
      <title>Competing Interests</title>
      <fn id="conflict-1" fn-type="COI-statement">
        <p>The authors declare there are no competing interests.</p>
      </fn>
    </fn-group>
    <fn-group content-type="author-contributions">
      <title>Author Contributions</title>
      <fn id="contribution-1" fn-type="con">
        <p><xref ref-type="contrib" rid="author-1">Nguyen Quoc Khanh Le</xref> conceived and designed the experiments, performed the experiments, analyzed the data, contributed reagents/materials/analysis tools, prepared figures and/or tables, performed the computation work, authored or reviewed drafts of the paper, approved the final draft.</p>
      </fn>
      <fn id="contribution-2" fn-type="con">
        <p><xref ref-type="contrib" rid="author-2">Van-Nui Nguyen</xref> conceived and designed the experiments, authored or reviewed drafts of the paper, approved the final draft.</p>
      </fn>
    </fn-group>
    <fn-group content-type="other">
      <title>Data Availability</title>
      <fn id="addinfo-1">
        <p>The following information was supplied regarding data availability:</p>
        <p>Data is available at GitHub: <ext-link ext-link-type="uri" xlink:href="https://github.com/khanhlee/snare-cnn">https://github.com/khanhlee/snare-cnn</ext-link>.</p>
      </fn>
    </fn-group>
  </sec>
  <ref-list content-type="authoryear">
    <title>References</title>
    <ref id="ref-1">
      <label>Altschul et al. (1997)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Altschul</surname>
            <given-names>SF</given-names>
          </name>
          <name>
            <surname>Madden</surname>
            <given-names>TL</given-names>
          </name>
          <name>
            <surname>Schäffer</surname>
            <given-names>AA</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Miller</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Lipman</surname>
            <given-names>DJ</given-names>
          </name>
        </person-group>
        <year>1997</year>
        <article-title>Gapped BLAST and PSI-BLAST: a new generation of protein database search programs</article-title>
        <source>Nucleic Acids Research</source>
        <volume>25</volume>
        <issue>17</issue>
        <fpage>3389</fpage>
        <lpage>3402</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/25.17.3389</pub-id>
        <pub-id pub-id-type="pmid">9254694</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-2">
      <label>Amidi et al. (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Amidi</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Amidi</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Vlachakis</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Megalooikonomou</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Paragios</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Zacharaki</surname>
            <given-names>EI</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <article-title>EnzyNet: enzyme classification using 3D convolutional neural networks on spatial representation</article-title>
        <source>PeerJ</source>
        <volume>6</volume>
        <elocation-id>e4750</elocation-id>
        <pub-id pub-id-type="doi">10.7717/peerj.4750</pub-id>
        <pub-id pub-id-type="pmid">29740518</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-3">
      <label>Burlet &amp; Hindle (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Burlet</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Hindle</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>Isolated guitar transcription using a deep belief network</article-title>
        <source>PeerJ Computer Science</source>
        <volume>3</volume>
        <elocation-id>e109</elocation-id>
        <pub-id pub-id-type="doi">10.7717/peerj-cs.109</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-4">
      <label>Chang &amp; Lin (2011)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chang</surname>
            <given-names>C-C</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>C-J</given-names>
          </name>
        </person-group>
        <year>2011</year>
        <article-title>LIBSVM: a library for support vector machines</article-title>
        <source>ACM Transactions on Intelligent Systems and Technology</source>
        <volume>2</volume>
        <issue>3</issue>
        <comment>Article 27</comment>
      </element-citation>
    </ref>
    <ref id="ref-5">
      <label>Chen et al. (2007)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2007</year>
        <article-title>Prediction of linear B-cell epitopes using amino acid pair antigenicity scale</article-title>
        <source>Amino Acids</source>
        <volume>33</volume>
        <issue>3</issue>
        <fpage>423</fpage>
        <lpage>428</lpage>
        <pub-id pub-id-type="doi">10.1007/s00726-006-0485-9</pub-id>
        <pub-id pub-id-type="pmid">17252308</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-6">
      <label>Chen et al. (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <article-title>iRNA(m6A)-PseDNC: identifying N6-methyladenosine sites using pseudo dinucleotide composition</article-title>
        <source>Analytical Biochemistry</source>
        <volume>561–562</volume>
        <fpage>59</fpage>
        <lpage>65</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ab.2018.09.002</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-7">
      <label>Chen et al. (2013)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Feng</surname>
            <given-names>P-M</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2013</year>
        <article-title>iRSpot-PseDNC: identify recombination spots with pseudo dinucleotide composition</article-title>
        <source>Nucleic Acids Research</source>
        <volume>41</volume>
        <issue>6</issue>
        <elocation-id>e68-e68</elocation-id>
        <pub-id pub-id-type="doi">10.1093/nar/gks1450</pub-id>
        <pub-id pub-id-type="pmid">23303794</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-8">
      <label>Cheng, Xiao &amp; Chou (2017a)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2017a</year>
        <article-title>pLoc-mPlant: predict subcellular localization of multi-location plant proteins by incorporating the optimal GO information into general PseAAC</article-title>
        <source>Molecular BioSystems</source>
        <volume>13</volume>
        <issue>9</issue>
        <fpage>1722</fpage>
        <lpage>1727</lpage>
        <pub-id pub-id-type="doi">10.1039/C7MB00267J</pub-id>
        <pub-id pub-id-type="pmid">28702580</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-9">
      <label>Cheng, Xiao &amp; Chou (2017b)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2017b</year>
        <article-title>pLoc-mVirus: predict subcellular localization of multi-location virus proteins via incorporating the optimal GO information into general PseAAC</article-title>
        <source>Gene</source>
        <volume>628</volume>
        <fpage>315</fpage>
        <lpage>321</lpage>
        <pub-id pub-id-type="doi">10.1016/j.gene.2017.07.036</pub-id>
        <pub-id pub-id-type="pmid">28728979</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-10">
      <label>Cheng, Xiao &amp; Chou (2018a)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2018a</year>
        <article-title>pLoc-mEuk: predict subcellular localization of multi-label eukaryotic proteins by extracting the key GO information into general PseAAC</article-title>
        <source>Genomics</source>
        <volume>110</volume>
        <issue>1</issue>
        <fpage>50</fpage>
        <lpage>58</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ygeno.2017.08.005</pub-id>
        <pub-id pub-id-type="pmid">28818512</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-11">
      <label>Cheng, Xiao &amp; Chou (2018b)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2018b</year>
        <article-title>pLoc-mGneg: Predict subcellular localization of Gram-negative bacterial proteins by deep gene ontology learning via general PseAAC</article-title>
        <source>Genomics</source>
        <volume>110</volume>
        <issue>4</issue>
        <fpage>231</fpage>
        <lpage>239</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ygeno.2017.10.002</pub-id>
        <pub-id pub-id-type="pmid">29074368</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-12">
      <label>Cheng et al. (2017a)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>S-G</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>W-Z</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2017a</year>
        <article-title>pLoc-mAnimal: predict subcellular localization of animal proteins with both single and multiple sites</article-title>
        <source>Bioinformatics</source>
        <volume>33</volume>
        <issue>22</issue>
        <fpage>3524</fpage>
        <lpage>3531</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btx476</pub-id>
        <pub-id pub-id-type="pmid">29036535</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-13">
      <label>Cheng et al. (2017b)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>S-G</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2017b</year>
        <article-title>iATC-mISF: a multi-label classifier for predicting the classes of anatomical therapeutic chemicals</article-title>
        <source>Bioinformatics</source>
        <volume>33</volume>
        <issue>3</issue>
        <fpage>341</fpage>
        <lpage>346</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw644</pub-id>
        <pub-id pub-id-type="pmid">28172617</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-14">
      <label>Chou (2001)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2001</year>
        <article-title>Prediction of signal peptides using scaled window</article-title>
        <source>Peptides</source>
        <volume>22</volume>
        <issue>12</issue>
        <fpage>1973</fpage>
        <lpage>1979</lpage>
        <pub-id pub-id-type="doi">10.1016/S0196-9781(01)00540-x</pub-id>
        <pub-id pub-id-type="pmid">11786179</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-15">
      <label>Chou (2011)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2011</year>
        <article-title>Some remarks on protein attribute prediction and pseudo amino acid composition</article-title>
        <source>Journal of Theoretical Biology</source>
        <volume>273</volume>
        <issue>1</issue>
        <fpage>236</fpage>
        <lpage>247</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2010.12.024</pub-id>
        <pub-id pub-id-type="pmid">21168420</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-16">
      <label>Chou (2013)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2013</year>
        <article-title>Some remarks on predicting multi-label attributes in molecular biosystems</article-title>
        <source>Molecular BioSystems</source>
        <volume>9</volume>
        <issue>6</issue>
        <fpage>1092</fpage>
        <lpage>1100</lpage>
        <pub-id pub-id-type="doi">10.1039/C3MB25555G</pub-id>
        <pub-id pub-id-type="pmid">23536215</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-17">
      <label>Chou (2015)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2015</year>
        <article-title>Impacts of bioinformatics to medicinal chemistry</article-title>
        <source>Medicinal Chemistry</source>
        <volume>11</volume>
        <issue>3</issue>
        <fpage>218</fpage>
        <lpage>234</lpage>
        <pub-id pub-id-type="doi">10.2174/1573406411666141229162834</pub-id>
        <pub-id pub-id-type="pmid">25548930</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-18">
      <label>Chou (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>An unprecedented revolution in medicinal chemistry driven by the progress of biological science</article-title>
        <source>Current Topics in Medicinal Chemistry</source>
        <volume>17</volume>
        <issue>21</issue>
        <fpage>2337</fpage>
        <lpage>2358</lpage>
        <pub-id pub-id-type="doi">10.2174/1568026617666170414145508</pub-id>
        <pub-id pub-id-type="pmid">28413951</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-19">
      <label>Chou, Cheng &amp; Xiao (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <article-title>pLoc_bal-mHum: predict subcellular localization of human proteins by PseAAC and quasi-balancing training dataset</article-title>
        <source>Genomics</source>
        <pub-id pub-id-type="doi">10.1016/j.ygeno.2018.08.007</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-20">
      <label>Feng et al. (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Feng</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <article-title>iDNA6mA-PseKNC: identifying DNA N6-methyladenosine sites by incorporating nucleotide physicochemical properties into PseKNC</article-title>
        <source>Genomics</source>
        <volume>111</volume>
        <issue>1</issue>
        <fpage>96</fpage>
        <lpage>102</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ygeno.2018.01.005</pub-id>
        <pub-id pub-id-type="pmid">29360500</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-21">
      <label>Feng et al. (2013)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Feng</surname>
            <given-names>P-M</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2013</year>
        <article-title>iHSP-PseRAAAC: identifying the heat shock protein families using pseudo reduced amino acid alphabet composition</article-title>
        <source>Analytical Biochemistry</source>
        <volume>442</volume>
        <issue>1</issue>
        <fpage>118</fpage>
        <lpage>125</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ab.2013.05.024</pub-id>
        <pub-id pub-id-type="pmid">23756733</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-22">
      <label>Fernandes et al. (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Fernandes</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Chicco</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Cardoso</surname>
            <given-names>JS</given-names>
          </name>
          <name>
            <surname>Fernandes</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <article-title>Supervised deep learning embeddings for the prediction of cervical cancer diagnosis</article-title>
        <source>PeerJ Computer Science</source>
        <volume>4</volume>
        <elocation-id>e154</elocation-id>
        <pub-id pub-id-type="doi">10.7717/peerj-cs.154</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-23">
      <label>Honer et al. (2002)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Honer</surname>
            <given-names>WG</given-names>
          </name>
          <name>
            <surname>Falkai</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Bayer</surname>
            <given-names>TA</given-names>
          </name>
          <name>
            <surname>Xie</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>H-Y</given-names>
          </name>
          <name>
            <surname>Arango</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Mann</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Dwork</surname>
            <given-names>AJ</given-names>
          </name>
          <name>
            <surname>Trimble</surname>
            <given-names>WS</given-names>
          </name>
        </person-group>
        <year>2002</year>
        <article-title>Abnormalities of SNARE mechanism proteins in anterior frontal cortex in severe mental illness</article-title>
        <source>Cerebral Cortex</source>
        <volume>12</volume>
        <issue>4</issue>
        <fpage>349</fpage>
        <lpage>356</lpage>
        <pub-id pub-id-type="doi">10.1093/cercor/12.4.349</pub-id>
        <pub-id pub-id-type="pmid">11884350</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-24">
      <label>Hou et al. (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hou</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Long</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>Neurodegenerative disease related proteins have negative effects on SNARE-mediated membrane fusion in pathological confirmation</article-title>
        <source>Frontiers in Molecular Neuroscience</source>
        <volume>10</volume>
        <fpage>66</fpage>
        <pub-id pub-id-type="doi">10.3389/fnmol.2017.00066</pub-id>
        <pub-id pub-id-type="pmid">28377692</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-25">
      <label>Jahn &amp; Scheller (2006)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jahn</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Scheller</surname>
            <given-names>RH</given-names>
          </name>
        </person-group>
        <year>2006</year>
        <article-title>SNAREs—engines for membrane fusion</article-title>
        <source>Nature Reviews Molecular Cell Biology</source>
        <volume>7</volume>
        <fpage>631</fpage>
        <lpage>643</lpage>
        <pub-id pub-id-type="doi">10.1038/nrm2002</pub-id>
        <pub-id pub-id-type="pmid">16912714</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-26">
      <label>Jia et al. (2019)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jia</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2019</year>
        <article-title>iPPI-PseAAC(CGR): Identify protein-protein interactions by incorporating chaos game representation into PseAAC</article-title>
        <source>Journal of Theoretical Biology</source>
        <volume>460</volume>
        <fpage>195</fpage>
        <lpage>203</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jtbi.2018.10.021</pub-id>
        <pub-id pub-id-type="pmid">30312687</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-27">
      <label>Jones (1999)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jones</surname>
            <given-names>DT</given-names>
          </name>
        </person-group>
        <year>1999</year>
        <article-title>Protein secondary structure prediction based on position-specific scoring matrices1</article-title>
        <source>Journal of Molecular Biology</source>
        <volume>292</volume>
        <issue>2</issue>
        <fpage>195</fpage>
        <lpage>202</lpage>
        <pub-id pub-id-type="doi">10.1006/jmbi.1999.3091</pub-id>
        <pub-id pub-id-type="pmid">10493868</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-28">
      <label>Khan et al. (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Khan</surname>
            <given-names>YD</given-names>
          </name>
          <name>
            <surname>Rasool</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hussain</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Khan</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <article-title>iPhosT-PseAAC: identify phosphothreonine sites by incorporating sequence statistical moments into PseAAC</article-title>
        <source>Analytical Biochemistry</source>
        <volume>550</volume>
        <fpage>109</fpage>
        <lpage>116</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ab.2018.04.021</pub-id>
        <pub-id pub-id-type="pmid">29704476</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-29">
      <label>Kienle, Kloepper &amp; Fasshauer (2009)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kienle</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Kloepper</surname>
            <given-names>TH</given-names>
          </name>
          <name>
            <surname>Fasshauer</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <year>2009</year>
        <article-title>Phylogeny of the SNARE vesicle fusion machinery yields insights into the conservation of the secretory pathway in fungi</article-title>
        <source>BMC Evolutionary Biology</source>
        <volume>9</volume>
        <issue>1</issue>
        <fpage>19</fpage>
        <pub-id pub-id-type="doi">10.1186/1471-2148-9-19</pub-id>
        <pub-id pub-id-type="pmid">19166604</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-30">
      <label>Kloepper, Kienle &amp; Fasshauer (2007)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kloepper</surname>
            <given-names>TH</given-names>
          </name>
          <name>
            <surname>Kienle</surname>
            <given-names>CN</given-names>
          </name>
          <name>
            <surname>Fasshauer</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <year>2007</year>
        <article-title>An elaborate classification of SNARE proteins sheds light on the conservation of the eukaryotic endomembrane system</article-title>
        <source>Molecular Biology of the Cell</source>
        <volume>18</volume>
        <issue>9</issue>
        <fpage>3463</fpage>
        <lpage>3471</lpage>
        <pub-id pub-id-type="doi">10.1091/mbc.e07-03-0193</pub-id>
        <pub-id pub-id-type="pmid">17596510</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-31">
      <label>Kloepper, Kienle &amp; Fasshauer (2008)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Kloepper</surname>
            <given-names>TH</given-names>
          </name>
          <name>
            <surname>Kienle</surname>
            <given-names>CN</given-names>
          </name>
          <name>
            <surname>Fasshauer</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <year>2008</year>
        <article-title>SNAREing the basis of multicellularity: consequences of protein family expansion during evolution</article-title>
        <source>Molecular Biology and Evolution</source>
        <volume>25</volume>
        <issue>9</issue>
        <fpage>2055</fpage>
        <lpage>2068</lpage>
        <pub-id pub-id-type="doi">10.1093/molbev/msn151</pub-id>
        <pub-id pub-id-type="pmid">18621745</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-32">
      <label>Le, Ho &amp; Ou (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Le</surname>
            <given-names>NQK</given-names>
          </name>
          <name>
            <surname>Ho</surname>
            <given-names>Q-T</given-names>
          </name>
          <name>
            <surname>Ou</surname>
            <given-names>Y-Y</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>Incorporating deep learning with convolutional neural networks and position specific scoring matrices for identifying electron transport proteins</article-title>
        <source>Journal of Computational Chemistry</source>
        <volume>38</volume>
        <issue>23</issue>
        <fpage>2000</fpage>
        <lpage>2006</lpage>
        <pub-id pub-id-type="doi">10.1002/jcc.24842</pub-id>
        <pub-id pub-id-type="pmid">28643394</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-33">
      <label>Le, Ho &amp; Ou (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Le</surname>
            <given-names>NQK</given-names>
          </name>
          <name>
            <surname>Ho</surname>
            <given-names>Q-T</given-names>
          </name>
          <name>
            <surname>Ou</surname>
            <given-names>Y-Y</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <article-title>Classifying the molecular functions of Rab GTPases in membrane trafficking using deep convolutional neural networks</article-title>
        <source>Analytical Biochemistry</source>
        <volume>555</volume>
        <fpage>33</fpage>
        <lpage>41</lpage>
        <pub-id pub-id-type="doi">10.1016/j.ab.2018.06.011</pub-id>
        <pub-id pub-id-type="pmid">29908156</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-34">
      <label>Le, Ho &amp; Ou (2019)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Le</surname>
            <given-names>NQK</given-names>
          </name>
          <name>
            <surname>Ho</surname>
            <given-names>Q-T</given-names>
          </name>
          <name>
            <surname>Ou</surname>
            <given-names>Y-Y</given-names>
          </name>
        </person-group>
        <year>2019</year>
        <article-title>Using two-dimensional convolutional neural networks for identifying GTP binding sites in Rab proteins</article-title>
        <source>Journal of Bioinformatics and Computational Biology</source>
        <volume>17</volume>
        <issue>1</issue>
        <fpage>1950005</fpage>
        <pub-id pub-id-type="doi">10.1142/s0219720019500057</pub-id>
        <pub-id pub-id-type="pmid">30866734</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-35">
      <label>Le, Nguyen &amp; Ou (2017)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Le</surname>
            <given-names>NQK</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>T-T-D</given-names>
          </name>
          <name>
            <surname>Ou</surname>
            <given-names>Y-Y</given-names>
          </name>
        </person-group>
        <year>2017</year>
        <article-title>Identifying the molecular functions of electron transport proteins using radial basis function networks and biochemical properties</article-title>
        <source>Journal of Molecular Graphics and Modelling</source>
        <volume>73</volume>
        <fpage>166</fpage>
        <lpage>178</lpage>
        <pub-id pub-id-type="doi">10.1016/j.jmgm.2017.01.003</pub-id>
        <pub-id pub-id-type="pmid">28285094</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-36">
      <label>Le &amp; Ou (2016a)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Le</surname>
            <given-names>NQK</given-names>
          </name>
          <name>
            <surname>Ou</surname>
            <given-names>Y-Y</given-names>
          </name>
        </person-group>
        <year>2016a</year>
        <article-title>Incorporating efficient radial basis function networks and significant amino acid pairs for predicting GTP binding sites in transport proteins</article-title>
        <source>BMC Bioinformatics</source>
        <volume>17</volume>
        <issue>19</issue>
        <fpage>501</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-016-1369-y</pub-id>
        <pub-id pub-id-type="pmid">28155651</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-37">
      <label>Le &amp; Ou (2016b)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Le</surname>
            <given-names>NQK</given-names>
          </name>
          <name>
            <surname>Ou</surname>
            <given-names>Y-Y</given-names>
          </name>
        </person-group>
        <year>2016b</year>
        <article-title>Prediction of FAD binding sites in electron transport proteins according to efficient radial basis function networks and significant amino acid pairs</article-title>
        <source>BMC Bioinformatics</source>
        <volume>17</volume>
        <issue>1</issue>
        <fpage>298</fpage>
        <pub-id pub-id-type="doi">10.1186/s12859-016-1163-x</pub-id>
        <pub-id pub-id-type="pmid">27475771</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-38">
      <label>Le, Sandag &amp; Ou (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Le</surname>
            <given-names>NQK</given-names>
          </name>
          <name>
            <surname>Sandag</surname>
            <given-names>GA</given-names>
          </name>
          <name>
            <surname>Ou</surname>
            <given-names>Y-Y</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <article-title>Incorporating post translational modification information for enhancing the predictive performance of membrane transport proteins</article-title>
        <source>Computational Biology and Chemistry</source>
        <volume>77</volume>
        <fpage>251</fpage>
        <lpage>260</lpage>
        <pub-id pub-id-type="doi">10.1016/j.compbiolchem.2018.10.010</pub-id>
        <pub-id pub-id-type="pmid">30393099</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-39">
      <label>LeCun, Bengio &amp; Hinton (2015)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>LeCun</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Bengio</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <year>2015</year>
        <article-title>Deep learning</article-title>
        <source>Nature</source>
        <volume>521</volume>
        <issue>7553</issue>
        <fpage>436</fpage>
        <lpage>444</lpage>
        <pub-id pub-id-type="doi">10.1038/nature14539</pub-id>
        <pub-id pub-id-type="pmid">26017442</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-40">
      <label>Lu (2015)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lu</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <year>2015</year>
        <article-title>The destructive effect of botulinum neurotoxins on the SNARE protein: SNAP-25 and synaptic membrane fusion</article-title>
        <source>PeerJ</source>
        <volume>3</volume>
        <elocation-id>e1065</elocation-id>
        <pub-id pub-id-type="doi">10.7717/peerj.1065</pub-id>
        <pub-id pub-id-type="pmid">26157630</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-41">
      <label>Meng &amp; Wang (2015)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Meng</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <year>2015</year>
        <article-title>Role of SNARE proteins in tumourigenesis and their potential as targets for novel anti-cancer therapeutics</article-title>
        <source>Biochimica et Biophysica Acta (BBA) - Reviews on Cancer</source>
        <volume>1856</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>12</lpage>
        <pub-id pub-id-type="doi">10.1016/j.bbcan.2015.04.002</pub-id>
        <pub-id pub-id-type="pmid">25956199</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-42">
      <label>Ou, Chen &amp; Gromiha (2010)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ou</surname>
            <given-names>YY</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>SA</given-names>
          </name>
          <name>
            <surname>Gromiha</surname>
            <given-names>MM</given-names>
          </name>
        </person-group>
        <year>2010</year>
        <article-title>Classification of transporters using efficient radial basis function networks with position-specific scoring matrices and biochemical properties</article-title>
        <source>Proteins: Structure, Function, and Bioinformatics</source>
        <volume>78</volume>
        <issue>7</issue>
        <fpage>1789</fpage>
        <lpage>1797</lpage>
        <pub-id pub-id-type="doi">10.1002/prot.22694</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-43">
      <label>Oyang et al. (2005)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Oyang</surname>
            <given-names>Y-J</given-names>
          </name>
          <name>
            <surname>Hwang</surname>
            <given-names>S-C</given-names>
          </name>
          <name>
            <surname>Ou</surname>
            <given-names>Y-Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>C-Y</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Z-W</given-names>
          </name>
        </person-group>
        <year>2005</year>
        <article-title>Data classification with radial basis function networks based on a novel kernel density estimation algorithm</article-title>
        <source>IEEE Transactions on Neural Networks</source>
        <volume>16</volume>
        <issue>1</issue>
        <fpage>225</fpage>
        <lpage>236</lpage>
        <pub-id pub-id-type="doi">10.1109/TNN.2004.836229</pub-id>
        <pub-id pub-id-type="pmid">15732402</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-44">
      <label>Palatnik de Sousa (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Palatnik de Sousa</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <article-title>Convolutional ensembles for Arabic handwritten character and digit recognition</article-title>
        <source>PeerJ Computer Science</source>
        <volume>4</volume>
        <elocation-id>e167</elocation-id>
        <pub-id pub-id-type="doi">10.7717/peerj-cs.167</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-45">
      <label>Qiu et al. (2016)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Qiu</surname>
            <given-names>W-R</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>B-Q</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Z-C</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2016</year>
        <article-title>iPTM-mLys: identifying multiple lysine PTM sites and their different types</article-title>
        <source>Bioinformatics</source>
        <volume>32</volume>
        <issue>20</issue>
        <fpage>3116</fpage>
        <lpage>3123</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btw380</pub-id>
        <pub-id pub-id-type="pmid">27334473</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-46">
      <label>Shi et al. (2016)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shi</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Halder</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Yavuz</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Jahn</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Shuman</surname>
            <given-names>HA</given-names>
          </name>
        </person-group>
        <year>2016</year>
        <article-title>Direct targeting of membrane fusion by SNARE mimicry: convergent evolution of Legionella effectors</article-title>
        <source>Proceedings of the National Academy of Sciences of the United States of America</source>
        <volume>113</volume>
        <issue>31</issue>
        <fpage>8807</fpage>
        <lpage>8812</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.1608755113</pub-id>
        <pub-id pub-id-type="pmid">27436892</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-47">
      <label>Shimizu, Hirose &amp; Noguchi (2007)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shimizu</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Hirose</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Noguchi</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <year>2007</year>
        <article-title>POODLE-S: web application for predicting protein disorder by using physicochemical features and reduced amino acid set of a position-specific scoring matrix</article-title>
        <source>Bioinformatics</source>
        <volume>23</volume>
        <issue>17</issue>
        <fpage>2337</fpage>
        <lpage>2338</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btm330</pub-id>
        <pub-id pub-id-type="pmid">17599940</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-48">
      <label>Spencer, Eickholt &amp; Cheng (2015)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Spencer</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Eickholt</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <year>2015</year>
        <article-title>A deep learning network approach to ab initio protein secondary structure prediction</article-title>
        <source>IEEE/ACM Transactions on Computational Biology and Bioinformatics (TCBB)</source>
        <volume>12</volume>
        <issue>1</issue>
        <fpage>103</fpage>
        <lpage>112</lpage>
        <pub-id pub-id-type="doi">10.1109/TCBB.2014.2343960</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-49">
      <label>Srivastava et al. (2014)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Srivastava</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Krizhevsky</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Sutskever</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Salakhutdinov</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <year>2014</year>
        <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>
        <source>The Journal of Machine Learning Research</source>
        <volume>15</volume>
        <issue>1</issue>
        <fpage>1929</fpage>
        <lpage>1958</lpage>
      </element-citation>
    </ref>
    <ref id="ref-50">
      <label>Sun et al. (2016)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Sun</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Qu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Ren</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <year>2016</year>
        <article-title>SNAP23 promotes the malignant process of ovarian cancer</article-title>
        <source>Journal of Ovarian Research</source>
        <volume>9</volume>
        <issue>1</issue>
        <fpage>80</fpage>
        <pub-id pub-id-type="doi">10.1186/s13048-016-0289-9</pub-id>
        <pub-id pub-id-type="pmid">27855700</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-51">
      <label>Taju et al. (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Taju</surname>
            <given-names>SW</given-names>
          </name>
          <name>
            <surname>Nguyen</surname>
            <given-names>T-T-D</given-names>
          </name>
          <name>
            <surname>Le</surname>
            <given-names>N-Q-K</given-names>
          </name>
          <name>
            <surname>Kusuma</surname>
            <given-names>RMI</given-names>
          </name>
          <name>
            <surname>Ou</surname>
            <given-names>Y-Y</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <article-title>DeepEfflux: a 2D convolutional neural network model for identifying families of efflux proteins in transporters</article-title>
        <source>Bioinformatics</source>
        <volume>34</volume>
        <issue>18</issue>
        <fpage>3111</fpage>
        <lpage>3117</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/bty302</pub-id>
        <pub-id pub-id-type="pmid">29668844</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-52">
      <label>UniProt Consortium (2014)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <collab>UniProt Consortium</collab>
        </person-group>
        <year>2014</year>
        <article-title>UniProt: a hub for protein information</article-title>
        <source>Nucleic Acids Research</source>
        <volume>43</volume>
        <issue>D1</issue>
        <fpage>D204</fpage>
        <lpage>D212</lpage>
        <pub-id pub-id-type="doi">10.1093/nar/gku989</pub-id>
        <pub-id pub-id-type="pmid">25348405</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-53">
      <label>Van Dijk et al. (2008)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Van Dijk</surname>
            <given-names>ADJ</given-names>
          </name>
          <name>
            <surname>Bosch</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>ter Braak</surname>
            <given-names>CJF</given-names>
          </name>
          <name>
            <surname>van der Krol</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>van Ham</surname>
            <given-names>RCHJ</given-names>
          </name>
        </person-group>
        <year>2008</year>
        <article-title>Predicting sub-Golgi localization of type II membrane proteins</article-title>
        <source>Bioinformatics</source>
        <volume>24</volume>
        <issue>16</issue>
        <fpage>1779</fpage>
        <lpage>1786</lpage>
        <pub-id pub-id-type="doi">10.1093/bioinformatics/btn309</pub-id>
        <pub-id pub-id-type="pmid">18562268</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-54">
      <label>Wang, Hoeksema &amp; Liang (2018)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wang</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Hoeksema</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Liang</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <year>2018</year>
        <article-title>piRNN: deep learning algorithm for piRNA prediction</article-title>
        <source>PeerJ</source>
        <volume>6</volume>
        <elocation-id>e5429</elocation-id>
        <pub-id pub-id-type="doi">10.7717/peerj.5429</pub-id>
        <pub-id pub-id-type="pmid">30083483</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-55">
      <label>Weimbs et al. (1997)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Weimbs</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Low</surname>
            <given-names>SH</given-names>
          </name>
          <name>
            <surname>Chapin</surname>
            <given-names>SJ</given-names>
          </name>
          <name>
            <surname>Mostov</surname>
            <given-names>KE</given-names>
          </name>
          <name>
            <surname>Bucher</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Hofmann</surname>
            <given-names>K</given-names>
          </name>
        </person-group>
        <year>1997</year>
        <article-title>A conserved domain is present in different families of vesicular fusion proteins: a new superfamily</article-title>
        <source>Proceedings of the National Academy of Sciences of the United States of America</source>
        <volume>94</volume>
        <issue>7</issue>
        <fpage>3046</fpage>
        <lpage>3051</lpage>
        <pub-id pub-id-type="doi">10.1073/pnas.94.7.3046</pub-id>
        <pub-id pub-id-type="pmid">9096343</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-56">
      <label>Wickner &amp; Schekman (2008)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wickner</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Schekman</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <year>2008</year>
        <article-title>Membrane fusion</article-title>
        <source>Nature Structural &amp; Molecular Biology</source>
        <volume>15</volume>
        <issue>7</issue>
        <fpage>658</fpage>
        <pub-id pub-id-type="doi">10.1038/nsmb.1451</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-57">
      <label>Xiao et al. (2018a)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Cheng</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Mao</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2018a</year>
        <article-title>pLoc_bal-mGpos: predict subcellular localization of Gram-positive bacterial proteins by quasi-balancing training dataset and PseAAC</article-title>
        <source>Genomics</source>
        <pub-id pub-id-type="doi">10.1016/j.ygeno.2018.05.017</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-58">
      <label>Xiao et al. (2018b)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Z-C</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>W-R</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Ge</surname>
            <given-names>H-T</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2018b</year>
        <article-title>iPSW(2L)-PseKNC: a two-layer predictor for identifying promoters and their strength by hybrid features via pseudo K-tuple nucleotide composition</article-title>
        <source>Genomics</source>
        <pub-id pub-id-type="doi">10.1016/j.ygeno.2018.12.001</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-59">
      <label>Xu et al. (2013)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shao</surname>
            <given-names>X-J</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>L-Y</given-names>
          </name>
          <name>
            <surname>Deng</surname>
            <given-names>N-Y</given-names>
          </name>
          <name>
            <surname>Chou</surname>
            <given-names>K-C</given-names>
          </name>
        </person-group>
        <year>2013</year>
        <article-title>iSNO-AAPair: incorporating amino acid pairwise coupling into PseAAC for predicting cysteine S-nitrosylation sites in proteins</article-title>
        <source>PeerJ</source>
        <volume>1</volume>
        <elocation-id>e171</elocation-id>
        <pub-id pub-id-type="doi">10.7717/peerj.171</pub-id>
        <pub-id pub-id-type="pmid">24109555</pub-id>
      </element-citation>
    </ref>
    <ref id="ref-60">
      <label>Yoshizawa et al. (2006)</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yoshizawa</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Kawashima</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Okuda</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Fujita</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Itoh</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Moriya</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Hattori</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Kanehisa</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <year>2006</year>
        <article-title>Extracting sequence motifs and the phylogenetic features of SNARE-dependent membrane traffic</article-title>
        <source>Traffic</source>
        <volume>7</volume>
        <issue>8</issue>
        <fpage>1104</fpage>
        <lpage>1118</lpage>
        <pub-id pub-id-type="doi">10.1111/j.1600-0854.2006.00451.x</pub-id>
        <pub-id pub-id-type="pmid">16882042</pub-id>
      </element-citation>
    </ref>
  </ref-list>
</back>
