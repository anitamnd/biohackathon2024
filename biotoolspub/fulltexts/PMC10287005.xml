<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLOS Digit Health</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLOS Digit Health</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLOS Digital Health</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2767-3170</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10287005</article-id>
    <article-id pub-id-type="publisher-id">PDIG-D-22-00328</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pdig.0000276</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Epidemiology</subject>
          <subj-group>
            <subject>Medical Risk Factors</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Endocrinology</subject>
          <subj-group>
            <subject>Endocrine Disorders</subject>
            <subj-group>
              <subject>Diabetes Mellitus</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Medical Conditions</subject>
          <subj-group>
            <subject>Metabolic Disorders</subject>
            <subj-group>
              <subject>Diabetes Mellitus</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and health sciences</subject>
        <subj-group>
          <subject>Diagnostic medicine</subject>
          <subj-group>
            <subject>Diabetes diagnosis and management</subject>
            <subj-group>
              <subject>HbA1c</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and life sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Hemoglobin</subject>
              <subj-group>
                <subject>HbA1c</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Computational Techniques</subject>
          <subj-group>
            <subject>Computational Pipelines</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
              <subj-group>
                <subject>Machine Learning Algorithms</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Statistical Methods</subject>
            <subj-group>
              <subject>Forecasting</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical Methods</subject>
              <subj-group>
                <subject>Forecasting</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Optimization</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>AutoPrognosis 2.0: Democratizing diagnostic and prognostic modeling in healthcare with automated machine learning</article-title>
      <alt-title alt-title-type="running-head">AutoPrognosis 2.0: Diagnostic and prognostic modeling with AutoML</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6241-0123</contrib-id>
        <name>
          <surname>Imrie</surname>
          <given-names>Fergus</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cebere</surname>
          <given-names>Bogdan</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>McKinney</surname>
          <given-names>Eoin F.</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff003" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>van der Schaar</surname>
          <given-names>Mihaela</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff004" ref-type="aff">
          <sup>4</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Department of Electrical and Computer Engineering, University of California, Los Angeles, California, United States of America</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Department of Applied Mathematics and Theoretical Physics, University of Cambridge, Cambridge, United Kingdom</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Department of Medicine, University of Cambridge, Cambridge, United Kingdom</addr-line>
    </aff>
    <aff id="aff004">
      <label>4</label>
      <addr-line>The Alan Turing Institute, London, United Kingdom</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Guillot</surname>
          <given-names>Gilles</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>CSL Behring / Swiss Institute for Translational and Entrepreneurial Medicine (SITEM), SWITZERLAND</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have no competing interests to declare.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>imrie@ucla.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <volume>2</volume>
    <issue>6</issue>
    <elocation-id>e0000276</elocation-id>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>17</day>
        <month>5</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 Imrie et al</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Imrie et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pdig.0000276.pdf"/>
    <abstract>
      <p>Diagnostic and prognostic models are increasingly important in medicine and inform many clinical decisions. Recently, machine learning approaches have shown improvement over conventional modeling techniques by better capturing complex interactions between patient covariates in a data-driven manner. However, the use of machine learning introduces technical and practical challenges that have thus far restricted widespread adoption of such techniques in clinical settings. To address these challenges and empower healthcare professionals, we present an open-source machine learning framework, AutoPrognosis 2.0, to facilitate the development of diagnostic and prognostic models. AutoPrognosis leverages state-of-the-art advances in automated machine learning to develop optimized machine learning pipelines, incorporates model explainability tools, and enables deployment of clinical demonstrators, <italic toggle="yes">without</italic> requiring significant technical expertise. To demonstrate AutoPrognosis 2.0, we provide an illustrative application where we construct a prognostic risk score for diabetes using the UK Biobank, a prospective study of 502,467 individuals. The models produced by our automated framework achieve greater discrimination for diabetes than expert clinical risk scores. We have implemented our risk score as a web-based decision support tool, which can be publicly accessed by patients and clinicians. By open-sourcing our framework as a tool for the community, we aim to provide clinicians and other medical practitioners with an accessible resource to develop new risk scores, personalized diagnostics, and prognostics using machine learning techniques.</p>
      <p><bold>Software</bold>: <ext-link xlink:href="https://github.com/vanderschaarlab/AutoPrognosis" ext-link-type="uri">https://github.com/vanderschaarlab/AutoPrognosis</ext-link></p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>Previous studies have reported promising applications of machine learning (ML) approaches in healthcare. However, there remain significant challenges to using ML for diagnostic and prognostic modeling, particularly for non-ML experts, that currently prevent broader adoption of these approaches. We developed an open-source tool, AutoPrognosis 2.0, to address these challenges and make modern statistical and machine learning methods available to expert and non-expert ML users. AutoPrognosis configures and optimizes ML pipelines using automated machine learning to develop powerful predictive models, while also providing interpretability methods to allow users to understand and debug these models. This study illustrates the application of AutoPrognosis to diabetes risk prediction using data from UK Biobank. The risk score developed using AutoPrognosis outperforms existing risk scores and has been implemented as a web-based decision support tool that can be publicly accessed by patients and clinicians. This study suggests that AutoPrognosis 2.0 can be used by healthcare experts to create new clinical tools and predictive pipelines across various clinical outcomes, employing advanced machine learning techniques.</p>
    </abstract>
    <funding-group>
      <funding-statement>The authors received no specific funding for this work.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="6"/>
      <page-count count="21"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>This research has been conducted using the UK Biobank resource. Data from UK Biobank is accessible through a request process (<ext-link xlink:href="https://www.ukbiobank.ac.uk/enable-your-research/register" ext-link-type="uri">https://www.ukbiobank.ac.uk/enable-your-research/register</ext-link>). The authors had no special access or privileges when accessing the data.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>This research has been conducted using the UK Biobank resource. Data from UK Biobank is accessible through a request process (<ext-link xlink:href="https://www.ukbiobank.ac.uk/enable-your-research/register" ext-link-type="uri">https://www.ukbiobank.ac.uk/enable-your-research/register</ext-link>). The authors had no special access or privileges when accessing the data.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Machine learning (ML) systems have the potential to revolutionize medicine and become core clinical tools [<xref rid="pdig.0000276.ref001" ref-type="bibr">1</xref>]. However, there are a diverse set of challenges that must be overcome prior to routine and widespread ML adoption [<xref rid="pdig.0000276.ref002" ref-type="bibr">2</xref>, <xref rid="pdig.0000276.ref003" ref-type="bibr">3</xref>]. In particular, there are substantial technical challenges in developing, understanding, and deploying ML systems which currently render them largely inaccessible for medical practitioners [<xref rid="pdig.0000276.ref003" ref-type="bibr">3</xref>–<xref rid="pdig.0000276.ref006" ref-type="bibr">6</xref>].</p>
    <p>In an attempt to address this, we previously developed AutoPrognosis, an automated machine learning (AutoML) framework that optimizes predictive pipelines [<xref rid="pdig.0000276.ref007" ref-type="bibr">7</xref>]. AutoML aims to automate various aspects of the machine learning process. Initial AutoML approaches performed Neural Architecture Search [<xref rid="pdig.0000276.ref008" ref-type="bibr">8</xref>] or hyperparameter optimization [<xref rid="pdig.0000276.ref009" ref-type="bibr">9</xref>]. More recently, prior work has focused on both selecting the best algorithm and optimizing its hyperparameters from a pre-defined set, known as the combined algorithm selection and hyperparameter optimization (CASH) problem [<xref rid="pdig.0000276.ref010" ref-type="bibr">10</xref>, <xref rid="pdig.0000276.ref011" ref-type="bibr">11</xref>]. However, limited work focused on optimizing full ML <italic toggle="yes">pipelines</italic>, and almost all existing frameworks could only handle complete data (i.e. without missing values) and did not construct model ensembles. The initial version of AutoPrognosis [<xref rid="pdig.0000276.ref007" ref-type="bibr">7</xref>] incorporated these components in an efficient manner, employing a novel Bayesian Optimization procedure using structured kernels to solve the pipeline selection and configuration problem (PSCP). Our framework has been since applied to derive prognostic models for cardiovascular disease [<xref rid="pdig.0000276.ref012" ref-type="bibr">12</xref>], cystic fibrosis [<xref rid="pdig.0000276.ref013" ref-type="bibr">13</xref>], and breast cancer [<xref rid="pdig.0000276.ref014" ref-type="bibr">14</xref>], among a number of other indications [<xref rid="pdig.0000276.ref015" ref-type="bibr">15</xref>–<xref rid="pdig.0000276.ref021" ref-type="bibr">21</xref>]. However, our initial approach had significant limitations from both algorithmic and usability perspectives. Perhaps most significantly, it was limited to classification, did not include interpretability methods, and did not readily allow models to be shared.</p>
    <p>Consequently, in this work, we describe AutoPrognosis 2.0, a framework that addresses several major obstacles limiting the development, interpretation, and deployment of ML methods in medicine. To the best of our knowledge, this is the first approach that can simultaneously: (1) solve classification, regression, and time-to-event problems; (2) optimize ML pipelines, determine the most appropriate models, and automatically tune hyperparameters; (3) identify key variables and novel risk factors, enabling clinicians to select different numbers of variables and understand the value of information; (4) provide a diverse range of model explanations, including feature-based, example-based, and closed-form risk equations; and (5) produce web-based applications, allowing models to be readily shared with the clinical community.</p>
    <p>After describing AutoPrognosis 2.0, we outline major challenges facing clinical development and translation of diagnostic and prognostic modeling, and detail how AutoPrognosis addresses each challenge. Finally, we demonstrate the application of AutoPrognosis 2.0 in an illustrative scenario: prognostic risk prediction of diabetes using a cohort of 502,467 individuals from UK Biobank. However, we emphasize that AutoPrognosis can be applied to construct diagnostic and prognostic models for <italic toggle="yes">any</italic> disease or clinical outcome, and is explicitly designed to make model building accessible to both experts and non-ML experts. We have open-sourced AutoPrognosis 2.0 as a tool for the community, allowing model developers of all levels of expertise to robustly and reproducibly develop optimized personalized diagnostics, prognostics, and risk scores using modern machine learning techniques.</p>
  </sec>
  <sec id="sec002">
    <title>Methods: AutoPrognosis 2.0</title>
    <p>AutoPrognosis 2.0 is an algorithmic framework and software package that allows healthcare professionals to leverage ML to develop diagnostic and prognostic models. Our framework employs automated machine learning [<xref rid="pdig.0000276.ref011" ref-type="bibr">11</xref>] to tackle the challenges faced by clinical users. By automating the optimization of ML pipelines involving data processing, model development, and model training, we reduce the burden on technical experts and turn deriving ML models from an art to a science, democratizing machine learning and opening the field to non-ML domain experts, such as clinicians. We believe that AutoPrognosis 2.0 represents a step-change in algorithmic and software capabilities and can unlock the potential of ML in healthcare for clinical researchers <italic toggle="yes">without</italic> the requirement for extensive technical capabilities.</p>
    <p>AutoPrognosis 2.0 empowers users with the following capabilities:</p>
    <list list-type="order">
      <list-item>
        <p>Build highly performant ML pipelines for classification, regression, and time-to-event analysis, optimized specifically for the data at hand.</p>
      </list-item>
      <list-item>
        <p>Understand when ML provides benefits over traditional regression models, and thus when ML is valuable.</p>
      </list-item>
      <list-item>
        <p>Enable principled selection of variables and allow users to understand the value of information.</p>
      </list-item>
      <list-item>
        <p>Explain and debug how ML models issue predictions using diverse interpretability methods.</p>
      </list-item>
      <list-item>
        <p>Update systems whenever the available data changes to ensure the best possible clinical models.</p>
      </list-item>
      <list-item>
        <p>Provide confidence in the reproducibility of models.</p>
      </list-item>
    </list>
    <sec id="sec003">
      <title>Overview</title>
      <p>After a clinician has determined an appropriate cohort of patients and an outcome of interest, the AutoPrognosis framework handles all steps in the computational pipeline: missing data imputation, feature processing, model selection and fitting, model interpretability or explanations, and production of clinical demonstrators. Together, we believe AutoPrognosis significantly reduces the technical expertise necessary to derive powerful prognostic models, empowering clinical users and democratizing machine learning in healthcare.</p>
      <p>AutoPrognosis is provided as an open-source package at <ext-link xlink:href="https://github.com/vanderschaarlab/AutoPrognosis" ext-link-type="uri">https://github.com/vanderschaarlab/AutoPrognosis</ext-link> and can be readily installed with PyPI (<ext-link xlink:href="https://pypi.org/project/autoprognosis/" ext-link-type="uri">https://pypi.org/project/autoprognosis/</ext-link>). AutoPrognosis is primarily intended as a Python package, but we also provide bindings for R users. AutoPrognosis 2.0 requires only basic familiarity with either language for successful deployment. Note that, as for any computational approach, care must be taken when preparing data for use with AutoPrognosis. However, while the package cannot prevent input of inappropriate data (as no package can), it does ensure the selection of appropriate and optimal methods and hyperparameters for each step in the pipeline outlined in <xref rid="pdig.0000276.t001" ref-type="table">Table 1</xref>. An overview of AutoPrognosis 2.0 is provided in <xref rid="pdig.0000276.g001" ref-type="fig">Fig 1</xref>. Below, we provide a summary of each of the core components of AutoPrognosis.</p>
      <fig position="float" id="pdig.0000276.g001">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>Overview of the AutoPrognosis 2.0 framework.</title>
          <p>AutoPrognosis takes as input a medical dataset and provides an imputed dataset, a report detailing the optimized machine learning pipelines, a diagnostic or prognostic model, explanations, and a web-based interface for clinicians to interact with and use the derived model.</p>
        </caption>
        <graphic xlink:href="pdig.0000276.g001" position="float"/>
      </fig>
      <table-wrap position="float" id="pdig.0000276.t001">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>List of algorithms currently included in AutoPrognosis 2.0.</title>
          <p>Algorithms grouped by pipeline stage. Numbers in brackets correspond to the number of hyperparameters optimized over by AutoPrognosis. AutoPrognosis is readily extendable to additional methods, algorithms, and hyperparameters.</p>
        </caption>
        <alternatives>
          <graphic xlink:href="pdig.0000276.t001" id="pdig.0000276.t001g" position="float"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" style="border-bottom-width:thick" rowspan="1" colspan="1">Pipeline Stage</th>
                <th align="center" colspan="5" style="border-bottom-width:thick" rowspan="1">Algorithm (No. Hyperparameters Optimized by AutoPrognosis)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Imputation</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">HyperImpute<break/>(M)ICE (0)</td>
                <td align="left" rowspan="1" colspan="1">Mean (0)<break/>SoftImpute (2)</td>
                <td align="left" rowspan="1" colspan="1">Median (0)<break/>EM (1)</td>
                <td align="left" rowspan="1" colspan="1">Most-Frequent (0)<break/>Sinkhorn (6)</td>
                <td align="left" rowspan="1" colspan="1">MissForest (2)<break/>None (0)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Dimensionality Reduction</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Fast ICA (1)</td>
                <td align="left" rowspan="1" colspan="1">Feat. Agg. (1)</td>
                <td align="left" rowspan="1" colspan="1">Gauss. Rand. Proj. (1)</td>
                <td align="left" rowspan="1" colspan="1">PCA (1)</td>
                <td align="left" rowspan="1" colspan="1">Var. Thresh. (0)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Feature Scaling</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">L2 Norm. (0)<break/>Unif. Trans. (0)</td>
                <td align="left" rowspan="1" colspan="1">Max (0)<break/>None (0)</td>
                <td align="left" rowspan="1" colspan="1">MinMax (0)</td>
                <td align="left" rowspan="1" colspan="1">Normal Trans. (0)</td>
                <td align="left" rowspan="1" colspan="1">Quant. Trans. (0)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Classification</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">ADABoost (3)<break/>ExtraTree (1)<break/>LDA (0)<break/>Neural Net. (6)<break/>TabNet (8)</td>
                <td align="left" rowspan="1" colspan="1">Bagging (4)<break/>Gauss. NB (0)<break/>Light GBM (6)<break/>Perceptron (2)<break/>XGBoost (11)</td>
                <td align="left" rowspan="1" colspan="1">Bernoulli NB (1)<break/>Grad. Boost. (3)<break/>Linear SVM (1)<break/>QDA (0)</td>
                <td align="left" rowspan="1" colspan="1">CatBoost (2)<break/>Hist. Grad. Boost. (2)<break/>Log. Reg. (4)<break/>Random Forest (5)</td>
                <td align="left" rowspan="1" colspan="1">Decision Tree (1)<break/>KNN (4)<break/>Multi. NB (1)<break/>Ridge Class. (1)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Regression</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Bayesian RR (1)<break/>TabNet (8)</td>
                <td align="left" rowspan="1" colspan="1">CatBoost (2)<break/>XGBoost (2)</td>
                <td align="left" rowspan="1" colspan="1">Linear (0)</td>
                <td align="left" rowspan="1" colspan="1">MLP (0)</td>
                <td align="left" rowspan="1" colspan="1">Neural Net. (6)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Survival Analysis</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Cox PH (2)<break/>Surv. XGB (4)</td>
                <td align="left" rowspan="1" colspan="1">CoxNet (6)<break/>Weibull AFT (2)</td>
                <td align="left" rowspan="1" colspan="1">DeepHit (7)</td>
                <td align="left" rowspan="1" colspan="1">LogLogistic AFT (1)</td>
                <td align="left" rowspan="1" colspan="1">LogNorm. AFT (2)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Interpretability</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">INVASE<break/>SimplEx</td>
                <td align="left" rowspan="1" colspan="1">KernelSHAP<break/>Symb. Pursuit</td>
                <td align="left" rowspan="1" colspan="1">LIME</td>
                <td align="left" rowspan="1" colspan="1">Effect Size</td>
                <td align="left" rowspan="1" colspan="1">Shap Permutation</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec id="sec004">
      <title>Missing data imputation</title>
      <p>Medical datasets are often incomplete; however, most models require complete data as input, thus imputation is a necessary first step. There are many different imputation methods available, ranging from traditional statistical approaches such as mean imputation to well-known alternatives such as MICE [<xref rid="pdig.0000276.ref022" ref-type="bibr">22</xref>] and MissForest [<xref rid="pdig.0000276.ref023" ref-type="bibr">23</xref>]. We include eight common imputation algorithms in AutoPrognosis for users to select if they desire a specific imputation method.</p>
      <p>In addition, we also include a state-of-the-art AutoML approach for imputation, HyperImpute [<xref rid="pdig.0000276.ref024" ref-type="bibr">24</xref>]. HyperImpute is a generalized iterative imputation algorithm that automatically configures feature-wise imputation models. HyperImpute inherits the usual properties of classical iterative imputation algorithms [<xref rid="pdig.0000276.ref022" ref-type="bibr">22</xref>, <xref rid="pdig.0000276.ref025" ref-type="bibr">25</xref>, <xref rid="pdig.0000276.ref026" ref-type="bibr">26</xref>] while benefiting from an automated model selection and hyperparameter optimization procedure that allows the most appropriate model to be chosen for each feature. HyperImpute optimizes over five classes of model, with a total of 29 configurable hyperparameters. For additional details, we refer to the recent technical report detailing HyperImpute [<xref rid="pdig.0000276.ref024" ref-type="bibr">24</xref>]. HyperImpute is the recommended imputation strategy in AutoPrognosis unless a specific method is preferred by the user. Alternatively, the imputation step can be jointly optimized as part of a larger pipeline.</p>
    </sec>
    <sec id="sec005">
      <title>Developing optimized ML pipelines</title>
      <p>After imputation, we construct ML pipelines consisting of feature processing, model selection, and model fitting. Given an objective function, these steps are jointly optimized using AutoML. There are several possible choices for the pipeline search algorithm, such as Bayesian optimization [<xref rid="pdig.0000276.ref007" ref-type="bibr">7</xref>, <xref rid="pdig.0000276.ref027" ref-type="bibr">27</xref>] or bandit-based approaches [<xref rid="pdig.0000276.ref028" ref-type="bibr">28</xref>]. A key difference in this work is the extension of such approaches beyond hyperparameter optimization, the typical use of AutoML, to accommodate more general configuration spaces that encompass ML pipelines. AutoPrognosis is flexible to the choice of AutoML search algorithm and can be extended as new approaches are developed. Currently, our default approach is based on Bayesian optimization but we have also included an extension of Hyperband [<xref rid="pdig.0000276.ref028" ref-type="bibr">28</xref>]. In <xref rid="pdig.0000276.t001" ref-type="table">Table 1</xref>, we provide a list of the algorithms currently implemented in AutoPrognosis 2.0, together with the number of hyperparameters optimized over for each method. We emphasize the extendability of our approach to new methods, algorithms, and hyperparameters.</p>
      <sec id="sec006">
        <title>Feature processing</title>
        <p>While imputation ensures data is complete, preprocessing datasets is a common requirement for many ML estimators. In particular, feature scaling to normalize the range or the shape of features can significantly affect performance [<xref rid="pdig.0000276.ref029" ref-type="bibr">29</xref>]. AutoPrognosis can optimize over five dimensionality reduction and six feature scaling algorithms.</p>
      </sec>
      <sec id="sec007">
        <title>Model selection and fitting</title>
        <p>Next, a model and hyperparameters must be selected. This is a key step as suboptimal choice of model or hyperparameters can significantly affect the performance of the resulting ML system. AutoPrognosis contains 22 classification algorithms, seven regression algorithms, and seven methods for survival analysis. Together with a range of hyperparameters, this defines a broad algorithmic search space. While navigating this space manually by hand is extremely challenging, AutoPrognosis learns relationships between different settings to efficiently arrive at an optimized solution. Finally, AutoPrognosis combines the best-performing models into a single ensemble. AutoPrognosis can construct ensembles that are weighted combinations of the best-performing models or stacking ensembles, where a meta-model is placed on top of the underlying models. For the illustrative application included in this paper, we used weighted ensembles.</p>
      </sec>
    </sec>
    <sec id="sec008">
      <title>Model explanations</title>
      <p>Predictive models alone are not sufficient and a deeper understanding is required to engender model trust from both clinical users [<xref rid="pdig.0000276.ref005" ref-type="bibr">5</xref>] and regulatory bodies [<xref rid="pdig.0000276.ref030" ref-type="bibr">30</xref>–<xref rid="pdig.0000276.ref032" ref-type="bibr">32</xref>]. Consequently, AutoPrognosis contains a suite of methods for explaining ML models. We have included feature-based interpretability methods, such as SHAP [<xref rid="pdig.0000276.ref033" ref-type="bibr">33</xref>], that allow us to understand the importance of individual features, as well as an example-based interpretability method, SimplEx [<xref rid="pdig.0000276.ref034" ref-type="bibr">34</xref>], that explains the model output for a particular sample with examples of similar instances, similar to case-based reasoning. Furthermore, sometimes outputs of a specific form are required, such as explicit risk equations [<xref rid="pdig.0000276.ref032" ref-type="bibr">32</xref>]. We have therefore included the ability to convert optimized models into transparent risk equations using symbolic regression [<xref rid="pdig.0000276.ref035" ref-type="bibr">35</xref>].</p>
    </sec>
    <sec id="sec009">
      <title>Demonstrators</title>
      <p>In order for risk scores to be useful, they need to be readily available to clinical practitioners. To facilitate this, AutoPrognosis allows interactive demonstrators to be produced for clinical use. We build our clinical demonstrators on top of the open-source Streamlit package [<xref rid="pdig.0000276.ref036" ref-type="bibr">36</xref>]. Compared to traditional solutions, these require almost no technical capabilities to set up, and the standardized nature simplifies adoption for end-users.</p>
    </sec>
  </sec>
  <sec id="sec010">
    <title>Challenges in diagnostic and prognostic modeling</title>
    <p>There are numerous obstacles to developing and deploying diagnostic and prognostic models that currently prevent healthcare professionals from capitalizing on recent algorithmic advances [<xref rid="pdig.0000276.ref001" ref-type="bibr">1</xref>]. Our work seeks to empower clinicians, medical researchers, epidemiologists, and biostatisticians through an accessible, automated framework capable of identifying optimal solutions to all major obstacles limiting ML model building with minimal need for technical expertise. We begin by describing seven major challenges faced by these communities and how they are addressed by AutoPrognosis 2.0 (<xref rid="pdig.0000276.t002" ref-type="table">Table 2</xref>).</p>
    <table-wrap position="float" id="pdig.0000276.t002">
      <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.t002</object-id>
      <label>Table 2</label>
      <caption>
        <title>Major challenges facing clinical development of diagnostic and prognostic models and how these are addressed by AutoPrognosis.</title>
        <p>See Challenges in diagnostic and prognostic modeling for more detail.</p>
      </caption>
      <alternatives>
        <graphic xlink:href="pdig.0000276.t002" id="pdig.0000276.t002g" position="float"/>
        <table frame="box" rules="all" border="0">
          <colgroup span="1">
            <col align="left" valign="middle" span="1"/>
          </colgroup>
          <tbody>
            <tr>
              <td align="left" style="background-color:#BF0000" rowspan="1" colspan="1">Challenge 1. Developing powerful ML pipelines</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis uses AutoML to automate pipeline configuration, performing missing value imputation, feature processing, model selection, and hyperparameter optimization.</td>
            </tr>
            <tr>
              <td align="left" style="background-color:#BF6000" rowspan="1" colspan="1">Challenge 2. Understanding the value of ML and when it is necessary</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis compares a range of ML methods to traditional approaches and automatically identifies what approach is best.</td>
            </tr>
            <tr>
              <td align="left" style="background-color:#BF8600" rowspan="1" colspan="1">Challenge 3. Determining the value of information</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis can quantify the value of including additional predictors, enabling systematic identification of optimal variables.</td>
            </tr>
            <tr>
              <td align="left" style="background-color:#173921" rowspan="1" colspan="1">Challenge 4. Understanding and debugging ML models</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis incorporates seven state-of-the-art interpretability methods, allowing models to be understood and debugged as they are generated.</td>
            </tr>
            <tr>
              <td align="left" style="background-color:#0000BF" rowspan="1" colspan="1">Challenge 5. Making ML models accessible and usable</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis provides a platform to share model outputs by automating the creation of web-based applications.</td>
            </tr>
            <tr>
              <td align="left" style="background-color:#370062" rowspan="1" colspan="1">Challenge 6. Deciding when and if to update clinical models</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis can quantify the benefit of additional data or new predictive variables, and automatically determine the optimal system for the new dataset.</td>
            </tr>
            <tr>
              <td align="left" style="background-color:#600060" rowspan="1" colspan="1">Challenge 7. Transparent reproducibility</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis provides a standardized, publicly available framework, facilitating reproducibility.</td>
            </tr>
          </tbody>
        </table>
      </alternatives>
    </table-wrap>
    <sec id="sec011">
      <title>Challenge 1. Developing powerful ML pipelines</title>
      <p>Developing performant ML models remains complex and typically involves significant time and effort for both clinicians [<xref rid="pdig.0000276.ref037" ref-type="bibr">37</xref>] and expert ML practitioners [<xref rid="pdig.0000276.ref038" ref-type="bibr">38</xref>] alike. Indeed, some estimates suggest over 95% of work is expended on software technicals, leaving less than 5% for addressing the medical or scientific problem at hand [<xref rid="pdig.0000276.ref039" ref-type="bibr">39</xref>]. This is further complicated by the myriad of choices that must be made when developing a new predictive model for diagnosis or prognosis, such as: what imputation strategy should be used; how should the data be preprocessed; what (ML) model is best suited for the specific task; what configuration of hyperparameters should be used. These decisions affect each other, thus cannot be made in isolation [<xref rid="pdig.0000276.ref038" ref-type="bibr">38</xref>]; further, the optimal choices not only vary between applications, but also can change over time as more data is collected and clinical practice changes [<xref rid="pdig.0000276.ref040" ref-type="bibr">40</xref>].</p>
      <p>Few resources are available to help empirically define optimal computational pipelines. AutoPrognosis 2.0 addresses this by incorporating an AutoML approach within a standardized framework, automating the process of pipeline configuration. AutoPrognosis navigates a broad algorithmic search space in an efficient fashion, systematically performing missing value imputation, feature processing, model selection, and hyperparameter optimization in an unbiased manner without the need for human intervention or expert insight. This avoids arbitrary parameter selection and ensures standardization of pipelines, facilitating both reproducibility and optimized model performance. Critically, this democratizes the model building step, eliminating the requirement for expert ML knowledge and making cutting-edge methodology accessible to all, freeing healthcare domain experts to define and address the core clinical problems.</p>
    </sec>
    <sec id="sec012">
      <title>Challenge 2. Understanding the value of ML and when it is necessary</title>
      <p>Traditional approaches, such as linear regression and Cox proportional hazard models [<xref rid="pdig.0000276.ref041" ref-type="bibr">41</xref>], are widely used and accepted across healthcare. Before replacing these established methods, it is vital to understand whether ML is valuable for a given problem and quantify the benefit of ML systems. Indeed, there is no “free lunch” and we should not expect ML to always outperform existing approaches [<xref rid="pdig.0000276.ref042" ref-type="bibr">42</xref>]. Further, simple solutions can be desirable [<xref rid="pdig.0000276.ref043" ref-type="bibr">43</xref>]. Several recent examples exist that present settings where comparatively “simple” approaches outperformed ML [<xref rid="pdig.0000276.ref044" ref-type="bibr">44</xref>, <xref rid="pdig.0000276.ref045" ref-type="bibr">45</xref>].</p>
      <p>AutoPrognosis 2.0 can be used to compare a range of ML methods to traditional approaches at minimal technical cost to the user. Furthermore, since these solutions are included in the algorithmic search space, AutoPrognosis will automatically identify whether such approaches are indeed best or if more complex ML models are required.</p>
    </sec>
    <sec id="sec013">
      <title>Challenge 3. Determining the value of information</title>
      <p>Selecting which variables to include in a predictive model is a critical aspect of model development that not only impacts model performance but also the ease of subsequent clinical use [<xref rid="pdig.0000276.ref046" ref-type="bibr">46</xref>]. This is due to models with fewer features being easier to interpret and use in practice [<xref rid="pdig.0000276.ref047" ref-type="bibr">47</xref>] but also since any feature used will need to be collected in an ongoing manner to use such systems. Thus, understanding the <italic toggle="yes">value</italic> of an individual variable and the information it provides is critical. Often, this is assessed by univariate statistical analysis or other selection methods such as forward selection or backward elimination [<xref rid="pdig.0000276.ref048" ref-type="bibr">48</xref>]. AutoPrognosis 2.0 provides methods to test and quantify the value of including additional predictors, allowing systematic identification of optimal variables in an informed manner.</p>
    </sec>
    <sec id="sec014">
      <title>Challenge 4. Understanding and debugging ML models</title>
      <p>A predictive clinical model must be more than just accurate, it must be interpretable. Without a transparent understanding of <italic toggle="yes">how</italic> a model makes predictions it may act in unintended and undesirable ways, for example learning incorrect or aberrant features unique to the training data [<xref rid="pdig.0000276.ref049" ref-type="bibr">49</xref>, <xref rid="pdig.0000276.ref050" ref-type="bibr">50</xref>]. In particular, model debugging can be used to check for shortcut learning [<xref rid="pdig.0000276.ref051" ref-type="bibr">51</xref>], where the model learns spurious relationships in the provided data, or data leakage [<xref rid="pdig.0000276.ref052" ref-type="bibr">52</xref>], which can lead to overly optimistic performance estimates. As seen in several machine learning applications in healthcare [<xref rid="pdig.0000276.ref050" ref-type="bibr">50</xref>, <xref rid="pdig.0000276.ref053" ref-type="bibr">53</xref>, <xref rid="pdig.0000276.ref054" ref-type="bibr">54</xref>], shortcut learning can be a serious issue that must be avoided. Additionally, fairness and bias are two important considerations when developing any predictive model, particularly in healthcare [<xref rid="pdig.0000276.ref055" ref-type="bibr">55</xref>], and existing societal biases in the data should not be reinforced by models [<xref rid="pdig.0000276.ref043" ref-type="bibr">43</xref>]. While related to Challenge 1 (since a perfectly predictive model is both fair and unbiased), assessing fairness and bias, as well as understanding their origin, are key steps in model development and debugging. While interpretability does not guarantee that a model will be fair and unbiased, it creates the opportunity to assess these characteristics by probing how the model issues predictions.</p>
      <p>The debugging step is critical for building model trust [<xref rid="pdig.0000276.ref005" ref-type="bibr">5</xref>] and cannot be achieved without interpretation of the training features or cases that support model accuracy. It is clear that clinical deployment of an interpretable model is supported by the additional trust gained by understanding the model’s performance [<xref rid="pdig.0000276.ref056" ref-type="bibr">56</xref>].</p>
      <p>Furthermore, a clear understanding of computational models is now a requirement for deployment in healthcare systems globally: in the United States, the FDA demands “transparency about the function and modifications of medical devices” as a key safety aspect [<xref rid="pdig.0000276.ref030" ref-type="bibr">30</xref>]; Article 22 of GDPR legislation in the EU requires that “meaningful information about the logic involved” be provided in certain circumstances [<xref rid="pdig.0000276.ref031" ref-type="bibr">31</xref>]; and Article 13 (1) of the European Commision Proposal for the AI Act states “High-risk AI systems shall be …sufficiently transparent to enable users to interpret the system’s output”, among others. To achieve this transparency, interpretable outputs of a specific form can also be required. For example, the American Joint Committee on Cancer requires explicit risk equations [<xref rid="pdig.0000276.ref032" ref-type="bibr">32</xref>].</p>
      <p>The ‘black-box’ nature of many ML methods means that they remain inherently uninterpretable and require specialized methods to unravel the underlying rationale for predictions. In AutoPrognosis 2.0, we have incorporated seven state-of-the-art interpretability methods allowing researchers to understand and debug ML models as they are generated.</p>
    </sec>
    <sec id="sec015">
      <title>Challenge 5. Making ML models accessible and usable</title>
      <p>Predictive models need to be accessible to be used in clinical practice. This step often limits adoption, since bespoke deployment can result in significant costs and reliance on technical expertise. While full clinical deployment may require additional systems (e.g. due to regulatory requirements), a standardized, user-friendly solution to rapidly visualize and share models is also a necessary part of both debugging and confirming clinical acceptance. AutoPrognosis 2.0 provides a platform to share model outputs by automating the creation of web-based applications, allowing clinicians to explore predictions in diverse scenarios.</p>
    </sec>
    <sec id="sec016">
      <title>Challenge 6. Deciding when and if to update clinical models</title>
      <p>Over time, more data is collected, new variables are measured, and even clinical practice changes [<xref rid="pdig.0000276.ref057" ref-type="bibr">57</xref>, <xref rid="pdig.0000276.ref058" ref-type="bibr">58</xref>]. For the former, existing clinical predictive models might benefit from additional data or features, while in the latter case, model performance may degrade [<xref rid="pdig.0000276.ref040" ref-type="bibr">40</xref>]. However, deciding whether to update a clinical model is not a decision to be made lightly, since beyond model building, further regulatory approval might be necessary and the updated model will need to be redeployed. AutoPrognosis can help answer this difficult question by quantifying the benefit of additional data and new predictive variables, while also automatically determining the optimal system configurations for the new dataset, which may have changed.</p>
    </sec>
    <sec id="sec017">
      <title>Challenge 7. Transparent reproducibility</title>
      <p>Reproducibility is a fundamental requirement for the acceptance and adoption of any predictive model. While transparently reproducing a model’s output on a given dataset is conceptually simple, several factors can confound this necessary step. Serial data releases, code updates, and even inherent properties of ML algorithms (for example, stochastic descent methods can give different answers even when run repeatedly on the same data) can conspire to make ML model building less reproducible than it should be [<xref rid="pdig.0000276.ref059" ref-type="bibr">59</xref>]. These issues demonstrably obstruct translation of clinical prediction and erode trust in ML approaches [<xref rid="pdig.0000276.ref060" ref-type="bibr">60</xref>–<xref rid="pdig.0000276.ref062" ref-type="bibr">62</xref>]. AutoPrognosis 2.0 addresses this major challenge by providing a standardized, publicly available framework to train predictive models, allowing straightforward demonstration of reproducibility on source data.</p>
    </sec>
  </sec>
  <sec id="sec018">
    <title>Illustrative application: Diabetes risk prediction</title>
    <p>In this section, we show how AutoPrognosis 2.0 can be applied to address the challenges described in Challenges in diagnostic and prognostic modeling. We demonstrate the application of AutoPrognosis 2.0 using an illustrative scenario: prognostic risk prediction of developing diabetes using a cohort of 502,467 individuals from UK Biobank. Our goal is <italic toggle="yes">not</italic> to develop the best model for diabetes risk prediction possible, but instead to exemplify how our tool can be used.</p>
    <p>In our use scenario, we show that the model derived with AutoPrognosis outperforms risk models currently used in clinical practice and quantify the benefit of ML methods over Cox proportional hazard models. In addition, we show how the model interpretability components of AutoPrognosis can be used to understand the drivers of predictions and identify novel risk factors not incorporated into previous risk scores. Finally, we use AutoPrognosis to share the diabetes risk score as a web-based decision support tool that can be publicly accessed by patients and clinicians (<ext-link xlink:href="https://autoprognosis-biobank-diabetes.streamlitapp.com/" ext-link-type="uri">https://autoprognosis-biobank-diabetes.streamlitapp.com/</ext-link>).</p>
    <p>While we illustrate risk prediction of developing diabetes using a cohort from UK Biobank, AutoPrognosis can be applied to construct diagnostic and prognostic models for any disease or clinical outcome. Furthermore, AutoPrognosis is applicable to classification and regression tasks, in addition to survival analysis.</p>
    <sec id="sec019">
      <title>Designing experiments</title>
      <sec id="sec020">
        <title>Selecting which dataset to use</title>
        <p>AutoPrognosis can be used with data from many different origins, such as biobanks [<xref rid="pdig.0000276.ref012" ref-type="bibr">12</xref>], registries [<xref rid="pdig.0000276.ref013" ref-type="bibr">13</xref>, <xref rid="pdig.0000276.ref014" ref-type="bibr">14</xref>], and private hospital data [<xref rid="pdig.0000276.ref017" ref-type="bibr">17</xref>]. Here, we use the UK Biobank due to its availability and popularity as a resource for healthcare researchers. UK Biobank enrolled half a million participants from 22 assessment centers across England, Wales, and Scotland between 2006 and 2010 [<xref rid="pdig.0000276.ref063" ref-type="bibr">63</xref>], with follow-up data collected from hospital records [<xref rid="pdig.0000276.ref064" ref-type="bibr">64</xref>]. From UK Biobank, we extracted a cohort of participants who were 40 years of age or older with no diagnosis or history of diabetes at baseline; the primary outcome was diagnosis of diabetes within a 10-year horizon. We selected diabetes as our outcome of interest due to its global prevalence and role as a risk factor for a multitude of other indications [<xref rid="pdig.0000276.ref065" ref-type="bibr">65</xref>].</p>
      </sec>
      <sec id="sec021">
        <title>Selecting variables</title>
        <p>Variables can be selected for inclusion in a study in a myriad of ways. Often, healthcare professionals will select a subset of exploratory features that are of particular interest to them. This could be due to supporting medical literature, to explore a hypothesis, or based on features included in existing risk scores. Alternatively, we can always choose to initially include all available variables. Here, we selected an initial set of 109 exploratory features based on their general clinical availability, discussions with clinicians, and features used by existing risk scores. Descriptive characteristics of the UK Biobank cohort are provided in <xref rid="pdig.0000276.s004" ref-type="supplementary-material">S4 Table</xref>. Most variables had low levels of missingness (&lt; 1%); however, some important variables had higher missingness rates (e.g. HbA1c: 6.8%). We purposefully selected almost an order of magnitude increase compared to existing risk scores to illustrate how AutoPrognosis can be used in such a scenario.</p>
      </sec>
      <sec id="sec022">
        <title>Selecting benchmarks</title>
        <p>Often, existing risk scores will exist for the outcome of interest; this is certainly true for diabetes, where several risk scores that estimate the probability of developing diabetes are currently used in clinical practice. Therefore, we use the following as baseline risk scores:</p>
        <list list-type="bullet">
          <list-item>
            <p><bold>ADA</bold>: The American Diabetes Association (ADA) risk score [<xref rid="pdig.0000276.ref066" ref-type="bibr">66</xref>] is a points-based score employing six features, namely age, sex, family history of diabetes, history of hypertension, obesity, and physical activity.</p>
          </list-item>
          <list-item>
            <p><bold>FINRISK</bold>: A risk score for diabetes was derived from FINRISK, a large population survey in Finland, based on age, body mass index (BMI), waist circumference, history of antihypertensive drug treatment and high blood glucose, physical activity, and daily consumption of fruits, berries, or vegetables [<xref rid="pdig.0000276.ref067" ref-type="bibr">67</xref>].</p>
          </list-item>
          <list-item>
            <p><bold>DiabetesUK</bold>: The risk score from Diabetes UK uses seven features: gender, age, ethnicity, family history, waist size, BMI, and high blood pressure requiring treatment.</p>
          </list-item>
          <list-item>
            <p><bold>QDiabetes</bold>: Finally, QDiabetes [<xref rid="pdig.0000276.ref068" ref-type="bibr">68</xref>] consists of three separate models depending on the clinical information available and stage of risk screening. Model A uses 16 non-laboratory features that do not require a blood test and is intended primarily as an initial screening tool. Models B and C include the same variables as Model A together with fasting blood glucose and hemoglobin A1c (HbA1c), respectively, with the aim of refining risk assessment following a blood test.</p>
          </list-item>
        </list>
        <p>In addition to the baseline risk scores, a comparison with traditional modeling approaches can be made using AutoPrognosis. We demonstrate this by fitting Cox proportional hazard (Cox PH) [<xref rid="pdig.0000276.ref041" ref-type="bibr">41</xref>] models using the same features as each of the baseline risk scores. These models can be thought of as variants of the respective risk scores calibrated to the specific dataset.</p>
      </sec>
    </sec>
    <sec id="sec023">
      <title>Results</title>
      <p>Through the lens of our example (diabetes risk prediction), we demonstrate how AutoPrognosis 2.0 can be used to address the challenges of diagnostic and prognostic modeling introduced in Challenges in diagnostic and prognostic modeling.</p>
      <sec id="sec024">
        <title>Challenge 1. Developing powerful ML pipelines</title>
        <p>We begin by using AutoPrognosis to derive a clinical risk score for diabetes. We evaluated the performance of the models using concordance index (C-index) to assess model discrimination, Brier score to assess calibration, and the area under the receiver-operating curve (AUROC) to assess prediction accuracy. We performed imputation five times and conducted 3-fold cross-validation for each of the imputed datasets.</p>
        <p>As seen in <xref rid="pdig.0000276.t003" ref-type="table">Table 3</xref>, the risk score developed by AutoPrognosis significantly outperforms all baseline risk scores and Cox PH models (two-sample unpaired t-test between C-indices: p-value &lt;0.001), achieving a C-index on the validation cohort of 0.888 (95% confidence interval: 0.881–0.895). This compares to 0.696 (0.681–0.711) for the ADA score, 0.728 (0.699–0.757) for FINRISK, 0.759 (0.746–0.772) for DiabetesUK, and 0.839 (0.818–0.860) for the best performing QDiabetes model (Model C). Cox PH models fit with the same risk factors as the clinical risk scores achieved improved performance (C-indices: 0.774, 0.786, 0.794, and 0.858, respectively), but exhibit lower performance than AutoPrognosis.</p>
        <table-wrap position="float" id="pdig.0000276.t003">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.t003</object-id>
          <label>Table 3</label>
          <caption>
            <title>Diabetes risk prediction results.</title>
            <p>The risk scores automatically derived by AutoPrognosis outperform the existing risk scores and Cox PH models retrained on the same features. Mean performance reported with 95% confidence interval.</p>
          </caption>
          <alternatives>
            <graphic xlink:href="pdig.0000276.t003" id="pdig.0000276.t003g" position="float"/>
            <table frame="box" rules="all" border="0">
              <colgroup span="1">
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th align="center" rowspan="1" colspan="1">Method</th>
                  <th align="center" rowspan="1" colspan="1">C-index ↑</th>
                  <th align="center" rowspan="1" colspan="1">Brier score ↓</th>
                  <th align="center" rowspan="1" colspan="1">AUROC ↑</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="center" rowspan="1" colspan="1">ADA</td>
                  <td align="center" rowspan="1" colspan="1">0.696 ± 0.015</td>
                  <td align="center" rowspan="1" colspan="1">0.011 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.697 ± 0.018</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">FINRISK</td>
                  <td align="center" rowspan="1" colspan="1">0.728 ± 0.029</td>
                  <td align="center" rowspan="1" colspan="1">0.019 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.729 ± 0.020</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">DiabetesUK</td>
                  <td align="center" rowspan="1" colspan="1">0.759 ± 0.013</td>
                  <td align="center" rowspan="1" colspan="1">0.016 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.759 ± 0.019</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">QDiabetes Model A</td>
                  <td align="center" rowspan="1" colspan="1">0.794 ± 0.022</td>
                  <td align="center" rowspan="1" colspan="1">0.008 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.795 ± 0.017</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">QDiabetes Model B</td>
                  <td align="center" rowspan="1" colspan="1">0.788 ± 0.019</td>
                  <td align="center" rowspan="1" colspan="1">0.015 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.788 ± 0.013</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">QDiabetes Model C</td>
                  <td align="center" rowspan="1" colspan="1">0.839 ± 0.021</td>
                  <td align="center" rowspan="1" colspan="1">0.005 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.840 ± 0.010</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Cox PH (ADA)</td>
                  <td align="center" rowspan="1" colspan="1">0.774 ± 0.027</td>
                  <td align="center" rowspan="1" colspan="1">0.002 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.774 ± 0.020</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Cox PH (FINRISK)</td>
                  <td align="center" rowspan="1" colspan="1">0.786 ± 0.023</td>
                  <td align="center" rowspan="1" colspan="1">0.002 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.786 ± 0.026</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Cox PH (DiabetesUK)</td>
                  <td align="center" rowspan="1" colspan="1">0.794 ± 0.023</td>
                  <td align="center" rowspan="1" colspan="1">0.002 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.794 ± 0.022</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Cox PH (QDiabetes C)</td>
                  <td align="center" rowspan="1" colspan="1">0.858 ± 0.007</td>
                  <td align="center" rowspan="1" colspan="1">0.002 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.860 ± 0.018</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">
                    <bold>AutoPrognosis 2.0</bold>
                  </td>
                  <td align="center" rowspan="1" colspan="1">
                    <bold>0.888 ± 0.007</bold>
                  </td>
                  <td align="center" rowspan="1" colspan="1">
                    <bold>0.002 ± 0.000</bold>
                  </td>
                  <td align="center" rowspan="1" colspan="1">
                    <bold>0.888 ± 0.012</bold>
                  </td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">AutoPrognosis (18 feat.)</td>
                  <td align="center" rowspan="1" colspan="1">0.870 ± 0.011</td>
                  <td align="center" rowspan="1" colspan="1">0.002 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.867 ± 0.020</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
        <p>As an alternate way of understanding the clinical impact of our results, we performed decision curve analysis [<xref rid="pdig.0000276.ref069" ref-type="bibr">69</xref>, <xref rid="pdig.0000276.ref070" ref-type="bibr">70</xref>]. Decision curve analysis assesses the clinical value of a predictor by calculating the clinical net benefit across a range of risk threshold probabilities, where the threshold probability is defined as the minimum probability of an event at which a decision-maker would take a given action. Net benefit is defined as the difference between the proportion of true positives and the proportion of false positives weighted by the odds of the selected threshold. Evaluating net benefit is recommended in the TRIPOD guidelines [<xref rid="pdig.0000276.ref071" ref-type="bibr">71</xref>]. At any given threshold, the model with the higher net benefit is preferred.</p>
        <p>We compared the predicted risk by AutoPrognosis with the QDiabetes models, the best performing of the existing clinical risk scores, as well as baseline strategies to assume all patients will develop diabetes (All) or that no-one will (None). Decision curve analysis further demonstrates the benefit of AutoPrognosis compared to existing risk scores for diabetes (<xref rid="pdig.0000276.g002" ref-type="fig">Fig 2</xref>). At all decision thresholds, AutoPrognosis offers greater net benefit and is the only score to outperform “All” between the thresholds of 0.1 and 0.2, and the only model to perform similarly to “All” below a threshold of 0.1.</p>
        <fig position="float" id="pdig.0000276.g002">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.g002</object-id>
          <label>Fig 2</label>
          <caption>
            <title>Decision curve analysis.</title>
            <p>AutoPrognosis exhibits higher net benefit at all decision thresholds compared to existing risk scores and baseline strategies.</p>
          </caption>
          <graphic xlink:href="pdig.0000276.g002" position="float"/>
        </fig>
      </sec>
      <sec id="sec025">
        <title>Challenge 2. Understanding when ML is necessary and its value</title>
        <p><xref rid="pdig.0000276.t003" ref-type="table">Table 3</xref> demonstrates the benefit of AutoPrognosis compared to existing risk scores and Cox PH models retrained on the same features. We now directly compare AutoPrognosis to Cox PH models on the same training data to understand if ML is needed for this problem. In <xref rid="pdig.0000276.t004" ref-type="table">Table 4</xref>, we show the performance of AutoPrognosis and a Cox PH model using the full feature set considered. We see that while some of the benefit is due to the additional features, there remains value in the improved modeling approach, even for identical feature sets.</p>
        <table-wrap position="float" id="pdig.0000276.t004">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.t004</object-id>
          <label>Table 4</label>
          <caption>
            <title>Quantifying the value of ML.</title>
            <p>The risk score automatically derived by AutoPrognosis significantly outperforms a Cox PH model trained on the same features.</p>
          </caption>
          <alternatives>
            <graphic xlink:href="pdig.0000276.t004" id="pdig.0000276.t004g" position="float"/>
            <table frame="box" rules="all" border="0">
              <colgroup span="1">
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th align="center" rowspan="1" colspan="1">Method</th>
                  <th align="center" rowspan="1" colspan="1">C-index ↑</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="center" colspan="2" rowspan="1">
                    <italic toggle="yes">All Variables</italic>
                  </td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Cox PH</td>
                  <td align="center" rowspan="1" colspan="1">0.883 ± 0.010</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">AutoPrognosis</td>
                  <td align="center" rowspan="1" colspan="1">0.888 ± 0.007</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
      </sec>
      <sec id="sec026">
        <title>Challenge 3. Determining the value of information</title>
        <p>Understanding the predictive power of variables is key and often there is a trade-off (e.g. cost or time) in clinical practice to acquiring additional variables. We evaluate AutoPrognosis using different subsets of features. We selected features using the magnitude of the effect size. We measure the distributional shift for an increase in predicted risk using Cohen’s D [<xref rid="pdig.0000276.ref072" ref-type="bibr">72</xref>] and select features with effect sizes exceeding the thresholds {0.5, 0.6, 0.7, 0.8, 0.9, 1.0}. Even using only eight features (effect size: 1.0), AutoPrognosis slightly outperforms the best performing existing risk score, QDiabetes Model C, which employs 17 features (<xref rid="pdig.0000276.g003" ref-type="fig">Fig 3</xref>). With a comparable number of features (18 features, effect size 0.7), AutoPrognosis displays significantly improved performance (<xref rid="pdig.0000276.t003" ref-type="table">Table 3</xref>). As the number of features increases, performance rapidly increases until 35 features are used (effect size: 0.5). After this point, while there is some gain from additional features, it could be considered marginal given the number of additional features employed. See <xref rid="pdig.0000276.s001" ref-type="supplementary-material">S1 Table</xref> for the most important features using effect size.</p>
        <fig position="float" id="pdig.0000276.g003">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.g003</object-id>
          <label>Fig 3</label>
          <caption>
            <title>Value of information.</title>
            <p>We evaluate AutoPrognosis with different numbers of features, selected using effect size. Feature efficiency is compared to QDiabetes Model C, the best performing existing risk score. Note y-axis does not start at 0 nor end at 1.</p>
          </caption>
          <graphic xlink:href="pdig.0000276.g003" position="float"/>
        </fig>
      </sec>
      <sec id="sec027">
        <title>Challenge 4. Understanding and debugging ML models</title>
        <p>Highly predictive models alone are insufficient and it is necessary to understand which features are important. We demonstrate how the interpretability methods incorporated in AutoPrognosis 2.0 can be used to understand how ML models make predictions and debug their behavior. We begin by examining the SHAP values [<xref rid="pdig.0000276.ref033" ref-type="bibr">33</xref>] to explain the key contributors to model performance. <xref rid="pdig.0000276.g004" ref-type="fig">Fig 4</xref> shows the top 20 features. Encouragingly, these features are largely consistent with clinical knowledge, providing evidence that the model is acting in a desirable manner. Several of the top risk factors, such as HbA1c, waist size, and body mass index, were also included in previous risk scores. However, a number of additional features, including both laboratory and non-laboratory tests, were deemed important. A number of these features have been shown to be risk factors for diabetes (e.g. gamma-glutamyl transferase [<xref rid="pdig.0000276.ref073" ref-type="bibr">73</xref>]), but have not been incorporated into other risk scores. Of the existing risk factors, we find that HbA1c is significantly more important to the predictions of AutoPrognosis than blood glucose, which is consistent with our earlier experiments that showed QDiabetes Model C (which uses HbA1c) outperforms Model B (which uses blood glucose) on the UK Biobank population.</p>
        <fig position="float" id="pdig.0000276.g004">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.g004</object-id>
          <label>Fig 4</label>
          <caption>
            <title>SHAP values for the most important features.</title>
          </caption>
          <graphic xlink:href="pdig.0000276.g004" position="float"/>
        </fig>
        <p>Finally, several features commonly incorporated in previous risk scores are notably missing: for example age and sex. One explanation could be that UK Biobank contains a limited age range (40–69 at enrollment), and thus the role of age could be reduced over that range. However, increasingly, younger individuals are being diagnosed with diabetes [<xref rid="pdig.0000276.ref074" ref-type="bibr">74</xref>], which could also explain the omission of age as a key risk factor. In the case of sex, while it was once assumed that there were sex differences, diabetes is equally prevalent among men and women in most populations [<xref rid="pdig.0000276.ref075" ref-type="bibr">75</xref>].</p>
        <p>To illustrate debugging, we consider the development of diabetes in individuals with differing HbA1c levels. We divide the overall cohort into two approximately equal parts using the median HbA1c value of 4.69%. This equates to splitting the population into a low-normal subgroup and a high-normal and elevated subgroup [<xref rid="pdig.0000276.ref076" ref-type="bibr">76</xref>].</p>
        <p>We evaluated AutoPrognosis and the QDiabetes models on these two cohorts (<xref rid="pdig.0000276.t005" ref-type="table">Table 5</xref>). Despite displaying better performance across the entire dataset, QDiabetes Model C <italic toggle="yes">under</italic> performs Model A for patients in the low-normal HbA1c cohort. Conversely, AutoPrognosis performs best for both subgroups, although predicting future risk of diabetes is more challenging for low-normal HbA1c patients, in line with the other models. This could suggest that QDiabetes Model C is overly reliant on HbA1c while AutoPrognosis has more accurately captured the risk factors for low HbA1c patients.</p>
        <table-wrap position="float" id="pdig.0000276.t005">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.t005</object-id>
          <label>Table 5</label>
          <caption>
            <title>Performance of diabetes risk scores for subgroups defined by HbA1c.</title>
          </caption>
          <alternatives>
            <graphic xlink:href="pdig.0000276.t005" id="pdig.0000276.t005g" position="float"/>
            <table frame="box" rules="all" border="0">
              <colgroup span="1">
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th align="center" rowspan="2" colspan="1">Method</th>
                  <th align="center" colspan="2" rowspan="1">C-index</th>
                  <th align="center" colspan="2" rowspan="1">AUROC</th>
                </tr>
                <tr>
                  <th align="center" rowspan="1" colspan="1">HbA1c &lt; 4.69%</th>
                  <th align="center" rowspan="1" colspan="1">HbA1c ≥ 4.69%</th>
                  <th align="center" rowspan="1" colspan="1">HbA1c &lt; 4.69%</th>
                  <th align="center" rowspan="1" colspan="1">HbA1c ≥ 4.69%</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="center" rowspan="1" colspan="1">QDiabetes Model A</td>
                  <td align="center" rowspan="1" colspan="1">0.771 ± 0.053</td>
                  <td align="center" rowspan="1" colspan="1">0.775 ± 0.016</td>
                  <td align="center" rowspan="1" colspan="1">0.772 ± 0.009</td>
                  <td align="center" rowspan="1" colspan="1">0.775 ± 0.023</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">QDiabetes Model B</td>
                  <td align="center" rowspan="1" colspan="1">0.738 ± 0.031</td>
                  <td align="center" rowspan="1" colspan="1">0.773 ± 0.010</td>
                  <td align="center" rowspan="1" colspan="1">0.738 ± 0.007</td>
                  <td align="center" rowspan="1" colspan="1">0.773 ± 0.017</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">QDiabetes Model C</td>
                  <td align="center" rowspan="1" colspan="1">0.735 ± 0.052</td>
                  <td align="center" rowspan="1" colspan="1">0.855 ± 0.008</td>
                  <td align="center" rowspan="1" colspan="1">0.736 ± 0.022</td>
                  <td align="center" rowspan="1" colspan="1">0.856 ± 0.004</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">AutoPrognosis 2.0</td>
                  <td align="center" rowspan="1" colspan="1">0.818 ± 0.047</td>
                  <td align="center" rowspan="1" colspan="1">0.889 ± 0.011</td>
                  <td align="center" rowspan="1" colspan="1">0.807 ± 0.013</td>
                  <td align="center" rowspan="1" colspan="1">0.896 ± 0.009</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
        <p>This raises the question of <italic toggle="yes">why</italic> AutoPrognosis is able to issue more accurate predictions for the low-normal HbA1c cohort, in particular given HbA1c is ranked as the most important feature globally (<xref rid="pdig.0000276.g004" ref-type="fig">Fig 4</xref>). <xref rid="pdig.0000276.t006" ref-type="table">Table 6</xref> shows the most important features (measured by risk effect size) for the two subgroups defined by HbA1c. While there is significant overlap, there are five unique features in the top 20 for each cohort. This type of analysis can help clinicians understand and debug the predictions of models not only for the entire population, but specific subgroups of interest.</p>
        <table-wrap position="float" id="pdig.0000276.t006">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.t006</object-id>
          <label>Table 6</label>
          <caption>
            <title>The most important features for AutoPrognosis measured by risk effect size for the two cohorts defined by median HbA1c.</title>
            <p>Features with * differ between the two cohorts. Effect size in parenthesis.</p>
          </caption>
          <alternatives>
            <graphic xlink:href="pdig.0000276.t006" id="pdig.0000276.t006g" position="float"/>
            <table frame="box" rules="all" border="0">
              <colgroup span="1">
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th align="center" rowspan="1" colspan="1">HbA1c &lt; 4.69%</th>
                  <th align="center" rowspan="1" colspan="1">HbA1c ≥ 4.69%</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="center" rowspan="1" colspan="1">*Atrial fibrillation (3.0)</td>
                  <td align="center" rowspan="1" colspan="1">*HbA1c (3.0)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Waist Size (2.8)</td>
                  <td align="center" rowspan="1" colspan="1">*Glucose (2.5)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Body Mass Index (2.7)</td>
                  <td align="center" rowspan="1" colspan="1">Weight/Height Ratio (1.5)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Weight/Height Ratio (2.7)</td>
                  <td align="center" rowspan="1" colspan="1">Waist Size (1.5)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Weight (2.7)</td>
                  <td align="center" rowspan="1" colspan="1">Body Mass Index (1.4)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Hip Size (2.2)</td>
                  <td align="center" rowspan="1" colspan="1">Weight (1.3)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Waist/Hip Ratio (1.8)</td>
                  <td align="center" rowspan="1" colspan="1">Waist/Hip Ratio (1.1)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Cystatin-c (1.6)</td>
                  <td align="center" rowspan="1" colspan="1">Hip Size (1.1)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">*Kidney Disease (1.5)</td>
                  <td align="center" rowspan="1" colspan="1">Alanine Transaminase (0.87)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">*Uric Acid (1.3)</td>
                  <td align="center" rowspan="1" colspan="1">Triglycerides (0.76)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Alanine Transaminase (1.1)</td>
                  <td align="center" rowspan="1" colspan="1">Gamma-Glutamyl Transferase (0.74)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">*Anti-hypertensive Medication (1.1)</td>
                  <td align="center" rowspan="1" colspan="1">*HDL (0.71)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">*History of Hypertension (0.99)</td>
                  <td align="center" rowspan="1" colspan="1">*C-Reactive Protein (0.70)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Triglycerides (0.97)</td>
                  <td align="center" rowspan="1" colspan="1">Cystatin-c (0.68)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Gamma-Glutamyl Transferase (0.96)</td>
                  <td align="center" rowspan="1" colspan="1">*Sex Hormone-Binding Globulin (0.67)</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
      </sec>
      <sec id="sec028">
        <title>Challenge 5. Making ML models accessible and usable</title>
        <p>Finally, we end our illustrative scenario with an example web-based demonstrator enabling the use of the risk model derived by AutoPrognosis. The web application can be accessed at <ext-link xlink:href="https://autoprognosis-biobank-diabetes.streamlitapp.com/" ext-link-type="uri">https://autoprognosis-biobank-diabetes.streamlitapp.com/</ext-link>. A screenshot is provided in <xref rid="pdig.0000276.g005" ref-type="fig">Fig 5</xref>.</p>
        <fig position="float" id="pdig.0000276.g005">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.g005</object-id>
          <label>Fig 5</label>
          <caption>
            <title>Screenshot of an example clinical demonstrator produced by AutoPrognosis.</title>
          </caption>
          <graphic xlink:href="pdig.0000276.g005" position="float"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec id="sec029">
    <title>Discussion: Using AutoPrognosis in Healthcare and Beyond</title>
    <p>Advances in ML algorithms harbor the potential to transform healthcare; however, major challenges continue to limit their adoption in medicine. In this work, we define these challenges and describe the first integrated, automated framework for diagnostic and prognostic modeling, AutoPrognosis 2.0, that is designed to overcome each obstacle in a way that is accessible to non-expert users, democratizing model construction, understanding, debugging, and sharing.</p>
    <p>While AutoPrognosis seeks to address many of the algorithmic challenges of applying machine learning to clinical settings, there remains significant responsibility with the healthcare expert using AutoPrognosis to ensure appropriate study design and data curation. In particular, inappropriate use can result in inaccurate or biased results. For example, if the data used is not representative of the patient population of interest, then the model may not be applicable or accurate in real-world settings. Additionally, if the model is not adequately validated, its use could lead to a greater number of incorrect diagnoses, prognoses, or treatment recommendations than expected, which would be adverse for patient health.</p>
    <p>In this study, we explored how AutoPrognosis could be used to construct a prognostic risk score for diabetes. The developed risk score outperformed existing approaches when evaluated on the UK Biobank cohort. However, prior to deployment in a different population, external validation should be conducted to ensure the accuracy of the risk score is not impacted by differences in patient characteristics or care.</p>
    <p>While we have provided an illustrative example of how AutoPrognosis can be used, the key finding reported here is <italic toggle="yes">not</italic> the performance of a single illustrative model, but rather the way in which it was built. We believe AutoPrognosis 2.0 is a necessary development in the journey towards widespread adoption of ML systems in clinical practice and hope that researchers will engage with this tool. Rather than marginalizing healthcare experts, we believe AutoPrognosis places them at the center and empowers them to create new clinical tools. As part of this journey, we will continue to add new features and improve AutoPrognosis.</p>
    <p>The adoption of AutoPrognosis and similar tools in healthcare has the potential to transform clinical decision-making and foster collaboration between ML experts and healthcare professionals. However, implementing models developed with AutoPrognosis in real-world clinical settings may present challenges, such as integration with existing medical systems. These issues are not unique to AutoPrognosis and addressing these issues will be crucial to the successful deployment of any machine learning model or other computational tools.</p>
    <p>Finally, while the focus and motivation for AutoPrognosis is medicine, it has not escaped our notice that AutoPrognosis can be used to construct predictive models and risk scores for applications beyond healthcare.</p>
  </sec>
  <sec id="sec030" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pdig.0000276.s001" position="float" content-type="local-data">
      <label>S1 Table</label>
      <caption>
        <title>Most important features as measured by effect size.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pdig.0000276.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pdig.0000276.s002" position="float" content-type="local-data">
      <label>S2 Table</label>
      <caption>
        <title>Performance of AutoPrognosis 2.0 for different subgroups.</title>
        <p>Subgroups created by splitting population on median feature value.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pdig.0000276.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pdig.0000276.s003" position="float" content-type="local-data">
      <label>S3 Table</label>
      <caption>
        <title>Diabetes risk prediction results at different horizons.</title>
        <p>Mean performance reported with 95% confidence interval.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pdig.0000276.s003.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pdig.0000276.s004" position="float" content-type="local-data">
      <label>S4 Table</label>
      <caption>
        <title>Descriptive characteristics of UK Biobank cohort.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pdig.0000276.s004.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pdig.0000276.s005" position="float" content-type="local-data">
      <label>S1 Appendix</label>
      <caption>
        <title>Treatment of missing values.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pdig.0000276.s005.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pdig.0000276.s006" position="float" content-type="local-data">
      <label>S1 Fig</label>
      <caption>
        <title>Incidence of diabetes in the UK Biobank cohort.</title>
        <p>Proportion of cohort together with the number of individuals who have been diagnosed with diabetes for each time horizon.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pdig.0000276.s006.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pdig.0000276.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Topol</surname><given-names>EJ</given-names></name>. <article-title>High-performance medicine: The convergence of human and artificial intelligence</article-title>. <source>Nat Med</source>. <year>2019</year>;<volume>25</volume>(<issue>1</issue>):<fpage>44</fpage>–<lpage>56</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41591-018-0300-7</pub-id><?supplied-pmid 30617339?><pub-id pub-id-type="pmid">30617339</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref002">
      <label>2</label>
      <mixed-citation publication-type="book"><name><surname>Gerke</surname><given-names>S</given-names></name>, <name><surname>Minssen</surname><given-names>T</given-names></name>, <name><surname>Cohen</surname><given-names>G</given-names></name>. <part-title>Chapter 12—Ethical and legal challenges of artificial intelligence-driven healthcare</part-title>. In: <name><surname>Bohr</surname><given-names>A</given-names></name>, <name><surname>Memarzadeh</surname><given-names>K</given-names></name>, editors. <source>Artificial Intelligence in Healthcare</source>. <publisher-name>Academic Press</publisher-name>; <year>2020</year>. p. <fpage>295</fpage>–<lpage>336</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Sun</surname><given-names>TQ</given-names></name>, <name><surname>Medaglia</surname><given-names>R</given-names></name>. <article-title>Mapping the challenges of artificial intelligence in the public sector: Evidence from public healthcare</article-title>. <source>Government Information Quarterly</source>. <year>2019</year>;<volume>36</volume>(<issue>2</issue>):<fpage>368</fpage>–<lpage>383</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.giq.2018.09.008</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Yu</surname><given-names>KH</given-names></name>, <name><surname>Beam</surname><given-names>AL</given-names></name>, <name><surname>Kohane</surname><given-names>IS</given-names></name>. <article-title>Artificial intelligence in healthcare</article-title>. <source>Nat Biomed Eng</source>. <year>2018</year>;<volume>2</volume>(<issue>10</issue>):<fpage>719</fpage>–<lpage>731</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41551-018-0305-z</pub-id><?supplied-pmid 31015651?><pub-id pub-id-type="pmid">31015651</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Rajpurkar</surname><given-names>P</given-names></name>, <name><surname>Chen</surname><given-names>Emma</given-names></name> and <name><surname>Banerjee</surname><given-names>O</given-names></name>, <name><surname>Topol</surname><given-names>EJ</given-names></name>. <article-title>AI in health and medicine</article-title>. <source>Nat Med</source>. <year>2022</year>;<volume>28</volume>(<issue>1</issue>):<fpage>31</fpage>–<lpage>38</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41591-021-01614-0</pub-id>
<?supplied-pmid 35058619?><pub-id pub-id-type="pmid">35058619</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Petersson</surname><given-names>L</given-names></name>, <name><surname>Larsson</surname><given-names>I</given-names></name>, <name><surname>Nygren</surname><given-names>JM</given-names></name>, <name><surname>Nilsen</surname><given-names>P</given-names></name>, <name><surname>Neher</surname><given-names>M</given-names></name>, <name><surname>Reed</surname><given-names>JE</given-names></name>, <etal>et al</etal>. <article-title>Challenges to implementing artificial intelligence in healthcare: A qualitative interview study with healthcare leaders in Sweden</article-title>. <source>BMC Health Serv Res</source>. <year>2022</year>;<volume>22</volume>(<issue>1</issue>):<fpage>850</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12913-022-08215-8</pub-id><?supplied-pmid 35778736?><pub-id pub-id-type="pmid">35778736</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref007">
      <label>7</label>
      <mixed-citation publication-type="other">Alaa A, van der Schaar M. AutoPrognosis: Automated clinical prognostic modeling via Bayesian optimization with structured kernel learning. In: Proceedings of the 35th International Conference on Machine Learning. 2018;80:139–148.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Elsken</surname><given-names>T</given-names></name>, <name><surname>Metzen</surname><given-names>JH</given-names></name>, <name><surname>Hutter</surname><given-names>F</given-names></name>. <article-title>Neural architecture search: A survey</article-title>. <source>J Mach Learn Res</source>. <year>2019</year>;<volume>20</volume>(<issue>55</issue>):<fpage>1</fpage>–<lpage>21</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Bergstra</surname><given-names>J</given-names></name>, <name><surname>Bardenet</surname><given-names>R</given-names></name>, <name><surname>Bengio</surname><given-names>Y</given-names></name>, <name><surname>Kégl</surname><given-names>B</given-names></name>. <article-title>Algorithms for hyper-parameter optimization</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2011</year>;<volume>24</volume>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref010">
      <label>10</label>
      <mixed-citation publication-type="other">Thornton C, Hutter F, Hoos HH, Leyton-Brown K. Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms. In: Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. Association for Computing Machinery; 2013. p. 847–855. Available from: <pub-id pub-id-type="doi">10.1145/2487575.2487629</pub-id>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Feurer</surname><given-names>M</given-names></name>, <name><surname>Klein</surname><given-names>A</given-names></name>, <name><surname>Eggensperger</surname><given-names>K</given-names></name>, <name><surname>Springenberg</surname><given-names>J</given-names></name>, <name><surname>Blum</surname><given-names>M</given-names></name>, <name><surname>Hutter</surname><given-names>F</given-names></name>. <article-title>Efficient and robust automated machine learning</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2015</year>;<volume>28</volume>:<fpage>2755</fpage>–<lpage>2763</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Alaa</surname><given-names>AM</given-names></name>, <name><surname>Bolton</surname><given-names>T</given-names></name>, <name><surname>Di Angelantonio</surname><given-names>E</given-names></name>, <name><surname>Rudd</surname><given-names>JHF</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>. <article-title>Cardiovascular disease risk prediction using automated machine learning: A prospective study of 423,604 UK Biobank participants</article-title>. <source>PLoS One</source>. <year>2019</year>;<volume>14</volume>(<issue>5</issue>):<fpage>1</fpage>–<lpage>17</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0213653</pub-id><?supplied-pmid 31091238?><pub-id pub-id-type="pmid">31091238</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Alaa</surname><given-names>AM</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>. <article-title>Prognostication and risk factors for cystic fibrosis via automated machine learning</article-title>. <source>Sci Rep</source>. <year>2018</year>;<volume>8</volume>(<issue>1</issue>):<fpage>11242</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-018-29523-2</pub-id><?supplied-pmid 30050169?><pub-id pub-id-type="pmid">30050169</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Alaa</surname><given-names>AM</given-names></name>, <name><surname>Gurdasani</surname><given-names>D</given-names></name>, <name><surname>Harris</surname><given-names>AL</given-names></name>, <name><surname>Rashbass</surname><given-names>J</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>. <article-title>Machine learning to guide the use of adjuvant therapies for breast cancer</article-title>. <source>Nat Mach Intell</source>. <year>2021</year>;<volume>3</volume>(<issue>8</issue>):<fpage>716</fpage>–<lpage>726</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s42256-021-00353-8</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Rahbar</surname><given-names>H</given-names></name>, <name><surname>Hippe</surname><given-names>DS</given-names></name>, <name><surname>Alaa</surname><given-names>A</given-names></name>, <name><surname>Cheeney</surname><given-names>SH</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>, <name><surname>Partridge</surname><given-names>SC</given-names></name>, <etal>et al</etal>. <article-title>The value of patient and tumor factors in predicting preoperative breast MRI outcomes</article-title>. <source>Radiol Imaging Cancer</source>. <year>2020</year>;<volume>2</volume>(<issue>4</issue>):<fpage>e190099</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1148/rycan.2020190099</pub-id><?supplied-pmid 32803166?><pub-id pub-id-type="pmid">32803166</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Qian</surname><given-names>Z</given-names></name>, <name><surname>Alaa</surname><given-names>AM</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>. <article-title>CPAS: The UK’s national machine learning-based hospital capacity planning system for COVID-19</article-title>. <source>Machine Learning</source>. <year>2021</year>;<volume>110</volume>(<issue>1</issue>):<fpage>15</fpage>–<lpage>35</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10994-020-05921-4</pub-id><?supplied-pmid 33250568?><pub-id pub-id-type="pmid">33250568</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Shah</surname><given-names>AA</given-names></name>, <name><surname>Devana</surname><given-names>SK</given-names></name>, <name><surname>Lee</surname><given-names>C</given-names></name>, <name><surname>Kianian</surname><given-names>R</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>, <name><surname>SooHoo</surname><given-names>NF</given-names></name>. <article-title>Development of a novel, potentially universal machine learning algorithm for prediction of complications after total hip arthroplasty</article-title>. <source>J Arthroplasty</source>. <year>2021</year>;<volume>36</volume>(<issue>5</issue>):<fpage>1655</fpage>–<lpage>1662.e1</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.arth.2020.12.040</pub-id><?supplied-pmid 33478891?><pub-id pub-id-type="pmid">33478891</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Devana</surname><given-names>SK</given-names></name>, <name><surname>Shah</surname><given-names>AA</given-names></name>, <name><surname>Lee</surname><given-names>C</given-names></name>, <name><surname>Roney</surname><given-names>AR</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>, <name><surname>SooHoo</surname><given-names>NF</given-names></name>. <article-title>A novel, potentially universal machine learning algorithm to predict complications in total knee arthroplasty</article-title>. <source>Arthroplast Today</source>. <year>2021</year>;<volume>10</volume>:<fpage>135</fpage>–<lpage>143</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.artd.2021.06.020</pub-id><?supplied-pmid 34401416?><pub-id pub-id-type="pmid">34401416</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Shah</surname><given-names>AA</given-names></name>, <name><surname>Devana</surname><given-names>SK</given-names></name>, <name><surname>Lee</surname><given-names>C</given-names></name>, <name><surname>Bugarin</surname><given-names>A</given-names></name>, <name><surname>Lord</surname><given-names>EL</given-names></name>, <name><surname>Shamie</surname><given-names>AN</given-names></name>, <etal>et al</etal>. <article-title>Machine learning-driven identification of novel patient factors for prediction of major complications after posterior cervical spinal fusion</article-title>. <source>Eur Spine J</source>. <year>2022</year>;<volume>31</volume>(<issue>8</issue>):<fpage>1952</fpage>–<lpage>1959</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s00586-021-06961-7</pub-id><?supplied-pmid 34392418?><pub-id pub-id-type="pmid">34392418</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Shah</surname><given-names>AA</given-names></name>, <name><surname>Devana</surname><given-names>SK</given-names></name>, <name><surname>Lee</surname><given-names>C</given-names></name>, <name><surname>Bugarin</surname><given-names>A</given-names></name>, <name><surname>Hong</surname><given-names>MK</given-names></name>, <name><surname>Upfill-Brown</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>A risk calculator for the prediction of C5 nerve root palsy after instrumented cervical fusion</article-title>. <source>World Neurosurg</source>. <year>2022</year>;<volume>166</volume>:<fpage>e703</fpage>–<lpage>e710</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.wneu.2022.07.082</pub-id><?supplied-pmid 35872129?><pub-id pub-id-type="pmid">35872129</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Callender</surname><given-names>T</given-names></name>, <name><surname>Imrie</surname><given-names>F</given-names></name>, <name><surname>Cebere</surname><given-names>B</given-names></name>, <name><surname>Pashayan</surname><given-names>N</given-names></name>, <name><surname>Navani</surname><given-names>N</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Assessing eligibility for lung cancer screening: Parsimonious multi-country ensemble machine learning models for lung cancer prediction</article-title>. <source>medRxiv</source>. <year>2023</year>; p. <fpage>2023</fpage>–<lpage>01</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>van Buuren</surname><given-names>S</given-names></name>, <name><surname>Groothuis-Oudshoorn</surname><given-names>K</given-names></name>. <article-title>mice: Multivariate imputation by chained equations in R</article-title>. <source>J Stat Softw</source>. <year>2011</year>;<volume>45</volume>(<issue>3</issue>):<fpage>1</fpage>–<lpage>67</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Stekhoven</surname><given-names>DJ</given-names></name>, <name><surname>Bühlmann</surname><given-names>P</given-names></name>. <article-title>MissForest—non-parametric missing value imputation for mixed-type data</article-title>. <source>Bioinformatics</source>. <year>2011</year>;<volume>28</volume>(<issue>1</issue>):<fpage>112</fpage>–<lpage>118</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btr597</pub-id><?supplied-pmid 22039212?><pub-id pub-id-type="pmid">22039212</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref024">
      <label>24</label>
      <mixed-citation publication-type="other">Jarrett D, Cebere BC, Liu T, Curth A, van der Schaar M. HyperImpute: Generalized iterative imputation with automatic model selection. In: Proceedings of the 39th International Conference on Machine Learning. 2022;162:9916–9937.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>J</given-names></name>, <name><surname>Gelman</surname><given-names>A</given-names></name>, <name><surname>Hill</surname><given-names>J</given-names></name>, <name><surname>Su</surname><given-names>YS</given-names></name>, <name><surname>Kropko</surname><given-names>J</given-names></name>. <article-title>On the stationary distribution of iterative imputations</article-title>. <source>Biometrika</source>. <year>2013</year>;<volume>101</volume>(<issue>1</issue>):<fpage>155</fpage>–<lpage>173</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/biomet/ast044</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref026">
      <label>26</label>
      <mixed-citation publication-type="book"><name><surname>Van Buuren</surname><given-names>S</given-names></name>. <source>Flexible imputation of missing data</source>. <publisher-name>CRC press</publisher-name>; <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref027">
      <label>27</label>
      <mixed-citation publication-type="other">Wang Z, Li C, Jegelka S, Kohli P. Batched high-dimensional Bayesian optimization via structural kernel learning. In: Proceedings of the 34th International Conference on Machine Learning. 2017; p. 3656–3664.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>L</given-names></name>, <name><surname>Jamieson</surname><given-names>K</given-names></name>, <name><surname>DeSalvo</surname><given-names>G</given-names></name>, <name><surname>Rostamizadeh</surname><given-names>A</given-names></name>, <name><surname>Talwalkar</surname><given-names>A</given-names></name>. <article-title>Hyperband: A novel bandit-based approach to hyperparameter optimization</article-title>. <source>J Mach Learn Res</source>. <year>2018</year>;<volume>18</volume>(<issue>185</issue>):<fpage>1</fpage>–<lpage>52</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Crone</surname><given-names>SF</given-names></name>, <name><surname>Lessmann</surname><given-names>S</given-names></name>, <name><surname>Stahlbock</surname><given-names>R</given-names></name>. <article-title>The impact of preprocessing on data mining: An evaluation of classifier sensitivity in direct marketing</article-title>. <source>Eur J Oper Res</source>. <year>2006</year>;<volume>173</volume>(<issue>3</issue>):<fpage>781</fpage>–<lpage>800</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ejor.2005.07.023</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref030">
      <label>30</label>
      <mixed-citation publication-type="other">Food and Drug Administration and others. Proposed regulatory framework for modifications to artificial intelligence/machine learning (AI/ML)-based software as a medical device (SaMD). 2019;.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Mourby</surname><given-names>M</given-names></name>, <name><surname>Ó Cathaoir</surname><given-names>K</given-names></name>, <name><surname>Collin</surname><given-names>CB</given-names></name>. <article-title>Transparency of machine-learning in healthcare: The GDPR &amp; European health law</article-title>. <source>Comput Law Secur Rev</source>. <year>2021</year>;<volume>43</volume>:<fpage>105611</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.clsr.2021.105611</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Kattan</surname><given-names>MW</given-names></name>, <name><surname>Hess</surname><given-names>KR</given-names></name>, <name><surname>Amin</surname><given-names>MB</given-names></name>, <name><surname>Lu</surname><given-names>Y</given-names></name>, <name><surname>Moons</surname><given-names>KGM</given-names></name>, <name><surname>Gershenwald</surname><given-names>JE</given-names></name>, <etal>et al</etal>. <article-title>American Joint Committee on Cancer acceptance criteria for inclusion of risk models for individualized prognosis in the practice of precision medicine</article-title>. <source>CA Cancer J Clin</source>. <year>2016</year>;<volume>66</volume>(<issue>5</issue>):<fpage>370</fpage>–<lpage>374</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3322/caac.21339</pub-id><?supplied-pmid 26784705?><pub-id pub-id-type="pmid">26784705</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Lundberg</surname><given-names>SM</given-names></name>, <name><surname>Lee</surname><given-names>SI</given-names></name>. <article-title>A unified approach to interpreting model predictions</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2017</year>;<volume>30</volume>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Crabbe</surname><given-names>J</given-names></name>, <name><surname>Qian</surname><given-names>Z</given-names></name>, <name><surname>Imrie</surname><given-names>F</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>. <article-title>Explaining latent representations with a corpus of examples</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2021</year>;<volume>34</volume>:<fpage>12154</fpage>–<lpage>12166</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Crabbe</surname><given-names>J</given-names></name>, <name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Zame</surname><given-names>W</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>. <article-title>Learning outside the Black-Box: The pursuit of interpretable models</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2020</year>;<volume>33</volume>:<fpage>17838</fpage>–<lpage>17849</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref036">
      <label>36</label>
      <mixed-citation publication-type="other">Streamlit. Available from: <ext-link xlink:href="https://streamlit.io/" ext-link-type="uri">https://streamlit.io/</ext-link>;.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Luo</surname><given-names>G</given-names></name>, <name><surname>Stone</surname><given-names>BL</given-names></name>, <name><surname>Johnson</surname><given-names>MD</given-names></name>, <name><surname>Tarczy-Hornoch</surname><given-names>P</given-names></name>, <name><surname>Wilcox</surname><given-names>AB</given-names></name>, <name><surname>Mooney</surname><given-names>SD</given-names></name>, <etal>et al</etal>. <article-title>Automating construction of machine learning models with clinical big data: Proposal rationale and methods</article-title>. <source>JMIR Res Protoc</source>. <year>2017</year>;<volume>6</volume>(<issue>8</issue>):<fpage>e175</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2196/resprot.7757</pub-id><?supplied-pmid 28851678?><pub-id pub-id-type="pmid">28851678</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref038">
      <label>38</label>
      <mixed-citation publication-type="other">Elshawi R, Maher M, Sakr S. Automated machine learning: State-of-the-art and open challenges. arXiv preprint arXiv:190602287. 2019;.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Sculley</surname><given-names>D</given-names></name>, <name><surname>Holt</surname><given-names>G</given-names></name>, <name><surname>Golovin</surname><given-names>D</given-names></name>, <name><surname>Davydov</surname><given-names>E</given-names></name>, <name><surname>Phillips</surname><given-names>T</given-names></name>, <name><surname>Ebner</surname><given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Hidden technical debt in machine learning systems</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2015</year>;<volume>28</volume>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>Nestor</surname><given-names>B</given-names></name>, <name><surname>McDermott</surname><given-names>M</given-names></name>, <name><surname>Chauhan</surname><given-names>G</given-names></name>, <name><surname>Naumann</surname><given-names>T</given-names></name>, <name><surname>Hughes</surname><given-names>MC</given-names></name>, <name><surname>Goldenberg</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Rethinking clinical prediction: Why machine learning must consider year of care and feature aggregation</article-title>. <source>Machine Learning for Health (ML4H) Workshop at NeurIPS</source>. <year>2018</year>;.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Cox</surname><given-names>DR</given-names></name>. <article-title>Regression models and life-tables</article-title>. <source>J R Stat Soc Series B Stat Methodol</source>. <year>1972</year>;<volume>34</volume>(<issue>2</issue>):<fpage>187</fpage>–<lpage>202</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref042">
      <label>42</label>
      <mixed-citation publication-type="journal"><name><surname>Volovici</surname><given-names>V</given-names></name>, <name><surname>Syn</surname><given-names>NL</given-names></name>, <name><surname>Ercole</surname><given-names>A</given-names></name>, <name><surname>Zhao</surname><given-names>JJ</given-names></name>, <name><surname>Liu</surname><given-names>N</given-names></name>. <article-title>Steps to avoid overuse and misuse of machine learning in clinical research</article-title>. <source>Nat Med</source>. <year>2022</year>;<volume>28</volume>(<issue>10</issue>):<fpage>1996</fpage>–<lpage>1999</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41591-022-01961-6</pub-id><?supplied-pmid 36097217?><pub-id pub-id-type="pmid">36097217</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Tomašev</surname><given-names>N</given-names></name>, <name><surname>Cornebise</surname><given-names>J</given-names></name>, <name><surname>Hutter</surname><given-names>F</given-names></name>, <name><surname>Mohamed</surname><given-names>S</given-names></name>, <name><surname>Picciariello</surname><given-names>A</given-names></name>, <name><surname>Connelly</surname><given-names>B</given-names></name>, <etal>et al</etal>. <article-title>AI for social good: Unlocking the opportunity for positive impact</article-title>. <source>Nat Commun</source>. <year>2020</year>;<volume>11</volume>(<issue>1</issue>):<fpage>2468</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41467-020-15871-z</pub-id><?supplied-pmid 32424119?><pub-id pub-id-type="pmid">32424119</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref044">
      <label>44</label>
      <mixed-citation publication-type="journal"><name><surname>Akbilgic</surname><given-names>O</given-names></name>, <name><surname>Davis</surname><given-names>RL</given-names></name>. <article-title>The promise of machine learning: When will it be delivered?</article-title><source>J Card Fail</source>. <year>2019</year>;<volume>25</volume>(<issue>6</issue>):<fpage>484</fpage>–<lpage>485</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.cardfail.2019.04.006</pub-id><?supplied-pmid 30978508?><pub-id pub-id-type="pmid">30978508</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref045">
      <label>45</label>
      <mixed-citation publication-type="journal"><name><surname>Schulz</surname><given-names>MA</given-names></name>, <name><surname>Yeo</surname><given-names>BTT</given-names></name>, <name><surname>Vogelstein</surname><given-names>JT</given-names></name>, <name><surname>Mourao-Miranada</surname><given-names>J</given-names></name>, <name><surname>Kather</surname><given-names>JN</given-names></name>, <name><surname>Kording</surname><given-names>K</given-names></name>, <etal>et al</etal>. <article-title>Different scaling of linear models and deep learning in UKBiobank brain images versus machine-learning datasets</article-title>. <source>Nat Commun</source>. <year>2020</year>;<volume>11</volume>(<issue>1</issue>):<fpage>4238</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41467-020-18037-z</pub-id><?supplied-pmid 32843633?><pub-id pub-id-type="pmid">32843633</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref046">
      <label>46</label>
      <mixed-citation publication-type="journal"><name><surname>Chowdhury</surname><given-names>MZI</given-names></name>, <name><surname>Turin</surname><given-names>TC</given-names></name>. <article-title>Variable selection strategies and its importance in clinical prediction modelling</article-title>. <source>Fam Med Community Health</source>. <year>2020</year>;<volume>8</volume>(<issue>1</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1136/fmch-2019-000262</pub-id><?supplied-pmid 32148735?><pub-id pub-id-type="pmid">32148735</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref047">
      <label>47</label>
      <mixed-citation publication-type="book"><name><surname>Steyerberg</surname><given-names>E</given-names></name>. <source>Clinical prediction models: A practical approach to development, validation, and updating</source>. <publisher-name>Springer</publisher-name>; <year>2008</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref048">
      <label>48</label>
      <mixed-citation publication-type="journal"><name><surname>Guyon</surname><given-names>I</given-names></name>, <name><surname>Elisseeff</surname><given-names>A</given-names></name>. <article-title>An introduction to variable and feature selection</article-title>. <source>J Mach Learn Res</source>. <year>2003</year>;<volume>3</volume>(<issue>Mar</issue>):<fpage>1157</fpage>–<lpage>1182</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref049">
      <label>49</label>
      <mixed-citation publication-type="other">Caruana R, Lou Y, Gehrke J, Koch P, Sturm M, Elhadad N. Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission. In: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 2015; p. 1721–1730.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref050">
      <label>50</label>
      <mixed-citation publication-type="journal"><name><surname>Winkler</surname><given-names>JK</given-names></name>, <name><surname>Fink</surname><given-names>C</given-names></name>, <name><surname>Toberer</surname><given-names>F</given-names></name>, <name><surname>Enk</surname><given-names>A</given-names></name>, <name><surname>Deinlein</surname><given-names>T</given-names></name>, <name><surname>Hofmann-Wellenhof</surname><given-names>R</given-names></name>, <etal>et al</etal>. <article-title>Association between surgical skin markings in dermoscopic images and diagnostic performance of a deep learning convolutional neural network for melanoma recognition</article-title>. <source>JAMA Dermatol</source>. <year>2019</year>;<volume>155</volume>(<issue>10</issue>):<fpage>1135</fpage>–<lpage>1141</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1001/jamadermatol.2019.1735</pub-id><?supplied-pmid 31411641?><pub-id pub-id-type="pmid">31411641</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref051">
      <label>51</label>
      <mixed-citation publication-type="journal"><name><surname>Geirhos</surname><given-names>R</given-names></name>, <name><surname>Jacobsen</surname><given-names>JH</given-names></name>, <name><surname>Michaelis</surname><given-names>C</given-names></name>, <name><surname>Zemel</surname><given-names>R</given-names></name>, <name><surname>Brendel</surname><given-names>W</given-names></name>, <name><surname>Bethge</surname><given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Shortcut learning in deep neural networks</article-title>. <source>Nat Mach Intell</source>. <year>2020</year>;<volume>2</volume>(<issue>11</issue>):<fpage>665</fpage>–<lpage>673</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s42256-020-00257-z</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref052">
      <label>52</label>
      <mixed-citation publication-type="journal"><name><surname>Tampu</surname><given-names>IE</given-names></name>, <name><surname>Eklund</surname><given-names>A</given-names></name>, <name><surname>Haj-Hosseini</surname><given-names>N</given-names></name>. <article-title>Inflation of test accuracy due to data leakage in deep learning-based classification of OCT images</article-title>. <source>Sci Data</source>. <year>2022</year>;<volume>9</volume>(<issue>1</issue>):<fpage>580</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41597-022-01618-6</pub-id><?supplied-pmid 36138025?><pub-id pub-id-type="pmid">36138025</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref053">
      <label>53</label>
      <mixed-citation publication-type="journal"><name><surname>DeGrave</surname><given-names>AJ</given-names></name>, <name><surname>Janizek</surname><given-names>JD</given-names></name>, <name><surname>Lee</surname><given-names>SI</given-names></name>. <article-title>AI for radiographic COVID-19 detection selects shortcuts over signal</article-title>. <source>Nat Mach Intell</source>. <year>2021</year>;<volume>3</volume>(<issue>7</issue>):<fpage>610</fpage>–<lpage>619</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s42256-021-00338-7</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref054">
      <label>54</label>
      <mixed-citation publication-type="journal"><name><surname>Roberts</surname><given-names>M</given-names></name>, <name><surname>Driggs</surname><given-names>D</given-names></name>, <name><surname>Thorpe</surname><given-names>M</given-names></name>, <name><surname>Gilbey</surname><given-names>J</given-names></name>, <name><surname>Yeung</surname><given-names>M</given-names></name>, <name><surname>Ursprung</surname><given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Common pitfalls and recommendations for using machine learning to detect and prognosticate for COVID-19 using chest radiographs and CT scans</article-title>. <source>Nat Mach Intell</source>. <year>2021</year>;<volume>3</volume>(<issue>3</issue>):<fpage>199</fpage>–<lpage>217</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s42256-021-00307-0</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref055">
      <label>55</label>
      <mixed-citation publication-type="journal"><name><surname>Rajkomar</surname><given-names>A</given-names></name>, <name><surname>Hardt</surname><given-names>M</given-names></name>, <name><surname>Howell</surname><given-names>MD</given-names></name>, <name><surname>Corrado</surname><given-names>G</given-names></name>, <name><surname>Chin</surname><given-names>MH</given-names></name>. <article-title>Ensuring fairness in machine learning to advance health equity</article-title>. <source>Ann Intern Med</source>. <year>2018</year>;<volume>169</volume>(<issue>12</issue>):<fpage>866</fpage>–<lpage>872</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.7326/M18-1990</pub-id><?supplied-pmid 30508424?><pub-id pub-id-type="pmid">30508424</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref056">
      <label>56</label>
      <mixed-citation publication-type="journal"><name><surname>Yoon</surname><given-names>CH</given-names></name>, <name><surname>Torrance</surname><given-names>R</given-names></name>, <name><surname>Scheinerman</surname><given-names>N</given-names></name>. <article-title>Machine learning in medicine: Should the pursuit of enhanced interpretability be abandoned?</article-title><source>J Med Ethics</source>. <year>2022</year>;<volume>48</volume>(<issue>9</issue>):<fpage>581</fpage>–<lpage>585</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1136/medethics-2020-107102</pub-id><?supplied-pmid 34006600?><pub-id pub-id-type="pmid">34006600</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref057">
      <label>57</label>
      <mixed-citation publication-type="journal"><name><surname>Laiteerapong</surname><given-names>N</given-names></name>, <name><surname>Huang</surname><given-names>ES</given-names></name>. <article-title>The pace of change in medical practice and health policy: Collision or coexistence?</article-title><source>J Gen Intern Med</source>. <year>2015</year>;<volume>30</volume>(<issue>6</issue>):<fpage>848</fpage>–<lpage>852</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s11606-015-3182-0</pub-id><?supplied-pmid 25608743?><pub-id pub-id-type="pmid">25608743</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref058">
      <label>58</label>
      <mixed-citation publication-type="journal"><name><surname>Gupta</surname><given-names>DM</given-names></name>, <name><surname>Boland</surname><given-names>RJ</given-names></name>, <name><surname>Aron</surname><given-names>DC</given-names></name>. <article-title>The physician’s experience of changing clinical practice: a struggle to unlearn</article-title>. <source>Implement Sci</source>. <year>2017</year>;<volume>12</volume>(<issue>1</issue>):<fpage>28</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s13012-017-0555-2</pub-id><?supplied-pmid 28245849?><pub-id pub-id-type="pmid">28245849</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref059">
      <label>59</label>
      <mixed-citation publication-type="journal"><name><surname>Beam</surname><given-names>AL</given-names></name>, <name><surname>Manrai</surname><given-names>AK</given-names></name>, <name><surname>Ghassemi</surname><given-names>M</given-names></name>. <article-title>Challenges to the reproducibility of machine learning models in health care</article-title>. <source>JAMA</source>. <year>2020</year>;<volume>323</volume>(<issue>4</issue>):<fpage>305</fpage>–<lpage>306</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1001/jama.2019.20866</pub-id><?supplied-pmid 31904799?><pub-id pub-id-type="pmid">31904799</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref060">
      <label>60</label>
      <mixed-citation publication-type="journal"><name><surname>LeVeque</surname><given-names>RJ</given-names></name>, <name><surname>Mitchell</surname><given-names>IM</given-names></name>, <name><surname>Stodden</surname><given-names>V</given-names></name>. <article-title>Reproducible research for scientific computing: Tools and strategies for changing the culture</article-title>. <source>Comput Sci Eng</source>. <year>2012</year>;<volume>14</volume>(<issue>4</issue>):<fpage>13</fpage>–<lpage>17</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/MCSE.2012.38</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref061">
      <label>61</label>
      <mixed-citation publication-type="journal"><name><surname>Miłkowski</surname><given-names>M</given-names></name>, <name><surname>Hensel</surname><given-names>WM</given-names></name>, <name><surname>Hohol</surname><given-names>M</given-names></name>. <article-title>Replicability or reproducibility? On the replication crisis in computational neuroscience and sharing only relevant detail</article-title>. <source>J Comput Neurosci</source>. <year>2018</year>;<volume>45</volume>(<issue>3</issue>):<fpage>163</fpage>–<lpage>172</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10827-018-0702-z</pub-id><?supplied-pmid 30377880?><pub-id pub-id-type="pmid">30377880</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref062">
      <label>62</label>
      <mixed-citation publication-type="journal"><name><surname>Haibe-Kains</surname><given-names>B</given-names></name>, <name><surname>Adam</surname><given-names>GA</given-names></name>, <name><surname>Hosny</surname><given-names>A</given-names></name>, <name><surname>Khodakarami</surname><given-names>F</given-names></name>, <collab>Board MAQCMS</collab>, <name><surname>Levi</surname></name>, <etal>et al</etal>. <article-title>Transparency and reproducibility in artificial intelligence</article-title>. <source>Nature</source>. <year>2020</year>;<volume>586</volume>(<issue>7829</issue>):<fpage>E14</fpage>–<lpage>E16</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41586-020-2766-y</pub-id><?supplied-pmid 33057217?><pub-id pub-id-type="pmid">33057217</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref063">
      <label>63</label>
      <mixed-citation publication-type="journal"><name><surname>Sudlow</surname><given-names>C</given-names></name>, <name><surname>Gallacher</surname><given-names>J</given-names></name>, <name><surname>Allen</surname><given-names>N</given-names></name>, <name><surname>Beral</surname><given-names>V</given-names></name>, <name><surname>Burton</surname><given-names>P</given-names></name>, <name><surname>Danesh</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>UK Biobank: An open access resource for identifying the causes of a wide range of complex diseases of middle and old age</article-title>. <source>PLoS Med</source>. <year>2015</year>;<volume>12</volume>(<issue>3</issue>):<fpage>1</fpage>–<lpage>10</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pmed.1001779</pub-id><?supplied-pmid 25826379?><pub-id pub-id-type="pmid">25826379</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref064">
      <label>64</label>
      <mixed-citation publication-type="journal"><name><surname>Adamska</surname><given-names>L</given-names></name>, <name><surname>Allen</surname><given-names>N</given-names></name>, <name><surname>Flaig</surname><given-names>R</given-names></name>, <name><surname>Sudlow</surname><given-names>C</given-names></name>, <name><surname>Lay</surname><given-names>M</given-names></name>, <name><surname>Landray</surname><given-names>M</given-names></name>. <article-title>Challenges of linking to routine healthcare records in UK Biobank</article-title>. <source>Trials</source>. <year>2015</year>;<volume>16</volume>(<issue>2</issue>):<fpage>O68</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/1745-6215-16-S2-O68</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref065">
      <label>65</label>
      <mixed-citation publication-type="other">World Health Organization, et al. Global report on diabetes. World Health Organization; 2016.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref066">
      <label>66</label>
      <mixed-citation publication-type="journal"><name><surname>Bang</surname><given-names>H</given-names></name>, <name><surname>Edwards</surname><given-names>AM</given-names></name>, <name><surname>Bomback</surname><given-names>AS</given-names></name>, <name><surname>Ballantyne</surname><given-names>CM</given-names></name>, <name><surname>Brillon</surname><given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Development and validation of a patient self-assessment score for diabetes risk</article-title>. <source>Ann Intern Med</source>. <year>2009</year>;<volume>151</volume>(<issue>11</issue>):<fpage>775</fpage>–<lpage>783</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1059/0003-4819-151-11-200912010-00005</pub-id><?supplied-pmid 19949143?><pub-id pub-id-type="pmid">19949143</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref067">
      <label>67</label>
      <mixed-citation publication-type="journal"><name><surname>Lindström̈</surname><given-names>J</given-names></name>, <name><surname>Tuomilehto</surname><given-names>J</given-names></name>. <article-title>The Diabetes Risk Score: A practical tool to predict type 2 diabetes risk</article-title>. <source>Diabetes Care</source>. <year>2003</year>;<volume>26</volume>(<issue>3</issue>):<fpage>725</fpage>–<lpage>731</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2337/diacare.26.3.725</pub-id><?supplied-pmid 12610029?><pub-id pub-id-type="pmid">12610029</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref068">
      <label>68</label>
      <mixed-citation publication-type="journal"><name><surname>Hippisley-Cox</surname><given-names>J</given-names></name>, <name><surname>Coupland</surname><given-names>C</given-names></name>. <article-title>Development and validation of QDiabetes-2018 risk prediction algorithm to estimate future risk of type 2 diabetes: cohort study</article-title>. <source>BMJ</source>. <year>2017</year>;<volume>359</volume>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1136/bmj.j5019</pub-id><?supplied-pmid 29158232?><pub-id pub-id-type="pmid">29158232</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref069">
      <label>69</label>
      <mixed-citation publication-type="journal"><name><surname>Vickers</surname><given-names>AJ</given-names></name>, <name><surname>Elkin</surname><given-names>EB</given-names></name>. <article-title>Decision curve analysis: A novel method for evaluating prediction models</article-title>. <source>Med Decis Making</source>. <year>2006</year>;<volume>26</volume>(<issue>6</issue>):<fpage>565</fpage>–<lpage>574</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1177/0272989X06295361</pub-id><?supplied-pmid 17099194?><pub-id pub-id-type="pmid">17099194</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref070">
      <label>70</label>
      <mixed-citation publication-type="journal"><name><surname>Vickers</surname><given-names>AJ</given-names></name>. <article-title>Decision analysis for the evaluation of diagnostic tests, prediction models, and molecular markers</article-title>. <source>Am Stat</source>. <year>2008</year>;<volume>62</volume>(<issue>4</issue>):<fpage>314</fpage>–<lpage>320</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1198/000313008X370302</pub-id><?supplied-pmid 19132141?><pub-id pub-id-type="pmid">19132141</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref071">
      <label>71</label>
      <mixed-citation publication-type="journal"><name><surname>Moons</surname><given-names>KGM</given-names></name>, <name><surname>Altman</surname><given-names>DG</given-names></name>, <name><surname>Reitsma</surname><given-names>JB</given-names></name>, <name><surname>Ioannidis</surname><given-names>JPA</given-names></name>, <name><surname>Macaskill</surname><given-names>P</given-names></name>, <name><surname>Steyerberg</surname><given-names>EW</given-names></name>, <etal>et al</etal>. <article-title>Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD): Explanation and Elaboration</article-title>. <source>Ann Intern Med</source>. <year>2015</year>;<volume>162</volume>(<issue>1</issue>):<fpage>W1</fpage>–<lpage>W73</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.7326/M14-0698</pub-id><?supplied-pmid 25560730?><pub-id pub-id-type="pmid">25560730</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref072">
      <label>72</label>
      <mixed-citation publication-type="book"><name><surname>Cohen</surname><given-names>J</given-names></name>. <source>Statistical power analysis for the behavioral sciences</source>. <publisher-name>Routledge</publisher-name>; <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref073">
      <label>73</label>
      <mixed-citation publication-type="journal"><name><surname>Nano</surname><given-names>J</given-names></name>, <name><surname>Muka</surname><given-names>T</given-names></name>, <name><surname>Ligthart</surname><given-names>S</given-names></name>, <name><surname>Hofman</surname><given-names>A</given-names></name>, <name><surname>Darwish Murad</surname><given-names>S</given-names></name>, <name><surname>Janssen</surname><given-names>HL</given-names></name>, <etal>et al</etal>. <article-title>Gamma-glutamyltransferase levels, prediabetes and type 2 diabetes: A Mendelian randomization study</article-title>. <source>Int J Epidemiol</source>. <year>2017</year>;<volume>46</volume>(<issue>5</issue>):<fpage>1400</fpage>–<lpage>1409</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/ije/dyx006</pub-id><?supplied-pmid 28338987?><pub-id pub-id-type="pmid">28338987</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref074">
      <label>74</label>
      <mixed-citation publication-type="book"><collab>International Diabetes Federation</collab>. <source>IDF Diabetes Atlas</source>, <edition designator="6">6th edn</edition>.; <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref075">
      <label>75</label>
      <mixed-citation publication-type="journal"><name><surname>Gale</surname><given-names>EA</given-names></name>, <name><surname>Gillespie</surname><given-names>KM</given-names></name>. <article-title>Diabetes and gender</article-title>. <source>Diabetologia</source>. <year>2001</year>;<volume>44</volume>(<issue>1</issue>):<fpage>3</fpage>–<lpage>15</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s001250051573</pub-id><?supplied-pmid 11206408?><pub-id pub-id-type="pmid">11206408</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref076">
      <label>76</label>
      <mixed-citation publication-type="other">American Diabetes Association. <ext-link xlink:href="https://diabetes.org/diabetes/a1c/diagnosis" ext-link-type="uri">https://diabetes.org/diabetes/a1c/diagnosis</ext-link>;.</mixed-citation>
    </ref>
  </ref-list>
</back>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jats2jats3.xsl?>
<?ConverterInfo.Version 1?>
<?properties open_access?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLOS Digit Health</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLOS Digit Health</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-title-group>
      <journal-title>PLOS Digital Health</journal-title>
    </journal-title-group>
    <issn pub-type="epub">2767-3170</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">10287005</article-id>
    <article-id pub-id-type="publisher-id">PDIG-D-22-00328</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pdig.0000276</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Epidemiology</subject>
          <subj-group>
            <subject>Medical Risk Factors</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Endocrinology</subject>
          <subj-group>
            <subject>Endocrine Disorders</subject>
            <subj-group>
              <subject>Diabetes Mellitus</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Medical Conditions</subject>
          <subj-group>
            <subject>Metabolic Disorders</subject>
            <subj-group>
              <subject>Diabetes Mellitus</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and health sciences</subject>
        <subj-group>
          <subject>Diagnostic medicine</subject>
          <subj-group>
            <subject>Diabetes diagnosis and management</subject>
            <subj-group>
              <subject>HbA1c</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and life sciences</subject>
        <subj-group>
          <subject>Biochemistry</subject>
          <subj-group>
            <subject>Proteins</subject>
            <subj-group>
              <subject>Hemoglobin</subject>
              <subj-group>
                <subject>HbA1c</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Computational Techniques</subject>
          <subj-group>
            <subject>Computational Pipelines</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
              <subj-group>
                <subject>Machine Learning Algorithms</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Machine Learning Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Mathematical and Statistical Techniques</subject>
          <subj-group>
            <subject>Statistical Methods</subject>
            <subj-group>
              <subject>Forecasting</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical Methods</subject>
              <subj-group>
                <subject>Forecasting</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Optimization</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>AutoPrognosis 2.0: Democratizing diagnostic and prognostic modeling in healthcare with automated machine learning</article-title>
      <alt-title alt-title-type="running-head">AutoPrognosis 2.0: Diagnostic and prognostic modeling with AutoML</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6241-0123</contrib-id>
        <name>
          <surname>Imrie</surname>
          <given-names>Fergus</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/visualization/">Visualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <xref rid="aff001" ref-type="aff">
          <sup>1</sup>
        </xref>
        <xref rid="cor001" ref-type="corresp">*</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Cebere</surname>
          <given-names>Bogdan</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/data-curation/">Data curation</role>
        <role content-type="http://credit.niso.org/contributor-roles/formal-analysis/">Formal analysis</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/software/">Software</role>
        <role content-type="http://credit.niso.org/contributor-roles/validation/">Validation</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>McKinney</surname>
          <given-names>Eoin F.</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/conceptualization/">Conceptualization</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff003" ref-type="aff">
          <sup>3</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>van der Schaar</surname>
          <given-names>Mihaela</given-names>
        </name>
        <role content-type="http://credit.niso.org/contributor-roles/funding-acquisition/">Funding acquisition</role>
        <role content-type="http://credit.niso.org/contributor-roles/investigation/">Investigation</role>
        <role content-type="http://credit.niso.org/contributor-roles/methodology/">Methodology</role>
        <role content-type="http://credit.niso.org/contributor-roles/project-administration/">Project administration</role>
        <role content-type="http://credit.niso.org/contributor-roles/resources/">Resources</role>
        <role content-type="http://credit.niso.org/contributor-roles/supervision/">Supervision</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-original-draft/">Writing – original draft</role>
        <role content-type="http://credit.niso.org/contributor-roles/writing-review-editing/">Writing – review &amp; editing</role>
        <xref rid="aff002" ref-type="aff">
          <sup>2</sup>
        </xref>
        <xref rid="aff004" ref-type="aff">
          <sup>4</sup>
        </xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Department of Electrical and Computer Engineering, University of California, Los Angeles, California, United States of America</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Department of Applied Mathematics and Theoretical Physics, University of Cambridge, Cambridge, United Kingdom</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Department of Medicine, University of Cambridge, Cambridge, United Kingdom</addr-line>
    </aff>
    <aff id="aff004">
      <label>4</label>
      <addr-line>The Alan Turing Institute, London, United Kingdom</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Guillot</surname>
          <given-names>Gilles</given-names>
        </name>
        <role>Editor</role>
        <xref rid="edit1" ref-type="aff"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>CSL Behring / Swiss Institute for Translational and Entrepreneurial Medicine (SITEM), SWITZERLAND</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p>The authors have no competing interests to declare.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>imrie@ucla.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="collection">
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <pub-date pub-type="epub">
      <day>22</day>
      <month>6</month>
      <year>2023</year>
    </pub-date>
    <volume>2</volume>
    <issue>6</issue>
    <elocation-id>e0000276</elocation-id>
    <history>
      <date date-type="received">
        <day>21</day>
        <month>11</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>17</day>
        <month>5</month>
        <year>2023</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2023 Imrie et al</copyright-statement>
      <copyright-year>2023</copyright-year>
      <copyright-holder>Imrie et al</copyright-holder>
      <license>
        <ali:license_ref xmlns:ali="http://www.niso.org/schemas/ali/1.0/" specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pdig.0000276.pdf"/>
    <abstract>
      <p>Diagnostic and prognostic models are increasingly important in medicine and inform many clinical decisions. Recently, machine learning approaches have shown improvement over conventional modeling techniques by better capturing complex interactions between patient covariates in a data-driven manner. However, the use of machine learning introduces technical and practical challenges that have thus far restricted widespread adoption of such techniques in clinical settings. To address these challenges and empower healthcare professionals, we present an open-source machine learning framework, AutoPrognosis 2.0, to facilitate the development of diagnostic and prognostic models. AutoPrognosis leverages state-of-the-art advances in automated machine learning to develop optimized machine learning pipelines, incorporates model explainability tools, and enables deployment of clinical demonstrators, <italic toggle="yes">without</italic> requiring significant technical expertise. To demonstrate AutoPrognosis 2.0, we provide an illustrative application where we construct a prognostic risk score for diabetes using the UK Biobank, a prospective study of 502,467 individuals. The models produced by our automated framework achieve greater discrimination for diabetes than expert clinical risk scores. We have implemented our risk score as a web-based decision support tool, which can be publicly accessed by patients and clinicians. By open-sourcing our framework as a tool for the community, we aim to provide clinicians and other medical practitioners with an accessible resource to develop new risk scores, personalized diagnostics, and prognostics using machine learning techniques.</p>
      <p><bold>Software</bold>: <ext-link xlink:href="https://github.com/vanderschaarlab/AutoPrognosis" ext-link-type="uri">https://github.com/vanderschaarlab/AutoPrognosis</ext-link></p>
    </abstract>
    <abstract abstract-type="summary">
      <title>Author summary</title>
      <p>Previous studies have reported promising applications of machine learning (ML) approaches in healthcare. However, there remain significant challenges to using ML for diagnostic and prognostic modeling, particularly for non-ML experts, that currently prevent broader adoption of these approaches. We developed an open-source tool, AutoPrognosis 2.0, to address these challenges and make modern statistical and machine learning methods available to expert and non-expert ML users. AutoPrognosis configures and optimizes ML pipelines using automated machine learning to develop powerful predictive models, while also providing interpretability methods to allow users to understand and debug these models. This study illustrates the application of AutoPrognosis to diabetes risk prediction using data from UK Biobank. The risk score developed using AutoPrognosis outperforms existing risk scores and has been implemented as a web-based decision support tool that can be publicly accessed by patients and clinicians. This study suggests that AutoPrognosis 2.0 can be used by healthcare experts to create new clinical tools and predictive pipelines across various clinical outcomes, employing advanced machine learning techniques.</p>
    </abstract>
    <funding-group>
      <funding-statement>The authors received no specific funding for this work.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="6"/>
      <page-count count="21"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>This research has been conducted using the UK Biobank resource. Data from UK Biobank is accessible through a request process (<ext-link xlink:href="https://www.ukbiobank.ac.uk/enable-your-research/register" ext-link-type="uri">https://www.ukbiobank.ac.uk/enable-your-research/register</ext-link>). The authors had no special access or privileges when accessing the data.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>This research has been conducted using the UK Biobank resource. Data from UK Biobank is accessible through a request process (<ext-link xlink:href="https://www.ukbiobank.ac.uk/enable-your-research/register" ext-link-type="uri">https://www.ukbiobank.ac.uk/enable-your-research/register</ext-link>). The authors had no special access or privileges when accessing the data.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>Introduction</title>
    <p>Machine learning (ML) systems have the potential to revolutionize medicine and become core clinical tools [<xref rid="pdig.0000276.ref001" ref-type="bibr">1</xref>]. However, there are a diverse set of challenges that must be overcome prior to routine and widespread ML adoption [<xref rid="pdig.0000276.ref002" ref-type="bibr">2</xref>, <xref rid="pdig.0000276.ref003" ref-type="bibr">3</xref>]. In particular, there are substantial technical challenges in developing, understanding, and deploying ML systems which currently render them largely inaccessible for medical practitioners [<xref rid="pdig.0000276.ref003" ref-type="bibr">3</xref>–<xref rid="pdig.0000276.ref006" ref-type="bibr">6</xref>].</p>
    <p>In an attempt to address this, we previously developed AutoPrognosis, an automated machine learning (AutoML) framework that optimizes predictive pipelines [<xref rid="pdig.0000276.ref007" ref-type="bibr">7</xref>]. AutoML aims to automate various aspects of the machine learning process. Initial AutoML approaches performed Neural Architecture Search [<xref rid="pdig.0000276.ref008" ref-type="bibr">8</xref>] or hyperparameter optimization [<xref rid="pdig.0000276.ref009" ref-type="bibr">9</xref>]. More recently, prior work has focused on both selecting the best algorithm and optimizing its hyperparameters from a pre-defined set, known as the combined algorithm selection and hyperparameter optimization (CASH) problem [<xref rid="pdig.0000276.ref010" ref-type="bibr">10</xref>, <xref rid="pdig.0000276.ref011" ref-type="bibr">11</xref>]. However, limited work focused on optimizing full ML <italic toggle="yes">pipelines</italic>, and almost all existing frameworks could only handle complete data (i.e. without missing values) and did not construct model ensembles. The initial version of AutoPrognosis [<xref rid="pdig.0000276.ref007" ref-type="bibr">7</xref>] incorporated these components in an efficient manner, employing a novel Bayesian Optimization procedure using structured kernels to solve the pipeline selection and configuration problem (PSCP). Our framework has been since applied to derive prognostic models for cardiovascular disease [<xref rid="pdig.0000276.ref012" ref-type="bibr">12</xref>], cystic fibrosis [<xref rid="pdig.0000276.ref013" ref-type="bibr">13</xref>], and breast cancer [<xref rid="pdig.0000276.ref014" ref-type="bibr">14</xref>], among a number of other indications [<xref rid="pdig.0000276.ref015" ref-type="bibr">15</xref>–<xref rid="pdig.0000276.ref021" ref-type="bibr">21</xref>]. However, our initial approach had significant limitations from both algorithmic and usability perspectives. Perhaps most significantly, it was limited to classification, did not include interpretability methods, and did not readily allow models to be shared.</p>
    <p>Consequently, in this work, we describe AutoPrognosis 2.0, a framework that addresses several major obstacles limiting the development, interpretation, and deployment of ML methods in medicine. To the best of our knowledge, this is the first approach that can simultaneously: (1) solve classification, regression, and time-to-event problems; (2) optimize ML pipelines, determine the most appropriate models, and automatically tune hyperparameters; (3) identify key variables and novel risk factors, enabling clinicians to select different numbers of variables and understand the value of information; (4) provide a diverse range of model explanations, including feature-based, example-based, and closed-form risk equations; and (5) produce web-based applications, allowing models to be readily shared with the clinical community.</p>
    <p>After describing AutoPrognosis 2.0, we outline major challenges facing clinical development and translation of diagnostic and prognostic modeling, and detail how AutoPrognosis addresses each challenge. Finally, we demonstrate the application of AutoPrognosis 2.0 in an illustrative scenario: prognostic risk prediction of diabetes using a cohort of 502,467 individuals from UK Biobank. However, we emphasize that AutoPrognosis can be applied to construct diagnostic and prognostic models for <italic toggle="yes">any</italic> disease or clinical outcome, and is explicitly designed to make model building accessible to both experts and non-ML experts. We have open-sourced AutoPrognosis 2.0 as a tool for the community, allowing model developers of all levels of expertise to robustly and reproducibly develop optimized personalized diagnostics, prognostics, and risk scores using modern machine learning techniques.</p>
  </sec>
  <sec id="sec002">
    <title>Methods: AutoPrognosis 2.0</title>
    <p>AutoPrognosis 2.0 is an algorithmic framework and software package that allows healthcare professionals to leverage ML to develop diagnostic and prognostic models. Our framework employs automated machine learning [<xref rid="pdig.0000276.ref011" ref-type="bibr">11</xref>] to tackle the challenges faced by clinical users. By automating the optimization of ML pipelines involving data processing, model development, and model training, we reduce the burden on technical experts and turn deriving ML models from an art to a science, democratizing machine learning and opening the field to non-ML domain experts, such as clinicians. We believe that AutoPrognosis 2.0 represents a step-change in algorithmic and software capabilities and can unlock the potential of ML in healthcare for clinical researchers <italic toggle="yes">without</italic> the requirement for extensive technical capabilities.</p>
    <p>AutoPrognosis 2.0 empowers users with the following capabilities:</p>
    <list list-type="order">
      <list-item>
        <p>Build highly performant ML pipelines for classification, regression, and time-to-event analysis, optimized specifically for the data at hand.</p>
      </list-item>
      <list-item>
        <p>Understand when ML provides benefits over traditional regression models, and thus when ML is valuable.</p>
      </list-item>
      <list-item>
        <p>Enable principled selection of variables and allow users to understand the value of information.</p>
      </list-item>
      <list-item>
        <p>Explain and debug how ML models issue predictions using diverse interpretability methods.</p>
      </list-item>
      <list-item>
        <p>Update systems whenever the available data changes to ensure the best possible clinical models.</p>
      </list-item>
      <list-item>
        <p>Provide confidence in the reproducibility of models.</p>
      </list-item>
    </list>
    <sec id="sec003">
      <title>Overview</title>
      <p>After a clinician has determined an appropriate cohort of patients and an outcome of interest, the AutoPrognosis framework handles all steps in the computational pipeline: missing data imputation, feature processing, model selection and fitting, model interpretability or explanations, and production of clinical demonstrators. Together, we believe AutoPrognosis significantly reduces the technical expertise necessary to derive powerful prognostic models, empowering clinical users and democratizing machine learning in healthcare.</p>
      <p>AutoPrognosis is provided as an open-source package at <ext-link xlink:href="https://github.com/vanderschaarlab/AutoPrognosis" ext-link-type="uri">https://github.com/vanderschaarlab/AutoPrognosis</ext-link> and can be readily installed with PyPI (<ext-link xlink:href="https://pypi.org/project/autoprognosis/" ext-link-type="uri">https://pypi.org/project/autoprognosis/</ext-link>). AutoPrognosis is primarily intended as a Python package, but we also provide bindings for R users. AutoPrognosis 2.0 requires only basic familiarity with either language for successful deployment. Note that, as for any computational approach, care must be taken when preparing data for use with AutoPrognosis. However, while the package cannot prevent input of inappropriate data (as no package can), it does ensure the selection of appropriate and optimal methods and hyperparameters for each step in the pipeline outlined in <xref rid="pdig.0000276.t001" ref-type="table">Table 1</xref>. An overview of AutoPrognosis 2.0 is provided in <xref rid="pdig.0000276.g001" ref-type="fig">Fig 1</xref>. Below, we provide a summary of each of the core components of AutoPrognosis.</p>
      <fig position="float" id="pdig.0000276.g001">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>Overview of the AutoPrognosis 2.0 framework.</title>
          <p>AutoPrognosis takes as input a medical dataset and provides an imputed dataset, a report detailing the optimized machine learning pipelines, a diagnostic or prognostic model, explanations, and a web-based interface for clinicians to interact with and use the derived model.</p>
        </caption>
        <graphic xlink:href="pdig.0000276.g001" position="float"/>
      </fig>
      <table-wrap position="float" id="pdig.0000276.t001">
        <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>List of algorithms currently included in AutoPrognosis 2.0.</title>
          <p>Algorithms grouped by pipeline stage. Numbers in brackets correspond to the number of hyperparameters optimized over by AutoPrognosis. AutoPrognosis is readily extendable to additional methods, algorithms, and hyperparameters.</p>
        </caption>
        <alternatives>
          <graphic xlink:href="pdig.0000276.t001" id="pdig.0000276.t001g" position="float"/>
          <table frame="box" rules="all" border="0">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" style="border-bottom-width:thick" rowspan="1" colspan="1">Pipeline Stage</th>
                <th align="center" colspan="5" style="border-bottom-width:thick" rowspan="1">Algorithm (No. Hyperparameters Optimized by AutoPrognosis)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Imputation</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">HyperImpute<break/>(M)ICE (0)</td>
                <td align="left" rowspan="1" colspan="1">Mean (0)<break/>SoftImpute (2)</td>
                <td align="left" rowspan="1" colspan="1">Median (0)<break/>EM (1)</td>
                <td align="left" rowspan="1" colspan="1">Most-Frequent (0)<break/>Sinkhorn (6)</td>
                <td align="left" rowspan="1" colspan="1">MissForest (2)<break/>None (0)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Dimensionality Reduction</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Fast ICA (1)</td>
                <td align="left" rowspan="1" colspan="1">Feat. Agg. (1)</td>
                <td align="left" rowspan="1" colspan="1">Gauss. Rand. Proj. (1)</td>
                <td align="left" rowspan="1" colspan="1">PCA (1)</td>
                <td align="left" rowspan="1" colspan="1">Var. Thresh. (0)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Feature Scaling</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">L2 Norm. (0)<break/>Unif. Trans. (0)</td>
                <td align="left" rowspan="1" colspan="1">Max (0)<break/>None (0)</td>
                <td align="left" rowspan="1" colspan="1">MinMax (0)</td>
                <td align="left" rowspan="1" colspan="1">Normal Trans. (0)</td>
                <td align="left" rowspan="1" colspan="1">Quant. Trans. (0)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Classification</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">ADABoost (3)<break/>ExtraTree (1)<break/>LDA (0)<break/>Neural Net. (6)<break/>TabNet (8)</td>
                <td align="left" rowspan="1" colspan="1">Bagging (4)<break/>Gauss. NB (0)<break/>Light GBM (6)<break/>Perceptron (2)<break/>XGBoost (11)</td>
                <td align="left" rowspan="1" colspan="1">Bernoulli NB (1)<break/>Grad. Boost. (3)<break/>Linear SVM (1)<break/>QDA (0)</td>
                <td align="left" rowspan="1" colspan="1">CatBoost (2)<break/>Hist. Grad. Boost. (2)<break/>Log. Reg. (4)<break/>Random Forest (5)</td>
                <td align="left" rowspan="1" colspan="1">Decision Tree (1)<break/>KNN (4)<break/>Multi. NB (1)<break/>Ridge Class. (1)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Regression</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Bayesian RR (1)<break/>TabNet (8)</td>
                <td align="left" rowspan="1" colspan="1">CatBoost (2)<break/>XGBoost (2)</td>
                <td align="left" rowspan="1" colspan="1">Linear (0)</td>
                <td align="left" rowspan="1" colspan="1">MLP (0)</td>
                <td align="left" rowspan="1" colspan="1">Neural Net. (6)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Survival Analysis</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">Cox PH (2)<break/>Surv. XGB (4)</td>
                <td align="left" rowspan="1" colspan="1">CoxNet (6)<break/>Weibull AFT (2)</td>
                <td align="left" rowspan="1" colspan="1">DeepHit (7)</td>
                <td align="left" rowspan="1" colspan="1">LogLogistic AFT (1)</td>
                <td align="left" rowspan="1" colspan="1">LogNorm. AFT (2)</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>Interpretability</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">INVASE<break/>SimplEx</td>
                <td align="left" rowspan="1" colspan="1">KernelSHAP<break/>Symb. Pursuit</td>
                <td align="left" rowspan="1" colspan="1">LIME</td>
                <td align="left" rowspan="1" colspan="1">Effect Size</td>
                <td align="left" rowspan="1" colspan="1">Shap Permutation</td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
    </sec>
    <sec id="sec004">
      <title>Missing data imputation</title>
      <p>Medical datasets are often incomplete; however, most models require complete data as input, thus imputation is a necessary first step. There are many different imputation methods available, ranging from traditional statistical approaches such as mean imputation to well-known alternatives such as MICE [<xref rid="pdig.0000276.ref022" ref-type="bibr">22</xref>] and MissForest [<xref rid="pdig.0000276.ref023" ref-type="bibr">23</xref>]. We include eight common imputation algorithms in AutoPrognosis for users to select if they desire a specific imputation method.</p>
      <p>In addition, we also include a state-of-the-art AutoML approach for imputation, HyperImpute [<xref rid="pdig.0000276.ref024" ref-type="bibr">24</xref>]. HyperImpute is a generalized iterative imputation algorithm that automatically configures feature-wise imputation models. HyperImpute inherits the usual properties of classical iterative imputation algorithms [<xref rid="pdig.0000276.ref022" ref-type="bibr">22</xref>, <xref rid="pdig.0000276.ref025" ref-type="bibr">25</xref>, <xref rid="pdig.0000276.ref026" ref-type="bibr">26</xref>] while benefiting from an automated model selection and hyperparameter optimization procedure that allows the most appropriate model to be chosen for each feature. HyperImpute optimizes over five classes of model, with a total of 29 configurable hyperparameters. For additional details, we refer to the recent technical report detailing HyperImpute [<xref rid="pdig.0000276.ref024" ref-type="bibr">24</xref>]. HyperImpute is the recommended imputation strategy in AutoPrognosis unless a specific method is preferred by the user. Alternatively, the imputation step can be jointly optimized as part of a larger pipeline.</p>
    </sec>
    <sec id="sec005">
      <title>Developing optimized ML pipelines</title>
      <p>After imputation, we construct ML pipelines consisting of feature processing, model selection, and model fitting. Given an objective function, these steps are jointly optimized using AutoML. There are several possible choices for the pipeline search algorithm, such as Bayesian optimization [<xref rid="pdig.0000276.ref007" ref-type="bibr">7</xref>, <xref rid="pdig.0000276.ref027" ref-type="bibr">27</xref>] or bandit-based approaches [<xref rid="pdig.0000276.ref028" ref-type="bibr">28</xref>]. A key difference in this work is the extension of such approaches beyond hyperparameter optimization, the typical use of AutoML, to accommodate more general configuration spaces that encompass ML pipelines. AutoPrognosis is flexible to the choice of AutoML search algorithm and can be extended as new approaches are developed. Currently, our default approach is based on Bayesian optimization but we have also included an extension of Hyperband [<xref rid="pdig.0000276.ref028" ref-type="bibr">28</xref>]. In <xref rid="pdig.0000276.t001" ref-type="table">Table 1</xref>, we provide a list of the algorithms currently implemented in AutoPrognosis 2.0, together with the number of hyperparameters optimized over for each method. We emphasize the extendability of our approach to new methods, algorithms, and hyperparameters.</p>
      <sec id="sec006">
        <title>Feature processing</title>
        <p>While imputation ensures data is complete, preprocessing datasets is a common requirement for many ML estimators. In particular, feature scaling to normalize the range or the shape of features can significantly affect performance [<xref rid="pdig.0000276.ref029" ref-type="bibr">29</xref>]. AutoPrognosis can optimize over five dimensionality reduction and six feature scaling algorithms.</p>
      </sec>
      <sec id="sec007">
        <title>Model selection and fitting</title>
        <p>Next, a model and hyperparameters must be selected. This is a key step as suboptimal choice of model or hyperparameters can significantly affect the performance of the resulting ML system. AutoPrognosis contains 22 classification algorithms, seven regression algorithms, and seven methods for survival analysis. Together with a range of hyperparameters, this defines a broad algorithmic search space. While navigating this space manually by hand is extremely challenging, AutoPrognosis learns relationships between different settings to efficiently arrive at an optimized solution. Finally, AutoPrognosis combines the best-performing models into a single ensemble. AutoPrognosis can construct ensembles that are weighted combinations of the best-performing models or stacking ensembles, where a meta-model is placed on top of the underlying models. For the illustrative application included in this paper, we used weighted ensembles.</p>
      </sec>
    </sec>
    <sec id="sec008">
      <title>Model explanations</title>
      <p>Predictive models alone are not sufficient and a deeper understanding is required to engender model trust from both clinical users [<xref rid="pdig.0000276.ref005" ref-type="bibr">5</xref>] and regulatory bodies [<xref rid="pdig.0000276.ref030" ref-type="bibr">30</xref>–<xref rid="pdig.0000276.ref032" ref-type="bibr">32</xref>]. Consequently, AutoPrognosis contains a suite of methods for explaining ML models. We have included feature-based interpretability methods, such as SHAP [<xref rid="pdig.0000276.ref033" ref-type="bibr">33</xref>], that allow us to understand the importance of individual features, as well as an example-based interpretability method, SimplEx [<xref rid="pdig.0000276.ref034" ref-type="bibr">34</xref>], that explains the model output for a particular sample with examples of similar instances, similar to case-based reasoning. Furthermore, sometimes outputs of a specific form are required, such as explicit risk equations [<xref rid="pdig.0000276.ref032" ref-type="bibr">32</xref>]. We have therefore included the ability to convert optimized models into transparent risk equations using symbolic regression [<xref rid="pdig.0000276.ref035" ref-type="bibr">35</xref>].</p>
    </sec>
    <sec id="sec009">
      <title>Demonstrators</title>
      <p>In order for risk scores to be useful, they need to be readily available to clinical practitioners. To facilitate this, AutoPrognosis allows interactive demonstrators to be produced for clinical use. We build our clinical demonstrators on top of the open-source Streamlit package [<xref rid="pdig.0000276.ref036" ref-type="bibr">36</xref>]. Compared to traditional solutions, these require almost no technical capabilities to set up, and the standardized nature simplifies adoption for end-users.</p>
    </sec>
  </sec>
  <sec id="sec010">
    <title>Challenges in diagnostic and prognostic modeling</title>
    <p>There are numerous obstacles to developing and deploying diagnostic and prognostic models that currently prevent healthcare professionals from capitalizing on recent algorithmic advances [<xref rid="pdig.0000276.ref001" ref-type="bibr">1</xref>]. Our work seeks to empower clinicians, medical researchers, epidemiologists, and biostatisticians through an accessible, automated framework capable of identifying optimal solutions to all major obstacles limiting ML model building with minimal need for technical expertise. We begin by describing seven major challenges faced by these communities and how they are addressed by AutoPrognosis 2.0 (<xref rid="pdig.0000276.t002" ref-type="table">Table 2</xref>).</p>
    <table-wrap position="float" id="pdig.0000276.t002">
      <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.t002</object-id>
      <label>Table 2</label>
      <caption>
        <title>Major challenges facing clinical development of diagnostic and prognostic models and how these are addressed by AutoPrognosis.</title>
        <p>See Challenges in diagnostic and prognostic modeling for more detail.</p>
      </caption>
      <alternatives>
        <graphic xlink:href="pdig.0000276.t002" id="pdig.0000276.t002g" position="float"/>
        <table frame="box" rules="all" border="0">
          <colgroup span="1">
            <col align="left" valign="middle" span="1"/>
          </colgroup>
          <tbody>
            <tr>
              <td align="left" style="background-color:#BF0000" rowspan="1" colspan="1">Challenge 1. Developing powerful ML pipelines</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis uses AutoML to automate pipeline configuration, performing missing value imputation, feature processing, model selection, and hyperparameter optimization.</td>
            </tr>
            <tr>
              <td align="left" style="background-color:#BF6000" rowspan="1" colspan="1">Challenge 2. Understanding the value of ML and when it is necessary</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis compares a range of ML methods to traditional approaches and automatically identifies what approach is best.</td>
            </tr>
            <tr>
              <td align="left" style="background-color:#BF8600" rowspan="1" colspan="1">Challenge 3. Determining the value of information</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis can quantify the value of including additional predictors, enabling systematic identification of optimal variables.</td>
            </tr>
            <tr>
              <td align="left" style="background-color:#173921" rowspan="1" colspan="1">Challenge 4. Understanding and debugging ML models</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis incorporates seven state-of-the-art interpretability methods, allowing models to be understood and debugged as they are generated.</td>
            </tr>
            <tr>
              <td align="left" style="background-color:#0000BF" rowspan="1" colspan="1">Challenge 5. Making ML models accessible and usable</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis provides a platform to share model outputs by automating the creation of web-based applications.</td>
            </tr>
            <tr>
              <td align="left" style="background-color:#370062" rowspan="1" colspan="1">Challenge 6. Deciding when and if to update clinical models</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis can quantify the benefit of additional data or new predictive variables, and automatically determine the optimal system for the new dataset.</td>
            </tr>
            <tr>
              <td align="left" style="background-color:#600060" rowspan="1" colspan="1">Challenge 7. Transparent reproducibility</td>
            </tr>
            <tr>
              <td align="left" rowspan="1" colspan="1">AutoPrognosis provides a standardized, publicly available framework, facilitating reproducibility.</td>
            </tr>
          </tbody>
        </table>
      </alternatives>
    </table-wrap>
    <sec id="sec011">
      <title>Challenge 1. Developing powerful ML pipelines</title>
      <p>Developing performant ML models remains complex and typically involves significant time and effort for both clinicians [<xref rid="pdig.0000276.ref037" ref-type="bibr">37</xref>] and expert ML practitioners [<xref rid="pdig.0000276.ref038" ref-type="bibr">38</xref>] alike. Indeed, some estimates suggest over 95% of work is expended on software technicals, leaving less than 5% for addressing the medical or scientific problem at hand [<xref rid="pdig.0000276.ref039" ref-type="bibr">39</xref>]. This is further complicated by the myriad of choices that must be made when developing a new predictive model for diagnosis or prognosis, such as: what imputation strategy should be used; how should the data be preprocessed; what (ML) model is best suited for the specific task; what configuration of hyperparameters should be used. These decisions affect each other, thus cannot be made in isolation [<xref rid="pdig.0000276.ref038" ref-type="bibr">38</xref>]; further, the optimal choices not only vary between applications, but also can change over time as more data is collected and clinical practice changes [<xref rid="pdig.0000276.ref040" ref-type="bibr">40</xref>].</p>
      <p>Few resources are available to help empirically define optimal computational pipelines. AutoPrognosis 2.0 addresses this by incorporating an AutoML approach within a standardized framework, automating the process of pipeline configuration. AutoPrognosis navigates a broad algorithmic search space in an efficient fashion, systematically performing missing value imputation, feature processing, model selection, and hyperparameter optimization in an unbiased manner without the need for human intervention or expert insight. This avoids arbitrary parameter selection and ensures standardization of pipelines, facilitating both reproducibility and optimized model performance. Critically, this democratizes the model building step, eliminating the requirement for expert ML knowledge and making cutting-edge methodology accessible to all, freeing healthcare domain experts to define and address the core clinical problems.</p>
    </sec>
    <sec id="sec012">
      <title>Challenge 2. Understanding the value of ML and when it is necessary</title>
      <p>Traditional approaches, such as linear regression and Cox proportional hazard models [<xref rid="pdig.0000276.ref041" ref-type="bibr">41</xref>], are widely used and accepted across healthcare. Before replacing these established methods, it is vital to understand whether ML is valuable for a given problem and quantify the benefit of ML systems. Indeed, there is no “free lunch” and we should not expect ML to always outperform existing approaches [<xref rid="pdig.0000276.ref042" ref-type="bibr">42</xref>]. Further, simple solutions can be desirable [<xref rid="pdig.0000276.ref043" ref-type="bibr">43</xref>]. Several recent examples exist that present settings where comparatively “simple” approaches outperformed ML [<xref rid="pdig.0000276.ref044" ref-type="bibr">44</xref>, <xref rid="pdig.0000276.ref045" ref-type="bibr">45</xref>].</p>
      <p>AutoPrognosis 2.0 can be used to compare a range of ML methods to traditional approaches at minimal technical cost to the user. Furthermore, since these solutions are included in the algorithmic search space, AutoPrognosis will automatically identify whether such approaches are indeed best or if more complex ML models are required.</p>
    </sec>
    <sec id="sec013">
      <title>Challenge 3. Determining the value of information</title>
      <p>Selecting which variables to include in a predictive model is a critical aspect of model development that not only impacts model performance but also the ease of subsequent clinical use [<xref rid="pdig.0000276.ref046" ref-type="bibr">46</xref>]. This is due to models with fewer features being easier to interpret and use in practice [<xref rid="pdig.0000276.ref047" ref-type="bibr">47</xref>] but also since any feature used will need to be collected in an ongoing manner to use such systems. Thus, understanding the <italic toggle="yes">value</italic> of an individual variable and the information it provides is critical. Often, this is assessed by univariate statistical analysis or other selection methods such as forward selection or backward elimination [<xref rid="pdig.0000276.ref048" ref-type="bibr">48</xref>]. AutoPrognosis 2.0 provides methods to test and quantify the value of including additional predictors, allowing systematic identification of optimal variables in an informed manner.</p>
    </sec>
    <sec id="sec014">
      <title>Challenge 4. Understanding and debugging ML models</title>
      <p>A predictive clinical model must be more than just accurate, it must be interpretable. Without a transparent understanding of <italic toggle="yes">how</italic> a model makes predictions it may act in unintended and undesirable ways, for example learning incorrect or aberrant features unique to the training data [<xref rid="pdig.0000276.ref049" ref-type="bibr">49</xref>, <xref rid="pdig.0000276.ref050" ref-type="bibr">50</xref>]. In particular, model debugging can be used to check for shortcut learning [<xref rid="pdig.0000276.ref051" ref-type="bibr">51</xref>], where the model learns spurious relationships in the provided data, or data leakage [<xref rid="pdig.0000276.ref052" ref-type="bibr">52</xref>], which can lead to overly optimistic performance estimates. As seen in several machine learning applications in healthcare [<xref rid="pdig.0000276.ref050" ref-type="bibr">50</xref>, <xref rid="pdig.0000276.ref053" ref-type="bibr">53</xref>, <xref rid="pdig.0000276.ref054" ref-type="bibr">54</xref>], shortcut learning can be a serious issue that must be avoided. Additionally, fairness and bias are two important considerations when developing any predictive model, particularly in healthcare [<xref rid="pdig.0000276.ref055" ref-type="bibr">55</xref>], and existing societal biases in the data should not be reinforced by models [<xref rid="pdig.0000276.ref043" ref-type="bibr">43</xref>]. While related to Challenge 1 (since a perfectly predictive model is both fair and unbiased), assessing fairness and bias, as well as understanding their origin, are key steps in model development and debugging. While interpretability does not guarantee that a model will be fair and unbiased, it creates the opportunity to assess these characteristics by probing how the model issues predictions.</p>
      <p>The debugging step is critical for building model trust [<xref rid="pdig.0000276.ref005" ref-type="bibr">5</xref>] and cannot be achieved without interpretation of the training features or cases that support model accuracy. It is clear that clinical deployment of an interpretable model is supported by the additional trust gained by understanding the model’s performance [<xref rid="pdig.0000276.ref056" ref-type="bibr">56</xref>].</p>
      <p>Furthermore, a clear understanding of computational models is now a requirement for deployment in healthcare systems globally: in the United States, the FDA demands “transparency about the function and modifications of medical devices” as a key safety aspect [<xref rid="pdig.0000276.ref030" ref-type="bibr">30</xref>]; Article 22 of GDPR legislation in the EU requires that “meaningful information about the logic involved” be provided in certain circumstances [<xref rid="pdig.0000276.ref031" ref-type="bibr">31</xref>]; and Article 13 (1) of the European Commision Proposal for the AI Act states “High-risk AI systems shall be …sufficiently transparent to enable users to interpret the system’s output”, among others. To achieve this transparency, interpretable outputs of a specific form can also be required. For example, the American Joint Committee on Cancer requires explicit risk equations [<xref rid="pdig.0000276.ref032" ref-type="bibr">32</xref>].</p>
      <p>The ‘black-box’ nature of many ML methods means that they remain inherently uninterpretable and require specialized methods to unravel the underlying rationale for predictions. In AutoPrognosis 2.0, we have incorporated seven state-of-the-art interpretability methods allowing researchers to understand and debug ML models as they are generated.</p>
    </sec>
    <sec id="sec015">
      <title>Challenge 5. Making ML models accessible and usable</title>
      <p>Predictive models need to be accessible to be used in clinical practice. This step often limits adoption, since bespoke deployment can result in significant costs and reliance on technical expertise. While full clinical deployment may require additional systems (e.g. due to regulatory requirements), a standardized, user-friendly solution to rapidly visualize and share models is also a necessary part of both debugging and confirming clinical acceptance. AutoPrognosis 2.0 provides a platform to share model outputs by automating the creation of web-based applications, allowing clinicians to explore predictions in diverse scenarios.</p>
    </sec>
    <sec id="sec016">
      <title>Challenge 6. Deciding when and if to update clinical models</title>
      <p>Over time, more data is collected, new variables are measured, and even clinical practice changes [<xref rid="pdig.0000276.ref057" ref-type="bibr">57</xref>, <xref rid="pdig.0000276.ref058" ref-type="bibr">58</xref>]. For the former, existing clinical predictive models might benefit from additional data or features, while in the latter case, model performance may degrade [<xref rid="pdig.0000276.ref040" ref-type="bibr">40</xref>]. However, deciding whether to update a clinical model is not a decision to be made lightly, since beyond model building, further regulatory approval might be necessary and the updated model will need to be redeployed. AutoPrognosis can help answer this difficult question by quantifying the benefit of additional data and new predictive variables, while also automatically determining the optimal system configurations for the new dataset, which may have changed.</p>
    </sec>
    <sec id="sec017">
      <title>Challenge 7. Transparent reproducibility</title>
      <p>Reproducibility is a fundamental requirement for the acceptance and adoption of any predictive model. While transparently reproducing a model’s output on a given dataset is conceptually simple, several factors can confound this necessary step. Serial data releases, code updates, and even inherent properties of ML algorithms (for example, stochastic descent methods can give different answers even when run repeatedly on the same data) can conspire to make ML model building less reproducible than it should be [<xref rid="pdig.0000276.ref059" ref-type="bibr">59</xref>]. These issues demonstrably obstruct translation of clinical prediction and erode trust in ML approaches [<xref rid="pdig.0000276.ref060" ref-type="bibr">60</xref>–<xref rid="pdig.0000276.ref062" ref-type="bibr">62</xref>]. AutoPrognosis 2.0 addresses this major challenge by providing a standardized, publicly available framework to train predictive models, allowing straightforward demonstration of reproducibility on source data.</p>
    </sec>
  </sec>
  <sec id="sec018">
    <title>Illustrative application: Diabetes risk prediction</title>
    <p>In this section, we show how AutoPrognosis 2.0 can be applied to address the challenges described in Challenges in diagnostic and prognostic modeling. We demonstrate the application of AutoPrognosis 2.0 using an illustrative scenario: prognostic risk prediction of developing diabetes using a cohort of 502,467 individuals from UK Biobank. Our goal is <italic toggle="yes">not</italic> to develop the best model for diabetes risk prediction possible, but instead to exemplify how our tool can be used.</p>
    <p>In our use scenario, we show that the model derived with AutoPrognosis outperforms risk models currently used in clinical practice and quantify the benefit of ML methods over Cox proportional hazard models. In addition, we show how the model interpretability components of AutoPrognosis can be used to understand the drivers of predictions and identify novel risk factors not incorporated into previous risk scores. Finally, we use AutoPrognosis to share the diabetes risk score as a web-based decision support tool that can be publicly accessed by patients and clinicians (<ext-link xlink:href="https://autoprognosis-biobank-diabetes.streamlitapp.com/" ext-link-type="uri">https://autoprognosis-biobank-diabetes.streamlitapp.com/</ext-link>).</p>
    <p>While we illustrate risk prediction of developing diabetes using a cohort from UK Biobank, AutoPrognosis can be applied to construct diagnostic and prognostic models for any disease or clinical outcome. Furthermore, AutoPrognosis is applicable to classification and regression tasks, in addition to survival analysis.</p>
    <sec id="sec019">
      <title>Designing experiments</title>
      <sec id="sec020">
        <title>Selecting which dataset to use</title>
        <p>AutoPrognosis can be used with data from many different origins, such as biobanks [<xref rid="pdig.0000276.ref012" ref-type="bibr">12</xref>], registries [<xref rid="pdig.0000276.ref013" ref-type="bibr">13</xref>, <xref rid="pdig.0000276.ref014" ref-type="bibr">14</xref>], and private hospital data [<xref rid="pdig.0000276.ref017" ref-type="bibr">17</xref>]. Here, we use the UK Biobank due to its availability and popularity as a resource for healthcare researchers. UK Biobank enrolled half a million participants from 22 assessment centers across England, Wales, and Scotland between 2006 and 2010 [<xref rid="pdig.0000276.ref063" ref-type="bibr">63</xref>], with follow-up data collected from hospital records [<xref rid="pdig.0000276.ref064" ref-type="bibr">64</xref>]. From UK Biobank, we extracted a cohort of participants who were 40 years of age or older with no diagnosis or history of diabetes at baseline; the primary outcome was diagnosis of diabetes within a 10-year horizon. We selected diabetes as our outcome of interest due to its global prevalence and role as a risk factor for a multitude of other indications [<xref rid="pdig.0000276.ref065" ref-type="bibr">65</xref>].</p>
      </sec>
      <sec id="sec021">
        <title>Selecting variables</title>
        <p>Variables can be selected for inclusion in a study in a myriad of ways. Often, healthcare professionals will select a subset of exploratory features that are of particular interest to them. This could be due to supporting medical literature, to explore a hypothesis, or based on features included in existing risk scores. Alternatively, we can always choose to initially include all available variables. Here, we selected an initial set of 109 exploratory features based on their general clinical availability, discussions with clinicians, and features used by existing risk scores. Descriptive characteristics of the UK Biobank cohort are provided in <xref rid="pdig.0000276.s004" ref-type="supplementary-material">S4 Table</xref>. Most variables had low levels of missingness (&lt; 1%); however, some important variables had higher missingness rates (e.g. HbA1c: 6.8%). We purposefully selected almost an order of magnitude increase compared to existing risk scores to illustrate how AutoPrognosis can be used in such a scenario.</p>
      </sec>
      <sec id="sec022">
        <title>Selecting benchmarks</title>
        <p>Often, existing risk scores will exist for the outcome of interest; this is certainly true for diabetes, where several risk scores that estimate the probability of developing diabetes are currently used in clinical practice. Therefore, we use the following as baseline risk scores:</p>
        <list list-type="bullet">
          <list-item>
            <p><bold>ADA</bold>: The American Diabetes Association (ADA) risk score [<xref rid="pdig.0000276.ref066" ref-type="bibr">66</xref>] is a points-based score employing six features, namely age, sex, family history of diabetes, history of hypertension, obesity, and physical activity.</p>
          </list-item>
          <list-item>
            <p><bold>FINRISK</bold>: A risk score for diabetes was derived from FINRISK, a large population survey in Finland, based on age, body mass index (BMI), waist circumference, history of antihypertensive drug treatment and high blood glucose, physical activity, and daily consumption of fruits, berries, or vegetables [<xref rid="pdig.0000276.ref067" ref-type="bibr">67</xref>].</p>
          </list-item>
          <list-item>
            <p><bold>DiabetesUK</bold>: The risk score from Diabetes UK uses seven features: gender, age, ethnicity, family history, waist size, BMI, and high blood pressure requiring treatment.</p>
          </list-item>
          <list-item>
            <p><bold>QDiabetes</bold>: Finally, QDiabetes [<xref rid="pdig.0000276.ref068" ref-type="bibr">68</xref>] consists of three separate models depending on the clinical information available and stage of risk screening. Model A uses 16 non-laboratory features that do not require a blood test and is intended primarily as an initial screening tool. Models B and C include the same variables as Model A together with fasting blood glucose and hemoglobin A1c (HbA1c), respectively, with the aim of refining risk assessment following a blood test.</p>
          </list-item>
        </list>
        <p>In addition to the baseline risk scores, a comparison with traditional modeling approaches can be made using AutoPrognosis. We demonstrate this by fitting Cox proportional hazard (Cox PH) [<xref rid="pdig.0000276.ref041" ref-type="bibr">41</xref>] models using the same features as each of the baseline risk scores. These models can be thought of as variants of the respective risk scores calibrated to the specific dataset.</p>
      </sec>
    </sec>
    <sec id="sec023">
      <title>Results</title>
      <p>Through the lens of our example (diabetes risk prediction), we demonstrate how AutoPrognosis 2.0 can be used to address the challenges of diagnostic and prognostic modeling introduced in Challenges in diagnostic and prognostic modeling.</p>
      <sec id="sec024">
        <title>Challenge 1. Developing powerful ML pipelines</title>
        <p>We begin by using AutoPrognosis to derive a clinical risk score for diabetes. We evaluated the performance of the models using concordance index (C-index) to assess model discrimination, Brier score to assess calibration, and the area under the receiver-operating curve (AUROC) to assess prediction accuracy. We performed imputation five times and conducted 3-fold cross-validation for each of the imputed datasets.</p>
        <p>As seen in <xref rid="pdig.0000276.t003" ref-type="table">Table 3</xref>, the risk score developed by AutoPrognosis significantly outperforms all baseline risk scores and Cox PH models (two-sample unpaired t-test between C-indices: p-value &lt;0.001), achieving a C-index on the validation cohort of 0.888 (95% confidence interval: 0.881–0.895). This compares to 0.696 (0.681–0.711) for the ADA score, 0.728 (0.699–0.757) for FINRISK, 0.759 (0.746–0.772) for DiabetesUK, and 0.839 (0.818–0.860) for the best performing QDiabetes model (Model C). Cox PH models fit with the same risk factors as the clinical risk scores achieved improved performance (C-indices: 0.774, 0.786, 0.794, and 0.858, respectively), but exhibit lower performance than AutoPrognosis.</p>
        <table-wrap position="float" id="pdig.0000276.t003">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.t003</object-id>
          <label>Table 3</label>
          <caption>
            <title>Diabetes risk prediction results.</title>
            <p>The risk scores automatically derived by AutoPrognosis outperform the existing risk scores and Cox PH models retrained on the same features. Mean performance reported with 95% confidence interval.</p>
          </caption>
          <alternatives>
            <graphic xlink:href="pdig.0000276.t003" id="pdig.0000276.t003g" position="float"/>
            <table frame="box" rules="all" border="0">
              <colgroup span="1">
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th align="center" rowspan="1" colspan="1">Method</th>
                  <th align="center" rowspan="1" colspan="1">C-index ↑</th>
                  <th align="center" rowspan="1" colspan="1">Brier score ↓</th>
                  <th align="center" rowspan="1" colspan="1">AUROC ↑</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="center" rowspan="1" colspan="1">ADA</td>
                  <td align="center" rowspan="1" colspan="1">0.696 ± 0.015</td>
                  <td align="center" rowspan="1" colspan="1">0.011 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.697 ± 0.018</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">FINRISK</td>
                  <td align="center" rowspan="1" colspan="1">0.728 ± 0.029</td>
                  <td align="center" rowspan="1" colspan="1">0.019 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.729 ± 0.020</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">DiabetesUK</td>
                  <td align="center" rowspan="1" colspan="1">0.759 ± 0.013</td>
                  <td align="center" rowspan="1" colspan="1">0.016 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.759 ± 0.019</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">QDiabetes Model A</td>
                  <td align="center" rowspan="1" colspan="1">0.794 ± 0.022</td>
                  <td align="center" rowspan="1" colspan="1">0.008 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.795 ± 0.017</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">QDiabetes Model B</td>
                  <td align="center" rowspan="1" colspan="1">0.788 ± 0.019</td>
                  <td align="center" rowspan="1" colspan="1">0.015 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.788 ± 0.013</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">QDiabetes Model C</td>
                  <td align="center" rowspan="1" colspan="1">0.839 ± 0.021</td>
                  <td align="center" rowspan="1" colspan="1">0.005 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.840 ± 0.010</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Cox PH (ADA)</td>
                  <td align="center" rowspan="1" colspan="1">0.774 ± 0.027</td>
                  <td align="center" rowspan="1" colspan="1">0.002 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.774 ± 0.020</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Cox PH (FINRISK)</td>
                  <td align="center" rowspan="1" colspan="1">0.786 ± 0.023</td>
                  <td align="center" rowspan="1" colspan="1">0.002 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.786 ± 0.026</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Cox PH (DiabetesUK)</td>
                  <td align="center" rowspan="1" colspan="1">0.794 ± 0.023</td>
                  <td align="center" rowspan="1" colspan="1">0.002 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.794 ± 0.022</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Cox PH (QDiabetes C)</td>
                  <td align="center" rowspan="1" colspan="1">0.858 ± 0.007</td>
                  <td align="center" rowspan="1" colspan="1">0.002 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.860 ± 0.018</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">
                    <bold>AutoPrognosis 2.0</bold>
                  </td>
                  <td align="center" rowspan="1" colspan="1">
                    <bold>0.888 ± 0.007</bold>
                  </td>
                  <td align="center" rowspan="1" colspan="1">
                    <bold>0.002 ± 0.000</bold>
                  </td>
                  <td align="center" rowspan="1" colspan="1">
                    <bold>0.888 ± 0.012</bold>
                  </td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">AutoPrognosis (18 feat.)</td>
                  <td align="center" rowspan="1" colspan="1">0.870 ± 0.011</td>
                  <td align="center" rowspan="1" colspan="1">0.002 ± 0.000</td>
                  <td align="center" rowspan="1" colspan="1">0.867 ± 0.020</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
        <p>As an alternate way of understanding the clinical impact of our results, we performed decision curve analysis [<xref rid="pdig.0000276.ref069" ref-type="bibr">69</xref>, <xref rid="pdig.0000276.ref070" ref-type="bibr">70</xref>]. Decision curve analysis assesses the clinical value of a predictor by calculating the clinical net benefit across a range of risk threshold probabilities, where the threshold probability is defined as the minimum probability of an event at which a decision-maker would take a given action. Net benefit is defined as the difference between the proportion of true positives and the proportion of false positives weighted by the odds of the selected threshold. Evaluating net benefit is recommended in the TRIPOD guidelines [<xref rid="pdig.0000276.ref071" ref-type="bibr">71</xref>]. At any given threshold, the model with the higher net benefit is preferred.</p>
        <p>We compared the predicted risk by AutoPrognosis with the QDiabetes models, the best performing of the existing clinical risk scores, as well as baseline strategies to assume all patients will develop diabetes (All) or that no-one will (None). Decision curve analysis further demonstrates the benefit of AutoPrognosis compared to existing risk scores for diabetes (<xref rid="pdig.0000276.g002" ref-type="fig">Fig 2</xref>). At all decision thresholds, AutoPrognosis offers greater net benefit and is the only score to outperform “All” between the thresholds of 0.1 and 0.2, and the only model to perform similarly to “All” below a threshold of 0.1.</p>
        <fig position="float" id="pdig.0000276.g002">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.g002</object-id>
          <label>Fig 2</label>
          <caption>
            <title>Decision curve analysis.</title>
            <p>AutoPrognosis exhibits higher net benefit at all decision thresholds compared to existing risk scores and baseline strategies.</p>
          </caption>
          <graphic xlink:href="pdig.0000276.g002" position="float"/>
        </fig>
      </sec>
      <sec id="sec025">
        <title>Challenge 2. Understanding when ML is necessary and its value</title>
        <p><xref rid="pdig.0000276.t003" ref-type="table">Table 3</xref> demonstrates the benefit of AutoPrognosis compared to existing risk scores and Cox PH models retrained on the same features. We now directly compare AutoPrognosis to Cox PH models on the same training data to understand if ML is needed for this problem. In <xref rid="pdig.0000276.t004" ref-type="table">Table 4</xref>, we show the performance of AutoPrognosis and a Cox PH model using the full feature set considered. We see that while some of the benefit is due to the additional features, there remains value in the improved modeling approach, even for identical feature sets.</p>
        <table-wrap position="float" id="pdig.0000276.t004">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.t004</object-id>
          <label>Table 4</label>
          <caption>
            <title>Quantifying the value of ML.</title>
            <p>The risk score automatically derived by AutoPrognosis significantly outperforms a Cox PH model trained on the same features.</p>
          </caption>
          <alternatives>
            <graphic xlink:href="pdig.0000276.t004" id="pdig.0000276.t004g" position="float"/>
            <table frame="box" rules="all" border="0">
              <colgroup span="1">
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th align="center" rowspan="1" colspan="1">Method</th>
                  <th align="center" rowspan="1" colspan="1">C-index ↑</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="center" colspan="2" rowspan="1">
                    <italic toggle="yes">All Variables</italic>
                  </td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Cox PH</td>
                  <td align="center" rowspan="1" colspan="1">0.883 ± 0.010</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">AutoPrognosis</td>
                  <td align="center" rowspan="1" colspan="1">0.888 ± 0.007</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
      </sec>
      <sec id="sec026">
        <title>Challenge 3. Determining the value of information</title>
        <p>Understanding the predictive power of variables is key and often there is a trade-off (e.g. cost or time) in clinical practice to acquiring additional variables. We evaluate AutoPrognosis using different subsets of features. We selected features using the magnitude of the effect size. We measure the distributional shift for an increase in predicted risk using Cohen’s D [<xref rid="pdig.0000276.ref072" ref-type="bibr">72</xref>] and select features with effect sizes exceeding the thresholds {0.5, 0.6, 0.7, 0.8, 0.9, 1.0}. Even using only eight features (effect size: 1.0), AutoPrognosis slightly outperforms the best performing existing risk score, QDiabetes Model C, which employs 17 features (<xref rid="pdig.0000276.g003" ref-type="fig">Fig 3</xref>). With a comparable number of features (18 features, effect size 0.7), AutoPrognosis displays significantly improved performance (<xref rid="pdig.0000276.t003" ref-type="table">Table 3</xref>). As the number of features increases, performance rapidly increases until 35 features are used (effect size: 0.5). After this point, while there is some gain from additional features, it could be considered marginal given the number of additional features employed. See <xref rid="pdig.0000276.s001" ref-type="supplementary-material">S1 Table</xref> for the most important features using effect size.</p>
        <fig position="float" id="pdig.0000276.g003">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.g003</object-id>
          <label>Fig 3</label>
          <caption>
            <title>Value of information.</title>
            <p>We evaluate AutoPrognosis with different numbers of features, selected using effect size. Feature efficiency is compared to QDiabetes Model C, the best performing existing risk score. Note y-axis does not start at 0 nor end at 1.</p>
          </caption>
          <graphic xlink:href="pdig.0000276.g003" position="float"/>
        </fig>
      </sec>
      <sec id="sec027">
        <title>Challenge 4. Understanding and debugging ML models</title>
        <p>Highly predictive models alone are insufficient and it is necessary to understand which features are important. We demonstrate how the interpretability methods incorporated in AutoPrognosis 2.0 can be used to understand how ML models make predictions and debug their behavior. We begin by examining the SHAP values [<xref rid="pdig.0000276.ref033" ref-type="bibr">33</xref>] to explain the key contributors to model performance. <xref rid="pdig.0000276.g004" ref-type="fig">Fig 4</xref> shows the top 20 features. Encouragingly, these features are largely consistent with clinical knowledge, providing evidence that the model is acting in a desirable manner. Several of the top risk factors, such as HbA1c, waist size, and body mass index, were also included in previous risk scores. However, a number of additional features, including both laboratory and non-laboratory tests, were deemed important. A number of these features have been shown to be risk factors for diabetes (e.g. gamma-glutamyl transferase [<xref rid="pdig.0000276.ref073" ref-type="bibr">73</xref>]), but have not been incorporated into other risk scores. Of the existing risk factors, we find that HbA1c is significantly more important to the predictions of AutoPrognosis than blood glucose, which is consistent with our earlier experiments that showed QDiabetes Model C (which uses HbA1c) outperforms Model B (which uses blood glucose) on the UK Biobank population.</p>
        <fig position="float" id="pdig.0000276.g004">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.g004</object-id>
          <label>Fig 4</label>
          <caption>
            <title>SHAP values for the most important features.</title>
          </caption>
          <graphic xlink:href="pdig.0000276.g004" position="float"/>
        </fig>
        <p>Finally, several features commonly incorporated in previous risk scores are notably missing: for example age and sex. One explanation could be that UK Biobank contains a limited age range (40–69 at enrollment), and thus the role of age could be reduced over that range. However, increasingly, younger individuals are being diagnosed with diabetes [<xref rid="pdig.0000276.ref074" ref-type="bibr">74</xref>], which could also explain the omission of age as a key risk factor. In the case of sex, while it was once assumed that there were sex differences, diabetes is equally prevalent among men and women in most populations [<xref rid="pdig.0000276.ref075" ref-type="bibr">75</xref>].</p>
        <p>To illustrate debugging, we consider the development of diabetes in individuals with differing HbA1c levels. We divide the overall cohort into two approximately equal parts using the median HbA1c value of 4.69%. This equates to splitting the population into a low-normal subgroup and a high-normal and elevated subgroup [<xref rid="pdig.0000276.ref076" ref-type="bibr">76</xref>].</p>
        <p>We evaluated AutoPrognosis and the QDiabetes models on these two cohorts (<xref rid="pdig.0000276.t005" ref-type="table">Table 5</xref>). Despite displaying better performance across the entire dataset, QDiabetes Model C <italic toggle="yes">under</italic> performs Model A for patients in the low-normal HbA1c cohort. Conversely, AutoPrognosis performs best for both subgroups, although predicting future risk of diabetes is more challenging for low-normal HbA1c patients, in line with the other models. This could suggest that QDiabetes Model C is overly reliant on HbA1c while AutoPrognosis has more accurately captured the risk factors for low HbA1c patients.</p>
        <table-wrap position="float" id="pdig.0000276.t005">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.t005</object-id>
          <label>Table 5</label>
          <caption>
            <title>Performance of diabetes risk scores for subgroups defined by HbA1c.</title>
          </caption>
          <alternatives>
            <graphic xlink:href="pdig.0000276.t005" id="pdig.0000276.t005g" position="float"/>
            <table frame="box" rules="all" border="0">
              <colgroup span="1">
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th align="center" rowspan="2" colspan="1">Method</th>
                  <th align="center" colspan="2" rowspan="1">C-index</th>
                  <th align="center" colspan="2" rowspan="1">AUROC</th>
                </tr>
                <tr>
                  <th align="center" rowspan="1" colspan="1">HbA1c &lt; 4.69%</th>
                  <th align="center" rowspan="1" colspan="1">HbA1c ≥ 4.69%</th>
                  <th align="center" rowspan="1" colspan="1">HbA1c &lt; 4.69%</th>
                  <th align="center" rowspan="1" colspan="1">HbA1c ≥ 4.69%</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="center" rowspan="1" colspan="1">QDiabetes Model A</td>
                  <td align="center" rowspan="1" colspan="1">0.771 ± 0.053</td>
                  <td align="center" rowspan="1" colspan="1">0.775 ± 0.016</td>
                  <td align="center" rowspan="1" colspan="1">0.772 ± 0.009</td>
                  <td align="center" rowspan="1" colspan="1">0.775 ± 0.023</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">QDiabetes Model B</td>
                  <td align="center" rowspan="1" colspan="1">0.738 ± 0.031</td>
                  <td align="center" rowspan="1" colspan="1">0.773 ± 0.010</td>
                  <td align="center" rowspan="1" colspan="1">0.738 ± 0.007</td>
                  <td align="center" rowspan="1" colspan="1">0.773 ± 0.017</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">QDiabetes Model C</td>
                  <td align="center" rowspan="1" colspan="1">0.735 ± 0.052</td>
                  <td align="center" rowspan="1" colspan="1">0.855 ± 0.008</td>
                  <td align="center" rowspan="1" colspan="1">0.736 ± 0.022</td>
                  <td align="center" rowspan="1" colspan="1">0.856 ± 0.004</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">AutoPrognosis 2.0</td>
                  <td align="center" rowspan="1" colspan="1">0.818 ± 0.047</td>
                  <td align="center" rowspan="1" colspan="1">0.889 ± 0.011</td>
                  <td align="center" rowspan="1" colspan="1">0.807 ± 0.013</td>
                  <td align="center" rowspan="1" colspan="1">0.896 ± 0.009</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
        <p>This raises the question of <italic toggle="yes">why</italic> AutoPrognosis is able to issue more accurate predictions for the low-normal HbA1c cohort, in particular given HbA1c is ranked as the most important feature globally (<xref rid="pdig.0000276.g004" ref-type="fig">Fig 4</xref>). <xref rid="pdig.0000276.t006" ref-type="table">Table 6</xref> shows the most important features (measured by risk effect size) for the two subgroups defined by HbA1c. While there is significant overlap, there are five unique features in the top 20 for each cohort. This type of analysis can help clinicians understand and debug the predictions of models not only for the entire population, but specific subgroups of interest.</p>
        <table-wrap position="float" id="pdig.0000276.t006">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.t006</object-id>
          <label>Table 6</label>
          <caption>
            <title>The most important features for AutoPrognosis measured by risk effect size for the two cohorts defined by median HbA1c.</title>
            <p>Features with * differ between the two cohorts. Effect size in parenthesis.</p>
          </caption>
          <alternatives>
            <graphic xlink:href="pdig.0000276.t006" id="pdig.0000276.t006g" position="float"/>
            <table frame="box" rules="all" border="0">
              <colgroup span="1">
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th align="center" rowspan="1" colspan="1">HbA1c &lt; 4.69%</th>
                  <th align="center" rowspan="1" colspan="1">HbA1c ≥ 4.69%</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="center" rowspan="1" colspan="1">*Atrial fibrillation (3.0)</td>
                  <td align="center" rowspan="1" colspan="1">*HbA1c (3.0)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Waist Size (2.8)</td>
                  <td align="center" rowspan="1" colspan="1">*Glucose (2.5)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Body Mass Index (2.7)</td>
                  <td align="center" rowspan="1" colspan="1">Weight/Height Ratio (1.5)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Weight/Height Ratio (2.7)</td>
                  <td align="center" rowspan="1" colspan="1">Waist Size (1.5)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Weight (2.7)</td>
                  <td align="center" rowspan="1" colspan="1">Body Mass Index (1.4)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Hip Size (2.2)</td>
                  <td align="center" rowspan="1" colspan="1">Weight (1.3)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Waist/Hip Ratio (1.8)</td>
                  <td align="center" rowspan="1" colspan="1">Waist/Hip Ratio (1.1)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Cystatin-c (1.6)</td>
                  <td align="center" rowspan="1" colspan="1">Hip Size (1.1)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">*Kidney Disease (1.5)</td>
                  <td align="center" rowspan="1" colspan="1">Alanine Transaminase (0.87)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">*Uric Acid (1.3)</td>
                  <td align="center" rowspan="1" colspan="1">Triglycerides (0.76)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Alanine Transaminase (1.1)</td>
                  <td align="center" rowspan="1" colspan="1">Gamma-Glutamyl Transferase (0.74)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">*Anti-hypertensive Medication (1.1)</td>
                  <td align="center" rowspan="1" colspan="1">*HDL (0.71)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">*History of Hypertension (0.99)</td>
                  <td align="center" rowspan="1" colspan="1">*C-Reactive Protein (0.70)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Triglycerides (0.97)</td>
                  <td align="center" rowspan="1" colspan="1">Cystatin-c (0.68)</td>
                </tr>
                <tr>
                  <td align="center" rowspan="1" colspan="1">Gamma-Glutamyl Transferase (0.96)</td>
                  <td align="center" rowspan="1" colspan="1">*Sex Hormone-Binding Globulin (0.67)</td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
      </sec>
      <sec id="sec028">
        <title>Challenge 5. Making ML models accessible and usable</title>
        <p>Finally, we end our illustrative scenario with an example web-based demonstrator enabling the use of the risk model derived by AutoPrognosis. The web application can be accessed at <ext-link xlink:href="https://autoprognosis-biobank-diabetes.streamlitapp.com/" ext-link-type="uri">https://autoprognosis-biobank-diabetes.streamlitapp.com/</ext-link>. A screenshot is provided in <xref rid="pdig.0000276.g005" ref-type="fig">Fig 5</xref>.</p>
        <fig position="float" id="pdig.0000276.g005">
          <object-id pub-id-type="doi">10.1371/journal.pdig.0000276.g005</object-id>
          <label>Fig 5</label>
          <caption>
            <title>Screenshot of an example clinical demonstrator produced by AutoPrognosis.</title>
          </caption>
          <graphic xlink:href="pdig.0000276.g005" position="float"/>
        </fig>
      </sec>
    </sec>
  </sec>
  <sec id="sec029">
    <title>Discussion: Using AutoPrognosis in Healthcare and Beyond</title>
    <p>Advances in ML algorithms harbor the potential to transform healthcare; however, major challenges continue to limit their adoption in medicine. In this work, we define these challenges and describe the first integrated, automated framework for diagnostic and prognostic modeling, AutoPrognosis 2.0, that is designed to overcome each obstacle in a way that is accessible to non-expert users, democratizing model construction, understanding, debugging, and sharing.</p>
    <p>While AutoPrognosis seeks to address many of the algorithmic challenges of applying machine learning to clinical settings, there remains significant responsibility with the healthcare expert using AutoPrognosis to ensure appropriate study design and data curation. In particular, inappropriate use can result in inaccurate or biased results. For example, if the data used is not representative of the patient population of interest, then the model may not be applicable or accurate in real-world settings. Additionally, if the model is not adequately validated, its use could lead to a greater number of incorrect diagnoses, prognoses, or treatment recommendations than expected, which would be adverse for patient health.</p>
    <p>In this study, we explored how AutoPrognosis could be used to construct a prognostic risk score for diabetes. The developed risk score outperformed existing approaches when evaluated on the UK Biobank cohort. However, prior to deployment in a different population, external validation should be conducted to ensure the accuracy of the risk score is not impacted by differences in patient characteristics or care.</p>
    <p>While we have provided an illustrative example of how AutoPrognosis can be used, the key finding reported here is <italic toggle="yes">not</italic> the performance of a single illustrative model, but rather the way in which it was built. We believe AutoPrognosis 2.0 is a necessary development in the journey towards widespread adoption of ML systems in clinical practice and hope that researchers will engage with this tool. Rather than marginalizing healthcare experts, we believe AutoPrognosis places them at the center and empowers them to create new clinical tools. As part of this journey, we will continue to add new features and improve AutoPrognosis.</p>
    <p>The adoption of AutoPrognosis and similar tools in healthcare has the potential to transform clinical decision-making and foster collaboration between ML experts and healthcare professionals. However, implementing models developed with AutoPrognosis in real-world clinical settings may present challenges, such as integration with existing medical systems. These issues are not unique to AutoPrognosis and addressing these issues will be crucial to the successful deployment of any machine learning model or other computational tools.</p>
    <p>Finally, while the focus and motivation for AutoPrognosis is medicine, it has not escaped our notice that AutoPrognosis can be used to construct predictive models and risk scores for applications beyond healthcare.</p>
  </sec>
  <sec id="sec030" sec-type="supplementary-material">
    <title>Supporting information</title>
    <supplementary-material id="pdig.0000276.s001" position="float" content-type="local-data">
      <label>S1 Table</label>
      <caption>
        <title>Most important features as measured by effect size.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pdig.0000276.s001.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pdig.0000276.s002" position="float" content-type="local-data">
      <label>S2 Table</label>
      <caption>
        <title>Performance of AutoPrognosis 2.0 for different subgroups.</title>
        <p>Subgroups created by splitting population on median feature value.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pdig.0000276.s002.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pdig.0000276.s003" position="float" content-type="local-data">
      <label>S3 Table</label>
      <caption>
        <title>Diabetes risk prediction results at different horizons.</title>
        <p>Mean performance reported with 95% confidence interval.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pdig.0000276.s003.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pdig.0000276.s004" position="float" content-type="local-data">
      <label>S4 Table</label>
      <caption>
        <title>Descriptive characteristics of UK Biobank cohort.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pdig.0000276.s004.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pdig.0000276.s005" position="float" content-type="local-data">
      <label>S1 Appendix</label>
      <caption>
        <title>Treatment of missing values.</title>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pdig.0000276.s005.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material id="pdig.0000276.s006" position="float" content-type="local-data">
      <label>S1 Fig</label>
      <caption>
        <title>Incidence of diabetes in the UK Biobank cohort.</title>
        <p>Proportion of cohort together with the number of individuals who have been diagnosed with diabetes for each time horizon.</p>
        <p>(PDF)</p>
      </caption>
      <media xlink:href="pdig.0000276.s006.pdf">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pdig.0000276.ref001">
      <label>1</label>
      <mixed-citation publication-type="journal"><name><surname>Topol</surname><given-names>EJ</given-names></name>. <article-title>High-performance medicine: The convergence of human and artificial intelligence</article-title>. <source>Nat Med</source>. <year>2019</year>;<volume>25</volume>(<issue>1</issue>):<fpage>44</fpage>–<lpage>56</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41591-018-0300-7</pub-id><?supplied-pmid 30617339?><pub-id pub-id-type="pmid">30617339</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref002">
      <label>2</label>
      <mixed-citation publication-type="book"><name><surname>Gerke</surname><given-names>S</given-names></name>, <name><surname>Minssen</surname><given-names>T</given-names></name>, <name><surname>Cohen</surname><given-names>G</given-names></name>. <part-title>Chapter 12—Ethical and legal challenges of artificial intelligence-driven healthcare</part-title>. In: <name><surname>Bohr</surname><given-names>A</given-names></name>, <name><surname>Memarzadeh</surname><given-names>K</given-names></name>, editors. <source>Artificial Intelligence in Healthcare</source>. <publisher-name>Academic Press</publisher-name>; <year>2020</year>. p. <fpage>295</fpage>–<lpage>336</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>Sun</surname><given-names>TQ</given-names></name>, <name><surname>Medaglia</surname><given-names>R</given-names></name>. <article-title>Mapping the challenges of artificial intelligence in the public sector: Evidence from public healthcare</article-title>. <source>Government Information Quarterly</source>. <year>2019</year>;<volume>36</volume>(<issue>2</issue>):<fpage>368</fpage>–<lpage>383</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.giq.2018.09.008</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Yu</surname><given-names>KH</given-names></name>, <name><surname>Beam</surname><given-names>AL</given-names></name>, <name><surname>Kohane</surname><given-names>IS</given-names></name>. <article-title>Artificial intelligence in healthcare</article-title>. <source>Nat Biomed Eng</source>. <year>2018</year>;<volume>2</volume>(<issue>10</issue>):<fpage>719</fpage>–<lpage>731</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41551-018-0305-z</pub-id><?supplied-pmid 31015651?><pub-id pub-id-type="pmid">31015651</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Rajpurkar</surname><given-names>P</given-names></name>, <name><surname>Chen</surname><given-names>Emma</given-names></name> and <name><surname>Banerjee</surname><given-names>O</given-names></name>, <name><surname>Topol</surname><given-names>EJ</given-names></name>. <article-title>AI in health and medicine</article-title>. <source>Nat Med</source>. <year>2022</year>;<volume>28</volume>(<issue>1</issue>):<fpage>31</fpage>–<lpage>38</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41591-021-01614-0</pub-id>
<?supplied-pmid 35058619?><pub-id pub-id-type="pmid">35058619</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref006">
      <label>6</label>
      <mixed-citation publication-type="journal"><name><surname>Petersson</surname><given-names>L</given-names></name>, <name><surname>Larsson</surname><given-names>I</given-names></name>, <name><surname>Nygren</surname><given-names>JM</given-names></name>, <name><surname>Nilsen</surname><given-names>P</given-names></name>, <name><surname>Neher</surname><given-names>M</given-names></name>, <name><surname>Reed</surname><given-names>JE</given-names></name>, <etal>et al</etal>. <article-title>Challenges to implementing artificial intelligence in healthcare: A qualitative interview study with healthcare leaders in Sweden</article-title>. <source>BMC Health Serv Res</source>. <year>2022</year>;<volume>22</volume>(<issue>1</issue>):<fpage>850</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s12913-022-08215-8</pub-id><?supplied-pmid 35778736?><pub-id pub-id-type="pmid">35778736</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref007">
      <label>7</label>
      <mixed-citation publication-type="other">Alaa A, van der Schaar M. AutoPrognosis: Automated clinical prognostic modeling via Bayesian optimization with structured kernel learning. In: Proceedings of the 35th International Conference on Machine Learning. 2018;80:139–148.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Elsken</surname><given-names>T</given-names></name>, <name><surname>Metzen</surname><given-names>JH</given-names></name>, <name><surname>Hutter</surname><given-names>F</given-names></name>. <article-title>Neural architecture search: A survey</article-title>. <source>J Mach Learn Res</source>. <year>2019</year>;<volume>20</volume>(<issue>55</issue>):<fpage>1</fpage>–<lpage>21</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Bergstra</surname><given-names>J</given-names></name>, <name><surname>Bardenet</surname><given-names>R</given-names></name>, <name><surname>Bengio</surname><given-names>Y</given-names></name>, <name><surname>Kégl</surname><given-names>B</given-names></name>. <article-title>Algorithms for hyper-parameter optimization</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2011</year>;<volume>24</volume>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref010">
      <label>10</label>
      <mixed-citation publication-type="other">Thornton C, Hutter F, Hoos HH, Leyton-Brown K. Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms. In: Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. Association for Computing Machinery; 2013. p. 847–855. Available from: <pub-id pub-id-type="doi">10.1145/2487575.2487629</pub-id>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Feurer</surname><given-names>M</given-names></name>, <name><surname>Klein</surname><given-names>A</given-names></name>, <name><surname>Eggensperger</surname><given-names>K</given-names></name>, <name><surname>Springenberg</surname><given-names>J</given-names></name>, <name><surname>Blum</surname><given-names>M</given-names></name>, <name><surname>Hutter</surname><given-names>F</given-names></name>. <article-title>Efficient and robust automated machine learning</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2015</year>;<volume>28</volume>:<fpage>2755</fpage>–<lpage>2763</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Alaa</surname><given-names>AM</given-names></name>, <name><surname>Bolton</surname><given-names>T</given-names></name>, <name><surname>Di Angelantonio</surname><given-names>E</given-names></name>, <name><surname>Rudd</surname><given-names>JHF</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>. <article-title>Cardiovascular disease risk prediction using automated machine learning: A prospective study of 423,604 UK Biobank participants</article-title>. <source>PLoS One</source>. <year>2019</year>;<volume>14</volume>(<issue>5</issue>):<fpage>1</fpage>–<lpage>17</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pone.0213653</pub-id><?supplied-pmid 31091238?><pub-id pub-id-type="pmid">31091238</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Alaa</surname><given-names>AM</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>. <article-title>Prognostication and risk factors for cystic fibrosis via automated machine learning</article-title>. <source>Sci Rep</source>. <year>2018</year>;<volume>8</volume>(<issue>1</issue>):<fpage>11242</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41598-018-29523-2</pub-id><?supplied-pmid 30050169?><pub-id pub-id-type="pmid">30050169</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Alaa</surname><given-names>AM</given-names></name>, <name><surname>Gurdasani</surname><given-names>D</given-names></name>, <name><surname>Harris</surname><given-names>AL</given-names></name>, <name><surname>Rashbass</surname><given-names>J</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>. <article-title>Machine learning to guide the use of adjuvant therapies for breast cancer</article-title>. <source>Nat Mach Intell</source>. <year>2021</year>;<volume>3</volume>(<issue>8</issue>):<fpage>716</fpage>–<lpage>726</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s42256-021-00353-8</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>Rahbar</surname><given-names>H</given-names></name>, <name><surname>Hippe</surname><given-names>DS</given-names></name>, <name><surname>Alaa</surname><given-names>A</given-names></name>, <name><surname>Cheeney</surname><given-names>SH</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>, <name><surname>Partridge</surname><given-names>SC</given-names></name>, <etal>et al</etal>. <article-title>The value of patient and tumor factors in predicting preoperative breast MRI outcomes</article-title>. <source>Radiol Imaging Cancer</source>. <year>2020</year>;<volume>2</volume>(<issue>4</issue>):<fpage>e190099</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1148/rycan.2020190099</pub-id><?supplied-pmid 32803166?><pub-id pub-id-type="pmid">32803166</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Qian</surname><given-names>Z</given-names></name>, <name><surname>Alaa</surname><given-names>AM</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>. <article-title>CPAS: The UK’s national machine learning-based hospital capacity planning system for COVID-19</article-title>. <source>Machine Learning</source>. <year>2021</year>;<volume>110</volume>(<issue>1</issue>):<fpage>15</fpage>–<lpage>35</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10994-020-05921-4</pub-id><?supplied-pmid 33250568?><pub-id pub-id-type="pmid">33250568</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Shah</surname><given-names>AA</given-names></name>, <name><surname>Devana</surname><given-names>SK</given-names></name>, <name><surname>Lee</surname><given-names>C</given-names></name>, <name><surname>Kianian</surname><given-names>R</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>, <name><surname>SooHoo</surname><given-names>NF</given-names></name>. <article-title>Development of a novel, potentially universal machine learning algorithm for prediction of complications after total hip arthroplasty</article-title>. <source>J Arthroplasty</source>. <year>2021</year>;<volume>36</volume>(<issue>5</issue>):<fpage>1655</fpage>–<lpage>1662.e1</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.arth.2020.12.040</pub-id><?supplied-pmid 33478891?><pub-id pub-id-type="pmid">33478891</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Devana</surname><given-names>SK</given-names></name>, <name><surname>Shah</surname><given-names>AA</given-names></name>, <name><surname>Lee</surname><given-names>C</given-names></name>, <name><surname>Roney</surname><given-names>AR</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>, <name><surname>SooHoo</surname><given-names>NF</given-names></name>. <article-title>A novel, potentially universal machine learning algorithm to predict complications in total knee arthroplasty</article-title>. <source>Arthroplast Today</source>. <year>2021</year>;<volume>10</volume>:<fpage>135</fpage>–<lpage>143</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.artd.2021.06.020</pub-id><?supplied-pmid 34401416?><pub-id pub-id-type="pmid">34401416</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Shah</surname><given-names>AA</given-names></name>, <name><surname>Devana</surname><given-names>SK</given-names></name>, <name><surname>Lee</surname><given-names>C</given-names></name>, <name><surname>Bugarin</surname><given-names>A</given-names></name>, <name><surname>Lord</surname><given-names>EL</given-names></name>, <name><surname>Shamie</surname><given-names>AN</given-names></name>, <etal>et al</etal>. <article-title>Machine learning-driven identification of novel patient factors for prediction of major complications after posterior cervical spinal fusion</article-title>. <source>Eur Spine J</source>. <year>2022</year>;<volume>31</volume>(<issue>8</issue>):<fpage>1952</fpage>–<lpage>1959</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s00586-021-06961-7</pub-id><?supplied-pmid 34392418?><pub-id pub-id-type="pmid">34392418</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Shah</surname><given-names>AA</given-names></name>, <name><surname>Devana</surname><given-names>SK</given-names></name>, <name><surname>Lee</surname><given-names>C</given-names></name>, <name><surname>Bugarin</surname><given-names>A</given-names></name>, <name><surname>Hong</surname><given-names>MK</given-names></name>, <name><surname>Upfill-Brown</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>A risk calculator for the prediction of C5 nerve root palsy after instrumented cervical fusion</article-title>. <source>World Neurosurg</source>. <year>2022</year>;<volume>166</volume>:<fpage>e703</fpage>–<lpage>e710</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.wneu.2022.07.082</pub-id><?supplied-pmid 35872129?><pub-id pub-id-type="pmid">35872129</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref021">
      <label>21</label>
      <mixed-citation publication-type="journal"><name><surname>Callender</surname><given-names>T</given-names></name>, <name><surname>Imrie</surname><given-names>F</given-names></name>, <name><surname>Cebere</surname><given-names>B</given-names></name>, <name><surname>Pashayan</surname><given-names>N</given-names></name>, <name><surname>Navani</surname><given-names>N</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Assessing eligibility for lung cancer screening: Parsimonious multi-country ensemble machine learning models for lung cancer prediction</article-title>. <source>medRxiv</source>. <year>2023</year>; p. <fpage>2023</fpage>–<lpage>01</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>van Buuren</surname><given-names>S</given-names></name>, <name><surname>Groothuis-Oudshoorn</surname><given-names>K</given-names></name>. <article-title>mice: Multivariate imputation by chained equations in R</article-title>. <source>J Stat Softw</source>. <year>2011</year>;<volume>45</volume>(<issue>3</issue>):<fpage>1</fpage>–<lpage>67</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Stekhoven</surname><given-names>DJ</given-names></name>, <name><surname>Bühlmann</surname><given-names>P</given-names></name>. <article-title>MissForest—non-parametric missing value imputation for mixed-type data</article-title>. <source>Bioinformatics</source>. <year>2011</year>;<volume>28</volume>(<issue>1</issue>):<fpage>112</fpage>–<lpage>118</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/bioinformatics/btr597</pub-id><?supplied-pmid 22039212?><pub-id pub-id-type="pmid">22039212</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref024">
      <label>24</label>
      <mixed-citation publication-type="other">Jarrett D, Cebere BC, Liu T, Curth A, van der Schaar M. HyperImpute: Generalized iterative imputation with automatic model selection. In: Proceedings of the 39th International Conference on Machine Learning. 2022;162:9916–9937.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>J</given-names></name>, <name><surname>Gelman</surname><given-names>A</given-names></name>, <name><surname>Hill</surname><given-names>J</given-names></name>, <name><surname>Su</surname><given-names>YS</given-names></name>, <name><surname>Kropko</surname><given-names>J</given-names></name>. <article-title>On the stationary distribution of iterative imputations</article-title>. <source>Biometrika</source>. <year>2013</year>;<volume>101</volume>(<issue>1</issue>):<fpage>155</fpage>–<lpage>173</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/biomet/ast044</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref026">
      <label>26</label>
      <mixed-citation publication-type="book"><name><surname>Van Buuren</surname><given-names>S</given-names></name>. <source>Flexible imputation of missing data</source>. <publisher-name>CRC press</publisher-name>; <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref027">
      <label>27</label>
      <mixed-citation publication-type="other">Wang Z, Li C, Jegelka S, Kohli P. Batched high-dimensional Bayesian optimization via structural kernel learning. In: Proceedings of the 34th International Conference on Machine Learning. 2017; p. 3656–3664.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref028">
      <label>28</label>
      <mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>L</given-names></name>, <name><surname>Jamieson</surname><given-names>K</given-names></name>, <name><surname>DeSalvo</surname><given-names>G</given-names></name>, <name><surname>Rostamizadeh</surname><given-names>A</given-names></name>, <name><surname>Talwalkar</surname><given-names>A</given-names></name>. <article-title>Hyperband: A novel bandit-based approach to hyperparameter optimization</article-title>. <source>J Mach Learn Res</source>. <year>2018</year>;<volume>18</volume>(<issue>185</issue>):<fpage>1</fpage>–<lpage>52</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref029">
      <label>29</label>
      <mixed-citation publication-type="journal"><name><surname>Crone</surname><given-names>SF</given-names></name>, <name><surname>Lessmann</surname><given-names>S</given-names></name>, <name><surname>Stahlbock</surname><given-names>R</given-names></name>. <article-title>The impact of preprocessing on data mining: An evaluation of classifier sensitivity in direct marketing</article-title>. <source>Eur J Oper Res</source>. <year>2006</year>;<volume>173</volume>(<issue>3</issue>):<fpage>781</fpage>–<lpage>800</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.ejor.2005.07.023</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref030">
      <label>30</label>
      <mixed-citation publication-type="other">Food and Drug Administration and others. Proposed regulatory framework for modifications to artificial intelligence/machine learning (AI/ML)-based software as a medical device (SaMD). 2019;.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref031">
      <label>31</label>
      <mixed-citation publication-type="journal"><name><surname>Mourby</surname><given-names>M</given-names></name>, <name><surname>Ó Cathaoir</surname><given-names>K</given-names></name>, <name><surname>Collin</surname><given-names>CB</given-names></name>. <article-title>Transparency of machine-learning in healthcare: The GDPR &amp; European health law</article-title>. <source>Comput Law Secur Rev</source>. <year>2021</year>;<volume>43</volume>:<fpage>105611</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.clsr.2021.105611</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref032">
      <label>32</label>
      <mixed-citation publication-type="journal"><name><surname>Kattan</surname><given-names>MW</given-names></name>, <name><surname>Hess</surname><given-names>KR</given-names></name>, <name><surname>Amin</surname><given-names>MB</given-names></name>, <name><surname>Lu</surname><given-names>Y</given-names></name>, <name><surname>Moons</surname><given-names>KGM</given-names></name>, <name><surname>Gershenwald</surname><given-names>JE</given-names></name>, <etal>et al</etal>. <article-title>American Joint Committee on Cancer acceptance criteria for inclusion of risk models for individualized prognosis in the practice of precision medicine</article-title>. <source>CA Cancer J Clin</source>. <year>2016</year>;<volume>66</volume>(<issue>5</issue>):<fpage>370</fpage>–<lpage>374</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.3322/caac.21339</pub-id><?supplied-pmid 26784705?><pub-id pub-id-type="pmid">26784705</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref033">
      <label>33</label>
      <mixed-citation publication-type="journal"><name><surname>Lundberg</surname><given-names>SM</given-names></name>, <name><surname>Lee</surname><given-names>SI</given-names></name>. <article-title>A unified approach to interpreting model predictions</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2017</year>;<volume>30</volume>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref034">
      <label>34</label>
      <mixed-citation publication-type="journal"><name><surname>Crabbe</surname><given-names>J</given-names></name>, <name><surname>Qian</surname><given-names>Z</given-names></name>, <name><surname>Imrie</surname><given-names>F</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>. <article-title>Explaining latent representations with a corpus of examples</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2021</year>;<volume>34</volume>:<fpage>12154</fpage>–<lpage>12166</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref035">
      <label>35</label>
      <mixed-citation publication-type="journal"><name><surname>Crabbe</surname><given-names>J</given-names></name>, <name><surname>Zhang</surname><given-names>Y</given-names></name>, <name><surname>Zame</surname><given-names>W</given-names></name>, <name><surname>van der Schaar</surname><given-names>M</given-names></name>. <article-title>Learning outside the Black-Box: The pursuit of interpretable models</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2020</year>;<volume>33</volume>:<fpage>17838</fpage>–<lpage>17849</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref036">
      <label>36</label>
      <mixed-citation publication-type="other">Streamlit. Available from: <ext-link xlink:href="https://streamlit.io/" ext-link-type="uri">https://streamlit.io/</ext-link>;.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref037">
      <label>37</label>
      <mixed-citation publication-type="journal"><name><surname>Luo</surname><given-names>G</given-names></name>, <name><surname>Stone</surname><given-names>BL</given-names></name>, <name><surname>Johnson</surname><given-names>MD</given-names></name>, <name><surname>Tarczy-Hornoch</surname><given-names>P</given-names></name>, <name><surname>Wilcox</surname><given-names>AB</given-names></name>, <name><surname>Mooney</surname><given-names>SD</given-names></name>, <etal>et al</etal>. <article-title>Automating construction of machine learning models with clinical big data: Proposal rationale and methods</article-title>. <source>JMIR Res Protoc</source>. <year>2017</year>;<volume>6</volume>(<issue>8</issue>):<fpage>e175</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2196/resprot.7757</pub-id><?supplied-pmid 28851678?><pub-id pub-id-type="pmid">28851678</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref038">
      <label>38</label>
      <mixed-citation publication-type="other">Elshawi R, Maher M, Sakr S. Automated machine learning: State-of-the-art and open challenges. arXiv preprint arXiv:190602287. 2019;.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref039">
      <label>39</label>
      <mixed-citation publication-type="journal"><name><surname>Sculley</surname><given-names>D</given-names></name>, <name><surname>Holt</surname><given-names>G</given-names></name>, <name><surname>Golovin</surname><given-names>D</given-names></name>, <name><surname>Davydov</surname><given-names>E</given-names></name>, <name><surname>Phillips</surname><given-names>T</given-names></name>, <name><surname>Ebner</surname><given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Hidden technical debt in machine learning systems</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2015</year>;<volume>28</volume>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref040">
      <label>40</label>
      <mixed-citation publication-type="journal"><name><surname>Nestor</surname><given-names>B</given-names></name>, <name><surname>McDermott</surname><given-names>M</given-names></name>, <name><surname>Chauhan</surname><given-names>G</given-names></name>, <name><surname>Naumann</surname><given-names>T</given-names></name>, <name><surname>Hughes</surname><given-names>MC</given-names></name>, <name><surname>Goldenberg</surname><given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Rethinking clinical prediction: Why machine learning must consider year of care and feature aggregation</article-title>. <source>Machine Learning for Health (ML4H) Workshop at NeurIPS</source>. <year>2018</year>;.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref041">
      <label>41</label>
      <mixed-citation publication-type="journal"><name><surname>Cox</surname><given-names>DR</given-names></name>. <article-title>Regression models and life-tables</article-title>. <source>J R Stat Soc Series B Stat Methodol</source>. <year>1972</year>;<volume>34</volume>(<issue>2</issue>):<fpage>187</fpage>–<lpage>202</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref042">
      <label>42</label>
      <mixed-citation publication-type="journal"><name><surname>Volovici</surname><given-names>V</given-names></name>, <name><surname>Syn</surname><given-names>NL</given-names></name>, <name><surname>Ercole</surname><given-names>A</given-names></name>, <name><surname>Zhao</surname><given-names>JJ</given-names></name>, <name><surname>Liu</surname><given-names>N</given-names></name>. <article-title>Steps to avoid overuse and misuse of machine learning in clinical research</article-title>. <source>Nat Med</source>. <year>2022</year>;<volume>28</volume>(<issue>10</issue>):<fpage>1996</fpage>–<lpage>1999</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41591-022-01961-6</pub-id><?supplied-pmid 36097217?><pub-id pub-id-type="pmid">36097217</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref043">
      <label>43</label>
      <mixed-citation publication-type="journal"><name><surname>Tomašev</surname><given-names>N</given-names></name>, <name><surname>Cornebise</surname><given-names>J</given-names></name>, <name><surname>Hutter</surname><given-names>F</given-names></name>, <name><surname>Mohamed</surname><given-names>S</given-names></name>, <name><surname>Picciariello</surname><given-names>A</given-names></name>, <name><surname>Connelly</surname><given-names>B</given-names></name>, <etal>et al</etal>. <article-title>AI for social good: Unlocking the opportunity for positive impact</article-title>. <source>Nat Commun</source>. <year>2020</year>;<volume>11</volume>(<issue>1</issue>):<fpage>2468</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41467-020-15871-z</pub-id><?supplied-pmid 32424119?><pub-id pub-id-type="pmid">32424119</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref044">
      <label>44</label>
      <mixed-citation publication-type="journal"><name><surname>Akbilgic</surname><given-names>O</given-names></name>, <name><surname>Davis</surname><given-names>RL</given-names></name>. <article-title>The promise of machine learning: When will it be delivered?</article-title><source>J Card Fail</source>. <year>2019</year>;<volume>25</volume>(<issue>6</issue>):<fpage>484</fpage>–<lpage>485</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1016/j.cardfail.2019.04.006</pub-id><?supplied-pmid 30978508?><pub-id pub-id-type="pmid">30978508</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref045">
      <label>45</label>
      <mixed-citation publication-type="journal"><name><surname>Schulz</surname><given-names>MA</given-names></name>, <name><surname>Yeo</surname><given-names>BTT</given-names></name>, <name><surname>Vogelstein</surname><given-names>JT</given-names></name>, <name><surname>Mourao-Miranada</surname><given-names>J</given-names></name>, <name><surname>Kather</surname><given-names>JN</given-names></name>, <name><surname>Kording</surname><given-names>K</given-names></name>, <etal>et al</etal>. <article-title>Different scaling of linear models and deep learning in UKBiobank brain images versus machine-learning datasets</article-title>. <source>Nat Commun</source>. <year>2020</year>;<volume>11</volume>(<issue>1</issue>):<fpage>4238</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41467-020-18037-z</pub-id><?supplied-pmid 32843633?><pub-id pub-id-type="pmid">32843633</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref046">
      <label>46</label>
      <mixed-citation publication-type="journal"><name><surname>Chowdhury</surname><given-names>MZI</given-names></name>, <name><surname>Turin</surname><given-names>TC</given-names></name>. <article-title>Variable selection strategies and its importance in clinical prediction modelling</article-title>. <source>Fam Med Community Health</source>. <year>2020</year>;<volume>8</volume>(<issue>1</issue>). <comment>doi: </comment><pub-id pub-id-type="doi">10.1136/fmch-2019-000262</pub-id><?supplied-pmid 32148735?><pub-id pub-id-type="pmid">32148735</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref047">
      <label>47</label>
      <mixed-citation publication-type="book"><name><surname>Steyerberg</surname><given-names>E</given-names></name>. <source>Clinical prediction models: A practical approach to development, validation, and updating</source>. <publisher-name>Springer</publisher-name>; <year>2008</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref048">
      <label>48</label>
      <mixed-citation publication-type="journal"><name><surname>Guyon</surname><given-names>I</given-names></name>, <name><surname>Elisseeff</surname><given-names>A</given-names></name>. <article-title>An introduction to variable and feature selection</article-title>. <source>J Mach Learn Res</source>. <year>2003</year>;<volume>3</volume>(<issue>Mar</issue>):<fpage>1157</fpage>–<lpage>1182</lpage>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref049">
      <label>49</label>
      <mixed-citation publication-type="other">Caruana R, Lou Y, Gehrke J, Koch P, Sturm M, Elhadad N. Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission. In: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 2015; p. 1721–1730.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref050">
      <label>50</label>
      <mixed-citation publication-type="journal"><name><surname>Winkler</surname><given-names>JK</given-names></name>, <name><surname>Fink</surname><given-names>C</given-names></name>, <name><surname>Toberer</surname><given-names>F</given-names></name>, <name><surname>Enk</surname><given-names>A</given-names></name>, <name><surname>Deinlein</surname><given-names>T</given-names></name>, <name><surname>Hofmann-Wellenhof</surname><given-names>R</given-names></name>, <etal>et al</etal>. <article-title>Association between surgical skin markings in dermoscopic images and diagnostic performance of a deep learning convolutional neural network for melanoma recognition</article-title>. <source>JAMA Dermatol</source>. <year>2019</year>;<volume>155</volume>(<issue>10</issue>):<fpage>1135</fpage>–<lpage>1141</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1001/jamadermatol.2019.1735</pub-id><?supplied-pmid 31411641?><pub-id pub-id-type="pmid">31411641</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref051">
      <label>51</label>
      <mixed-citation publication-type="journal"><name><surname>Geirhos</surname><given-names>R</given-names></name>, <name><surname>Jacobsen</surname><given-names>JH</given-names></name>, <name><surname>Michaelis</surname><given-names>C</given-names></name>, <name><surname>Zemel</surname><given-names>R</given-names></name>, <name><surname>Brendel</surname><given-names>W</given-names></name>, <name><surname>Bethge</surname><given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Shortcut learning in deep neural networks</article-title>. <source>Nat Mach Intell</source>. <year>2020</year>;<volume>2</volume>(<issue>11</issue>):<fpage>665</fpage>–<lpage>673</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s42256-020-00257-z</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref052">
      <label>52</label>
      <mixed-citation publication-type="journal"><name><surname>Tampu</surname><given-names>IE</given-names></name>, <name><surname>Eklund</surname><given-names>A</given-names></name>, <name><surname>Haj-Hosseini</surname><given-names>N</given-names></name>. <article-title>Inflation of test accuracy due to data leakage in deep learning-based classification of OCT images</article-title>. <source>Sci Data</source>. <year>2022</year>;<volume>9</volume>(<issue>1</issue>):<fpage>580</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41597-022-01618-6</pub-id><?supplied-pmid 36138025?><pub-id pub-id-type="pmid">36138025</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref053">
      <label>53</label>
      <mixed-citation publication-type="journal"><name><surname>DeGrave</surname><given-names>AJ</given-names></name>, <name><surname>Janizek</surname><given-names>JD</given-names></name>, <name><surname>Lee</surname><given-names>SI</given-names></name>. <article-title>AI for radiographic COVID-19 detection selects shortcuts over signal</article-title>. <source>Nat Mach Intell</source>. <year>2021</year>;<volume>3</volume>(<issue>7</issue>):<fpage>610</fpage>–<lpage>619</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s42256-021-00338-7</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref054">
      <label>54</label>
      <mixed-citation publication-type="journal"><name><surname>Roberts</surname><given-names>M</given-names></name>, <name><surname>Driggs</surname><given-names>D</given-names></name>, <name><surname>Thorpe</surname><given-names>M</given-names></name>, <name><surname>Gilbey</surname><given-names>J</given-names></name>, <name><surname>Yeung</surname><given-names>M</given-names></name>, <name><surname>Ursprung</surname><given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Common pitfalls and recommendations for using machine learning to detect and prognosticate for COVID-19 using chest radiographs and CT scans</article-title>. <source>Nat Mach Intell</source>. <year>2021</year>;<volume>3</volume>(<issue>3</issue>):<fpage>199</fpage>–<lpage>217</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s42256-021-00307-0</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref055">
      <label>55</label>
      <mixed-citation publication-type="journal"><name><surname>Rajkomar</surname><given-names>A</given-names></name>, <name><surname>Hardt</surname><given-names>M</given-names></name>, <name><surname>Howell</surname><given-names>MD</given-names></name>, <name><surname>Corrado</surname><given-names>G</given-names></name>, <name><surname>Chin</surname><given-names>MH</given-names></name>. <article-title>Ensuring fairness in machine learning to advance health equity</article-title>. <source>Ann Intern Med</source>. <year>2018</year>;<volume>169</volume>(<issue>12</issue>):<fpage>866</fpage>–<lpage>872</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.7326/M18-1990</pub-id><?supplied-pmid 30508424?><pub-id pub-id-type="pmid">30508424</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref056">
      <label>56</label>
      <mixed-citation publication-type="journal"><name><surname>Yoon</surname><given-names>CH</given-names></name>, <name><surname>Torrance</surname><given-names>R</given-names></name>, <name><surname>Scheinerman</surname><given-names>N</given-names></name>. <article-title>Machine learning in medicine: Should the pursuit of enhanced interpretability be abandoned?</article-title><source>J Med Ethics</source>. <year>2022</year>;<volume>48</volume>(<issue>9</issue>):<fpage>581</fpage>–<lpage>585</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1136/medethics-2020-107102</pub-id><?supplied-pmid 34006600?><pub-id pub-id-type="pmid">34006600</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref057">
      <label>57</label>
      <mixed-citation publication-type="journal"><name><surname>Laiteerapong</surname><given-names>N</given-names></name>, <name><surname>Huang</surname><given-names>ES</given-names></name>. <article-title>The pace of change in medical practice and health policy: Collision or coexistence?</article-title><source>J Gen Intern Med</source>. <year>2015</year>;<volume>30</volume>(<issue>6</issue>):<fpage>848</fpage>–<lpage>852</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s11606-015-3182-0</pub-id><?supplied-pmid 25608743?><pub-id pub-id-type="pmid">25608743</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref058">
      <label>58</label>
      <mixed-citation publication-type="journal"><name><surname>Gupta</surname><given-names>DM</given-names></name>, <name><surname>Boland</surname><given-names>RJ</given-names></name>, <name><surname>Aron</surname><given-names>DC</given-names></name>. <article-title>The physician’s experience of changing clinical practice: a struggle to unlearn</article-title>. <source>Implement Sci</source>. <year>2017</year>;<volume>12</volume>(<issue>1</issue>):<fpage>28</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/s13012-017-0555-2</pub-id><?supplied-pmid 28245849?><pub-id pub-id-type="pmid">28245849</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref059">
      <label>59</label>
      <mixed-citation publication-type="journal"><name><surname>Beam</surname><given-names>AL</given-names></name>, <name><surname>Manrai</surname><given-names>AK</given-names></name>, <name><surname>Ghassemi</surname><given-names>M</given-names></name>. <article-title>Challenges to the reproducibility of machine learning models in health care</article-title>. <source>JAMA</source>. <year>2020</year>;<volume>323</volume>(<issue>4</issue>):<fpage>305</fpage>–<lpage>306</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1001/jama.2019.20866</pub-id><?supplied-pmid 31904799?><pub-id pub-id-type="pmid">31904799</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref060">
      <label>60</label>
      <mixed-citation publication-type="journal"><name><surname>LeVeque</surname><given-names>RJ</given-names></name>, <name><surname>Mitchell</surname><given-names>IM</given-names></name>, <name><surname>Stodden</surname><given-names>V</given-names></name>. <article-title>Reproducible research for scientific computing: Tools and strategies for changing the culture</article-title>. <source>Comput Sci Eng</source>. <year>2012</year>;<volume>14</volume>(<issue>4</issue>):<fpage>13</fpage>–<lpage>17</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1109/MCSE.2012.38</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref061">
      <label>61</label>
      <mixed-citation publication-type="journal"><name><surname>Miłkowski</surname><given-names>M</given-names></name>, <name><surname>Hensel</surname><given-names>WM</given-names></name>, <name><surname>Hohol</surname><given-names>M</given-names></name>. <article-title>Replicability or reproducibility? On the replication crisis in computational neuroscience and sharing only relevant detail</article-title>. <source>J Comput Neurosci</source>. <year>2018</year>;<volume>45</volume>(<issue>3</issue>):<fpage>163</fpage>–<lpage>172</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s10827-018-0702-z</pub-id><?supplied-pmid 30377880?><pub-id pub-id-type="pmid">30377880</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref062">
      <label>62</label>
      <mixed-citation publication-type="journal"><name><surname>Haibe-Kains</surname><given-names>B</given-names></name>, <name><surname>Adam</surname><given-names>GA</given-names></name>, <name><surname>Hosny</surname><given-names>A</given-names></name>, <name><surname>Khodakarami</surname><given-names>F</given-names></name>, <collab>Board MAQCMS</collab>, <name><surname>Levi</surname></name>, <etal>et al</etal>. <article-title>Transparency and reproducibility in artificial intelligence</article-title>. <source>Nature</source>. <year>2020</year>;<volume>586</volume>(<issue>7829</issue>):<fpage>E14</fpage>–<lpage>E16</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1038/s41586-020-2766-y</pub-id><?supplied-pmid 33057217?><pub-id pub-id-type="pmid">33057217</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref063">
      <label>63</label>
      <mixed-citation publication-type="journal"><name><surname>Sudlow</surname><given-names>C</given-names></name>, <name><surname>Gallacher</surname><given-names>J</given-names></name>, <name><surname>Allen</surname><given-names>N</given-names></name>, <name><surname>Beral</surname><given-names>V</given-names></name>, <name><surname>Burton</surname><given-names>P</given-names></name>, <name><surname>Danesh</surname><given-names>J</given-names></name>, <etal>et al</etal>. <article-title>UK Biobank: An open access resource for identifying the causes of a wide range of complex diseases of middle and old age</article-title>. <source>PLoS Med</source>. <year>2015</year>;<volume>12</volume>(<issue>3</issue>):<fpage>1</fpage>–<lpage>10</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1371/journal.pmed.1001779</pub-id><?supplied-pmid 25826379?><pub-id pub-id-type="pmid">25826379</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref064">
      <label>64</label>
      <mixed-citation publication-type="journal"><name><surname>Adamska</surname><given-names>L</given-names></name>, <name><surname>Allen</surname><given-names>N</given-names></name>, <name><surname>Flaig</surname><given-names>R</given-names></name>, <name><surname>Sudlow</surname><given-names>C</given-names></name>, <name><surname>Lay</surname><given-names>M</given-names></name>, <name><surname>Landray</surname><given-names>M</given-names></name>. <article-title>Challenges of linking to routine healthcare records in UK Biobank</article-title>. <source>Trials</source>. <year>2015</year>;<volume>16</volume>(<issue>2</issue>):<fpage>O68</fpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1186/1745-6215-16-S2-O68</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref065">
      <label>65</label>
      <mixed-citation publication-type="other">World Health Organization, et al. Global report on diabetes. World Health Organization; 2016.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref066">
      <label>66</label>
      <mixed-citation publication-type="journal"><name><surname>Bang</surname><given-names>H</given-names></name>, <name><surname>Edwards</surname><given-names>AM</given-names></name>, <name><surname>Bomback</surname><given-names>AS</given-names></name>, <name><surname>Ballantyne</surname><given-names>CM</given-names></name>, <name><surname>Brillon</surname><given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Development and validation of a patient self-assessment score for diabetes risk</article-title>. <source>Ann Intern Med</source>. <year>2009</year>;<volume>151</volume>(<issue>11</issue>):<fpage>775</fpage>–<lpage>783</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1059/0003-4819-151-11-200912010-00005</pub-id><?supplied-pmid 19949143?><pub-id pub-id-type="pmid">19949143</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref067">
      <label>67</label>
      <mixed-citation publication-type="journal"><name><surname>Lindström̈</surname><given-names>J</given-names></name>, <name><surname>Tuomilehto</surname><given-names>J</given-names></name>. <article-title>The Diabetes Risk Score: A practical tool to predict type 2 diabetes risk</article-title>. <source>Diabetes Care</source>. <year>2003</year>;<volume>26</volume>(<issue>3</issue>):<fpage>725</fpage>–<lpage>731</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.2337/diacare.26.3.725</pub-id><?supplied-pmid 12610029?><pub-id pub-id-type="pmid">12610029</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref068">
      <label>68</label>
      <mixed-citation publication-type="journal"><name><surname>Hippisley-Cox</surname><given-names>J</given-names></name>, <name><surname>Coupland</surname><given-names>C</given-names></name>. <article-title>Development and validation of QDiabetes-2018 risk prediction algorithm to estimate future risk of type 2 diabetes: cohort study</article-title>. <source>BMJ</source>. <year>2017</year>;<volume>359</volume>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1136/bmj.j5019</pub-id><?supplied-pmid 29158232?><pub-id pub-id-type="pmid">29158232</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref069">
      <label>69</label>
      <mixed-citation publication-type="journal"><name><surname>Vickers</surname><given-names>AJ</given-names></name>, <name><surname>Elkin</surname><given-names>EB</given-names></name>. <article-title>Decision curve analysis: A novel method for evaluating prediction models</article-title>. <source>Med Decis Making</source>. <year>2006</year>;<volume>26</volume>(<issue>6</issue>):<fpage>565</fpage>–<lpage>574</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1177/0272989X06295361</pub-id><?supplied-pmid 17099194?><pub-id pub-id-type="pmid">17099194</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref070">
      <label>70</label>
      <mixed-citation publication-type="journal"><name><surname>Vickers</surname><given-names>AJ</given-names></name>. <article-title>Decision analysis for the evaluation of diagnostic tests, prediction models, and molecular markers</article-title>. <source>Am Stat</source>. <year>2008</year>;<volume>62</volume>(<issue>4</issue>):<fpage>314</fpage>–<lpage>320</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1198/000313008X370302</pub-id><?supplied-pmid 19132141?><pub-id pub-id-type="pmid">19132141</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref071">
      <label>71</label>
      <mixed-citation publication-type="journal"><name><surname>Moons</surname><given-names>KGM</given-names></name>, <name><surname>Altman</surname><given-names>DG</given-names></name>, <name><surname>Reitsma</surname><given-names>JB</given-names></name>, <name><surname>Ioannidis</surname><given-names>JPA</given-names></name>, <name><surname>Macaskill</surname><given-names>P</given-names></name>, <name><surname>Steyerberg</surname><given-names>EW</given-names></name>, <etal>et al</etal>. <article-title>Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD): Explanation and Elaboration</article-title>. <source>Ann Intern Med</source>. <year>2015</year>;<volume>162</volume>(<issue>1</issue>):<fpage>W1</fpage>–<lpage>W73</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.7326/M14-0698</pub-id><?supplied-pmid 25560730?><pub-id pub-id-type="pmid">25560730</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref072">
      <label>72</label>
      <mixed-citation publication-type="book"><name><surname>Cohen</surname><given-names>J</given-names></name>. <source>Statistical power analysis for the behavioral sciences</source>. <publisher-name>Routledge</publisher-name>; <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref073">
      <label>73</label>
      <mixed-citation publication-type="journal"><name><surname>Nano</surname><given-names>J</given-names></name>, <name><surname>Muka</surname><given-names>T</given-names></name>, <name><surname>Ligthart</surname><given-names>S</given-names></name>, <name><surname>Hofman</surname><given-names>A</given-names></name>, <name><surname>Darwish Murad</surname><given-names>S</given-names></name>, <name><surname>Janssen</surname><given-names>HL</given-names></name>, <etal>et al</etal>. <article-title>Gamma-glutamyltransferase levels, prediabetes and type 2 diabetes: A Mendelian randomization study</article-title>. <source>Int J Epidemiol</source>. <year>2017</year>;<volume>46</volume>(<issue>5</issue>):<fpage>1400</fpage>–<lpage>1409</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1093/ije/dyx006</pub-id><?supplied-pmid 28338987?><pub-id pub-id-type="pmid">28338987</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref074">
      <label>74</label>
      <mixed-citation publication-type="book"><collab>International Diabetes Federation</collab>. <source>IDF Diabetes Atlas</source>, <edition designator="6">6th edn</edition>.; <year>2013</year>.</mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref075">
      <label>75</label>
      <mixed-citation publication-type="journal"><name><surname>Gale</surname><given-names>EA</given-names></name>, <name><surname>Gillespie</surname><given-names>KM</given-names></name>. <article-title>Diabetes and gender</article-title>. <source>Diabetologia</source>. <year>2001</year>;<volume>44</volume>(<issue>1</issue>):<fpage>3</fpage>–<lpage>15</lpage>. <comment>doi: </comment><pub-id pub-id-type="doi">10.1007/s001250051573</pub-id><?supplied-pmid 11206408?><pub-id pub-id-type="pmid">11206408</pub-id></mixed-citation>
    </ref>
    <ref id="pdig.0000276.ref076">
      <label>76</label>
      <mixed-citation publication-type="other">American Diabetes Association. <ext-link xlink:href="https://diabetes.org/diabetes/a1c/diagnosis" ext-link-type="uri">https://diabetes.org/diabetes/a1c/diagnosis</ext-link>;.</mixed-citation>
    </ref>
  </ref-list>
</back>
