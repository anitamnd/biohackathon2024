<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats">
  <restricted-by>pmc</restricted-by>
</processing-meta>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">J Cheminform</journal-id>
    <journal-id journal-id-type="iso-abbrev">J Cheminform</journal-id>
    <journal-title-group>
      <journal-title>Journal of Cheminformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1758-2946</issn>
    <publisher>
      <publisher-name>Springer International Publishing</publisher-name>
      <publisher-loc>Cham</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">9667597</article-id>
    <article-id pub-id-type="publisher-id">659</article-id>
    <article-id pub-id-type="doi">10.1186/s13321-022-00659-8</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Methodology</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>MDDI-SCL: predicting multi-type drug-drug interactions via supervised contrastive learning</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Lin</surname>
          <given-names>Shenggeng</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Weizhi</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Chen</surname>
          <given-names>Gengwang</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Zhou</surname>
          <given-names>Songchi</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Wei</surname>
          <given-names>Dong-Qing</given-names>
        </name>
        <address>
          <email>dqwei@sjtu.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff2">2</xref>
        <xref ref-type="aff" rid="Aff3">3</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <name>
          <surname>Xiong</surname>
          <given-names>Yi</given-names>
        </name>
        <address>
          <email>xiongyi@sjtu.edu.cn</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
        <xref ref-type="aff" rid="Aff4">4</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.16821.3c</institution-id><institution-id institution-id-type="ISNI">0000 0004 0368 8293</institution-id><institution>State Key Laboratory of Microbial Metabolism, Shanghai-Islamabad-Belgrade Joint Innovation Center on Antibacterial Resistances, Joint International Research Laboratory of Metabolic &amp; Developmental Sciences and School of Life Sciences and Biotechnology, </institution><institution>Shanghai Jiao Tong University, </institution></institution-wrap>Shanghai, 200240 China </aff>
      <aff id="Aff2"><label>2</label>Zhongjing Research and Industrialization Institute of Chinese Medicine, Nanyang, 473006 China </aff>
      <aff id="Aff3"><label>3</label>Peng Cheng National Laboratory, Shenzhen, 518055 China </aff>
      <aff id="Aff4"><label>4</label>Shanghai Artificial Intelligence Laboratory, Shanghai, 200232 China </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>15</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>15</day>
      <month>11</month>
      <year>2022</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2022</year>
    </pub-date>
    <volume>14</volume>
    <elocation-id>81</elocation-id>
    <history>
      <date date-type="received">
        <day>2</day>
        <month>8</month>
        <year>2022</year>
      </date>
      <date date-type="accepted">
        <day>5</day>
        <month>11</month>
        <year>2022</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2022</copyright-statement>
      <license>
        <ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <p id="Par1">The joint use of multiple drugs may cause unintended drug-drug interactions (DDIs) and result in adverse consequence to the patients. Accurate identification of DDI types can not only provide hints to avoid these accidental events, but also elaborate the underlying mechanisms by how DDIs occur. Several computational methods have been proposed for multi-type DDI prediction, but room remains for improvement in prediction performance. In this study, we propose a supervised contrastive learning based method, MDDI-SCL, implemented by three-level loss functions, to predict multi-type DDIs. MDDI-SCL is mainly composed of three modules: drug feature encoder and mean squared error loss module, drug latent feature fusion and supervised contrastive loss module, multi-type DDI prediction and classification loss module. The drug feature encoder and mean squared error loss module uses self-attention mechanism and autoencoder to learn drug-level latent features. The drug latent feature fusion and supervised contrastive loss module uses multi-scale feature fusion to learn drug pair-level latent features. The prediction and classification loss module predicts DDI types of each drug pair. We evaluate MDDI-SCL on three different tasks of two datasets. Experimental results demonstrate that MDDI-SCL achieves better or comparable performance as the state-of-the-art methods. Furthermore, the effectiveness of supervised contrastive learning is validated by ablation experiment, and the feasibility of MDDI-SCL is supported by case studies. The source codes are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/ShenggengLin/MDDI-SCL">https://github.com/ShenggengLin/MDDI-SCL</ext-link>.</p>
      <sec>
        <title>Supplementary Information</title>
        <p>The online version contains supplementary material available at 10.1186/s13321-022-00659-8.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>Drug-drug interaction</kwd>
      <kwd>Multi-type classification</kwd>
      <kwd>Supervised contrastive learning</kwd>
      <kwd>Multi-scale feature fusion</kwd>
      <kwd>Self-attention mechanism</kwd>
    </kwd-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id>
            <institution>National Natural Science Foundation of China</institution>
          </institution-wrap>
        </funding-source>
        <award-id>62172274</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>the Science and Technology Commission of Shanghai Municipality</institution>
        </funding-source>
        <award-id>19430750600</award-id>
      </award-group>
    </funding-group>
    <funding-group>
      <award-group>
        <funding-source>
          <institution>Joint Research Fund for Medical and Engineering and Scientific Research at Shanghai Jiao Tong University</institution>
        </funding-source>
        <award-id>YG2021ZD02</award-id>
      </award-group>
    </funding-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2022</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Introduction</title>
    <p id="Par18">The use of multiple drugs, often termed as polypharmacy, is a therapeutic approach to treat various complex diseases [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>]. However, polypharmacy can lead to drug-drug interactions (DDIs), in which the pharmacological effect of a drug is altered by another drugs [<xref ref-type="bibr" rid="CR3">3</xref>–<xref ref-type="bibr" rid="CR5">5</xref>]. It has been estimated that DDIs are associated with 30% of all the reported adverse drug events (ADEs) which may result in the majority of incidence and mortality, and even drug withdrawal from the market, incurring huge medical expense due to the stringent demands on drug development [<xref ref-type="bibr" rid="CR6">6</xref>]. Therefore, it is necessary to reliably identify DDIs and understand their underlying mechanisms, which will be beneficial for drug development in pharmaceutical companies and can provide important information on polypharmacy prescription for clinicians and patients. In vitro experiments and clinical trials can be conducted to identify DDIs, but systematic combinatorial screening of DDI candidates from a large pool of drugs by experimental techniques remains challenging, time- and resource-consuming.</p>
    <p id="Par19">In the last decades, there are increasing availability of scientific literature, electronic medical records, population-based reports of adverse events, drug labels, and other related sources [<xref ref-type="bibr" rid="CR7">7</xref>]. Researchers attempted to extract DDIs from scientific literature and electronic medical records via natural language processing (NLP) techniques [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR9">9</xref>], infer potential DDIs by similarity-based methods based on known DDIs [<xref ref-type="bibr" rid="CR10">10</xref>], and predict DDIs by leveraging machine learning [<xref ref-type="bibr" rid="CR11">11</xref>], network modelling [<xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR13">13</xref>], and knowledge graphs [<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR15">15</xref>]. However, most of these computational methods (except the extraction of DDIs via NLP methods) only consider whether a DDI occurs or not given a pair of drugs.</p>
    <p id="Par20">To facilitate the understanding of the causal mechanisms of DDIs, recent studies have developed multi-type DDIs prediction methods to elaborate sufficient details beyond the chance of DDI occurrence [<xref ref-type="bibr" rid="CR16">16</xref>]. The pioneering study by Ryu et al. constructed the gold standard DDI dataset from DrugBank [<xref ref-type="bibr" rid="CR17">17</xref>], which covers 192,284 DDIs associated with 86 DDI types (changes in pharmacological effects and/or the risk of ADEs as a result of DDI) from 191,878 drug pairs [<xref ref-type="bibr" rid="CR18">18</xref>]. Then, they formulated the multi-type DDI prediction as a multi-label classification task and proposed DeepDDI by using deep neural network (DNN) based on structural information of chemical compounds for a drug pair. This architecture became a baseline for several other state-of-the-art multi-type DDI prediction methods, which improved the multi-type DDI prediction by incorporating various types of biological information such as drug targets and enzymes to represent a drug pair in addition to the structural information of drugs based on autoencoder or the encoder module of transformer for learning the low-dimensional latent features and DNN algorithms for classification [<xref ref-type="bibr" rid="CR19">19</xref>–<xref ref-type="bibr" rid="CR21">21</xref>]. It should be noted that those methods represent the feature vector of a drug by the similarity profile, which is generated by the similarity (i.e., structural similarity) of a given drug against each one in the rest of drugs across the entire dataset. More recently, Deng et al. used few-shot learning based on the latent features from a pair of drug structures to improve the prediction performance on rare types of DDIs which have few samples [<xref ref-type="bibr" rid="CR22">22</xref>]. Liu et al. proposed the method CSMDDI, which first generates the embedding representations of drugs and DDI types and then learns a mapping function to bridge the drugs attributes to their embeddings to predict multi-type DDIs [<xref ref-type="bibr" rid="CR23">23</xref>]. Feng et al. proposed deepMDDI, which consists of an encoder by deep relational graph convolutional networks constraining with similarity regularization to capture the topological features of DDI network and a tensor-like decoder for multi-label prediction of DDI types [<xref ref-type="bibr" rid="CR24">24</xref>]. Yang et al. proposed a substructure-aware graph neural network, utilizing a message-passing neural network with a novel substructure attention mechanism and a substructure-substructure interaction module for DDI prediction [<xref ref-type="bibr" rid="CR25">25</xref>].</p>
    <p id="Par21">With the increasing availability of large biomedical knowledge graphs (KGs), some studies attempt to incorporate KG with other data (i.e., drug molecular structures) for multi-type DDI predictions via graph neural networks (GNNs) [<xref ref-type="bibr" rid="CR26">26</xref>, <xref ref-type="bibr" rid="CR27">27</xref>]. However, there are data redundancy and noise in the large KGs, in which only a small subgraph is relevant to a prediction target [<xref ref-type="bibr" rid="CR28">28</xref>, <xref ref-type="bibr" rid="CR29">29</xref>]. Thus, the KG-based prediction methods for DDIs are still at the infant stage.</p>
    <p id="Par22">Although these published methods have achieved some success in multi-type DDI prediction, there still exist some limitations. First, datasets of DDI types are extremely unbalanced, and these methods have poor performance in predicting rare types with fewer samples. Second, most methods perform well in predicting unknown DDI types between known drugs, but they often fail to do it for new drugs. It will be useful to develop the new methods to resolve the problems and further improve the prediction performance.</p>
    <p id="Par23">Since the labelled data is limited and expensive to obtain, contrastive learning has recently become a popular and powerful strategy to get quality representations of samples in a self-supervised way. It aims at embedding augmented versions of the same sample close to each other while trying to push away embeddings from different samples [<xref ref-type="bibr" rid="CR30">30</xref>]. Contrastive learning is not only used for self-supervised tasks, but also for supervised tasks. Khosla et al. extend the self-supervised batch contrastive approach to the fully-supervised setting, allowing models to effectively leverage label information [<xref ref-type="bibr" rid="CR31">31</xref>]. For supervised contrastive learning, the samples belonging to the same class are pulled together in embedding space, while simultaneously pushing apart samples from different classes [<xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR32">32</xref>].</p>
    <p id="Par24">Contrastive learning has been successfully applied in the field of bioinformatics [<xref ref-type="bibr" rid="CR33">33</xref>–<xref ref-type="bibr" rid="CR38">38</xref>]. In this study, we propose a new method named MDDI-SCL for multi-type DDI prediction, which is based on Supervised Contrastive Learning (SCL) and three-level loss functions. MDDI-SCL (Fig. <xref rid="Fig1" ref-type="fig">1</xref>) mainly includes three parts: drug feature encoder and mean squared error (MSE) loss module, drug latent feature fusion and supervised contrastive loss module, DDI type prediction and classification loss module. Specifically, we first input the drugs into the drug encoder to obtain the lower-dimensional latent features of each drug by MSE. Then, the latent features of two drugs are combined as input into the feature fusion module to obtain the latent features of the drug pairs. Supervised contrastive loss can make the features of the same type of DDIs more similar, and the features of DDIs from different types more different. Therefore, we can obtain features that are more powerful to classification by using contrastive loss in the feature fusion module. Finally, we input the latent features of each drug pair into the multi-type DDI prediction module to predict DDI types, and update the model parameters by the classification loss.<fig id="Fig1"><label>Fig. 1</label><caption><p>The overview of the proposed MDDI-SCL method. <bold>A</bold> Drug feature encode and MSE loss module. <bold>B</bold> Drug latent feature fusion and supervised contrastive loss module. <bold>C</bold> Multi-type DDIs prediction and classification loss module. <bold>D</bold> Multi-head Attention (ATT) module. <bold>E</bold> Dense layer module</p></caption><graphic xlink:href="13321_2022_659_Fig1_HTML" id="MO1"/></fig></p>
    <p id="Par25">Experimental results demonstrate that MDDI-SCL achieves better performance than several state-of-the-art methods on all three tasks of two different datasets. Additionly, we also proved the effectiveness of supervised contrastive learning for multi-type DDI prediction. More importantly, results of the case studies validated the feasibility of our method in practice.</p>
  </sec>
  <sec id="Sec2">
    <title>Materials and methods</title>
    <sec id="Sec3">
      <title>Datasets</title>
      <p id="Par26">In this study, we use two datasets with the number of samples at a different scale. The first dataset (Dataset1) is the benchmark dataset that Deng et al. collected [<xref ref-type="bibr" rid="CR20">20</xref>]. Dataset1 contains 572 drugs with 74, 528 pairwise DDIs, which are associated with 65 DDI types. Each drug in Dataset1 has four types of features: chemical substructures, targets, pathways and enzymes, which are extracted from DrugBank [<xref ref-type="bibr" rid="CR39">39</xref>]. The second dataset (Dataset2) is the dataset from the study of Lin et al. [<xref ref-type="bibr" rid="CR21">21</xref>]. Dataset2 contains 1, 258 drugs with 323, 539 pairwise DDIs, which are associated with 100 DDI types. Each drug in Dataset2 has three types of features: substructures, targets and enzymes.</p>
    </sec>
    <sec id="Sec4">
      <title>Drug feature representation</title>
      <p id="Par27">Each feature type of a drug corresponds to a set of descriptors, so one drug can be represented by a binary feature vector, and its value (1 or 0) indicates the presence or absence of the corresponding element.</p>
      <p id="Par28">These feature vectors have high dimensionality with values of most of dimensions being 0. Therefore, we represent the feature vector of a drug by the similarity profile, which is generated by the similarity of drug A against each one (i.e., drug B) in the rest of drugs in the dataset [<xref ref-type="bibr" rid="CR18">18</xref>]. Jaccard similarity is calculated by the following equation,<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathbf{J}\mathbf{a}\mathbf{c}\mathbf{c}\mathbf{a}\mathbf{r}\mathbf{d}\left(\mathbf{A},\mathbf{B}\right)=\frac{\left|\mathbf{A}\cap \mathbf{B}\right|}{\left|\mathbf{A}\cup \mathbf{B}\right|}=\frac{\left|\mathbf{A}\cap \mathbf{B}\right|}{\left|\mathbf{A}\right|+\left|\mathbf{B}\right|-\left|\mathbf{A}\cap \mathbf{B}\right|}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mrow><mml:mi mathvariant="bold">J</mml:mi><mml:mi mathvariant="bold">a</mml:mi><mml:mi mathvariant="bold">c</mml:mi><mml:mi mathvariant="bold">c</mml:mi><mml:mi mathvariant="bold">a</mml:mi><mml:mi mathvariant="bold">r</mml:mi><mml:mi mathvariant="bold">d</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="bold">A</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">B</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mfenced close="|" open="|"><mml:mi mathvariant="bold">A</mml:mi><mml:mo>∩</mml:mo><mml:mi mathvariant="bold">B</mml:mi></mml:mfenced><mml:mfenced close="|" open="|"><mml:mi mathvariant="bold">A</mml:mi><mml:mo>∪</mml:mo><mml:mi mathvariant="bold">B</mml:mi></mml:mfenced></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mfenced close="|" open="|"><mml:mi mathvariant="bold">A</mml:mi><mml:mo>∩</mml:mo><mml:mi mathvariant="bold">B</mml:mi></mml:mfenced><mml:mrow><mml:mfenced close="|" open="|"><mml:mi mathvariant="bold">A</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:mfenced close="|" open="|"><mml:mi mathvariant="bold">B</mml:mi></mml:mfenced><mml:mo>-</mml:mo><mml:mfenced close="|" open="|"><mml:mi mathvariant="bold">A</mml:mi><mml:mo>∩</mml:mo><mml:mi mathvariant="bold">B</mml:mi></mml:mfenced></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="13321_2022_659_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where A and B are original bit vectors of two drugs; |A ∩ B| is the number of elements in the intersection of A and B; |A ∪ B| is the number of elements in the union of A and B.</p>
      <p id="Par29">Based on the Jaccard similarity, in Dataset1, each type feature of a drug is represented as a 572-dimensional vector. Therefore, each drug with four type of features is represented by a 4*572-dimentional vector. In the similar way, each drug is represented as a 3*1258-dimensional vector in Dataset2.</p>
    </sec>
    <sec id="Sec5">
      <title>Drug feature encoder and mean squared error loss</title>
      <p id="Par30">The drug feature encoder module mainly includes multi-head self-attention layers and an autoencoder. The multi-head self-attention layers can focus on more important drug features [<xref ref-type="bibr" rid="CR40">40</xref>, <xref ref-type="bibr" rid="CR41">41</xref>], and further the autoencoder performs feature dimensionality reduction [<xref ref-type="bibr" rid="CR42">42</xref>, <xref ref-type="bibr" rid="CR43">43</xref>]. Consequently, lower-dimensional and better drug representations can be obtained through the drug feature encoder module. We use mean squared error loss to update the parameters of the feature encoder module.</p>
      <sec id="Sec6">
        <title>Multi-head self-attention mechanism and autoencoder</title>
        <p id="Par31">The detailed description of the multi-head self-attention mechanism and autoencoder is provided in the Additional file <xref rid="MOESM1" ref-type="media">1</xref> [<xref ref-type="bibr" rid="CR41">41</xref>]. In the model, the hidden features obtained through the multi-head self-attention layers are denoted as DA1 and DB1 for a pair of drugs (i.e., drug A and drug B), as shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>A. The encoder of autoencoder has two linear layers. The output vectors of the first linear layer are denoted as DA2 and DB2, and the output vectors of the second linear layer are denoted as DA3 and DB3.</p>
      </sec>
      <sec id="Sec7">
        <title>Mean squared error</title>
        <p id="Par32">Mean squared error is commonly used as regression loss function, which calculates average squared difference between the observed and predicted values. In our model, MSE is the sum of squared distances between the drug feature vector and the output vector of decoder divided by the feature dimensionality. The MSE is calculated by following formula,<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{MSE}=\frac{\sum_{\mathrm{i}=1}^{\mathrm{fea}\_\mathrm{dim}}{({\mathrm{val}}_{\mathrm{i}}-{\mathrm{val}}_{\mathrm{i}}^{\sim })}^{2}}{\mathrm{fea}\_\mathrm{dim}}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:mrow><mml:mi mathvariant="normal">MSE</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">fea</mml:mi><mml:mi>_</mml:mi><mml:mi mathvariant="normal">dim</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">val</mml:mi><mml:mi mathvariant="normal">i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msubsup><mml:mi mathvariant="normal">val</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi></mml:mrow><mml:mo>∼</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mi mathvariant="normal">fea</mml:mi><mml:mi>_</mml:mi><mml:mi mathvariant="normal">dim</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="13321_2022_659_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <italic>fea_dim</italic> is the feature dimensionality of the drug, <italic>val</italic><sub><italic>i</italic></sub> is the value of each dimension of the drug feature vector, <italic>val</italic><sub><italic>i</italic></sub><sup>~</sup> is the value of each dimension of the output vector of the decoder.</p>
      </sec>
    </sec>
    <sec id="Sec8">
      <title>Drug latent feature fusion and supervised contrastive loss</title>
      <p id="Par33">The drug latent feature fusion module mainly includes two sub-modules: multi-scale feature fusion and latent feature dimensionality reduction. The multi-scale feature fusion sub-module can simultaneously combine the low-level features and high-level features of a drug pair, and the feature dimensionality reduction sub-module can further fuse latent features and reduce the feature dimensionality. The supervised contrastive learning loss function is utilized to update the parameters of the drug latent feature fusion module.</p>
      <sec id="Sec9">
        <title>Multi-scale feature fusion sub-module</title>
        <p id="Par34">A drug pair contains two drugs (i.e., drug A and drug B). Through the drug feature encoder module, three latent features of drug A are obtained: DA1, DA2, and DA3, as shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>A. Similarly, we can acquire three latent features of drug B: DB1, DB2, and DB3. DA1 and DB1 are low-level features, which usually contain more detailed information but also more noise [<xref ref-type="bibr" rid="CR44">44</xref>, <xref ref-type="bibr" rid="CR45">45</xref>]. DA3 and DB3 are high-level features. Normally, high-level features have more semantic information and less noise but lose a lot of detailed information [<xref ref-type="bibr" rid="CR45">45</xref>–<xref ref-type="bibr" rid="CR48">48</xref>]. Thus, in order to better integrate the advantages of low-level features and high-level features, we concatenate DA1 and DB3, DA2 and DB2, DA3 and DB1 to represent a drug pair, respectively. Then, we input the concatenated features into the fully connected layer to obtain the fused drug pair features FD1, FD2, and FD3, as shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>B.</p>
      </sec>
      <sec id="Sec10">
        <title>Latent feature dimension reduction sub-module</title>
        <p id="Par35">When the neural network becomes deep, residual connection can be used to avoid the problem of vanishing gradient [ <xref ref-type="bibr" rid="CR49">49</xref> ]. In this sub-module, the output (DA3 and DB3) of encoder and the output (FD1, FD2 and FD3) of multi-scale feature fusion sub-module are concatenated as input into the latent feature dimensionality reduction sub-module, which mainly includes multi-head self-attention layers and linear layers. The number of neurons for each linear layer is half of the former layer. Multi-head self-attention has been introduced in detail in “Multi-head self-attention mechanism and autoencoder” section.  The output vector of latent feature dimensionality reduction sub-module is named CFV, as shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>B.</p>
      </sec>
      <sec id="Sec11">
        <title>Supervised contrastive loss</title>
        <p id="Par36">Contrastive learning includes unsupervised contrastive learning and supervised contrastive learning. The latent features of samples obtained by unsupervised contrastive learning have the following property: the features of samples from the same source are more similar, whereas the features of samples from different sources are more different [<xref ref-type="bibr" rid="CR50">50</xref>]. However, one significant disadvantage of unsupervised contrastive learning is that it does not consider the correlation of features between samples from different sources yet belonging to the same class. To overcome this drawback of unsupervised contrastive learning, supervised contrastive learning is proposed. The latent features of samples obtained by supervised contrastive learning have the following property: the features of samples belonging to same type are more similar, while the features of samples of different types are more different [<xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR51">51</xref>].</p>
        <p id="Par37">Considering that the DDI type prediction task is a multi-class classification task, supervised contrastive learning is more competent for this task. Accordingly, our model employs supervised contrastive learning. The loss function of supervised comparative learning in our model can be calculated by the following formula,<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\varvec{l}}}^{{\varvec{c}}{\varvec{o}}{\varvec{n}}}=\frac{1}{{{\varvec{N}}}_{{\varvec{b}}{\varvec{a}}{\varvec{t}}{\varvec{c}}{\varvec{h}}{\varvec{s}}{\varvec{i}}{\varvec{z}}{\varvec{e}}}}\sum_{{\varvec{i}}=1}^{{{\varvec{N}}}_{{\varvec{b}}{\varvec{a}}{\varvec{t}}{\varvec{c}}{\varvec{h}}{\varvec{s}}{\varvec{i}}{\varvec{z}}{\varvec{e}}}}{{\varvec{l}}}_{{\varvec{i}}}^{{\varvec{c}}{\varvec{o}}{\varvec{n}}}$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">n</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:munderover><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">n</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math><graphic xlink:href="13321_2022_659_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula><disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\varvec{l}}}_{{\varvec{i}}}^{{\varvec{c}}{\varvec{o}}{\varvec{n}}}=\frac{-1}{{{\varvec{N}}}_{{{\varvec{y}}}_{{\varvec{i}}}}-1}\sum_{{\varvec{j}}=1,{\varvec{j}}\ne {\varvec{i}},{{\varvec{y}}}_{{\varvec{j}}}={{\varvec{y}}}_{{\varvec{i}}}}^{{{\varvec{N}}}_{{\varvec{b}}{\varvec{a}}{\varvec{t}}{\varvec{c}}{\varvec{h}}{\varvec{s}}{\varvec{i}}{\varvec{z}}{\varvec{e}}}}{\varvec{l}}{\varvec{o}}{\varvec{g}}\frac{{\varvec{e}}{\varvec{x}}{\varvec{p}}({\varvec{s}}{\varvec{i}}{\varvec{m}}({{\varvec{C}}{\varvec{F}}{\varvec{V}}}_{{\varvec{i}} },{{\varvec{C}}{\varvec{F}}{\varvec{V}}}_{{\varvec{j}}})/{\varvec{\tau}})}{\sum_{{\varvec{k}}=1,{\varvec{k}}\ne {\varvec{i}}}^{{{\varvec{N}}}_{{\varvec{b}}{\varvec{a}}{\varvec{t}}{\varvec{c}}{\varvec{h}}{\varvec{s}}{\varvec{i}}{\varvec{z}}{\varvec{e}}}}{\varvec{e}}{\varvec{x}}{\varvec{p}}({\varvec{s}}{\varvec{i}}{\varvec{m}}({{\varvec{C}}{\varvec{F}}{\varvec{V}}}_{{\varvec{i}}} , {{\varvec{C}}{\varvec{F}}{\varvec{V}}}_{{\varvec{k}}})/{\varvec{\tau}})}$$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">n</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:msub><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mo>≠</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:munderover><mml:mrow><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi></mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">/</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">τ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">k</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">k</mml:mi></mml:mrow><mml:mo>≠</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">a</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">z</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">m</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">/</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">τ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math><graphic xlink:href="13321_2022_659_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <italic>N</italic><sub><italic>batchsize</italic></sub> is the number of samples in each batch, <italic>y</italic><sub><italic>i</italic></sub> is the class label of sample <italic>i</italic>, and <italic>y</italic><sub><italic>j</italic></sub> is the class label of sample <italic>j</italic>. <italic>N</italic><sub><italic>yi</italic></sub> is the number of samples of class <italic>y</italic><sub><italic>i</italic></sub> in the same batch. <italic>sim</italic> is a function that measures the similarity of two vectors, such as cosine similarity. <italic>CFV</italic><sub><italic>i</italic></sub><italic>, CFV</italic><sub><italic>j</italic></sub><italic>, CFV</italic><sub><italic>k</italic></sub> are the latent feature vector, which are the output vector of latent feature dimensionality reduction sub-module of sample <italic>i</italic>, <italic>j</italic>, and <italic>k</italic>, respectively. <italic>τ ∈ R</italic><sup>+</sup> is a scalar temperature parameter. According to the above formulas, in order to make the <italic>l</italic><sub><italic>i</italic></sub><sup><italic>con</italic></sup> loss smaller, the value of <italic>sim(CFV</italic><sub><italic>i,</italic></sub><italic> CFV</italic><sub><italic>j</italic></sub><italic>)</italic> will be larger. So the hidden vectors <italic>CFV</italic><sub><italic>i</italic></sub> and <italic>CFV</italic><sub><italic>j</italic></sub> must be more similar. <italic>CFV</italic><sub><italic>i</italic></sub> and <italic>CFV</italic><sub><italic>j</italic></sub> are the latent vectors of the same type samples, so the latent features of the same type samples are more similar.</p>
      </sec>
    </sec>
    <sec id="Sec12">
      <title>Multi-type DDI prediction and classification loss</title>
      <p id="Par38">The module employs two fully connected layers to predict DDI types, and the number of neurons in the second fully connected layer is the number of DDI types. DDI type prediction is a multi-class classification task, and the sample size of each class is not balanced. Since focal loss can partially solve the problem of sample imbalance [<xref ref-type="bibr" rid="CR21">21</xref>], we use focal loss [<xref ref-type="bibr" rid="CR52">52</xref>] and cross-entropy loss as our classification loss functions. In detail, we choose the cross-entropy loss as our classification loss function in the first one third of training steps, and apply focal loss as our classification loss function in the last two thirds of steps. Therefore, the total loss function of the model is as follows:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{Loss}={\mathrm{l}}_{\mathrm{MSE}}(\mathrm{x},{\mathrm{x}}^{\sim })+{\mathrm{l}}_{\mathrm{con}}(\mathrm{CFV},\mathrm{y})+{\mathrm{l}}_{\mathrm{cla}}(\mathrm{y},{\mathrm{y}}^{\sim })$$\end{document}</tex-math><mml:math id="M10" display="block"><mml:mrow><mml:mi mathvariant="normal">Loss</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">MSE</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mo>∼</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">con</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">CFV</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">cla</mml:mi></mml:msub><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">y</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">y</mml:mi></mml:mrow><mml:mo>∼</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math><graphic xlink:href="13321_2022_659_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>
, where <italic>x</italic> is the feature vector of the drug pair, <italic>x</italic> ~ is the output vector of the decoder, <italic>CFV</italic> is the output vector of latent feature dimensionality reduction sub-module, <italic>y</italic> is the class label of sample, and <italic>y</italic> ~ is the predicted value of sample. <italic>l</italic><sub><italic>MSE</italic></sub> is MSE loss function, <italic>l</italic><sub><italic>con</italic></sub> is supervised contrastive learning loss function and <italic>l</italic><sub><italic>cla</italic></sub> is classification loss function. <italic>l</italic><sub><italic>cla</italic></sub> is composed of the cross-entropy loss in the first one third of training steps and focal loss in the last two thirds of steps.</p>
      <p id="Par39">In order to prevent over-fitting, the label smoothing strategy is implemented [<xref ref-type="bibr" rid="CR53">53</xref>]. For multi-classification problems, the class label vector is often converted into one-hot vector. However, the one-hot vector may weaken the generalization ability of the model and result in over-fitting. Label smoothing uses the smoothing parameter to add noise to the one-hot encoding, making the model less confident about its predictions. Therefore, it can partially solve the problem of over-fitting.</p>
      <p id="Par40">We utilize Gaussian error linear unit activation function and Radam optimizer [<xref ref-type="bibr" rid="CR54">54</xref>]. The dropout layer and batch normalization layer are placed between the fully connected layers [<xref ref-type="bibr" rid="CR55">55</xref>].</p>
    </sec>
  </sec>
  <sec id="Sec13">
    <title>Results and discussion</title>
    <sec id="Sec14">
      <title>Experimental settings of prediction tasks</title>
      <p id="Par41">This study evaluated the multi-type DDI prediction tasks based on three experimental settings: (i) prediction of unobserved interaction types between known drugs (Task1); (ii) prediction of interaction types between known drugs and new drugs (Task2) and (iii) prediction of interaction types between new drugs (Task3). New drugs in the corresponding task are missing in the training set, but exist in the test set.</p>
      <p id="Par42">For Task1, we apply five-fold cross-validation (5-CV) to DDI types and split all DDI types into five subsets. We train models based on DDI types in the training set, and then make predictions for DDI types in the test set. For Task2 and Task3, we apply 5-CV to drugs instead of DDI types. We randomly split drugs into five subsets, and used four of them as training drugs, leaving the remaining one as test drugs. For Task2, prediction models are constructed on the DDI types between two training drugs, and then make predictions for DDI types between training drugs and test drugs. For Task3, prediction models are built on the DDI types between two drugs in the training set to predict for DDI types between two drugs in the test set.</p>
      <p id="Par43">For model evaluation, accuracy (ACC), area under the precision-recall-curve (AUPR), area under the ROC curve (AUC), F1 score, precision and recall are adopted as evaluation metrics. On highly imbalanced data sets, AUPR and F1 score metrics are more objective for model evaluation. Consequently, in the following discussion, we will focus on these two metrics.</p>
    </sec>
    <sec id="Sec15">
      <title>Hyper-parameters setting</title>
      <p id="Par44">The chosen of hyper-parameters influences the performance of model. First, we discussed the settings of  six hyper-parameters on affecting the prediction performance on Task2 of Dataset1: smoothing parameter in the label smoothing strategy, temperature parameter in the contrastive learning, learning rate, batch size, training epochs and the epoch to change the cross-entropy loss to focal loss. Task1 is a relatively simple task, while Task3 is a relatively difficult task. Thus, to ensure the versatility of the hyper-parameters, we chose Task2 to tune the hyper-parameters. For Task1 and Task3, we used the optimal parameters tuned on Task2. The performance metrics under different settings are shown in Fig. <xref rid="Fig2" ref-type="fig">2</xref>.<fig id="Fig2"><label>Fig. 2</label><caption><p>The prediction performance of six hyper-parameters settings on Task2 of Dataset1</p></caption><graphic xlink:href="13321_2022_659_Fig2_HTML" id="MO2"/></fig></p>
      <p id="Par45">According to Fig. <xref rid="Fig2" ref-type="fig">2</xref>, the performance of the model does not change drastically as the hyper-parameters change. Almost all metric scores vary within the range of 0.01. This also illustrates the stability of our model. In the end, we chose 0.3 for smoothing parameter, 0.05 for temperature parameter, 2e-5 for learning rate, 512 for batch size, 120 for training epochs and the 40<sup>th</sup> epoch to change the cross-entropy loss to focal loss.</p>
    </sec>
    <sec id="Sec16">
      <title>The prediction effect of multi-scale feature fusion</title>
      <p id="Par46">In the drug latent feature fusion module, we tried three types of feature fusion methods. The first method is the single-scale feature fusion, which concatenates DA1 and DB1, DA2 and DB2, DA3 and DB3 as three assemblies. The second method is multi-scale feature fusion. Correspondingly, we concatenate DA1 and DB3, DA2 and DB2, DA3 and DB1 as three assemblies. The third method is to use only DA3 and DB3 without feature fusion. We compared these three feature fusion methods on three tasks of Dataset1, as shown in Fig. <xref rid="Fig3" ref-type="fig">3</xref>.<fig id="Fig3"><label>Fig. 3</label><caption><p>The prediction performance of different feature fusion methods on three tasks of Dataset1 </p></caption><graphic xlink:href="13321_2022_659_Fig3_HTML" id="MO3"/></fig></p>
      <p id="Par47">On three tasks, the AUPR and AUC of the multi-scale feature fusion method achieved the highest scores. In general, the performance of the multi-scale feature fusion method is slightly better than the other two methods. Therefore, multi-scale feature fusion is incorporated into the final model.</p>
    </sec>
    <sec id="Sec17">
      <title>The prediction effect of supervised contrastive learning</title>
      <p id="Par48">In order to verify the effectiveness of supervised contrastive learning, we compared the performance of the model with and without supervised contrastive learning on three tasks of Dataset1, as shown in Table <xref rid="Tab1" ref-type="table">1</xref>. The model with supervised contrastive learning achieved better performance in ACC, AUPR, and AUC on all three tasks. The AUPR of the model with supervised contrastive learning on Task2 is 0.6947 while the AUPR of the model without supervised contrastive learning on Task2 is 0.6765. The AUC of the model with supervised contrastive learning on Task3 is 0.0313 higher than that without supervised contrastive learning. In general, model with supervised contrastive learning achieves better prediction performance.<table-wrap id="Tab1"><label>Table 1</label><caption><p>The prediction effect of supervised contrastive learning on three tasks of Dataset1</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">ACC</th><th align="left">AUPR</th><th align="left">AUC</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th></tr></thead><tbody><tr><td align="left" colspan="7">Task1</td></tr><tr><td align="left"> With SCL</td><td align="left">0.9378</td><td align="left">0.9782</td><td align="left">0.9983</td><td align="left">0.8755</td><td align="left">0.8804</td><td align="left">0.8767</td></tr><tr><td align="left"> Without SCL</td><td align="left">0.9308</td><td align="left">0.9746</td><td align="left">0.9982</td><td align="left">0.8712</td><td align="left">0.8762</td><td align="left">0.8752</td></tr><tr><td align="left" colspan="7">Task2</td></tr><tr><td align="left"> With SCL</td><td align="left">0.6767</td><td align="left">0.6947</td><td align="left">0.9634</td><td align="left">0.5304</td><td align="left">0.6254</td><td align="left">0.4814</td></tr><tr><td align="left"> Without SCL</td><td align="left">0.6667</td><td align="left">0.6765</td><td align="left">0.9513</td><td align="left">0.5314</td><td align="left">0.5685</td><td align="left">0.5177</td></tr><tr><td align="left" colspan="7">Task3</td></tr><tr><td align="left"> With SCL</td><td align="left">0.4589</td><td align="left">0.3938</td><td align="left">0.9053</td><td align="left">0.1919</td><td align="left">0.2585</td><td align="left">0.1678</td></tr><tr><td align="left"> Without SCL</td><td align="left">0.4553</td><td align="left">0.3772</td><td align="left">0.8740</td><td align="left">0.2273</td><td align="left">0.2571</td><td align="left">0.2177</td></tr></tbody></table></table-wrap></p>
    </sec>
    <sec id="Sec18">
      <title>The prediction effect of focal loss</title>
      <p id="Par49">Focal loss can solve problems of imbalance in sample size of each category and difficulty of imbalanced classification. Focal loss improves the classification ability of the model by forcing the model to focus on categories with a small sample size. In order to examine whether focal loss improves the prediction for categories with small sample size, we selected 20 categories with the smallest sample size (from DDI type46 to DDI type65) on Task1 of Dataset1 for comparison, as shown in Fig. <xref rid="Fig4" ref-type="fig">4</xref>.<fig id="Fig4"><label>Fig. 4</label><caption><p>The F1 scores and AUPR scores of 20 categories with a small sample size with/without focal loss on Task1 of Dataset1</p></caption><graphic xlink:href="13321_2022_659_Fig4_HTML" id="MO4"/></fig></p>
      <p id="Par50">On categories with a small sample size, focal loss can boost the classification performance of the model. Among the 20 categories with a small sample size, the F1 score of the model with focal loss is higher than that of the model without focal loss on 19 categories. On DDI type 52, 63, and 64, the F1 score of the model without focal loss is 0, while the F1 score of the model with focal loss is 0.2222, 0.5, and 0.25, respectively. Among the 20 categories with a small sample size, the AUPR of the model with focal loss is higher than the AUPR of the model without focal loss on 16 categories. On DDI type 63, the AUPR of the model without focal loss is 0.0001, while the AUPR of the model with focal loss is 0.5334.</p>
    </sec>
    <sec id="Sec19">
      <title>The prediction effect of label smoothing strategy</title>
      <p id="Par51">We verified the effectiveness of the label smoothing strategy on three tasks of Dataset1. The experimental results are shown in Table <xref rid="Tab2" ref-type="table">2</xref>.<table-wrap id="Tab2"><label>Table 2</label><caption><p>The prediction effect of label smoothing (LS) strategy on three tasks of Dataset1</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">ACC</th><th align="left">AUPR</th><th align="left">AUC</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th></tr></thead><tbody><tr><td align="left" colspan="7">Task1</td></tr><tr><td align="left"> With LS</td><td align="left">0.9378</td><td align="left">0.9782</td><td align="left">0.9983</td><td align="left">0.8755</td><td align="left">0.8804</td><td align="left">0.8767</td></tr><tr><td align="left"> Without LS</td><td align="left">0.9377</td><td align="left">0.9776</td><td align="left">0.9981</td><td align="left">0.8840</td><td align="left">0.8718</td><td align="left">0.9023</td></tr><tr><td align="left" colspan="7">Task2</td></tr><tr><td align="left"> With LS</td><td align="left">0.6767</td><td align="left">0.6947</td><td align="left">0.9634</td><td align="left">0.5304</td><td align="left">0.6254</td><td align="left">0.4814</td></tr><tr><td align="left"> Without LS</td><td align="left">0.6659</td><td align="left">0.6705</td><td align="left">0.9470</td><td align="left">0.5120</td><td align="left">0.5275</td><td align="left">0.5243</td></tr><tr><td align="left" colspan="7">Task3</td></tr><tr><td align="left"> With LS</td><td align="left">0.4589</td><td align="left">0.3938</td><td align="left">0.9053</td><td align="left">0.1919</td><td align="left">0.2585</td><td align="left">0.1678</td></tr><tr><td align="left"> Without LS</td><td align="left">0.4449</td><td align="left">0.3636</td><td align="left">0.8723</td><td align="left">0.1971</td><td align="left">0.2022</td><td align="left">0.2063</td></tr></tbody></table></table-wrap></p>
      <p id="Par52">On all three tasks, the AUPR of the model using label smoothing is higher than that of the model which does not utilize label smoothing. The AUPR of the model using label smoothing on Task2 is 0.0242 higher than that without label smoothing. The AUPR of the model using label smoothing on Task3 is 0.0302 higher than that without label smoothing.</p>
    </sec>
    <sec id="Sec20">
      <title>Comparison with state-of-the-art DDI type prediction and baseline methods</title>
      <p id="Par53">We compared MDDI-SCL with other four state-of-the-art DDI type prediction methods: DeepDDI [<xref ref-type="bibr" rid="CR18">18</xref>], Lee et al.’s methods [<xref ref-type="bibr" rid="CR19">19</xref>], DDIMDL [<xref ref-type="bibr" rid="CR20">20</xref>] and MDF-SA-DDI [<xref ref-type="bibr" rid="CR21">21</xref>], and also several baseline classification methods: fully connected DNN, random forest (RF), k-nearest neighbor (KNN) and logistic regression (LR). The performance comparison of all prediction models on Dataset1 and Dataset2 is shown in Table <xref rid="Tab3" ref-type="table">3</xref> and Table <xref rid="Tab4" ref-type="table">4</xref>, respectively.<table-wrap id="Tab3"><label>Table 3</label><caption><p>Performance comparison with the state-of-the-art methods on three tasks of Dataset1</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">ACC</th><th align="left">AUPR</th><th align="left">AUC</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th></tr></thead><tbody><tr><td align="left" colspan="7">Task1</td></tr><tr><td align="left"> MDDI-SCL</td><td char="." align="char">0.9378</td><td char="." align="char">0.9782</td><td char="." align="char">0.9983</td><td char="." align="char">0.8755</td><td char="." align="char">0.8804</td><td char="." align="char">0.8767</td></tr><tr><td align="left"> MDF-SA-DDI</td><td char="." align="char">0.9301</td><td char="." align="char">0.9737</td><td char="." align="char">0.9989</td><td char="." align="char">0.8878</td><td char="." align="char">0.9085</td><td char="." align="char">0.8760</td></tr><tr><td align="left"> DDIMDL</td><td char="." align="char">0.8852</td><td char="." align="char">0.9208</td><td char="." align="char">0.9976</td><td char="." align="char">0.7585</td><td char="." align="char">0.8471</td><td char="." align="char">0.7182</td></tr><tr><td align="left"> Lee et al.'s methods</td><td char="." align="char">0.9094</td><td char="." align="char">0.9562</td><td char="." align="char">0.9961</td><td char="." align="char">0.8391</td><td char="." align="char">0.8509</td><td char="." align="char">0.8339</td></tr><tr><td align="left"> DeepDDI</td><td char="." align="char">0.8371</td><td char="." align="char">0.8899</td><td char="." align="char">0.9961</td><td char="." align="char">0.6848</td><td char="." align="char">0.7275</td><td char="." align="char">0.6611</td></tr><tr><td align="left"> DNN</td><td char="." align="char">0.8797</td><td char="." align="char">0.9134</td><td char="." align="char">0.9963</td><td char="." align="char">0.7223</td><td char="." align="char">0.8047</td><td char="." align="char">0.7027</td></tr><tr><td align="left"> RF</td><td char="." align="char">0.7775</td><td char="." align="char">0.8349</td><td char="." align="char">0.9956</td><td char="." align="char">0.5936</td><td char="." align="char">0.7893</td><td char="." align="char">0.5161</td></tr><tr><td align="left"> KNN</td><td char="." align="char">0.7214</td><td char="." align="char">0.7716</td><td char="." align="char">0.9813</td><td char="." align="char">0.4831</td><td char="." align="char">0.7174</td><td char="." align="char">0.4081</td></tr><tr><td align="left"> LR</td><td char="." align="char">0.7920</td><td char="." align="char">0.8400</td><td char="." align="char">0.9960</td><td char="." align="char">0.5948</td><td char="." align="char">0.7437</td><td char="." align="char">0.5236</td></tr><tr><td align="left" colspan="7">Task2</td></tr><tr><td align="left"> MDDI-SCL</td><td char="." align="char">0.6767</td><td char="." align="char">0.6947</td><td char="." align="char">0.9634</td><td char="." align="char">0.5304</td><td char="." align="char">0.6254</td><td char="." align="char">0.4814</td></tr><tr><td align="left"> MDF-SA-DDI</td><td char="." align="char">0.6633</td><td char="." align="char">0.6776</td><td char="." align="char">0.9497</td><td char="." align="char">0.5584</td><td char="." align="char">0.6547</td><td char="." align="char">0.5078</td></tr><tr><td align="left"> DDIMDL</td><td char="." align="char">0.6415</td><td char="." align="char">0.6558</td><td char="." align="char">0.9799</td><td char="." align="char">0.4460</td><td char="." align="char">0.5607</td><td char="." align="char">0.4319</td></tr><tr><td align="left"> Lee et al.'s methods</td><td char="." align="char">0.6405</td><td char="." align="char">0.6244</td><td char="." align="char">0.9247</td><td char="." align="char">0.5039</td><td char="." align="char">0.5388</td><td char="." align="char">0.4891</td></tr><tr><td align="left"> DeepDDI</td><td char="." align="char">0.5774</td><td char="." align="char">0.5594</td><td char="." align="char">0.9575</td><td char="." align="char">0.3416</td><td char="." align="char">0.3630</td><td char="." align="char">0.3890</td></tr><tr><td align="left"> DNN</td><td char="." align="char">0.6239</td><td char="." align="char">0.6361</td><td char="." align="char">0.9796</td><td char="." align="char">0.2997</td><td char="." align="char">0.4237</td><td char="." align="char">0.2840</td></tr><tr><td align="left" colspan="7">Task3</td></tr><tr><td align="left"> MDDI-SCL</td><td char="." align="char">0.4589</td><td char="." align="char">0.3938</td><td char="." align="char">0.9053</td><td char="." align="char">0.1919</td><td char="." align="char">0.2585</td><td char="." align="char">0.1678</td></tr><tr><td align="left"> MDF-SA-DDI</td><td char="." align="char">0.4338</td><td char="." align="char">0.3873</td><td char="." align="char">0.8630</td><td char="." align="char">0.2329</td><td char="." align="char">0.2715</td><td char="." align="char">0.2226</td></tr><tr><td align="left"> DDIMDL</td><td char="." align="char">0.4075</td><td char="." align="char">0.3635</td><td char="." align="char">0.9512</td><td char="." align="char">0.1590</td><td char="." align="char">0.2408</td><td char="." align="char">0.1452</td></tr><tr><td align="left"> Lee et al.'s methods</td><td char="." align="char">0.4097</td><td char="." align="char">0.3184</td><td char="." align="char">0.8302</td><td char="." align="char">0.2022</td><td char="." align="char">0.2216</td><td char="." align="char">0.2027</td></tr><tr><td align="left"> DeepDDI</td><td char="." align="char">0.3602</td><td char="." align="char">0.2781</td><td char="." align="char">0.9059</td><td char="." align="char">0.1373</td><td char="." align="char">0.1586</td><td char="." align="char">0.1450</td></tr><tr><td align="left"> DNN</td><td char="." align="char">0.4087</td><td char="." align="char">0.3776</td><td char="." align="char">0.9550</td><td char="." align="char">0.1152</td><td char="." align="char">0.1836</td><td char="." align="char">0.1093</td></tr></tbody></table></table-wrap><table-wrap id="Tab4"><label>Table 4</label><caption><p>Performance comparison with the state-of-the-art methods on three tasks of Dataset2</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">ACC</th><th align="left">AUPR</th><th align="left">AUC</th><th align="left">F1</th><th align="left">Precision</th><th align="left">Recall</th></tr></thead><tbody><tr><td align="left" colspan="7">Task1</td></tr><tr><td align="left"> MDDI-SCL</td><td char="." align="char">0.9516</td><td char="." align="char">0.9862</td><td char="." align="char">0.9995</td><td char="." align="char">0.9321</td><td char="." align="char">0.9162</td><td char="." align="char">0.9500</td></tr><tr><td align="left"> MDF-SA-DDI</td><td char="." align="char">0.9291</td><td char="." align="char">0.9773</td><td char="." align="char">0.9996</td><td char="." align="char">0.9117</td><td char="." align="char">0.9381</td><td char="." align="char">0.8910</td></tr><tr><td align="left"> DDIMDL</td><td char="." align="char">0.9229</td><td char="." align="char">0.9637</td><td char="." align="char">0.9993</td><td char="." align="char">0.9105</td><td char="." align="char">0.9212</td><td char="." align="char">0.9039</td></tr><tr><td align="left"> Lee et al.'s methods</td><td char="." align="char">0.9370</td><td char="." align="char">0.9791</td><td char="." align="char">0.9991</td><td char="." align="char">0.9181</td><td char="." align="char">0.9226</td><td char="." align="char">0.9153</td></tr><tr><td align="left"> DeepDDI</td><td char="." align="char">0.7211</td><td char="." align="char">0.7724</td><td char="." align="char">0.9914</td><td char="." align="char">0.6854</td><td char="." align="char">0.6654</td><td char="." align="char">0.7183</td></tr><tr><td align="left"> DNN</td><td char="." align="char">0.7908</td><td char="." align="char">0.8539</td><td char="." align="char">0.9949</td><td char="." align="char">0.7649</td><td char="." align="char">0.7560</td><td char="." align="char">0.8046</td></tr><tr><td align="left"> RF</td><td char="." align="char">0.6956</td><td char="." align="char">0.7567</td><td char="." align="char">0.9892</td><td char="." align="char">0.5760</td><td char="." align="char">0.6694</td><td char="." align="char">0.5426</td></tr><tr><td align="left"> KNN</td><td char="." align="char">0.5797</td><td char="." align="char">0.5964</td><td char="." align="char">0.8998</td><td char="." align="char">0.3805</td><td char="." align="char">0.4758</td><td char="." align="char">0.3347</td></tr><tr><td align="left"> LR</td><td char="." align="char">0.5229</td><td char="." align="char">0.5288</td><td char="." align="char">0.9805</td><td char="." align="char">0.2373</td><td char="." align="char">0.3128</td><td char="." align="char">0.2185</td></tr><tr><td align="left" colspan="7">Task2</td></tr><tr><td align="left"> MDDI-SCL</td><td char="." align="char">0.6595</td><td char="." align="char">0.6794</td><td char="." align="char">0.9757</td><td char="." align="char">0.5578</td><td char="." align="char">0.5605</td><td char="." align="char">0.5712</td></tr><tr><td align="left"> MDF-SA-DDI</td><td char="." align="char">0.6664</td><td char="." align="char">0.6820</td><td char="." align="char">0.9862</td><td char="." align="char">0.5919</td><td char="." align="char">0.6526</td><td char="." align="char">0.5518</td></tr><tr><td align="left"> DDIMDL</td><td char="." align="char">0.6720</td><td char="." align="char">0.7086</td><td char="." align="char">0.9885</td><td char="." align="char">0.5817</td><td char="." align="char">0.6680</td><td char="." align="char">0.5295</td></tr><tr><td align="left"> Lee et al.'s methods</td><td char="." align="char">0.6917</td><td char="." align="char">0.7119</td><td char="." align="char">0.9687</td><td char="." align="char">0.5934</td><td char="." align="char">0.6144</td><td char="." align="char">0.5848</td></tr><tr><td align="left"> DeepDDI</td><td char="." align="char">0.5883</td><td char="." align="char">0.5851</td><td char="." align="char">0.9746</td><td char="." align="char">0.4709</td><td char="." align="char">0.5250</td><td char="." align="char">0.4361</td></tr><tr><td align="left"> DNN</td><td char="." align="char">0.6687</td><td char="." align="char">0.6838</td><td char="." align="char">0.9818</td><td char="." align="char">0.6164</td><td char="." align="char">0.7279</td><td char="." align="char">0.5479</td></tr><tr><td align="left" colspan="7">Task3</td></tr><tr><td align="left"> MDDI-SCL</td><td char="." align="char">0.4696</td><td char="." align="char">0.4261</td><td char="." align="char">0.9315</td><td char="." align="char">0.2838</td><td char="." align="char">0.3160</td><td char="." align="char">0.2773</td></tr><tr><td align="left"> MDF-SA-DDI</td><td char="." align="char">0.4794</td><td char="." align="char">0.4450</td><td char="." align="char">0.9686</td><td char="." align="char">0.2937</td><td char="." align="char">0.3667</td><td char="." align="char">0.2659</td></tr><tr><td align="left"> DDIMDL</td><td char="." align="char">0.4699</td><td char="." align="char">0.4386</td><td char="." align="char">0.9685</td><td char="." align="char">0.3032</td><td char="." align="char">0.3773</td><td char="." align="char">0.2729</td></tr><tr><td align="left"> Lee et al.'s methods</td><td char="." align="char">0.4867</td><td char="." align="char">0.4349</td><td char="." align="char">0.9093</td><td char="." align="char">0.3082</td><td char="." align="char">0.3355</td><td char="." align="char">0.3066</td></tr><tr><td align="left"> DeepDDI</td><td char="." align="char">0.3611</td><td char="." align="char">0.2820</td><td char="." align="char">0.9264</td><td char="." align="char">0.1868</td><td char="." align="char">0.2301</td><td char="." align="char">0.1711</td></tr><tr><td align="left"> DNN</td><td char="." align="char">0.4570</td><td char="." align="char">0.4129</td><td char="." align="char">0.9565</td><td char="." align="char">0.2997</td><td char="." align="char">0.4345</td><td char="." align="char">0.2508</td></tr></tbody></table></table-wrap></p>
      <p id="Par54">We evaluated the performance of all prediction methods for Task1. Experimental results show that MDDI-SCL and MDF-SA-DDI perform much better than other methods on Task1 on Dataset1. MDDI-SCL achieves the best AUPR 0.9782. On Dataset2, the performance of MDDI-SCL is better than other methods. The AUPR, F1 score and ACC of MDDI-SCL is 0.9862, 0.9321 and 0.9516, respectively. These evaluation scores of MDDI-SCL are higher than that of other methods.</p>
      <p id="Par55">We also compared the state-of-the-art methods on Task2 and Task3 of the two datasets. Experimental results show that our method MDDI-SCL achieves better or comparable performance than the state-of-the-art methods on some evaluation metrics. On Dataset1, the AUPR of MDDI-SCL is 0.6947 and 0.3938 on Task2 and Task3, respectively. The AUC of MDDI-SCL is 0.6767 and 0.4589 on Task2 and Task3, respectively. These evaluation scores of MDDI-SCL are higher than that of other methods. The F1 score of MDDI-SCL is slightly worse than the state-of-the-art methods. It should be emphasized that we used the same hyper-parameters on different tasks and different datasets. We did not optimize the hyper-parameters of the model across all the datasets and tasks. The hyper-parameters of the deep learning model may affect the performance of the model, so the experimental results presented here may not be the optimal performance of our model.</p>
      <p id="Par56">In general, our model achieves better or similar performance on Task1 of both datasets compared to the state-of-the-art methods. Our model also achieves better or similar performance as the state-of-the-art methods on Task2 and Task3 of Dataset1. Our model performs slightly worse than the state-of-the-art models on Task2 and Task3 of Dataset2. This may be explained by the fact that the hyper-parameters of our model are obtained on Dataset1. Inappropriate hyper-parameters may affect the performance of the model.</p>
    </sec>
    <sec id="Sec21">
      <title>Case studies</title>
      <p id="Par57">The evaluation metrics have proved the effectiveness of our model. We conducted case studies to further validate the effectiveness of MDDI-SCL in practice.</p>
      <p id="Par58">We used all the DDI type samples on Dataset1 originally obtained from DrugBank [<xref ref-type="bibr" rid="CR17">17</xref>] to train the prediction model, and then predicted the drug-drug pairs that do not exist on Dataset1. We focused on the five most frequent DDI types and checked up the top 20 predictions related to each type. We used the interactions checker tool provided by <ext-link ext-link-type="uri" xlink:href="https://go.drugbank.com/drugs">https://go.drugbank.com/drugs</ext-link> to verify these predictions.</p>
      <p id="Par59">Among 100 samples, 43 DDI type samples were confirmed, which are shown in Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S1. For example, the interaction between Donepezil and Armodafinil is predicted to cause the DDI type #0, which means that metabolism of Donepezil can be decreased when combined with Armodafinil.</p>
      <p id="Par60">Under the same experimental setup, 43 of the 100 DDI samples predicted by MDDI-SCL were confirmed, whereas 35 of the 100 DDI samples predicted by MDF-SA-DDI were confirmed. This shows that MDDI-SCL is more effective than MDF-SA-DDI in practice. In Additional file <xref rid="MOESM1" ref-type="media">1</xref>: Table S2, we list the other 57 drug pairs among the 100 DDI samples. These drug pairs may not be reported in the literature, but these DDIs are likely to occur when taken together, which may be helpful for pharmaceutical research.</p>
    </sec>
  </sec>
  <sec id="Sec22">
    <title>Conclusions</title>
    <p id="Par61">We proposed a multi-type DDI prediction model based on supervised contrastive learning and three-level loss functions, and proved the effectiveness and robustness of our model. In addition, we also proved the prediction effect of supervised contrastive learning, focal loss and label smoothing strategy. Experimental results demonstrate that our proposed model achieves better or comparable performance than that of the state-of-the-art models. The case studies were also performed to identify the new DDIs which are not included in the current datasets. Moreover, the effectiveness of our model is supported by case studies in practice.
</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary Information</title>
    <sec id="Sec23">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="13321_2022_659_MOESM1_ESM.pdf">
            <caption>
              <p><bold>Additional file 1</bold><bold>: </bold><bold>Table S1.</bold> Forty-three DDI samples have been confirmed among the 100 DDI samples predicted by MDDI-SCL. <bold>Table S2.</bold> Fifty-seven DDI samples that may not be reported in the literature among the 100 DDI samples predicted by MDDI-SCL.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>DDIs</term>
        <def>
          <p id="Par2">Drug-drug interactions</p>
        </def>
      </def-item>
      <def-item>
        <term>ADEs</term>
        <def>
          <p id="Par3">Adverse drug events</p>
        </def>
      </def-item>
      <def-item>
        <term>NLP</term>
        <def>
          <p id="Par4">Natural language processing</p>
        </def>
      </def-item>
      <def-item>
        <term>DNN</term>
        <def>
          <p id="Par5">Deep neural network</p>
        </def>
      </def-item>
      <def-item>
        <term>KGs</term>
        <def>
          <p id="Par6">Knowledge graphs</p>
        </def>
      </def-item>
      <def-item>
        <term>GNNs</term>
        <def>
          <p id="Par7">Graph neural networks</p>
        </def>
      </def-item>
      <def-item>
        <term>SCL</term>
        <def>
          <p id="Par8">Supervised contrastive learning</p>
        </def>
      </def-item>
      <def-item>
        <term>MSE</term>
        <def>
          <p id="Par9">Mean squared error</p>
        </def>
      </def-item>
      <def-item>
        <term>ATT</term>
        <def>
          <p id="Par10">Attention</p>
        </def>
      </def-item>
      <def-item>
        <term>ACC</term>
        <def>
          <p id="Par11">Accuracy</p>
        </def>
      </def-item>
      <def-item>
        <term>AUPR</term>
        <def>
          <p id="Par12">Area under the precision-recall-curve</p>
        </def>
      </def-item>
      <def-item>
        <term>AUC</term>
        <def>
          <p id="Par13">Area under the ROC curve</p>
        </def>
      </def-item>
      <def-item>
        <term>LS</term>
        <def>
          <p id="Par14">Label smoothing</p>
        </def>
      </def-item>
      <def-item>
        <term>RF</term>
        <def>
          <p id="Par15">Random forest</p>
        </def>
      </def-item>
      <def-item>
        <term>KNN</term>
        <def>
          <p id="Par16">K-nearest neighbor</p>
        </def>
      </def-item>
      <def-item>
        <term>LR</term>
        <def>
          <p id="Par17">Logistic regression</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher's Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <ack>
    <title>Acknowledgements</title>
    <p>Not applicable.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Author contributions</title>
    <p>SL: conceptualization and design, data acquisition and analysis, methodology and writing—original draft. WC: validation. GC: investigation and visualization. SZ: writing—review editing and visualization. YX: writing-review, editing and project administration. YX and D-QW: funding acquisition. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>This work is supported by grants from the National Science Foundation of China (Grant Nos. 62172274, 32070662, 61832019, 32030063), the Science and Technology Commission of Shanghai Municipality (Grant No. 19430750600), as well as Joint Research Fund for Medical and Engineering and Scientific Research at Shanghai Jiao Tong University (Grant Nos. YG2021ZD02, YG2019GD01, YG2019ZDA12).</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>The source codes are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/ShenggengLin/MDDI-SCL">https://github.com/ShenggengLin/MDDI-SCL</ext-link>. The datasets are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/ShenggengLin/MDF-SA-DDI">https://github.com/ShenggengLin/MDF-SA-DDI</ext-link>.</p>
  </notes>
  <notes>
    <title>Declarations</title>
    <notes id="FPar1" notes-type="COI-statement">
      <title>Competing interests</title>
      <p id="Par62">The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
    </notes>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Bansal</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Karan</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Menden</surname>
            <given-names>MP</given-names>
          </name>
          <name>
            <surname>Costello</surname>
            <given-names>JC</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Allen</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Zhong</surname>
            <given-names>R</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A community computational challenge to predict the activity of pairs of compounds</article-title>
        <source>Nat Biotechnol</source>
        <year>2014</year>
        <volume>32</volume>
        <issue>12</issue>
        <fpage>1213</fpage>
        <lpage>1222</lpage>
        <?supplied-pmid 25419740?>
        <pub-id pub-id-type="pmid">25419740</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zitnik</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Agrawal</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Leskovec</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Modeling polypharmacy side effects with graph convolutional networks</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>13</issue>
        <fpage>457</fpage>
        <lpage>466</lpage>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vilar</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Harpaz</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Uriarte</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Santana</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Rabadan</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Friedman</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Drug-drug interaction through molecular structure similarity analysis</article-title>
        <source>J Am Med Inform Assn</source>
        <year>2012</year>
        <volume>19</volume>
        <issue>6</issue>
        <fpage>1066</fpage>
        <lpage>1074</lpage>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xiong</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Yi</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DDInter: an online drug-drug interaction database towards improving clinical decision-making and patient safety</article-title>
        <source>Nucleic Acids Res</source>
        <year>2022</year>
        <volume>50</volume>
        <issue>D1</issue>
        <fpage>D1200</fpage>
        <lpage>D1207</lpage>
        <?supplied-pmid 34634800?>
        <pub-id pub-id-type="pmid">34634800</pub-id>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Su</surname>
            <given-names>XR</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>You</surname>
            <given-names>ZH</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>PW</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>BW</given-names>
          </name>
        </person-group>
        <article-title>A deep learning method for repurposing antiviral drugs against new viruses via multi-view nonnegative matrix factorization and its application to SARS-CoV-2</article-title>
        <source>Brief Bioinform.</source>
        <year>2022</year>
        <volume>23</volume>
        <issue>1</issue>
        <fpage>bbab526</fpage>
        <?supplied-pmid 34965582?>
        <pub-id pub-id-type="pmid">34965582</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tatonetti</surname>
            <given-names>NP</given-names>
          </name>
          <name>
            <surname>Fernald</surname>
            <given-names>GH</given-names>
          </name>
          <name>
            <surname>Altman</surname>
            <given-names>RB</given-names>
          </name>
        </person-group>
        <article-title>A novel signal detection algorithm for identifying hidden drug-drug interactions in adverse event reports</article-title>
        <source>J Am Med Inform Assoc</source>
        <year>2012</year>
        <volume>19</volume>
        <issue>1</issue>
        <fpage>79</fpage>
        <lpage>85</lpage>
        <?supplied-pmid 21676938?>
        <pub-id pub-id-type="pmid">21676938</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tatonetti</surname>
            <given-names>NP</given-names>
          </name>
          <name>
            <surname>Ye</surname>
            <given-names>PP</given-names>
          </name>
          <name>
            <surname>Daneshjou</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Altman</surname>
            <given-names>RB</given-names>
          </name>
        </person-group>
        <article-title>Data-driven prediction of drug effects and interactions</article-title>
        <source>Sci Transl Med</source>
        <year>2012</year>
        <pub-id pub-id-type="doi">10.1126/scitranslmed.3003377</pub-id>
        <?supplied-pmid 22422992?>
        <pub-id pub-id-type="pmid">22422992</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vilar</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Friedman</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Hripcsak</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Detection of drug-drug interactions through data mining studies using clinical sources, scientific literature and social media</article-title>
        <source>Brief Bioinform</source>
        <year>2018</year>
        <volume>19</volume>
        <issue>5</issue>
        <fpage>863</fpage>
        <lpage>877</lpage>
        <?supplied-pmid 28334070?>
        <pub-id pub-id-type="pmid">28334070</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Zheng</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Lin</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Dumontier</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Drug-drug interaction extraction via hierarchical RNNs on sequence and shortest dependency paths</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>5</issue>
        <fpage>828</fpage>
        <lpage>835</lpage>
        <?supplied-pmid 29077847?>
        <pub-id pub-id-type="pmid">29077847</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vilar</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Uriarte</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Santana</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Lorberbaum</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Hripcsak</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Friedman</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Tatonetti</surname>
            <given-names>NP</given-names>
          </name>
        </person-group>
        <article-title>Similarity-based modeling in large-scale prediction of drug-drug interactions</article-title>
        <source>Nat Protoc</source>
        <year>2014</year>
        <volume>9</volume>
        <issue>9</issue>
        <fpage>2147</fpage>
        <lpage>2163</lpage>
        <?supplied-pmid 25122524?>
        <pub-id pub-id-type="pmid">25122524</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Cheng</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>Z</given-names>
          </name>
        </person-group>
        <article-title>Machine learning-based prediction of drug-drug interactions by integrating drug phenotypic, therapeutic, chemical, and genomic properties</article-title>
        <source>J Am Med Inform Assoc</source>
        <year>2014</year>
        <volume>21</volume>
        <issue>e2</issue>
        <fpage>e278</fpage>
        <lpage>286</lpage>
        <?supplied-pmid 24644270?>
        <pub-id pub-id-type="pmid">24644270</pub-id>
      </element-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Park</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Ha</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Predicting pharmacodynamic drug-drug interactions through signaling propagation interference on protein-protein interaction networks</article-title>
        <source>Plos ONE</source>
        <year>2015</year>
        <volume>10</volume>
        <issue>10</issue>
        <fpage>e0140816</fpage>
        <?supplied-pmid 26469276?>
        <pub-id pub-id-type="pmid">26469276</pub-id>
      </element-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Sorrentino</surname>
            <given-names>R</given-names>
          </name>
        </person-group>
        <article-title>Label propagation prediction of drug-drug interactions based on clinical side effects</article-title>
        <source>Sci Rep</source>
        <year>2015</year>
        <volume>5</volume>
        <fpage>12339</fpage>
        <?supplied-pmid 26196247?>
        <pub-id pub-id-type="pmid">26196247</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Lin X, Quan Z, Wang ZJ, Ma TF, Zeng XX. KGNN: Knowledge Graph Neural Network for Drug-Drug Interaction Prediction. Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence 2020:2739–2745.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dai</surname>
            <given-names>YF</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>CH</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>WZ</given-names>
          </name>
          <name>
            <surname>Eickhoff</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Drug-drug interaction prediction with Wasserstein Adversarial Autoencoder-based knowledge graph embeddings</article-title>
        <source>Brief Bioinform.</source>
        <year>2021</year>
        <volume>22</volume>
        <issue>4</issue>
        <fpage>bbaa256</fpage>
        <?supplied-pmid 33126246?>
        <pub-id pub-id-type="pmid">33126246</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>XD</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Meng</surname>
            <given-names>XY</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Rodriguez-Paton</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>X</given-names>
          </name>
        </person-group>
        <article-title>Molormer: a lightweight self-attention-based method focused on spatial structure of molecular graph for drug-drug interactions prediction</article-title>
        <source>Brief Bioinform.</source>
        <year>2022</year>
        <volume>23</volume>
        <issue>5</issue>
        <fpage>bbac296</fpage>
        <?supplied-pmid 35849817?>
        <pub-id pub-id-type="pmid">35849817</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wishart</surname>
            <given-names>DS</given-names>
          </name>
          <name>
            <surname>Feunang</surname>
            <given-names>YD</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Lo</surname>
            <given-names>EJ</given-names>
          </name>
          <name>
            <surname>Marcu</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Grant</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Sajed</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Johnson</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sayeeda</surname>
            <given-names>Z</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DrugBank 5.0: a major update to the DrugBank database for 2018</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2018</year>
        <volume>46</volume>
        <issue>D1</issue>
        <fpage>D1074</fpage>
        <lpage>D1082</lpage>
        <?supplied-pmid 29126136?>
        <pub-id pub-id-type="pmid">29126136</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ryu</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Kim</surname>
            <given-names>HU</given-names>
          </name>
          <name>
            <surname>Lee</surname>
            <given-names>SY</given-names>
          </name>
        </person-group>
        <article-title>Deep learning improves prediction of drug-drug and drug-food interactions</article-title>
        <source>Proc Natl Acad Sci USA</source>
        <year>2018</year>
        <volume>115</volume>
        <issue>18</issue>
        <fpage>E4304</fpage>
        <lpage>E4311</lpage>
        <?supplied-pmid 29666228?>
        <pub-id pub-id-type="pmid">29666228</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lee</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Park</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Ahn</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Novel deep learning model for more accurate prediction of drug-drug interaction effects</article-title>
        <source>BMC Bioinformatics.</source>
        <year>2019</year>
        <volume>20</volume>
        <issue>1</issue>
        <fpage>415</fpage>
        <?supplied-pmid 31387547?>
        <pub-id pub-id-type="pmid">31387547</pub-id>
      </element-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deng</surname>
            <given-names>YF</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>XR</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Xia</surname>
            <given-names>JB</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>SC</given-names>
          </name>
        </person-group>
        <article-title>A multimodal deep learning framework for predicting drug-drug interaction events</article-title>
        <source>Bioinformatics</source>
        <year>2020</year>
        <volume>36</volume>
        <issue>15</issue>
        <fpage>4316</fpage>
        <lpage>4322</lpage>
        <?supplied-pmid 32407508?>
        <pub-id pub-id-type="pmid">32407508</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>SG</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>YJ</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>LF</given-names>
          </name>
          <name>
            <surname>Chu</surname>
            <given-names>YY</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>YT</given-names>
          </name>
          <name>
            <surname>Fang</surname>
            <given-names>YT</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>MM</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>QK</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>BW</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>Y</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>MDF-SA-DDI: predicting drug-drug interaction events based on multi-source drug fusion, multi-source feature fusion and transformer self-attention mechanism</article-title>
        <source>Brief Bioinform.</source>
        <year>2022</year>
        <volume>23</volume>
        <issue>1</issue>
        <fpage>bbab421</fpage>
        <?supplied-pmid 34671814?>
        <pub-id pub-id-type="pmid">34671814</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Deng</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Qiu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Zhu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>META-DDIE: predicting drug-drug interaction events with few-shot learning</article-title>
        <source>Brief Bioinform.</source>
        <year>2022</year>
        <volume>23</volume>
        <issue>1</issue>
        <fpage>bbab421</fpage>
        <pub-id pub-id-type="pmid">34671814</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>XN</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>JY</given-names>
          </name>
          <name>
            <surname>Dong</surname>
            <given-names>WM</given-names>
          </name>
        </person-group>
        <article-title>Predict multi-type drug-drug interactions in cold start scenario</article-title>
        <source>BMC Bioinformatics</source>
        <year>2022</year>
        <volume>23</volume>
        <issue>1</issue>
        <fpage>75</fpage>
        <?supplied-pmid 35172712?>
        <pub-id pub-id-type="pmid">35172712</pub-id>
      </element-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Feng</surname>
            <given-names>YH</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>SW</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>QQ</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>CH</given-names>
          </name>
          <name>
            <surname>Shi</surname>
            <given-names>JY</given-names>
          </name>
        </person-group>
        <article-title>deepMDDI: a deep graph convolutional network framework for multi-label prediction of drug-drug interactions</article-title>
        <source>Anal Biochem</source>
        <year>2022</year>
        <volume>646</volume>
        <fpage>114631</fpage>
        <?supplied-pmid 35227661?>
        <pub-id pub-id-type="pmid">35227661</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>ZD</given-names>
          </name>
          <name>
            <surname>Zhong</surname>
            <given-names>WH</given-names>
          </name>
          <name>
            <surname>Lv</surname>
            <given-names>QJ</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>CYC</given-names>
          </name>
        </person-group>
        <article-title>Learning size-adaptive molecular substructures for explainable drug-drug interaction prediction by substructure-aware graph neural network</article-title>
        <source>Chem Sci</source>
        <year>2022</year>
        <volume>13</volume>
        <issue>29</issue>
        <fpage>8693</fpage>
        <lpage>8703</lpage>
        <?supplied-pmid 35974769?>
        <pub-id pub-id-type="pmid">35974769</pub-id>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>YJ</given-names>
          </name>
          <name>
            <surname>Ma</surname>
            <given-names>TF</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>XX</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>BS</given-names>
          </name>
          <name>
            <surname>Zeng</surname>
            <given-names>XX</given-names>
          </name>
        </person-group>
        <article-title>MUFFIN: multi-scale feature fusion for drug-drug interaction prediction</article-title>
        <source>Bioinformatics</source>
        <year>2021</year>
        <volume>37</volume>
        <issue>17</issue>
        <fpage>2651</fpage>
        <lpage>2658</lpage>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>KX</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Glass</surname>
            <given-names>LM</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>SumGNN: multi-typed drug interaction prediction via efficient knowledge graph summarization</article-title>
        <source>Bioinformatics</source>
        <year>2021</year>
        <volume>37</volume>
        <issue>18</issue>
        <fpage>2988</fpage>
        <lpage>2995</lpage>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Su</surname>
            <given-names>XR</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>You</surname>
            <given-names>ZH</given-names>
          </name>
          <name>
            <surname>Hu</surname>
            <given-names>PW</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>BW</given-names>
          </name>
        </person-group>
        <article-title>Attention-based knowledge graph representation learning for predicting drug-drug interactions</article-title>
        <source>Brief Bioinform</source>
        <year>2022</year>
        <volume>23</volume>
        <issue>3</issue>
        <fpage>bbac140</fpage>
        <?supplied-pmid 35453147?>
        <pub-id pub-id-type="pmid">35453147</pub-id>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Pan</surname>
            <given-names>XY</given-names>
          </name>
          <name>
            <surname>Yan</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>You</surname>
            <given-names>ZH</given-names>
          </name>
        </person-group>
        <article-title>HiSCF: leveraging higher-order structures for clustering analysis in biological networks</article-title>
        <source>Bioinformatics</source>
        <year>2021</year>
        <volume>37</volume>
        <issue>4</issue>
        <fpage>542</fpage>
        <lpage>550</lpage>
        <?supplied-pmid 32931549?>
        <pub-id pub-id-type="pmid">32931549</pub-id>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Jaiswal</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Babu</surname>
            <given-names>AR</given-names>
          </name>
          <name>
            <surname>Zadeh</surname>
            <given-names>MZ</given-names>
          </name>
          <name>
            <surname>Banerjee</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Makedon</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>A survey on contrastive self-supervised learning</article-title>
        <source>Technologies</source>
        <year>2021</year>
        <pub-id pub-id-type="doi">10.3390/technologies9010002</pub-id>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Khosla</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Teterwak</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Sarna</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Tian</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Isola</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Maschinot</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Krishnan</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Supervised contrastive learning</article-title>
        <source>arXiv</source>
        <year>2021</year>
        <pub-id pub-id-type="doi">10.48550/arXiv.2004.11362</pub-id>
      </element-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lopez-Martin</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Sanchez-Esguevillas</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Arribas</surname>
            <given-names>JI</given-names>
          </name>
          <name>
            <surname>Carro</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>Supervised contrastive learning over prototype-label embeddings for network intrusion detection</article-title>
        <source>Inform Fusion</source>
        <year>2022</year>
        <volume>79</volume>
        <fpage>200</fpage>
        <lpage>228</lpage>
      </element-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zheng</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>HB</given-names>
          </name>
        </person-group>
        <article-title>Accurate inference of gene regulatory interactions from spatial gene expression with deep contrastive learning</article-title>
        <source>Bioinformatics</source>
        <year>2022</year>
        <volume>38</volume>
        <issue>3</issue>
        <fpage>746</fpage>
        <lpage>753</lpage>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Song</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Huang</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Fu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Xiao</surname>
            <given-names>W</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>GraphCDR: a graph neural network method with contrastive learning for cancer drug response prediction</article-title>
        <source>Brief Bioinform.</source>
        <year>2022</year>
        <volume>23</volume>
        <issue>1</issue>
        <fpage>bbab457</fpage>
        <?supplied-pmid 34727569?>
        <pub-id pub-id-type="pmid">34727569</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Li</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Qiao</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Gao</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>Supervised graph co-contrastive learning for drug-target interaction prediction</article-title>
        <source>Bioinformatics</source>
        <year>2022</year>
        <volume>38</volume>
        <issue>10</issue>
        <fpage>2847</fpage>
        <lpage>2854</lpage>
        <?supplied-pmid 35561181?>
        <pub-id pub-id-type="pmid">35561181</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Hu</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Bindu</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Laskin</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Self-supervised clustering of mass spectrometry imaging data using contrastive learning</article-title>
        <source>Chem Sci</source>
        <year>2021</year>
        <volume>13</volume>
        <issue>1</issue>
        <fpage>90</fpage>
        <lpage>98</lpage>
        <?supplied-pmid 35059155?>
        <pub-id pub-id-type="pmid">35059155</pub-id>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <mixed-citation publication-type="other">Wang YH, Min YS, Chen X, Wu J. Multi-view Graph Contrastive Representation Learning for Drug-Drug Interaction Prediction. Proceedings of the World Wide Web Conference 2021 (Www 2021) 2021:2921–2933.</mixed-citation>
    </ref>
    <ref id="CR38">
      <label>38.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ciortan</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Defrance</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Contrastive self-supervised clustering of scRNA-seq data</article-title>
        <source>BMC Bioinformatics</source>
        <year>2021</year>
        <volume>22</volume>
        <issue>1</issue>
        <fpage>280</fpage>
        <?supplied-pmid 34044773?>
        <pub-id pub-id-type="pmid">34044773</pub-id>
      </element-citation>
    </ref>
    <ref id="CR39">
      <label>39.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Law</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Knox</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>Djoumbou</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Jewison</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Guo</surname>
            <given-names>AC</given-names>
          </name>
          <name>
            <surname>Liu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Maciejewski</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Arndt</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Wilson</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Neveu</surname>
            <given-names>V</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>DrugBank 4.0: shedding new light on drug metabolism</article-title>
        <source>Nucleic Acids Res.</source>
        <year>2014</year>
        <volume>42</volume>
        <issue>Database issue</issue>
        <fpage>1091</fpage>
        <lpage>1097</lpage>
      </element-citation>
    </ref>
    <ref id="CR40">
      <label>40.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chu</surname>
            <given-names>YY</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>QK</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>LF</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>XH</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>YJ</given-names>
          </name>
          <name>
            <surname>Salahub</surname>
            <given-names>DR</given-names>
          </name>
          <name>
            <surname>Xu</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>JM</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>X</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A transformer-based model to predict peptide-HLA class I binding and optimize mutated peptides for vaccine design</article-title>
        <source>Nat Mach Intell.</source>
        <year>2022</year>
        <volume>4</volume>
        <issue>3</issue>
        <fpage>300</fpage>
      </element-citation>
    </ref>
    <ref id="CR41">
      <label>41.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Vaswani</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Shazeer</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Parmar</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Uszkoreit</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Jones</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Gomez</surname>
            <given-names>AN</given-names>
          </name>
          <name>
            <surname>Kaiser</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Polosukhin</surname>
            <given-names>I</given-names>
          </name>
        </person-group>
        <article-title>Attention is all you need</article-title>
        <source>Adv Neur In</source>
        <year>2017</year>
        <pub-id pub-id-type="doi">10.48550/arXiv.1706.03762</pub-id>
      </element-citation>
    </ref>
    <ref id="CR42">
      <label>42.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Dai</surname>
            <given-names>QY</given-names>
          </name>
          <name>
            <surname>Chu</surname>
            <given-names>YY</given-names>
          </name>
          <name>
            <surname>Li</surname>
            <given-names>ZQ</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>YS</given-names>
          </name>
          <name>
            <surname>Mao</surname>
            <given-names>XY</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>YJ</given-names>
          </name>
          <name>
            <surname>Xiong</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Wei</surname>
            <given-names>DQ</given-names>
          </name>
        </person-group>
        <article-title>MDA-CF: predicting MiRNA-disease associations based on a cascade forest model by fusing multi-source information</article-title>
        <source>Comput Biol Med.</source>
        <year>2021</year>
        <volume>136</volume>
        <fpage>104706</fpage>
        <?supplied-pmid 34371319?>
        <pub-id pub-id-type="pmid">34371319</pub-id>
      </element-citation>
    </ref>
    <ref id="CR43">
      <label>43.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Rao</surname>
            <given-names>JH</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>YT</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>HY</given-names>
          </name>
          <name>
            <surname>Yang</surname>
            <given-names>YD</given-names>
          </name>
        </person-group>
        <article-title>Imputing single-cell RNA-seq data by combining graph convolution and autoencoder neural networks</article-title>
        <source>iScience</source>
        <year>2021</year>
        <volume>24</volume>
        <issue>5</issue>
        <fpage>102393</fpage>
        <?supplied-pmid 33997678?>
        <pub-id pub-id-type="pmid">33997678</pub-id>
      </element-citation>
    </ref>
    <ref id="CR44">
      <label>44.</label>
      <mixed-citation publication-type="other">Liu S, Qi L, Qin HF, Shi JP, Jia JY. Path Aggregation Network for Instance Segmentation. 2018 Ieee/Cvf Conference on Computer Vision and Pattern Recognition (Cvpr) 2018:8759-8768</mixed-citation>
    </ref>
    <ref id="CR45">
      <label>45.</label>
      <mixed-citation publication-type="other">Singh B, Davis LS. An Analysis of Scale Invariance in Object Detection - SNIP. 2018 Ieee/Cvf Conference on Computer Vision and Pattern Recognition (Cvpr) 2018:3578-3587</mixed-citation>
    </ref>
    <ref id="CR46">
      <label>46.</label>
      <mixed-citation publication-type="other">Li YH, Chen YT, Wang NY, Zhang ZX. Scale-Aware Trident Networks for Object Detection. Ieee I Conf Comp Vis 2019:6053–6062.</mixed-citation>
    </ref>
    <ref id="CR47">
      <label>47.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Song</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>XD</given-names>
          </name>
          <name>
            <surname>Ding</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Rodriguez-Paton</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>SD</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>DeepFusion: a deep learning based multi-scale feature fusion method for predicting drug-target interactions</article-title>
        <source>Methods</source>
        <year>2022</year>
        <volume>204</volume>
        <fpage>269</fpage>
        <lpage>277</lpage>
        <?supplied-pmid 35219861?>
        <pub-id pub-id-type="pmid">35219861</pub-id>
      </element-citation>
    </ref>
    <ref id="CR48">
      <label>48.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tang</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Nie</surname>
            <given-names>FL</given-names>
          </name>
          <name>
            <surname>Kang</surname>
            <given-names>JJ</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>W</given-names>
          </name>
        </person-group>
        <article-title>mRNALocater: enhance the prediction accuracy of eukaryotic mRNA subcellular localization by using model fusion strategy</article-title>
        <source>Mol Ther</source>
        <year>2021</year>
        <volume>29</volume>
        <issue>8</issue>
        <fpage>2617</fpage>
        <lpage>2623</lpage>
        <?supplied-pmid 33823302?>
        <pub-id pub-id-type="pmid">33823302</pub-id>
      </element-citation>
    </ref>
    <ref id="CR49">
      <label>49.</label>
      <mixed-citation publication-type="other">He KM, Zhang XY, Ren SQ, Sun J. Deep Residual Learning for Image Recognition. Proc Cvpr Ieee 2016:770–778.</mixed-citation>
    </ref>
    <ref id="CR50">
      <label>50.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Chen</surname>
            <given-names>T</given-names>
          </name>
          <name>
            <surname>Kornblith</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Norouzi</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Hinton</surname>
            <given-names>G</given-names>
          </name>
        </person-group>
        <article-title>A simple framework for contrastive learning of visual representations</article-title>
        <source>Pr Mach Learn Res.</source>
        <year>2020</year>
        <volume>119</volume>
        <fpage>1597</fpage>
      </element-citation>
    </ref>
    <ref id="CR51">
      <label>51.</label>
      <mixed-citation publication-type="other">Guo DE, Xia Y, Luo XB, Feng JF. 2021. Remote Sensing Image Scene Classification Based on Supervised Contrastive Learning. Acta Photonica Sinic. 50(7).</mixed-citation>
    </ref>
    <ref id="CR52">
      <label>52.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Lin</surname>
            <given-names>TY</given-names>
          </name>
          <name>
            <surname>Goyal</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Girshick</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>He</surname>
            <given-names>KM</given-names>
          </name>
          <name>
            <surname>Dollar</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Focal loss for dense object detection</article-title>
        <source>Ieee T Pattern Anal</source>
        <year>2020</year>
        <volume>42</volume>
        <issue>2</issue>
        <fpage>318</fpage>
        <lpage>327</lpage>
      </element-citation>
    </ref>
    <ref id="CR53">
      <label>53.</label>
      <mixed-citation publication-type="other">Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z. Rethinking the Inception Architecture for Computer Vision. Proc Cvpr Ieee 2016:2818–2826.</mixed-citation>
    </ref>
    <ref id="CR54">
      <label>54.</label>
      <mixed-citation publication-type="other">Zheng W, Zhang YX, Gong XH, Zhanghuali, Yu BY. DenseNet model with RAdam optimization algorithm for cancer image classification. 2021 Ieee International Conference on Consumer Electronics and Computer Engineering (Iccece) 2021:771-775.</mixed-citation>
    </ref>
    <ref id="CR55">
      <label>55.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ioffe</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Szegedy</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>Batch normalization: Accelerating deep network training by reducing internal covariate shift</article-title>
        <source>arXiv</source>
        <year>2015</year>
        <volume>37</volume>
        <fpage>448</fpage>
      </element-citation>
    </ref>
  </ref-list>
</back>
