<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName JATS-journalpublishing1.dtd?>
<?SourceDTD.Version 39.96?>
<?ConverterInfo.XSLTName jp2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">PLoS One</journal-id>
    <journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id>
    <journal-id journal-id-type="publisher-id">plos</journal-id>
    <journal-id journal-id-type="pmc">plosone</journal-id>
    <journal-title-group>
      <journal-title>PLoS ONE</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1932-6203</issn>
    <publisher>
      <publisher-name>Public Library of Science</publisher-name>
      <publisher-loc>San Francisco, CA USA</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">6905554</article-id>
    <article-id pub-id-type="doi">10.1371/journal.pone.0226115</article-id>
    <article-id pub-id-type="publisher-id">PONE-D-19-22116</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Research Article</subject>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Gene Expression</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Oncology</subject>
          <subj-group>
            <subject>Cancers and Neoplasms</subject>
            <subj-group>
              <subject>Hematologic Cancers and Related Disorders</subject>
              <subj-group>
                <subject>Leukemias</subject>
                <subj-group>
                  <subject>Myeloid Leukemia</subject>
                  <subj-group>
                    <subject>Acute Myeloid Leukemia</subject>
                  </subj-group>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Hematology</subject>
          <subj-group>
            <subject>Hematologic Cancers and Related Disorders</subject>
            <subj-group>
              <subject>Leukemias</subject>
              <subj-group>
                <subject>Myeloid Leukemia</subject>
                <subj-group>
                  <subject>Acute Myeloid Leukemia</subject>
                </subj-group>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Computational Biology</subject>
          <subj-group>
            <subject>Genome Analysis</subject>
            <subj-group>
              <subject>Gene Prediction</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Biology and Life Sciences</subject>
        <subj-group>
          <subject>Genetics</subject>
          <subj-group>
            <subject>Genomics</subject>
            <subj-group>
              <subject>Genome Analysis</subject>
              <subj-group>
                <subject>Gene Prediction</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
            <subj-group>
              <subject>Support Vector Machines</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
              <subj-group>
                <subject>Kernel Methods</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
            <subj-group>
              <subject>Kernel Methods</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Computer and Information Sciences</subject>
        <subj-group>
          <subject>Artificial Intelligence</subject>
          <subj-group>
            <subject>Machine Learning</subject>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Medicine and Health Sciences</subject>
        <subj-group>
          <subject>Pharmacology</subject>
          <subj-group>
            <subject>Drug Research and Development</subject>
            <subj-group>
              <subject>Drug Discovery</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Physical Sciences</subject>
        <subj-group>
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Applied Mathematics</subject>
            <subj-group>
              <subject>Algorithms</subject>
            </subj-group>
          </subj-group>
        </subj-group>
      </subj-group>
      <subj-group subj-group-type="Discipline-v3">
        <subject>Research and Analysis Methods</subject>
        <subj-group>
          <subject>Simulation and Modeling</subject>
          <subj-group>
            <subject>Algorithms</subject>
          </subj-group>
        </subj-group>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>A novel one-class classification approach to accurately predict disease-gene association in acute myeloid leukemia cancer</article-title>
      <alt-title alt-title-type="running-head">Accurately predict disease-gene association using OC-SVM</alt-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Vasighizaker</surname>
          <given-names>Akram</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Conceptualization</role>
        <role content-type="http://credit.casrai.org/">Data curation</role>
        <role content-type="http://credit.casrai.org/">Formal analysis</role>
        <role content-type="http://credit.casrai.org/">Methodology</role>
        <role content-type="http://credit.casrai.org/">Software</role>
        <role content-type="http://credit.casrai.org/">Validation</role>
        <role content-type="http://credit.casrai.org/">Visualization</role>
        <role content-type="http://credit.casrai.org/">Writing – original draft</role>
        <xref ref-type="aff" rid="aff001">
          <sup>1</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>Sharma</surname>
          <given-names>Alok</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Formal analysis</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff002">
          <sup>2</sup>
        </xref>
        <xref ref-type="aff" rid="aff003">
          <sup>3</sup>
        </xref>
        <xref ref-type="aff" rid="aff004">
          <sup>4</sup>
        </xref>
        <xref ref-type="aff" rid="aff005">
          <sup>5</sup>
        </xref>
        <xref ref-type="aff" rid="aff006">
          <sup>6</sup>
        </xref>
      </contrib>
      <contrib contrib-type="author">
        <contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8577-0271</contrib-id>
        <name>
          <surname>Dehzangi</surname>
          <given-names>Abdollah</given-names>
        </name>
        <role content-type="http://credit.casrai.org/">Project administration</role>
        <role content-type="http://credit.casrai.org/">Supervision</role>
        <role content-type="http://credit.casrai.org/">Writing – original draft</role>
        <role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
        <xref ref-type="aff" rid="aff007">
          <sup>7</sup>
        </xref>
        <xref ref-type="corresp" rid="cor001">*</xref>
      </contrib>
    </contrib-group>
    <aff id="aff001">
      <label>1</label>
      <addr-line>Electrical &amp; Computer Engineering Department, Tarbiat Modares University, Tehran, Iran</addr-line>
    </aff>
    <aff id="aff002">
      <label>2</label>
      <addr-line>Institute for Integrated and Intelligent Systems, Griffith University, Brisbane, Queensland, Australia</addr-line>
    </aff>
    <aff id="aff003">
      <label>3</label>
      <addr-line>Department of Medical Science Mathematics, Medical Research Institute, Tokyo Medical and Dental University (TMDU), Tokyo, Japan</addr-line>
    </aff>
    <aff id="aff004">
      <label>4</label>
      <addr-line>Laboratory for Medical Science Mathematics, RIKEN Center for Integrative Medical Sciences, Yokohama, Kanagawa, Japan</addr-line>
    </aff>
    <aff id="aff005">
      <label>5</label>
      <addr-line>School of Engineering and Physics, Faculty of Science Technology and Environment, University of the South Pacific, Suva, Fiji</addr-line>
    </aff>
    <aff id="aff006">
      <label>6</label>
      <addr-line>CREST, JST, Tokyo, Japan</addr-line>
    </aff>
    <aff id="aff007">
      <label>7</label>
      <addr-line>Department of Computer Science, Morgan State University, Baltimore, Maryland, United States of America</addr-line>
    </aff>
    <contrib-group>
      <contrib contrib-type="editor">
        <name>
          <surname>Taguchi</surname>
          <given-names>Y-h.</given-names>
        </name>
        <role>Editor</role>
        <xref ref-type="aff" rid="edit1"/>
      </contrib>
    </contrib-group>
    <aff id="edit1">
      <addr-line>Chuo University, JAPAN</addr-line>
    </aff>
    <author-notes>
      <fn fn-type="COI-statement" id="coi001">
        <p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p>
      </fn>
      <corresp id="cor001">* E-mail: <email>abdollah.dehzangi@morgan.edu</email></corresp>
    </author-notes>
    <pub-date pub-type="epub">
      <day>11</day>
      <month>12</month>
      <year>2019</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2019</year>
    </pub-date>
    <volume>14</volume>
    <issue>12</issue>
    <elocation-id>e0226115</elocation-id>
    <history>
      <date date-type="received">
        <day>5</day>
        <month>8</month>
        <year>2019</year>
      </date>
      <date date-type="accepted">
        <day>19</day>
        <month>11</month>
        <year>2019</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© 2019 Vasighizaker et al</copyright-statement>
      <copyright-year>2019</copyright-year>
      <copyright-holder>Vasighizaker et al</copyright-holder>
      <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
        <license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
      </license>
    </permissions>
    <self-uri content-type="pdf" xlink:href="pone.0226115.pdf"/>
    <abstract>
      <p>Disease causing gene identification is considered as an important step towards drug design and drug discovery. In disease gene identification and classification, the main aim is to identify disease genes while identifying non-disease genes are of less or no significant. Hence, this task can be defined as a one-class classification problem. Existing machine learning methods typically take into consideration known disease genes as positive training set and unknown genes as negative samples to build a binary-class classification model. Here we propose a new One-class Classification Support Vector Machines (OCSVM) method to precisely classify candidate disease genes. Our aim is to build a model that concentrate its focus on detecting known disease-causing gene to increase sensitivity and precision. We investigate the impact of our proposed model using a benchmark consisting of the gene expression dataset for Acute Myeloid Leukemia (AML) cancer. Compared with the traditional methods, our experimental result shows the superiority of our proposed method in terms of precision, recall, and F-measure to detect disease causing genes for AML. OCSVM codes and our extracted AML benchmark are publicly available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/imandehzangi/OCSVM">https://github.com/imandehzangi/OCSVM</ext-link>.</p>
    </abstract>
    <funding-group>
      <award-group id="award001">
        <funding-source>
          <institution-wrap>
            <institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000057</institution-id>
            <institution>National Institute of General Medical Sciences</institution>
          </institution-wrap>
        </funding-source>
        <award-id>UL1GM118973</award-id>
      </award-group>
      <funding-statement>Research reported in this publication was supported by the National Institute of General Medical Sciences of the National Institutes of Health under Award Number UL1GM118973. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
    </funding-group>
    <counts>
      <fig-count count="5"/>
      <table-count count="2"/>
      <page-count count="12"/>
    </counts>
    <custom-meta-group>
      <custom-meta id="data-availability">
        <meta-name>Data Availability</meta-name>
        <meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
  <notes>
    <title>Data Availability</title>
    <p>All relevant data are within the paper and its Supporting Information files.</p>
  </notes>
</front>
<body>
  <sec sec-type="intro" id="sec001">
    <title>1. Introduction</title>
    <p>In medicine and pharmacology, it is crucial to understand the mechanism of a disease in order to find an effective treatment method. When dealing with the inherent disorders, finding the disease genes is the first step. Genetic disorders occur due to dysfunction or disease-causing mutations in a single gene or group of genes. Finding disease-related genes experimentally is a time taking process due to the large number of genes. Hence, further biological findings rely on the computational approaches to accelerate experiments to predict novel disease genes from the huge number of unknown genes. Computational methods also decrease the cost of findings the best treatment approaches for patients. To develop these methods, the large number of genes which have been experimentally confirmed as disorder related genes, could be employed as a useful training resource. In addition, there is a group of genes that is not confirmed as disease causing but has a close connection or functional similarities with such genes [<xref rid="pone.0226115.ref001" ref-type="bibr">1</xref>]. For these genes, demonstrating similar attributes with disease-causing genes can indicate possible similarity in their functioning mechanism. Here, our aim is to show disease genes that share common patterns of gene expression-based features can provide a good basis for automatic prediction of candidate disease genes using computational methods.</p>
    <p>There is an observation that genes associated with similar disorders are likely to have similar functionality [<xref rid="pone.0226115.ref002" ref-type="bibr">2</xref>]. It is also shown that functionally related genes which caused phenotypically similar diseases can potentially be used to identify disease causing genes [<xref rid="pone.0226115.ref003" ref-type="bibr">3</xref>]. Taking this finding to account, a wide range of two-class classifiers have been employed to tackle this problem in which Decision Tree (DT) [<xref rid="pone.0226115.ref004" ref-type="bibr">4</xref>], K-Nearest Neighbor (KNN) [<xref rid="pone.0226115.ref005" ref-type="bibr">5</xref>], and Support Vector Machine (SVM) [<xref rid="pone.0226115.ref006" ref-type="bibr">6</xref>] are among the most well-known ones.</p>
    <p>To tackle this problem, Zhou et al. proposed a knowledge-based approach called Know-GENE to predict gene-disease associations [<xref rid="pone.0226115.ref007" ref-type="bibr">7</xref>]. To build this model they derived gene-gene mutual information from known gene-disease association data and then combined them with known protein-protein interaction networks using a boosted tree regression method [<xref rid="pone.0226115.ref007" ref-type="bibr">7</xref>]. In a different study, Ata et al., proposed N2VKO as an integrative framework to predict disease genes using binary classification [<xref rid="pone.0226115.ref008" ref-type="bibr">8</xref>]. Moreover, Luo et al. [<xref rid="pone.0226115.ref009" ref-type="bibr">9</xref>] and Han et al. [<xref rid="pone.0226115.ref010" ref-type="bibr">10</xref>] predicted disease-gene associations using the joint features and deep learning classifier. All of these techniques used binary classification method to tackle this problem. To this extent, the confirmed disease genes were considered as a positive set and unknown genes as a negative set. However, all of the unknown genes are not necessarily negative. In fact, unknown genes are composed of both positives and negatives. Therefore, such categorization could introduce noise and inaccuracy, and consequently, negatively impact on the performance.</p>
    <p>Other methods tried to use unknown genes as unlabeled set (instead of negative ones), and employed positive-unlabeled (PU) learning techniques to improve their results. Mordelet and Vert [<xref rid="pone.0226115.ref011" ref-type="bibr">11</xref>] and Yang et al. [<xref rid="pone.0226115.ref012" ref-type="bibr">12</xref>] proposed algorithms aimed at computing the weighted similarities between samples in unlabeled set and positive samples. They estimated the likelihood of the samples in unlabeled set to be either positive or negative. Jowkar and Mansoori presented a derived reliable set of negative data in order to form a binary classification problem [<xref rid="pone.0226115.ref013" ref-type="bibr">13</xref>]. Later on, Yousef and Charkari, proposed a fusion method to assign genes to disease class and obtained better results [<xref rid="pone.0226115.ref014" ref-type="bibr">14</xref>].</p>
    <p>Other studies incorporated network technique analysis to address this issue. For instance, Singh-Blom et al developed the CATAPULT using positive-unlabeled learning influenced by a version of network propagation technique on an Acute Myeloid Leukemia (AML) gene-phenotype network [<xref rid="pone.0226115.ref015" ref-type="bibr">15</xref>]. In another study, Vasighizaker et al. used a novel strategy to extract reliable negatives from a huge number of unlabeled samples in an integrative framework [<xref rid="pone.0226115.ref016" ref-type="bibr">16</xref>]. They introduced a novel method called C-PUGP, based on clustering approach to build a binary classifier and comparatively outperformed traditional methods.</p>
    <p>While recent methods indicated promising output in disease gene prediction, they all suffered from several inherent limitations that confined their performance. The main issue with such studies is not having a specific technique to retrieve validated negative data from unlabeled samples to produce reliable result. Therefore, to overcome this limitation, here we propose a novel machine learning method to accurately predict disease causing genes in AML based upon the concept of one-class classification using gene expression data. One-class classification method does not require negative data in the training set. Hence, it could potentially minimize the training error rate, and as a result, is able to perform as an effective and robust solution, compared to binary-class classification methods with unreliable training set.</p>
    <p>In general, the main contribution of this paper is proposing one-class classification method to enhancement prediction performance over binary class classification methods by overcoming the issue of noisy unlabeled data as negative samples. Also, we will demonstrate that it can obtain better sensitivity or in other words, better performance in detecting disease causing genes. Moreover, using gene expression as feature helps to build a biologically meaningful approach to determine differences between disease causing genes and other ones. To the best of our knowledge, our proposed method is the first to design a one-class classifier to identify disease genes.</p>
  </sec>
  <sec sec-type="materials|methods" id="sec002">
    <title>2. Materials and methods</title>
    <p>In this section, we describe our proposed method for identifying candidate disease genes in Acute Myeloid Leukemia (AML). We aim to assess the impact of a simple one-class classifier to solve this intrinsically one-class problem considering gene expression profile information. The rest of this section explains dataset, features representation, one-class classifier, the learning phase, and the evaluation method.</p>
    <sec id="sec003">
      <title>2.1. Datasets and features</title>
      <sec id="sec004">
        <title>2.1.1. Dataset</title>
        <p>There are a wide range of databases that consist gene expression data. The two of the most famous are NCBI GEO Datasets and NCBI GEO Profiles. It is possible to search these two datasets according to a specific condition, for example a disease name, or base upon a gene name/annotation. The data discussed here have been extracted from NCBI’s Gene Expression Omnibus [<xref rid="pone.0226115.ref017" ref-type="bibr">17</xref>].</p>
        <p>In general, GEO contains 4348 approved datasets in total. In order to compare the healthy and patient samples in AML, we added “Healthy” keyword in our search and obtain 1153 datasets instead of 2674 dataset related to only “AML”. As we interested in doing research on only human genes, we added this filter and narrowed down the result list to 1091. Another important factor to choose the dataset is to select those that also contain gene expression profile. Selecting those datasets that have expression profiling using microarray reduces the number of available datasets to 55.</p>
        <p>As this study aims at comparing and classifying patient cells using abnormal expression changes in AML, the other datasets were deleted from the list. Although other studies explore different issues related to AML (e.g. responding of Leukemia cells to a specific inhibitor), here we use a data set that was extracted from a study that focuses on the comparison of normal monocyte and myeloid Leukemia cells and the identification of abnormally expressed genes in AML [<xref rid="pone.0226115.ref018" ref-type="bibr">18</xref>]. In [<xref rid="pone.0226115.ref018" ref-type="bibr">18</xref>], authors indicate the over-expressed genes (compared with the other genes) as the potential therapeutic targets. Therefore, this dataset exactly matches our main goal and meet the requirement of our experiments to classify and identify genes with the abnormal expression changes.</p>
        <p>Moreover, in order to have a more significant p-value, we required a relatively large dataset in terms of the size. Considering each patient as a sample, the more sample size the more reliable result will achieve be obtained. Also, in order to guarantee the reliability and quality of the dataset, we tried to employ a dataset which has been widely used in the literature with proper quality check [<xref rid="pone.0226115.ref018" ref-type="bibr">18</xref>]. Hence, this dataset as one of the most updated ones is considered for our experimentations.</p>
        <p>The dataset used in this article made publicly available by Stirewalt et al. [<xref rid="pone.0226115.ref018" ref-type="bibr">18</xref>] and is accessible through GEP accession number GSE9476. The dataset comprises of gene expression levels of 38 normal and 26 acute myeloid leukemia (AML) patients, and was obtained using the Affymetrix Human Genome U133A microarray platform with accession number GPL96.</p>
        <p>After obtaining the data, the next step is to form our final benchmark dataset for statistical analysis. To this end, we first set up a measure to select a set of significant genes in the disease upstream process. Depending on the literature, there are different measures to define. A simple method is random selection as it was done in [<xref rid="pone.0226115.ref019" ref-type="bibr">19</xref>]. Another option is based on Log Fold Change and adjusted p-value, where the positive set consists of genes that are more differentially expressed and the remaining genes which are less differentially expressed are used to form the unlabeled set. We consider genes which have log fold change value less than −1 or greater than +1, together with an adjusted p-value less than a threshold of 0.05 as the top differentially expressed genes. As a result, the gene expression matrix for a total of 1174 positive genes and 1300 unlabeled genes are collected from the original dataset.</p>
        <p>The top list of positive genes obtained in the dataset preparation process are then employed for the classification method. Therefore, we could then evaluate the similarity between the genes in the unlabeled set and the characteristics of each gene in the positive set. If a gene in the unlabeled set met the similarity measurement in the model, this gene is listed in the candidate disease gene. This dataset is provided as supplementary material (<xref ref-type="supplementary-material" rid="pone.0226115.s001">S1</xref>, <xref ref-type="supplementary-material" rid="pone.0226115.s002">S2</xref>, and <xref ref-type="supplementary-material" rid="pone.0226115.s003">S3</xref> Files) to this article to make future comparisons feasible and reliable.</p>
      </sec>
      <sec id="sec005">
        <title>2.1.2. Biological feature representation</title>
        <p>It has been shown that gene expression levels in disease genes have predictable pattern in different diseases [<xref rid="pone.0226115.ref020" ref-type="bibr">20</xref>]. Hence, we use gene expression profiles in a dataset of AML to characterize genes with their corresponding feature vectors. Each gene <italic>g</italic><sub><italic>i</italic></sub> is represented as a vector <italic>v</italic><sub><italic>i</italic></sub> which consists of gene expression levels explaining the process of synthesizing information in the genes into the gene products. The gene expression profile is a collection of gene expression levels which is measured in different conditions or times. These conditions are dependent on different diseases and experiments. For example, the sequence of gene expression levels {<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>, …, <italic>x</italic><sub><italic>m</italic></sub>} which belongs to gene <italic>X</italic> is defined as its gene expression profile. One of the main feature of gene expression profile is that it can be calculated for different genes. For example, <italic>x</italic><sub>1</sub>, <italic>y</italic><sub>1</sub>, …, <italic>z</italic><sub>1</sub> are measured simultaneously under the particular experimental environments and conditions. We consider each expression of a gene, i.e. <italic>x</italic><sub><italic>m</italic></sub>, as a feature in the feature vector. In the other word, the gene expression profile <italic>G</italic><sub><italic>p</italic></sub> = {<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>, …, <italic>x</italic><sub><italic>m</italic></sub>} is a feature vector. The final dataset is presented as a <italic>N</italic> × <italic>P</italic> matrix format with W = {<italic>w</italic><sub><italic>np</italic></sub>} where <italic>w</italic><sub><italic>np</italic></sub> denotes the expression values of the gene <italic>n</italic> in the <italic>p-th</italic> sample.</p>
      </sec>
    </sec>
    <sec id="sec006">
      <title>2.2. One-class classifier</title>
      <p>Here we introduce one-class support vector machines (OCSVMs) as a means of identifying and predicting the presence of disease genes in AML samples in the unlabeled set. “One-class classification” term was employed first by Moya et.al [<xref rid="pone.0226115.ref021" ref-type="bibr">21</xref>] in 1993. Others, employed outlier detection, novelty detection, and concept learning for this type of learning problem. All of these terms inspired by different application of one-class classifiers. In one-class learning problem, the positive or target, which are either more abundant or clearly defined are labeled correct while the other negative or non-target samples are either non-existence or are very few and classifying them are not of any importance. In the prediction of disease genes, our main aim is to explore and detect disease genes (target class). OCSVM as a semi-supervised algorithm, learns a decision function for classifying new data as similar or different to the training set. The classifier tries to detect a single class and reject the others. The OCSVM method was introduced by Schölkopf et al. [<xref rid="pone.0226115.ref022" ref-type="bibr">22</xref>]. The idea behind the OCSVM is to describe target class by a function that maps the most part of it to a region where the function is nonzero. The problem is solved by finding a separating hyperplane (decision function) with maximum distance from the region containing target class (as shown in <xref ref-type="fig" rid="pone.0226115.g001">Fig 1</xref>, Left). The primal form of OCSVM is as follows:
<disp-formula id="pone.0226115.e001"><alternatives><graphic xlink:href="pone.0226115.e001.jpg" id="pone.0226115.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mtext>min</mml:mtext></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo><mml:mi>ξ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mi>w</mml:mi><mml:mo>-</mml:mo><mml:mi>ρ</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></alternatives><label>(1)</label></disp-formula>
Subject to:
<disp-formula id="pone.0226115.e002"><alternatives><graphic xlink:href="pone.0226115.e002.jpg" id="pone.0226115.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:msup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mi>ϕ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>≥</mml:mo><mml:mi>ρ</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></disp-formula>
<disp-formula id="pone.0226115.e003"><alternatives><graphic xlink:href="pone.0226115.e003.jpg" id="pone.0226115.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:msub><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:math></alternatives></disp-formula>
Where <italic>w</italic> and <italic>ρ</italic> are linear decision function parameters for <italic>l</italic> instances. Also, <italic>ξ</italic> is the cost of training with undergoing a little penalty, and <inline-formula id="pone.0226115.e004"><alternatives><graphic xlink:href="pone.0226115.e004.jpg" id="pone.0226115.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is the error rate of training. The penalty parameter or rejection fraction of the classifier, <italic>v</italic> ∈ (0, 1), is employed in order to control the tradeoff between the complexity of the model, <inline-formula id="pone.0226115.e005"><alternatives><graphic xlink:href="pone.0226115.e005.jpg" id="pone.0226115.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mi>w</mml:mi><mml:mo>-</mml:mo><mml:mi>ρ</mml:mi><mml:mo>,</mml:mo></mml:math></alternatives></inline-formula> and the error rate of the classifier. Also, <italic>ϕ</italic>(<italic>x</italic><sub><italic>i</italic></sub>) is the mapping function.</p>
      <fig id="pone.0226115.g001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0226115.g001</object-id>
        <label>Fig 1</label>
        <caption>
          <title>The general architecture of one-class classification of SVM, OCSVM (Left) and SVDD (Right).</title>
        </caption>
        <graphic xlink:href="pone.0226115.g001"/>
      </fig>
      <p>There are another OCSVM formulation, namely, Support Vector Domain Description (SVDD) which introduced by Tax and Duin [<xref rid="pone.0226115.ref023" ref-type="bibr">23</xref>]. In this model, they find a hypersphere with minimal radius containing only the target class samples and samples lying outside are outliers (as shown in <xref ref-type="fig" rid="pone.0226115.g001">Fig 1</xref>, Right). It was shown in [<xref rid="pone.0226115.ref024" ref-type="bibr">24</xref>] that when working with isotropic kernels, for example the Radial Basis Function (RBF), Gaussian kernels, and normalized data, both OCSVM and SVDD method yield the same solution in most cases.</p>
    </sec>
    <sec id="sec007">
      <title>2.3. Building classification model</title>
      <p>In this study, we use OCSVM with different kernels. Among different kernels, the best model in which yields the lowest classification error is using linear kernel. To this end, we suppose <italic>G</italic><sub><italic>p</italic></sub> = {<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>, …, <italic>x</italic><sub><italic>m</italic></sub>} as gene expression profiles of a disease gene. To avoid bias in sampling, we remove outliers. After that, all the feature vectors of instances are scaled according to Min-Max formulation presented by <xref ref-type="disp-formula" rid="pone.0226115.e001">Eq (1)</xref>
<disp-formula id="pone.0226115.e006"><alternatives><graphic xlink:href="pone.0226115.e006.jpg" id="pone.0226115.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></alternatives><label>(2)</label></disp-formula>
Where <italic>x</italic>′ ∈ [0, 1], and <italic>x</italic><sub><italic>min</italic></sub> and <italic>x</italic><sub><italic>max</italic></sub> are the minimum and the maximum values of the features, respectively. Also, in order to minimize the overfitting of the model, 10-fold cross validation is carried out in all of the experiments. As mentioned earlier, the binary-class classifiers treat unlabeled set as negative. In order to removing the bias effect, we investigate the performance of them using the balanced datasets such that |<italic>P</italic>| = |<italic>N</italic>|, so that we have a balanced dataset following the setup of [<xref rid="pone.0226115.ref004" ref-type="bibr">4</xref>], [<xref rid="pone.0226115.ref006" ref-type="bibr">6</xref>], and [<xref rid="pone.0226115.ref005" ref-type="bibr">5</xref>].</p>
      <p>In many applications, it is defined as a requirement to being able to decide whether a new sample belongs to the same distribution as existing samples (inlier), or should be considered as different (outlier). In this case, the training data contains outliers which are defined as instances that are far from (not similar) the others. Inliers are labeled positive, while outliers are labeled negative. The predict method makes use of a threshold on the scoring function computed by the estimator. A positive score for a class indicates that <italic>x</italic> is predicted to be in that class. A negative score indicates otherwise. The decision function is also defined from the scoring function, in such a way that negative values are outliers and non-negative ones are inliers.</p>
    </sec>
    <sec id="sec008">
      <title>2.4. Evaluation method</title>
      <p>Since the training data do not contain any negative data, trained model can only report accurately true positive rate and it is hard to guarantee high accuracy when model apply to a separate validation set consisting of both positive and unlabeled data. In this section, we describe the performance metrics used in this article and then explore the significant challenge of one-class classifier regarding the metrics.</p>
      <sec id="sec009">
        <title>2.4.1 Performance evaluation metrics and the main challenge of one-class classification</title>
        <p>The confusion matrix is normally used as the criterion to assess the performance of the binary classification algorithms. It includes the four elements, true positives rate (TP), the number of positive cases correctly classified; true negatives rate (TN), the number of negative cases correctly classified; false positives rate (FP), the number of misclassified negative cases; and, false negatives rate (FN), the number of misclassified positive cases. Also, measures precision, recall, and F-measure which are defined as Eqs <xref ref-type="disp-formula" rid="pone.0226115.e007">3</xref>–<xref ref-type="disp-formula" rid="pone.0226115.e009">5</xref>.</p>
        <disp-formula id="pone.0226115.e007">
          <alternatives>
            <graphic xlink:href="pone.0226115.e007.jpg" id="pone.0226115.e007g" mimetype="image" position="anchor" orientation="portrait"/>
            <mml:math id="M7">
              <mml:mi>p</mml:mi>
              <mml:mi>r</mml:mi>
              <mml:mi>e</mml:mi>
              <mml:mi>c</mml:mi>
              <mml:mi>i</mml:mi>
              <mml:mi>s</mml:mi>
              <mml:mi>i</mml:mi>
              <mml:mi>o</mml:mi>
              <mml:mi>n</mml:mi>
              <mml:mo>=</mml:mo>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mi>T</mml:mi>
                  <mml:mi>P</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>T</mml:mi>
                  <mml:mi>P</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mi>F</mml:mi>
                  <mml:mi>P</mml:mi>
                </mml:mrow>
              </mml:mfrac>
            </mml:math>
          </alternatives>
          <label>(3)</label>
        </disp-formula>
        <disp-formula id="pone.0226115.e008">
          <alternatives>
            <graphic xlink:href="pone.0226115.e008.jpg" id="pone.0226115.e008g" mimetype="image" position="anchor" orientation="portrait"/>
            <mml:math id="M8">
              <mml:mi>r</mml:mi>
              <mml:mi>e</mml:mi>
              <mml:mi>c</mml:mi>
              <mml:mi>a</mml:mi>
              <mml:mi>l</mml:mi>
              <mml:mi>l</mml:mi>
              <mml:mo>=</mml:mo>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mi>T</mml:mi>
                  <mml:mi>P</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>T</mml:mi>
                  <mml:mi>P</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mi>F</mml:mi>
                  <mml:mi>N</mml:mi>
                </mml:mrow>
              </mml:mfrac>
            </mml:math>
          </alternatives>
          <label>(4)</label>
        </disp-formula>
        <disp-formula id="pone.0226115.e009">
          <alternatives>
            <graphic xlink:href="pone.0226115.e009.jpg" id="pone.0226115.e009g" mimetype="image" position="anchor" orientation="portrait"/>
            <mml:math id="M9">
              <mml:mi>F</mml:mi>
              <mml:mo>-</mml:mo>
              <mml:mi>m</mml:mi>
              <mml:mi>e</mml:mi>
              <mml:mi>a</mml:mi>
              <mml:mi>s</mml:mi>
              <mml:mi>u</mml:mi>
              <mml:mi>r</mml:mi>
              <mml:mi>e</mml:mi>
              <mml:mo>=</mml:mo>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mn>2</mml:mn>
                  <mml:mi mathvariant="normal">*</mml:mi>
                  <mml:mi>p</mml:mi>
                  <mml:mi>r</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:mi>c</mml:mi>
                  <mml:mi>i</mml:mi>
                  <mml:mi>s</mml:mi>
                  <mml:mi>i</mml:mi>
                  <mml:mi>o</mml:mi>
                  <mml:mi>n</mml:mi>
                  <mml:mi mathvariant="normal">*</mml:mi>
                  <mml:mi>r</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:mi>c</mml:mi>
                  <mml:mi>a</mml:mi>
                  <mml:mi>l</mml:mi>
                  <mml:mi>l</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>p</mml:mi>
                  <mml:mi>r</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:mi>c</mml:mi>
                  <mml:mi>i</mml:mi>
                  <mml:mi>s</mml:mi>
                  <mml:mi>i</mml:mi>
                  <mml:mi>o</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mi>r</mml:mi>
                  <mml:mi>e</mml:mi>
                  <mml:mi>c</mml:mi>
                  <mml:mi>a</mml:mi>
                  <mml:mi>l</mml:mi>
                  <mml:mi>l</mml:mi>
                </mml:mrow>
              </mml:mfrac>
            </mml:math>
          </alternatives>
          <label>(5)</label>
        </disp-formula>
        <p>One of the main significant challenge in one-class classification context is the evaluation of the classifier [<xref rid="pone.0226115.ref025" ref-type="bibr">25</xref>]. According to the precision formula, the absence of negative samples in training set makes it impossible to estimate such a classical performance measures using this formula. The confusion matrix is required to calculate all four elements. In situations that there are no negative samples, only TP and FN can be calculated. Therefore, according to the definition, only recall can be estimated but calculating precision requires FP which is not available. Alternatively the following formula proposed in [<xref rid="pone.0226115.ref026" ref-type="bibr">26</xref>] is introduced as the model selection criteria:
<disp-formula id="pone.0226115.e010"><alternatives><graphic xlink:href="pone.0226115.e010.jpg" id="pone.0226115.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:math></alternatives><label>(6)</label></disp-formula>
<disp-formula id="pone.0226115.e011"><alternatives><graphic xlink:href="pone.0226115.e011.jpg" id="pone.0226115.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">P</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(7)</label></disp-formula>
Where X and Y present the input vector and the real label vector, respectively. According to these criteria, recall can be estimated as the proportion of correctly predicted positive data from the only positive data in the validation set, and <italic>P</italic>[<italic>f</italic>(<italic>x</italic>) = 1] can be estimated as the proportion of predicted positive data from the whole validation set, consist of positive and unlabeled data [<xref rid="pone.0226115.ref027" ref-type="bibr">27</xref>]. Hence, from a probabilistic point of view, the recall is the probability that a real positive case, <italic>Y</italic> = 1, is correctly predicted as positive by the classification function <italic>f</italic>(<italic>x</italic>), and the precision is the probability of a situation in which a predicted positive instance is really a positive instance, <italic>Y</italic> = 1. We apply this idea to our method and compare the results.</p>
      </sec>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec010">
    <title>3. Results and discussion</title>
    <p>Here we present the experimental results achieved using OCSVM. We also compare the results achieved from traditional two-class classifiers with our new one-class classification model. For running all the experiments, we use a PC equipped with 5 Intel cores CPU with 2.4GH frequency and 4G of RAM. The system requirement for running our model demonstrates the efficiency of training OCSVM.</p>
    <sec id="sec011">
      <title>3.1. The evaluation of the proposed method</title>
      <p>In this part, we aim at investigating how well the proposed method can produce more reliable results compared to the other methods by presenting the achieved results for the disease in question, AML cancer. In order to test our proposed model, we separate positive data to 70%-30% to employ as training and testing sets, respectively. In this way, we make sure that an independent test set has never been used for parameter tuning to avoid overfitting. We also employ unlabeled set to detect positive genes among unlabeled ones.</p>
      <sec id="sec012">
        <title>3.1.1. The results of the OCSVM</title>
        <p>Here we present the results of our proposed method. As it is shown in <xref ref-type="fig" rid="pone.0226115.g002">Fig 2</xref>, using linear kernel, we obtained better results compared to RBF kernel. Therefore, we report the results of the method using linear kernel. The results presented in <xref rid="pone.0226115.t001" ref-type="table">Table 1</xref> shows the precision, recall, and F-measure using linear and RBF kernel as 99.6% and 95.7%, respectively. As also shown in <xref rid="pone.0226115.t001" ref-type="table">Table 1</xref>, OCSVM is an even-break point support method since precision and recall have almost equal values. It means that this method does not sacrifice precision in favor of recall and conversely.</p>
        <table-wrap id="pone.0226115.t001" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0226115.t001</object-id>
          <label>Table 1</label>
          <caption>
            <title>The results of OCSVM with linear and RBF kernel.</title>
          </caption>
          <alternatives>
            <graphic id="pone.0226115.t001g" xlink:href="pone.0226115.t001"/>
            <table frame="hsides" rules="groups">
              <colgroup span="1">
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
                <col align="left" valign="middle" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <th align="left" rowspan="1" colspan="1">Kernel</th>
                  <th align="left" rowspan="1" colspan="1">Precision</th>
                  <th align="left" rowspan="1" colspan="1">Recall</th>
                  <th align="left" rowspan="1" colspan="1">F-measure</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" rowspan="1" colspan="1">
                    <bold>RBF</bold>
                  </td>
                  <td align="char" char="." rowspan="1" colspan="1">95.70</td>
                  <td align="char" char="." rowspan="1" colspan="1">95.70</td>
                  <td align="char" char="." rowspan="1" colspan="1">95.70</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">
                    <bold>Linear</bold>
                  </td>
                  <td align="char" char="." rowspan="1" colspan="1">
                    <bold>99.61</bold>
                  </td>
                  <td align="char" char="." rowspan="1" colspan="1">
                    <bold>99.61</bold>
                  </td>
                  <td align="char" char="." rowspan="1" colspan="1">
                    <bold>99.61</bold>
                  </td>
                </tr>
              </tbody>
            </table>
          </alternatives>
        </table-wrap>
        <fig id="pone.0226115.g002" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pone.0226115.g002</object-id>
          <label>Fig 2</label>
          <caption>
            <title>The results of OCSVM Method with linear and RBF kernel.</title>
          </caption>
          <graphic xlink:href="pone.0226115.g002"/>
        </fig>
      </sec>
    </sec>
    <sec id="sec013">
      <title>3.2. Comparing the results with previous studies</title>
      <p>The most significant aspects which are considered in disease-gene prediction are: 1) the classification method, 2) the biological features, and 3) the feature representation methods. As the all previous studies have utilized binary classifiers, in this study, we employ one-class classifier as the classification method to solve this intrinsic one-class problem and to compare it with the well-known two-class classifiers as well as positive-unlabeled (PU) learning methods. To the best of our knowledge, our proposed method is the first to design a one-class classifier to identify disease genes. As discussed in the Introduction Section, studies that used PU learning techniques also used two-class classifiers for their classification method [<xref rid="pone.0226115.ref011" ref-type="bibr">11</xref>–<xref rid="pone.0226115.ref013" ref-type="bibr">13</xref>, <xref rid="pone.0226115.ref016" ref-type="bibr">16</xref>]. Among methods in which used PU learning, recently proposed model called C-PUGP is opted for comparison. In the case of two-class classifier, we also choose three state-of-the-art classifiers which have been widely used for this problem (SVM, KNN, and DT). To conduct this comparison, we use feature vectors that is derived from gene expression information which has been shown effective to tackle this problem. Our main aim is to show the preference of one-class classifier compared to the recent (C-PUGP) and most widely used classical classifiers (SVM, KNN, and DT) using same set of features. In future, our aim is to extend this work using a larger benchmark to be able to directly compare our method with other methods such as deep learning techniques.</p>
      <p>We show the comparison between our proposed method and three state-of-the-art traditional binary-class classifiers such as those employed in Smalter’s method [<xref rid="pone.0226115.ref006" ref-type="bibr">6</xref>], Xu’s method [<xref rid="pone.0226115.ref005" ref-type="bibr">5</xref>], and PROSPECTR [<xref rid="pone.0226115.ref004" ref-type="bibr">4</xref>], as well as Positive-Unlabeled learning method (C-PUGP) [<xref rid="pone.0226115.ref016" ref-type="bibr">16</xref>]. All the five methods used the same group of training and test set for fair comparison and results are presented in <xref rid="pone.0226115.t002" ref-type="table">Table 2</xref> and the relevant charts are depicted in Figs <xref ref-type="fig" rid="pone.0226115.g003">3</xref>–<xref ref-type="fig" rid="pone.0226115.g005">5</xref>.</p>
      <fig id="pone.0226115.g003" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0226115.g003</object-id>
        <label>Fig 3</label>
        <caption>
          <title>The comparison between OCSVM and other methods for precision.</title>
        </caption>
        <graphic xlink:href="pone.0226115.g003"/>
      </fig>
      <fig id="pone.0226115.g004" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0226115.g004</object-id>
        <label>Fig 4</label>
        <caption>
          <title>The comparison between OCSVM and other methods for recall.</title>
        </caption>
        <graphic xlink:href="pone.0226115.g004"/>
      </fig>
      <fig id="pone.0226115.g005" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0226115.g005</object-id>
        <label>Fig 5</label>
        <caption>
          <title>The comparison between OCSVM and other methods for F-Measure.</title>
        </caption>
        <graphic xlink:href="pone.0226115.g005"/>
      </fig>
      <table-wrap id="pone.0226115.t002" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pone.0226115.t002</object-id>
        <label>Table 2</label>
        <caption>
          <title>The comparison among methods (precision, recall, and F-measure).</title>
        </caption>
        <alternatives>
          <graphic id="pone.0226115.t002g" xlink:href="pone.0226115.t002"/>
          <table frame="hsides" rules="groups">
            <colgroup span="1">
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
              <col align="left" valign="middle" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <th align="left" rowspan="1" colspan="1">Method</th>
                <th align="left" rowspan="1" colspan="1">Precision</th>
                <th align="left" rowspan="1" colspan="1">Recall</th>
                <th align="left" rowspan="1" colspan="1">F-measure</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1"><bold>PROSPCTOR</bold> [<xref rid="pone.0226115.ref004" ref-type="bibr">4</xref>]</td>
                <td align="char" char="." rowspan="1" colspan="1">82.21</td>
                <td align="char" char="." rowspan="1" colspan="1">82.54</td>
                <td align="char" char="." rowspan="1" colspan="1">82.36</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"><bold>Xu’s method</bold> [<xref rid="pone.0226115.ref005" ref-type="bibr">5</xref>]</td>
                <td align="char" char="." rowspan="1" colspan="1">93.70</td>
                <td align="char" char="." rowspan="1" colspan="1">82.33</td>
                <td align="char" char="." rowspan="1" colspan="1">87.64</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"><bold>Smalter method</bold> [<xref rid="pone.0226115.ref006" ref-type="bibr">6</xref>]</td>
                <td align="char" char="." rowspan="1" colspan="1">90.66</td>
                <td align="char" char="." rowspan="1" colspan="1">88.57</td>
                <td align="char" char="." rowspan="1" colspan="1">89.60</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"><bold>C-PUGP</bold> [<xref rid="pone.0226115.ref016" ref-type="bibr">16</xref>]</td>
                <td align="char" char="." rowspan="1" colspan="1">92.92</td>
                <td align="char" char="." rowspan="1" colspan="1">88.41</td>
                <td align="char" char="." rowspan="1" colspan="1">90.61</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>OCSVM</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>99.61</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>99.61</bold>
                </td>
                <td align="char" char="." rowspan="1" colspan="1">
                  <bold>99.61</bold>
                </td>
              </tr>
            </tbody>
          </table>
        </alternatives>
      </table-wrap>
      <p>According to the precision and recall shown in <xref rid="pone.0226115.t002" ref-type="table">Table 2</xref>, our one-class model is able to predict the positive instances with the highest performance. As shown in this table, KNN and C-PUGP achieve 93.7% and 92.9% precision, respectively, approximately 5% and 6% lower compared to those from the OCSVM. Also, reported recall for C-PUGP and SVM are both almost 88% which are and roughly 11% lower compared to those from the OCSVM. The overall results indicate that the C-PUGP is ranked after the OCSVM, according to its F-measure value of 90.6% which is 9% lower than the OCSVM. It also shows that C-PUGP can handle the unlabeled genes for distinguishing the hidden disease genes in the test set better than other methods. Also, it can be seen in <xref rid="pone.0226115.t002" ref-type="table">Table 2</xref> that the minimum value for precision and recall for other two-class classifiers are reported for DT with 82.2% precision and for KNN with 82.3% recall. Moreover, <xref rid="pone.0226115.t002" ref-type="table">Table 2</xref> confirms that DT reports the lowest value for F-measure as well (82.3%) which is 17.2% lower than those from the OCSVM. In general, better results achieved using the OCSVM compared to the other methods demonstrates the benefit of one-class classification over the conventional binary-class classification method.</p>
      <p>While the binary-class classifiers employ noisy unlabeled set as negative set which is not fully reliable, one-class classifier enjoy the advantages of only using disease genes (one class) without considering other class (non-disease genes) to produce more reliable results. Since there is no proven method to separate negative observations in the unlabeled set, the classifiers that use the unlabeled set in the learning phase are more prone to error. Therefore, it is the advantage of the OCSVM method in which it uses the disease gene information to find disease genes, and unlabeled genes do not appear in the training set to build the model. Indeed, biologists do the same way in their experiments as well. For them, finding non-disease genes is not an aim and priority. Instead they are interested in finding disease genes based on the signs appear on the relevant disease genes. Moreover, using gene expression profile leads to a high performance as it can be seen from the results. In other words, both feature set (biological view) and method (computational view) have significant effect on the performance of identification of candidate disease gene. The OCSVM method and our extracted AML benchmark are publicly available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/imandehzangi/OCSVM">https://github.com/imandehzangi/OCSVM</ext-link>.</p>
    </sec>
  </sec>
  <sec sec-type="conclusions" id="sec014">
    <title>4. Conclusion</title>
    <p>Machine learning approaches have been widely used to predict novel disease-causing genes. Despite substantial advancement in disease gene recognition, there are still many genes that are yet to be discovered. Since there are no real negative samples in this problem, selecting a suitable computational method that could encounter this inherent limitation can be considered as a solution with maximum reliability. In this paper, we propose OCSVM as a one-class classification method, to classify and predict novel disease genes from a large number of unknown genes using gene expression profile information. This model is build using one-class model of the support vector machine classifier. As the ultimate goal of one-class classifier is separating positive samples from other ones, we use it to find disease genes (positive set) which has the similar objective. In this specific problem, the main aim is to identify disease genes while identifying non-disease genes are of less or no significant. Here an independent test set is employed to evaluate the proposed method. We also employ unlabeled set to detect positive genes among unlabeled ones to avoid overfitting. The results achieved using our proposed method indicate significant improvement over those methods found in the literature (6.6%, 11.1%, and 9% in terms of precision, recall, and F-measure, respectively).</p>
    <p>We believe our model can be used in wide range of problems in Bioinformatics and computational biology. OCSVM codes and our extracted AML benchmark are publicly available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/imandehzangi/OCSVM">https://github.com/imandehzangi/OCSVM</ext-link>. Here we conducted our experiments for the AML cancer to investigate the ability of one-class classifier to predict disease-gene association. However, in our future work, we will extend our experiments and investigate the use of the one-class classifier for other diseases.</p>
  </sec>
  <sec sec-type="supplementary-material" id="sec015">
    <title>Supporting information</title>
    <supplementary-material content-type="local-data" id="pone.0226115.s001">
      <label>S1 File</label>
      <caption>
        <title>Supplementary material.docx.</title>
        <p>Detailed Information of our extracted Dataset.</p>
        <p>(DOCX)</p>
      </caption>
      <media xlink:href="pone.0226115.s001.docx">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pone.0226115.s002">
      <label>S2 File</label>
      <caption>
        <title>Positive_samples.csv.</title>
        <p>The gene expression matrix for a total of 1174 positive genes.</p>
        <p>(CSV)</p>
      </caption>
      <media xlink:href="pone.0226115.s002.csv">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
    <supplementary-material content-type="local-data" id="pone.0226115.s003">
      <label>S3 File</label>
      <caption>
        <title>EXP.csv.</title>
        <p>The complete gene expression matrix.</p>
        <p>(CSV)</p>
      </caption>
      <media xlink:href="pone.0226115.s003.csv">
        <caption>
          <p>Click here for additional data file.</p>
        </caption>
      </media>
    </supplementary-material>
  </sec>
</body>
<back>
  <ref-list>
    <title>References</title>
    <ref id="pone.0226115.ref001">
      <label>1</label>
      <mixed-citation publication-type="other">Luo, P., Tian, L. P., Ruan, J., and Wu, F. X., Identifying disease genes from PPI networks weighted by gene expression under different conditions. in 2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). 2016. IEEE.</mixed-citation>
    </ref>
    <ref id="pone.0226115.ref002">
      <label>2</label>
      <mixed-citation publication-type="journal"><name><surname>Asif</surname><given-names>M.</given-names></name>, <name><surname>Martiniano</surname><given-names>H. F.</given-names></name>, <name><surname>Vicente</surname><given-names>A. M.</given-names></name>, and <name><surname>Couto</surname><given-names>F. M.</given-names></name>, <article-title>Identifying disease genes using machine learning and gene functional similarities, assessed through Gene Ontology</article-title>. <source>PloS one</source>, <year>2018</year><volume>13</volume>(<issue>12</issue>): p. <fpage>e0208626</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0208626</pub-id><?supplied-pmid 30532199?><pub-id pub-id-type="pmid">30532199</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref003">
      <label>3</label>
      <mixed-citation publication-type="journal"><name><surname>McBride</surname><given-names>D. L.</given-names></name>, <article-title>Large Genetic Study Uncovers 14 New Genes Responsible for Developmental Disorders in Children</article-title>. <source>Journal of pediatric nursing</source>, <year>2017</year><volume>35</volume>: p. <fpage>1</fpage>–<lpage>2</lpage>. <pub-id pub-id-type="doi">10.1016/j.pedn.2017.02.002</pub-id><?supplied-pmid 28728758?><pub-id pub-id-type="pmid">28728758</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref004">
      <label>4</label>
      <mixed-citation publication-type="journal"><name><surname>Adie</surname><given-names>E. A.</given-names></name>, <name><surname>Adams</surname><given-names>R. R.</given-names></name>, <name><surname>Evans</surname><given-names>K. L.</given-names></name>, <name><surname>Porteous</surname><given-names>D. J.</given-names></name>, and <name><surname>Pickard</surname><given-names>B. S.</given-names></name>, <article-title>Speeding disease gene discovery by sequence based candidate prioritization</article-title>. <source>BMC bioinformatics</source>, <year>2005</year><volume>6</volume>(<issue>1</issue>): p. <fpage>55</fpage>.<pub-id pub-id-type="pmid">15766383</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref005">
      <label>5</label>
      <mixed-citation publication-type="journal"><name><surname>Xu</surname><given-names>J.</given-names></name> and <name><surname>Li</surname><given-names>Y.</given-names></name>, <article-title>Discovering disease-genes by topological features in human protein–protein interaction network</article-title>. <source>Bioinformatics</source>, <year>2006</year>
<volume>22</volume>(<issue>22</issue>): p. <fpage>2800</fpage>–<lpage>2805</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btl467</pub-id>
<?supplied-pmid 16954137?><pub-id pub-id-type="pmid">16954137</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref006">
      <label>6</label>
      <mixed-citation publication-type="other">Smalter, A., Lei, S. F., and Chen, X. W., Human disease-gene classification with integrative sequence-based and topological features of protein-protein interaction networks. in Bioinformatics and Biomedicine, 2007. BIBM 2007. IEEE International Conference on. 2007. IEEE.</mixed-citation>
    </ref>
    <ref id="pone.0226115.ref007">
      <label>7</label>
      <mixed-citation publication-type="journal"><name><surname>Zhou</surname><given-names>H.</given-names></name> and <name><surname>Skolnick</surname><given-names>J.</given-names></name>, <article-title>A knowledge-based approach for predicting gene–disease associations</article-title>. <source>Bioinformatics</source>, <year>2016</year>
<volume>32</volume>(<issue>18</issue>): p. <fpage>2831</fpage>–<lpage>2838</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btw358</pub-id>
<?supplied-pmid 27283949?><pub-id pub-id-type="pmid">27283949</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref008">
      <label>8</label>
      <mixed-citation publication-type="journal"><name><surname>Ata</surname><given-names>S. K.</given-names></name>, <name><surname>Ou-Yang</surname><given-names>L.</given-names></name>, <name><surname>Fang</surname><given-names>Y.</given-names></name>, <name><surname>Kwoh</surname><given-names>C. K.</given-names></name>, <name><surname>Wu</surname><given-names>M.</given-names></name>, and <name><surname>Li</surname><given-names>X. L.</given-names></name>, <article-title>Integrating node embeddings and biological annotations for genes to predict disease-gene associations</article-title>. <source>BMC systems biology</source>, <year>2018</year><volume>12</volume>(<issue>9</issue>): p. <fpage>138</fpage>.<pub-id pub-id-type="pmid">30598097</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref009">
      <label>9</label>
      <mixed-citation publication-type="journal"><name><surname>Luo</surname><given-names>P.</given-names></name>, <name><surname>Li</surname><given-names>Y.</given-names></name>, <name><surname>Tian</surname><given-names>L. P.</given-names></name>, and <name><surname>Wu</surname><given-names>F. X.</given-names></name>, <article-title>Enhancing the prediction of disease—gene associations with multimodal deep learning</article-title>. <source>Bioinformatics</source>, <year>2019</year>.</mixed-citation>
    </ref>
    <ref id="pone.0226115.ref010">
      <label>10</label>
      <mixed-citation publication-type="other">Han, P., Yang, P., Zhao, P., Shang, S., Liu, Y., Zhou, J., et al., GCN-MF: Disease-Gene Association Identification By Graph Convolutional Networks and Matrix Factorization. in Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. 2019. ACM.</mixed-citation>
    </ref>
    <ref id="pone.0226115.ref011">
      <label>11</label>
      <mixed-citation publication-type="journal"><name><surname>Mordelet</surname><given-names>F.</given-names></name> and <name><surname>Vert</surname><given-names>J. P.</given-names></name>, <article-title>ProDiGe: Prioritization Of Disease Genes with multitask machine learning from positive and unlabeled examples</article-title>. <source>BMC bioinformatics</source>, <year>2011</year>
<volume>12</volume>(<issue>1</issue>): p. <fpage>389</fpage>.<pub-id pub-id-type="pmid">21977986</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref012">
      <label>12</label>
      <mixed-citation publication-type="journal"><name><surname>Yang</surname><given-names>P.</given-names></name>, <name><surname>Li</surname><given-names>X. L.</given-names></name>, <name><surname>Mei</surname><given-names>J. P.</given-names></name>, <name><surname>Kwoh</surname><given-names>C. K.</given-names></name>, and <name><surname>Ng</surname><given-names>S. K.</given-names></name>, <article-title>Positive-unlabeled learning for disease gene identification</article-title>. <source>Bioinformatics</source>, <year>2012</year><volume>28</volume>(<issue>20</issue>): p. <fpage>2640</fpage>–<lpage>2647</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bts504</pub-id><?supplied-pmid 22923290?><pub-id pub-id-type="pmid">22923290</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref013">
      <label>13</label>
      <mixed-citation publication-type="journal"><name><surname>Jowkar</surname><given-names>G. H.</given-names></name> and <name><surname>Mansoori</surname><given-names>E. G.</given-names></name>, <article-title>Perceptron ensemble of graph-based positive-unlabeled learning for disease gene identification</article-title>. <source>Computational biology and chemistry</source>, <year>2016</year>
<volume>64</volume>: p. <fpage>263</fpage>–<lpage>270</lpage>. <pub-id pub-id-type="doi">10.1016/j.compbiolchem.2016.07.004</pub-id>
<?supplied-pmid 27475237?><pub-id pub-id-type="pmid">27475237</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref014">
      <label>14</label>
      <mixed-citation publication-type="journal"><name><surname>Yousef</surname><given-names>A.</given-names></name> and <name><surname>Charkari</surname><given-names>N.M.</given-names></name>, <article-title>SFM: a novel sequence-based fusion method for disease genes identification and prioritization</article-title>. <source>Journal of theoretical biology</source>, <year>2015</year>
<volume>383</volume>: p. <fpage>12</fpage>–<lpage>19</lpage>. <pub-id pub-id-type="doi">10.1016/j.jtbi.2015.07.010</pub-id>
<?supplied-pmid 26209022?><pub-id pub-id-type="pmid">26209022</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref015">
      <label>15</label>
      <mixed-citation publication-type="journal"><name><surname>S Singh-Blom</surname><given-names>U. M.</given-names></name>, <name><surname>Natarajan</surname><given-names>N.</given-names></name>, <name><surname>Tewari</surname><given-names>A.</given-names></name>, <name><surname>Woods</surname><given-names>J. O.</given-names></name>, <name><surname>Dhillon</surname><given-names>I. S.</given-names></name>, and <name><surname>Marcotte</surname><given-names>E. M.</given-names></name>, <article-title>Prediction and validation of gene-disease associations using methods inspired by social network analyses</article-title>. <source>PloS one</source>, <year>2013</year><volume>8</volume>(<issue>5</issue>): p. <fpage>e58977</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0058977</pub-id><?supplied-pmid 23650495?><pub-id pub-id-type="pmid">23650495</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref016">
      <label>16</label>
      <mixed-citation publication-type="journal"><name><surname>Vasighizaker</surname><given-names>A.</given-names></name> and <name><surname>Jalili</surname></name>, <article-title>C-PUGP: A Cluster-based Positive Unlabeled learning method for disease Gene Prediction and prioritization</article-title>. <source>Computational biology and chemistry</source>, <year>2018</year>.</mixed-citation>
    </ref>
    <ref id="pone.0226115.ref017">
      <label>17</label>
      <mixed-citation publication-type="journal"><name><surname>Tatusova</surname><given-names>T.</given-names></name>, <name><surname>DiCuccio</surname><given-names>M.</given-names></name>, <name><surname>Badretdin</surname><given-names>A.</given-names></name>, <name><surname>Chetvernin</surname><given-names>V.</given-names></name>, <name><surname>Nawrocki</surname><given-names>E. P.</given-names></name>, <name><surname>Zaslavsky</surname><given-names>L.</given-names></name>, <etal>et al</etal>, <article-title>NCBI prokaryotic genome annotation pipeline</article-title>. <source>Nucleic acids research</source>, <year>2016</year><volume>44</volume>(<issue>14</issue>): p. <fpage>6614</fpage>–<lpage>6624</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkw569</pub-id><?supplied-pmid 27342282?><pub-id pub-id-type="pmid">27342282</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref018">
      <label>18</label>
      <mixed-citation publication-type="journal"><name><surname>Stirewalt</surname><given-names>D. L.</given-names></name>, <name><surname>Meshinchi</surname><given-names>S.</given-names></name>, <name><surname>Kopecky</surname><given-names>K. J.</given-names></name>, <name><surname>Fan</surname><given-names>W.</given-names></name>, <name><surname>Pogosova-Agadjanyan</surname><given-names>E. L.</given-names></name>, <name><surname>Engel</surname><given-names>J. H.</given-names></name>,<etal>et al</etal>, <article-title>Identification of genes with abnormal expression changes in acute myeloid leukemia</article-title>. <source>Genes, Chromosomes and Cancer</source>, <year>2008</year><volume>47</volume>(<issue>1</issue>): p. <fpage>8</fpage>–<lpage>20</lpage>. <pub-id pub-id-type="doi">10.1002/gcc.20500</pub-id><?supplied-pmid 17910043?><pub-id pub-id-type="pmid">17910043</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref019">
      <label>19</label>
      <mixed-citation publication-type="journal"><name><surname>Yang</surname><given-names>P.</given-names></name>, <name><surname>Li</surname><given-names>X.</given-names></name>, <name><surname>Chua</surname><given-names>H. N.</given-names></name>, <name><surname>Kwoh</surname><given-names>C. K.</given-names></name>, and <name><surname>Ng</surname><given-names>S. K.</given-names></name>, <article-title>Ensemble positive unlabeled learning for disease gene identification</article-title>. <source>PloS one</source>, <year>2014</year><volume>9</volume>(<issue>5</issue>): p. <fpage>e97079</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0097079</pub-id><?supplied-pmid 24816822?><pub-id pub-id-type="pmid">24816822</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref020">
      <label>20</label>
      <mixed-citation publication-type="journal"><name><surname>Maji</surname><given-names>P.</given-names></name>, <name><surname>Shah</surname><given-names>E.</given-names></name>, and <name><surname>Paul</surname><given-names>S.</given-names></name>, <article-title>RelSim: An integrated method to identify disease genes using gene expression profiles and PPIN based similarity measure</article-title>. <source>Information Sciences</source>, <year>2017</year><volume>384</volume>: p. <fpage>110</fpage>–<lpage>125</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0226115.ref021">
      <label>21</label>
      <mixed-citation publication-type="other">Khan, S. S. and Madden, M. G., A survey of recent trends in one class classification. in Irish conference on artificial intelligence and cognitive science. 2009. Springer.</mixed-citation>
    </ref>
    <ref id="pone.0226115.ref022">
      <label>22</label>
      <mixed-citation publication-type="journal"><name><surname>Schölkopf</surname><given-names>B.</given-names></name>, <name><surname>Platt</surname><given-names>J. C.</given-names></name>, <name><surname>Shawe-Taylor</surname><given-names>J.</given-names></name>, <name><surname>Smola</surname><given-names>A. J.</given-names></name>, and <name><surname>Williamson</surname><given-names>R. C.</given-names></name>, <article-title>Estimating the support of a high-dimensional distribution</article-title>. <source>Neural computation</source>, <year>2001</year><volume>13</volume>(<issue>7</issue>): p. <fpage>1443</fpage>–<lpage>1471</lpage>. <pub-id pub-id-type="doi">10.1162/089976601750264965</pub-id><?supplied-pmid 11440593?><pub-id pub-id-type="pmid">11440593</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref023">
      <label>23</label>
      <mixed-citation publication-type="journal"><name><surname>Tax</surname><given-names>D. M.</given-names></name> and <name><surname>Duin</surname><given-names>R.P.</given-names></name>, <article-title>Support vector domain description</article-title>. <source>Pattern recognition letters</source>, <year>1999</year>
<volume>20</volume>(<issue>11–13</issue>): p. <fpage>1191</fpage>–<lpage>1199</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0226115.ref024">
      <label>24</label>
      <mixed-citation publication-type="journal"><name><surname>De Bie</surname><given-names>T.</given-names></name>, <name><surname>Tranchevent</surname><given-names>L. C.</given-names></name>, <name><surname>Van Oeffelen</surname><given-names>L. M.</given-names></name>, and <name><surname>Moreau</surname><given-names>Y.</given-names></name>, <article-title>Kernel-based data fusion for gene prioritization</article-title>. <source>Bioinformatics</source>, <year>2007</year><volume>23</volume>(<issue>13</issue>): p. <fpage>i125</fpage>–<lpage>i132</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btm187</pub-id><?supplied-pmid 17646288?><pub-id pub-id-type="pmid">17646288</pub-id></mixed-citation>
    </ref>
    <ref id="pone.0226115.ref025">
      <label>25</label>
      <mixed-citation publication-type="journal"><name><surname>Tran</surname><given-names>Q. A.</given-names></name>, <name><surname>Li</surname><given-names>X.</given-names></name>, and <name><surname>Duan</surname><given-names>H.</given-names></name>, <article-title>Efficient performance estimate for one-class support vector machine</article-title>. <source>Pattern Recognition Letters</source>, <year>2005</year><volume>26</volume>(<issue>8</issue>): p. <fpage>1174</fpage>–<lpage>1182</lpage>.</mixed-citation>
    </ref>
    <ref id="pone.0226115.ref026">
      <label>26</label>
      <mixed-citation publication-type="other">Lee, W. S. and Liu, B., Learning with positive and unlabeled examples using weighted logistic regression. in ICML. 2003.</mixed-citation>
    </ref>
    <ref id="pone.0226115.ref027">
      <label>27</label>
      <mixed-citation publication-type="other">Liu, B., Dai, Y., Li, X., Lee, W. S., and Philip, S. Y., Building text classifiers using positive and unlabeled examples. in Data Mining, 2003. ICDM 2003. Third IEEE International Conference on. 2003. IEEE.</mixed-citation>
    </ref>
  </ref-list>
</back>
