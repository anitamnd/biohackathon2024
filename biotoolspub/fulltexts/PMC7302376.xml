<?properties open_access?>
<?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?>
<?DTDIdentifier.IdentifierType public?>
<?SourceDTD.DTDName A++V2.4.dtd?>
<?SourceDTD.Version 2.4?>
<?ConverterInfo.XSLTName springer2nlmx2.xsl?>
<?ConverterInfo.Version 1?>
<front>
  <journal-meta>
    <journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id>
    <journal-id journal-id-type="iso-abbrev">BMC Bioinformatics</journal-id>
    <journal-title-group>
      <journal-title>BMC Bioinformatics</journal-title>
    </journal-title-group>
    <issn pub-type="epub">1471-2105</issn>
    <publisher>
      <publisher-name>BioMed Central</publisher-name>
      <publisher-loc>London</publisher-loc>
    </publisher>
  </journal-meta>
  <article-meta>
    <article-id pub-id-type="pmcid">7302376</article-id>
    <article-id pub-id-type="publisher-id">3584</article-id>
    <article-id pub-id-type="doi">10.1186/s12859-020-03584-5</article-id>
    <article-categories>
      <subj-group subj-group-type="heading">
        <subject>Methodology Article</subject>
      </subj-group>
    </article-categories>
    <title-group>
      <article-title>Hap10: reconstructing accurate and long polyploid haplotypes using linked reads</article-title>
    </title-group>
    <contrib-group>
      <contrib contrib-type="author">
        <name>
          <surname>Majidian</surname>
          <given-names>Sina</given-names>
        </name>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author" corresp="yes">
        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1920-659X</contrib-id>
        <name>
          <surname>Kahaei</surname>
          <given-names>Mohammad Hossein</given-names>
        </name>
        <address>
          <email>kahaei@iust.ac.ir</email>
        </address>
        <xref ref-type="aff" rid="Aff1">1</xref>
      </contrib>
      <contrib contrib-type="author">
        <name>
          <surname>de Ridder</surname>
          <given-names>Dick</given-names>
        </name>
        <xref ref-type="aff" rid="Aff2">2</xref>
      </contrib>
      <aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="GRID">grid.411748.f</institution-id><institution-id institution-id-type="ISNI">0000 0001 0387 0587</institution-id><institution>School of Electrical Engineering, </institution><institution>Iran University of Science &amp; Technology, </institution></institution-wrap>Narmak, Tehran, 16846-13114 Iran </aff>
      <aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="GRID">grid.4818.5</institution-id><institution-id institution-id-type="ISNI">0000 0001 0791 5666</institution-id><institution>Bioinformatics Group, </institution><institution>Wageningen University, </institution></institution-wrap>Droevendaalsesteeg 1, 6708PB, Wageningen, The Netherlands </aff>
    </contrib-group>
    <pub-date pub-type="epub">
      <day>18</day>
      <month>6</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="pmc-release">
      <day>18</day>
      <month>6</month>
      <year>2020</year>
    </pub-date>
    <pub-date pub-type="collection">
      <year>2020</year>
    </pub-date>
    <volume>21</volume>
    <elocation-id>253</elocation-id>
    <history>
      <date date-type="received">
        <day>8</day>
        <month>1</month>
        <year>2020</year>
      </date>
      <date date-type="accepted">
        <day>5</day>
        <month>6</month>
        <year>2020</year>
      </date>
    </history>
    <permissions>
      <copyright-statement>© The Author(s) 2020</copyright-statement>
      <license license-type="OpenAccess">
        <license-p><bold>Open Access</bold>This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated in a credit line to the data.</license-p>
      </license>
    </permissions>
    <abstract id="Abs1">
      <sec>
        <title>Background</title>
        <p id="Par1">Haplotype information is essential for many genetic and genomic analyses, including genotype-phenotype associations in human, animals and plants. Haplotype assembly is a method for reconstructing haplotypes from DNA sequencing reads. By the advent of new sequencing technologies, new algorithms are needed to ensure long and accurate haplotypes. While a few linked-read haplotype assembly algorithms are available for diploid genomes, to the best of our knowledge, no algorithms have yet been proposed for polyploids specifically exploiting linked reads.</p>
      </sec>
      <sec>
        <title>Results</title>
        <p id="Par2">The first haplotyping algorithm designed for linked reads generated from a polyploid genome is presented, built on a typical short-read haplotyping method, SDhaP. Using the input aligned reads and called variants, the haplotype-relevant information is extracted. Next, reads with the same barcodes are combined to produce molecule-specific fragments. Then, these fragments are clustered into strongly connected components which are then used as input of a haplotype assembly core in order to estimate accurate and long haplotypes.</p>
      </sec>
      <sec>
        <title>Conclusions</title>
        <p id="Par3">Hap10 is a novel algorithm for haplotype assembly of polyploid genomes using linked reads. The performance of the algorithms is evaluated in a number of simulation scenarios and its applicability is demonstrated on a real dataset of sweet potato.</p>
      </sec>
    </abstract>
    <kwd-group xml:lang="en">
      <title>Keywords</title>
      <kwd>DNA sequence analysis</kwd>
      <kwd>Computational genetics</kwd>
      <kwd>Haplotype</kwd>
      <kwd>Synthetic long reads</kwd>
      <kwd>Linked read</kwd>
      <kwd>10X genomics</kwd>
      <kwd>Polyploid genomes</kwd>
      <kwd>Clustering</kwd>
      <kwd>Mathematical optimization</kwd>
    </kwd-group>
    <custom-meta-group>
      <custom-meta>
        <meta-name>issue-copyright-statement</meta-name>
        <meta-value>© The Author(s) 2020</meta-value>
      </custom-meta>
    </custom-meta-group>
  </article-meta>
</front>
<body>
  <sec id="Sec1">
    <title>Background</title>
    <p id="Par14">Polyploids are organisms that possess three or more copies of each chromosome. There are numerous cases of polyploidy in the animal kingdom, including fish, amphibians and reptiles [<xref ref-type="bibr" rid="CR1">1</xref>]. In plants, economically important crops such as potato, wheat, cotton and oat are polyploids [<xref ref-type="bibr" rid="CR2">2</xref>]. For many genetic and genomic analyses, it is essential to know the sequence of alleles at variant sites corresponding to each homologous chromosome, i.e. the haplotypes. Haplotype information is needed to understand recombination patterns and uncover genotype-phenotype associations, with important applications in medicine [<xref ref-type="bibr" rid="CR3">3</xref>] and plant breeding [<xref ref-type="bibr" rid="CR2">2</xref>]. The development of DNA sequencing technologies, specific protocols and computational tools make it possible to reconstruct the haplotypes of individuals to some extent. Nevertheless, obtaining haplotypes of polyploids remains a challenging computational problem [<xref ref-type="bibr" rid="CR4">4</xref>].</p>
    <p id="Par15">Several algorithms for polyploid haplotyping have been developed in recent years for diploid and polyploid haplotyping [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR6">6</xref>]. In the absence of DNA sequencing errors, the haplotyping problem reduces to a simple clustering if the provided reads are sufficiently long to cover neighbouring variants. If errors have to be taken into account, no polynomial-time solution is known. Therefore, different approximative and heuristic approaches have been used to estimate haplotypes. HapTree [<xref ref-type="bibr" rid="CR7">7</xref>] is a greedy likelihood-based algorithm in which SNPs are added incrementally while keeping the tree of possible solutions to a manageable size. SDhaP [<xref ref-type="bibr" rid="CR8">8</xref>] solves a correlation clustering problem using a gradient method to estimate the haplotypes. H-PoP [<xref ref-type="bibr" rid="CR9">9</xref>], a heuristic algorithm, solves a combinatorial optimization problem called “polyploid balanced optimal partition”. Another approach is to use the minimum fragment removal (MFR) model in which conflicting fragments (due to erroneous reads) are removed. Siragusa et al. devised a new algorithm based on the MFR model, which uses integer linear programming [<xref ref-type="bibr" rid="CR10">10</xref>]. Polyphase, part of WhatsHap [<xref ref-type="bibr" rid="CR11">11</xref>], is a method for polyploid haplotyping developed for short and long reads. Reads are clustered based on a position-based score, and haplotypes are threaded by dynamic programming. Poly-Harsh [<xref ref-type="bibr" rid="CR12">12</xref>] is another method, minimizing the difference between the haplotypes and the input reads using a Gibbs sampling approach. The HapCompass algorithm [<xref ref-type="bibr" rid="CR13">13</xref>] defines a SNP graph, removing a minimum number of weighted edges to obtain unique haplotypes. This is done by finding the spanning tree in such graph. RanBow [<xref ref-type="bibr" rid="CR14">14</xref>], another program developed for short reads, first creates haplotype segments as the consensus sequences of fragments and then a graph in which haplotype segments and their overlaps are nodes resp. edges. The graph is used to merge the overlapping segments and calculate the haplotypeblocks [<xref ref-type="bibr" rid="CR14">14</xref>]. For a recent review on different methods of polyploid haplotyping, see [<xref ref-type="bibr" rid="CR6">6</xref>].</p>
    <p id="Par16">The above-mentioned algorithms are developed solely for short reads generated by Illumina DNA sequencing machines. These produce reads that have a low sequencing error rate (~ 0.1%) but do not provide long-range information, which is key in reconstruction of long haplotypes. Over the last years, a novel category of sequencing technology characterized by long-read sequencing was developed and commercialized by Pacific Biosciences and Oxford Nanopore [<xref ref-type="bibr" rid="CR15">15</xref>]. However, successful application of long-read sequencing for haplotyping is hampered by the still high sequencing error rate and significant costs involved. Although a new technique has been recently been proposed to resolve the issue of high error rate [<xref ref-type="bibr" rid="CR16">16</xref>].</p>
    <p id="Par17">Recently, 10X Genomics developed a linked-read sequencing library preparation strategy, commercialized through their Chromium platform, as a complementary technology to Illumina devices. This platform has the potential to provide long fragments at both low error rate and cost. In brief, the input genomic DNA, as little as 1 ng, is sheared into molecules of ~ 10–100 kbp. Subsequently, these molecules are isolated, partitioned into fragments, tagged with a unique 16 bp barcode, and amplified on beads in an emulsion. The resulting material is then sequenced by normal Illumina paired-end technology, which results in high-throughput reads that contain long-range genomic information through these barcodes [<xref ref-type="bibr" rid="CR17">17</xref>]. The 10X technology described above is one example of a general approach called synthetic long reads (SLRs), in which the low cost and high accuracy of short reads are combined with long range information provided by a barcoding scheme. Besides 10X Genomics, such technologies are commercialized by Illumina, Loop Genomics and Universal Sequencing Technology [<xref ref-type="bibr" rid="CR18">18</xref>]. Such linked reads make it possible to assemble repetitive genomic regions as well as reconstruct long haplotype blocks. 10X Genomics delivers a likelihood-based algorithm in a software package called LongRanger to reconstruct haplotypes of diploid organisms such as humans [<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR19">19</xref>]. HapCUT2 [<xref ref-type="bibr" rid="CR20">20</xref>] includes a program dedicated to linked-read haplotyping of diploids, which assembles the haplotypes to be maximally consistent with the read dataset by exploiting a likelihood-based model. Porubsky et al. proposed using a mixture of linked-read and strand-seq data to improve haplotype assembly [<xref ref-type="bibr" rid="CR21">21</xref>].</p>
    <p id="Par18">However, no polyploid haplotyping algorithm is available at this moment, precluding the application of 10X-based haplotyping to a number of commercial crops and animals. Current polyploid haplotyping algorithms can be used on the obtained reads, ignoring the barcode information, but obviously the reconstructed haplotype blocks would be shorter than possible.</p>
    <p id="Par19">Exploiting the barcode information for haplotyping is possible by leveraging the so-called “fragment file” format. This format is used in preprocessing steps in several haplotyping algorithms [<xref ref-type="bibr" rid="CR8">8</xref>, <xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR22">22</xref>]. The extractHAIRs (Extract HAplotype Informative Reads) program in the HapCUT2 package [<xref ref-type="bibr" rid="CR20">20</xref>] can be used to produce a fragment file based on aligned reads and heterozygous SNPs. Such a file contains only the relevant information from reads: the coded alleles of each read at the SNP position and their quality (see Step 2 of "<xref rid="Sec4" ref-type="sec">Hap++</xref>" Section and the illustrative example in Supplementary information: Figure <xref rid="MOESM1" ref-type="media">S1</xref>). While extractHAIRs is dedicated to diploids and is used for haplotyping based on 10X linked reads, the same concept (with some modifications) may be applied to polyploids. Using the obtained fragment file as input of a haplotype assembly core, SDhaP [<xref ref-type="bibr" rid="CR8">8</xref>], long haplotype blocks of a polyploid can be reconstructed. However, in our simulations for a small genome using the aforementioned approach we obtained poor results in terms of reconstruction rate and vector error rate. Moreover, SDhaP crashes for larger datasets. This indicates that this short-read haplotyping algorithm is currently unable to directly handle linked read data generated from a polyploid genome.</p>
    <p id="Par20">To tackle this computational problem, we designed Hap10 – a first haplotyping software package specifically tailored for 10X linked reads generated from a polyploid genome. We provide a general framework based on SDhaP that allows haplotyping at the chromosome scale. Furthermore, we propose a novel optimization method that generates more accurate haplotypes with almost the same block length.</p>
  </sec>
  <sec id="Sec2">
    <title>Methods</title>
    <p id="Par21">We have developed the Hap10 package to reconstruct haplotypes from a polyploid genome using linked reads. Prior to haplotyping, several processing steps on sequencing reads are required. These include barcode handling, read alignment and variant calling, which are discussed in "<xref rid="Sec3" ref-type="sec">Preparation procedure</xref>" Section. Thereafter, Hap++, a new pipeline for polyploid haplotyping of linked reads is explained in detail in "<xref rid="Sec4" ref-type="sec">Hap++</xref>" Section. This pipeline uses SDhaP as the assembly core. Lastly, the Hap10 algorithm is presented in "<xref rid="Sec8" ref-type="sec">Hap10: an improved assembly core</xref>" Section. This algorithm leverages the Hap++ pipeline, supplemented with a novel optimization based on an augmented Langrangian formulation as the assembly core. "<xref rid="Sec9" ref-type="sec">Experimental setup</xref>" Section concludes by discussing the data and performance measures used for validation of the method.</p>
    <sec id="Sec3">
      <title>Preparation procedure</title>
      <p id="Par22">First, the 16 bp 10X barcode is removed from the beginning of each paired-end read generated by the Illumina device. The barcode is stored as a read tag for further use. The possibility of sequencing errors in the barcode calls for an error correction scheme based on the known set of barcodes. Next, the reads are aligned to the reference genome using the barcode information. The barcodes contain long range information that can help provide a better alignment, particularly in repetitive genomic regions. These steps are performed using the LongRanger package (version 2.2.2) [<xref ref-type="bibr" rid="CR19">19</xref>] provided by 10X Genomics, which generates a binary sequence alignment (BAM) file in which the barcodes are stored in the BX tag of each read. Subsequently, single nucleotide polymorphism (SNP) sites and their genotypes are called using the FreeBayes package (version 1.3.1) [<xref ref-type="bibr" rid="CR23">23</xref>] with “-p 3” and “-p 4” for triploids and tetraploids, respectively and stored as a variant call format (VCF) file. The pipeline is depicted in Fig. <xref rid="Fig1" ref-type="fig">1</xref>.
<fig id="Fig1"><label>Fig. 1</label><caption><p>Preparation procedure for haplotyping of linked read data: barcode correction, read alignment and SNP/genotype calling. The output consists of aligned reads (BAM file) and called variants (VCF file)</p></caption><graphic xlink:href="12859_2020_3584_Fig1_HTML" id="MO1"/></fig></p>
    </sec>
    <sec id="Sec4">
      <title>Hap++</title>
      <p id="Par23">Hap++ is a fast program to reconstruct haplotypes in polyploids by exploiting linked read information. It consists of three main steps:</p>
      <p id="Par24">1) extracting haplotype-relevant information from input BAM and VCF files;</p>
      <p id="Par25">2) extracting molecule-specific fragments;</p>
      <p id="Par26">3) extracting strongly connected components of fragments.</p>
      <p id="Par27">The output of the last step can then be used by SDhaP to assemble the haplotypes. The three steps are described below.</p>
      <sec id="Sec5">
        <title>Step 1. Extracting haplotype information</title>
        <p id="Par28">We first extract data relevant for haplotyping from the BAM and VCF files. As only heterozygous SNPs are informative for haplotyping, we filter out the homozygous variants from the VCF file. Next, we remove reads that cover fewer than two SNPs, since these do not provide any information for haplotyping. Subsequently, we extract the alleles of SNP sites of each read stored in the BAM file. In order to exploit long-range information provided by the barcodes, we combine the obtained fragments originating from the same 10X bead, i.e. with the same barcode. This results in long barcode-specific fragments. If there are two mismatching alleles for a SNP site corresponding to a specific barcode, we choose the one with the higher base quality. The result is a compact fragment file, similar to the output file of extractHAIRS [<xref ref-type="bibr" rid="CR20">20</xref>, <xref ref-type="bibr" rid="CR24">24</xref>].</p>
      </sec>
      <sec id="Sec6">
        <title>Step 2. Extracting molecule-specific fragments</title>
        <p id="Par29">The reads generated from the molecules in the 10X bead have identical barcodes. In an ideal case, the microfluidic device is expected to produce one molecule within each bead. In reality however there are, on average, 10 molecules per bead that originate randomly from one of the haploid chromosomes [<xref ref-type="bibr" rid="CR17">17</xref>]. Therefore, the haplotypic origin of molecules with the same barcode is not identical, as discussed in [<xref ref-type="bibr" rid="CR20">20</xref>]. As a result, parts of fragments in the fragment file are derived from different haplotypes, which misleads the haplotype assembly program. To tackle this issue, we propose a fragment processing scheme to extract molecule-specific fragments from each barcode-specific fragment. This is done by splitting barcode-specific fragments into several parts such that distant parts are retained as individual fragments. To this end, we use the mean-shift clustering algorithm [<xref ref-type="bibr" rid="CR25">25</xref>] by means of its Python implementation from the Scikit-learn package [<xref ref-type="bibr" rid="CR26">26</xref>]. We set the bandwidth of clustering to half of the expected 10X molecule length. This approach is based on the fact that molecule coverage is very low, and thus, molecules with the same barcode are generally distant from each other.</p>
      </sec>
      <sec id="Sec7">
        <title>Step 3. Extracting strongly connected components of fragments</title>
        <p id="Par30">It is crucial to have a decent reference genome, because read alignment to the reference is upstream of haplotyping ("<xref rid="Sec3" ref-type="sec">Preparation procedure</xref>" Section). However, in practice, reference genomes are incomplete and contain assembly gaps (usually represented by Ns). This affects haplotyping: if the reference contains a gap with length comparable with that of the 10X molecules, only few fragments connect the two sides of the gap and sequencing/mapping errors can have undue influence on the haplotyping process.</p>
        <p id="Par31">To prevent such problems, we first create a graph <italic>G</italic> in which fragments are considered as vertices <italic>v</italic> ∈ <italic>G</italic>. The weight <italic>w</italic><sub><italic>ij</italic></sub> of the edge <italic>e</italic><sub><italic>ij</italic></sub> = (<italic>v</italic><sub><italic>i</italic></sub>, <italic>v</italic><sub><italic>j</italic></sub>) between two nodes is calculated as the number of shared SNPs between two corresponding fragments, inspired by SDhaP [<xref ref-type="bibr" rid="CR8">8</xref>]. As a demonstration, we generated such a graph for a read dataset (depicted in Supplementary information: Figure <xref rid="MOESM2" ref-type="media">S2</xref>), in which the length of the 10X DNA molecules is slightly higher than 50 kb, the length of the simulated gap. In this graph, one edge was found to connect two separate parts. This is based on a single molecule covering two distant SNPs in the vicinity of the gap. However, a single barcoded fragment is not enough for linking all haplotypes. Consequently, the accuracy of the whole haplotype block decreases.</p>
        <p id="Par32">As errors other than those due to gaps can lead to spurious edges in <italic>G</italic>, we provide a generic solution based on extracting strongly connected components of fragments. To this end, we exploit an iterative bipartitioning method based on the normalized cut (<italic>NC</italic>) [<xref ref-type="bibr" rid="CR27">27</xref>]. We calculate the normalized Laplacian matrix (<italic>L</italic><sub><italic>N</italic></sub>) of <italic>G</italic> based on the corresponding weight matrix <italic>W</italic>:
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {L}_N={D}^{-\frac{1}{2}}\left(D-W\right){D}^{-\frac{1}{2}}, $$\end{document}</tex-math><mml:math id="M2" display="block"><mml:msub><mml:mi>L</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mi>W</mml:mi></mml:mrow></mml:mfenced><mml:msup><mml:mi>D</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12859_2020_3584_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>where <italic>D</italic> is the degree matrix of the graph, a diagonal matrix with <inline-formula id="IEq1"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {D}_{ii}=\sum \limits_j{w}_{ij} $$\end{document}</tex-math><mml:math id="M4" display="inline"><mml:msub><mml:mi>D</mml:mi><mml:mi mathvariant="italic">ii</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2020_3584_Article_IEq1.gif"/></alternatives></inline-formula>. After calculating the eigenvalue decomposition of <italic>L</italic><sub><italic>N</italic></sub>, we use the eigenvector (<italic>E</italic><sub>2</sub>) that corresponds to the second smallest eigenvalue in order to bipartition the graph. In [<xref ref-type="bibr" rid="CR27">27</xref>], it is shown that minimization of <italic>NC</italic> value is equivalent to minimization of a Rayleigh quotient, <inline-formula id="IEq2"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{x^T{L}_Nx}{x^Tx} $$\end{document}</tex-math><mml:math id="M6" display="inline"><mml:mfrac><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:msub><mml:mi>L</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>x</mml:mi></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12859_2020_3584_Article_IEq2.gif"/></alternatives></inline-formula>. This can be used to show that the second eigenvalue presents the optimum partition in terms of the NC value defined in (2) [<xref ref-type="bibr" rid="CR27">27</xref>]. The sign of the elements of vector <italic>E</italic><sub>2</sub> indicates the affiliation of fragments to either subgraph <italic>G</italic><sub>1</sub> or <italic>G</italic><sub>2</sub>. Then, we calculate the <italic>NC</italic> value:
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ NC\left({G}_1,{G}_2\right)=\frac{\sum \limits_{i\in {G}_1,j\in {G}_2}{w}_{ij}}{\sum \limits_{i\in {G}_1;\forall j}{w}_{ij}}+\frac{\sum \limits_{i\in {G}_1,j\in {G}_2}{w}_{ij}}{\sum \limits_{\forall i;j\in {G}_2}{w}_{ij}}. $$\end{document}</tex-math><mml:math id="M8" display="block"><mml:mi mathvariant="italic">NC</mml:mi><mml:mfenced close=")" open="(" separators=","><mml:msub><mml:mi>G</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>G</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:mo>∀</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi><mml:mo>;</mml:mo><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mi>w</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math><graphic xlink:href="12859_2020_3584_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p>
        <p id="Par33">If <italic>NC</italic> is greater than a pre-specified threshold <italic>t</italic>, we stop the bi-partitioning procedure; otherwise, we continue bi-partitioning for each remaining partition. We set <italic>t</italic> to 0.03 for all simulations throughout the paper. When this step is finished, we output all strongly connected components of fragments as individual fragment files for processing by the assembly core, SDhaP. The Hap++ pipeline is depicted in Fig. <xref rid="Fig2" ref-type="fig">2</xref>. Note that this pipeline can be parallelized; specifically, the assembly core can be run on each strongly connected fragment simultaneously.
<fig id="Fig2"><label>Fig. 2</label><caption><p>Hap++ pipeline. The output of the preparation procedure – BAM and VCF files – is pre-processed to make the haplotyping of 10X data feasible for polyploids. Next, strongly connected components of the molecule-specific fragment graph are extracted and used as input to the assembly core, which yields the haplotype blocks</p></caption><graphic xlink:href="12859_2020_3584_Fig2_HTML" id="MO2"/></fig></p>
      </sec>
    </sec>
    <sec id="Sec8">
      <title>Hap10: an improved assembly core</title>
      <p id="Par34">The Hap10 pipeline leverages the Hap++ pipeline and adds a novel optimization as the assembly core. The goal of a haplotype assembly algorithm is to reconstruct <italic>K</italic> haplotypes <italic>H</italic> = {<italic>h</italic><sub>1</sub>, …, <italic>h</italic><sub><italic>K</italic></sub>} from <italic>N</italic> aligned fragments <italic>R</italic> = {<italic>r</italic><sub>1</sub>, …, <italic>r</italic><sub><italic>N</italic></sub>} generated by DNA sequencing of a <italic>K</italic>-ploid organism. This definition is universal and applies to different sequencing data types. Each <italic>r</italic><sub><italic>i</italic></sub> is assumed to originate from a single haplotype, as is the case for Illumina reads. As we discussed earlier, in linked read technology, we use molecule-specific fragments as <italic>r</italic><sub><italic>i</italic></sub> in our pipeline.</p>
      <p id="Par35">As a basis for Hap10, we use the three-step approach introduced by SDhaP:
<list list-type="simple"><list-item><label>I.</label><p id="Par36">Construct a fragment graph (similar to that of "<xref rid="Sec4" ref-type="sec">Hap++</xref>" Section, Step 2) with weights between fragments (vertices) <italic>i</italic> and <italic>j</italic> calculated as.</p></list-item></list></p>
      <p id="Par37">
        <disp-formula id="Equ3">
          <label>3</label>
          <alternatives>
            <tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {W}_{ij}=\frac{\#\mathrm{mismatched}\ \mathrm{alleles}-\#\mathrm{matched}\ \mathrm{alleles}}{\#\mathrm{shared}\ \mathrm{SNPs}}. $$\end{document}</tex-math>
            <mml:math id="M10" display="block">
              <mml:msub>
                <mml:mi>W</mml:mi>
                <mml:mi mathvariant="italic">ij</mml:mi>
              </mml:msub>
              <mml:mo>=</mml:mo>
              <mml:mfrac>
                <mml:mrow>
                  <mml:mo>#</mml:mo>
                  <mml:mtext>mismatched alleles</mml:mtext>
                  <mml:mo>−</mml:mo>
                  <mml:mo>#</mml:mo>
                  <mml:mtext>matched alleles</mml:mtext>
                </mml:mrow>
                <mml:mrow>
                  <mml:mo>#</mml:mo>
                  <mml:mtext>shared SNPs</mml:mtext>
                </mml:mrow>
              </mml:mfrac>
              <mml:mo>.</mml:mo>
            </mml:math>
            <graphic xlink:href="12859_2020_3584_Article_Equ3.gif" position="anchor"/>
          </alternatives>
        </disp-formula>
        <list list-type="simple">
          <list-item>
            <label>II.</label>
            <p id="Par38">Split the fragments into <italic>K</italic> clusters, exploiting the graph weights.</p>
          </list-item>
          <list-item>
            <label>III.</label>
            <p id="Par39">Combine fragments of each cluster into a single haplotype using majority voting.</p>
          </list-item>
        </list>
      </p>
      <p id="Par40">The reconstructed haplotypes are reported in a text file in a format similar to HapCUT2’s output [<xref ref-type="bibr" rid="CR20">20</xref>] presented in Supplementary information: Table <xref rid="MOESM3" ref-type="media">S1</xref>.</p>
      <p id="Par41">Here, we explore step II of the assembly core. We use max- <italic>K</italic>-cut modelling [<xref ref-type="bibr" rid="CR28">28</xref>] for clustering the graph based on the edge weights <italic>W</italic>, which results in the following convex optimization problem over <italic>X</italic> ∈ <italic>ℝ</italic><sup><italic>N</italic> × <italic>N</italic></sup>:
<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \min Tr(WX)\ \mathrm{s}.\mathrm{t}.{X}_{ij}\ge -\frac{1}{k-1},X\succcurlyeq 0, $$\end{document}</tex-math><mml:math id="M12" display="block"><mml:mo>min</mml:mo><mml:mi mathvariant="italic">Tr</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="italic">WX</mml:mi></mml:mfenced><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi mathvariant="italic">ij</mml:mi></mml:msub><mml:mo>≥</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mo>≽</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12859_2020_3584_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>in which <italic>X</italic> ≽ 0 indicates that <italic>X</italic> is a positive semi-definite matrix. Note that <inline-formula id="IEq3"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\hat{X}}_i $$\end{document}</tex-math><mml:math id="M14" display="inline"><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2020_3584_Article_IEq3.gif"/></alternatives></inline-formula>, the <italic>i</italic>-th column of the optimum <inline-formula id="IEq4"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{X} $$\end{document}</tex-math><mml:math id="M16" display="inline"><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2020_3584_Article_IEq4.gif"/></alternatives></inline-formula>, corresponds to the <italic>i</italic>-th fragment. The matrix <inline-formula id="IEq5"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{X} $$\end{document}</tex-math><mml:math id="M18" display="inline"><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2020_3584_Article_IEq5.gif"/></alternatives></inline-formula> is used to estimate the cluster membership of each fragment using a randomized approach [<xref ref-type="bibr" rid="CR28">28</xref>]. Each fragment is assigned to the <italic>k</italic>-th cluster when the corresponding column is the closest to the <italic>k</italic>-th random vector in terms of inner product [<xref ref-type="bibr" rid="CR29">29</xref>]. To do so, firstly, <italic>K</italic> random vectors {<italic>v</italic><sub>1</sub>, …, <italic>v</italic><sub><italic>K</italic></sub>} are generated, each an <italic>N</italic> × 1 vector with elements drawn from a standard normal distribution. Next, inner products between columns of <inline-formula id="IEq6"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{X} $$\end{document}</tex-math><mml:math id="M20" display="inline"><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2020_3584_Article_IEq6.gif"/></alternatives></inline-formula> and these random vectors are calculated and the <italic>i</italic>-th fragment is assigned to the <italic>k</italic>-th cluster, corresponding to the <italic>k</italic>-th haplotype, if
<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ k=\mathrm{argmax}\ \left\{\left\langle {\hat{X}}_i,{v}_1\right\rangle, \dots, \left\langle {\hat{X}}_i,{v}_K\right\rangle \right\}, $$\end{document}</tex-math><mml:math id="M22" display="block"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mtext>argmax</mml:mtext><mml:mspace width="0.25em"/><mml:mfenced close="}" open="{" separators=",,"><mml:mfenced close="〉" open="〈" separators=","><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>v</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mfenced><mml:mo>…</mml:mo><mml:mfenced close="〉" open="〈" separators=","><mml:msub><mml:mover accent="true"><mml:mi>X</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>v</mml:mi><mml:mi>K</mml:mi></mml:msub></mml:mfenced></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12859_2020_3584_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>in which 〈., .〉 represents the inner product of two vectors.</p>
      <p id="Par42">We exploit dual theory in optimization to solve the semidefinite programming problem (3). Note that the identity matrix is a positive definite matrix, and all its elements are nonnegative. Thus, the identity matrix belongs to the interior of the optimization domain. Thus, the optimization is strictly feasible. Therefore, Slater’s condition is satisfied for the optimization, which immediately results in strong duality (section 5.2.3 of [<xref ref-type="bibr" rid="CR30">30</xref>]). To derive the dual optimization problem of (4), the Lagrangian function can be written as <italic>L</italic>(<italic>X</italic>, <italic>λ</italic>, <italic>Z</italic>)=
<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ Tr(WX)+\sum \limits_t{\lambda}_t\left(\frac{1}{K-1}- Tr\left({A}_t{X}_{\left\{\left(i,j\right)| Ni+j=t\right\}}\right)\right)- Tr(ZX)\ \mathrm{s}.\mathrm{t}.\lambda \ge 0,Z\succcurlyeq 0, $$\end{document}</tex-math><mml:math id="M24" display="block"><mml:mspace width="0.25em"/><mml:mi mathvariant="italic">Tr</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="italic">WX</mml:mi></mml:mfenced><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:msub><mml:mi>λ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mi mathvariant="italic">Tr</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mfenced close="}" open="{" separators="|"><mml:mfenced close=")" open="(" separators=","><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mfenced><mml:mrow><mml:mi mathvariant="italic">Ni</mml:mi><mml:mo>+</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>−</mml:mo><mml:mi mathvariant="italic">Tr</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="italic">ZX</mml:mi></mml:mfenced><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo><mml:mi>λ</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>Z</mml:mi><mml:mo>≽</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12859_2020_3584_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>in which <italic>A</italic><sub><italic>t</italic></sub> is a matrix with the same dimensions as <italic>X</italic> of zeroes with a 1 in the (<italic>i</italic>, <italic>j</italic>)-th element. Then, (6) can be rearranged to
<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ L\left(X,\lambda, Z\right)=\frac{1}{K-1}\sum \limits_t{\lambda}_t+ Tr\left(X\left(W-\sum {\lambda}_t{A}_t-Z\right)\right)\ \mathrm{s}.\mathrm{t}.\lambda \ge 0,Z\succcurlyeq 0. $$\end{document}</tex-math><mml:math id="M26" display="block"><mml:mi>L</mml:mi><mml:mfenced close=")" open="(" separators=",,"><mml:mi>X</mml:mi><mml:mi>λ</mml:mi><mml:mi>Z</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:msub><mml:mi>λ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="italic">Tr</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>X</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>W</mml:mi><mml:mo>−</mml:mo><mml:mo>∑</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>Z</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo><mml:mi>λ</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>Z</mml:mi><mml:mo>≽</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo></mml:math><graphic xlink:href="12859_2020_3584_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par43">Since the second term is affine in <italic>X</italic>, we should make it bounded. To this end, the weight of the affine function should be zero. Thus, the maximization (6) can be simplified to
<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \max \frac{1}{K-1}\sum \limits_t{\lambda}_t\ \mathrm{s}.\mathrm{t}.W-\sum {\lambda}_t{A}_t-Z=0,\lambda \ge 0,Z\succcurlyeq 0. $$\end{document}</tex-math><mml:math id="M28" display="block"><mml:mo>max</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:msub><mml:mi>λ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant="normal">t</mml:mi><mml:mo>.</mml:mo><mml:mi>W</mml:mi><mml:mo>−</mml:mo><mml:mo>∑</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>Z</mml:mi><mml:mo>≽</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo></mml:math><graphic xlink:href="12859_2020_3584_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par44">To achieve an unconstrained optimization, we define the augmented Lagrangian function of the optimization as [<xref ref-type="bibr" rid="CR31">31</xref>]:
<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {L}_{\mu}\left(\lambda, Z,Y\right)=\frac{1}{K-1}\sum \limits_t{\lambda}_t+ Tr\left(Y\left(\ W-\sum {\lambda}_t{A}_t-Z\right)\right)+\frac{\mu }{2}{\left\Vert W-\sum {\lambda}_t{A}_t-Z\right\Vert}^2. $$\end{document}</tex-math><mml:math id="M30" display="block"><mml:msub><mml:mi>L</mml:mi><mml:mi>μ</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=",,"><mml:mi>λ</mml:mi><mml:mi>Z</mml:mi><mml:mi>Y</mml:mi></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:msub><mml:mi>λ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="italic">Tr</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mi>Y</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:mspace width="0.25em"/><mml:mi>W</mml:mi><mml:mo>−</mml:mo><mml:mo>∑</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>Z</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mfrac><mml:mi>μ</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mfenced close="‖" open="‖"><mml:mrow><mml:mi>W</mml:mi><mml:mo>−</mml:mo><mml:mo>∑</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>Z</mml:mi></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>.</mml:mo></mml:math><graphic xlink:href="12859_2020_3584_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula></p>
      <p id="Par45">A novel iterative optimization scheme for solving the max- <italic>K</italic>-cut problem then becomes:</p>
      <p id="Par46">
        <disp-formula id="Equ10">
          <label>10</label>
          <alternatives>
            <tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \left({\lambda}^{i+1},{Z}^{i+1}\right)=\mathrm{argmax}{L}_{\mu}\left(\lambda, Z,{Y}^i\right)\ \mathrm{s}.\mathrm{t}.\lambda \ge 0,Z\succcurlyeq 0,{Y}^{i+1}={Y}^i+{\sigma}_i\left(W-\sum {\lambda}_t^i{A}_t-{Z}^i\right) $$\end{document}</tex-math>
            <mml:math id="M32" display="block">
              <mml:mrow>
                <mml:mo>(</mml:mo>
                <mml:msup>
                  <mml:mrow>
                    <mml:mi>λ</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msup>
                <mml:mo>,</mml:mo>
                <mml:msup>
                  <mml:mrow>
                    <mml:mi>Z</mml:mi>
                  </mml:mrow>
                  <mml:mrow>
                    <mml:mi>i</mml:mi>
                    <mml:mo>+</mml:mo>
                    <mml:mn>1</mml:mn>
                  </mml:mrow>
                </mml:msup>
                <mml:mo>)</mml:mo>
              </mml:mrow>
              <mml:mo>=</mml:mo>
              <mml:mrow>
                <mml:mi mathvariant="normal">a</mml:mi>
                <mml:mi mathvariant="normal">r</mml:mi>
                <mml:mi mathvariant="normal">g</mml:mi>
                <mml:mi mathvariant="normal">m</mml:mi>
                <mml:mi mathvariant="normal">a</mml:mi>
                <mml:mi mathvariant="normal">x</mml:mi>
              </mml:mrow>
              <mml:msub>
                <mml:mrow>
                  <mml:mi>L</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>μ</mml:mi>
                </mml:mrow>
              </mml:msub>
              <mml:mrow>
                <mml:mo>(</mml:mo>
                <mml:mi>λ</mml:mi>
                <mml:mo>,</mml:mo>
                <mml:mi>Z</mml:mi>
                <mml:mo>,</mml:mo>
                <mml:msup>
                  <mml:mrow>
                    <mml:mi>Y</mml:mi>
                  </mml:mrow>
                  <mml:mi>i</mml:mi>
                </mml:msup>
                <mml:mo>)</mml:mo>
              </mml:mrow>
              <mml:mspace width="0.25em"/>
              <mml:mrow>
                <mml:mi mathvariant="normal">s</mml:mi>
              </mml:mrow>
              <mml:mo>.</mml:mo>
              <mml:mrow>
                <mml:mi mathvariant="normal">t</mml:mi>
              </mml:mrow>
              <mml:mo>.</mml:mo>
              <mml:mi>λ</mml:mi>
              <mml:mo>≥</mml:mo>
              <mml:mn>0</mml:mn>
              <mml:mo>,</mml:mo>
              <mml:mi>Z</mml:mi>
              <mml:mo>≽</mml:mo>
              <mml:mn>0</mml:mn>
              <mml:mo>,</mml:mo>
              <mml:msup>
                <mml:mrow>
                  <mml:mi>Y</mml:mi>
                </mml:mrow>
                <mml:mrow>
                  <mml:mi>i</mml:mi>
                  <mml:mo>+</mml:mo>
                  <mml:mn>1</mml:mn>
                </mml:mrow>
              </mml:msup>
              <mml:mo>=</mml:mo>
              <mml:msup>
                <mml:mrow>
                  <mml:mi>Y</mml:mi>
                </mml:mrow>
                <mml:mi>i</mml:mi>
              </mml:msup>
              <mml:mo>+</mml:mo>
              <mml:msub>
                <mml:mrow>
                  <mml:mi>σ</mml:mi>
                </mml:mrow>
                <mml:mi>i</mml:mi>
              </mml:msub>
              <mml:mrow>
                <mml:mo>(</mml:mo>
                <mml:mi>W</mml:mi>
                <mml:mo>−</mml:mo>
                <mml:mo>∑</mml:mo>
                <mml:msubsup>
                  <mml:mrow>
                    <mml:mi>λ</mml:mi>
                  </mml:mrow>
                  <mml:mi>t</mml:mi>
                  <mml:mi>i</mml:mi>
                </mml:msubsup>
                <mml:msub>
                  <mml:mrow>
                    <mml:mi>A</mml:mi>
                  </mml:mrow>
                  <mml:mi>t</mml:mi>
                </mml:msub>
                <mml:mo>−</mml:mo>
                <mml:msup>
                  <mml:mrow>
                    <mml:mi>Z</mml:mi>
                  </mml:mrow>
                  <mml:mi>i</mml:mi>
                </mml:msup>
                <mml:mo>)</mml:mo>
              </mml:mrow>
            </mml:math>
            <graphic xlink:href="12859_2020_3584_Article_Equ10.gif" position="anchor"/>
          </alternatives>
        </disp-formula>
      </p>
      <p id="Par47">Then, the optimality condition of the first optimization results in a linear equation, which is solved by a Newton conjugate gradient approach (Section 10.2 of [<xref ref-type="bibr" rid="CR32">32</xref>]). We stop the iteration when the relative duality gap (defined as <inline-formula id="IEq7"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \frac{obj_p-{obj}_d}{1+{obj}_p+{obj}_d} $$\end{document}</tex-math><mml:math id="M34" display="inline"><mml:mfrac><mml:mrow><mml:msub><mml:mi mathvariant="italic">obj</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi mathvariant="italic">obj</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="italic">obj</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="italic">obj</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math><inline-graphic xlink:href="12859_2020_3584_Article_IEq7.gif"/></alternatives></inline-formula> in which <italic>obj</italic><sub><italic>p</italic></sub> and <italic>obj</italic><sub><italic>d</italic></sub> are the value of primal and dual objective functions, respectively [<xref ref-type="bibr" rid="CR33">33</xref>]) falls below a certain convergence threshold, which we set to 0.01. Note that the smaller this threshold, the longer the runtime but the better the estimate (Supplementary information: Table <xref rid="MOESM4" ref-type="media">S2</xref>). Then, the primal optimal point <italic>X</italic> is found using complementary slackness conditions (section 5.5.2 of [<xref ref-type="bibr" rid="CR31">31</xref>]). To implement the mentioned algorithm, we use the SDPNAL+ package [<xref ref-type="bibr" rid="CR33">33</xref>].</p>
    </sec>
    <sec id="Sec9">
      <title>Experimental setup</title>
      <sec id="Sec10">
        <title>Data</title>
        <p id="Par48">In order to evaluate the performance of the developed pipelines and algorithms, we consider numerous scenarios on both simulated and experimental data. First, we performed extensive simulation experiments using the reference genome of potato (<italic>Solanum tuberosum)</italic> as a basis. We first simulated data based on an arbitrarily selected region of one million base pairs (1 Mb) starting from position 5,032,020 on chromosome 1 and subsequently used the full chromosome 1 sequence (88.6 Mb). We introduce SNPs in the reference at a rate of one per 100 or 1000 (for the 1 MB region) and one per 100 for the full chromosome. We generate synthetic triploid and tetraploid genomes as FASTA files by combining <italic>K</italic> = 3 resp. <italic>K</italic> = 4 mutated copies of the reference sequence using the haplo-generator routine from the Haplosim package [<xref ref-type="bibr" rid="CR4">4</xref>]. This package also produces <italic>K</italic> true haplotypes in a text file, including the genomic positions of SNPs and the corresponding alleles, which are used for evaluation (see "<xref rid="Sec11" ref-type="sec">Performance assessment</xref>" Section).</p>
        <p id="Par49">Subsequently, we simulated several linked-read datasets following the 10X technical specifications, using the LRSIM package [<xref ref-type="bibr" rid="CR34">34</xref>]. We set the number of molecules per bead (−m) as 10 and assigned the number of barcodes (−t) such that the molecule coverage is 0.2, as discussed in the 10X Genomics technical note (No. CG00044). The output of each LRSIM simulation consists of two FASTQ files, containing paired-end reads with length of 2 × 151 bp, in which the first 16 bases are the barcode sequence. The outer distance between the two reads in a pair is set to the default value, 350, with a standard deviation of 35. Then, as described in "<xref rid="Sec3" ref-type="sec">Preparation procedure</xref>" Section, the LongRanger and FreeBayes packages are used for aligning reads and calling SNPs, respectively.</p>
        <p id="Par50">To the best of our knowledge, there is no publicly available, real dataset for a polyploid organism containing true haplotype sets, which makes it hard to determine accuracy. To obtain an impression of the distribution of haplotype block lengths and runtimes, we download 10X raw read data of hexaploid sweet potato (<italic>Ipomoea batatas</italic>) from the NCBI database (accession SRX4706082) [<xref ref-type="bibr" rid="CR35">35</xref>].</p>
      </sec>
      <sec id="Sec11">
        <title>Performance assessment</title>
        <p id="Par51">To evaluate the length of the reconstructed haplotypes, we calculate and report the mean value over all haplotype blocks. To assess the accuracy of each algorithm, we consider two criteria: <bold>reconstruction rate</bold>, a measure of local accuracy; and <bold>vector error rate</bold>, a more global measure. Given reconstructed haplotypes <inline-formula id="IEq8"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{H}=\left\{{\hat{h}}_1,\dots, {\hat{h}}_K\right\} $$\end{document}</tex-math><mml:math id="M36" display="inline"><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfenced close="}" open="{" separators=",,"><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>…</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>K</mml:mi></mml:msub></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2020_3584_Article_IEq8.gif"/></alternatives></inline-formula> and ground truth haplotypes <italic>H</italic> = {<italic>h</italic><sub>1</sub>, …, <italic>h</italic><sub><italic>K</italic></sub>}, the reconstruction rate is defined as:
<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ RR=1-\frac{1}{kL}\ {\min}_p\sum \limits_{k=1}^K{D}_H\left({\hat{h}}_k,{h}_{p_k}\right), $$\end{document}</tex-math><mml:math id="M38" display="block"><mml:mi mathvariant="italic">RR</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi mathvariant="italic">kL</mml:mi></mml:mfrac><mml:mspace width="0.25em"/><mml:msub><mml:mo>min</mml:mo><mml:mi>p</mml:mi></mml:msub><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:msub><mml:mi>D</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=","><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msub></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="12859_2020_3584_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>in which <italic>L</italic> is the haplotype length and <italic>D</italic><sub><italic>H</italic></sub>(., .) is the Hamming distance function, which counts the number of mismatch elements between its arguments. Additionally, <italic>p</italic> is a permutation on the set {1, …, <italic>K</italic>}, and <italic>p</italic><sub><italic>k</italic></sub> is the <italic>k</italic>-th element of <italic>p</italic>. We calculate this criterion for each haplotype block and report the average. The vector error rate is calculated by finding the minimum number of switches needed in haplotype segments in order to match <inline-formula id="IEq9"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \hat{H} $$\end{document}</tex-math><mml:math id="M40" display="inline"><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:math><inline-graphic xlink:href="12859_2020_3584_Article_IEq9.gif"/></alternatives></inline-formula> to <italic>H</italic>; this number is then divided by the haplotype length [<xref ref-type="bibr" rid="CR9">9</xref>, <xref ref-type="bibr" rid="CR24">24</xref>].</p>
        <p id="Par52">Since for real data there is no ground truth for assessing the performance of the estimated haplotype, the mentioned metrics cannot be used. To handle this issue, another metric, the <bold>Minimum Error Correction</bold> (MEC) score, has been frequently used in the literature [<xref ref-type="bibr" rid="CR7">7</xref>, <xref ref-type="bibr" rid="CR8">8</xref>]:
<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ MEC\left(R,\hat{H}\right)=\sum \limits_{i=1}^N{\min}_k{D}_{HE}\left({R}_i,{\hat{h}}_k\right) $$\end{document}</tex-math><mml:math id="M42" display="block"><mml:mi mathvariant="italic">MEC</mml:mi><mml:mfenced close=")" open="(" separators=","><mml:mi>R</mml:mi><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mfenced><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mo>min</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>D</mml:mi><mml:mi mathvariant="italic">HE</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=","><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:mfenced></mml:math><graphic xlink:href="12859_2020_3584_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula>in which <italic>R</italic><sub><italic>i</italic></sub> is the <italic>i</italic>-th pre-processed read ("<xref rid="Sec3" ref-type="sec">Preparation procedure</xref>" Section). For haplotypes with a length of <italic>l</italic>, the extended Hamming distance function is defined as <inline-formula id="IEq10"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {D}_{HE}\left({R}_i,{\hat{h}}_k\right)=\sum \limits_{j=1}^ld\left({R}_i(j),{\hat{h}}_k(j)\right) $$\end{document}</tex-math><mml:math id="M44" display="inline"><mml:msub><mml:mi>D</mml:mi><mml:mi mathvariant="italic">HE</mml:mi></mml:msub><mml:mfenced close=")" open="(" separators=","><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:mfenced><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>l</mml:mi></mml:munderover><mml:mi>d</mml:mi><mml:mfenced close=")" open="(" separators=","><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>j</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>j</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2020_3584_Article_IEq10.gif"/></alternatives></inline-formula>. The value <inline-formula id="IEq11"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ d\left({R}_i(j),{\hat{h}}_k(j)\right) $$\end{document}</tex-math><mml:math id="M46" display="inline"><mml:mi>d</mml:mi><mml:mfenced close=")" open="(" separators=","><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>j</mml:mi></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mfenced close=")" open="("><mml:mi>j</mml:mi></mml:mfenced></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2020_3584_Article_IEq11.gif"/></alternatives></inline-formula> will be one when read <italic>R</italic><sub><italic>i</italic></sub> covers the <italic>j</italic>-th position of haplotype <inline-formula id="IEq12"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\hat{h}}_k $$\end{document}</tex-math><mml:math id="M48" display="inline"><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:math><inline-graphic xlink:href="12859_2020_3584_Article_IEq12.gif"/></alternatives></inline-formula> and both are of the same allele, and will be zero otherwise. To interpret this metric, we should note that MEC shows the extent of match between the reconstructed haplotypes and the read dataset.</p>
      </sec>
    </sec>
  </sec>
  <sec id="Sec12">
    <title>Results</title>
    <p id="Par53">We have developed Hap10, a novel pipeline for haplotyping polyploids based on linked-read (SLR) data. The basis of Hap10 is a set of pre-processing steps called Hap++. After application of Hap++, SDhaP [<xref ref-type="bibr" rid="CR8">8</xref>] can be used as an assembly core. We also propose an alternative core, based on the SDPNAL+ algorithm. The combination of Hap++ and the new assembly core is called Hap10.</p>
    <p id="Par54">To obtain an impression of the performance of SDhaP, Hap++/SDhaP and Hap10, we performed extensive simulations based on real-world data, the potato genome. This allows us to investigate accuracy ("<xref rid="Sec11" ref-type="sec">Performance assessment</xref>" Section) and run time in different scenarios, varying sequence length, coverage, ploidy, heterozygosity etc. ("<xref rid="Sec13" ref-type="sec">Simulated data</xref>" Section). We then apply the pipeline to real-world data to evaluate performance in terms of haplotype block length and run time ("<xref rid="Sec19" ref-type="sec">Real data</xref>" Section).</p>
    <sec id="Sec13">
      <title>Simulated data</title>
      <p id="Par55">We first applied the various algorithms on 10X data simulated based on a relatively short stretch of the potato genome, of 1 Mb ("<xref rid="Sec9" ref-type="sec">Experimental setup</xref>" Section), to learn about the influence of various genome and sequencing characteristics.</p>
      <sec id="Sec14">
        <title>Linked-read information yields longer haplotypes</title>
        <p id="Par56">As a first test, we applied SDhaP to the simulated read data with and without taking the barcode information into account. The program has no problem dealing with data for a region of this length. Without linked-read information, the reconstruction rate and the vector error rate are relatively good, but the reconstructed haplotype blocks are very short, 11.8 SNPs on average (Supplementary information: Table <xref rid="MOESM5" ref-type="media">S3</xref>, first row) as is to be expected.</p>
        <p id="Par57">Taking the linked read information into account here improves average haplotype block length dramatically, to over 6000 SNPs (Supplementary information: Table <xref rid="MOESM5" ref-type="media">S3</xref>, second row compared to the first row). At the same time, the reconstruction rate drops, and the vector error rate increases, indicating low quality haplotypes. This is due to the effect of mixed haplotypic origin of fragments, misleading the haplotype assembly program. It can be also considered the consequence of the poor connections between subgraphs, insufficient for haplotyping, as illustrated in Supplementary information: Figure <xref rid="MOESM2" ref-type="media">S2</xref>. An approach in which haplotypes are calculated independently on three equally sized parts of the region of interest supports this: the average block length decreases, but both reconstruction rate and vector error rate improve (Supplementary information: Table <xref rid="MOESM5" ref-type="media">S3</xref>, third row compared to the second row). This suggests that while SDhaP in principle works for haplotype assembly in polyploids, performance may be improved by pre-processing the data. From here on, all results reported for SDhaP are based on barcode information.</p>
      </sec>
      <sec id="Sec15">
        <title>Preprocessing by hap++ yields shorter, more reliable haplotype blocks</title>
        <p id="Par58">To solve the problems encountered in "<xref rid="Sec13" ref-type="sec">Simulated data</xref>" Section, we developed a novel preprocessing pipeline Hap++, to extract strongly connected components from the fragment graph. This reduces the potential for erroneous haplotype assembly, at the expense of a reduced haplotype block length. We apply Hap++ to triploid and tetraploid data simulated on the 1 Mb region taken from the potato genome, at various levels of coverage (2, 5 and 10 per haploid) and different SNP rates (0.01 and 0.001). We repeated the simulations 5 times and report average haplotype block lengths, reconstruction rates and vector error rates in Fig. <xref rid="Fig3" ref-type="fig">3</xref>.
<fig id="Fig3"><label>Fig. 3</label><caption><p>Average haplotype block length (left column, note the logarithmic scale), reconstruction rate (middle) and vector error rate (right) for different coverage levels. Bars indicate averages, whiskers standard deviation of 5 repeated simulations</p></caption><graphic xlink:href="12859_2020_3584_Fig3_HTML" id="MO3"/></fig></p>
        <p id="Par59">Hap++ indeed yields much shorter haplotype blocks (e.g. 339.9 versus 787.2 Kb for SDhaP for triploid, SNP rate 0.01, coverage 10), but drastically improves performance over SDhaP. The reconstruction rate increases, in particular for the triploid simulations, and the vector error rate drops to below 0.1 for almost all simulations where for SDhaP it can reach as high as 0.6. This indicates that the spurious connection problem discussed before occurs in practice and seriously impacts results. It is clear that the SNP rate has a large influence on performance: at low SNP rates, average haplotype block lengths are shorter and accuracy is higher, again particularly for the triploid simulations.</p>
        <p id="Par60">Figure <xref rid="Fig3" ref-type="fig">3</xref> also shows that performance improves with coverage (as expected), and that a coverage of 2 is so low that all methods make errors, due to the fact that SNPs often cannot even be detected. Hap++ benefits more quickly from increasing coverage than SDhaP. SDhaP performance improves up to a coverage of 10 per haploid and keeps improving, as spurious connections in the fragment graph will increasingly be supported by more connections and errors will be counteracted by solid data: in fact, SDhaP needs 5 times as much coverage to reach a similar vector error rate (Supplementary information: Table <xref rid="MOESM6" ref-type="media">S4</xref>).</p>
        <p id="Par61">Figure <xref rid="Fig4" ref-type="fig">4</xref> shows performance at different ploidy levels. While haplotype block length is invariant to the ploidy level, in most cases more trustworthy haplotypes are attained at higher ploidy levels. To understand this, note that the max-<italic>K</italic>-cut randomized approach (part of the assembly core) is theoretically guaranteed to converge to near the optimal value (by a factor of <inline-formula id="IEq13"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \left(1-\frac{1}{K}+\frac{2\ln K}{K^2}\right) $$\end{document}</tex-math><mml:math id="M50" display="inline"><mml:mfenced close=")" open="("><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>K</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>ln</mml:mo><mml:mi>K</mml:mi></mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfrac></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="12859_2020_3584_Article_IEq13.gif"/></alternatives></inline-formula>, a function increasing in <italic>K,</italic> as presented in Theorem 1 of [<xref ref-type="bibr" rid="CR28">28</xref>]). However, limited precision in the SDP solver means this solution is not always found in practice.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Average haplotype block length (left), reconstruction rate (middle) and vector error rate (right) for different ploidy levels (SNP rate 0.01). Bars indicate averages, whiskers standard deviation of 5 repeated simulations</p></caption><graphic xlink:href="12859_2020_3584_Fig4_HTML" id="MO4"/></fig></p>
      </sec>
      <sec id="Sec16">
        <title>Hap++ deals better with imperfect 10X data</title>
        <p id="Par62">Ideally, the 10X technology ensures each unique barcode is assigned to fragments that originate from a single, long DNA molecule. In practice however, fragmentation is imperfect, leading to shorter molecules, and more than one molecule may receive the same barcode (see "<xref rid="Sec4" ref-type="sec">Hap++</xref>" Section). Hap++ contains a pre-processing step to cluster reads based on the expected molecule size, to avoid the concatenation of different molecules in a single line of the fragment file as much as possible.</p>
        <p id="Par63">Figure <xref rid="Fig5" ref-type="fig">5</xref> (top) shows performance as a function of both the number of molecules that on average receives the same barcode (in simulated data). The difference between SDhaP and Hap++ is striking, in that vector error rate increases drastically with the number of molecules per barcode for SDhaP but remains negligible for Hap++. The Hap++ reconstruction rate decreases somewhat, but remains higher than that of SDhaP up to at least 10 molecules per barcode – which, given the sequence length of 1 Mb and the molecule length of 100 kb entails a significant probability of overlap between molecules with the same barcode.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Average haplotype block length (left), reconstruction rate (middle) and vector error rate (right) for different settings of the 10X linked-read simulation (SNP rate 0.01, tetraploid), varying the number of molecules per bead (top) and the molecule length (bottom). Bars indicate averages, whiskers standard deviation of 5 repeated simulations</p></caption><graphic xlink:href="12859_2020_3584_Fig5_HTML" id="MO5"/></fig></p>
        <p id="Par64">We also varied the length of the 10X molecules in the simulations, from 30, 50 and 100 to 150 kb. Figure <xref rid="Fig5" ref-type="fig">5</xref> (bottom) shows that longer molecules yield better haplotypes in terms of reconstruction rate due to the improved long-range information, but eventually increases the vector error rate, likely due to the increased probability of overlap of such long molecules (150 kb in a 1 Mb region).</p>
      </sec>
      <sec id="Sec17">
        <title>Hap10 improves performance, at considerable computational cost</title>
        <p id="Par65">Figure <xref rid="Fig3" ref-type="fig">3</xref> also includes performance of Hap10, a combination of the Hap++ pre-processing stage with a new assembly core based on the SDPNAL+ algorithm. Overall, Hap10 and Hap++ perform more or less on par, with a slight advantage for Hap10 at higher coverage levels, at lower molecule lengths and when more molecules receive the same barcode. This suggests the Hap10 assembly core is more robust to errors and problems due to imperfect 10X data. However, this comes at a cost: the Hap10 runtime is significantly higher. Table <xref rid="Tab1" ref-type="table">1</xref> reports CPU times for the results reported in Fig. <xref rid="Fig3" ref-type="fig">3</xref>. The pipelines were run on 24 CPU cores of a machine with 48 cores (Intel Xeon Silver 4116) and 754 GiB system memory. Clearly, the pre-processing by Hap++ occurs a time penalty, most visible for lower coverages, which pays off in a quicker runtime of the final SDhaP application, clearly seen at higher coverages. Hap10 is up to two orders of magnitude slower. When this is worth the effort, the pipeline can be run in <italic>accurate mode</italic> (using Hap10 optimization) with high haplotype quality, or in <italic>fast mode</italic> (using Hap++) with reasonable quality, depending on user preference.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>Run times (seconds) of the algorithms compared in Fig. <xref rid="Fig3" ref-type="fig">3</xref></p></caption><table frame="hsides" rules="groups"><thead><tr><th>Ploidy</th><th>SNP rate</th><th>Coverage</th><th>SDhaP</th><th>Hap++</th><th>Hap10</th></tr></thead><tbody><tr><td rowspan="6">Triploid</td><td char="." align="char" rowspan="3">0.001</td><td>2</td><td>4</td><td>53</td><td>419</td></tr><tr><td>5</td><td>24</td><td>54</td><td>2919</td></tr><tr><td>10</td><td>34</td><td>92</td><td>1590</td></tr><tr><td char="." align="char" rowspan="3">0.01</td><td>2</td><td>3</td><td>64</td><td>2590</td></tr><tr><td>5</td><td>150</td><td>162</td><td>8590</td></tr><tr><td>10</td><td>660</td><td>400</td><td>19,221</td></tr><tr><td rowspan="6">Tetraploid</td><td char="." align="char" rowspan="3">0.001</td><td>2</td><td>8</td><td>39</td><td>710</td></tr><tr><td>5</td><td>21</td><td>90</td><td>4119</td></tr><tr><td>10</td><td>65</td><td>204</td><td>13,824</td></tr><tr><td char="." align="char" rowspan="3">0.01</td><td>2</td><td>43</td><td>98</td><td>15,307</td></tr><tr><td>5</td><td>478</td><td>370</td><td>28,598</td></tr><tr><td>10</td><td>1497</td><td>1022</td><td>36,736</td></tr></tbody></table></table-wrap></p>
      </sec>
      <sec id="Sec18">
        <title>Hap++ and Hap10 work on longer sequences</title>
        <p id="Par66">As a final test, we generated linked read data for the full chromosome 1 of the potato genome, simulating a tetraploid genome at a SNP rate of 0.01. The coverage is 10 per haploid genome. Results are reported in Table <xref rid="Tab2" ref-type="table">2</xref>. Notably, SDhaP encountered a segmentation fault in this simulation, leaving us unable to report a result. Hap++ and Hap10 provide haplotypes with the same block lengths, with better accuracy in terms reconstruction rate and vector error rate. Moreover, the MEC between the read set and the reconstructed haplotypes is lower, suggesting a better compatibility between the two. However, as before, the computational cost of Hap10 is significant at approx. Nine hundred CPU hours vs. 12 h for Hap++. The results for H-PoP [<xref ref-type="bibr" rid="CR9">9</xref>] on short reads show a very small haplotype length, but accurate, as expected.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Results for chromosome 1 of a tetraploid potato with coverage 10 per haploid and a SNP rate of 0.01</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Method</th><th>Avg. haplotype block length<break/>(no. SNPs)</th><th>N50 haplotype block length (bp)</th><th>Reconstruction rate</th><th>Vector error rate</th><th>MEC</th><th>CPU time<break/>(min)</th></tr></thead><tbody><tr><td>SDhaP</td><td>–</td><td>–</td><td>–</td><td>–</td><td>–</td><td>–</td></tr><tr><td>H-PoP</td><td>12</td><td>1597</td><td>0.93</td><td>0.11</td><td>36,228</td><td>39</td></tr><tr><td>Hap++</td><td>3923</td><td>828,058</td><td>0.88</td><td>0.0083</td><td>342,956</td><td>741</td></tr><tr><td>Hap10</td><td>3923</td><td>828,058</td><td>0.92</td><td>0.0070</td><td>218,635</td><td>54,835</td></tr></tbody></table></table-wrap></p>
      </sec>
    </sec>
    <sec id="Sec19">
      <title>Real data</title>
      <p id="Par67">To obtain an idea of the applicability of Hap++ and Hap10 to real data, we ran the pipeline to reconstruct the six haplotypes of chromosome one of sweet potato (with the length of 36 Mb) based on 10X data available in the NCBI Short Read Archive.</p>
      <p id="Par68">The length distribution of the reconstructed haplotypes is displayed in Fig. <xref rid="Fig6" ref-type="fig">6</xref>; the N50 length of the blocks is 78.4 resp. 78.3 kb for Hap++ and Hap10. To compare the two plots, note that the SNP positions assigned to haplotype blocks are determined using the strongly connected components, which are the same for Hap++ and Hap10. Afterwards, the alternative optimization routine employed by Hap10 can yield different results than found by Hap++. The MEC scores between the read set and the reconstructed haplotypes are 122,363 resp. 133,282 for the reconstructed haplotypes using Hap++ and Hap10, respectively, which would indicate that in this case the reconstructed haplotypes by Hap++ are more compatible with the read dataset than those generated by Hap10. However, true accuracy can only be evaluated by comparison to a ground truth.
<fig id="Fig6"><label>Fig. 6</label><caption><p>Haplotype block length distributions for 10X real data of sweet potato using Hap++ (top) and Hap10 (bottom)</p></caption><graphic xlink:href="12859_2020_3584_Fig6_HTML" id="MO6"/></fig></p>
    </sec>
  </sec>
  <sec id="Sec20">
    <title>Conclusion</title>
    <p id="Par69">We developed a first haplotyping pipeline specifically for linked-read data generated from a polyploid genome. It makes haplotyping full chromosomes of complex genomes feasible. The proposed Hap++ preprocessing pipeline improves on the accuracy of immediate application of SDhaP by approximately 30% (resp. 20%) on simulated 10X data of triploids (resp. tetraploids) at the cost of a decreased haplotype block length. Our framework builds on SDhaP, a typical Illumina haplotyping algorithm, using a standard fragment file as input. Any improvement in SDhaP or similar algorithms thus may immediately enhance linked-read (SLR) haplotyping. The proposed novel optimization scheme, Hap10, provides even more accurate haplotypes, albeit at significant computational cost.</p>
    <p id="Par70">One topic for future research is to consider different optimization techniques for the max-<italic>K</italic>-cut clustering problem [<xref ref-type="bibr" rid="CR36">36</xref>]. A new method based on linear programming [<xref ref-type="bibr" rid="CR37">37</xref>] may provide a solution for overcoming the high runtime involved in the semidefinite programming problem. A second avenue for research is automatic optimization of the key parameters of the pipeline, specifically the threshold <italic>t</italic> for the normalized cut algorithm and the convergence threshold used in the optimization step.</p>
  </sec>
  <sec sec-type="supplementary-material">
    <title>Supplementary information</title>
    <sec id="Sec21">
      <p>
        <supplementary-material content-type="local-data" id="MOESM1">
          <media xlink:href="12859_2020_3584_MOESM1_ESM.jpg">
            <caption>
              <p><bold>Additional file 1: Figure S1.</bold> Description of the fragment file format using an example SAM and VCF input. <bold>A)</bold> In the SAM format, each line corresponds to a read (except for the header lines). The fourth column shows the genomic position of the first base of the aligned read. As a simple example, for each read 10 bases are shown in the 10th column. The next column shows the Phred quality of each base. Finally, the BX tag shows the barcode of each read provided by LongRanger software. For more information on the SAM format, see <ext-link ext-link-type="uri" xlink:href="http://samtools.github.io">http://samtools.github.io</ext-link>. <bold>B)</bold> In the VCF format, the second column shows the genomic position of the variant in each line (except for the header lines). The third and fourth columns contain the reference and alternative alleles, respectively. The last column shows the genotype of the variant, in this example for a triploid. For more information on the SAM format see <ext-link ext-link-type="uri" xlink:href="http://samtools.github.io">http://samtools.github.io</ext-link>. <bold>C)</bold> In fragment file designed for short reads, the first column shows the number of consecutive alleles (called part here) in the fragment, the second column the id of the fragment, the third column the start position of the first part, followed by the alleles of the part. The position is reported as the index of the variant in the VCF file, starting from 1. If there are more parts, they will appear next. The last column shows the Phred quality scores of all alleles in all parts consecutively. <bold>D)</bold> To include the barcode information for haplotyping, the barcodes in the SAM file BX tag are provided in the third column of the fragment file. The other columns are shifted accordingly. <bold>E)</bold> In Barcode-specific fragment file, reads with the same barcode are combined, as discussed in step one of "<xref rid="Sec4" ref-type="sec">Hap++</xref>" Section. <bold>F)</bold> Molecule-specific fragments file is the output of step one of "<xref rid="Sec4" ref-type="sec">Hap++</xref>" Section. The third column, which was the barcode, is iterated from one to the number of molecules for each barcode with an underscore in between. <bold>G)</bold> A schematic of the mentioned procedures is illustrated here. Eight fragments are presented in the image, colors indicating barcodes. In all three boxes, row corresponds to a line in the corresponding file.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM2">
          <media xlink:href="12859_2020_3584_MOESM2_ESM.jpg">
            <caption>
              <p><bold>Additional file 2: Figure S2.</bold> A graph indicating overlap between fragments. Red dots are vertices (corresponding to the fragments), grey lines are edges drawn when two fragments have at least one SNP in common. The depicted graph is for a case with 5 mb reference genome containing an N-region of 50 kb. The coverage is 15 per haploid and the SNP rate is 0.01. The average length of 10X DNA molecules for this simulation is set to 50 kb. Few fragments originate from a DNA molecule larger than 50 kb. The resulting graph has two separate subgraphs connected by a single edge. Note that one barcode-specific fragment connecting two read blocks is not sufficient for connecting the corresponding haplotypes. This phenomenon decreases the quality of reconstructed haplotype. The figure is generated using Cytoscape (<ext-link ext-link-type="uri" xlink:href="http://www.cytoscape.org">www.cytoscape.org</ext-link>).</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM3">
          <media xlink:href="12859_2020_3584_MOESM3_ESM.docx">
            <caption>
              <p><bold>Additional file 3: Table S1.</bold> An example of the haplotype output format. We report the reconstructed haplotypes as a text file with a specific format similar to that of HapCUT2. Each haplotype block starts with a line describing the length of the haplotype, number of reads corresponding to the block and the minimum error correction (MEC) score. From the next line, each row corresponds to each variant. The first and second columns show the 1-based index and variant position, respectively. Then, the next 2 ∗ ploidy columns are haplotypes and quality scores. For each allele of haplotypes, a quality score is provided. As a metric for quality, we use the number of matching reads at each position that are estimated for each haplotype.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM4">
          <media xlink:href="12859_2020_3584_MOESM4_ESM.docx">
            <caption>
              <p><bold>Additional file 4: Table S2.</bold> The impact of the convergence threshold on Hap10 performance. A triploid genome of 230 kb with a SNP rate of 0.001 is simulated. The average molecule length and number of molecules per bead are 50 k and 10, respectively.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM5">
          <media xlink:href="12859_2020_3584_MOESM5_ESM.docx">
            <caption>
              <p><bold>Additional file 5: Table S3.</bold> SDhaP with and without linked-read information. For the latter, the input data is considered as regular Illumina reads and barcodes are not used. The dataset is simulated using 1 Mb of chromosome one of potato genome with a SNP rate of 0.01. The coverage is 10. The results are averaged over 5 independent simulations. For the third row, we split the 1 Mb region into three independent parts of the same size. The last two rows present results of Hap++ and Hap10 on the same data.</p>
            </caption>
          </media>
        </supplementary-material>
        <supplementary-material content-type="local-data" id="MOESM6">
          <media xlink:href="12859_2020_3584_MOESM6_ESM.docx">
            <caption>
              <p><bold>Additional file 6: Table S4.</bold> Performance of SDhaP at different coverage levels, for a triploid genome with SNP rate of 0.001. The average molecule length and number of molecules per bead are 50 k and 10, respectively. The results are averaged over 5 independent simulations.</p>
            </caption>
          </media>
        </supplementary-material>
      </p>
    </sec>
  </sec>
</body>
<back>
  <glossary>
    <title>Abbreviations</title>
    <def-list>
      <def-item>
        <term>BAM</term>
        <def>
          <p id="Par4">Binary sequence alignment</p>
        </def>
      </def-item>
      <def-item>
        <term>bp</term>
        <def>
          <p id="Par5">Base pair</p>
        </def>
      </def-item>
      <def-item>
        <term>extractHAIRs</term>
        <def>
          <p id="Par6">Extract haplotype informative reads</p>
        </def>
      </def-item>
      <def-item>
        <term>MEC</term>
        <def>
          <p id="Par7">Minimum error correction</p>
        </def>
      </def-item>
      <def-item>
        <term>MFR</term>
        <def>
          <p id="Par8">Minimum fragment removal</p>
        </def>
      </def-item>
      <def-item>
        <term>NC</term>
        <def>
          <p id="Par9">Normalized cut</p>
        </def>
      </def-item>
      <def-item>
        <term>RR</term>
        <def>
          <p id="Par10">Reconstruction rate</p>
        </def>
      </def-item>
      <def-item>
        <term>SLRs</term>
        <def>
          <p id="Par11">Synthetic long reads</p>
        </def>
      </def-item>
      <def-item>
        <term>SNP</term>
        <def>
          <p id="Par12">Single nucleotide polymorphism</p>
        </def>
      </def-item>
      <def-item>
        <term>VCF</term>
        <def>
          <p id="Par13">Variant call format</p>
        </def>
      </def-item>
    </def-list>
  </glossary>
  <fn-group>
    <fn>
      <p>
        <bold>Publisher’s Note</bold>
      </p>
      <p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
    </fn>
  </fn-group>
  <sec>
    <title>Supplementary information</title>
    <p><bold>Supplementary information</bold> accompanies this paper at 10.1186/s12859-020-03584-5.</p>
  </sec>
  <ack>
    <title>Acknowledgements</title>
    <p>We would like to thank Brian Lavrijssen for helpful discussions.</p>
  </ack>
  <notes notes-type="author-contribution">
    <title>Authors’ contributions</title>
    <p>Methods and experiments were designed by SM and DdR. Algorithm code was implemented by SM. SM and DdR wrote the manuscript. DdR and MHK supervised the project. All authors read and approved the final manuscript.</p>
  </notes>
  <notes notes-type="funding-information">
    <title>Funding</title>
    <p>The authors received no specific funding for this work.</p>
  </notes>
  <notes notes-type="data-availability">
    <title>Availability of data and materials</title>
    <p>● Reference genome of <italic>Solanum tuberosum</italic></p>
    <p>
      <ext-link ext-link-type="uri" xlink:href="ftp://ftp.ensemblgenomes.org/pub/plants/release-42/fasta/solanum_tuberosum/dna/">ftp://ftp.ensemblgenomes.org/pub/plants/release-42/fasta/solanum_tuberosum/dna/</ext-link>
    </p>
    <p>● 10X read data of sweet potato: <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/sra/SRX4706082">https://www.ncbi.nlm.nih.gov/sra/SRX4706082</ext-link></p>
    <p>● LRSIM: <ext-link ext-link-type="uri" xlink:href="https://github.com/aquaskyline/LRSIM">https://github.com/aquaskyline/LRSIM</ext-link></p>
    <p>● LongRanger: <ext-link ext-link-type="uri" xlink:href="https://github.com/10XGenomics/longranger">https://github.com/10XGenomics/longranger</ext-link></p>
    <p>● FreeBayes: <ext-link ext-link-type="uri" xlink:href="https://github.com/ekg/freebayes">https://github.com/ekg/freebayes</ext-link></p>
    <p>● SDPNAL+: <ext-link ext-link-type="uri" xlink:href="https://blog.nus.edu.sg/mattohkc/softwares/sdpnalplus/">https://blog.nus.edu.sg/mattohkc/softwares/sdpnalplus/</ext-link></p>
    <p>● Scikit-learn: <ext-link ext-link-type="uri" xlink:href="https://scikit-learn.org/">https://scikit-learn.org/</ext-link></p>
    <p>● SDhaP: <ext-link ext-link-type="uri" xlink:href="https://sourceforge.net/projects/SDhaP/">https://sourceforge.net/projects/SDhaP/</ext-link></p>
    <p>● Our pipeline and code: <ext-link ext-link-type="uri" xlink:href="https://github.com/smajidian/Hap10">https://github.com/smajidian/Hap10</ext-link></p>
  </notes>
  <notes id="FPar1">
    <title>Ethics approval and consent to participate</title>
    <p id="Par71">Not applicable.</p>
  </notes>
  <notes id="FPar2">
    <title>Consent for publication</title>
    <p id="Par72">Not applicable.</p>
  </notes>
  <notes id="FPar3" notes-type="COI-statement">
    <title>Competing interests</title>
    <p id="Par73">Author Dick de Ridder is an Associate Editor for BMC Bioinformatics.</p>
  </notes>
  <ref-list id="Bib1">
    <title>References</title>
    <ref id="CR1">
      <label>1.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Comai</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>The advantages and disadvantages of being polyploid</article-title>
        <source>Nat Rev Genet</source>
        <year>2005</year>
        <volume>6</volume>
        <issue>11</issue>
        <fpage>836</fpage>
        <lpage>846</lpage>
        <?supplied-pmid 16304599?>
        <pub-id pub-id-type="pmid">16304599</pub-id>
      </element-citation>
    </ref>
    <ref id="CR2">
      <label>2.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Qian</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Hickey</surname>
            <given-names>LT</given-names>
          </name>
          <name>
            <surname>Stahl</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Werner</surname>
            <given-names>CR</given-names>
          </name>
          <name>
            <surname>Hayes</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Snowdon</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Voss-Fels</surname>
            <given-names>KP</given-names>
          </name>
        </person-group>
        <article-title>Exploring and harnessing haplotype diversity to improve yield stability in crops</article-title>
        <source>Front Plant Sci</source>
        <year>2017</year>
        <volume>8</volume>
        <fpage>1534</fpage>
        <?supplied-pmid 28928764?>
        <pub-id pub-id-type="pmid">28928764</pub-id>
      </element-citation>
    </ref>
    <ref id="CR3">
      <label>3.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Liu</surname>
            <given-names>PY</given-names>
          </name>
          <name>
            <surname>Zhang</surname>
            <given-names>YY</given-names>
          </name>
          <name>
            <surname>Lu</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Long</surname>
            <given-names>JR</given-names>
          </name>
          <name>
            <surname>Shen</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhao</surname>
            <given-names>LJ</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>A survey of haplotype variants at several disease candidate genes: the importance of rare variants for complex diseases</article-title>
        <source>J Med Genet</source>
        <year>2005</year>
        <volume>42</volume>
        <issue>3</issue>
        <fpage>221</fpage>
        <lpage>227</lpage>
        <?supplied-pmid 15744035?>
        <pub-id pub-id-type="pmid">15744035</pub-id>
      </element-citation>
    </ref>
    <ref id="CR4">
      <label>4.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Motazedi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Finkers</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Maliepaard</surname>
            <given-names>C</given-names>
          </name>
          <name>
            <surname>de Ridder</surname>
            <given-names>D</given-names>
          </name>
        </person-group>
        <article-title>Exploiting next-generation sequencing to solve the haplotyping puzzle in polyploids: a simulation study</article-title>
        <source>Brief Bioinform</source>
        <year>2017</year>
        <volume>19</volume>
        <issue>3</issue>
        <fpage>387</fpage>
        <lpage>403</lpage>
      </element-citation>
    </ref>
    <ref id="CR5">
      <label>5.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Choi</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Chan</surname>
            <given-names>AP</given-names>
          </name>
          <name>
            <surname>Kirkness</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Telenti</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Schork</surname>
            <given-names>NJ</given-names>
          </name>
        </person-group>
        <article-title>Comparison of phasing strategies for whole human genomes</article-title>
        <source>PLoS Genet</source>
        <year>2018</year>
        <volume>14</volume>
        <issue>4</issue>
        <fpage>e1007308</fpage>
        <?supplied-pmid 29621242?>
        <pub-id pub-id-type="pmid">29621242</pub-id>
      </element-citation>
    </ref>
    <ref id="CR6">
      <label>6.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Zhang</surname>
            <given-names>X</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>Y</given-names>
          </name>
          <name>
            <surname>Yu</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Tang</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>Unzipping haplotypes in diploid and polyploid genomes</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2020</year>
        <volume>18</volume>
        <fpage>66</fpage>
        <lpage>72</lpage>
        <?supplied-pmid 31908732?>
        <pub-id pub-id-type="pmid">31908732</pub-id>
      </element-citation>
    </ref>
    <ref id="CR7">
      <label>7.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Berger</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Yorukoglu</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Peng</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Berger</surname>
            <given-names>B</given-names>
          </name>
        </person-group>
        <article-title>HapTree: a novel Bayesian framework for single individual polyplotyping using NGS data</article-title>
        <source>PLoS Comput Biol</source>
        <year>2014</year>
        <volume>10</volume>
        <issue>3</issue>
        <fpage>e1003502</fpage>
        <?supplied-pmid 24675685?>
        <pub-id pub-id-type="pmid">24675685</pub-id>
      </element-citation>
    </ref>
    <ref id="CR8">
      <label>8.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Das</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Vikalo</surname>
            <given-names>H</given-names>
          </name>
        </person-group>
        <article-title>SDhaP: haplotype assembly for diploids and polyploids via semi-definite programming</article-title>
        <source>BMC Genomics</source>
        <year>2015</year>
        <volume>16</volume>
        <fpage>260</fpage>
        <?supplied-pmid 25885901?>
        <pub-id pub-id-type="pmid">25885901</pub-id>
      </element-citation>
    </ref>
    <ref id="CR9">
      <label>9.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Xie</surname>
            <given-names>M</given-names>
          </name>
          <name>
            <surname>Wu</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Wang</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Jiang</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>H-PoP and H-PoPG: heuristic partitioning algorithms for single individual haplotyping of polyploids</article-title>
        <source>Bioinformatics</source>
        <year>2016</year>
        <volume>32</volume>
        <issue>24</issue>
        <fpage>3735</fpage>
        <lpage>3744</lpage>
        <?supplied-pmid 27531103?>
        <pub-id pub-id-type="pmid">27531103</pub-id>
      </element-citation>
    </ref>
    <ref id="CR10">
      <label>10.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Siragusa</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Haiminen</surname>
            <given-names>N</given-names>
          </name>
          <name>
            <surname>Finkers</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Visser</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Parida</surname>
            <given-names>L</given-names>
          </name>
        </person-group>
        <article-title>Haplotype assembly of autotetraploid potato using integer linear programming</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35</volume>
        <issue>21</issue>
        <fpage>4534</fpage>
        <?supplied-pmid 31280288?>
        <pub-id pub-id-type="pmid">31280288</pub-id>
      </element-citation>
    </ref>
    <ref id="CR11">
      <label>11.</label>
      <mixed-citation publication-type="other">Schrinner S, Mari RS, Ebler JW, Rautiainen M, Seillier L, Reimer J, Usadel B, Marschall T and Klau GW. "Haplotype threading: accurate polyploid phasing from long reads. 2020. BioRxiv. <pub-id pub-id-type="doi">10.1101/2020.02.04.933523.</pub-id>.</mixed-citation>
    </ref>
    <ref id="CR12">
      <label>12.</label>
      <mixed-citation publication-type="other">He D, Saha S, Finkers R, Parida L. Efficient algorithms for polyploid haplotype phasing. BMC Genomics. 2018;19(Suppl 2):171-80. Article number 110. 10.1186/s12864-018-4464-9.</mixed-citation>
    </ref>
    <ref id="CR13">
      <label>13.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Aguiar</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Istrail</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Haplotype assembly in polyploid genomes and identical by descent shared tracts</article-title>
        <source>Bioinformatics.</source>
        <year>2013</year>
        <volume>29</volume>
        <issue>13</issue>
        <fpage>i352</fpage>
        <lpage>i360</lpage>
        <?supplied-pmid 23813004?>
        <pub-id pub-id-type="pmid">23813004</pub-id>
      </element-citation>
    </ref>
    <ref id="CR14">
      <label>14.</label>
      <mixed-citation publication-type="other">Moeinzadeh MH. De novo and haplotype assembly of polyploid genomes. PhD thesis. Germany: Freie Universität Berlin; 2019. <pub-id pub-id-type="doi">10.17169/refubium-2712</pub-id>.</mixed-citation>
    </ref>
    <ref id="CR15">
      <label>15.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Goodwin</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>McPherson</surname>
            <given-names>JD</given-names>
          </name>
          <name>
            <surname>McCombie</surname>
            <given-names>WR</given-names>
          </name>
        </person-group>
        <article-title>Coming of age: ten years of next-generation sequencing technologies</article-title>
        <source>Nat Rev Genet</source>
        <year>2016</year>
        <volume>17</volume>
        <issue>6</issue>
        <fpage>333</fpage>
        <lpage>351</lpage>
        <?supplied-pmid 27184599?>
        <pub-id pub-id-type="pmid">27184599</pub-id>
      </element-citation>
    </ref>
    <ref id="CR16">
      <label>16.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wenger</surname>
            <given-names>AM</given-names>
          </name>
          <name>
            <surname>Peluso</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Rowell</surname>
            <given-names>WJ</given-names>
          </name>
          <name>
            <surname>Chang</surname>
            <given-names>PC</given-names>
          </name>
          <name>
            <surname>Hall</surname>
            <given-names>RJ</given-names>
          </name>
          <name>
            <surname>Concepcion</surname>
            <given-names>GT</given-names>
          </name>
          <name>
            <surname>Ebler</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Fungtammasan</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Kolesnikov</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Olson</surname>
            <given-names>ND</given-names>
          </name>
          <name>
            <surname>Töpfer</surname>
            <given-names>A</given-names>
          </name>
        </person-group>
        <article-title>Accurate circular consensus long-read sequencing improves variant detection and assembly of a human genome</article-title>
        <source>Nat Biotechnol</source>
        <year>2019</year>
        <volume>37</volume>
        <issue>10</issue>
        <fpage>1155</fpage>
        <lpage>1162</lpage>
        <?supplied-pmid 31406327?>
        <pub-id pub-id-type="pmid">31406327</pub-id>
      </element-citation>
    </ref>
    <ref id="CR17">
      <label>17.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Weisenfeld</surname>
            <given-names>NI</given-names>
          </name>
          <name>
            <surname>Kumar</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Shah</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Church</surname>
            <given-names>DM</given-names>
          </name>
          <name>
            <surname>Jaffe</surname>
            <given-names>DB</given-names>
          </name>
        </person-group>
        <article-title>Direct determination of diploid genome sequences</article-title>
        <source>Genome Res</source>
        <year>2017</year>
        <volume>27</volume>
        <issue>5</issue>
        <fpage>757</fpage>
        <lpage>767</lpage>
        <?supplied-pmid 28381613?>
        <pub-id pub-id-type="pmid">28381613</pub-id>
      </element-citation>
    </ref>
    <ref id="CR18">
      <label>18.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Tolstoganov</surname>
            <given-names>I</given-names>
          </name>
          <name>
            <surname>Bankevich</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Chen</surname>
            <given-names>Z</given-names>
          </name>
          <name>
            <surname>Pevzner</surname>
            <given-names>PA</given-names>
          </name>
        </person-group>
        <article-title>cloudSPAdes: assembly of synthetic long reads using de Bruijn graphs</article-title>
        <source>Bioinformatics</source>
        <year>2019</year>
        <volume>35.14</volume>
        <fpage>i61</fpage>
        <lpage>i70</lpage>
        <pub-id pub-id-type="pmid">31510642</pub-id>
      </element-citation>
    </ref>
    <ref id="CR19">
      <label>19.</label>
      <mixed-citation publication-type="other">Marks P, Garcia S, Barrio AM, Belhocine K, Bernate J, Bharadwaj R, et al. Resolving the full spectrum of human genome variation using linked-reads. Genome Res. 2019;29(4):635–45.</mixed-citation>
    </ref>
    <ref id="CR20">
      <label>20.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Edge</surname>
            <given-names>P</given-names>
          </name>
          <name>
            <surname>Bafna</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Bansal</surname>
            <given-names>V</given-names>
          </name>
        </person-group>
        <article-title>HapCUT2: robust and accurate haplotype assembly for diverse sequencing technologies</article-title>
        <source>Genome Res</source>
        <year>2017</year>
        <volume>27</volume>
        <issue>5</issue>
        <fpage>801</fpage>
        <lpage>812</lpage>
        <?supplied-pmid 27940952?>
        <pub-id pub-id-type="pmid">27940952</pub-id>
      </element-citation>
    </ref>
    <ref id="CR21">
      <label>21.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Porubsky</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Garg</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Sanders</surname>
            <given-names>AD</given-names>
          </name>
          <name>
            <surname>Korbel</surname>
            <given-names>JO</given-names>
          </name>
          <name>
            <surname>Guryev</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Lansdorp</surname>
            <given-names>PM</given-names>
          </name>
          <name>
            <surname>Marschall</surname>
            <given-names>T</given-names>
          </name>
        </person-group>
        <article-title>Dense and accurate whole-chromosome haplotyping of individual genomes</article-title>
        <source>Nat Commun</source>
        <year>2017</year>
        <volume>8</volume>
        <issue>1</issue>
        <fpage>1</fpage>
        <lpage>10</lpage>
        <pub-id pub-id-type="pmid">28232747</pub-id>
      </element-citation>
    </ref>
    <ref id="CR22">
      <label>22.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Majidian</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Kahaei</surname>
            <given-names>MH</given-names>
          </name>
        </person-group>
        <article-title>NGS based haplotype assembly using matrix completion</article-title>
        <source>PLoS One</source>
        <year>2019</year>
        <volume>14</volume>
        <issue>3</issue>
        <fpage>e0214455</fpage>
        <?supplied-pmid 30913270?>
        <pub-id pub-id-type="pmid">30913270</pub-id>
      </element-citation>
    </ref>
    <ref id="CR23">
      <label>23.</label>
      <mixed-citation publication-type="other">Garrison E, Marth G. Haplotype-based variant detection from short-read sequencing.  2012. ​arXiv preprint q-bio.GN/1207.3907.</mixed-citation>
    </ref>
    <ref id="CR24">
      <label>24.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Motazedi</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>de Ridder</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Finkers</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Baldwin</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Thomson</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Monaghan</surname>
            <given-names>K</given-names>
          </name>
          <name>
            <surname>Maliepaard</surname>
            <given-names>C</given-names>
          </name>
        </person-group>
        <article-title>TriPoly: haplotype estimation for polyploids using sequencing data of related individuals</article-title>
        <source>Bioinformatics</source>
        <year>2018</year>
        <volume>34</volume>
        <issue>22</issue>
        <fpage>3864</fpage>
        <lpage>3872</lpage>
        <?supplied-pmid 29868858?>
        <pub-id pub-id-type="pmid">29868858</pub-id>
      </element-citation>
    </ref>
    <ref id="CR25">
      <label>25.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Comaniciu</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Meer</surname>
            <given-names>P</given-names>
          </name>
        </person-group>
        <article-title>Mean shift: a robust approach toward feature space analysis</article-title>
        <source>IEEE Trans Pattern Anal Mach Intell</source>
        <year>2002</year>
        <volume>24</volume>
        <issue>5</issue>
        <fpage>603</fpage>
        <lpage>619</lpage>
      </element-citation>
    </ref>
    <ref id="CR26">
      <label>26.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Pedregosa</surname>
            <given-names>F</given-names>
          </name>
          <name>
            <surname>Varoquaux</surname>
            <given-names>G</given-names>
          </name>
          <name>
            <surname>Gramfort</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Michel</surname>
            <given-names>V</given-names>
          </name>
          <name>
            <surname>Thirion</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Grisel</surname>
            <given-names>O</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Scikit-learn: machine learning in Python</article-title>
        <source>J Mach Learn Res</source>
        <year>2011</year>
        <volume>12</volume>
        <fpage>2825</fpage>
        <lpage>2830</lpage>
      </element-citation>
    </ref>
    <ref id="CR27">
      <label>27.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Shi</surname>
            <given-names>J</given-names>
          </name>
          <name>
            <surname>Malik</surname>
            <given-names>J</given-names>
          </name>
        </person-group>
        <article-title>Normalized cuts and image segmentation</article-title>
        <source>IEEE Trans Pattern Anal Mach Intell</source>
        <year>2000</year>
        <volume>22</volume>
        <issue>8</issue>
        <fpage>888</fpage>
        <lpage>905</lpage>
      </element-citation>
    </ref>
    <ref id="CR28">
      <label>28.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Frieze</surname>
            <given-names>A</given-names>
          </name>
          <name>
            <surname>Jerrum</surname>
            <given-names>M</given-names>
          </name>
        </person-group>
        <article-title>Improved approximation algorithms for max <italic>k</italic>-cut and max bisection</article-title>
        <source>Algorithmica</source>
        <year>1997</year>
        <volume>18</volume>
        <issue>1</issue>
        <fpage>67</fpage>
        <lpage>81</lpage>
      </element-citation>
    </ref>
    <ref id="CR29">
      <label>29.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Klerk</surname>
            <given-names>E</given-names>
          </name>
          <name>
            <surname>Pasechnik</surname>
            <given-names>DV</given-names>
          </name>
          <name>
            <surname>Warners</surname>
            <given-names>JP</given-names>
          </name>
        </person-group>
        <article-title>On approximate graph colouring and max-<italic>k</italic>-cut algorithms based on the θ-function</article-title>
        <source>J Comb Optim</source>
        <year>2004</year>
        <volume>8</volume>
        <issue>3</issue>
        <fpage>267</fpage>
        <lpage>294</lpage>
      </element-citation>
    </ref>
    <ref id="CR30">
      <label>30.</label>
      <element-citation publication-type="book">
        <person-group person-group-type="author">
          <name>
            <surname>Boyd</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <source>Vandenberghe L</source>
        <year>2004</year>
        <publisher-loc>Convex optimization</publisher-loc>
        <publisher-name>Cambridge University Press</publisher-name>
      </element-citation>
    </ref>
    <ref id="CR31">
      <label>31.</label>
      <mixed-citation publication-type="other">Rockafellar RT. Augmented Lagrangians and applications of the proximal point algorithm in convex programming. Math Oper Res USA. 1976;1(2):97–116.</mixed-citation>
    </ref>
    <ref id="CR32">
      <label>32.</label>
      <mixed-citation publication-type="other">Golub GH, Van Loan CF. Matrix computations: Johns Hopkins University Press; 1996.</mixed-citation>
    </ref>
    <ref id="CR33">
      <label>33.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Yang</surname>
            <given-names>L</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>D</given-names>
          </name>
          <name>
            <surname>Toh</surname>
            <given-names>KC</given-names>
          </name>
        </person-group>
        <article-title>SDPNAL++: a majorized semismooth Newton-CG augmented Lagrangian method for semidefinite programming with nonnegative constraints</article-title>
        <source>Math Program Comput</source>
        <year>2015</year>
        <volume>7</volume>
        <issue>3</issue>
        <fpage>331</fpage>
        <lpage>366</lpage>
      </element-citation>
    </ref>
    <ref id="CR34">
      <label>34.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Luo</surname>
            <given-names>R</given-names>
          </name>
          <name>
            <surname>Sedlazeck</surname>
            <given-names>FJ</given-names>
          </name>
          <name>
            <surname>Darby</surname>
            <given-names>CA</given-names>
          </name>
          <name>
            <surname>Kelly</surname>
            <given-names>SM</given-names>
          </name>
          <name>
            <surname>Schatz</surname>
            <given-names>MC</given-names>
          </name>
        </person-group>
        <article-title>LRSim: a linked reads simulator generating insights for better genome partitioning</article-title>
        <source>Comput Struct Biotechnol J</source>
        <year>2017</year>
        <volume>15</volume>
        <fpage>478</fpage>
        <lpage>484</lpage>
        <?supplied-pmid 29213995?>
        <pub-id pub-id-type="pmid">29213995</pub-id>
      </element-citation>
    </ref>
    <ref id="CR35">
      <label>35.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Wu</surname>
            <given-names>S</given-names>
          </name>
          <name>
            <surname>Lau</surname>
            <given-names>KH</given-names>
          </name>
          <name>
            <surname>Cao</surname>
            <given-names>Q</given-names>
          </name>
          <name>
            <surname>Hamilton</surname>
            <given-names>JP</given-names>
          </name>
          <name>
            <surname>Sun</surname>
            <given-names>H</given-names>
          </name>
          <name>
            <surname>Zhou</surname>
            <given-names>C</given-names>
          </name>
          <etal/>
        </person-group>
        <article-title>Genome sequences of two diploid wild relatives of cultivated sweetpotato reveal targets for genetic improvement</article-title>
        <source>Nat Commun</source>
        <year>2018</year>
        <volume>9</volume>
        <issue>1</issue>
        <fpage>4580</fpage>
        <?supplied-pmid 30389915?>
        <pub-id pub-id-type="pmid">30389915</pub-id>
      </element-citation>
    </ref>
    <ref id="CR36">
      <label>36.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>Ghaddar</surname>
            <given-names>B</given-names>
          </name>
          <name>
            <surname>Anjos</surname>
            <given-names>MF</given-names>
          </name>
          <name>
            <surname>Liers</surname>
            <given-names>F</given-names>
          </name>
        </person-group>
        <article-title>A branch-and-cut algorithm based on semidefinite programming for the minimum <italic>k</italic>-partition problem</article-title>
        <source>Ann Oper Res</source>
        <year>2011</year>
        <volume>188</volume>
        <issue>1</issue>
        <fpage>155</fpage>
        <lpage>174</lpage>
      </element-citation>
    </ref>
    <ref id="CR37">
      <label>37.</label>
      <element-citation publication-type="journal">
        <person-group person-group-type="author">
          <name>
            <surname>de Sousa</surname>
            <given-names>VJR</given-names>
          </name>
          <name>
            <surname>Anjos</surname>
            <given-names>MF</given-names>
          </name>
          <name>
            <surname>Le Digabel</surname>
            <given-names>S</given-names>
          </name>
        </person-group>
        <article-title>Improving the linear relaxation of maximum <italic>k</italic>-cut with semidefinite-based constraints</article-title>
        <source>EURO J Comput Optimization</source>
        <year>2019</year>
        <volume>7</volume>
        <issue>2</issue>
        <fpage>123</fpage>
        <lpage>151</lpage>
      </element-citation>
    </ref>
  </ref-list>
</back>
